I0832 2019-01-16 08:08:34.819652 ops/training.py:229 Log written to /gpfs_home/dlinsley/cluttered_nist_experiments/logs/nist_3_ix2v2_50k_2019_01_16_08_07_39_512188
I0832 2019-01-16 08:13:42.929608 ops/training.py:396 Failed to save checkpoint: global name 'db' is not defined
I0832 2019-01-16 08:13:42.930437 ops/training.py:41 2019-01-16 08:13:42.930393: step 0, loss = 1.10 (0.1 examples/sec; 285.942 sec/batch) | Training accuracy = 0.5 | Validation accuracy = 0.499 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_08_07_39_512188
I0832 2019-01-16 08:13:43.890136 ops/training.py:65 2019-01-16 08:13:43.890079: step 1, loss = 1.09340 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:13:44.850778 ops/training.py:65 2019-01-16 08:13:44.850725: step 2, loss = 1.28281 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:13:45.814247 ops/training.py:65 2019-01-16 08:13:45.814192: step 3, loss = 0.97692 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:13:46.775518 ops/training.py:65 2019-01-16 08:13:46.775451: step 4, loss = 1.03017 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:13:47.735194 ops/training.py:65 2019-01-16 08:13:47.735143: step 5, loss = 0.93180 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:13:48.693420 ops/training.py:65 2019-01-16 08:13:48.693363: step 6, loss = 0.96354 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:13:49.654340 ops/training.py:65 2019-01-16 08:13:49.654296: step 7, loss = 0.90336 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:13:50.611879 ops/training.py:65 2019-01-16 08:13:50.611831: step 8, loss = 0.99574 (33.5 examples/sec; 0.957 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:13:51.568897 ops/training.py:65 2019-01-16 08:13:51.568851: step 9, loss = 1.11079 (33.5 examples/sec; 0.956 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:13:52.526712 ops/training.py:65 2019-01-16 08:13:52.526664: step 10, loss = 1.09464 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:13:53.490024 ops/training.py:65 2019-01-16 08:13:53.489985: step 11, loss = 0.76903 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:13:54.452240 ops/training.py:65 2019-01-16 08:13:54.452196: step 12, loss = 1.17456 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:13:55.413786 ops/training.py:65 2019-01-16 08:13:55.413742: step 13, loss = 1.00893 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:13:56.373128 ops/training.py:65 2019-01-16 08:13:56.373089: step 14, loss = 0.90004 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:13:57.331493 ops/training.py:65 2019-01-16 08:13:57.331451: step 15, loss = 1.07558 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:13:58.293893 ops/training.py:65 2019-01-16 08:13:58.293855: step 16, loss = 0.99083 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:13:59.257967 ops/training.py:65 2019-01-16 08:13:59.257929: step 17, loss = 1.12014 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:14:00.220521 ops/training.py:65 2019-01-16 08:14:00.220483: step 18, loss = 1.04288 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:14:01.184147 ops/training.py:65 2019-01-16 08:14:01.184092: step 19, loss = 0.83189 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:14:02.145331 ops/training.py:65 2019-01-16 08:14:02.145289: step 20, loss = 0.80873 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:14:03.105262 ops/training.py:65 2019-01-16 08:14:03.105225: step 21, loss = 1.17415 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:14:04.067255 ops/training.py:65 2019-01-16 08:14:04.067215: step 22, loss = 0.89887 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:14:05.027357 ops/training.py:65 2019-01-16 08:14:05.027318: step 23, loss = 0.89974 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:14:05.985778 ops/training.py:65 2019-01-16 08:14:05.985739: step 24, loss = 1.09417 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:14:06.944067 ops/training.py:65 2019-01-16 08:14:06.944021: step 25, loss = 0.99418 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:14:07.904201 ops/training.py:65 2019-01-16 08:14:07.904156: step 26, loss = 0.94095 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:14:08.868310 ops/training.py:65 2019-01-16 08:14:08.868271: step 27, loss = 0.77173 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:14:09.832170 ops/training.py:65 2019-01-16 08:14:09.832132: step 28, loss = 0.98174 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:14:10.795372 ops/training.py:65 2019-01-16 08:14:10.795330: step 29, loss = 0.80162 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:14:11.758507 ops/training.py:65 2019-01-16 08:14:11.758460: step 30, loss = 0.95747 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:14:12.722530 ops/training.py:65 2019-01-16 08:14:12.722478: step 31, loss = 0.86059 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:14:13.685675 ops/training.py:65 2019-01-16 08:14:13.685626: step 32, loss = 1.05937 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:14:14.649869 ops/training.py:65 2019-01-16 08:14:14.649818: step 33, loss = 0.97809 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:14:15.612495 ops/training.py:65 2019-01-16 08:14:15.612453: step 34, loss = 0.83890 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:14:16.576093 ops/training.py:65 2019-01-16 08:14:16.576054: step 35, loss = 0.87301 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:14:17.539400 ops/training.py:65 2019-01-16 08:14:17.539363: step 36, loss = 1.07667 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:14:18.502873 ops/training.py:65 2019-01-16 08:14:18.502835: step 37, loss = 1.23557 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:14:19.465267 ops/training.py:65 2019-01-16 08:14:19.465220: step 38, loss = 1.08482 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:14:20.424822 ops/training.py:65 2019-01-16 08:14:20.424754: step 39, loss = 0.90763 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:14:21.384662 ops/training.py:65 2019-01-16 08:14:21.384616: step 40, loss = 1.12291 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:14:22.347167 ops/training.py:65 2019-01-16 08:14:22.347125: step 41, loss = 1.10307 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:14:23.310333 ops/training.py:65 2019-01-16 08:14:23.310284: step 42, loss = 1.17974 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:14:24.272574 ops/training.py:65 2019-01-16 08:14:24.272518: step 43, loss = 1.13672 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:14:25.235439 ops/training.py:65 2019-01-16 08:14:25.235392: step 44, loss = 0.94551 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:14:26.197621 ops/training.py:65 2019-01-16 08:14:26.197567: step 45, loss = 1.12076 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:14:27.159961 ops/training.py:65 2019-01-16 08:14:27.159904: step 46, loss = 0.83780 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:14:28.123612 ops/training.py:65 2019-01-16 08:14:28.123548: step 47, loss = 0.92965 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:14:29.085330 ops/training.py:65 2019-01-16 08:14:29.085267: step 48, loss = 1.09686 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:14:30.046040 ops/training.py:65 2019-01-16 08:14:30.045990: step 49, loss = 1.07191 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:14:31.004986 ops/training.py:65 2019-01-16 08:14:31.004935: step 50, loss = 0.96236 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:14:31.965352 ops/training.py:65 2019-01-16 08:14:31.965289: step 51, loss = 1.03559 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:14:32.923703 ops/training.py:65 2019-01-16 08:14:32.923647: step 52, loss = 0.95941 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:14:33.886188 ops/training.py:65 2019-01-16 08:14:33.886137: step 53, loss = 1.06455 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:14:34.846930 ops/training.py:65 2019-01-16 08:14:34.846884: step 54, loss = 0.82565 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:14:35.806372 ops/training.py:65 2019-01-16 08:14:35.806320: step 55, loss = 0.68749 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:14:36.764789 ops/training.py:65 2019-01-16 08:14:36.764749: step 56, loss = 0.83893 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:14:37.728056 ops/training.py:65 2019-01-16 08:14:37.728008: step 57, loss = 0.83733 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:14:38.691197 ops/training.py:65 2019-01-16 08:14:38.691142: step 58, loss = 0.81976 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:14:39.654849 ops/training.py:65 2019-01-16 08:14:39.654794: step 59, loss = 1.07805 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:14:40.613861 ops/training.py:65 2019-01-16 08:14:40.613806: step 60, loss = 0.88863 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:14:41.580791 ops/training.py:65 2019-01-16 08:14:41.580746: step 61, loss = 0.75717 (33.1 examples/sec; 0.966 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:14:42.543546 ops/training.py:65 2019-01-16 08:14:42.543493: step 62, loss = 0.91625 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:14:43.504432 ops/training.py:65 2019-01-16 08:14:43.504374: step 63, loss = 0.79658 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:14:44.462678 ops/training.py:65 2019-01-16 08:14:44.462625: step 64, loss = 1.02166 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:14:45.419870 ops/training.py:65 2019-01-16 08:14:45.419817: step 65, loss = 0.72133 (33.5 examples/sec; 0.956 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:14:46.378079 ops/training.py:65 2019-01-16 08:14:46.378041: step 66, loss = 0.92308 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:14:47.337362 ops/training.py:65 2019-01-16 08:14:47.337321: step 67, loss = 0.87903 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:14:48.300128 ops/training.py:65 2019-01-16 08:14:48.300084: step 68, loss = 1.11030 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:14:49.263278 ops/training.py:65 2019-01-16 08:14:49.263235: step 69, loss = 0.96139 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:14:50.224306 ops/training.py:65 2019-01-16 08:14:50.224266: step 70, loss = 0.86684 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:14:51.184173 ops/training.py:65 2019-01-16 08:14:51.184129: step 71, loss = 0.78532 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:14:52.148253 ops/training.py:65 2019-01-16 08:14:52.148210: step 72, loss = 0.83742 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:14:53.112874 ops/training.py:65 2019-01-16 08:14:53.112827: step 73, loss = 0.94968 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:14:54.075307 ops/training.py:65 2019-01-16 08:14:54.075267: step 74, loss = 0.67933 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:14:55.037121 ops/training.py:65 2019-01-16 08:14:55.037075: step 75, loss = 1.12941 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:14:55.999599 ops/training.py:65 2019-01-16 08:14:55.999560: step 76, loss = 1.01092 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:14:56.961390 ops/training.py:65 2019-01-16 08:14:56.961353: step 77, loss = 0.80863 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:14:57.922719 ops/training.py:65 2019-01-16 08:14:57.922677: step 78, loss = 0.85062 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:14:58.885442 ops/training.py:65 2019-01-16 08:14:58.885401: step 79, loss = 0.98583 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:14:59.847828 ops/training.py:65 2019-01-16 08:14:59.847786: step 80, loss = 0.77425 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:15:00.808890 ops/training.py:65 2019-01-16 08:15:00.808848: step 81, loss = 0.83456 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:15:01.772721 ops/training.py:65 2019-01-16 08:15:01.772682: step 82, loss = 0.68740 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:15:02.735062 ops/training.py:65 2019-01-16 08:15:02.735025: step 83, loss = 0.63836 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:15:03.698136 ops/training.py:65 2019-01-16 08:15:03.698099: step 84, loss = 0.83855 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:15:04.660886 ops/training.py:65 2019-01-16 08:15:04.660848: step 85, loss = 0.97656 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:15:05.621599 ops/training.py:65 2019-01-16 08:15:05.621537: step 86, loss = 0.91466 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:15:06.579588 ops/training.py:65 2019-01-16 08:15:06.579536: step 87, loss = 0.86181 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:15:07.543611 ops/training.py:65 2019-01-16 08:15:07.543573: step 88, loss = 1.04996 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:15:08.508261 ops/training.py:65 2019-01-16 08:15:08.508223: step 89, loss = 1.00458 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:15:09.471274 ops/training.py:65 2019-01-16 08:15:09.471237: step 90, loss = 1.14449 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:15:10.433555 ops/training.py:65 2019-01-16 08:15:10.433513: step 91, loss = 0.86520 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:15:11.393682 ops/training.py:65 2019-01-16 08:15:11.393631: step 92, loss = 0.81355 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:15:12.356660 ops/training.py:65 2019-01-16 08:15:12.356622: step 93, loss = 0.89929 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:15:13.320034 ops/training.py:65 2019-01-16 08:15:13.319988: step 94, loss = 0.76142 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:15:14.284560 ops/training.py:65 2019-01-16 08:15:14.284520: step 95, loss = 1.15345 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:15:15.246357 ops/training.py:65 2019-01-16 08:15:15.246311: step 96, loss = 0.82661 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:15:16.207764 ops/training.py:65 2019-01-16 08:15:16.207711: step 97, loss = 0.77340 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:15:17.172045 ops/training.py:65 2019-01-16 08:15:17.172001: step 98, loss = 0.80720 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:15:18.136524 ops/training.py:65 2019-01-16 08:15:18.136474: step 99, loss = 1.26289 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:15:19.100453 ops/training.py:65 2019-01-16 08:15:19.100407: step 100, loss = 0.71402 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:15:20.064474 ops/training.py:65 2019-01-16 08:15:20.064429: step 101, loss = 0.96693 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:15:21.025303 ops/training.py:65 2019-01-16 08:15:21.025268: step 102, loss = 0.99581 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:15:21.985295 ops/training.py:65 2019-01-16 08:15:21.985248: step 103, loss = 0.92293 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:15:22.948907 ops/training.py:65 2019-01-16 08:15:22.948863: step 104, loss = 0.79352 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:15:23.912497 ops/training.py:65 2019-01-16 08:15:23.912455: step 105, loss = 0.84884 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:15:24.875068 ops/training.py:65 2019-01-16 08:15:24.875029: step 106, loss = 0.82412 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:15:25.836844 ops/training.py:65 2019-01-16 08:15:25.836807: step 107, loss = 1.04758 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:15:26.799633 ops/training.py:65 2019-01-16 08:15:26.799595: step 108, loss = 0.88027 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:15:27.761881 ops/training.py:65 2019-01-16 08:15:27.761844: step 109, loss = 0.74880 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:15:28.725438 ops/training.py:65 2019-01-16 08:15:28.725396: step 110, loss = 0.74997 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:15:29.688031 ops/training.py:65 2019-01-16 08:15:29.687994: step 111, loss = 1.02245 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:15:30.650478 ops/training.py:65 2019-01-16 08:15:30.650439: step 112, loss = 1.30880 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:15:31.613524 ops/training.py:65 2019-01-16 08:15:31.613467: step 113, loss = 0.96496 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:15:32.575820 ops/training.py:65 2019-01-16 08:15:32.575755: step 114, loss = 0.77196 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:15:33.536357 ops/training.py:65 2019-01-16 08:15:33.536296: step 115, loss = 0.95251 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:15:34.496291 ops/training.py:65 2019-01-16 08:15:34.496232: step 116, loss = 0.74042 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:15:35.460233 ops/training.py:65 2019-01-16 08:15:35.460166: step 117, loss = 1.09658 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:15:36.424412 ops/training.py:65 2019-01-16 08:15:36.424349: step 118, loss = 1.03669 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:15:37.387845 ops/training.py:65 2019-01-16 08:15:37.387790: step 119, loss = 0.81359 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:15:38.350063 ops/training.py:65 2019-01-16 08:15:38.350005: step 120, loss = 0.91856 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:15:39.312894 ops/training.py:65 2019-01-16 08:15:39.312823: step 121, loss = 1.08649 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:15:40.275182 ops/training.py:65 2019-01-16 08:15:40.275118: step 122, loss = 0.84556 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:15:41.237265 ops/training.py:65 2019-01-16 08:15:41.237199: step 123, loss = 0.69667 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:15:42.198357 ops/training.py:65 2019-01-16 08:15:42.198295: step 124, loss = 1.00714 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:15:43.159713 ops/training.py:65 2019-01-16 08:15:43.159646: step 125, loss = 1.03076 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:15:44.121598 ops/training.py:65 2019-01-16 08:15:44.121532: step 126, loss = 0.99540 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:15:45.083925 ops/training.py:65 2019-01-16 08:15:45.083864: step 127, loss = 0.61616 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:15:46.046167 ops/training.py:65 2019-01-16 08:15:46.046079: step 128, loss = 0.91399 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:15:47.008183 ops/training.py:65 2019-01-16 08:15:47.008121: step 129, loss = 0.95758 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:15:47.970371 ops/training.py:65 2019-01-16 08:15:47.970323: step 130, loss = 0.88887 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:15:48.930844 ops/training.py:65 2019-01-16 08:15:48.930791: step 131, loss = 0.90373 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:15:49.894690 ops/training.py:65 2019-01-16 08:15:49.894615: step 132, loss = 0.87268 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:15:50.858616 ops/training.py:65 2019-01-16 08:15:50.858561: step 133, loss = 1.00083 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:15:51.823645 ops/training.py:65 2019-01-16 08:15:51.823584: step 134, loss = 1.09436 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:15:52.787126 ops/training.py:65 2019-01-16 08:15:52.787062: step 135, loss = 1.14057 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:15:53.747254 ops/training.py:65 2019-01-16 08:15:53.747200: step 136, loss = 1.00660 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:15:54.712331 ops/training.py:65 2019-01-16 08:15:54.712280: step 137, loss = 1.05566 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:15:55.676705 ops/training.py:65 2019-01-16 08:15:55.676647: step 138, loss = 0.89315 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:15:56.641787 ops/training.py:65 2019-01-16 08:15:56.641721: step 139, loss = 0.79846 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:15:57.606483 ops/training.py:65 2019-01-16 08:15:57.606411: step 140, loss = 0.86460 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:15:58.567331 ops/training.py:65 2019-01-16 08:15:58.567264: step 141, loss = 1.26388 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 08:15:59.526890 ops/training.py:65 2019-01-16 08:15:59.526841: step 142, loss = 0.81555 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:16:00.484910 ops/training.py:65 2019-01-16 08:16:00.484840: step 143, loss = 0.99269 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:16:01.442515 ops/training.py:65 2019-01-16 08:16:01.442445: step 144, loss = 1.01232 (33.5 examples/sec; 0.957 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:16:02.404954 ops/training.py:65 2019-01-16 08:16:02.404904: step 145, loss = 1.11716 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 08:16:03.368603 ops/training.py:65 2019-01-16 08:16:03.368550: step 146, loss = 0.79501 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:16:04.331311 ops/training.py:65 2019-01-16 08:16:04.331258: step 147, loss = 1.09054 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:16:05.291322 ops/training.py:65 2019-01-16 08:16:05.291271: step 148, loss = 0.99170 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:16:06.255973 ops/training.py:65 2019-01-16 08:16:06.255911: step 149, loss = 1.13439 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 08:16:07.219021 ops/training.py:65 2019-01-16 08:16:07.218964: step 150, loss = 0.85415 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:16:08.181441 ops/training.py:65 2019-01-16 08:16:08.181372: step 151, loss = 0.77987 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:16:09.142555 ops/training.py:65 2019-01-16 08:16:09.142483: step 152, loss = 0.97093 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:16:10.104622 ops/training.py:65 2019-01-16 08:16:10.104552: step 153, loss = 0.97278 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:16:11.066109 ops/training.py:65 2019-01-16 08:16:11.066063: step 154, loss = 0.82836 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:16:12.030110 ops/training.py:65 2019-01-16 08:16:12.030051: step 155, loss = 1.05600 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:16:12.993548 ops/training.py:65 2019-01-16 08:16:12.993473: step 156, loss = 0.89055 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:16:13.953747 ops/training.py:65 2019-01-16 08:16:13.953683: step 157, loss = 1.00522 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:16:14.918614 ops/training.py:65 2019-01-16 08:16:14.918566: step 158, loss = 0.76072 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:16:15.881893 ops/training.py:65 2019-01-16 08:16:15.881842: step 159, loss = 0.80331 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:16:16.846777 ops/training.py:65 2019-01-16 08:16:16.846726: step 160, loss = 0.90597 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:16:17.811373 ops/training.py:65 2019-01-16 08:16:17.811320: step 161, loss = 0.93148 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:16:18.773285 ops/training.py:65 2019-01-16 08:16:18.773235: step 162, loss = 1.08085 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:16:19.735375 ops/training.py:65 2019-01-16 08:16:19.735331: step 163, loss = 1.05467 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:16:20.698571 ops/training.py:65 2019-01-16 08:16:20.698525: step 164, loss = 0.93183 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:16:21.660860 ops/training.py:65 2019-01-16 08:16:21.660798: step 165, loss = 0.89216 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:16:22.620563 ops/training.py:65 2019-01-16 08:16:22.620506: step 166, loss = 0.81117 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:16:23.581262 ops/training.py:65 2019-01-16 08:16:23.581216: step 167, loss = 0.93435 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:16:24.544877 ops/training.py:65 2019-01-16 08:16:24.544828: step 168, loss = 0.98832 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:16:25.506279 ops/training.py:65 2019-01-16 08:16:25.506229: step 169, loss = 0.86016 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:16:26.463686 ops/training.py:65 2019-01-16 08:16:26.463617: step 170, loss = 1.00341 (33.5 examples/sec; 0.956 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:16:27.422549 ops/training.py:65 2019-01-16 08:16:27.422497: step 171, loss = 0.90834 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:16:28.384669 ops/training.py:65 2019-01-16 08:16:28.384620: step 172, loss = 1.08485 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:16:29.347849 ops/training.py:65 2019-01-16 08:16:29.347805: step 173, loss = 0.90067 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:16:30.311892 ops/training.py:65 2019-01-16 08:16:30.311848: step 174, loss = 0.82575 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:16:31.272463 ops/training.py:65 2019-01-16 08:16:31.272412: step 175, loss = 1.28348 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:16:32.231443 ops/training.py:65 2019-01-16 08:16:32.231395: step 176, loss = 0.62744 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:16:33.190235 ops/training.py:65 2019-01-16 08:16:33.190192: step 177, loss = 0.91813 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:16:34.154362 ops/training.py:65 2019-01-16 08:16:34.154311: step 178, loss = 0.74017 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:16:35.115018 ops/training.py:65 2019-01-16 08:16:35.114966: step 179, loss = 0.80750 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:16:36.073076 ops/training.py:65 2019-01-16 08:16:36.073026: step 180, loss = 0.98581 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:16:37.036849 ops/training.py:65 2019-01-16 08:16:37.036805: step 181, loss = 1.08278 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:16:37.997825 ops/training.py:65 2019-01-16 08:16:37.997784: step 182, loss = 0.91464 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:16:38.957371 ops/training.py:65 2019-01-16 08:16:38.957329: step 183, loss = 0.82043 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:16:39.916465 ops/training.py:65 2019-01-16 08:16:39.916423: step 184, loss = 0.89060 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:16:40.874577 ops/training.py:65 2019-01-16 08:16:40.874535: step 185, loss = 0.88552 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:16:41.832789 ops/training.py:65 2019-01-16 08:16:41.832748: step 186, loss = 0.78395 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:16:42.791727 ops/training.py:65 2019-01-16 08:16:42.791686: step 187, loss = 0.79253 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:16:43.757536 ops/training.py:65 2019-01-16 08:16:43.757495: step 188, loss = 0.86727 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:16:44.722060 ops/training.py:65 2019-01-16 08:16:44.722015: step 189, loss = 0.89790 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:16:45.688605 ops/training.py:65 2019-01-16 08:16:45.688566: step 190, loss = 1.04644 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:16:46.651872 ops/training.py:65 2019-01-16 08:16:46.651832: step 191, loss = 1.00307 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:16:47.613350 ops/training.py:65 2019-01-16 08:16:47.613310: step 192, loss = 1.05417 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:16:48.576562 ops/training.py:65 2019-01-16 08:16:48.576523: step 193, loss = 0.92559 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:16:49.538463 ops/training.py:65 2019-01-16 08:16:49.538424: step 194, loss = 0.67030 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:16:50.497552 ops/training.py:65 2019-01-16 08:16:50.497511: step 195, loss = 1.05177 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:16:51.456488 ops/training.py:65 2019-01-16 08:16:51.456447: step 196, loss = 0.83425 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:16:52.416379 ops/training.py:65 2019-01-16 08:16:52.416337: step 197, loss = 0.89915 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:16:53.381550 ops/training.py:65 2019-01-16 08:16:53.381486: step 198, loss = 0.68207 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:16:54.346488 ops/training.py:65 2019-01-16 08:16:54.346447: step 199, loss = 0.73471 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:16:55.307595 ops/training.py:65 2019-01-16 08:16:55.307542: step 200, loss = 0.90042 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:16:56.266820 ops/training.py:65 2019-01-16 08:16:56.266759: step 201, loss = 0.93535 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:16:57.231898 ops/training.py:65 2019-01-16 08:16:57.231857: step 202, loss = 0.98324 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:16:58.195963 ops/training.py:65 2019-01-16 08:16:58.195925: step 203, loss = 0.89586 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:16:59.160543 ops/training.py:65 2019-01-16 08:16:59.160505: step 204, loss = 0.97273 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:17:00.124992 ops/training.py:65 2019-01-16 08:17:00.124955: step 205, loss = 0.90819 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:17:01.086437 ops/training.py:65 2019-01-16 08:17:01.086399: step 206, loss = 0.93427 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:17:02.045446 ops/training.py:65 2019-01-16 08:17:02.045389: step 207, loss = 0.81460 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:17:03.004417 ops/training.py:65 2019-01-16 08:17:03.004354: step 208, loss = 0.96671 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:17:03.970210 ops/training.py:65 2019-01-16 08:17:03.970169: step 209, loss = 1.06186 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:17:04.934676 ops/training.py:65 2019-01-16 08:17:04.934636: step 210, loss = 0.67650 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:17:05.897933 ops/training.py:65 2019-01-16 08:17:05.897894: step 211, loss = 0.96121 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:17:06.860259 ops/training.py:65 2019-01-16 08:17:06.860213: step 212, loss = 0.80389 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:17:07.821469 ops/training.py:65 2019-01-16 08:17:07.821409: step 213, loss = 0.83698 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:17:08.798380 ops/training.py:65 2019-01-16 08:17:08.798335: step 214, loss = 0.78658 (32.8 examples/sec; 0.976 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:17:09.759740 ops/training.py:65 2019-01-16 08:17:09.759688: step 215, loss = 0.59343 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:17:10.725235 ops/training.py:65 2019-01-16 08:17:10.725188: step 216, loss = 1.06873 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.1875
I0832 2019-01-16 08:17:11.688533 ops/training.py:65 2019-01-16 08:17:11.688495: step 217, loss = 0.86229 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:17:12.651925 ops/training.py:65 2019-01-16 08:17:12.651884: step 218, loss = 0.79072 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:17:13.616539 ops/training.py:65 2019-01-16 08:17:13.616501: step 219, loss = 0.84772 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:17:14.588156 ops/training.py:65 2019-01-16 08:17:14.588117: step 220, loss = 0.92693 (33.0 examples/sec; 0.971 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:17:15.551397 ops/training.py:65 2019-01-16 08:17:15.551359: step 221, loss = 1.21785 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:17:16.514650 ops/training.py:65 2019-01-16 08:17:16.514611: step 222, loss = 0.89634 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:17:17.478690 ops/training.py:65 2019-01-16 08:17:17.478647: step 223, loss = 0.87378 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:17:18.445312 ops/training.py:65 2019-01-16 08:17:18.445256: step 224, loss = 0.89091 (33.1 examples/sec; 0.966 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:17:19.406260 ops/training.py:65 2019-01-16 08:17:19.406204: step 225, loss = 0.79672 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:17:20.367019 ops/training.py:65 2019-01-16 08:17:20.366972: step 226, loss = 0.82394 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:17:21.329316 ops/training.py:65 2019-01-16 08:17:21.329264: step 227, loss = 0.78381 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:17:22.290068 ops/training.py:65 2019-01-16 08:17:22.290014: step 228, loss = 0.88589 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:17:23.253808 ops/training.py:65 2019-01-16 08:17:23.253756: step 229, loss = 0.76419 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:17:24.216529 ops/training.py:65 2019-01-16 08:17:24.216487: step 230, loss = 1.23026 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 08:17:25.177796 ops/training.py:65 2019-01-16 08:17:25.177742: step 231, loss = 0.88384 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:17:26.141235 ops/training.py:65 2019-01-16 08:17:26.141178: step 232, loss = 1.09929 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:17:27.101950 ops/training.py:65 2019-01-16 08:17:27.101894: step 233, loss = 0.83201 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:17:28.063229 ops/training.py:65 2019-01-16 08:17:28.063191: step 234, loss = 0.99965 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:17:29.026417 ops/training.py:65 2019-01-16 08:17:29.026373: step 235, loss = 0.86206 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:17:29.988272 ops/training.py:65 2019-01-16 08:17:29.988223: step 236, loss = 1.09146 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:17:30.949440 ops/training.py:65 2019-01-16 08:17:30.949388: step 237, loss = 1.17901 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:17:31.908847 ops/training.py:65 2019-01-16 08:17:31.908807: step 238, loss = 0.94915 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:17:32.866956 ops/training.py:65 2019-01-16 08:17:32.866919: step 239, loss = 0.79273 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:17:33.827018 ops/training.py:65 2019-01-16 08:17:33.826979: step 240, loss = 0.86511 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:17:34.785924 ops/training.py:65 2019-01-16 08:17:34.785885: step 241, loss = 0.95310 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:17:35.744356 ops/training.py:65 2019-01-16 08:17:35.744316: step 242, loss = 0.99548 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:17:36.702390 ops/training.py:65 2019-01-16 08:17:36.702351: step 243, loss = 0.94100 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:17:37.660778 ops/training.py:65 2019-01-16 08:17:37.660738: step 244, loss = 0.85370 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:17:38.620958 ops/training.py:65 2019-01-16 08:17:38.620901: step 245, loss = 0.97027 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:17:39.581099 ops/training.py:65 2019-01-16 08:17:39.581049: step 246, loss = 0.96613 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:17:40.545167 ops/training.py:65 2019-01-16 08:17:40.545118: step 247, loss = 0.85352 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:17:41.507823 ops/training.py:65 2019-01-16 08:17:41.507784: step 248, loss = 0.76915 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:17:42.472200 ops/training.py:65 2019-01-16 08:17:42.472159: step 249, loss = 1.00726 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:17:43.436366 ops/training.py:65 2019-01-16 08:17:43.436323: step 250, loss = 0.80714 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:17:44.397656 ops/training.py:65 2019-01-16 08:17:44.397614: step 251, loss = 0.86328 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:17:45.359834 ops/training.py:65 2019-01-16 08:17:45.359784: step 252, loss = 1.10882 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:17:46.319424 ops/training.py:65 2019-01-16 08:17:46.319371: step 253, loss = 0.99305 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:17:47.279496 ops/training.py:65 2019-01-16 08:17:47.279449: step 254, loss = 0.96322 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:17:48.239672 ops/training.py:65 2019-01-16 08:17:48.239629: step 255, loss = 0.81951 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:17:49.203831 ops/training.py:65 2019-01-16 08:17:49.203792: step 256, loss = 0.75120 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:17:50.167973 ops/training.py:65 2019-01-16 08:17:50.167932: step 257, loss = 1.16946 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:17:51.131463 ops/training.py:65 2019-01-16 08:17:51.131414: step 258, loss = 0.73128 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:17:52.093995 ops/training.py:65 2019-01-16 08:17:52.093958: step 259, loss = 1.07514 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:17:53.056435 ops/training.py:65 2019-01-16 08:17:53.056382: step 260, loss = 1.08535 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:17:54.018971 ops/training.py:65 2019-01-16 08:17:54.018917: step 261, loss = 0.91291 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:17:54.981098 ops/training.py:65 2019-01-16 08:17:54.981044: step 262, loss = 0.84764 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:17:55.943124 ops/training.py:65 2019-01-16 08:17:55.943072: step 263, loss = 1.04010 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:17:56.905718 ops/training.py:65 2019-01-16 08:17:56.905655: step 264, loss = 1.05185 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:17:57.867466 ops/training.py:65 2019-01-16 08:17:57.867407: step 265, loss = 1.00391 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:17:58.829925 ops/training.py:65 2019-01-16 08:17:58.829859: step 266, loss = 0.99835 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:17:59.794557 ops/training.py:65 2019-01-16 08:17:59.794501: step 267, loss = 0.93692 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:18:00.758826 ops/training.py:65 2019-01-16 08:18:00.758770: step 268, loss = 1.15484 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.25
I0832 2019-01-16 08:18:01.722023 ops/training.py:65 2019-01-16 08:18:01.721973: step 269, loss = 0.87110 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:18:02.681902 ops/training.py:65 2019-01-16 08:18:02.681853: step 270, loss = 0.79907 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:18:03.646118 ops/training.py:65 2019-01-16 08:18:03.646078: step 271, loss = 0.88072 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:18:04.611262 ops/training.py:65 2019-01-16 08:18:04.611225: step 272, loss = 1.03665 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:18:05.572722 ops/training.py:65 2019-01-16 08:18:05.572685: step 273, loss = 1.12557 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:18:06.536292 ops/training.py:65 2019-01-16 08:18:06.536255: step 274, loss = 1.02992 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:18:07.499461 ops/training.py:65 2019-01-16 08:18:07.499423: step 275, loss = 1.03070 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:18:08.462621 ops/training.py:65 2019-01-16 08:18:08.462582: step 276, loss = 0.92015 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:18:09.425652 ops/training.py:65 2019-01-16 08:18:09.425595: step 277, loss = 0.89582 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:18:10.388382 ops/training.py:65 2019-01-16 08:18:10.388334: step 278, loss = 0.88381 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:18:11.350281 ops/training.py:65 2019-01-16 08:18:11.350234: step 279, loss = 0.85503 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:18:12.310034 ops/training.py:65 2019-01-16 08:18:12.309986: step 280, loss = 0.90515 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:18:13.269322 ops/training.py:65 2019-01-16 08:18:13.269273: step 281, loss = 0.81103 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:18:14.227783 ops/training.py:65 2019-01-16 08:18:14.227733: step 282, loss = 1.13328 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:18:15.192803 ops/training.py:65 2019-01-16 08:18:15.192756: step 283, loss = 0.89952 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:18:16.156694 ops/training.py:65 2019-01-16 08:18:16.156651: step 284, loss = 1.04513 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:18:17.120998 ops/training.py:65 2019-01-16 08:18:17.120961: step 285, loss = 0.68005 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:18:18.084336 ops/training.py:65 2019-01-16 08:18:18.084299: step 286, loss = 0.88562 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:18:19.046784 ops/training.py:65 2019-01-16 08:18:19.046747: step 287, loss = 0.90322 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:18:20.009303 ops/training.py:65 2019-01-16 08:18:20.009267: step 288, loss = 0.99041 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:18:20.971769 ops/training.py:65 2019-01-16 08:18:20.971733: step 289, loss = 0.75944 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:18:21.932724 ops/training.py:65 2019-01-16 08:18:21.932688: step 290, loss = 1.09675 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:18:22.891258 ops/training.py:65 2019-01-16 08:18:22.891220: step 291, loss = 0.99322 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:18:23.849721 ops/training.py:65 2019-01-16 08:18:23.849681: step 292, loss = 0.77222 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:18:24.811736 ops/training.py:65 2019-01-16 08:18:24.811683: step 293, loss = 0.83962 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:18:25.773316 ops/training.py:65 2019-01-16 08:18:25.773280: step 294, loss = 0.74476 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:18:26.736064 ops/training.py:65 2019-01-16 08:18:26.736030: step 295, loss = 0.95902 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:18:27.697205 ops/training.py:65 2019-01-16 08:18:27.697145: step 296, loss = 0.89815 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:18:28.656630 ops/training.py:65 2019-01-16 08:18:28.656564: step 297, loss = 1.03998 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:18:29.620675 ops/training.py:65 2019-01-16 08:18:29.620630: step 298, loss = 1.10629 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:18:30.584769 ops/training.py:65 2019-01-16 08:18:30.584726: step 299, loss = 0.91324 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:18:31.547463 ops/training.py:65 2019-01-16 08:18:31.547420: step 300, loss = 0.97092 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:18:32.510908 ops/training.py:65 2019-01-16 08:18:32.510851: step 301, loss = 1.38976 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:18:33.473562 ops/training.py:65 2019-01-16 08:18:33.473519: step 302, loss = 0.90752 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:18:34.435183 ops/training.py:65 2019-01-16 08:18:34.435142: step 303, loss = 1.19408 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:18:35.397310 ops/training.py:65 2019-01-16 08:18:35.397273: step 304, loss = 0.99870 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:18:36.359956 ops/training.py:65 2019-01-16 08:18:36.359919: step 305, loss = 0.97899 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:18:37.321812 ops/training.py:65 2019-01-16 08:18:37.321776: step 306, loss = 1.17446 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:18:38.284294 ops/training.py:65 2019-01-16 08:18:38.284236: step 307, loss = 1.05270 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:18:39.247257 ops/training.py:65 2019-01-16 08:18:39.247191: step 308, loss = 0.76524 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:18:40.210541 ops/training.py:65 2019-01-16 08:18:40.210502: step 309, loss = 0.89470 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:18:41.172420 ops/training.py:65 2019-01-16 08:18:41.172359: step 310, loss = 1.04006 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:18:42.134648 ops/training.py:65 2019-01-16 08:18:42.134599: step 311, loss = 1.18644 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:18:43.093656 ops/training.py:65 2019-01-16 08:18:43.093619: step 312, loss = 1.09094 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:18:44.054369 ops/training.py:65 2019-01-16 08:18:44.054333: step 313, loss = 1.10727 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:18:45.013595 ops/training.py:65 2019-01-16 08:18:45.013558: step 314, loss = 1.20676 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:18:45.977248 ops/training.py:65 2019-01-16 08:18:45.977211: step 315, loss = 0.99756 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:18:46.940606 ops/training.py:65 2019-01-16 08:18:46.940572: step 316, loss = 1.03471 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:18:47.903400 ops/training.py:65 2019-01-16 08:18:47.903365: step 317, loss = 1.02435 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:18:48.865123 ops/training.py:65 2019-01-16 08:18:48.865086: step 318, loss = 1.02209 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:18:49.826219 ops/training.py:65 2019-01-16 08:18:49.826182: step 319, loss = 1.17561 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:18:50.788461 ops/training.py:65 2019-01-16 08:18:50.788424: step 320, loss = 1.03719 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:18:51.747711 ops/training.py:65 2019-01-16 08:18:51.747675: step 321, loss = 0.94407 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:18:52.712376 ops/training.py:65 2019-01-16 08:18:52.712339: step 322, loss = 0.92137 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:18:53.676999 ops/training.py:65 2019-01-16 08:18:53.676962: step 323, loss = 0.84311 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:18:54.640657 ops/training.py:65 2019-01-16 08:18:54.640620: step 324, loss = 0.98222 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:18:55.603676 ops/training.py:65 2019-01-16 08:18:55.603633: step 325, loss = 0.89653 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:18:56.566106 ops/training.py:65 2019-01-16 08:18:56.566069: step 326, loss = 0.90513 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:18:57.526426 ops/training.py:65 2019-01-16 08:18:57.526363: step 327, loss = 0.87444 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:18:58.485701 ops/training.py:65 2019-01-16 08:18:58.485613: step 328, loss = 1.32010 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:18:59.445747 ops/training.py:65 2019-01-16 08:18:59.445684: step 329, loss = 0.71499 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:19:00.407216 ops/training.py:65 2019-01-16 08:19:00.407166: step 330, loss = 0.84234 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:19:01.370792 ops/training.py:65 2019-01-16 08:19:01.370755: step 331, loss = 0.99499 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:19:02.334535 ops/training.py:65 2019-01-16 08:19:02.334500: step 332, loss = 0.80479 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:19:03.298762 ops/training.py:65 2019-01-16 08:19:03.298725: step 333, loss = 0.76391 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:19:04.266304 ops/training.py:65 2019-01-16 08:19:04.266267: step 334, loss = 0.88055 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:19:05.227937 ops/training.py:65 2019-01-16 08:19:05.227900: step 335, loss = 0.78522 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:19:06.190619 ops/training.py:65 2019-01-16 08:19:06.190580: step 336, loss = 0.95401 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:19:07.153593 ops/training.py:65 2019-01-16 08:19:07.153556: step 337, loss = 0.86863 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:19:08.114861 ops/training.py:65 2019-01-16 08:19:08.114824: step 338, loss = 0.69942 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 08:19:09.078306 ops/training.py:65 2019-01-16 08:19:09.078269: step 339, loss = 0.70208 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:19:10.040342 ops/training.py:65 2019-01-16 08:19:10.040307: step 340, loss = 0.74284 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:19:11.000584 ops/training.py:65 2019-01-16 08:19:11.000521: step 341, loss = 0.78279 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:19:11.961001 ops/training.py:65 2019-01-16 08:19:11.960942: step 342, loss = 0.81963 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:19:12.924440 ops/training.py:65 2019-01-16 08:19:12.924396: step 343, loss = 0.92208 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:19:13.888123 ops/training.py:65 2019-01-16 08:19:13.888087: step 344, loss = 0.75289 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:19:14.850953 ops/training.py:65 2019-01-16 08:19:14.850917: step 345, loss = 0.73448 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:19:15.813272 ops/training.py:65 2019-01-16 08:19:15.813233: step 346, loss = 1.20069 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 08:19:16.775224 ops/training.py:65 2019-01-16 08:19:16.775188: step 347, loss = 0.64339 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 08:19:17.738110 ops/training.py:65 2019-01-16 08:19:17.738074: step 348, loss = 0.80339 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:19:18.700046 ops/training.py:65 2019-01-16 08:19:18.700009: step 349, loss = 0.87334 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:19:19.662688 ops/training.py:65 2019-01-16 08:19:19.662648: step 350, loss = 0.73222 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:19:20.625947 ops/training.py:65 2019-01-16 08:19:20.625903: step 351, loss = 0.86793 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:19:21.589691 ops/training.py:65 2019-01-16 08:19:21.589654: step 352, loss = 0.83107 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:19:22.552860 ops/training.py:65 2019-01-16 08:19:22.552822: step 353, loss = 0.89898 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:19:23.516540 ops/training.py:65 2019-01-16 08:19:23.516502: step 354, loss = 0.76188 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:19:24.480413 ops/training.py:65 2019-01-16 08:19:24.480374: step 355, loss = 0.81524 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:19:25.443879 ops/training.py:65 2019-01-16 08:19:25.443832: step 356, loss = 0.85781 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:19:26.406988 ops/training.py:65 2019-01-16 08:19:26.406950: step 357, loss = 0.69317 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:19:27.369566 ops/training.py:65 2019-01-16 08:19:27.369529: step 358, loss = 0.67234 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:19:28.333103 ops/training.py:65 2019-01-16 08:19:28.333064: step 359, loss = 0.84376 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:19:29.296110 ops/training.py:65 2019-01-16 08:19:29.296072: step 360, loss = 0.87376 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:19:30.258888 ops/training.py:65 2019-01-16 08:19:30.258842: step 361, loss = 0.70712 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:19:31.222170 ops/training.py:65 2019-01-16 08:19:31.222132: step 362, loss = 0.68762 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:19:32.185576 ops/training.py:65 2019-01-16 08:19:32.185539: step 363, loss = 0.67767 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:19:33.149759 ops/training.py:65 2019-01-16 08:19:33.149715: step 364, loss = 0.83393 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:19:34.113153 ops/training.py:65 2019-01-16 08:19:34.113116: step 365, loss = 0.75712 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:19:35.075041 ops/training.py:65 2019-01-16 08:19:35.075003: step 366, loss = 0.93454 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:19:36.036470 ops/training.py:65 2019-01-16 08:19:36.036433: step 367, loss = 0.75603 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:19:36.999816 ops/training.py:65 2019-01-16 08:19:36.999776: step 368, loss = 0.63250 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:19:37.964792 ops/training.py:65 2019-01-16 08:19:37.964753: step 369, loss = 0.76657 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:19:38.927672 ops/training.py:65 2019-01-16 08:19:38.927631: step 370, loss = 0.79512 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:19:39.891561 ops/training.py:65 2019-01-16 08:19:39.891509: step 371, loss = 0.77980 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:19:40.852405 ops/training.py:65 2019-01-16 08:19:40.852351: step 372, loss = 0.82222 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:19:41.811051 ops/training.py:65 2019-01-16 08:19:41.811013: step 373, loss = 0.81129 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:19:42.769933 ops/training.py:65 2019-01-16 08:19:42.769889: step 374, loss = 0.80553 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:19:43.728836 ops/training.py:65 2019-01-16 08:19:43.728791: step 375, loss = 0.77972 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:19:44.692660 ops/training.py:65 2019-01-16 08:19:44.692621: step 376, loss = 0.74664 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:19:45.655355 ops/training.py:65 2019-01-16 08:19:45.655318: step 377, loss = 0.78145 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:19:46.618172 ops/training.py:65 2019-01-16 08:19:46.618135: step 378, loss = 0.84284 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:19:47.580333 ops/training.py:65 2019-01-16 08:19:47.580296: step 379, loss = 0.88891 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:19:48.542880 ops/training.py:65 2019-01-16 08:19:48.542842: step 380, loss = 0.92410 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:19:49.506021 ops/training.py:65 2019-01-16 08:19:49.505981: step 381, loss = 0.80494 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:19:50.471076 ops/training.py:65 2019-01-16 08:19:50.471038: step 382, loss = 0.83328 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:19:51.433052 ops/training.py:65 2019-01-16 08:19:51.433014: step 383, loss = 0.84543 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:19:52.395886 ops/training.py:65 2019-01-16 08:19:52.395849: step 384, loss = 0.83296 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:19:53.357248 ops/training.py:65 2019-01-16 08:19:53.357191: step 385, loss = 0.81854 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:19:54.321268 ops/training.py:65 2019-01-16 08:19:54.321232: step 386, loss = 0.81088 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:19:55.284054 ops/training.py:65 2019-01-16 08:19:55.284003: step 387, loss = 0.85803 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:19:56.246448 ops/training.py:65 2019-01-16 08:19:56.246410: step 388, loss = 0.88753 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:19:57.208666 ops/training.py:65 2019-01-16 08:19:57.208629: step 389, loss = 0.88309 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:19:58.169108 ops/training.py:65 2019-01-16 08:19:58.169071: step 390, loss = 0.85201 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:19:59.133828 ops/training.py:65 2019-01-16 08:19:59.133791: step 391, loss = 0.89863 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:20:00.095060 ops/training.py:65 2019-01-16 08:20:00.095025: step 392, loss = 0.73415 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:20:01.058239 ops/training.py:65 2019-01-16 08:20:01.058190: step 393, loss = 0.87760 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:20:02.021643 ops/training.py:65 2019-01-16 08:20:02.021597: step 394, loss = 0.83690 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:20:02.985706 ops/training.py:65 2019-01-16 08:20:02.985665: step 395, loss = 0.66995 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:20:03.950010 ops/training.py:65 2019-01-16 08:20:03.949969: step 396, loss = 0.76404 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:20:04.910517 ops/training.py:65 2019-01-16 08:20:04.910479: step 397, loss = 1.01000 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:20:05.874239 ops/training.py:65 2019-01-16 08:20:05.874202: step 398, loss = 0.89737 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:20:06.836573 ops/training.py:65 2019-01-16 08:20:06.836533: step 399, loss = 0.86325 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:20:07.799219 ops/training.py:65 2019-01-16 08:20:07.799182: step 400, loss = 0.95920 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:20:08.761526 ops/training.py:65 2019-01-16 08:20:08.761487: step 401, loss = 0.88234 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:20:09.723391 ops/training.py:65 2019-01-16 08:20:09.723349: step 402, loss = 0.82862 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:20:10.685298 ops/training.py:65 2019-01-16 08:20:10.685251: step 403, loss = 0.87661 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:20:11.645809 ops/training.py:65 2019-01-16 08:20:11.645744: step 404, loss = 0.74689 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:20:12.609248 ops/training.py:65 2019-01-16 08:20:12.609206: step 405, loss = 0.82796 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:20:13.572860 ops/training.py:65 2019-01-16 08:20:13.572810: step 406, loss = 0.83736 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:20:14.535989 ops/training.py:65 2019-01-16 08:20:14.535940: step 407, loss = 0.80911 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:20:15.498984 ops/training.py:65 2019-01-16 08:20:15.498938: step 408, loss = 0.85140 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:20:16.459490 ops/training.py:65 2019-01-16 08:20:16.459436: step 409, loss = 0.81470 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:20:17.418639 ops/training.py:65 2019-01-16 08:20:17.418570: step 410, loss = 0.90724 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:20:18.383339 ops/training.py:65 2019-01-16 08:20:18.383279: step 411, loss = 0.63386 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:20:19.347624 ops/training.py:65 2019-01-16 08:20:19.347582: step 412, loss = 0.81255 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:20:20.311246 ops/training.py:65 2019-01-16 08:20:20.311205: step 413, loss = 0.90685 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 08:20:21.274428 ops/training.py:65 2019-01-16 08:20:21.274385: step 414, loss = 0.82809 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:20:22.237915 ops/training.py:65 2019-01-16 08:20:22.237861: step 415, loss = 0.81929 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:20:23.198675 ops/training.py:65 2019-01-16 08:20:23.198625: step 416, loss = 0.80476 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:20:24.158540 ops/training.py:65 2019-01-16 08:20:24.158492: step 417, loss = 0.92156 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:20:25.117202 ops/training.py:65 2019-01-16 08:20:25.117145: step 418, loss = 0.80574 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:20:26.075345 ops/training.py:65 2019-01-16 08:20:26.075294: step 419, loss = 0.85584 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:20:27.039156 ops/training.py:65 2019-01-16 08:20:27.039114: step 420, loss = 0.72284 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:20:28.002401 ops/training.py:65 2019-01-16 08:20:28.002339: step 421, loss = 0.70630 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:20:28.964961 ops/training.py:65 2019-01-16 08:20:28.964901: step 422, loss = 0.73917 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:20:29.927786 ops/training.py:65 2019-01-16 08:20:29.927735: step 423, loss = 0.64885 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:20:30.889415 ops/training.py:65 2019-01-16 08:20:30.889365: step 424, loss = 0.70887 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:20:31.853281 ops/training.py:65 2019-01-16 08:20:31.853228: step 425, loss = 0.91767 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:20:32.816019 ops/training.py:65 2019-01-16 08:20:32.815969: step 426, loss = 0.72971 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:20:33.778373 ops/training.py:65 2019-01-16 08:20:33.778333: step 427, loss = 0.71216 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:20:34.739920 ops/training.py:65 2019-01-16 08:20:34.739879: step 428, loss = 0.77172 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:20:35.700857 ops/training.py:65 2019-01-16 08:20:35.700812: step 429, loss = 0.82773 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:20:36.663668 ops/training.py:65 2019-01-16 08:20:36.663614: step 430, loss = 0.80199 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:20:37.626133 ops/training.py:65 2019-01-16 08:20:37.626066: step 431, loss = 0.69110 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:20:38.588213 ops/training.py:65 2019-01-16 08:20:38.588146: step 432, loss = 0.71599 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:20:39.549155 ops/training.py:65 2019-01-16 08:20:39.549089: step 433, loss = 0.67747 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:20:40.511941 ops/training.py:65 2019-01-16 08:20:40.511891: step 434, loss = 0.82148 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:20:41.473060 ops/training.py:65 2019-01-16 08:20:41.473007: step 435, loss = 0.92891 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:20:42.438902 ops/training.py:65 2019-01-16 08:20:42.438855: step 436, loss = 0.64999 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:20:43.404331 ops/training.py:65 2019-01-16 08:20:43.404282: step 437, loss = 0.84601 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:20:44.368072 ops/training.py:65 2019-01-16 08:20:44.368023: step 438, loss = 0.90876 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:20:45.329659 ops/training.py:65 2019-01-16 08:20:45.329589: step 439, loss = 0.78987 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:20:46.291609 ops/training.py:65 2019-01-16 08:20:46.291541: step 440, loss = 0.65547 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:20:47.254029 ops/training.py:65 2019-01-16 08:20:47.253960: step 441, loss = 0.82278 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:20:48.216804 ops/training.py:65 2019-01-16 08:20:48.216740: step 442, loss = 0.87477 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:20:49.178257 ops/training.py:65 2019-01-16 08:20:49.178206: step 443, loss = 0.81190 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:20:50.139453 ops/training.py:65 2019-01-16 08:20:50.139408: step 444, loss = 0.80797 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:20:51.100815 ops/training.py:65 2019-01-16 08:20:51.100768: step 445, loss = 0.86463 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:20:52.064263 ops/training.py:65 2019-01-16 08:20:52.064206: step 446, loss = 0.86476 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:20:53.026093 ops/training.py:65 2019-01-16 08:20:53.026016: step 447, loss = 0.83712 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:20:53.987843 ops/training.py:65 2019-01-16 08:20:53.987777: step 448, loss = 0.97251 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:20:54.951048 ops/training.py:65 2019-01-16 08:20:54.950990: step 449, loss = 0.66559 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 08:20:55.913761 ops/training.py:65 2019-01-16 08:20:55.913709: step 450, loss = 0.79780 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:20:56.876949 ops/training.py:65 2019-01-16 08:20:56.876877: step 451, loss = 0.80432 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:20:57.840522 ops/training.py:65 2019-01-16 08:20:57.840453: step 452, loss = 0.85590 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:20:58.801769 ops/training.py:65 2019-01-16 08:20:58.801695: step 453, loss = 0.72938 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:20:59.761977 ops/training.py:65 2019-01-16 08:20:59.761925: step 454, loss = 1.00456 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:21:00.725800 ops/training.py:65 2019-01-16 08:21:00.725753: step 455, loss = 0.77363 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:21:01.690500 ops/training.py:65 2019-01-16 08:21:01.690453: step 456, loss = 0.91642 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:21:02.654479 ops/training.py:65 2019-01-16 08:21:02.654431: step 457, loss = 0.94796 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:21:03.618167 ops/training.py:65 2019-01-16 08:21:03.618118: step 458, loss = 0.78505 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:21:04.580660 ops/training.py:65 2019-01-16 08:21:04.580610: step 459, loss = 0.73530 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:21:05.542043 ops/training.py:65 2019-01-16 08:21:05.541995: step 460, loss = 0.84455 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:21:06.504660 ops/training.py:65 2019-01-16 08:21:06.504611: step 461, loss = 0.79780 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:21:07.468158 ops/training.py:65 2019-01-16 08:21:07.468108: step 462, loss = 0.68158 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:21:08.430732 ops/training.py:65 2019-01-16 08:21:08.430679: step 463, loss = 0.75459 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:21:09.393271 ops/training.py:65 2019-01-16 08:21:09.393204: step 464, loss = 0.83504 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:21:10.356622 ops/training.py:65 2019-01-16 08:21:10.356558: step 465, loss = 0.79120 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:21:11.319352 ops/training.py:65 2019-01-16 08:21:11.319284: step 466, loss = 0.74403 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:21:12.281685 ops/training.py:65 2019-01-16 08:21:12.281616: step 467, loss = 0.79645 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:21:13.242591 ops/training.py:65 2019-01-16 08:21:13.242544: step 468, loss = 0.65019 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:21:14.202557 ops/training.py:65 2019-01-16 08:21:14.202506: step 469, loss = 1.00368 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:21:15.165074 ops/training.py:65 2019-01-16 08:21:15.165028: step 470, loss = 0.74191 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:21:16.126592 ops/training.py:65 2019-01-16 08:21:16.126535: step 471, loss = 0.67172 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:21:17.090562 ops/training.py:65 2019-01-16 08:21:17.090510: step 472, loss = 0.71622 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:21:18.052739 ops/training.py:65 2019-01-16 08:21:18.052663: step 473, loss = 0.67721 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:21:19.013204 ops/training.py:65 2019-01-16 08:21:19.013138: step 474, loss = 0.86215 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:21:19.973032 ops/training.py:65 2019-01-16 08:21:19.972976: step 475, loss = 0.82435 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:21:20.936356 ops/training.py:65 2019-01-16 08:21:20.936310: step 476, loss = 0.69808 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:21:21.899450 ops/training.py:65 2019-01-16 08:21:21.899368: step 477, loss = 0.77679 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:21:22.863375 ops/training.py:65 2019-01-16 08:21:22.863305: step 478, loss = 0.81788 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:21:23.825986 ops/training.py:65 2019-01-16 08:21:23.825920: step 479, loss = 0.88710 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:21:24.788513 ops/training.py:65 2019-01-16 08:21:24.788448: step 480, loss = 0.71028 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:21:25.750668 ops/training.py:65 2019-01-16 08:21:25.750601: step 481, loss = 0.80649 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:21:26.713640 ops/training.py:65 2019-01-16 08:21:26.713567: step 482, loss = 0.69653 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:21:27.676414 ops/training.py:65 2019-01-16 08:21:27.676363: step 483, loss = 0.79271 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:21:28.638941 ops/training.py:65 2019-01-16 08:21:28.638893: step 484, loss = 0.89444 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:21:29.602261 ops/training.py:65 2019-01-16 08:21:29.602189: step 485, loss = 0.82876 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:21:30.563947 ops/training.py:65 2019-01-16 08:21:30.563882: step 486, loss = 0.60444 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:21:31.525932 ops/training.py:65 2019-01-16 08:21:31.525861: step 487, loss = 0.77116 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:21:32.488271 ops/training.py:65 2019-01-16 08:21:32.488203: step 488, loss = 0.66166 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:21:33.451660 ops/training.py:65 2019-01-16 08:21:33.451613: step 489, loss = 0.64941 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:21:34.414444 ops/training.py:65 2019-01-16 08:21:34.414395: step 490, loss = 0.95214 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 08:21:35.376418 ops/training.py:65 2019-01-16 08:21:35.376370: step 491, loss = 0.78155 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:21:36.339425 ops/training.py:65 2019-01-16 08:21:36.339373: step 492, loss = 0.86415 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:21:37.302179 ops/training.py:65 2019-01-16 08:21:37.302118: step 493, loss = 0.74667 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:21:38.261760 ops/training.py:65 2019-01-16 08:21:38.261697: step 494, loss = 0.82377 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:21:39.222140 ops/training.py:65 2019-01-16 08:21:39.222072: step 495, loss = 0.69460 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:21:40.182266 ops/training.py:65 2019-01-16 08:21:40.182211: step 496, loss = 0.73751 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:21:41.146543 ops/training.py:65 2019-01-16 08:21:41.146496: step 497, loss = 0.80872 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:21:42.111543 ops/training.py:65 2019-01-16 08:21:42.111493: step 498, loss = 0.76913 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:21:43.074692 ops/training.py:65 2019-01-16 08:21:43.074620: step 499, loss = 0.75538 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:21:44.036771 ops/training.py:65 2019-01-16 08:21:44.036702: step 500, loss = 0.73651 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:21:44.998923 ops/training.py:65 2019-01-16 08:21:44.998866: step 501, loss = 0.77914 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:21:45.959806 ops/training.py:65 2019-01-16 08:21:45.959736: step 502, loss = 0.90199 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:21:46.919464 ops/training.py:65 2019-01-16 08:21:46.919389: step 503, loss = 0.81466 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:21:47.879038 ops/training.py:65 2019-01-16 08:21:47.878956: step 504, loss = 0.80886 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:21:48.836728 ops/training.py:65 2019-01-16 08:21:48.836669: step 505, loss = 0.69058 (33.5 examples/sec; 0.957 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:21:49.794779 ops/training.py:65 2019-01-16 08:21:49.794731: step 506, loss = 0.77651 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:21:50.758207 ops/training.py:65 2019-01-16 08:21:50.758152: step 507, loss = 0.74760 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:21:51.722608 ops/training.py:65 2019-01-16 08:21:51.722530: step 508, loss = 0.72422 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:21:52.687197 ops/training.py:65 2019-01-16 08:21:52.687143: step 509, loss = 0.86682 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:21:53.650696 ops/training.py:65 2019-01-16 08:21:53.650624: step 510, loss = 0.81944 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:21:54.613197 ops/training.py:65 2019-01-16 08:21:54.613128: step 511, loss = 0.85460 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:21:55.577005 ops/training.py:65 2019-01-16 08:21:55.576931: step 512, loss = 0.89098 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:21:56.541126 ops/training.py:65 2019-01-16 08:21:56.541064: step 513, loss = 0.70912 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:21:57.505177 ops/training.py:65 2019-01-16 08:21:57.505127: step 514, loss = 0.75805 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:21:58.467726 ops/training.py:65 2019-01-16 08:21:58.467655: step 515, loss = 0.88277 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:21:59.432248 ops/training.py:65 2019-01-16 08:21:59.432168: step 516, loss = 0.82908 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:22:00.396894 ops/training.py:65 2019-01-16 08:22:00.396837: step 517, loss = 0.80563 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:22:01.360578 ops/training.py:65 2019-01-16 08:22:01.360508: step 518, loss = 0.72240 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:22:02.322529 ops/training.py:65 2019-01-16 08:22:02.322461: step 519, loss = 0.86160 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:22:03.284159 ops/training.py:65 2019-01-16 08:22:03.284089: step 520, loss = 0.86477 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:22:04.244348 ops/training.py:65 2019-01-16 08:22:04.244286: step 521, loss = 0.64174 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 08:22:05.208444 ops/training.py:65 2019-01-16 08:22:05.208401: step 522, loss = 0.64721 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:22:06.170972 ops/training.py:65 2019-01-16 08:22:06.170926: step 523, loss = 0.75762 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:22:07.133192 ops/training.py:65 2019-01-16 08:22:07.133142: step 524, loss = 0.69594 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:22:08.095862 ops/training.py:65 2019-01-16 08:22:08.095787: step 525, loss = 0.74050 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:22:09.060165 ops/training.py:65 2019-01-16 08:22:09.060097: step 526, loss = 0.73067 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:22:10.022362 ops/training.py:65 2019-01-16 08:22:10.022311: step 527, loss = 0.77366 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:22:10.983583 ops/training.py:65 2019-01-16 08:22:10.983520: step 528, loss = 0.92597 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:22:11.946399 ops/training.py:65 2019-01-16 08:22:11.946334: step 529, loss = 0.72274 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:22:12.911482 ops/training.py:65 2019-01-16 08:22:12.911432: step 530, loss = 0.80732 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:22:13.874595 ops/training.py:65 2019-01-16 08:22:13.874532: step 531, loss = 0.89823 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:22:14.837499 ops/training.py:65 2019-01-16 08:22:14.837433: step 532, loss = 0.76466 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:22:15.801053 ops/training.py:65 2019-01-16 08:22:15.801004: step 533, loss = 0.80678 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:22:16.762412 ops/training.py:65 2019-01-16 08:22:16.762339: step 534, loss = 0.70071 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:22:17.725242 ops/training.py:65 2019-01-16 08:22:17.725181: step 535, loss = 0.64776 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:22:18.688141 ops/training.py:65 2019-01-16 08:22:18.688067: step 536, loss = 0.55845 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 08:22:19.652923 ops/training.py:65 2019-01-16 08:22:19.652875: step 537, loss = 0.73845 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:22:20.614845 ops/training.py:65 2019-01-16 08:22:20.614792: step 538, loss = 0.75267 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:22:21.577744 ops/training.py:65 2019-01-16 08:22:21.577693: step 539, loss = 0.86655 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:22:22.541195 ops/training.py:65 2019-01-16 08:22:22.541125: step 540, loss = 0.75780 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:22:23.505165 ops/training.py:65 2019-01-16 08:22:23.505089: step 541, loss = 0.92525 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:22:24.465476 ops/training.py:65 2019-01-16 08:22:24.465423: step 542, loss = 0.73564 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:22:25.425373 ops/training.py:65 2019-01-16 08:22:25.425300: step 543, loss = 0.76195 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:22:26.384524 ops/training.py:65 2019-01-16 08:22:26.384453: step 544, loss = 0.68373 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:22:27.348615 ops/training.py:65 2019-01-16 08:22:27.348570: step 545, loss = 0.65816 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:22:28.313079 ops/training.py:65 2019-01-16 08:22:28.313037: step 546, loss = 0.78798 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:22:29.275609 ops/training.py:65 2019-01-16 08:22:29.275541: step 547, loss = 0.81859 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:22:30.237074 ops/training.py:65 2019-01-16 08:22:30.237012: step 548, loss = 0.73649 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:22:31.198921 ops/training.py:65 2019-01-16 08:22:31.198850: step 549, loss = 0.73042 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:22:32.160777 ops/training.py:65 2019-01-16 08:22:32.160711: step 550, loss = 0.73503 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:22:33.125216 ops/training.py:65 2019-01-16 08:22:33.125166: step 551, loss = 0.76303 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:22:34.088612 ops/training.py:65 2019-01-16 08:22:34.088560: step 552, loss = 0.77509 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:22:35.051089 ops/training.py:65 2019-01-16 08:22:35.051040: step 553, loss = 0.66593 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:22:36.014037 ops/training.py:65 2019-01-16 08:22:36.013987: step 554, loss = 0.75511 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:22:36.974919 ops/training.py:65 2019-01-16 08:22:36.974870: step 555, loss = 0.68220 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:22:37.936330 ops/training.py:65 2019-01-16 08:22:37.936277: step 556, loss = 0.67802 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:22:38.897471 ops/training.py:65 2019-01-16 08:22:38.897423: step 557, loss = 0.70825 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:22:39.857741 ops/training.py:65 2019-01-16 08:22:39.857656: step 558, loss = 0.72064 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:22:40.818305 ops/training.py:65 2019-01-16 08:22:40.818254: step 559, loss = 0.77760 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:22:41.776382 ops/training.py:65 2019-01-16 08:22:41.776329: step 560, loss = 0.76622 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:22:42.734696 ops/training.py:65 2019-01-16 08:22:42.734649: step 561, loss = 0.68497 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:22:43.694207 ops/training.py:65 2019-01-16 08:22:43.694157: step 562, loss = 0.72386 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:22:44.652120 ops/training.py:65 2019-01-16 08:22:44.652071: step 563, loss = 0.76566 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:22:45.615776 ops/training.py:65 2019-01-16 08:22:45.615736: step 564, loss = 0.66321 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:22:46.578155 ops/training.py:65 2019-01-16 08:22:46.578108: step 565, loss = 0.78490 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:22:47.541291 ops/training.py:65 2019-01-16 08:22:47.541245: step 566, loss = 0.79017 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:22:48.501495 ops/training.py:65 2019-01-16 08:22:48.501444: step 567, loss = 0.81027 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:22:49.465436 ops/training.py:65 2019-01-16 08:22:49.465386: step 568, loss = 0.75543 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:22:50.428776 ops/training.py:65 2019-01-16 08:22:50.428730: step 569, loss = 0.71369 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:22:51.391527 ops/training.py:65 2019-01-16 08:22:51.391482: step 570, loss = 0.80573 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:22:52.351636 ops/training.py:65 2019-01-16 08:22:52.351581: step 571, loss = 0.79443 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:22:53.311867 ops/training.py:65 2019-01-16 08:22:53.311805: step 572, loss = 0.74913 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:22:54.274507 ops/training.py:65 2019-01-16 08:22:54.274456: step 573, loss = 0.84120 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:22:55.238931 ops/training.py:65 2019-01-16 08:22:55.238873: step 574, loss = 0.64023 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:22:56.199801 ops/training.py:65 2019-01-16 08:22:56.199746: step 575, loss = 0.75353 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:22:57.157971 ops/training.py:65 2019-01-16 08:22:57.157924: step 576, loss = 0.72983 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:22:58.122372 ops/training.py:65 2019-01-16 08:22:58.122332: step 577, loss = 0.80554 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:22:59.086959 ops/training.py:65 2019-01-16 08:22:59.086898: step 578, loss = 0.65563 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:23:00.050892 ops/training.py:65 2019-01-16 08:23:00.050835: step 579, loss = 0.74866 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:23:01.012652 ops/training.py:65 2019-01-16 08:23:01.012591: step 580, loss = 0.68422 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:23:01.972016 ops/training.py:65 2019-01-16 08:23:01.971968: step 581, loss = 0.65946 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:23:02.932053 ops/training.py:65 2019-01-16 08:23:02.931991: step 582, loss = 0.78297 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:23:03.891055 ops/training.py:65 2019-01-16 08:23:03.890982: step 583, loss = 0.76422 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:23:04.849936 ops/training.py:65 2019-01-16 08:23:04.849870: step 584, loss = 0.65710 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:23:05.813194 ops/training.py:65 2019-01-16 08:23:05.813151: step 585, loss = 0.74638 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:23:06.777056 ops/training.py:65 2019-01-16 08:23:06.777012: step 586, loss = 0.74408 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:23:07.739945 ops/training.py:65 2019-01-16 08:23:07.739907: step 587, loss = 0.71309 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:23:08.701057 ops/training.py:65 2019-01-16 08:23:08.701022: step 588, loss = 0.81444 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:23:09.663552 ops/training.py:65 2019-01-16 08:23:09.663508: step 589, loss = 0.68626 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:23:10.625379 ops/training.py:65 2019-01-16 08:23:10.625341: step 590, loss = 0.71043 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:23:11.587513 ops/training.py:65 2019-01-16 08:23:11.587468: step 591, loss = 0.84612 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:23:12.551704 ops/training.py:65 2019-01-16 08:23:12.551672: step 592, loss = 0.85625 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:23:13.515807 ops/training.py:65 2019-01-16 08:23:13.515770: step 593, loss = 0.68705 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:23:14.477330 ops/training.py:65 2019-01-16 08:23:14.477286: step 594, loss = 0.77339 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:23:15.439151 ops/training.py:65 2019-01-16 08:23:15.439086: step 595, loss = 0.83883 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:23:16.401659 ops/training.py:65 2019-01-16 08:23:16.401580: step 596, loss = 0.89439 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:23:17.364965 ops/training.py:65 2019-01-16 08:23:17.364902: step 597, loss = 0.76601 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:23:18.327350 ops/training.py:65 2019-01-16 08:23:18.327296: step 598, loss = 0.82323 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:23:19.292129 ops/training.py:65 2019-01-16 08:23:19.292068: step 599, loss = 0.72566 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:23:20.252497 ops/training.py:65 2019-01-16 08:23:20.252437: step 600, loss = 0.76662 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:23:21.211690 ops/training.py:65 2019-01-16 08:23:21.211617: step 601, loss = 0.84502 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:23:22.174347 ops/training.py:65 2019-01-16 08:23:22.174287: step 602, loss = 0.83765 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:23:23.135299 ops/training.py:65 2019-01-16 08:23:23.135247: step 603, loss = 0.69588 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:23:24.100152 ops/training.py:65 2019-01-16 08:23:24.100069: step 604, loss = 0.86393 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:23:25.064211 ops/training.py:65 2019-01-16 08:23:25.064142: step 605, loss = 0.69853 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:23:26.028623 ops/training.py:65 2019-01-16 08:23:26.028565: step 606, loss = 0.70127 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:23:26.992878 ops/training.py:65 2019-01-16 08:23:26.992829: step 607, loss = 0.70806 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:23:27.954256 ops/training.py:65 2019-01-16 08:23:27.954185: step 608, loss = 1.06539 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:23:28.919129 ops/training.py:65 2019-01-16 08:23:28.919074: step 609, loss = 0.81178 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:23:29.883241 ops/training.py:65 2019-01-16 08:23:29.883187: step 610, loss = 0.83035 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:23:30.849136 ops/training.py:65 2019-01-16 08:23:30.849077: step 611, loss = 0.92596 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:23:31.813214 ops/training.py:65 2019-01-16 08:23:31.813142: step 612, loss = 0.76955 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:23:32.776944 ops/training.py:65 2019-01-16 08:23:32.776876: step 613, loss = 0.96709 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:23:33.738524 ops/training.py:65 2019-01-16 08:23:33.738453: step 614, loss = 0.96539 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:23:34.698422 ops/training.py:65 2019-01-16 08:23:34.698353: step 615, loss = 0.82438 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:23:35.658010 ops/training.py:65 2019-01-16 08:23:35.657954: step 616, loss = 0.88322 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:23:36.617139 ops/training.py:65 2019-01-16 08:23:36.617085: step 617, loss = 0.77703 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:23:37.575546 ops/training.py:65 2019-01-16 08:23:37.575493: step 618, loss = 1.10904 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 08:23:38.538696 ops/training.py:65 2019-01-16 08:23:38.538642: step 619, loss = 0.86749 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:23:39.503606 ops/training.py:65 2019-01-16 08:23:39.503552: step 620, loss = 0.70859 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:23:40.465676 ops/training.py:65 2019-01-16 08:23:40.465605: step 621, loss = 0.86833 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:23:41.426067 ops/training.py:65 2019-01-16 08:23:41.426002: step 622, loss = 0.95240 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:23:42.384872 ops/training.py:65 2019-01-16 08:23:42.384817: step 623, loss = 0.75410 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:23:43.343784 ops/training.py:65 2019-01-16 08:23:43.343735: step 624, loss = 0.81850 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:23:44.302186 ops/training.py:65 2019-01-16 08:23:44.302132: step 625, loss = 0.82523 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:23:45.267621 ops/training.py:65 2019-01-16 08:23:45.267566: step 626, loss = 0.95307 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:23:46.230699 ops/training.py:65 2019-01-16 08:23:46.230634: step 627, loss = 0.78642 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:23:47.194102 ops/training.py:65 2019-01-16 08:23:47.194034: step 628, loss = 0.93923 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:23:48.155446 ops/training.py:65 2019-01-16 08:23:48.155381: step 629, loss = 0.81288 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:23:49.113900 ops/training.py:65 2019-01-16 08:23:49.113848: step 630, loss = 0.69926 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:23:50.073290 ops/training.py:65 2019-01-16 08:23:50.073244: step 631, loss = 0.81185 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:23:51.035940 ops/training.py:65 2019-01-16 08:23:51.035876: step 632, loss = 0.74130 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:23:51.998070 ops/training.py:65 2019-01-16 08:23:51.997988: step 633, loss = 0.83650 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:23:52.960715 ops/training.py:65 2019-01-16 08:23:52.960642: step 634, loss = 0.83956 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:23:53.921032 ops/training.py:65 2019-01-16 08:23:53.920967: step 635, loss = 0.91123 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:23:54.880092 ops/training.py:65 2019-01-16 08:23:54.880035: step 636, loss = 0.79230 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:23:55.838699 ops/training.py:65 2019-01-16 08:23:55.838631: step 637, loss = 0.79484 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:23:56.797803 ops/training.py:65 2019-01-16 08:23:56.797729: step 638, loss = 0.79648 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:23:57.756647 ops/training.py:65 2019-01-16 08:23:57.756597: step 639, loss = 0.71883 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:23:58.715010 ops/training.py:65 2019-01-16 08:23:58.714943: step 640, loss = 0.75898 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:23:59.673758 ops/training.py:65 2019-01-16 08:23:59.673701: step 641, loss = 0.78103 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:24:00.637650 ops/training.py:65 2019-01-16 08:24:00.637606: step 642, loss = 0.75427 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:24:01.601733 ops/training.py:65 2019-01-16 08:24:01.601693: step 643, loss = 0.78554 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:24:02.563513 ops/training.py:65 2019-01-16 08:24:02.563461: step 644, loss = 0.72831 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:24:03.526143 ops/training.py:65 2019-01-16 08:24:03.526098: step 645, loss = 0.71904 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:24:04.488636 ops/training.py:65 2019-01-16 08:24:04.488587: step 646, loss = 0.78513 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:24:05.452231 ops/training.py:65 2019-01-16 08:24:05.452178: step 647, loss = 0.65813 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:24:06.414766 ops/training.py:65 2019-01-16 08:24:06.414716: step 648, loss = 0.71368 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:24:07.377359 ops/training.py:65 2019-01-16 08:24:07.377302: step 649, loss = 0.78549 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:24:08.340093 ops/training.py:65 2019-01-16 08:24:08.340043: step 650, loss = 0.72668 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:24:09.301112 ops/training.py:65 2019-01-16 08:24:09.301042: step 651, loss = 0.84398 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:24:10.264828 ops/training.py:65 2019-01-16 08:24:10.264775: step 652, loss = 0.64071 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:24:11.228773 ops/training.py:65 2019-01-16 08:24:11.228710: step 653, loss = 0.83240 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:24:12.191489 ops/training.py:65 2019-01-16 08:24:12.191426: step 654, loss = 0.69597 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:24:13.151812 ops/training.py:65 2019-01-16 08:24:13.151745: step 655, loss = 0.69712 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:24:14.112302 ops/training.py:65 2019-01-16 08:24:14.112237: step 656, loss = 0.68926 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:24:15.076103 ops/training.py:65 2019-01-16 08:24:15.076050: step 657, loss = 0.71081 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:24:16.040466 ops/training.py:65 2019-01-16 08:24:16.040418: step 658, loss = 0.81890 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:24:17.003452 ops/training.py:65 2019-01-16 08:24:17.003401: step 659, loss = 0.65574 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:24:17.965117 ops/training.py:65 2019-01-16 08:24:17.965065: step 660, loss = 0.73593 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:24:18.924912 ops/training.py:65 2019-01-16 08:24:18.924842: step 661, loss = 0.75159 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:24:19.885124 ops/training.py:65 2019-01-16 08:24:19.885057: step 662, loss = 0.83198 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:24:20.847266 ops/training.py:65 2019-01-16 08:24:20.847215: step 663, loss = 0.83860 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:24:21.808799 ops/training.py:65 2019-01-16 08:24:21.808728: step 664, loss = 0.72680 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:24:22.767996 ops/training.py:65 2019-01-16 08:24:22.767950: step 665, loss = 0.80305 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:24:23.726180 ops/training.py:65 2019-01-16 08:24:23.726128: step 666, loss = 0.76637 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:24:24.684487 ops/training.py:65 2019-01-16 08:24:24.684436: step 667, loss = 0.89746 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:24:25.642746 ops/training.py:65 2019-01-16 08:24:25.642682: step 668, loss = 0.60478 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:24:26.605101 ops/training.py:65 2019-01-16 08:24:26.605040: step 669, loss = 0.73902 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:24:27.566570 ops/training.py:65 2019-01-16 08:24:27.566515: step 670, loss = 0.87121 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:24:28.525839 ops/training.py:65 2019-01-16 08:24:28.525774: step 671, loss = 0.74161 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:24:29.483929 ops/training.py:65 2019-01-16 08:24:29.483882: step 672, loss = 0.77778 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:24:30.447379 ops/training.py:65 2019-01-16 08:24:30.447344: step 673, loss = 0.55853 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 08:24:31.411216 ops/training.py:65 2019-01-16 08:24:31.411174: step 674, loss = 0.89822 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:24:32.373748 ops/training.py:65 2019-01-16 08:24:32.373700: step 675, loss = 0.75482 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:24:33.336801 ops/training.py:65 2019-01-16 08:24:33.336757: step 676, loss = 0.80858 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:24:34.298076 ops/training.py:65 2019-01-16 08:24:34.298033: step 677, loss = 0.83843 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:24:35.261545 ops/training.py:65 2019-01-16 08:24:35.261509: step 678, loss = 0.71725 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:24:36.223208 ops/training.py:65 2019-01-16 08:24:36.223173: step 679, loss = 0.81071 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:24:37.184128 ops/training.py:65 2019-01-16 08:24:37.184089: step 680, loss = 0.86591 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:24:38.147342 ops/training.py:65 2019-01-16 08:24:38.147294: step 681, loss = 0.91487 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:24:39.108905 ops/training.py:65 2019-01-16 08:24:39.108854: step 682, loss = 0.77512 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:24:40.071950 ops/training.py:65 2019-01-16 08:24:40.071892: step 683, loss = 0.93020 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:24:41.031842 ops/training.py:65 2019-01-16 08:24:41.031783: step 684, loss = 0.78657 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:24:41.991376 ops/training.py:65 2019-01-16 08:24:41.991311: step 685, loss = 0.70446 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:24:42.955780 ops/training.py:65 2019-01-16 08:24:42.955733: step 686, loss = 0.77309 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:24:43.919153 ops/training.py:65 2019-01-16 08:24:43.919091: step 687, loss = 0.80626 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:24:44.882221 ops/training.py:65 2019-01-16 08:24:44.882164: step 688, loss = 0.85880 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:24:45.844939 ops/training.py:65 2019-01-16 08:24:45.844881: step 689, loss = 0.77590 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:24:46.804204 ops/training.py:65 2019-01-16 08:24:46.804135: step 690, loss = 0.93456 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:24:47.763938 ops/training.py:65 2019-01-16 08:24:47.763873: step 691, loss = 0.66441 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:24:48.728181 ops/training.py:65 2019-01-16 08:24:48.728137: step 692, loss = 0.78709 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:24:49.691291 ops/training.py:65 2019-01-16 08:24:49.691237: step 693, loss = 0.79790 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:24:50.652633 ops/training.py:65 2019-01-16 08:24:50.652561: step 694, loss = 0.70984 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:24:51.615557 ops/training.py:65 2019-01-16 08:24:51.615492: step 695, loss = 0.76478 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:24:52.577540 ops/training.py:65 2019-01-16 08:24:52.577472: step 696, loss = 0.79928 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:24:53.537181 ops/training.py:65 2019-01-16 08:24:53.537114: step 697, loss = 0.72028 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:24:54.501597 ops/training.py:65 2019-01-16 08:24:54.501545: step 698, loss = 0.72989 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:24:55.465965 ops/training.py:65 2019-01-16 08:24:55.465911: step 699, loss = 0.79274 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:24:56.429368 ops/training.py:65 2019-01-16 08:24:56.429315: step 700, loss = 0.80522 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:24:57.389009 ops/training.py:65 2019-01-16 08:24:57.388951: step 701, loss = 0.89098 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:24:58.348558 ops/training.py:65 2019-01-16 08:24:58.348496: step 702, loss = 0.77839 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:24:59.307582 ops/training.py:65 2019-01-16 08:24:59.307527: step 703, loss = 0.85077 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:25:00.264995 ops/training.py:65 2019-01-16 08:25:00.264943: step 704, loss = 0.67453 (33.5 examples/sec; 0.956 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:25:01.223109 ops/training.py:65 2019-01-16 08:25:01.223059: step 705, loss = 0.80537 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:25:02.181908 ops/training.py:65 2019-01-16 08:25:02.181860: step 706, loss = 0.81938 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:25:03.141520 ops/training.py:65 2019-01-16 08:25:03.141468: step 707, loss = 0.77460 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:25:04.099745 ops/training.py:65 2019-01-16 08:25:04.099690: step 708, loss = 0.76011 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:25:05.058013 ops/training.py:65 2019-01-16 08:25:05.057960: step 709, loss = 0.89122 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:25:06.020679 ops/training.py:65 2019-01-16 08:25:06.020623: step 710, loss = 0.68305 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:25:06.983559 ops/training.py:65 2019-01-16 08:25:06.983503: step 711, loss = 0.58806 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:25:07.947504 ops/training.py:65 2019-01-16 08:25:07.947454: step 712, loss = 0.67027 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:25:08.910651 ops/training.py:65 2019-01-16 08:25:08.910594: step 713, loss = 0.73091 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:25:09.870971 ops/training.py:65 2019-01-16 08:25:09.870902: step 714, loss = 0.82058 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:25:10.835967 ops/training.py:65 2019-01-16 08:25:10.835904: step 715, loss = 0.77984 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:25:11.801619 ops/training.py:65 2019-01-16 08:25:11.801554: step 716, loss = 0.84838 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:25:12.767057 ops/training.py:65 2019-01-16 08:25:12.767004: step 717, loss = 0.78941 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:25:13.730025 ops/training.py:65 2019-01-16 08:25:13.729964: step 718, loss = 0.66262 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:25:14.692276 ops/training.py:65 2019-01-16 08:25:14.692226: step 719, loss = 0.83640 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:25:15.654692 ops/training.py:65 2019-01-16 08:25:15.654644: step 720, loss = 0.75597 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:25:16.617625 ops/training.py:65 2019-01-16 08:25:16.617578: step 721, loss = 0.76273 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:25:17.580195 ops/training.py:65 2019-01-16 08:25:17.580151: step 722, loss = 0.81542 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:25:18.543579 ops/training.py:65 2019-01-16 08:25:18.543523: step 723, loss = 0.73358 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:25:19.503997 ops/training.py:65 2019-01-16 08:25:19.503934: step 724, loss = 0.83172 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:25:20.464433 ops/training.py:65 2019-01-16 08:25:20.464369: step 725, loss = 0.72375 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:25:21.423127 ops/training.py:65 2019-01-16 08:25:21.423078: step 726, loss = 0.67437 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:25:22.386505 ops/training.py:65 2019-01-16 08:25:22.386465: step 727, loss = 0.79945 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:25:23.350417 ops/training.py:65 2019-01-16 08:25:23.350371: step 728, loss = 0.74032 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:25:24.314834 ops/training.py:65 2019-01-16 08:25:24.314783: step 729, loss = 0.83588 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:25:25.277223 ops/training.py:65 2019-01-16 08:25:25.277171: step 730, loss = 0.79305 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:25:26.240543 ops/training.py:65 2019-01-16 08:25:26.240493: step 731, loss = 0.67859 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:25:27.200630 ops/training.py:65 2019-01-16 08:25:27.200577: step 732, loss = 0.83232 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:25:28.160504 ops/training.py:65 2019-01-16 08:25:28.160441: step 733, loss = 0.68085 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:25:29.119488 ops/training.py:65 2019-01-16 08:25:29.119434: step 734, loss = 0.82096 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:25:30.083974 ops/training.py:65 2019-01-16 08:25:30.083921: step 735, loss = 0.63719 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:25:31.048339 ops/training.py:65 2019-01-16 08:25:31.048285: step 736, loss = 0.80026 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:25:32.009251 ops/training.py:65 2019-01-16 08:25:32.009191: step 737, loss = 0.85728 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:25:32.969387 ops/training.py:65 2019-01-16 08:25:32.969320: step 738, loss = 0.75803 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:25:33.930850 ops/training.py:65 2019-01-16 08:25:33.930788: step 739, loss = 0.74660 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:25:34.894911 ops/training.py:65 2019-01-16 08:25:34.894853: step 740, loss = 0.90721 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:25:35.857609 ops/training.py:65 2019-01-16 08:25:35.857550: step 741, loss = 0.81893 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:25:36.820194 ops/training.py:65 2019-01-16 08:25:36.820157: step 742, loss = 0.71733 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:25:37.780945 ops/training.py:65 2019-01-16 08:25:37.780887: step 743, loss = 0.76617 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:25:38.743385 ops/training.py:65 2019-01-16 08:25:38.743338: step 744, loss = 0.74305 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:25:39.704795 ops/training.py:65 2019-01-16 08:25:39.704749: step 745, loss = 0.81663 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:25:40.665935 ops/training.py:65 2019-01-16 08:25:40.665893: step 746, loss = 0.83677 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:25:41.627450 ops/training.py:65 2019-01-16 08:25:41.627405: step 747, loss = 0.67051 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:25:42.588654 ops/training.py:65 2019-01-16 08:25:42.588611: step 748, loss = 0.84708 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:25:43.549521 ops/training.py:65 2019-01-16 08:25:43.549466: step 749, loss = 0.71155 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:25:44.510719 ops/training.py:65 2019-01-16 08:25:44.510659: step 750, loss = 0.95150 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:25:45.470069 ops/training.py:65 2019-01-16 08:25:45.470002: step 751, loss = 0.89113 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:25:46.429179 ops/training.py:65 2019-01-16 08:25:46.429112: step 752, loss = 0.89661 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:25:47.393004 ops/training.py:65 2019-01-16 08:25:47.392951: step 753, loss = 0.82672 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:25:48.355888 ops/training.py:65 2019-01-16 08:25:48.355830: step 754, loss = 0.76423 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:25:49.319262 ops/training.py:65 2019-01-16 08:25:49.319201: step 755, loss = 0.59862 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:25:50.279733 ops/training.py:65 2019-01-16 08:25:50.279664: step 756, loss = 0.69653 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:25:51.238027 ops/training.py:65 2019-01-16 08:25:51.237971: step 757, loss = 0.73954 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:25:52.202051 ops/training.py:65 2019-01-16 08:25:52.202006: step 758, loss = 0.73595 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:25:53.164742 ops/training.py:65 2019-01-16 08:25:53.164687: step 759, loss = 0.73851 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:25:54.126627 ops/training.py:65 2019-01-16 08:25:54.126570: step 760, loss = 0.76402 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:25:55.090667 ops/training.py:65 2019-01-16 08:25:55.090623: step 761, loss = 0.72939 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:25:56.055423 ops/training.py:65 2019-01-16 08:25:56.055377: step 762, loss = 0.68280 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:25:57.017801 ops/training.py:65 2019-01-16 08:25:57.017753: step 763, loss = 0.91078 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:25:57.980371 ops/training.py:65 2019-01-16 08:25:57.980333: step 764, loss = 0.73893 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:25:58.942315 ops/training.py:65 2019-01-16 08:25:58.942273: step 765, loss = 0.88840 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:25:59.907101 ops/training.py:65 2019-01-16 08:25:59.907058: step 766, loss = 0.70590 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:26:00.871278 ops/training.py:65 2019-01-16 08:26:00.871241: step 767, loss = 0.74013 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:26:01.833690 ops/training.py:65 2019-01-16 08:26:01.833654: step 768, loss = 0.94533 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:26:02.795809 ops/training.py:65 2019-01-16 08:26:02.795770: step 769, loss = 0.89309 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:26:03.757423 ops/training.py:65 2019-01-16 08:26:03.757360: step 770, loss = 0.74262 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:26:04.720459 ops/training.py:65 2019-01-16 08:26:04.720393: step 771, loss = 0.64750 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:26:05.683324 ops/training.py:65 2019-01-16 08:26:05.683255: step 772, loss = 0.61124 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:26:06.645761 ops/training.py:65 2019-01-16 08:26:06.645693: step 773, loss = 0.79149 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:26:07.607172 ops/training.py:65 2019-01-16 08:26:07.607110: step 774, loss = 0.96125 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:26:08.569157 ops/training.py:65 2019-01-16 08:26:08.569092: step 775, loss = 0.80675 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:26:09.533365 ops/training.py:65 2019-01-16 08:26:09.533305: step 776, loss = 0.72383 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:26:10.495782 ops/training.py:65 2019-01-16 08:26:10.495712: step 777, loss = 0.79896 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:26:11.458698 ops/training.py:65 2019-01-16 08:26:11.458633: step 778, loss = 0.76564 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:26:12.421228 ops/training.py:65 2019-01-16 08:26:12.421163: step 779, loss = 0.66903 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:26:13.381236 ops/training.py:65 2019-01-16 08:26:13.381173: step 780, loss = 0.72573 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:26:14.340408 ops/training.py:65 2019-01-16 08:26:14.340354: step 781, loss = 0.73268 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:26:15.303662 ops/training.py:65 2019-01-16 08:26:15.303610: step 782, loss = 0.77351 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:26:16.265821 ops/training.py:65 2019-01-16 08:26:16.265757: step 783, loss = 0.65900 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:26:17.227260 ops/training.py:65 2019-01-16 08:26:17.227198: step 784, loss = 0.76311 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:26:18.188273 ops/training.py:65 2019-01-16 08:26:18.188211: step 785, loss = 0.73547 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:26:19.153736 ops/training.py:65 2019-01-16 08:26:19.153671: step 786, loss = 0.69725 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:26:20.117051 ops/training.py:65 2019-01-16 08:26:20.116989: step 787, loss = 0.71582 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:26:21.080624 ops/training.py:65 2019-01-16 08:26:21.080561: step 788, loss = 0.74606 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:26:22.042371 ops/training.py:65 2019-01-16 08:26:22.042308: step 789, loss = 0.75022 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:26:23.004538 ops/training.py:65 2019-01-16 08:26:23.004468: step 790, loss = 0.71701 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:26:23.967272 ops/training.py:65 2019-01-16 08:26:23.967208: step 791, loss = 0.76777 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:26:24.930191 ops/training.py:65 2019-01-16 08:26:24.930130: step 792, loss = 0.66081 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:26:25.893093 ops/training.py:65 2019-01-16 08:26:25.893040: step 793, loss = 0.64185 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:26:26.855634 ops/training.py:65 2019-01-16 08:26:26.855573: step 794, loss = 0.71833 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:26:27.816422 ops/training.py:65 2019-01-16 08:26:27.816368: step 795, loss = 0.71153 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:26:28.778679 ops/training.py:65 2019-01-16 08:26:28.778617: step 796, loss = 0.81139 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:26:29.740907 ops/training.py:65 2019-01-16 08:26:29.740844: step 797, loss = 0.71141 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:26:30.703584 ops/training.py:65 2019-01-16 08:26:30.703509: step 798, loss = 0.68097 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:26:31.662272 ops/training.py:65 2019-01-16 08:26:31.662197: step 799, loss = 0.89691 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:26:32.621919 ops/training.py:65 2019-01-16 08:26:32.621860: step 800, loss = 0.74478 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:26:33.584168 ops/training.py:65 2019-01-16 08:26:33.584114: step 801, loss = 0.65081 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:26:34.545834 ops/training.py:65 2019-01-16 08:26:34.545756: step 802, loss = 0.80340 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:26:35.507665 ops/training.py:65 2019-01-16 08:26:35.507595: step 803, loss = 0.82320 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:26:36.470188 ops/training.py:65 2019-01-16 08:26:36.470117: step 804, loss = 0.69046 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:26:37.429307 ops/training.py:65 2019-01-16 08:26:37.429232: step 805, loss = 0.64318 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:26:38.388551 ops/training.py:65 2019-01-16 08:26:38.388492: step 806, loss = 0.68274 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:26:39.347025 ops/training.py:65 2019-01-16 08:26:39.346958: step 807, loss = 0.74935 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:26:40.307383 ops/training.py:65 2019-01-16 08:26:40.307314: step 808, loss = 0.72995 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:26:41.266902 ops/training.py:65 2019-01-16 08:26:41.266850: step 809, loss = 0.69142 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:26:42.226172 ops/training.py:65 2019-01-16 08:26:42.226119: step 810, loss = 0.61234 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:26:43.185683 ops/training.py:65 2019-01-16 08:26:43.185628: step 811, loss = 0.78413 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:26:44.149413 ops/training.py:65 2019-01-16 08:26:44.149350: step 812, loss = 0.70831 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:26:45.112464 ops/training.py:65 2019-01-16 08:26:45.112400: step 813, loss = 0.74775 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:26:46.075050 ops/training.py:65 2019-01-16 08:26:46.074986: step 814, loss = 0.74662 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:26:47.037591 ops/training.py:65 2019-01-16 08:26:47.037527: step 815, loss = 0.76486 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:26:47.998329 ops/training.py:65 2019-01-16 08:26:47.998266: step 816, loss = 0.72584 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:26:48.961029 ops/training.py:65 2019-01-16 08:26:48.960968: step 817, loss = 0.88417 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:26:49.923511 ops/training.py:65 2019-01-16 08:26:49.923448: step 818, loss = 0.78655 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:26:50.886537 ops/training.py:65 2019-01-16 08:26:50.886473: step 819, loss = 0.74001 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:26:51.848775 ops/training.py:65 2019-01-16 08:26:51.848705: step 820, loss = 0.85170 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:26:52.815322 ops/training.py:65 2019-01-16 08:26:52.815244: step 821, loss = 0.66743 (33.1 examples/sec; 0.966 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:26:53.777417 ops/training.py:65 2019-01-16 08:26:53.777321: step 822, loss = 0.71249 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:26:54.740717 ops/training.py:65 2019-01-16 08:26:54.740656: step 823, loss = 0.86662 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:26:55.703718 ops/training.py:65 2019-01-16 08:26:55.703662: step 824, loss = 0.75275 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:26:56.665379 ops/training.py:65 2019-01-16 08:26:56.665312: step 825, loss = 0.69656 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:26:57.624671 ops/training.py:65 2019-01-16 08:26:57.624618: step 826, loss = 0.68630 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:26:58.584478 ops/training.py:65 2019-01-16 08:26:58.584422: step 827, loss = 0.64051 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:26:59.543103 ops/training.py:65 2019-01-16 08:26:59.543039: step 828, loss = 0.76810 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:27:00.502708 ops/training.py:65 2019-01-16 08:27:00.502643: step 829, loss = 0.69963 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:27:01.461305 ops/training.py:65 2019-01-16 08:27:01.461255: step 830, loss = 0.71084 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:27:02.419946 ops/training.py:65 2019-01-16 08:27:02.419900: step 831, loss = 0.84422 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:27:03.377735 ops/training.py:65 2019-01-16 08:27:03.377689: step 832, loss = 0.66139 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:27:04.335406 ops/training.py:65 2019-01-16 08:27:04.335361: step 833, loss = 0.87271 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:27:05.301744 ops/training.py:65 2019-01-16 08:27:05.301699: step 834, loss = 0.76008 (33.1 examples/sec; 0.965 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:27:06.263848 ops/training.py:65 2019-01-16 08:27:06.263787: step 835, loss = 0.77589 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:27:07.226744 ops/training.py:65 2019-01-16 08:27:07.226680: step 836, loss = 0.73699 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:27:08.188913 ops/training.py:65 2019-01-16 08:27:08.188841: step 837, loss = 0.63529 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:27:09.151171 ops/training.py:65 2019-01-16 08:27:09.151114: step 838, loss = 0.81691 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:27:10.113910 ops/training.py:65 2019-01-16 08:27:10.113862: step 839, loss = 0.88185 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:27:11.075743 ops/training.py:65 2019-01-16 08:27:11.075696: step 840, loss = 0.74374 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:27:12.037391 ops/training.py:65 2019-01-16 08:27:12.037342: step 841, loss = 0.84784 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:27:12.998691 ops/training.py:65 2019-01-16 08:27:12.998634: step 842, loss = 0.87413 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:27:13.958502 ops/training.py:65 2019-01-16 08:27:13.958456: step 843, loss = 0.76890 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:27:14.922586 ops/training.py:65 2019-01-16 08:27:14.922539: step 844, loss = 0.80948 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:27:15.884249 ops/training.py:65 2019-01-16 08:27:15.884199: step 845, loss = 0.78370 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:27:16.847667 ops/training.py:65 2019-01-16 08:27:16.847621: step 846, loss = 0.90874 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:27:17.809285 ops/training.py:65 2019-01-16 08:27:17.809235: step 847, loss = 0.68579 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:27:18.771255 ops/training.py:65 2019-01-16 08:27:18.771185: step 848, loss = 0.80385 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:27:19.734528 ops/training.py:65 2019-01-16 08:27:19.734466: step 849, loss = 0.71368 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:27:20.697354 ops/training.py:65 2019-01-16 08:27:20.697305: step 850, loss = 0.79883 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:27:21.659501 ops/training.py:65 2019-01-16 08:27:21.659443: step 851, loss = 0.77853 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:27:22.621205 ops/training.py:65 2019-01-16 08:27:22.621151: step 852, loss = 0.72878 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:27:23.582313 ops/training.py:65 2019-01-16 08:27:23.582265: step 853, loss = 0.68840 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:27:24.543907 ops/training.py:65 2019-01-16 08:27:24.543860: step 854, loss = 0.76584 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:27:25.504474 ops/training.py:65 2019-01-16 08:27:25.504424: step 855, loss = 0.77211 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:27:26.466051 ops/training.py:65 2019-01-16 08:27:26.465991: step 856, loss = 0.74999 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:27:27.427681 ops/training.py:65 2019-01-16 08:27:27.427634: step 857, loss = 0.71320 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:27:28.389567 ops/training.py:65 2019-01-16 08:27:28.389513: step 858, loss = 0.76674 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:27:29.352203 ops/training.py:65 2019-01-16 08:27:29.352152: step 859, loss = 0.74437 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:27:30.315593 ops/training.py:65 2019-01-16 08:27:30.315538: step 860, loss = 0.63237 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:27:31.278049 ops/training.py:65 2019-01-16 08:27:31.277988: step 861, loss = 0.78469 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:27:32.241656 ops/training.py:65 2019-01-16 08:27:32.241586: step 862, loss = 0.70731 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:27:33.202413 ops/training.py:65 2019-01-16 08:27:33.202338: step 863, loss = 0.75387 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:27:34.166302 ops/training.py:65 2019-01-16 08:27:34.166242: step 864, loss = 0.80321 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:27:35.130120 ops/training.py:65 2019-01-16 08:27:35.130055: step 865, loss = 0.65389 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:27:36.092018 ops/training.py:65 2019-01-16 08:27:36.091944: step 866, loss = 0.81087 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:27:37.051554 ops/training.py:65 2019-01-16 08:27:37.051510: step 867, loss = 0.77118 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:27:38.010981 ops/training.py:65 2019-01-16 08:27:38.010934: step 868, loss = 0.77761 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:27:38.969900 ops/training.py:65 2019-01-16 08:27:38.969855: step 869, loss = 0.79643 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:27:39.929130 ops/training.py:65 2019-01-16 08:27:39.929081: step 870, loss = 0.83333 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:27:40.888178 ops/training.py:65 2019-01-16 08:27:40.888134: step 871, loss = 0.84586 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:27:41.846398 ops/training.py:65 2019-01-16 08:27:41.846354: step 872, loss = 0.97365 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:27:42.806039 ops/training.py:65 2019-01-16 08:27:42.805963: step 873, loss = 0.68751 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:27:43.765881 ops/training.py:65 2019-01-16 08:27:43.765832: step 874, loss = 0.72747 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:27:44.724300 ops/training.py:65 2019-01-16 08:27:44.724254: step 875, loss = 0.65945 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:27:45.686580 ops/training.py:65 2019-01-16 08:27:45.686533: step 876, loss = 0.77646 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:27:46.649534 ops/training.py:65 2019-01-16 08:27:46.649466: step 877, loss = 0.77900 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:27:47.612310 ops/training.py:65 2019-01-16 08:27:47.612245: step 878, loss = 0.77473 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:27:48.574466 ops/training.py:65 2019-01-16 08:27:48.574397: step 879, loss = 0.78277 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:27:49.535119 ops/training.py:65 2019-01-16 08:27:49.535054: step 880, loss = 0.77840 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:27:50.495763 ops/training.py:65 2019-01-16 08:27:50.495694: step 881, loss = 0.81399 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:27:51.457718 ops/training.py:65 2019-01-16 08:27:51.457652: step 882, loss = 0.71332 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:27:52.418908 ops/training.py:65 2019-01-16 08:27:52.418820: step 883, loss = 0.76398 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:27:53.381522 ops/training.py:65 2019-01-16 08:27:53.381452: step 884, loss = 0.75291 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:27:54.343427 ops/training.py:65 2019-01-16 08:27:54.343366: step 885, loss = 0.82379 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:27:55.306744 ops/training.py:65 2019-01-16 08:27:55.306691: step 886, loss = 0.73507 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:27:56.270247 ops/training.py:65 2019-01-16 08:27:56.270194: step 887, loss = 0.82662 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:27:57.231246 ops/training.py:65 2019-01-16 08:27:57.231180: step 888, loss = 0.91551 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:27:58.193617 ops/training.py:65 2019-01-16 08:27:58.193542: step 889, loss = 0.94576 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:27:59.156845 ops/training.py:65 2019-01-16 08:27:59.156774: step 890, loss = 0.72638 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:28:00.118776 ops/training.py:65 2019-01-16 08:28:00.118709: step 891, loss = 0.79027 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:28:01.079599 ops/training.py:65 2019-01-16 08:28:01.079532: step 892, loss = 0.88459 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:28:02.040843 ops/training.py:65 2019-01-16 08:28:02.040782: step 893, loss = 0.67181 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:28:03.002339 ops/training.py:65 2019-01-16 08:28:03.002286: step 894, loss = 0.85242 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:28:03.962758 ops/training.py:65 2019-01-16 08:28:03.962710: step 895, loss = 0.67840 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:28:04.922143 ops/training.py:65 2019-01-16 08:28:04.922099: step 896, loss = 0.69337 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:28:05.884798 ops/training.py:65 2019-01-16 08:28:05.884748: step 897, loss = 0.92359 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:28:06.848723 ops/training.py:65 2019-01-16 08:28:06.848654: step 898, loss = 0.62065 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:28:07.811974 ops/training.py:65 2019-01-16 08:28:07.811908: step 899, loss = 0.78318 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:28:08.775521 ops/training.py:65 2019-01-16 08:28:08.775446: step 900, loss = 0.73228 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:28:09.738555 ops/training.py:65 2019-01-16 08:28:09.738488: step 901, loss = 0.70938 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:28:10.702175 ops/training.py:65 2019-01-16 08:28:10.702124: step 902, loss = 0.79854 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:28:11.664841 ops/training.py:65 2019-01-16 08:28:11.664772: step 903, loss = 0.77677 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:28:12.626326 ops/training.py:65 2019-01-16 08:28:12.626255: step 904, loss = 0.71076 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:28:13.589054 ops/training.py:65 2019-01-16 08:28:13.588987: step 905, loss = 0.79487 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:28:14.551929 ops/training.py:65 2019-01-16 08:28:14.551884: step 906, loss = 0.71233 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:28:15.515474 ops/training.py:65 2019-01-16 08:28:15.515404: step 907, loss = 0.72249 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:28:16.477909 ops/training.py:65 2019-01-16 08:28:16.477844: step 908, loss = 0.80823 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:28:17.438756 ops/training.py:65 2019-01-16 08:28:17.438675: step 909, loss = 0.83496 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:28:18.400772 ops/training.py:65 2019-01-16 08:28:18.400707: step 910, loss = 0.86032 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:28:19.362081 ops/training.py:65 2019-01-16 08:28:19.362011: step 911, loss = 0.76442 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:28:20.323609 ops/training.py:65 2019-01-16 08:28:20.323551: step 912, loss = 0.73453 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:28:21.288251 ops/training.py:65 2019-01-16 08:28:21.288188: step 913, loss = 0.89103 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:28:22.250823 ops/training.py:65 2019-01-16 08:28:22.250757: step 914, loss = 0.84749 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:28:23.211906 ops/training.py:65 2019-01-16 08:28:23.211833: step 915, loss = 0.67496 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:28:24.174027 ops/training.py:65 2019-01-16 08:28:24.173976: step 916, loss = 0.69475 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:28:25.137059 ops/training.py:65 2019-01-16 08:28:25.137015: step 917, loss = 0.68149 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:28:26.100895 ops/training.py:65 2019-01-16 08:28:26.100843: step 918, loss = 0.76178 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:28:27.062609 ops/training.py:65 2019-01-16 08:28:27.062537: step 919, loss = 0.87145 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:28:28.022693 ops/training.py:65 2019-01-16 08:28:28.022620: step 920, loss = 0.88993 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:28:28.983937 ops/training.py:65 2019-01-16 08:28:28.983864: step 921, loss = 0.73524 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:28:29.944999 ops/training.py:65 2019-01-16 08:28:29.944936: step 922, loss = 0.78230 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:28:30.905687 ops/training.py:65 2019-01-16 08:28:30.905622: step 923, loss = 0.70329 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:28:31.867566 ops/training.py:65 2019-01-16 08:28:31.867490: step 924, loss = 0.85294 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:28:32.828472 ops/training.py:65 2019-01-16 08:28:32.828414: step 925, loss = 0.74660 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:28:33.787503 ops/training.py:65 2019-01-16 08:28:33.787461: step 926, loss = 0.66299 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:28:34.745705 ops/training.py:65 2019-01-16 08:28:34.745661: step 927, loss = 0.96548 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:28:35.708602 ops/training.py:65 2019-01-16 08:28:35.708556: step 928, loss = 0.68537 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:28:36.671507 ops/training.py:65 2019-01-16 08:28:36.671431: step 929, loss = 0.75768 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:28:37.634915 ops/training.py:65 2019-01-16 08:28:37.634871: step 930, loss = 0.71851 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:28:38.597269 ops/training.py:65 2019-01-16 08:28:38.597197: step 931, loss = 0.70208 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:28:39.559330 ops/training.py:65 2019-01-16 08:28:39.559286: step 932, loss = 0.77274 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:28:40.522486 ops/training.py:65 2019-01-16 08:28:40.522427: step 933, loss = 0.90931 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:28:41.483219 ops/training.py:65 2019-01-16 08:28:41.483154: step 934, loss = 0.72648 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:28:42.444068 ops/training.py:65 2019-01-16 08:28:42.444005: step 935, loss = 0.73510 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:28:43.405799 ops/training.py:65 2019-01-16 08:28:43.405733: step 936, loss = 0.88349 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:28:44.367370 ops/training.py:65 2019-01-16 08:28:44.367278: step 937, loss = 0.72386 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:28:45.328973 ops/training.py:65 2019-01-16 08:28:45.328898: step 938, loss = 0.71959 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:28:46.291987 ops/training.py:65 2019-01-16 08:28:46.291920: step 939, loss = 0.75995 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:28:47.255405 ops/training.py:65 2019-01-16 08:28:47.255339: step 940, loss = 0.83592 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:28:48.217292 ops/training.py:65 2019-01-16 08:28:48.217241: step 941, loss = 0.72461 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:28:49.178146 ops/training.py:65 2019-01-16 08:28:49.178094: step 942, loss = 0.81965 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:28:50.139109 ops/training.py:65 2019-01-16 08:28:50.139060: step 943, loss = 0.68969 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:28:51.099749 ops/training.py:65 2019-01-16 08:28:51.099683: step 944, loss = 0.76460 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:28:52.060508 ops/training.py:65 2019-01-16 08:28:52.060444: step 945, loss = 0.71387 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:28:53.021722 ops/training.py:65 2019-01-16 08:28:53.021649: step 946, loss = 0.79755 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:28:53.984134 ops/training.py:65 2019-01-16 08:28:53.984059: step 947, loss = 0.76360 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:28:54.947178 ops/training.py:65 2019-01-16 08:28:54.947113: step 948, loss = 0.79184 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:28:55.908583 ops/training.py:65 2019-01-16 08:28:55.908524: step 949, loss = 0.77678 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:28:56.867913 ops/training.py:65 2019-01-16 08:28:56.867839: step 950, loss = 0.69853 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:28:57.830727 ops/training.py:65 2019-01-16 08:28:57.830684: step 951, loss = 0.59930 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 08:28:58.793080 ops/training.py:65 2019-01-16 08:28:58.793014: step 952, loss = 0.72806 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:28:59.756873 ops/training.py:65 2019-01-16 08:28:59.756804: step 953, loss = 0.66756 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:29:00.717647 ops/training.py:65 2019-01-16 08:29:00.717579: step 954, loss = 0.87700 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:29:01.678177 ops/training.py:65 2019-01-16 08:29:01.678123: step 955, loss = 0.72483 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:29:02.639302 ops/training.py:65 2019-01-16 08:29:02.639237: step 956, loss = 0.65188 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:29:03.600030 ops/training.py:65 2019-01-16 08:29:03.599979: step 957, loss = 0.78793 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:29:04.561453 ops/training.py:65 2019-01-16 08:29:04.561392: step 958, loss = 0.75911 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:29:05.523776 ops/training.py:65 2019-01-16 08:29:05.523723: step 959, loss = 0.74848 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:29:06.484271 ops/training.py:65 2019-01-16 08:29:06.484213: step 960, loss = 0.74893 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:29:07.444505 ops/training.py:65 2019-01-16 08:29:07.444450: step 961, loss = 0.72905 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:29:08.405768 ops/training.py:65 2019-01-16 08:29:08.405708: step 962, loss = 0.71834 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:29:09.367133 ops/training.py:65 2019-01-16 08:29:09.367063: step 963, loss = 0.74297 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:29:10.327598 ops/training.py:65 2019-01-16 08:29:10.327531: step 964, loss = 0.79613 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:29:11.287713 ops/training.py:65 2019-01-16 08:29:11.287650: step 965, loss = 0.70775 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:29:12.248694 ops/training.py:65 2019-01-16 08:29:12.248629: step 966, loss = 0.72328 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:29:13.208485 ops/training.py:65 2019-01-16 08:29:13.208417: step 967, loss = 0.72307 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:29:14.168692 ops/training.py:65 2019-01-16 08:29:14.168626: step 968, loss = 0.61917 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:29:15.127468 ops/training.py:65 2019-01-16 08:29:15.127400: step 969, loss = 0.72257 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:29:16.087203 ops/training.py:65 2019-01-16 08:29:16.087133: step 970, loss = 0.68050 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:29:17.046491 ops/training.py:65 2019-01-16 08:29:17.046432: step 971, loss = 0.71152 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:29:18.007184 ops/training.py:65 2019-01-16 08:29:18.007120: step 972, loss = 0.69201 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:29:18.966524 ops/training.py:65 2019-01-16 08:29:18.966458: step 973, loss = 0.75318 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:29:19.929162 ops/training.py:65 2019-01-16 08:29:19.929106: step 974, loss = 0.72095 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:29:20.892331 ops/training.py:65 2019-01-16 08:29:20.892272: step 975, loss = 0.78237 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:29:21.854999 ops/training.py:65 2019-01-16 08:29:21.854935: step 976, loss = 0.69422 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:29:22.817472 ops/training.py:65 2019-01-16 08:29:22.817407: step 977, loss = 0.65812 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:29:23.778642 ops/training.py:65 2019-01-16 08:29:23.778579: step 978, loss = 0.82923 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:29:24.740613 ops/training.py:65 2019-01-16 08:29:24.740547: step 979, loss = 0.79698 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:29:25.701716 ops/training.py:65 2019-01-16 08:29:25.701661: step 980, loss = 0.82505 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:29:26.662980 ops/training.py:65 2019-01-16 08:29:26.662915: step 981, loss = 0.76861 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:29:27.624898 ops/training.py:65 2019-01-16 08:29:27.624835: step 982, loss = 0.66380 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:29:28.587750 ops/training.py:65 2019-01-16 08:29:28.587677: step 983, loss = 0.75075 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:29:29.550077 ops/training.py:65 2019-01-16 08:29:29.550008: step 984, loss = 0.71036 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:29:30.512879 ops/training.py:65 2019-01-16 08:29:30.512802: step 985, loss = 0.75795 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:29:31.473244 ops/training.py:65 2019-01-16 08:29:31.473178: step 986, loss = 0.56545 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 08:29:32.433965 ops/training.py:65 2019-01-16 08:29:32.433903: step 987, loss = 0.81356 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:29:33.395334 ops/training.py:65 2019-01-16 08:29:33.395274: step 988, loss = 0.80873 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:29:34.356766 ops/training.py:65 2019-01-16 08:29:34.356696: step 989, loss = 0.82060 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:29:35.317457 ops/training.py:65 2019-01-16 08:29:35.317385: step 990, loss = 0.72986 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:29:36.277752 ops/training.py:65 2019-01-16 08:29:36.277691: step 991, loss = 0.61640 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:29:37.238876 ops/training.py:65 2019-01-16 08:29:37.238818: step 992, loss = 0.68199 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:29:38.201096 ops/training.py:65 2019-01-16 08:29:38.201033: step 993, loss = 0.77160 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:29:39.163576 ops/training.py:65 2019-01-16 08:29:39.163508: step 994, loss = 0.82052 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:29:40.125275 ops/training.py:65 2019-01-16 08:29:40.125209: step 995, loss = 0.77385 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:29:41.085501 ops/training.py:65 2019-01-16 08:29:41.085451: step 996, loss = 0.75446 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:29:42.045822 ops/training.py:65 2019-01-16 08:29:42.045764: step 997, loss = 0.78313 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:29:43.006656 ops/training.py:65 2019-01-16 08:29:43.006604: step 998, loss = 0.72113 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:29:43.968014 ops/training.py:65 2019-01-16 08:29:43.967940: step 999, loss = 0.79887 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:29:44.929191 ops/training.py:65 2019-01-16 08:29:44.929124: step 1000, loss = 0.77507 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:29:45.890398 ops/training.py:65 2019-01-16 08:29:45.890324: step 1001, loss = 0.76243 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:29:46.851846 ops/training.py:65 2019-01-16 08:29:46.851772: step 1002, loss = 0.72371 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:29:47.812607 ops/training.py:65 2019-01-16 08:29:47.812535: step 1003, loss = 0.86983 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:29:48.773546 ops/training.py:65 2019-01-16 08:29:48.773471: step 1004, loss = 0.71141 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:29:49.738611 ops/training.py:65 2019-01-16 08:29:49.738537: step 1005, loss = 0.75250 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:29:50.699726 ops/training.py:65 2019-01-16 08:29:50.699653: step 1006, loss = 0.76667 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:29:51.660750 ops/training.py:65 2019-01-16 08:29:51.660679: step 1007, loss = 0.66688 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:29:52.621766 ops/training.py:65 2019-01-16 08:29:52.621696: step 1008, loss = 0.73423 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:29:53.583344 ops/training.py:65 2019-01-16 08:29:53.583271: step 1009, loss = 0.68588 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:29:54.543914 ops/training.py:65 2019-01-16 08:29:54.543843: step 1010, loss = 0.72455 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:29:55.506418 ops/training.py:65 2019-01-16 08:29:55.506343: step 1011, loss = 0.75316 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:29:56.467528 ops/training.py:65 2019-01-16 08:29:56.467466: step 1012, loss = 0.77606 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:29:57.428558 ops/training.py:65 2019-01-16 08:29:57.428507: step 1013, loss = 0.65985 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:29:58.389149 ops/training.py:65 2019-01-16 08:29:58.389090: step 1014, loss = 0.76751 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:29:59.350790 ops/training.py:65 2019-01-16 08:29:59.350719: step 1015, loss = 0.68136 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:30:00.312571 ops/training.py:65 2019-01-16 08:30:00.312500: step 1016, loss = 0.72699 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:30:01.273751 ops/training.py:65 2019-01-16 08:30:01.273684: step 1017, loss = 0.86261 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:30:02.234942 ops/training.py:65 2019-01-16 08:30:02.234868: step 1018, loss = 0.62669 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:30:03.196612 ops/training.py:65 2019-01-16 08:30:03.196531: step 1019, loss = 0.66749 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:30:04.158563 ops/training.py:65 2019-01-16 08:30:04.158480: step 1020, loss = 0.78754 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:30:05.121182 ops/training.py:65 2019-01-16 08:30:05.121111: step 1021, loss = 0.69653 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:30:06.083143 ops/training.py:65 2019-01-16 08:30:06.083072: step 1022, loss = 0.77114 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:30:07.044727 ops/training.py:65 2019-01-16 08:30:07.044657: step 1023, loss = 0.70655 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:30:08.005212 ops/training.py:65 2019-01-16 08:30:08.005148: step 1024, loss = 0.75350 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:30:08.965396 ops/training.py:65 2019-01-16 08:30:08.965328: step 1025, loss = 0.73884 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:30:09.926670 ops/training.py:65 2019-01-16 08:30:09.926600: step 1026, loss = 0.69606 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:30:10.887309 ops/training.py:65 2019-01-16 08:30:10.887240: step 1027, loss = 0.78832 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:30:11.848608 ops/training.py:65 2019-01-16 08:30:11.848536: step 1028, loss = 0.66561 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:30:12.811424 ops/training.py:65 2019-01-16 08:30:12.811353: step 1029, loss = 0.71860 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:30:13.773786 ops/training.py:65 2019-01-16 08:30:13.773710: step 1030, loss = 0.67032 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:30:14.737613 ops/training.py:65 2019-01-16 08:30:14.737537: step 1031, loss = 0.72704 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:30:15.700936 ops/training.py:65 2019-01-16 08:30:15.700861: step 1032, loss = 0.66730 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:30:16.664403 ops/training.py:65 2019-01-16 08:30:16.664328: step 1033, loss = 0.81630 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:30:17.626372 ops/training.py:65 2019-01-16 08:30:17.626308: step 1034, loss = 0.70757 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:30:18.585759 ops/training.py:65 2019-01-16 08:30:18.585693: step 1035, loss = 0.75986 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:30:19.546050 ops/training.py:65 2019-01-16 08:30:19.545984: step 1036, loss = 0.63084 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:30:20.510760 ops/training.py:65 2019-01-16 08:30:20.510688: step 1037, loss = 0.74870 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:30:21.473784 ops/training.py:65 2019-01-16 08:30:21.473712: step 1038, loss = 0.76056 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:30:22.437119 ops/training.py:65 2019-01-16 08:30:22.437049: step 1039, loss = 0.75591 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:30:23.399219 ops/training.py:65 2019-01-16 08:30:23.399148: step 1040, loss = 0.62204 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:30:24.361662 ops/training.py:65 2019-01-16 08:30:24.361591: step 1041, loss = 0.80166 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:30:25.324051 ops/training.py:65 2019-01-16 08:30:25.323979: step 1042, loss = 0.78139 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:30:26.285639 ops/training.py:65 2019-01-16 08:30:26.285571: step 1043, loss = 0.65206 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:30:27.247902 ops/training.py:65 2019-01-16 08:30:27.247832: step 1044, loss = 0.65246 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:30:28.210306 ops/training.py:65 2019-01-16 08:30:28.210236: step 1045, loss = 0.76416 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:30:29.172152 ops/training.py:65 2019-01-16 08:30:29.172078: step 1046, loss = 0.74153 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:30:30.133159 ops/training.py:65 2019-01-16 08:30:30.133087: step 1047, loss = 0.75742 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:30:31.094186 ops/training.py:65 2019-01-16 08:30:31.094105: step 1048, loss = 0.72176 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:30:32.056853 ops/training.py:65 2019-01-16 08:30:32.056788: step 1049, loss = 0.66843 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:30:33.018308 ops/training.py:65 2019-01-16 08:30:33.018239: step 1050, loss = 0.74856 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:30:33.980240 ops/training.py:65 2019-01-16 08:30:33.980167: step 1051, loss = 0.81929 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:30:34.942641 ops/training.py:65 2019-01-16 08:30:34.942570: step 1052, loss = 0.69222 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:30:35.904963 ops/training.py:65 2019-01-16 08:30:35.904896: step 1053, loss = 0.71234 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:30:36.867059 ops/training.py:65 2019-01-16 08:30:36.866984: step 1054, loss = 0.66901 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:30:37.828580 ops/training.py:65 2019-01-16 08:30:37.828509: step 1055, loss = 0.73083 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:30:38.790241 ops/training.py:65 2019-01-16 08:30:38.790173: step 1056, loss = 0.70250 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:30:39.752848 ops/training.py:65 2019-01-16 08:30:39.752772: step 1057, loss = 0.69456 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:30:40.714277 ops/training.py:65 2019-01-16 08:30:40.714215: step 1058, loss = 0.61523 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:30:41.675377 ops/training.py:65 2019-01-16 08:30:41.675303: step 1059, loss = 0.72580 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:30:42.637526 ops/training.py:65 2019-01-16 08:30:42.637468: step 1060, loss = 0.72016 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:30:43.599775 ops/training.py:65 2019-01-16 08:30:43.599704: step 1061, loss = 0.73241 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:30:44.561950 ops/training.py:65 2019-01-16 08:30:44.561878: step 1062, loss = 0.65107 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:30:45.523643 ops/training.py:65 2019-01-16 08:30:45.523570: step 1063, loss = 0.77190 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:30:46.485192 ops/training.py:65 2019-01-16 08:30:46.485123: step 1064, loss = 0.76486 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:30:47.446995 ops/training.py:65 2019-01-16 08:30:47.446931: step 1065, loss = 0.73961 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:30:48.407825 ops/training.py:65 2019-01-16 08:30:48.407754: step 1066, loss = 0.73197 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:30:49.369428 ops/training.py:65 2019-01-16 08:30:49.369351: step 1067, loss = 0.75989 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:30:50.331535 ops/training.py:65 2019-01-16 08:30:50.331461: step 1068, loss = 0.71463 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:30:51.294335 ops/training.py:65 2019-01-16 08:30:51.294259: step 1069, loss = 0.66559 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:30:52.256579 ops/training.py:65 2019-01-16 08:30:52.256510: step 1070, loss = 0.73325 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:30:53.219175 ops/training.py:65 2019-01-16 08:30:53.219107: step 1071, loss = 0.70225 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:30:54.180991 ops/training.py:65 2019-01-16 08:30:54.180917: step 1072, loss = 0.73732 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:30:55.140635 ops/training.py:65 2019-01-16 08:30:55.140566: step 1073, loss = 0.79680 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:30:56.098481 ops/training.py:65 2019-01-16 08:30:56.098416: step 1074, loss = 0.76822 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:30:57.056801 ops/training.py:65 2019-01-16 08:30:57.056733: step 1075, loss = 0.71010 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:30:58.015578 ops/training.py:65 2019-01-16 08:30:58.015513: step 1076, loss = 0.73974 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:30:58.975299 ops/training.py:65 2019-01-16 08:30:58.975229: step 1077, loss = 0.72882 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:30:59.934056 ops/training.py:65 2019-01-16 08:30:59.933986: step 1078, loss = 0.85873 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:31:00.892799 ops/training.py:65 2019-01-16 08:31:00.892729: step 1079, loss = 0.75701 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:31:01.852098 ops/training.py:65 2019-01-16 08:31:01.852041: step 1080, loss = 0.69934 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:31:02.810788 ops/training.py:65 2019-01-16 08:31:02.810715: step 1081, loss = 0.73600 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:31:03.774913 ops/training.py:65 2019-01-16 08:31:03.774843: step 1082, loss = 0.67122 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:31:04.737523 ops/training.py:65 2019-01-16 08:31:04.737460: step 1083, loss = 0.74225 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:31:05.699816 ops/training.py:65 2019-01-16 08:31:05.699755: step 1084, loss = 0.83406 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:31:06.661417 ops/training.py:65 2019-01-16 08:31:06.661350: step 1085, loss = 0.61890 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 08:31:07.623431 ops/training.py:65 2019-01-16 08:31:07.623366: step 1086, loss = 0.71365 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:31:08.585890 ops/training.py:65 2019-01-16 08:31:08.585821: step 1087, loss = 0.71759 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:31:09.547599 ops/training.py:65 2019-01-16 08:31:09.547533: step 1088, loss = 0.75000 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:31:10.508345 ops/training.py:65 2019-01-16 08:31:10.508284: step 1089, loss = 0.71352 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:31:11.469241 ops/training.py:65 2019-01-16 08:31:11.469175: step 1090, loss = 0.68325 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:31:12.432807 ops/training.py:65 2019-01-16 08:31:12.432758: step 1091, loss = 0.66799 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:31:13.392467 ops/training.py:65 2019-01-16 08:31:13.392398: step 1092, loss = 0.74748 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:31:14.351300 ops/training.py:65 2019-01-16 08:31:14.351227: step 1093, loss = 0.69553 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:31:15.310046 ops/training.py:65 2019-01-16 08:31:15.309968: step 1094, loss = 0.63712 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:31:16.268467 ops/training.py:65 2019-01-16 08:31:16.268399: step 1095, loss = 0.67959 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:31:17.230988 ops/training.py:65 2019-01-16 08:31:17.230926: step 1096, loss = 0.72831 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:31:18.193075 ops/training.py:65 2019-01-16 08:31:18.193011: step 1097, loss = 0.71467 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:31:19.155459 ops/training.py:65 2019-01-16 08:31:19.155420: step 1098, loss = 0.71739 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:31:20.116919 ops/training.py:65 2019-01-16 08:31:20.116852: step 1099, loss = 0.77607 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:31:21.077776 ops/training.py:65 2019-01-16 08:31:21.077709: step 1100, loss = 0.72305 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:31:22.038929 ops/training.py:65 2019-01-16 08:31:22.038836: step 1101, loss = 0.73697 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:31:23.000293 ops/training.py:65 2019-01-16 08:31:23.000226: step 1102, loss = 0.80268 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:31:23.961116 ops/training.py:65 2019-01-16 08:31:23.961059: step 1103, loss = 0.66569 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:31:24.925105 ops/training.py:65 2019-01-16 08:31:24.925047: step 1104, loss = 0.67604 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:31:25.888548 ops/training.py:65 2019-01-16 08:31:25.888492: step 1105, loss = 0.78268 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:31:26.850985 ops/training.py:65 2019-01-16 08:31:26.850937: step 1106, loss = 0.74585 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:31:27.814338 ops/training.py:65 2019-01-16 08:31:27.814288: step 1107, loss = 0.68543 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:31:28.776950 ops/training.py:65 2019-01-16 08:31:28.776883: step 1108, loss = 0.72725 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:31:29.738024 ops/training.py:65 2019-01-16 08:31:29.737964: step 1109, loss = 0.74669 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:31:30.698529 ops/training.py:65 2019-01-16 08:31:30.698474: step 1110, loss = 0.75894 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:31:31.659777 ops/training.py:65 2019-01-16 08:31:31.659706: step 1111, loss = 0.68637 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:31:32.621019 ops/training.py:65 2019-01-16 08:31:32.620941: step 1112, loss = 0.73505 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:31:33.583181 ops/training.py:65 2019-01-16 08:31:33.583121: step 1113, loss = 0.68138 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:31:34.545261 ops/training.py:65 2019-01-16 08:31:34.545199: step 1114, loss = 0.64556 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:31:35.506373 ops/training.py:65 2019-01-16 08:31:35.506306: step 1115, loss = 0.79204 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:31:36.468348 ops/training.py:65 2019-01-16 08:31:36.468278: step 1116, loss = 0.71216 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:31:37.430177 ops/training.py:65 2019-01-16 08:31:37.430115: step 1117, loss = 0.71214 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:31:38.392318 ops/training.py:65 2019-01-16 08:31:38.392259: step 1118, loss = 0.69264 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:31:39.354371 ops/training.py:65 2019-01-16 08:31:39.354296: step 1119, loss = 0.61242 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:31:40.316905 ops/training.py:65 2019-01-16 08:31:40.316839: step 1120, loss = 0.69961 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:31:41.279153 ops/training.py:65 2019-01-16 08:31:41.279088: step 1121, loss = 0.64361 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:31:42.240687 ops/training.py:65 2019-01-16 08:31:42.240608: step 1122, loss = 0.72837 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:31:43.202270 ops/training.py:65 2019-01-16 08:31:43.202201: step 1123, loss = 0.71372 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:31:44.164616 ops/training.py:65 2019-01-16 08:31:44.164552: step 1124, loss = 0.73786 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:31:45.126153 ops/training.py:65 2019-01-16 08:31:45.126091: step 1125, loss = 0.69243 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:31:46.087764 ops/training.py:65 2019-01-16 08:31:46.087699: step 1126, loss = 0.68637 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:31:47.049151 ops/training.py:65 2019-01-16 08:31:47.049069: step 1127, loss = 0.70948 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:31:48.011819 ops/training.py:65 2019-01-16 08:31:48.011759: step 1128, loss = 0.65807 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:31:48.974069 ops/training.py:65 2019-01-16 08:31:48.974001: step 1129, loss = 0.76080 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:31:49.935349 ops/training.py:65 2019-01-16 08:31:49.935272: step 1130, loss = 0.72608 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:31:50.896219 ops/training.py:65 2019-01-16 08:31:50.896157: step 1131, loss = 0.79676 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:31:51.855317 ops/training.py:65 2019-01-16 08:31:51.855244: step 1132, loss = 0.64942 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:31:52.814648 ops/training.py:65 2019-01-16 08:31:52.814567: step 1133, loss = 0.68439 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:31:53.778683 ops/training.py:65 2019-01-16 08:31:53.778608: step 1134, loss = 0.72051 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:31:54.741910 ops/training.py:65 2019-01-16 08:31:54.741838: step 1135, loss = 0.71911 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:31:55.705684 ops/training.py:65 2019-01-16 08:31:55.705626: step 1136, loss = 0.73626 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:31:56.666601 ops/training.py:65 2019-01-16 08:31:56.666526: step 1137, loss = 0.70437 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:31:57.628807 ops/training.py:65 2019-01-16 08:31:57.628746: step 1138, loss = 0.79573 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:31:58.588632 ops/training.py:65 2019-01-16 08:31:58.588553: step 1139, loss = 0.69890 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:31:59.548143 ops/training.py:65 2019-01-16 08:31:59.548084: step 1140, loss = 0.77402 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:32:00.511806 ops/training.py:65 2019-01-16 08:32:00.511732: step 1141, loss = 0.67980 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:32:01.476330 ops/training.py:65 2019-01-16 08:32:01.476243: step 1142, loss = 0.74590 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:32:02.440550 ops/training.py:65 2019-01-16 08:32:02.440464: step 1143, loss = 0.74570 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:32:03.403068 ops/training.py:65 2019-01-16 08:32:03.403002: step 1144, loss = 0.73161 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:32:04.364875 ops/training.py:65 2019-01-16 08:32:04.364784: step 1145, loss = 0.80180 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:32:05.325516 ops/training.py:65 2019-01-16 08:32:05.325334: step 1146, loss = 0.71988 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:32:06.288593 ops/training.py:65 2019-01-16 08:32:06.288522: step 1147, loss = 0.77503 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.25
I0832 2019-01-16 08:32:07.251814 ops/training.py:65 2019-01-16 08:32:07.251752: step 1148, loss = 0.74800 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:32:08.210007 ops/training.py:65 2019-01-16 08:32:08.209941: step 1149, loss = 0.63620 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:32:09.172633 ops/training.py:65 2019-01-16 08:32:09.172572: step 1150, loss = 0.76888 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:32:10.135863 ops/training.py:65 2019-01-16 08:32:10.135788: step 1151, loss = 0.72262 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:32:11.098533 ops/training.py:65 2019-01-16 08:32:11.098464: step 1152, loss = 0.75635 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:32:12.059470 ops/training.py:65 2019-01-16 08:32:12.059404: step 1153, loss = 0.69968 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:32:13.058033 ops/training.py:65 2019-01-16 08:32:13.057971: step 1154, loss = 0.71417 (32.1 examples/sec; 0.998 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:32:14.020284 ops/training.py:65 2019-01-16 08:32:14.020216: step 1155, loss = 0.75234 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:32:14.980779 ops/training.py:65 2019-01-16 08:32:14.980715: step 1156, loss = 0.82434 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:32:15.941239 ops/training.py:65 2019-01-16 08:32:15.941175: step 1157, loss = 0.71642 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:32:16.900391 ops/training.py:65 2019-01-16 08:32:16.900321: step 1158, loss = 0.72340 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:32:17.864404 ops/training.py:65 2019-01-16 08:32:17.864344: step 1159, loss = 0.72703 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:32:18.826006 ops/training.py:65 2019-01-16 08:32:18.825943: step 1160, loss = 0.73817 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:32:19.788626 ops/training.py:65 2019-01-16 08:32:19.788557: step 1161, loss = 0.76371 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:32:20.749417 ops/training.py:65 2019-01-16 08:32:20.749338: step 1162, loss = 0.69687 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:32:21.710791 ops/training.py:65 2019-01-16 08:32:21.710723: step 1163, loss = 0.64796 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:32:22.671982 ops/training.py:65 2019-01-16 08:32:22.671912: step 1164, loss = 0.75725 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:32:23.633070 ops/training.py:65 2019-01-16 08:32:23.632991: step 1165, loss = 0.67021 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:32:24.594535 ops/training.py:65 2019-01-16 08:32:24.594471: step 1166, loss = 0.76396 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:32:25.554878 ops/training.py:65 2019-01-16 08:32:25.554819: step 1167, loss = 0.80057 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:32:26.515369 ops/training.py:65 2019-01-16 08:32:26.515302: step 1168, loss = 0.80108 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:32:27.475442 ops/training.py:65 2019-01-16 08:32:27.475379: step 1169, loss = 0.73370 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:32:28.436406 ops/training.py:65 2019-01-16 08:32:28.436335: step 1170, loss = 0.65266 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:32:29.396521 ops/training.py:65 2019-01-16 08:32:29.396452: step 1171, loss = 0.62217 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:32:30.358652 ops/training.py:65 2019-01-16 08:32:30.358584: step 1172, loss = 0.69900 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:32:31.322331 ops/training.py:65 2019-01-16 08:32:31.322262: step 1173, loss = 0.73982 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:32:32.285207 ops/training.py:65 2019-01-16 08:32:32.285140: step 1174, loss = 0.69480 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:32:33.247744 ops/training.py:65 2019-01-16 08:32:33.247680: step 1175, loss = 0.68065 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:32:34.208213 ops/training.py:65 2019-01-16 08:32:34.208139: step 1176, loss = 0.74337 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:32:35.168989 ops/training.py:65 2019-01-16 08:32:35.168901: step 1177, loss = 0.71513 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:32:36.128845 ops/training.py:65 2019-01-16 08:32:36.128780: step 1178, loss = 0.72136 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:32:37.090867 ops/training.py:65 2019-01-16 08:32:37.090801: step 1179, loss = 0.85376 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:32:38.052062 ops/training.py:65 2019-01-16 08:32:38.051995: step 1180, loss = 0.76530 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:32:39.012333 ops/training.py:65 2019-01-16 08:32:39.012263: step 1181, loss = 0.70437 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:32:39.973989 ops/training.py:65 2019-01-16 08:32:39.973920: step 1182, loss = 0.67002 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:32:40.935256 ops/training.py:65 2019-01-16 08:32:40.935191: step 1183, loss = 0.78863 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:32:41.896820 ops/training.py:65 2019-01-16 08:32:41.896753: step 1184, loss = 0.71357 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:32:42.859051 ops/training.py:65 2019-01-16 08:32:42.858981: step 1185, loss = 0.68979 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:32:43.820484 ops/training.py:65 2019-01-16 08:32:43.820417: step 1186, loss = 0.63005 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:32:44.782989 ops/training.py:65 2019-01-16 08:32:44.782918: step 1187, loss = 0.66634 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:32:45.744713 ops/training.py:65 2019-01-16 08:32:45.744644: step 1188, loss = 0.76184 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:32:46.705003 ops/training.py:65 2019-01-16 08:32:46.704930: step 1189, loss = 0.83953 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:32:47.665233 ops/training.py:65 2019-01-16 08:32:47.665166: step 1190, loss = 0.73625 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:32:48.626391 ops/training.py:65 2019-01-16 08:32:48.626326: step 1191, loss = 0.72076 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:32:49.586978 ops/training.py:65 2019-01-16 08:32:49.586915: step 1192, loss = 0.79938 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:32:50.548603 ops/training.py:65 2019-01-16 08:32:50.548537: step 1193, loss = 0.68258 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:32:51.510684 ops/training.py:65 2019-01-16 08:32:51.510624: step 1194, loss = 0.74359 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:32:52.471261 ops/training.py:65 2019-01-16 08:32:52.471205: step 1195, loss = 0.76956 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:32:53.433506 ops/training.py:65 2019-01-16 08:32:53.433440: step 1196, loss = 0.76156 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:32:54.395368 ops/training.py:65 2019-01-16 08:32:54.395295: step 1197, loss = 0.67934 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:32:55.357298 ops/training.py:65 2019-01-16 08:32:55.357233: step 1198, loss = 0.83858 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:32:56.319004 ops/training.py:65 2019-01-16 08:32:56.318940: step 1199, loss = 0.81157 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:32:57.279952 ops/training.py:65 2019-01-16 08:32:57.279900: step 1200, loss = 0.76299 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:32:58.241078 ops/training.py:65 2019-01-16 08:32:58.241022: step 1201, loss = 0.69230 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:32:59.202529 ops/training.py:65 2019-01-16 08:32:59.202469: step 1202, loss = 0.67508 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:33:00.163665 ops/training.py:65 2019-01-16 08:33:00.163599: step 1203, loss = 0.67349 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:33:01.123480 ops/training.py:65 2019-01-16 08:33:01.123415: step 1204, loss = 0.76234 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:33:02.084787 ops/training.py:65 2019-01-16 08:33:02.084727: step 1205, loss = 0.74635 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:33:03.045855 ops/training.py:65 2019-01-16 08:33:03.045786: step 1206, loss = 0.84597 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:33:04.007756 ops/training.py:65 2019-01-16 08:33:04.007697: step 1207, loss = 0.56451 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:33:04.969600 ops/training.py:65 2019-01-16 08:33:04.969548: step 1208, loss = 0.75479 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:33:05.930972 ops/training.py:65 2019-01-16 08:33:05.930903: step 1209, loss = 0.72722 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:33:06.892959 ops/training.py:65 2019-01-16 08:33:06.892892: step 1210, loss = 0.78930 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:33:07.853628 ops/training.py:65 2019-01-16 08:33:07.853565: step 1211, loss = 0.77233 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:33:08.813965 ops/training.py:65 2019-01-16 08:33:08.813895: step 1212, loss = 0.73869 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:33:09.778172 ops/training.py:65 2019-01-16 08:33:09.778105: step 1213, loss = 0.68812 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:33:10.738755 ops/training.py:65 2019-01-16 08:33:10.738690: step 1214, loss = 0.68353 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:33:11.699983 ops/training.py:65 2019-01-16 08:33:11.699905: step 1215, loss = 0.72732 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:33:12.663655 ops/training.py:65 2019-01-16 08:33:12.663601: step 1216, loss = 0.72838 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:33:13.627628 ops/training.py:65 2019-01-16 08:33:13.627563: step 1217, loss = 0.62384 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:33:14.589931 ops/training.py:65 2019-01-16 08:33:14.589865: step 1218, loss = 0.79173 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:33:15.552611 ops/training.py:65 2019-01-16 08:33:15.552540: step 1219, loss = 0.78370 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:33:16.514339 ops/training.py:65 2019-01-16 08:33:16.514268: step 1220, loss = 0.70784 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:33:17.476089 ops/training.py:65 2019-01-16 08:33:17.476027: step 1221, loss = 0.70167 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:33:18.437740 ops/training.py:65 2019-01-16 08:33:18.437673: step 1222, loss = 0.75990 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:33:19.399799 ops/training.py:65 2019-01-16 08:33:19.399723: step 1223, loss = 0.71759 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:33:20.361427 ops/training.py:65 2019-01-16 08:33:20.361356: step 1224, loss = 0.70041 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:33:21.322543 ops/training.py:65 2019-01-16 08:33:21.322472: step 1225, loss = 0.82934 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 08:33:22.283465 ops/training.py:65 2019-01-16 08:33:22.283396: step 1226, loss = 0.68002 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:33:23.245391 ops/training.py:65 2019-01-16 08:33:23.245325: step 1227, loss = 0.64002 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:33:24.208324 ops/training.py:65 2019-01-16 08:33:24.208251: step 1228, loss = 0.73830 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:33:25.171507 ops/training.py:65 2019-01-16 08:33:25.171442: step 1229, loss = 0.74755 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:33:26.131698 ops/training.py:65 2019-01-16 08:33:26.131634: step 1230, loss = 0.75080 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:33:27.095524 ops/training.py:65 2019-01-16 08:33:27.095460: step 1231, loss = 0.73271 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:33:28.061204 ops/training.py:65 2019-01-16 08:33:28.061152: step 1232, loss = 0.73635 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:33:29.023366 ops/training.py:65 2019-01-16 08:33:29.023294: step 1233, loss = 0.69556 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:33:29.984718 ops/training.py:65 2019-01-16 08:33:29.984658: step 1234, loss = 0.74821 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:33:30.948446 ops/training.py:65 2019-01-16 08:33:30.948398: step 1235, loss = 0.68344 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:33:31.911517 ops/training.py:65 2019-01-16 08:33:31.911465: step 1236, loss = 0.69210 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:33:32.873734 ops/training.py:65 2019-01-16 08:33:32.873646: step 1237, loss = 0.76995 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:33:33.834687 ops/training.py:65 2019-01-16 08:33:33.834630: step 1238, loss = 0.70860 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:33:34.794751 ops/training.py:65 2019-01-16 08:33:34.794680: step 1239, loss = 0.69178 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:33:35.756260 ops/training.py:65 2019-01-16 08:33:35.756191: step 1240, loss = 0.71389 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:33:36.717686 ops/training.py:65 2019-01-16 08:33:36.717616: step 1241, loss = 0.69133 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:33:37.680833 ops/training.py:65 2019-01-16 08:33:37.680784: step 1242, loss = 0.63204 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:33:38.642579 ops/training.py:65 2019-01-16 08:33:38.642519: step 1243, loss = 0.70641 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:33:39.602946 ops/training.py:65 2019-01-16 08:33:39.602891: step 1244, loss = 0.77760 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:33:40.565121 ops/training.py:65 2019-01-16 08:33:40.565066: step 1245, loss = 0.66498 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:33:41.528516 ops/training.py:65 2019-01-16 08:33:41.528468: step 1246, loss = 0.81837 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:33:42.489748 ops/training.py:65 2019-01-16 08:33:42.489690: step 1247, loss = 0.80141 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:33:43.451796 ops/training.py:65 2019-01-16 08:33:43.451740: step 1248, loss = 0.72023 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:33:44.413281 ops/training.py:65 2019-01-16 08:33:44.413225: step 1249, loss = 0.65458 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:33:45.373420 ops/training.py:65 2019-01-16 08:33:45.373364: step 1250, loss = 0.74418 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:33:46.335404 ops/training.py:65 2019-01-16 08:33:46.335351: step 1251, loss = 0.67539 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:33:47.298342 ops/training.py:65 2019-01-16 08:33:47.298292: step 1252, loss = 0.76865 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:33:48.260714 ops/training.py:65 2019-01-16 08:33:48.260659: step 1253, loss = 0.71772 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:33:49.222142 ops/training.py:65 2019-01-16 08:33:49.222084: step 1254, loss = 0.79328 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:33:50.184378 ops/training.py:65 2019-01-16 08:33:50.184328: step 1255, loss = 0.76916 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:33:51.146342 ops/training.py:65 2019-01-16 08:33:51.146274: step 1256, loss = 0.71275 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:33:52.108587 ops/training.py:65 2019-01-16 08:33:52.108526: step 1257, loss = 0.74505 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:33:53.069616 ops/training.py:65 2019-01-16 08:33:53.069567: step 1258, loss = 0.75431 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:33:54.030855 ops/training.py:65 2019-01-16 08:33:54.030795: step 1259, loss = 0.84162 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:33:54.991651 ops/training.py:65 2019-01-16 08:33:54.991591: step 1260, loss = 0.81572 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:33:55.952821 ops/training.py:65 2019-01-16 08:33:55.952764: step 1261, loss = 0.77397 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:33:56.912677 ops/training.py:65 2019-01-16 08:33:56.912617: step 1262, loss = 0.65376 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:33:57.873341 ops/training.py:65 2019-01-16 08:33:57.873290: step 1263, loss = 0.67129 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:33:58.837397 ops/training.py:65 2019-01-16 08:33:58.837344: step 1264, loss = 0.68673 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:33:59.801924 ops/training.py:65 2019-01-16 08:33:59.801872: step 1265, loss = 0.74991 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:34:00.764470 ops/training.py:65 2019-01-16 08:34:00.764416: step 1266, loss = 0.74090 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:34:01.725717 ops/training.py:65 2019-01-16 08:34:01.725670: step 1267, loss = 0.65596 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:34:02.687548 ops/training.py:65 2019-01-16 08:34:02.687496: step 1268, loss = 0.67623 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:34:03.648825 ops/training.py:65 2019-01-16 08:34:03.648773: step 1269, loss = 0.72313 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:34:04.610110 ops/training.py:65 2019-01-16 08:34:04.610058: step 1270, loss = 0.75573 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:34:05.571579 ops/training.py:65 2019-01-16 08:34:05.571525: step 1271, loss = 0.69186 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:34:06.532764 ops/training.py:65 2019-01-16 08:34:06.532717: step 1272, loss = 0.69418 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:34:07.494463 ops/training.py:65 2019-01-16 08:34:07.494410: step 1273, loss = 0.73863 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:34:08.455573 ops/training.py:65 2019-01-16 08:34:08.455519: step 1274, loss = 0.69137 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:34:09.417797 ops/training.py:65 2019-01-16 08:34:09.417745: step 1275, loss = 0.66018 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:34:10.382268 ops/training.py:65 2019-01-16 08:34:10.382214: step 1276, loss = 0.73570 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:34:11.345359 ops/training.py:65 2019-01-16 08:34:11.345309: step 1277, loss = 0.78653 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:34:12.307754 ops/training.py:65 2019-01-16 08:34:12.307706: step 1278, loss = 0.73886 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:34:13.268308 ops/training.py:65 2019-01-16 08:34:13.268259: step 1279, loss = 0.75860 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:34:14.229025 ops/training.py:65 2019-01-16 08:34:14.228974: step 1280, loss = 0.69044 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:34:15.189568 ops/training.py:65 2019-01-16 08:34:15.189509: step 1281, loss = 0.70947 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:34:16.151576 ops/training.py:65 2019-01-16 08:34:16.151524: step 1282, loss = 0.74692 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:34:17.111656 ops/training.py:65 2019-01-16 08:34:17.111604: step 1283, loss = 0.74021 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:34:18.073237 ops/training.py:65 2019-01-16 08:34:18.073181: step 1284, loss = 0.72073 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:34:19.033659 ops/training.py:65 2019-01-16 08:34:19.033609: step 1285, loss = 0.72654 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:34:19.997023 ops/training.py:65 2019-01-16 08:34:19.996972: step 1286, loss = 0.63659 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:34:20.961392 ops/training.py:65 2019-01-16 08:34:20.961341: step 1287, loss = 0.77502 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:34:21.924169 ops/training.py:65 2019-01-16 08:34:21.924119: step 1288, loss = 0.68732 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:34:22.886625 ops/training.py:65 2019-01-16 08:34:22.886575: step 1289, loss = 0.86747 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:34:23.848136 ops/training.py:65 2019-01-16 08:34:23.848075: step 1290, loss = 0.75990 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:34:24.814591 ops/training.py:65 2019-01-16 08:34:24.814542: step 1291, loss = 0.77594 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:34:25.776033 ops/training.py:65 2019-01-16 08:34:25.775977: step 1292, loss = 0.76285 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:34:26.739415 ops/training.py:65 2019-01-16 08:34:26.739344: step 1293, loss = 0.74294 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:34:27.703574 ops/training.py:65 2019-01-16 08:34:27.703525: step 1294, loss = 0.81410 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:34:28.665837 ops/training.py:65 2019-01-16 08:34:28.665787: step 1295, loss = 0.79100 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:34:29.626234 ops/training.py:65 2019-01-16 08:34:29.626180: step 1296, loss = 0.81455 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:34:30.588815 ops/training.py:65 2019-01-16 08:34:30.588757: step 1297, loss = 0.77148 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:34:31.553246 ops/training.py:65 2019-01-16 08:34:31.553199: step 1298, loss = 0.74156 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:34:32.518362 ops/training.py:65 2019-01-16 08:34:32.518310: step 1299, loss = 0.80877 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:34:33.480017 ops/training.py:65 2019-01-16 08:34:33.479942: step 1300, loss = 0.63787 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:34:34.441084 ops/training.py:65 2019-01-16 08:34:34.441035: step 1301, loss = 0.68749 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:34:35.404402 ops/training.py:65 2019-01-16 08:34:35.404346: step 1302, loss = 0.80038 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:34:36.367163 ops/training.py:65 2019-01-16 08:34:36.367110: step 1303, loss = 0.66718 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:34:37.328546 ops/training.py:65 2019-01-16 08:34:37.328493: step 1304, loss = 0.72965 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:34:38.290906 ops/training.py:65 2019-01-16 08:34:38.290854: step 1305, loss = 0.75788 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:34:39.252876 ops/training.py:65 2019-01-16 08:34:39.252817: step 1306, loss = 0.71614 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:34:40.213833 ops/training.py:65 2019-01-16 08:34:40.213772: step 1307, loss = 0.62210 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:34:41.174927 ops/training.py:65 2019-01-16 08:34:41.174867: step 1308, loss = 0.76401 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:34:42.136439 ops/training.py:65 2019-01-16 08:34:42.136382: step 1309, loss = 0.73444 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:34:43.099125 ops/training.py:65 2019-01-16 08:34:43.099063: step 1310, loss = 0.80513 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:34:44.061743 ops/training.py:65 2019-01-16 08:34:44.061690: step 1311, loss = 0.75382 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:34:45.024343 ops/training.py:65 2019-01-16 08:34:45.024283: step 1312, loss = 0.65209 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:34:45.988119 ops/training.py:65 2019-01-16 08:34:45.988058: step 1313, loss = 0.66119 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:34:46.951914 ops/training.py:65 2019-01-16 08:34:46.951857: step 1314, loss = 0.74248 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:34:47.915383 ops/training.py:65 2019-01-16 08:34:47.915321: step 1315, loss = 0.72770 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:34:48.877219 ops/training.py:65 2019-01-16 08:34:48.877157: step 1316, loss = 0.75000 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:34:49.838721 ops/training.py:65 2019-01-16 08:34:49.838663: step 1317, loss = 0.83345 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:34:50.800701 ops/training.py:65 2019-01-16 08:34:50.800645: step 1318, loss = 0.75746 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:34:51.762028 ops/training.py:65 2019-01-16 08:34:51.761965: step 1319, loss = 0.70957 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:34:52.723600 ops/training.py:65 2019-01-16 08:34:52.723540: step 1320, loss = 0.70715 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:34:53.684415 ops/training.py:65 2019-01-16 08:34:53.684360: step 1321, loss = 0.68830 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:34:54.645457 ops/training.py:65 2019-01-16 08:34:54.645396: step 1322, loss = 0.71934 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:34:55.606114 ops/training.py:65 2019-01-16 08:34:55.606054: step 1323, loss = 0.76099 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:34:56.571075 ops/training.py:65 2019-01-16 08:34:56.571024: step 1324, loss = 0.71490 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:34:57.533533 ops/training.py:65 2019-01-16 08:34:57.533481: step 1325, loss = 0.68667 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:34:58.495307 ops/training.py:65 2019-01-16 08:34:58.495254: step 1326, loss = 0.72793 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:34:59.456822 ops/training.py:65 2019-01-16 08:34:59.456763: step 1327, loss = 0.73071 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:35:00.419026 ops/training.py:65 2019-01-16 08:35:00.418971: step 1328, loss = 0.68266 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:35:01.380588 ops/training.py:65 2019-01-16 08:35:01.380536: step 1329, loss = 0.75983 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:35:02.342055 ops/training.py:65 2019-01-16 08:35:02.342003: step 1330, loss = 0.69116 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:35:03.304862 ops/training.py:65 2019-01-16 08:35:03.304807: step 1331, loss = 0.65376 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:35:04.266312 ops/training.py:65 2019-01-16 08:35:04.266254: step 1332, loss = 0.76450 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:35:05.227396 ops/training.py:65 2019-01-16 08:35:05.227335: step 1333, loss = 0.71351 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:35:06.189594 ops/training.py:65 2019-01-16 08:35:06.189540: step 1334, loss = 0.66707 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:35:07.151716 ops/training.py:65 2019-01-16 08:35:07.151661: step 1335, loss = 0.88454 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 08:35:08.114100 ops/training.py:65 2019-01-16 08:35:08.114037: step 1336, loss = 0.63952 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:35:09.075695 ops/training.py:65 2019-01-16 08:35:09.075640: step 1337, loss = 0.75662 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:35:10.036207 ops/training.py:65 2019-01-16 08:35:10.036152: step 1338, loss = 0.75983 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:35:10.999426 ops/training.py:65 2019-01-16 08:35:10.999365: step 1339, loss = 0.72287 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:35:11.961930 ops/training.py:65 2019-01-16 08:35:11.961868: step 1340, loss = 0.76317 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:35:12.923814 ops/training.py:65 2019-01-16 08:35:12.923756: step 1341, loss = 0.72233 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:35:13.885508 ops/training.py:65 2019-01-16 08:35:13.885445: step 1342, loss = 0.79494 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:35:14.846229 ops/training.py:65 2019-01-16 08:35:14.846164: step 1343, loss = 0.78015 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:35:15.811609 ops/training.py:65 2019-01-16 08:35:15.811553: step 1344, loss = 0.72248 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:35:16.775035 ops/training.py:65 2019-01-16 08:35:16.774977: step 1345, loss = 0.69375 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:35:17.736388 ops/training.py:65 2019-01-16 08:35:17.736330: step 1346, loss = 0.72217 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:35:18.697095 ops/training.py:65 2019-01-16 08:35:18.697035: step 1347, loss = 0.74168 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:35:19.658220 ops/training.py:65 2019-01-16 08:35:19.658149: step 1348, loss = 0.83246 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:35:20.622804 ops/training.py:65 2019-01-16 08:35:20.622747: step 1349, loss = 0.66651 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:35:21.586739 ops/training.py:65 2019-01-16 08:35:21.586682: step 1350, loss = 0.75920 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:35:22.548494 ops/training.py:65 2019-01-16 08:35:22.548440: step 1351, loss = 0.71623 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:35:23.511394 ops/training.py:65 2019-01-16 08:35:23.511341: step 1352, loss = 0.73869 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:35:24.473876 ops/training.py:65 2019-01-16 08:35:24.473822: step 1353, loss = 0.74021 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:35:25.435589 ops/training.py:65 2019-01-16 08:35:25.435530: step 1354, loss = 0.65885 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:35:26.397786 ops/training.py:65 2019-01-16 08:35:26.397735: step 1355, loss = 0.82779 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:35:27.359057 ops/training.py:65 2019-01-16 08:35:27.358999: step 1356, loss = 0.67925 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:35:28.321061 ops/training.py:65 2019-01-16 08:35:28.320990: step 1357, loss = 0.67651 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:35:29.283215 ops/training.py:65 2019-01-16 08:35:29.283138: step 1358, loss = 0.80269 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:35:30.245253 ops/training.py:65 2019-01-16 08:35:30.245200: step 1359, loss = 0.72572 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:35:31.208364 ops/training.py:65 2019-01-16 08:35:31.208314: step 1360, loss = 0.73423 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:35:32.170904 ops/training.py:65 2019-01-16 08:35:32.170847: step 1361, loss = 0.75333 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:35:33.133002 ops/training.py:65 2019-01-16 08:35:33.132939: step 1362, loss = 0.70241 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:35:34.095770 ops/training.py:65 2019-01-16 08:35:34.095706: step 1363, loss = 0.77017 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:35:35.057401 ops/training.py:65 2019-01-16 08:35:35.057342: step 1364, loss = 0.72825 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:35:36.019173 ops/training.py:65 2019-01-16 08:35:36.019118: step 1365, loss = 0.68288 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:35:36.981031 ops/training.py:65 2019-01-16 08:35:36.980972: step 1366, loss = 0.79160 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:35:37.942847 ops/training.py:65 2019-01-16 08:35:37.942790: step 1367, loss = 0.68160 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:35:38.902767 ops/training.py:65 2019-01-16 08:35:38.902707: step 1368, loss = 0.68992 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:35:39.863129 ops/training.py:65 2019-01-16 08:35:39.863067: step 1369, loss = 0.68674 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:35:40.823784 ops/training.py:65 2019-01-16 08:35:40.823726: step 1370, loss = 0.69622 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:35:41.787041 ops/training.py:65 2019-01-16 08:35:41.786981: step 1371, loss = 0.76411 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:35:42.748334 ops/training.py:65 2019-01-16 08:35:42.748277: step 1372, loss = 0.79574 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:35:43.712646 ops/training.py:65 2019-01-16 08:35:43.712589: step 1373, loss = 0.81612 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:35:44.673733 ops/training.py:65 2019-01-16 08:35:44.673678: step 1374, loss = 0.77028 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:35:45.633935 ops/training.py:65 2019-01-16 08:35:45.633892: step 1375, loss = 0.74788 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:35:46.594977 ops/training.py:65 2019-01-16 08:35:46.594936: step 1376, loss = 0.70722 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:35:47.560373 ops/training.py:65 2019-01-16 08:35:47.560329: step 1377, loss = 0.71762 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:35:48.523786 ops/training.py:65 2019-01-16 08:35:48.523746: step 1378, loss = 0.69929 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:35:49.485800 ops/training.py:65 2019-01-16 08:35:49.485758: step 1379, loss = 0.73898 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:35:50.447430 ops/training.py:65 2019-01-16 08:35:50.447383: step 1380, loss = 0.79261 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:35:51.409420 ops/training.py:65 2019-01-16 08:35:51.409373: step 1381, loss = 0.74267 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:35:52.371824 ops/training.py:65 2019-01-16 08:35:52.371778: step 1382, loss = 0.67450 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:35:53.334080 ops/training.py:65 2019-01-16 08:35:53.334033: step 1383, loss = 0.72008 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:35:54.295658 ops/training.py:65 2019-01-16 08:35:54.295610: step 1384, loss = 0.73102 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:35:55.258323 ops/training.py:65 2019-01-16 08:35:55.258278: step 1385, loss = 0.71157 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:35:56.220455 ops/training.py:65 2019-01-16 08:35:56.220397: step 1386, loss = 0.73233 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:35:57.180716 ops/training.py:65 2019-01-16 08:35:57.180664: step 1387, loss = 0.73838 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:35:58.140911 ops/training.py:65 2019-01-16 08:35:58.140851: step 1388, loss = 0.74633 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:35:59.100727 ops/training.py:65 2019-01-16 08:35:59.100669: step 1389, loss = 0.73023 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:36:00.060665 ops/training.py:65 2019-01-16 08:36:00.060610: step 1390, loss = 0.75072 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:36:01.020906 ops/training.py:65 2019-01-16 08:36:01.020868: step 1391, loss = 0.66093 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:36:01.983462 ops/training.py:65 2019-01-16 08:36:01.983426: step 1392, loss = 0.69270 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:36:02.945302 ops/training.py:65 2019-01-16 08:36:02.945266: step 1393, loss = 0.69753 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:36:03.908566 ops/training.py:65 2019-01-16 08:36:03.908527: step 1394, loss = 0.69960 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:36:04.871280 ops/training.py:65 2019-01-16 08:36:04.871243: step 1395, loss = 0.66909 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:36:05.833323 ops/training.py:65 2019-01-16 08:36:05.833281: step 1396, loss = 0.65516 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:36:06.795914 ops/training.py:65 2019-01-16 08:36:06.795869: step 1397, loss = 0.70179 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:36:07.757739 ops/training.py:65 2019-01-16 08:36:07.757694: step 1398, loss = 0.68822 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:36:08.723558 ops/training.py:65 2019-01-16 08:36:08.723513: step 1399, loss = 0.71344 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:36:09.686055 ops/training.py:65 2019-01-16 08:36:09.686005: step 1400, loss = 0.69758 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:36:10.648932 ops/training.py:65 2019-01-16 08:36:10.648872: step 1401, loss = 0.74895 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:36:11.610586 ops/training.py:65 2019-01-16 08:36:11.610516: step 1402, loss = 0.78839 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:36:12.574873 ops/training.py:65 2019-01-16 08:36:12.574817: step 1403, loss = 0.72921 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:36:13.539350 ops/training.py:65 2019-01-16 08:36:13.539294: step 1404, loss = 0.76464 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:36:14.502731 ops/training.py:65 2019-01-16 08:36:14.502670: step 1405, loss = 0.70619 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:36:15.464660 ops/training.py:65 2019-01-16 08:36:15.464587: step 1406, loss = 0.71372 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:36:16.427057 ops/training.py:65 2019-01-16 08:36:16.427002: step 1407, loss = 0.74471 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:36:17.386973 ops/training.py:65 2019-01-16 08:36:17.386917: step 1408, loss = 0.71797 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:36:18.351089 ops/training.py:65 2019-01-16 08:36:18.351046: step 1409, loss = 0.77512 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:36:19.313586 ops/training.py:65 2019-01-16 08:36:19.313538: step 1410, loss = 0.68180 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:36:20.275491 ops/training.py:65 2019-01-16 08:36:20.275449: step 1411, loss = 0.73103 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:36:21.239782 ops/training.py:65 2019-01-16 08:36:21.239733: step 1412, loss = 0.70615 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:36:22.202979 ops/training.py:65 2019-01-16 08:36:22.202936: step 1413, loss = 0.70718 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:36:23.165051 ops/training.py:65 2019-01-16 08:36:23.165004: step 1414, loss = 0.71928 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:36:24.125746 ops/training.py:65 2019-01-16 08:36:24.125701: step 1415, loss = 0.73212 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:36:25.086937 ops/training.py:65 2019-01-16 08:36:25.086894: step 1416, loss = 0.71271 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:36:26.050793 ops/training.py:65 2019-01-16 08:36:26.050738: step 1417, loss = 0.72644 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:36:27.013494 ops/training.py:65 2019-01-16 08:36:27.013450: step 1418, loss = 0.74466 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:36:27.976289 ops/training.py:65 2019-01-16 08:36:27.976247: step 1419, loss = 0.77157 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:36:28.939145 ops/training.py:65 2019-01-16 08:36:28.939101: step 1420, loss = 0.66183 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:36:29.901202 ops/training.py:65 2019-01-16 08:36:29.901162: step 1421, loss = 0.77660 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:36:30.863166 ops/training.py:65 2019-01-16 08:36:30.863120: step 1422, loss = 0.74505 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:36:31.825596 ops/training.py:65 2019-01-16 08:36:31.825551: step 1423, loss = 0.71788 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:36:32.787461 ops/training.py:65 2019-01-16 08:36:32.787419: step 1424, loss = 0.70829 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:36:33.748794 ops/training.py:65 2019-01-16 08:36:33.748754: step 1425, loss = 0.64811 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:36:34.709956 ops/training.py:65 2019-01-16 08:36:34.709914: step 1426, loss = 0.68574 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:36:35.672246 ops/training.py:65 2019-01-16 08:36:35.672200: step 1427, loss = 0.75801 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:36:36.634379 ops/training.py:65 2019-01-16 08:36:36.634333: step 1428, loss = 0.76606 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:36:37.598828 ops/training.py:65 2019-01-16 08:36:37.598779: step 1429, loss = 0.76399 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:36:38.562615 ops/training.py:65 2019-01-16 08:36:38.562576: step 1430, loss = 0.70861 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:36:39.525458 ops/training.py:65 2019-01-16 08:36:39.525413: step 1431, loss = 0.65320 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:36:40.486753 ops/training.py:65 2019-01-16 08:36:40.486706: step 1432, loss = 0.72932 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:36:41.447299 ops/training.py:65 2019-01-16 08:36:41.447242: step 1433, loss = 0.80376 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:36:42.411405 ops/training.py:65 2019-01-16 08:36:42.411357: step 1434, loss = 0.68050 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:36:43.374176 ops/training.py:65 2019-01-16 08:36:43.374129: step 1435, loss = 0.70935 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:36:44.336937 ops/training.py:65 2019-01-16 08:36:44.336893: step 1436, loss = 0.74126 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:36:45.300667 ops/training.py:65 2019-01-16 08:36:45.300600: step 1437, loss = 0.60436 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:36:46.262159 ops/training.py:65 2019-01-16 08:36:46.262087: step 1438, loss = 0.75071 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:36:47.222900 ops/training.py:65 2019-01-16 08:36:47.222851: step 1439, loss = 0.84901 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:36:48.183631 ops/training.py:65 2019-01-16 08:36:48.183576: step 1440, loss = 0.78032 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:36:49.145415 ops/training.py:65 2019-01-16 08:36:49.145366: step 1441, loss = 0.81297 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:36:50.107452 ops/training.py:65 2019-01-16 08:36:50.107388: step 1442, loss = 0.68493 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:36:51.068551 ops/training.py:65 2019-01-16 08:36:51.068497: step 1443, loss = 0.83684 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:36:52.029679 ops/training.py:65 2019-01-16 08:36:52.029623: step 1444, loss = 0.74644 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:36:52.994695 ops/training.py:65 2019-01-16 08:36:52.994634: step 1445, loss = 0.95323 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:36:53.956502 ops/training.py:65 2019-01-16 08:36:53.956430: step 1446, loss = 0.81350 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:36:54.917289 ops/training.py:65 2019-01-16 08:36:54.917228: step 1447, loss = 0.74677 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:36:55.880656 ops/training.py:65 2019-01-16 08:36:55.880597: step 1448, loss = 0.72770 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:36:56.840660 ops/training.py:65 2019-01-16 08:36:56.840596: step 1449, loss = 0.69623 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:36:57.800683 ops/training.py:65 2019-01-16 08:36:57.800617: step 1450, loss = 0.73905 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:36:58.760635 ops/training.py:65 2019-01-16 08:36:58.760574: step 1451, loss = 0.70218 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:36:59.724201 ops/training.py:65 2019-01-16 08:36:59.724149: step 1452, loss = 0.64074 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:37:00.684072 ops/training.py:65 2019-01-16 08:37:00.684002: step 1453, loss = 0.72434 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:37:01.643573 ops/training.py:65 2019-01-16 08:37:01.643498: step 1454, loss = 0.83967 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:37:02.602916 ops/training.py:65 2019-01-16 08:37:02.602852: step 1455, loss = 0.83833 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:37:03.568050 ops/training.py:65 2019-01-16 08:37:03.568006: step 1456, loss = 0.81618 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:37:04.531334 ops/training.py:65 2019-01-16 08:37:04.531285: step 1457, loss = 0.67794 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:37:05.493737 ops/training.py:65 2019-01-16 08:37:05.493680: step 1458, loss = 0.75267 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:37:06.454295 ops/training.py:65 2019-01-16 08:37:06.454245: step 1459, loss = 0.72357 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:37:07.414129 ops/training.py:65 2019-01-16 08:37:07.414080: step 1460, loss = 0.80169 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:37:08.378386 ops/training.py:65 2019-01-16 08:37:08.378339: step 1461, loss = 0.85650 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:37:09.342880 ops/training.py:65 2019-01-16 08:37:09.342832: step 1462, loss = 0.82770 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:37:10.306052 ops/training.py:65 2019-01-16 08:37:10.306002: step 1463, loss = 0.74643 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:37:11.266409 ops/training.py:65 2019-01-16 08:37:11.266362: step 1464, loss = 0.80617 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:37:12.226984 ops/training.py:65 2019-01-16 08:37:12.226922: step 1465, loss = 0.71979 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:37:13.191304 ops/training.py:65 2019-01-16 08:37:13.191257: step 1466, loss = 0.67548 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:37:14.153136 ops/training.py:65 2019-01-16 08:37:14.153083: step 1467, loss = 0.77274 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:37:15.115944 ops/training.py:65 2019-01-16 08:37:15.115885: step 1468, loss = 0.63559 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:37:16.078230 ops/training.py:65 2019-01-16 08:37:16.078178: step 1469, loss = 0.73609 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:37:17.038875 ops/training.py:65 2019-01-16 08:37:17.038823: step 1470, loss = 0.73288 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:37:18.002750 ops/training.py:65 2019-01-16 08:37:18.002702: step 1471, loss = 0.70090 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:37:18.962300 ops/training.py:65 2019-01-16 08:37:18.962255: step 1472, loss = 0.74530 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:37:19.921361 ops/training.py:65 2019-01-16 08:37:19.921309: step 1473, loss = 0.62293 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:37:20.885509 ops/training.py:65 2019-01-16 08:37:20.885450: step 1474, loss = 0.95807 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.25
I0832 2019-01-16 08:37:21.847875 ops/training.py:65 2019-01-16 08:37:21.847805: step 1475, loss = 0.69838 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:37:22.808007 ops/training.py:65 2019-01-16 08:37:22.807946: step 1476, loss = 0.74449 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:37:23.769650 ops/training.py:65 2019-01-16 08:37:23.769598: step 1477, loss = 0.76834 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:37:24.730614 ops/training.py:65 2019-01-16 08:37:24.730566: step 1478, loss = 0.78908 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:37:25.694881 ops/training.py:65 2019-01-16 08:37:25.694840: step 1479, loss = 0.70003 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:37:26.657390 ops/training.py:65 2019-01-16 08:37:26.657342: step 1480, loss = 0.76027 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:37:27.621337 ops/training.py:65 2019-01-16 08:37:27.621291: step 1481, loss = 0.64867 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:37:28.583850 ops/training.py:65 2019-01-16 08:37:28.583800: step 1482, loss = 0.79161 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:37:29.545927 ops/training.py:65 2019-01-16 08:37:29.545881: step 1483, loss = 0.73474 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:37:30.506831 ops/training.py:65 2019-01-16 08:37:30.506783: step 1484, loss = 0.85612 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:37:31.467423 ops/training.py:65 2019-01-16 08:37:31.467369: step 1485, loss = 0.73828 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:37:32.429863 ops/training.py:65 2019-01-16 08:37:32.429807: step 1486, loss = 0.65768 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:37:33.390413 ops/training.py:65 2019-01-16 08:37:33.390362: step 1487, loss = 0.86213 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:37:34.352595 ops/training.py:65 2019-01-16 08:37:34.352545: step 1488, loss = 0.77480 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:37:35.315868 ops/training.py:65 2019-01-16 08:37:35.315821: step 1489, loss = 0.67473 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:37:36.279118 ops/training.py:65 2019-01-16 08:37:36.279068: step 1490, loss = 0.71322 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:37:37.241636 ops/training.py:65 2019-01-16 08:37:37.241588: step 1491, loss = 0.78105 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:37:38.203983 ops/training.py:65 2019-01-16 08:37:38.203932: step 1492, loss = 0.70528 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:37:39.166889 ops/training.py:65 2019-01-16 08:37:39.166839: step 1493, loss = 0.84755 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:37:40.128746 ops/training.py:65 2019-01-16 08:37:40.128701: step 1494, loss = 0.73837 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:37:41.091319 ops/training.py:65 2019-01-16 08:37:41.091272: step 1495, loss = 0.71628 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:37:42.053921 ops/training.py:65 2019-01-16 08:37:42.053879: step 1496, loss = 0.74244 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:37:43.015645 ops/training.py:65 2019-01-16 08:37:43.015589: step 1497, loss = 0.76033 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:37:43.978174 ops/training.py:65 2019-01-16 08:37:43.978115: step 1498, loss = 0.74299 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:37:44.939581 ops/training.py:65 2019-01-16 08:37:44.939535: step 1499, loss = 0.79264 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:37:45.900718 ops/training.py:65 2019-01-16 08:37:45.900669: step 1500, loss = 0.72426 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:37:46.861764 ops/training.py:65 2019-01-16 08:37:46.861717: step 1501, loss = 0.75520 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:37:47.823855 ops/training.py:65 2019-01-16 08:37:47.823809: step 1502, loss = 0.83287 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:37:48.787255 ops/training.py:65 2019-01-16 08:37:48.787215: step 1503, loss = 0.72193 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:37:49.750187 ops/training.py:65 2019-01-16 08:37:49.750135: step 1504, loss = 0.81276 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:37:50.713582 ops/training.py:65 2019-01-16 08:37:50.713539: step 1505, loss = 0.74709 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:37:51.675444 ops/training.py:65 2019-01-16 08:37:51.675396: step 1506, loss = 0.78175 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:37:52.638513 ops/training.py:65 2019-01-16 08:37:52.638467: step 1507, loss = 0.74505 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:37:53.600276 ops/training.py:65 2019-01-16 08:37:53.600205: step 1508, loss = 0.76163 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:37:54.562474 ops/training.py:65 2019-01-16 08:37:54.562427: step 1509, loss = 0.84421 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:37:55.523858 ops/training.py:65 2019-01-16 08:37:55.523804: step 1510, loss = 0.69627 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:37:56.488351 ops/training.py:65 2019-01-16 08:37:56.488297: step 1511, loss = 0.76224 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:37:57.451192 ops/training.py:65 2019-01-16 08:37:57.451144: step 1512, loss = 0.75197 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:37:58.412386 ops/training.py:65 2019-01-16 08:37:58.412319: step 1513, loss = 0.74737 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:37:59.373186 ops/training.py:65 2019-01-16 08:37:59.373107: step 1514, loss = 0.73546 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:38:00.333349 ops/training.py:65 2019-01-16 08:38:00.333283: step 1515, loss = 0.71024 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:38:01.292262 ops/training.py:65 2019-01-16 08:38:01.292212: step 1516, loss = 0.72128 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:38:02.252598 ops/training.py:65 2019-01-16 08:38:02.252542: step 1517, loss = 0.75181 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:38:03.212335 ops/training.py:65 2019-01-16 08:38:03.212280: step 1518, loss = 0.70572 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:38:04.170352 ops/training.py:65 2019-01-16 08:38:04.170284: step 1519, loss = 0.69558 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:38:05.128781 ops/training.py:65 2019-01-16 08:38:05.128694: step 1520, loss = 0.71936 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:38:06.090729 ops/training.py:65 2019-01-16 08:38:06.090674: step 1521, loss = 0.79372 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:38:07.052420 ops/training.py:65 2019-01-16 08:38:07.052370: step 1522, loss = 0.74490 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:38:08.018643 ops/training.py:65 2019-01-16 08:38:08.018574: step 1523, loss = 0.73199 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:38:08.979876 ops/training.py:65 2019-01-16 08:38:08.979808: step 1524, loss = 0.65485 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:38:09.940512 ops/training.py:65 2019-01-16 08:38:09.940462: step 1525, loss = 0.69854 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:38:10.899768 ops/training.py:65 2019-01-16 08:38:10.899718: step 1526, loss = 0.60431 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 08:38:11.863728 ops/training.py:65 2019-01-16 08:38:11.863680: step 1527, loss = 0.63098 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:38:12.824396 ops/training.py:65 2019-01-16 08:38:12.824348: step 1528, loss = 0.71504 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:38:13.785399 ops/training.py:65 2019-01-16 08:38:13.785343: step 1529, loss = 0.68824 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:38:14.745598 ops/training.py:65 2019-01-16 08:38:14.745540: step 1530, loss = 0.70276 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:38:15.710851 ops/training.py:65 2019-01-16 08:38:15.710799: step 1531, loss = 0.68183 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:38:16.672401 ops/training.py:65 2019-01-16 08:38:16.672347: step 1532, loss = 0.72122 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:38:17.636221 ops/training.py:65 2019-01-16 08:38:17.636170: step 1533, loss = 0.77474 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:38:18.597373 ops/training.py:65 2019-01-16 08:38:18.597315: step 1534, loss = 0.79479 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:38:19.560404 ops/training.py:65 2019-01-16 08:38:19.560345: step 1535, loss = 0.73158 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:38:20.521973 ops/training.py:65 2019-01-16 08:38:20.521898: step 1536, loss = 0.70613 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:38:21.482248 ops/training.py:65 2019-01-16 08:38:21.482169: step 1537, loss = 0.79913 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:38:22.441661 ops/training.py:65 2019-01-16 08:38:22.441615: step 1538, loss = 0.63233 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:38:23.399814 ops/training.py:65 2019-01-16 08:38:23.399759: step 1539, loss = 0.86435 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:38:24.359487 ops/training.py:65 2019-01-16 08:38:24.359430: step 1540, loss = 0.75681 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:38:25.317546 ops/training.py:65 2019-01-16 08:38:25.317496: step 1541, loss = 0.69465 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:38:26.280450 ops/training.py:65 2019-01-16 08:38:26.280392: step 1542, loss = 0.71260 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:38:27.243409 ops/training.py:65 2019-01-16 08:38:27.243349: step 1543, loss = 0.69549 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:38:28.205770 ops/training.py:65 2019-01-16 08:38:28.205716: step 1544, loss = 0.75317 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:38:29.165929 ops/training.py:65 2019-01-16 08:38:29.165874: step 1545, loss = 0.70116 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:38:30.126308 ops/training.py:65 2019-01-16 08:38:30.126253: step 1546, loss = 0.69860 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:38:31.089437 ops/training.py:65 2019-01-16 08:38:31.089384: step 1547, loss = 0.74619 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:38:32.052656 ops/training.py:65 2019-01-16 08:38:32.052606: step 1548, loss = 0.75516 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:38:33.013160 ops/training.py:65 2019-01-16 08:38:33.013103: step 1549, loss = 0.68565 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:38:33.972622 ops/training.py:65 2019-01-16 08:38:33.972565: step 1550, loss = 0.75975 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:38:34.936534 ops/training.py:65 2019-01-16 08:38:34.936480: step 1551, loss = 0.81779 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:38:35.899939 ops/training.py:65 2019-01-16 08:38:35.899875: step 1552, loss = 0.70274 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:38:36.860795 ops/training.py:65 2019-01-16 08:38:36.860714: step 1553, loss = 0.72031 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:38:37.826902 ops/training.py:65 2019-01-16 08:38:37.826842: step 1554, loss = 0.73114 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:38:38.787625 ops/training.py:65 2019-01-16 08:38:38.787565: step 1555, loss = 0.71030 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:38:39.748151 ops/training.py:65 2019-01-16 08:38:39.748080: step 1556, loss = 0.74660 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:38:40.706108 ops/training.py:65 2019-01-16 08:38:40.706043: step 1557, loss = 0.66213 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:38:41.667956 ops/training.py:65 2019-01-16 08:38:41.667904: step 1558, loss = 0.69922 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:38:42.630368 ops/training.py:65 2019-01-16 08:38:42.630303: step 1559, loss = 0.80304 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:38:43.592370 ops/training.py:65 2019-01-16 08:38:43.592303: step 1560, loss = 0.70869 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:38:44.556113 ops/training.py:65 2019-01-16 08:38:44.556047: step 1561, loss = 0.73747 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:38:45.516644 ops/training.py:65 2019-01-16 08:38:45.516586: step 1562, loss = 0.74901 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:38:46.476742 ops/training.py:65 2019-01-16 08:38:46.476684: step 1563, loss = 0.69041 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:38:47.436989 ops/training.py:65 2019-01-16 08:38:47.436920: step 1564, loss = 0.67485 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:38:48.397205 ops/training.py:65 2019-01-16 08:38:48.397151: step 1565, loss = 0.82017 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:38:49.357189 ops/training.py:65 2019-01-16 08:38:49.357133: step 1566, loss = 0.69752 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:38:50.322048 ops/training.py:65 2019-01-16 08:38:50.321998: step 1567, loss = 0.66081 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:38:51.283912 ops/training.py:65 2019-01-16 08:38:51.283854: step 1568, loss = 0.70678 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:38:52.245133 ops/training.py:65 2019-01-16 08:38:52.245055: step 1569, loss = 0.64746 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:38:53.210216 ops/training.py:65 2019-01-16 08:38:53.210157: step 1570, loss = 0.67863 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:38:54.172760 ops/training.py:65 2019-01-16 08:38:54.172714: step 1571, loss = 0.72129 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:38:55.134512 ops/training.py:65 2019-01-16 08:38:55.134431: step 1572, loss = 0.68820 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:38:56.097611 ops/training.py:65 2019-01-16 08:38:56.097550: step 1573, loss = 0.75145 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:38:57.059613 ops/training.py:65 2019-01-16 08:38:57.059561: step 1574, loss = 0.69125 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:38:58.021166 ops/training.py:65 2019-01-16 08:38:58.021122: step 1575, loss = 0.74317 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:38:58.981937 ops/training.py:65 2019-01-16 08:38:58.981881: step 1576, loss = 0.70962 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:38:59.947346 ops/training.py:65 2019-01-16 08:38:59.947296: step 1577, loss = 0.73593 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:39:00.912230 ops/training.py:65 2019-01-16 08:39:00.912180: step 1578, loss = 0.66579 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:39:01.877119 ops/training.py:65 2019-01-16 08:39:01.877074: step 1579, loss = 0.75043 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:39:02.839211 ops/training.py:65 2019-01-16 08:39:02.839166: step 1580, loss = 0.62541 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 08:39:03.800867 ops/training.py:65 2019-01-16 08:39:03.800806: step 1581, loss = 0.72918 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:39:04.761574 ops/training.py:65 2019-01-16 08:39:04.761504: step 1582, loss = 0.76672 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:39:05.726345 ops/training.py:65 2019-01-16 08:39:05.726295: step 1583, loss = 0.75149 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:39:06.686940 ops/training.py:65 2019-01-16 08:39:06.686886: step 1584, loss = 0.70584 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:39:07.647238 ops/training.py:65 2019-01-16 08:39:07.647183: step 1585, loss = 0.77821 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:39:08.607685 ops/training.py:65 2019-01-16 08:39:08.607626: step 1586, loss = 0.78988 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:39:09.567901 ops/training.py:65 2019-01-16 08:39:09.567844: step 1587, loss = 0.66112 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:39:10.530706 ops/training.py:65 2019-01-16 08:39:10.530659: step 1588, loss = 0.74652 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:39:11.492549 ops/training.py:65 2019-01-16 08:39:11.492498: step 1589, loss = 0.70648 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:39:12.456072 ops/training.py:65 2019-01-16 08:39:12.456014: step 1590, loss = 0.70996 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:39:13.418176 ops/training.py:65 2019-01-16 08:39:13.418109: step 1591, loss = 0.73120 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:39:14.379792 ops/training.py:65 2019-01-16 08:39:14.379716: step 1592, loss = 0.73528 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:39:15.339645 ops/training.py:65 2019-01-16 08:39:15.339570: step 1593, loss = 0.70324 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:39:16.300011 ops/training.py:65 2019-01-16 08:39:16.299934: step 1594, loss = 0.68360 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:39:17.262256 ops/training.py:65 2019-01-16 08:39:17.262210: step 1595, loss = 0.73884 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:39:18.223905 ops/training.py:65 2019-01-16 08:39:18.223853: step 1596, loss = 0.67234 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:39:19.184904 ops/training.py:65 2019-01-16 08:39:19.184833: step 1597, loss = 0.67594 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:39:20.145565 ops/training.py:65 2019-01-16 08:39:20.145499: step 1598, loss = 0.78370 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:39:21.104349 ops/training.py:65 2019-01-16 08:39:21.104277: step 1599, loss = 0.79421 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:39:22.062266 ops/training.py:65 2019-01-16 08:39:22.062201: step 1600, loss = 0.78997 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 08:39:23.020166 ops/training.py:65 2019-01-16 08:39:23.020122: step 1601, loss = 0.66233 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:39:23.977969 ops/training.py:65 2019-01-16 08:39:23.977907: step 1602, loss = 0.75432 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:39:24.935827 ops/training.py:65 2019-01-16 08:39:24.935771: step 1603, loss = 0.78846 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:39:25.894115 ops/training.py:65 2019-01-16 08:39:25.894041: step 1604, loss = 0.79272 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:39:26.853938 ops/training.py:65 2019-01-16 08:39:26.853870: step 1605, loss = 0.75114 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:39:27.819071 ops/training.py:65 2019-01-16 08:39:27.819019: step 1606, loss = 0.71321 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:39:28.782663 ops/training.py:65 2019-01-16 08:39:28.782620: step 1607, loss = 0.74809 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:39:29.743462 ops/training.py:65 2019-01-16 08:39:29.743407: step 1608, loss = 0.73545 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:39:30.703972 ops/training.py:65 2019-01-16 08:39:30.703897: step 1609, loss = 0.83539 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:39:31.665853 ops/training.py:65 2019-01-16 08:39:31.665795: step 1610, loss = 0.70973 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:39:32.625894 ops/training.py:65 2019-01-16 08:39:32.625829: step 1611, loss = 0.74706 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:39:33.590070 ops/training.py:65 2019-01-16 08:39:33.590021: step 1612, loss = 0.66478 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:39:34.553490 ops/training.py:65 2019-01-16 08:39:34.553436: step 1613, loss = 0.70526 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:39:35.513839 ops/training.py:65 2019-01-16 08:39:35.513779: step 1614, loss = 0.67174 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:39:36.474898 ops/training.py:65 2019-01-16 08:39:36.474844: step 1615, loss = 0.75840 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:39:37.434659 ops/training.py:65 2019-01-16 08:39:37.434592: step 1616, loss = 0.73466 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:39:38.397701 ops/training.py:65 2019-01-16 08:39:38.397650: step 1617, loss = 0.74600 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:39:39.362049 ops/training.py:65 2019-01-16 08:39:39.361999: step 1618, loss = 0.72956 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:39:40.325330 ops/training.py:65 2019-01-16 08:39:40.325282: step 1619, loss = 0.67744 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:39:41.286308 ops/training.py:65 2019-01-16 08:39:41.286256: step 1620, loss = 0.68554 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:39:42.246648 ops/training.py:65 2019-01-16 08:39:42.246584: step 1621, loss = 0.72583 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:39:43.207351 ops/training.py:65 2019-01-16 08:39:43.207284: step 1622, loss = 0.71728 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:39:44.167512 ops/training.py:65 2019-01-16 08:39:44.167458: step 1623, loss = 0.65337 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:39:45.132524 ops/training.py:65 2019-01-16 08:39:45.132475: step 1624, loss = 0.69572 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:39:46.094716 ops/training.py:65 2019-01-16 08:39:46.094659: step 1625, loss = 0.73105 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:39:47.055268 ops/training.py:65 2019-01-16 08:39:47.055218: step 1626, loss = 0.74757 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:39:48.019630 ops/training.py:65 2019-01-16 08:39:48.019577: step 1627, loss = 0.72058 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:39:48.980182 ops/training.py:65 2019-01-16 08:39:48.980107: step 1628, loss = 0.67755 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:39:49.940816 ops/training.py:65 2019-01-16 08:39:49.940723: step 1629, loss = 0.71636 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:39:50.903808 ops/training.py:65 2019-01-16 08:39:50.903753: step 1630, loss = 0.68953 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:39:51.864199 ops/training.py:65 2019-01-16 08:39:51.864121: step 1631, loss = 0.70819 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:39:52.823980 ops/training.py:65 2019-01-16 08:39:52.823910: step 1632, loss = 0.66671 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:39:53.782382 ops/training.py:65 2019-01-16 08:39:53.782331: step 1633, loss = 0.74971 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:39:54.742083 ops/training.py:65 2019-01-16 08:39:54.742038: step 1634, loss = 0.67351 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:39:55.701603 ops/training.py:65 2019-01-16 08:39:55.701535: step 1635, loss = 0.71841 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:39:56.660192 ops/training.py:65 2019-01-16 08:39:56.660096: step 1636, loss = 0.70169 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:39:57.620127 ops/training.py:65 2019-01-16 08:39:57.620043: step 1637, loss = 0.68075 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:39:58.579858 ops/training.py:65 2019-01-16 08:39:58.579806: step 1638, loss = 0.67924 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:39:59.540279 ops/training.py:65 2019-01-16 08:39:59.540226: step 1639, loss = 0.72766 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:40:00.500650 ops/training.py:65 2019-01-16 08:40:00.500585: step 1640, loss = 0.70968 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:40:01.466011 ops/training.py:65 2019-01-16 08:40:01.465962: step 1641, loss = 0.67489 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:40:02.426237 ops/training.py:65 2019-01-16 08:40:02.426180: step 1642, loss = 0.72299 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:40:03.385730 ops/training.py:65 2019-01-16 08:40:03.385670: step 1643, loss = 0.70591 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:40:04.346406 ops/training.py:65 2019-01-16 08:40:04.346330: step 1644, loss = 0.64507 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:40:05.311151 ops/training.py:65 2019-01-16 08:40:05.311086: step 1645, loss = 0.69493 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:40:06.272588 ops/training.py:65 2019-01-16 08:40:06.272533: step 1646, loss = 0.67987 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:40:07.236518 ops/training.py:65 2019-01-16 08:40:07.236446: step 1647, loss = 0.76423 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:40:08.197990 ops/training.py:65 2019-01-16 08:40:08.197905: step 1648, loss = 0.76733 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:40:09.157401 ops/training.py:65 2019-01-16 08:40:09.157335: step 1649, loss = 0.71642 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:40:10.121053 ops/training.py:65 2019-01-16 08:40:10.121005: step 1650, loss = 0.66412 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:40:11.082727 ops/training.py:65 2019-01-16 08:40:11.082644: step 1651, loss = 0.74220 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:40:12.047159 ops/training.py:65 2019-01-16 08:40:12.047093: step 1652, loss = 0.69776 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:40:13.008946 ops/training.py:65 2019-01-16 08:40:13.008892: step 1653, loss = 0.65189 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:40:13.968783 ops/training.py:65 2019-01-16 08:40:13.968734: step 1654, loss = 0.74225 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:40:14.933296 ops/training.py:65 2019-01-16 08:40:14.933239: step 1655, loss = 0.64170 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:40:15.895851 ops/training.py:65 2019-01-16 08:40:15.895795: step 1656, loss = 0.69840 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:40:16.857347 ops/training.py:65 2019-01-16 08:40:16.857272: step 1657, loss = 0.70489 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:40:17.817067 ops/training.py:65 2019-01-16 08:40:17.817013: step 1658, loss = 0.71049 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:40:18.776985 ops/training.py:65 2019-01-16 08:40:18.776924: step 1659, loss = 0.71041 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:40:19.736426 ops/training.py:65 2019-01-16 08:40:19.736374: step 1660, loss = 0.63291 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 08:40:20.696281 ops/training.py:65 2019-01-16 08:40:20.696220: step 1661, loss = 0.70283 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:40:21.655495 ops/training.py:65 2019-01-16 08:40:21.655419: step 1662, loss = 0.73239 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:40:22.613744 ops/training.py:65 2019-01-16 08:40:22.613670: step 1663, loss = 0.71901 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:40:23.577108 ops/training.py:65 2019-01-16 08:40:23.577061: step 1664, loss = 0.66249 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:40:24.537822 ops/training.py:65 2019-01-16 08:40:24.537766: step 1665, loss = 0.72141 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:40:25.498756 ops/training.py:65 2019-01-16 08:40:25.498703: step 1666, loss = 0.67392 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:40:26.459913 ops/training.py:65 2019-01-16 08:40:26.459856: step 1667, loss = 0.67714 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:40:27.420124 ops/training.py:65 2019-01-16 08:40:27.420050: step 1668, loss = 0.74380 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:40:28.380538 ops/training.py:65 2019-01-16 08:40:28.380450: step 1669, loss = 0.71567 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:40:29.340967 ops/training.py:65 2019-01-16 08:40:29.340902: step 1670, loss = 0.66378 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:40:30.299298 ops/training.py:65 2019-01-16 08:40:30.299236: step 1671, loss = 0.70986 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:40:31.258881 ops/training.py:65 2019-01-16 08:40:31.258823: step 1672, loss = 0.71888 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:40:32.218447 ops/training.py:65 2019-01-16 08:40:32.218389: step 1673, loss = 0.70256 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:40:33.182374 ops/training.py:65 2019-01-16 08:40:33.182330: step 1674, loss = 0.71675 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:40:34.144799 ops/training.py:65 2019-01-16 08:40:34.144749: step 1675, loss = 0.68363 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:40:35.107650 ops/training.py:65 2019-01-16 08:40:35.107596: step 1676, loss = 0.67733 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:40:36.067756 ops/training.py:65 2019-01-16 08:40:36.067689: step 1677, loss = 0.72852 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:40:37.027157 ops/training.py:65 2019-01-16 08:40:37.027104: step 1678, loss = 0.65628 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:40:37.986416 ops/training.py:65 2019-01-16 08:40:37.986351: step 1679, loss = 0.68840 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:40:38.944516 ops/training.py:65 2019-01-16 08:40:38.944443: step 1680, loss = 0.76251 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:40:39.908302 ops/training.py:65 2019-01-16 08:40:39.908250: step 1681, loss = 0.71640 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:40:40.871228 ops/training.py:65 2019-01-16 08:40:40.871163: step 1682, loss = 0.75588 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:40:41.833077 ops/training.py:65 2019-01-16 08:40:41.833010: step 1683, loss = 0.67661 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:40:42.794086 ops/training.py:65 2019-01-16 08:40:42.794036: step 1684, loss = 0.70892 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:40:43.754173 ops/training.py:65 2019-01-16 08:40:43.754122: step 1685, loss = 0.69047 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:40:44.712874 ops/training.py:65 2019-01-16 08:40:44.712815: step 1686, loss = 0.62110 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 08:40:45.670726 ops/training.py:65 2019-01-16 08:40:45.670683: step 1687, loss = 0.63475 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:40:46.634063 ops/training.py:65 2019-01-16 08:40:46.634008: step 1688, loss = 0.74976 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:40:47.596596 ops/training.py:65 2019-01-16 08:40:47.596548: step 1689, loss = 0.75748 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:40:48.559112 ops/training.py:65 2019-01-16 08:40:48.559063: step 1690, loss = 0.68636 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:40:49.521083 ops/training.py:65 2019-01-16 08:40:49.521034: step 1691, loss = 0.69988 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:40:50.482402 ops/training.py:65 2019-01-16 08:40:50.482355: step 1692, loss = 0.71386 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:40:51.444493 ops/training.py:65 2019-01-16 08:40:51.444439: step 1693, loss = 0.71182 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:40:52.405263 ops/training.py:65 2019-01-16 08:40:52.405211: step 1694, loss = 0.68358 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:40:53.369178 ops/training.py:65 2019-01-16 08:40:53.369126: step 1695, loss = 0.69834 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:40:54.330227 ops/training.py:65 2019-01-16 08:40:54.330174: step 1696, loss = 0.71935 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:40:55.289794 ops/training.py:65 2019-01-16 08:40:55.289726: step 1697, loss = 0.72536 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:40:56.250166 ops/training.py:65 2019-01-16 08:40:56.250110: step 1698, loss = 0.64430 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:40:57.214340 ops/training.py:65 2019-01-16 08:40:57.214289: step 1699, loss = 0.68741 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:40:58.175725 ops/training.py:65 2019-01-16 08:40:58.175684: step 1700, loss = 0.72358 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:40:59.137611 ops/training.py:65 2019-01-16 08:40:59.137561: step 1701, loss = 0.67811 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:41:00.100732 ops/training.py:65 2019-01-16 08:41:00.100690: step 1702, loss = 0.73396 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:41:01.064825 ops/training.py:65 2019-01-16 08:41:01.064778: step 1703, loss = 0.75058 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:41:02.028327 ops/training.py:65 2019-01-16 08:41:02.028283: step 1704, loss = 0.73010 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:41:02.989639 ops/training.py:65 2019-01-16 08:41:02.989587: step 1705, loss = 0.70685 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:41:03.948999 ops/training.py:65 2019-01-16 08:41:03.948940: step 1706, loss = 0.73323 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:41:04.908606 ops/training.py:65 2019-01-16 08:41:04.908556: step 1707, loss = 0.67239 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:41:05.872422 ops/training.py:65 2019-01-16 08:41:05.872372: step 1708, loss = 0.75108 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:41:06.834336 ops/training.py:65 2019-01-16 08:41:06.834278: step 1709, loss = 0.70472 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:41:07.794082 ops/training.py:65 2019-01-16 08:41:07.794011: step 1710, loss = 0.69816 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:41:08.752547 ops/training.py:65 2019-01-16 08:41:08.752476: step 1711, loss = 0.76103 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:41:09.710878 ops/training.py:65 2019-01-16 08:41:09.710820: step 1712, loss = 0.71972 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:41:10.668881 ops/training.py:65 2019-01-16 08:41:10.668819: step 1713, loss = 0.73808 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:41:11.626894 ops/training.py:65 2019-01-16 08:41:11.626845: step 1714, loss = 0.76970 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:41:12.585949 ops/training.py:65 2019-01-16 08:41:12.585896: step 1715, loss = 0.68208 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:41:13.545194 ops/training.py:65 2019-01-16 08:41:13.545130: step 1716, loss = 0.69660 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:41:14.504861 ops/training.py:65 2019-01-16 08:41:14.504804: step 1717, loss = 0.66877 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:41:15.468578 ops/training.py:65 2019-01-16 08:41:15.468528: step 1718, loss = 0.68863 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:41:16.432135 ops/training.py:65 2019-01-16 08:41:16.432092: step 1719, loss = 0.67443 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:41:17.395177 ops/training.py:65 2019-01-16 08:41:17.395128: step 1720, loss = 0.69603 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:41:18.358709 ops/training.py:65 2019-01-16 08:41:18.358658: step 1721, loss = 0.75616 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:41:19.321260 ops/training.py:65 2019-01-16 08:41:19.321216: step 1722, loss = 0.65175 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:41:20.282683 ops/training.py:65 2019-01-16 08:41:20.282632: step 1723, loss = 0.64391 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:41:21.244858 ops/training.py:65 2019-01-16 08:41:21.244807: step 1724, loss = 0.66846 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:41:22.204324 ops/training.py:65 2019-01-16 08:41:22.204266: step 1725, loss = 0.70446 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:41:23.169859 ops/training.py:65 2019-01-16 08:41:23.169810: step 1726, loss = 0.71883 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:41:24.134692 ops/training.py:65 2019-01-16 08:41:24.134647: step 1727, loss = 0.70576 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:41:25.098091 ops/training.py:65 2019-01-16 08:41:25.098036: step 1728, loss = 0.69613 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:41:26.059696 ops/training.py:65 2019-01-16 08:41:26.059637: step 1729, loss = 0.70771 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:41:27.020708 ops/training.py:65 2019-01-16 08:41:27.020640: step 1730, loss = 0.64494 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:41:27.986402 ops/training.py:65 2019-01-16 08:41:27.986354: step 1731, loss = 0.74948 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:41:28.950214 ops/training.py:65 2019-01-16 08:41:28.950168: step 1732, loss = 0.74355 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:41:29.912257 ops/training.py:65 2019-01-16 08:41:29.912203: step 1733, loss = 0.67442 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:41:30.872936 ops/training.py:65 2019-01-16 08:41:30.872860: step 1734, loss = 0.74892 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:41:31.834127 ops/training.py:65 2019-01-16 08:41:31.834054: step 1735, loss = 0.70136 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:41:32.794037 ops/training.py:65 2019-01-16 08:41:32.793960: step 1736, loss = 0.70341 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:41:33.754779 ops/training.py:65 2019-01-16 08:41:33.754715: step 1737, loss = 0.72000 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:41:34.713135 ops/training.py:65 2019-01-16 08:41:34.713081: step 1738, loss = 0.75960 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:41:35.671616 ops/training.py:65 2019-01-16 08:41:35.671556: step 1739, loss = 0.69994 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:41:36.630896 ops/training.py:65 2019-01-16 08:41:36.630848: step 1740, loss = 0.76111 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:41:37.595925 ops/training.py:65 2019-01-16 08:41:37.595881: step 1741, loss = 0.76569 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:41:38.559859 ops/training.py:65 2019-01-16 08:41:38.559819: step 1742, loss = 0.86286 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:41:39.522187 ops/training.py:65 2019-01-16 08:41:39.522137: step 1743, loss = 0.74971 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:41:40.484755 ops/training.py:65 2019-01-16 08:41:40.484710: step 1744, loss = 0.78919 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:41:41.446296 ops/training.py:65 2019-01-16 08:41:41.446236: step 1745, loss = 0.67822 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:41:42.408067 ops/training.py:65 2019-01-16 08:41:42.408010: step 1746, loss = 0.73599 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:41:43.370506 ops/training.py:65 2019-01-16 08:41:43.370456: step 1747, loss = 0.74522 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:41:44.329911 ops/training.py:65 2019-01-16 08:41:44.329819: step 1748, loss = 0.80123 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:41:45.294586 ops/training.py:65 2019-01-16 08:41:45.294519: step 1749, loss = 0.71473 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:41:46.255488 ops/training.py:65 2019-01-16 08:41:46.255398: step 1750, loss = 0.76849 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:41:47.221627 ops/training.py:65 2019-01-16 08:41:47.221564: step 1751, loss = 0.67357 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:41:48.182037 ops/training.py:65 2019-01-16 08:41:48.181981: step 1752, loss = 0.77561 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:41:49.141464 ops/training.py:65 2019-01-16 08:41:49.141404: step 1753, loss = 0.66503 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:41:50.106411 ops/training.py:65 2019-01-16 08:41:50.106365: step 1754, loss = 0.72612 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:41:51.069037 ops/training.py:65 2019-01-16 08:41:51.068992: step 1755, loss = 0.75009 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:41:52.032128 ops/training.py:65 2019-01-16 08:41:52.032081: step 1756, loss = 0.70049 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:41:52.992030 ops/training.py:65 2019-01-16 08:41:52.991976: step 1757, loss = 0.60497 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:41:53.956405 ops/training.py:65 2019-01-16 08:41:53.956359: step 1758, loss = 0.69392 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:41:54.919918 ops/training.py:65 2019-01-16 08:41:54.919878: step 1759, loss = 0.72728 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:41:55.882384 ops/training.py:65 2019-01-16 08:41:55.882339: step 1760, loss = 0.73405 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:41:56.842498 ops/training.py:65 2019-01-16 08:41:56.842428: step 1761, loss = 0.77132 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:41:57.807385 ops/training.py:65 2019-01-16 08:41:57.807325: step 1762, loss = 0.76558 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:41:58.770844 ops/training.py:65 2019-01-16 08:41:58.770804: step 1763, loss = 0.70867 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:41:59.735220 ops/training.py:65 2019-01-16 08:41:59.735167: step 1764, loss = 0.66720 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:42:00.695158 ops/training.py:65 2019-01-16 08:42:00.695070: step 1765, loss = 0.70647 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:42:01.659240 ops/training.py:65 2019-01-16 08:42:01.659182: step 1766, loss = 0.72005 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:42:02.623280 ops/training.py:65 2019-01-16 08:42:02.623236: step 1767, loss = 0.77561 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:42:03.585323 ops/training.py:65 2019-01-16 08:42:03.585277: step 1768, loss = 0.66958 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:42:04.547317 ops/training.py:65 2019-01-16 08:42:04.547270: step 1769, loss = 0.77137 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:42:05.509106 ops/training.py:65 2019-01-16 08:42:05.509059: step 1770, loss = 0.67352 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:42:06.470789 ops/training.py:65 2019-01-16 08:42:06.470737: step 1771, loss = 0.67673 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:42:07.432654 ops/training.py:65 2019-01-16 08:42:07.432608: step 1772, loss = 0.66682 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:42:08.394346 ops/training.py:65 2019-01-16 08:42:08.394293: step 1773, loss = 0.67061 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:42:09.356392 ops/training.py:65 2019-01-16 08:42:09.356341: step 1774, loss = 0.71750 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:42:10.318122 ops/training.py:65 2019-01-16 08:42:10.318066: step 1775, loss = 0.73828 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:42:11.279334 ops/training.py:65 2019-01-16 08:42:11.279296: step 1776, loss = 0.74490 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:42:12.240767 ops/training.py:65 2019-01-16 08:42:12.240712: step 1777, loss = 0.70463 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:42:13.202674 ops/training.py:65 2019-01-16 08:42:13.202626: step 1778, loss = 0.71662 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:42:14.165559 ops/training.py:65 2019-01-16 08:42:14.165517: step 1779, loss = 0.74882 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:42:15.127745 ops/training.py:65 2019-01-16 08:42:15.127704: step 1780, loss = 0.70907 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:42:16.088992 ops/training.py:65 2019-01-16 08:42:16.088948: step 1781, loss = 0.67751 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:42:17.050709 ops/training.py:65 2019-01-16 08:42:17.050657: step 1782, loss = 0.69243 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:42:18.012747 ops/training.py:65 2019-01-16 08:42:18.012692: step 1783, loss = 0.73226 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:42:18.973780 ops/training.py:65 2019-01-16 08:42:18.973733: step 1784, loss = 0.72946 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:42:19.936783 ops/training.py:65 2019-01-16 08:42:19.936741: step 1785, loss = 0.74826 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:42:20.898575 ops/training.py:65 2019-01-16 08:42:20.898531: step 1786, loss = 0.70998 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:42:21.860762 ops/training.py:65 2019-01-16 08:42:21.860716: step 1787, loss = 0.67743 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:42:22.822046 ops/training.py:65 2019-01-16 08:42:22.822006: step 1788, loss = 0.75167 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:42:23.783777 ops/training.py:65 2019-01-16 08:42:23.783737: step 1789, loss = 0.74518 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:42:24.745405 ops/training.py:65 2019-01-16 08:42:24.745364: step 1790, loss = 0.71285 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:42:25.707862 ops/training.py:65 2019-01-16 08:42:25.707822: step 1791, loss = 0.70842 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:42:26.668830 ops/training.py:65 2019-01-16 08:42:26.668779: step 1792, loss = 0.74219 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:42:27.630348 ops/training.py:65 2019-01-16 08:42:27.630305: step 1793, loss = 0.78018 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:42:28.592992 ops/training.py:65 2019-01-16 08:42:28.592951: step 1794, loss = 0.69433 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:42:29.554896 ops/training.py:65 2019-01-16 08:42:29.554855: step 1795, loss = 0.72629 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:42:30.517108 ops/training.py:65 2019-01-16 08:42:30.517066: step 1796, loss = 0.76394 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:42:31.479248 ops/training.py:65 2019-01-16 08:42:31.479195: step 1797, loss = 0.74460 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:42:32.441508 ops/training.py:65 2019-01-16 08:42:32.441459: step 1798, loss = 0.67431 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:42:33.402415 ops/training.py:65 2019-01-16 08:42:33.402376: step 1799, loss = 0.69738 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:42:34.365390 ops/training.py:65 2019-01-16 08:42:34.365346: step 1800, loss = 0.81916 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:42:35.327596 ops/training.py:65 2019-01-16 08:42:35.327556: step 1801, loss = 0.69674 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:42:36.290475 ops/training.py:65 2019-01-16 08:42:36.290434: step 1802, loss = 0.77650 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:42:37.253363 ops/training.py:65 2019-01-16 08:42:37.253308: step 1803, loss = 0.64621 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:42:38.216420 ops/training.py:65 2019-01-16 08:42:38.216369: step 1804, loss = 0.72746 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:42:39.177780 ops/training.py:65 2019-01-16 08:42:39.177743: step 1805, loss = 0.74191 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:42:40.139585 ops/training.py:65 2019-01-16 08:42:40.139541: step 1806, loss = 0.75243 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:42:41.101133 ops/training.py:65 2019-01-16 08:42:41.101093: step 1807, loss = 0.75702 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:42:42.063084 ops/training.py:65 2019-01-16 08:42:42.063044: step 1808, loss = 0.76711 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:42:43.024016 ops/training.py:65 2019-01-16 08:42:43.023964: step 1809, loss = 0.65849 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:42:43.985272 ops/training.py:65 2019-01-16 08:42:43.985222: step 1810, loss = 0.69262 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:42:44.947889 ops/training.py:65 2019-01-16 08:42:44.947847: step 1811, loss = 0.74211 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:42:45.908326 ops/training.py:65 2019-01-16 08:42:45.908286: step 1812, loss = 0.69048 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:42:46.868992 ops/training.py:65 2019-01-16 08:42:46.868951: step 1813, loss = 0.75903 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:42:47.831730 ops/training.py:65 2019-01-16 08:42:47.831685: step 1814, loss = 0.66872 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:42:48.793284 ops/training.py:65 2019-01-16 08:42:48.793244: step 1815, loss = 0.75246 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:42:49.755273 ops/training.py:65 2019-01-16 08:42:49.755231: step 1816, loss = 0.71194 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:42:50.716423 ops/training.py:65 2019-01-16 08:42:50.716380: step 1817, loss = 0.71528 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:42:51.676228 ops/training.py:65 2019-01-16 08:42:51.676152: step 1818, loss = 0.74736 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:42:52.637916 ops/training.py:65 2019-01-16 08:42:52.637848: step 1819, loss = 0.67516 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:42:53.601429 ops/training.py:65 2019-01-16 08:42:53.601369: step 1820, loss = 0.67748 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:42:54.564189 ops/training.py:65 2019-01-16 08:42:54.564142: step 1821, loss = 0.71703 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:42:55.526851 ops/training.py:65 2019-01-16 08:42:55.526803: step 1822, loss = 0.69238 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:42:56.488334 ops/training.py:65 2019-01-16 08:42:56.488276: step 1823, loss = 0.74858 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:42:57.450422 ops/training.py:65 2019-01-16 08:42:57.450378: step 1824, loss = 0.67913 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:42:58.413008 ops/training.py:65 2019-01-16 08:42:58.412961: step 1825, loss = 0.68643 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:42:59.375140 ops/training.py:65 2019-01-16 08:42:59.375097: step 1826, loss = 0.70906 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:43:00.336986 ops/training.py:65 2019-01-16 08:43:00.336941: step 1827, loss = 0.71960 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:43:01.298420 ops/training.py:65 2019-01-16 08:43:01.298374: step 1828, loss = 0.78557 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 08:43:02.259711 ops/training.py:65 2019-01-16 08:43:02.259651: step 1829, loss = 0.73973 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:43:03.222627 ops/training.py:65 2019-01-16 08:43:03.222581: step 1830, loss = 0.69703 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:43:04.184684 ops/training.py:65 2019-01-16 08:43:04.184631: step 1831, loss = 0.70159 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:43:05.147044 ops/training.py:65 2019-01-16 08:43:05.146976: step 1832, loss = 0.71193 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:43:06.109656 ops/training.py:65 2019-01-16 08:43:06.109579: step 1833, loss = 0.77303 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:43:07.070755 ops/training.py:65 2019-01-16 08:43:07.070685: step 1834, loss = 0.73313 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:43:08.029911 ops/training.py:65 2019-01-16 08:43:08.029848: step 1835, loss = 0.68748 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:43:08.989920 ops/training.py:65 2019-01-16 08:43:08.989861: step 1836, loss = 0.69513 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:43:09.952638 ops/training.py:65 2019-01-16 08:43:09.952587: step 1837, loss = 0.71320 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:43:10.915412 ops/training.py:65 2019-01-16 08:43:10.915363: step 1838, loss = 0.69951 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:43:11.878027 ops/training.py:65 2019-01-16 08:43:11.877964: step 1839, loss = 0.73549 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:43:12.838883 ops/training.py:65 2019-01-16 08:43:12.838829: step 1840, loss = 0.73705 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:43:13.798346 ops/training.py:65 2019-01-16 08:43:13.798296: step 1841, loss = 0.75519 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:43:14.756907 ops/training.py:65 2019-01-16 08:43:14.756849: step 1842, loss = 0.68246 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:43:15.721859 ops/training.py:65 2019-01-16 08:43:15.721803: step 1843, loss = 0.66674 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:43:16.682888 ops/training.py:65 2019-01-16 08:43:16.682821: step 1844, loss = 0.66519 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:43:17.647330 ops/training.py:65 2019-01-16 08:43:17.647265: step 1845, loss = 0.69511 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:43:18.607573 ops/training.py:65 2019-01-16 08:43:18.607513: step 1846, loss = 0.70601 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:43:19.568058 ops/training.py:65 2019-01-16 08:43:19.567984: step 1847, loss = 0.63024 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:43:20.532067 ops/training.py:65 2019-01-16 08:43:20.531997: step 1848, loss = 0.68774 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:43:21.495508 ops/training.py:65 2019-01-16 08:43:21.495452: step 1849, loss = 0.73405 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:43:22.455578 ops/training.py:65 2019-01-16 08:43:22.455530: step 1850, loss = 0.70458 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:43:23.416003 ops/training.py:65 2019-01-16 08:43:23.415954: step 1851, loss = 0.71772 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:43:24.377862 ops/training.py:65 2019-01-16 08:43:24.377814: step 1852, loss = 0.65298 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:43:25.339864 ops/training.py:65 2019-01-16 08:43:25.339815: step 1853, loss = 0.74787 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:43:26.301591 ops/training.py:65 2019-01-16 08:43:26.301536: step 1854, loss = 0.66270 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:43:27.262737 ops/training.py:65 2019-01-16 08:43:27.262674: step 1855, loss = 0.70251 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:43:28.224330 ops/training.py:65 2019-01-16 08:43:28.224283: step 1856, loss = 0.71050 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:43:29.185117 ops/training.py:65 2019-01-16 08:43:29.185065: step 1857, loss = 0.76264 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:43:30.145952 ops/training.py:65 2019-01-16 08:43:30.145898: step 1858, loss = 0.74490 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:43:31.106442 ops/training.py:65 2019-01-16 08:43:31.106390: step 1859, loss = 0.71137 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:43:32.067362 ops/training.py:65 2019-01-16 08:43:32.067306: step 1860, loss = 0.69868 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:43:33.028815 ops/training.py:65 2019-01-16 08:43:33.028765: step 1861, loss = 0.71792 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:43:33.989716 ops/training.py:65 2019-01-16 08:43:33.989670: step 1862, loss = 0.71290 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:43:34.949936 ops/training.py:65 2019-01-16 08:43:34.949880: step 1863, loss = 0.75852 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:43:35.912683 ops/training.py:65 2019-01-16 08:43:35.912630: step 1864, loss = 0.64883 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:43:36.874466 ops/training.py:65 2019-01-16 08:43:36.874402: step 1865, loss = 0.68743 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:43:37.836962 ops/training.py:65 2019-01-16 08:43:37.836888: step 1866, loss = 0.70862 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:43:38.797816 ops/training.py:65 2019-01-16 08:43:38.797754: step 1867, loss = 0.62415 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:43:39.759996 ops/training.py:65 2019-01-16 08:43:39.759927: step 1868, loss = 0.72175 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:43:40.720704 ops/training.py:65 2019-01-16 08:43:40.720652: step 1869, loss = 0.65738 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:43:41.681991 ops/training.py:65 2019-01-16 08:43:41.681937: step 1870, loss = 0.79648 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:43:42.643380 ops/training.py:65 2019-01-16 08:43:42.643326: step 1871, loss = 0.67478 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:43:43.605351 ops/training.py:65 2019-01-16 08:43:43.605302: step 1872, loss = 0.70528 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:43:44.566453 ops/training.py:65 2019-01-16 08:43:44.566400: step 1873, loss = 0.73486 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:43:45.529639 ops/training.py:65 2019-01-16 08:43:45.529591: step 1874, loss = 0.77968 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 08:43:46.490938 ops/training.py:65 2019-01-16 08:43:46.490889: step 1875, loss = 0.72923 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:43:47.452198 ops/training.py:65 2019-01-16 08:43:47.452143: step 1876, loss = 0.67540 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:43:48.412763 ops/training.py:65 2019-01-16 08:43:48.412710: step 1877, loss = 0.69764 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:43:49.372204 ops/training.py:65 2019-01-16 08:43:49.372142: step 1878, loss = 0.73941 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:43:50.331838 ops/training.py:65 2019-01-16 08:43:50.331781: step 1879, loss = 0.72398 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:43:51.292614 ops/training.py:65 2019-01-16 08:43:51.292558: step 1880, loss = 0.71567 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:43:52.253517 ops/training.py:65 2019-01-16 08:43:52.253459: step 1881, loss = 0.66565 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:43:53.213520 ops/training.py:65 2019-01-16 08:43:53.213471: step 1882, loss = 0.72513 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:43:54.176918 ops/training.py:65 2019-01-16 08:43:54.176870: step 1883, loss = 0.70787 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:43:55.137508 ops/training.py:65 2019-01-16 08:43:55.137447: step 1884, loss = 0.69231 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:43:56.097245 ops/training.py:65 2019-01-16 08:43:56.097189: step 1885, loss = 0.68225 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:43:57.061239 ops/training.py:65 2019-01-16 08:43:57.061176: step 1886, loss = 0.72886 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:43:58.023297 ops/training.py:65 2019-01-16 08:43:58.023237: step 1887, loss = 0.70104 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:43:58.985528 ops/training.py:65 2019-01-16 08:43:58.985474: step 1888, loss = 0.69749 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:43:59.945828 ops/training.py:65 2019-01-16 08:43:59.945781: step 1889, loss = 0.75912 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:44:00.906273 ops/training.py:65 2019-01-16 08:44:00.906204: step 1890, loss = 0.72411 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:44:01.867394 ops/training.py:65 2019-01-16 08:44:01.867326: step 1891, loss = 0.72523 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:44:02.828169 ops/training.py:65 2019-01-16 08:44:02.828113: step 1892, loss = 0.73308 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:44:03.787141 ops/training.py:65 2019-01-16 08:44:03.787053: step 1893, loss = 0.72366 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:44:04.746284 ops/training.py:65 2019-01-16 08:44:04.746213: step 1894, loss = 0.73681 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:44:05.708753 ops/training.py:65 2019-01-16 08:44:05.708711: step 1895, loss = 0.69731 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:44:06.670970 ops/training.py:65 2019-01-16 08:44:06.670921: step 1896, loss = 0.71217 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:44:07.633862 ops/training.py:65 2019-01-16 08:44:07.633810: step 1897, loss = 0.69216 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:44:08.594413 ops/training.py:65 2019-01-16 08:44:08.594356: step 1898, loss = 0.77215 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:44:09.558555 ops/training.py:65 2019-01-16 08:44:09.558507: step 1899, loss = 0.68249 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:44:10.521636 ops/training.py:65 2019-01-16 08:44:10.521588: step 1900, loss = 0.73493 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:44:11.483056 ops/training.py:65 2019-01-16 08:44:11.483002: step 1901, loss = 0.67854 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:44:12.445490 ops/training.py:65 2019-01-16 08:44:12.445438: step 1902, loss = 0.74147 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:44:13.409026 ops/training.py:65 2019-01-16 08:44:13.408980: step 1903, loss = 0.74977 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:44:14.372608 ops/training.py:65 2019-01-16 08:44:14.372557: step 1904, loss = 0.77353 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:44:15.335004 ops/training.py:65 2019-01-16 08:44:15.334958: step 1905, loss = 0.69489 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:44:16.297519 ops/training.py:65 2019-01-16 08:44:16.297469: step 1906, loss = 0.69248 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:44:17.258613 ops/training.py:65 2019-01-16 08:44:17.258541: step 1907, loss = 0.68517 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:44:18.220041 ops/training.py:65 2019-01-16 08:44:18.219969: step 1908, loss = 0.66525 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:44:19.182007 ops/training.py:65 2019-01-16 08:44:19.181939: step 1909, loss = 0.70765 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:44:20.147265 ops/training.py:65 2019-01-16 08:44:20.147194: step 1910, loss = 0.72120 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:44:21.109377 ops/training.py:65 2019-01-16 08:44:21.109305: step 1911, loss = 0.73895 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:44:22.073251 ops/training.py:65 2019-01-16 08:44:22.073203: step 1912, loss = 0.71601 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:44:23.037360 ops/training.py:65 2019-01-16 08:44:23.037313: step 1913, loss = 0.71874 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:44:24.000187 ops/training.py:65 2019-01-16 08:44:24.000139: step 1914, loss = 0.69697 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:44:24.962183 ops/training.py:65 2019-01-16 08:44:24.962119: step 1915, loss = 0.70855 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:44:25.924916 ops/training.py:65 2019-01-16 08:44:25.924869: step 1916, loss = 0.67791 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:44:26.886448 ops/training.py:65 2019-01-16 08:44:26.886382: step 1917, loss = 0.67207 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:44:27.847841 ops/training.py:65 2019-01-16 08:44:27.847772: step 1918, loss = 0.71080 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:44:28.809713 ops/training.py:65 2019-01-16 08:44:28.809645: step 1919, loss = 0.72089 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:44:29.770617 ops/training.py:65 2019-01-16 08:44:29.770544: step 1920, loss = 0.71535 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:44:30.730670 ops/training.py:65 2019-01-16 08:44:30.730603: step 1921, loss = 0.72563 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:44:31.689059 ops/training.py:65 2019-01-16 08:44:31.688994: step 1922, loss = 0.75123 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:44:32.651276 ops/training.py:65 2019-01-16 08:44:32.651230: step 1923, loss = 0.70358 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:44:33.614861 ops/training.py:65 2019-01-16 08:44:33.614809: step 1924, loss = 0.67880 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:44:34.577411 ops/training.py:65 2019-01-16 08:44:34.577364: step 1925, loss = 0.68026 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:44:35.538512 ops/training.py:65 2019-01-16 08:44:35.538462: step 1926, loss = 0.76642 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:44:36.499744 ops/training.py:65 2019-01-16 08:44:36.499691: step 1927, loss = 0.71384 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:44:37.463553 ops/training.py:65 2019-01-16 08:44:37.463507: step 1928, loss = 0.67766 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:44:38.424609 ops/training.py:65 2019-01-16 08:44:38.424561: step 1929, loss = 0.66810 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:44:39.385761 ops/training.py:65 2019-01-16 08:44:39.385710: step 1930, loss = 0.67966 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:44:40.347013 ops/training.py:65 2019-01-16 08:44:40.346962: step 1931, loss = 0.74316 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:44:41.308437 ops/training.py:65 2019-01-16 08:44:41.308385: step 1932, loss = 0.68612 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:44:42.271431 ops/training.py:65 2019-01-16 08:44:42.271377: step 1933, loss = 0.69836 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:44:43.232367 ops/training.py:65 2019-01-16 08:44:43.232311: step 1934, loss = 0.65017 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:44:44.193542 ops/training.py:65 2019-01-16 08:44:44.193493: step 1935, loss = 0.68658 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:44:45.154749 ops/training.py:65 2019-01-16 08:44:45.154698: step 1936, loss = 0.70316 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:44:46.118270 ops/training.py:65 2019-01-16 08:44:46.118222: step 1937, loss = 0.69159 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:44:47.080107 ops/training.py:65 2019-01-16 08:44:47.080062: step 1938, loss = 0.66245 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:44:48.042780 ops/training.py:65 2019-01-16 08:44:48.042732: step 1939, loss = 0.66164 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:44:49.003830 ops/training.py:65 2019-01-16 08:44:49.003781: step 1940, loss = 0.68925 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:44:49.964045 ops/training.py:65 2019-01-16 08:44:49.963991: step 1941, loss = 0.73875 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:44:50.925879 ops/training.py:65 2019-01-16 08:44:50.925829: step 1942, loss = 0.70465 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:44:51.889858 ops/training.py:65 2019-01-16 08:44:51.889810: step 1943, loss = 0.71145 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:44:52.851957 ops/training.py:65 2019-01-16 08:44:52.851905: step 1944, loss = 0.74311 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:44:53.815580 ops/training.py:65 2019-01-16 08:44:53.815532: step 1945, loss = 0.69308 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:44:54.778738 ops/training.py:65 2019-01-16 08:44:54.778693: step 1946, loss = 0.71052 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:44:55.740144 ops/training.py:65 2019-01-16 08:44:55.740072: step 1947, loss = 0.65543 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:44:56.701951 ops/training.py:65 2019-01-16 08:44:56.701881: step 1948, loss = 0.68804 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:44:57.664589 ops/training.py:65 2019-01-16 08:44:57.664508: step 1949, loss = 0.71148 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:44:58.626326 ops/training.py:65 2019-01-16 08:44:58.626258: step 1950, loss = 0.67031 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:44:59.589859 ops/training.py:65 2019-01-16 08:44:59.589792: step 1951, loss = 0.67525 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:45:00.551827 ops/training.py:65 2019-01-16 08:45:00.551762: step 1952, loss = 0.71451 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:45:01.513746 ops/training.py:65 2019-01-16 08:45:01.513676: step 1953, loss = 0.66688 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:45:02.476916 ops/training.py:65 2019-01-16 08:45:02.476858: step 1954, loss = 0.68673 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:45:03.438466 ops/training.py:65 2019-01-16 08:45:03.438409: step 1955, loss = 0.74478 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.21875
I0832 2019-01-16 08:45:04.398896 ops/training.py:65 2019-01-16 08:45:04.398831: step 1956, loss = 0.73484 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:45:05.362375 ops/training.py:65 2019-01-16 08:45:05.362305: step 1957, loss = 0.66734 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 08:45:06.323916 ops/training.py:65 2019-01-16 08:45:06.323848: step 1958, loss = 0.73290 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:45:07.284195 ops/training.py:65 2019-01-16 08:45:07.284127: step 1959, loss = 0.72887 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:45:08.245743 ops/training.py:65 2019-01-16 08:45:08.245673: step 1960, loss = 0.73944 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:45:09.206330 ops/training.py:65 2019-01-16 08:45:09.206265: step 1961, loss = 0.68775 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:45:10.167556 ops/training.py:65 2019-01-16 08:45:10.167503: step 1962, loss = 0.69036 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:45:11.127846 ops/training.py:65 2019-01-16 08:45:11.127782: step 1963, loss = 0.69617 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:45:12.087568 ops/training.py:65 2019-01-16 08:45:12.087507: step 1964, loss = 0.67717 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:45:13.047448 ops/training.py:65 2019-01-16 08:45:13.047386: step 1965, loss = 0.68518 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:45:14.011821 ops/training.py:65 2019-01-16 08:45:14.011751: step 1966, loss = 0.70073 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:45:14.973415 ops/training.py:65 2019-01-16 08:45:14.973346: step 1967, loss = 0.69689 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:45:15.933864 ops/training.py:65 2019-01-16 08:45:15.933797: step 1968, loss = 0.77288 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:45:16.895493 ops/training.py:65 2019-01-16 08:45:16.895427: step 1969, loss = 0.67559 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:45:17.855467 ops/training.py:65 2019-01-16 08:45:17.855401: step 1970, loss = 0.70277 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:45:18.815210 ops/training.py:65 2019-01-16 08:45:18.815155: step 1971, loss = 0.72320 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:45:19.775146 ops/training.py:65 2019-01-16 08:45:19.775078: step 1972, loss = 0.79416 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:45:20.738994 ops/training.py:65 2019-01-16 08:45:20.738931: step 1973, loss = 0.70420 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:45:21.700293 ops/training.py:65 2019-01-16 08:45:21.700226: step 1974, loss = 0.65825 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:45:22.660469 ops/training.py:65 2019-01-16 08:45:22.660422: step 1975, loss = 0.78147 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:45:23.620852 ops/training.py:65 2019-01-16 08:45:23.620789: step 1976, loss = 0.78838 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:45:24.585042 ops/training.py:65 2019-01-16 08:45:24.584975: step 1977, loss = 0.69699 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:45:25.546079 ops/training.py:65 2019-01-16 08:45:25.546029: step 1978, loss = 0.68409 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:45:26.509258 ops/training.py:65 2019-01-16 08:45:26.509205: step 1979, loss = 0.74980 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:45:27.471294 ops/training.py:65 2019-01-16 08:45:27.471221: step 1980, loss = 0.62885 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:45:28.432970 ops/training.py:65 2019-01-16 08:45:28.432918: step 1981, loss = 0.75032 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:45:29.396870 ops/training.py:65 2019-01-16 08:45:29.396818: step 1982, loss = 0.76234 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:45:30.357469 ops/training.py:65 2019-01-16 08:45:30.357398: step 1983, loss = 0.71855 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:45:31.321235 ops/training.py:65 2019-01-16 08:45:31.321182: step 1984, loss = 0.61226 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:45:32.284079 ops/training.py:65 2019-01-16 08:45:32.284031: step 1985, loss = 0.66960 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:45:33.246593 ops/training.py:65 2019-01-16 08:45:33.246530: step 1986, loss = 0.71139 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:45:34.207346 ops/training.py:65 2019-01-16 08:45:34.207264: step 1987, loss = 0.77101 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:45:35.171029 ops/training.py:65 2019-01-16 08:45:35.170976: step 1988, loss = 0.73149 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:45:36.133656 ops/training.py:65 2019-01-16 08:45:36.133607: step 1989, loss = 0.77627 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:45:37.096661 ops/training.py:65 2019-01-16 08:45:37.096609: step 1990, loss = 0.74807 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:45:38.059385 ops/training.py:65 2019-01-16 08:45:38.059334: step 1991, loss = 0.72733 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:45:39.020612 ops/training.py:65 2019-01-16 08:45:39.020555: step 1992, loss = 0.85926 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 08:45:39.980881 ops/training.py:65 2019-01-16 08:45:39.980818: step 1993, loss = 0.76682 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:45:40.945108 ops/training.py:65 2019-01-16 08:45:40.945049: step 1994, loss = 0.68278 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:45:41.907712 ops/training.py:65 2019-01-16 08:45:41.907649: step 1995, loss = 0.67316 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:45:42.870270 ops/training.py:65 2019-01-16 08:45:42.870206: step 1996, loss = 0.71259 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:45:43.832648 ops/training.py:65 2019-01-16 08:45:43.832584: step 1997, loss = 0.74646 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:45:44.794758 ops/training.py:65 2019-01-16 08:45:44.794694: step 1998, loss = 0.73074 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:45:45.755691 ops/training.py:65 2019-01-16 08:45:45.755635: step 1999, loss = 0.66622 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:50:24.646629 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I0832 2019-01-16 08:50:24.647555 ops/training.py:41 2019-01-16 08:50:24.647501: step 2000, loss = 0.77 (0.1 examples/sec; 277.931 sec/batch) | Training accuracy = 0.40625 | Validation accuracy = 0.50005 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_08_07_39_512188
I0832 2019-01-16 08:50:25.612221 ops/training.py:65 2019-01-16 08:50:25.612149: step 2001, loss = 0.75409 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:50:26.575867 ops/training.py:65 2019-01-16 08:50:26.575812: step 2002, loss = 0.69799 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:50:27.538872 ops/training.py:65 2019-01-16 08:50:27.538805: step 2003, loss = 0.74556 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:50:28.503068 ops/training.py:65 2019-01-16 08:50:28.503020: step 2004, loss = 0.70086 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:50:29.465368 ops/training.py:65 2019-01-16 08:50:29.465316: step 2005, loss = 0.63900 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:50:30.428315 ops/training.py:65 2019-01-16 08:50:30.428260: step 2006, loss = 0.72481 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:50:31.391024 ops/training.py:65 2019-01-16 08:50:31.390965: step 2007, loss = 0.69700 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:50:32.353659 ops/training.py:65 2019-01-16 08:50:32.353620: step 2008, loss = 0.67889 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:50:33.316743 ops/training.py:65 2019-01-16 08:50:33.316699: step 2009, loss = 0.66139 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:50:34.279499 ops/training.py:65 2019-01-16 08:50:34.279448: step 2010, loss = 0.67792 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:50:35.242237 ops/training.py:65 2019-01-16 08:50:35.242192: step 2011, loss = 0.71437 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:50:36.204505 ops/training.py:65 2019-01-16 08:50:36.204461: step 2012, loss = 0.66780 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:50:37.166722 ops/training.py:65 2019-01-16 08:50:37.166674: step 2013, loss = 0.69703 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:50:38.128773 ops/training.py:65 2019-01-16 08:50:38.128725: step 2014, loss = 0.80927 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:50:39.090939 ops/training.py:65 2019-01-16 08:50:39.090884: step 2015, loss = 0.70196 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:50:40.054007 ops/training.py:65 2019-01-16 08:50:40.053935: step 2016, loss = 0.71504 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:50:41.016284 ops/training.py:65 2019-01-16 08:50:41.016211: step 2017, loss = 0.69522 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:50:41.977061 ops/training.py:65 2019-01-16 08:50:41.976992: step 2018, loss = 0.70665 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:50:42.938441 ops/training.py:65 2019-01-16 08:50:42.938398: step 2019, loss = 0.69417 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:50:43.901886 ops/training.py:65 2019-01-16 08:50:43.901833: step 2020, loss = 0.72144 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:50:44.867022 ops/training.py:65 2019-01-16 08:50:44.866949: step 2021, loss = 0.71997 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:50:45.830904 ops/training.py:65 2019-01-16 08:50:45.830830: step 2022, loss = 0.71547 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:50:46.794120 ops/training.py:65 2019-01-16 08:50:46.794072: step 2023, loss = 0.69341 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:50:47.757633 ops/training.py:65 2019-01-16 08:50:47.757582: step 2024, loss = 0.75499 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:50:48.719870 ops/training.py:65 2019-01-16 08:50:48.719814: step 2025, loss = 0.75495 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:50:49.681732 ops/training.py:65 2019-01-16 08:50:49.681662: step 2026, loss = 0.75302 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:50:50.643760 ops/training.py:65 2019-01-16 08:50:50.643688: step 2027, loss = 0.72569 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:50:51.604910 ops/training.py:65 2019-01-16 08:50:51.604842: step 2028, loss = 0.70556 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:50:52.565702 ops/training.py:65 2019-01-16 08:50:52.565637: step 2029, loss = 0.69977 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:50:53.530429 ops/training.py:65 2019-01-16 08:50:53.530367: step 2030, loss = 0.72064 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:50:54.494781 ops/training.py:65 2019-01-16 08:50:54.494721: step 2031, loss = 0.74096 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:50:55.459013 ops/training.py:65 2019-01-16 08:50:55.458941: step 2032, loss = 0.69770 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:50:56.420816 ops/training.py:65 2019-01-16 08:50:56.420761: step 2033, loss = 0.69244 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:50:57.385130 ops/training.py:65 2019-01-16 08:50:57.385060: step 2034, loss = 0.78185 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:50:58.349828 ops/training.py:65 2019-01-16 08:50:58.349755: step 2035, loss = 0.70502 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:50:59.314012 ops/training.py:65 2019-01-16 08:50:59.313961: step 2036, loss = 0.68812 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:51:00.276867 ops/training.py:65 2019-01-16 08:51:00.276800: step 2037, loss = 0.69522 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:51:01.238613 ops/training.py:65 2019-01-16 08:51:01.238521: step 2038, loss = 0.67921 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:51:02.200388 ops/training.py:65 2019-01-16 08:51:02.200320: step 2039, loss = 0.67431 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:51:03.164326 ops/training.py:65 2019-01-16 08:51:03.164252: step 2040, loss = 0.71334 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:51:04.128315 ops/training.py:65 2019-01-16 08:51:04.128237: step 2041, loss = 0.74172 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:51:05.090737 ops/training.py:65 2019-01-16 08:51:05.090681: step 2042, loss = 0.69906 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:51:06.052168 ops/training.py:65 2019-01-16 08:51:06.052091: step 2043, loss = 0.70024 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:51:07.017404 ops/training.py:65 2019-01-16 08:51:07.017326: step 2044, loss = 0.63985 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:51:07.982264 ops/training.py:65 2019-01-16 08:51:07.982214: step 2045, loss = 0.69705 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:51:08.946649 ops/training.py:65 2019-01-16 08:51:08.946599: step 2046, loss = 0.71302 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:51:09.909334 ops/training.py:65 2019-01-16 08:51:09.909285: step 2047, loss = 0.69560 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:51:10.872216 ops/training.py:65 2019-01-16 08:51:10.872149: step 2048, loss = 0.69758 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:51:11.834305 ops/training.py:65 2019-01-16 08:51:11.834252: step 2049, loss = 0.76027 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:51:12.795522 ops/training.py:65 2019-01-16 08:51:12.795470: step 2050, loss = 0.77740 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:51:13.758525 ops/training.py:65 2019-01-16 08:51:13.758467: step 2051, loss = 0.70143 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:51:14.721076 ops/training.py:65 2019-01-16 08:51:14.721003: step 2052, loss = 0.68259 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:51:15.684358 ops/training.py:65 2019-01-16 08:51:15.684307: step 2053, loss = 0.73277 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:51:16.647511 ops/training.py:65 2019-01-16 08:51:16.647465: step 2054, loss = 0.67967 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:51:17.609441 ops/training.py:65 2019-01-16 08:51:17.609376: step 2055, loss = 0.68697 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:51:18.571948 ops/training.py:65 2019-01-16 08:51:18.571873: step 2056, loss = 0.76433 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:51:19.531917 ops/training.py:65 2019-01-16 08:51:19.531849: step 2057, loss = 0.75376 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:51:20.492043 ops/training.py:65 2019-01-16 08:51:20.491988: step 2058, loss = 0.70471 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:51:21.455196 ops/training.py:65 2019-01-16 08:51:21.455143: step 2059, loss = 0.68563 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:51:22.419005 ops/training.py:65 2019-01-16 08:51:22.418956: step 2060, loss = 0.69126 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:51:23.382900 ops/training.py:65 2019-01-16 08:51:23.382846: step 2061, loss = 0.70243 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:51:24.345303 ops/training.py:65 2019-01-16 08:51:24.345253: step 2062, loss = 0.69816 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:51:25.307263 ops/training.py:65 2019-01-16 08:51:25.307201: step 2063, loss = 0.74528 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:51:26.268337 ops/training.py:65 2019-01-16 08:51:26.268275: step 2064, loss = 0.71788 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:51:27.229071 ops/training.py:65 2019-01-16 08:51:27.229006: step 2065, loss = 0.71061 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:51:28.191425 ops/training.py:65 2019-01-16 08:51:28.191352: step 2066, loss = 0.79943 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:51:29.153756 ops/training.py:65 2019-01-16 08:51:29.153698: step 2067, loss = 0.65574 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:51:30.117557 ops/training.py:65 2019-01-16 08:51:30.117504: step 2068, loss = 0.64481 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:51:31.081423 ops/training.py:65 2019-01-16 08:51:31.081368: step 2069, loss = 0.72166 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:51:32.046202 ops/training.py:65 2019-01-16 08:51:32.046154: step 2070, loss = 0.72691 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:51:33.009417 ops/training.py:65 2019-01-16 08:51:33.009365: step 2071, loss = 0.72246 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:51:33.972028 ops/training.py:65 2019-01-16 08:51:33.971965: step 2072, loss = 0.68475 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:51:34.934246 ops/training.py:65 2019-01-16 08:51:34.934193: step 2073, loss = 0.70908 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:51:35.895265 ops/training.py:65 2019-01-16 08:51:35.895211: step 2074, loss = 0.70849 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:51:36.860201 ops/training.py:65 2019-01-16 08:51:36.860156: step 2075, loss = 0.72720 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:51:37.823765 ops/training.py:65 2019-01-16 08:51:37.823715: step 2076, loss = 0.71919 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:51:38.785760 ops/training.py:65 2019-01-16 08:51:38.785704: step 2077, loss = 0.70528 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:51:39.749597 ops/training.py:65 2019-01-16 08:51:39.749542: step 2078, loss = 0.69150 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:51:40.712578 ops/training.py:65 2019-01-16 08:51:40.712526: step 2079, loss = 0.76837 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 08:51:41.675882 ops/training.py:65 2019-01-16 08:51:41.675831: step 2080, loss = 0.72653 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:51:42.639422 ops/training.py:65 2019-01-16 08:51:42.639348: step 2081, loss = 0.67375 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:51:43.601828 ops/training.py:65 2019-01-16 08:51:43.601740: step 2082, loss = 0.70994 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:51:44.562324 ops/training.py:65 2019-01-16 08:51:44.562255: step 2083, loss = 0.75783 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:51:45.524884 ops/training.py:65 2019-01-16 08:51:45.524832: step 2084, loss = 0.73714 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 08:51:46.489314 ops/training.py:65 2019-01-16 08:51:46.489267: step 2085, loss = 0.70055 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:51:47.453764 ops/training.py:65 2019-01-16 08:51:47.453710: step 2086, loss = 0.65866 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:51:48.416147 ops/training.py:65 2019-01-16 08:51:48.416095: step 2087, loss = 0.70110 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:51:49.378360 ops/training.py:65 2019-01-16 08:51:49.378306: step 2088, loss = 0.68602 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:51:50.340442 ops/training.py:65 2019-01-16 08:51:50.340388: step 2089, loss = 0.72748 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:51:51.302487 ops/training.py:65 2019-01-16 08:51:51.302434: step 2090, loss = 0.76030 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:51:52.263199 ops/training.py:65 2019-01-16 08:51:52.263145: step 2091, loss = 0.73136 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:51:53.225284 ops/training.py:65 2019-01-16 08:51:53.225231: step 2092, loss = 0.70839 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:51:54.186493 ops/training.py:65 2019-01-16 08:51:54.186438: step 2093, loss = 0.69049 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:51:55.150048 ops/training.py:65 2019-01-16 08:51:55.149992: step 2094, loss = 0.72974 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:51:56.113643 ops/training.py:65 2019-01-16 08:51:56.113589: step 2095, loss = 0.70838 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:51:57.076903 ops/training.py:65 2019-01-16 08:51:57.076845: step 2096, loss = 0.73545 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:51:58.037674 ops/training.py:65 2019-01-16 08:51:58.037620: step 2097, loss = 0.72531 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:51:59.002017 ops/training.py:65 2019-01-16 08:51:59.001972: step 2098, loss = 0.66618 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:51:59.967422 ops/training.py:65 2019-01-16 08:51:59.967357: step 2099, loss = 0.67268 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:52:00.929934 ops/training.py:65 2019-01-16 08:52:00.929861: step 2100, loss = 0.74670 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:52:01.893042 ops/training.py:65 2019-01-16 08:52:01.892989: step 2101, loss = 0.73517 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:52:02.857544 ops/training.py:65 2019-01-16 08:52:02.857472: step 2102, loss = 0.75211 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:52:03.822031 ops/training.py:65 2019-01-16 08:52:03.821958: step 2103, loss = 0.69687 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:52:04.786207 ops/training.py:65 2019-01-16 08:52:04.786142: step 2104, loss = 0.69449 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:52:05.748819 ops/training.py:65 2019-01-16 08:52:05.748752: step 2105, loss = 0.71995 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:52:06.709938 ops/training.py:65 2019-01-16 08:52:06.709884: step 2106, loss = 0.68626 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:52:07.674813 ops/training.py:65 2019-01-16 08:52:07.674763: step 2107, loss = 0.72723 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:52:08.637662 ops/training.py:65 2019-01-16 08:52:08.637613: step 2108, loss = 0.70884 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:52:09.599363 ops/training.py:65 2019-01-16 08:52:09.599309: step 2109, loss = 0.68175 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:52:10.561748 ops/training.py:65 2019-01-16 08:52:10.561677: step 2110, loss = 0.69684 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:52:11.526219 ops/training.py:65 2019-01-16 08:52:11.526148: step 2111, loss = 0.69239 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:52:12.488312 ops/training.py:65 2019-01-16 08:52:12.488247: step 2112, loss = 0.66297 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:52:13.449516 ops/training.py:65 2019-01-16 08:52:13.449462: step 2113, loss = 0.72301 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:52:14.409916 ops/training.py:65 2019-01-16 08:52:14.409851: step 2114, loss = 0.71982 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:52:15.371365 ops/training.py:65 2019-01-16 08:52:15.371313: step 2115, loss = 0.69957 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:52:16.333270 ops/training.py:65 2019-01-16 08:52:16.333211: step 2116, loss = 0.68754 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:52:17.296429 ops/training.py:65 2019-01-16 08:52:17.296356: step 2117, loss = 0.80318 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:52:18.259345 ops/training.py:65 2019-01-16 08:52:18.259276: step 2118, loss = 0.73884 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:52:19.222998 ops/training.py:65 2019-01-16 08:52:19.222933: step 2119, loss = 0.66270 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:52:20.185107 ops/training.py:65 2019-01-16 08:52:20.185034: step 2120, loss = 0.69600 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:52:21.145609 ops/training.py:65 2019-01-16 08:52:21.145537: step 2121, loss = 0.70947 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:52:22.105945 ops/training.py:65 2019-01-16 08:52:22.105859: step 2122, loss = 0.66784 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:52:23.064860 ops/training.py:65 2019-01-16 08:52:23.064800: step 2123, loss = 0.71129 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:52:24.028687 ops/training.py:65 2019-01-16 08:52:24.028621: step 2124, loss = 0.73665 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 08:52:24.991896 ops/training.py:65 2019-01-16 08:52:24.991845: step 2125, loss = 0.68950 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:52:25.953918 ops/training.py:65 2019-01-16 08:52:25.953866: step 2126, loss = 0.69428 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:52:26.915881 ops/training.py:65 2019-01-16 08:52:26.915825: step 2127, loss = 0.70042 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:52:27.877043 ops/training.py:65 2019-01-16 08:52:27.876973: step 2128, loss = 0.69713 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:52:28.838241 ops/training.py:65 2019-01-16 08:52:28.838187: step 2129, loss = 0.70629 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:52:29.799991 ops/training.py:65 2019-01-16 08:52:29.799917: step 2130, loss = 0.70576 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:52:30.761594 ops/training.py:65 2019-01-16 08:52:30.761525: step 2131, loss = 0.71493 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:52:31.723011 ops/training.py:65 2019-01-16 08:52:31.722961: step 2132, loss = 0.72280 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:52:32.684047 ops/training.py:65 2019-01-16 08:52:32.683974: step 2133, loss = 0.72910 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:52:33.644941 ops/training.py:65 2019-01-16 08:52:33.644872: step 2134, loss = 0.76479 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:52:34.605754 ops/training.py:65 2019-01-16 08:52:34.605691: step 2135, loss = 0.69772 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:52:35.566356 ops/training.py:65 2019-01-16 08:52:35.566288: step 2136, loss = 0.72526 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:52:36.525418 ops/training.py:65 2019-01-16 08:52:36.525353: step 2137, loss = 0.71236 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:52:37.484563 ops/training.py:65 2019-01-16 08:52:37.484498: step 2138, loss = 0.70245 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:52:38.442965 ops/training.py:65 2019-01-16 08:52:38.442900: step 2139, loss = 0.73585 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:52:39.406502 ops/training.py:65 2019-01-16 08:52:39.406441: step 2140, loss = 0.67056 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:52:40.370512 ops/training.py:65 2019-01-16 08:52:40.370469: step 2141, loss = 0.77063 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:52:41.333661 ops/training.py:65 2019-01-16 08:52:41.333611: step 2142, loss = 0.67765 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:52:42.296282 ops/training.py:65 2019-01-16 08:52:42.296227: step 2143, loss = 0.70141 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:52:43.258046 ops/training.py:65 2019-01-16 08:52:43.257980: step 2144, loss = 0.71882 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:52:44.222858 ops/training.py:65 2019-01-16 08:52:44.222800: step 2145, loss = 0.74114 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:52:45.186219 ops/training.py:65 2019-01-16 08:52:45.186164: step 2146, loss = 0.69248 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:52:46.148722 ops/training.py:65 2019-01-16 08:52:46.148670: step 2147, loss = 0.70859 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:52:47.110596 ops/training.py:65 2019-01-16 08:52:47.110524: step 2148, loss = 0.71358 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:52:48.073249 ops/training.py:65 2019-01-16 08:52:48.073177: step 2149, loss = 0.70557 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:52:49.035563 ops/training.py:65 2019-01-16 08:52:49.035510: step 2150, loss = 0.68647 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:52:49.997691 ops/training.py:65 2019-01-16 08:52:49.997622: step 2151, loss = 0.70300 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:52:50.961635 ops/training.py:65 2019-01-16 08:52:50.961576: step 2152, loss = 0.65504 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:52:51.923424 ops/training.py:65 2019-01-16 08:52:51.923367: step 2153, loss = 0.67496 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:52:52.885182 ops/training.py:65 2019-01-16 08:52:52.885122: step 2154, loss = 0.69266 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:52:53.846746 ops/training.py:65 2019-01-16 08:52:53.846687: step 2155, loss = 0.72683 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:52:54.808494 ops/training.py:65 2019-01-16 08:52:54.808433: step 2156, loss = 0.72998 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:52:55.770323 ops/training.py:65 2019-01-16 08:52:55.770266: step 2157, loss = 0.74168 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:52:56.730962 ops/training.py:65 2019-01-16 08:52:56.730906: step 2158, loss = 0.69692 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:52:57.693487 ops/training.py:65 2019-01-16 08:52:57.693415: step 2159, loss = 0.70633 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:52:58.656097 ops/training.py:65 2019-01-16 08:52:58.656026: step 2160, loss = 0.67576 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:52:59.616507 ops/training.py:65 2019-01-16 08:52:59.616439: step 2161, loss = 0.67401 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:53:00.575997 ops/training.py:65 2019-01-16 08:53:00.575928: step 2162, loss = 0.69135 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:53:01.535632 ops/training.py:65 2019-01-16 08:53:01.535566: step 2163, loss = 0.66215 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:53:02.499995 ops/training.py:65 2019-01-16 08:53:02.499936: step 2164, loss = 0.68192 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:53:03.463375 ops/training.py:65 2019-01-16 08:53:03.463304: step 2165, loss = 0.67741 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:53:04.425410 ops/training.py:65 2019-01-16 08:53:04.425338: step 2166, loss = 0.70062 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:53:05.386970 ops/training.py:65 2019-01-16 08:53:05.386898: step 2167, loss = 0.71481 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:53:06.348560 ops/training.py:65 2019-01-16 08:53:06.348484: step 2168, loss = 0.78070 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:53:07.310779 ops/training.py:65 2019-01-16 08:53:07.310705: step 2169, loss = 0.69826 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:53:08.273337 ops/training.py:65 2019-01-16 08:53:08.273266: step 2170, loss = 0.72926 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:53:09.235209 ops/training.py:65 2019-01-16 08:53:09.235159: step 2171, loss = 0.69155 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:53:10.196932 ops/training.py:65 2019-01-16 08:53:10.196874: step 2172, loss = 0.73345 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:53:11.158814 ops/training.py:65 2019-01-16 08:53:11.158759: step 2173, loss = 0.68678 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:53:12.121068 ops/training.py:65 2019-01-16 08:53:12.121014: step 2174, loss = 0.77880 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:53:13.085913 ops/training.py:65 2019-01-16 08:53:13.085862: step 2175, loss = 0.70455 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:53:14.049513 ops/training.py:65 2019-01-16 08:53:14.049463: step 2176, loss = 0.67442 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:53:15.012072 ops/training.py:65 2019-01-16 08:53:15.012003: step 2177, loss = 0.68621 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:53:15.975297 ops/training.py:65 2019-01-16 08:53:15.975223: step 2178, loss = 0.66632 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:53:16.937177 ops/training.py:65 2019-01-16 08:53:16.937128: step 2179, loss = 0.70071 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:53:17.898650 ops/training.py:65 2019-01-16 08:53:17.898598: step 2180, loss = 0.71193 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:53:18.860448 ops/training.py:65 2019-01-16 08:53:18.860395: step 2181, loss = 0.65810 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:53:19.825376 ops/training.py:65 2019-01-16 08:53:19.825326: step 2182, loss = 0.67961 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:53:20.789803 ops/training.py:65 2019-01-16 08:53:20.789750: step 2183, loss = 0.73192 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:53:21.753317 ops/training.py:65 2019-01-16 08:53:21.753248: step 2184, loss = 0.72565 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:53:22.715726 ops/training.py:65 2019-01-16 08:53:22.715653: step 2185, loss = 0.70640 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:53:23.677790 ops/training.py:65 2019-01-16 08:53:23.677703: step 2186, loss = 0.72686 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:53:24.640882 ops/training.py:65 2019-01-16 08:53:24.640791: step 2187, loss = 0.73460 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:53:25.603313 ops/training.py:65 2019-01-16 08:53:25.603261: step 2188, loss = 0.75969 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:53:26.564905 ops/training.py:65 2019-01-16 08:53:26.564835: step 2189, loss = 0.68630 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:53:27.526880 ops/training.py:65 2019-01-16 08:53:27.526809: step 2190, loss = 0.67964 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:53:28.488569 ops/training.py:65 2019-01-16 08:53:28.488515: step 2191, loss = 0.66784 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:53:29.449223 ops/training.py:65 2019-01-16 08:53:29.449173: step 2192, loss = 0.64918 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 08:53:30.409894 ops/training.py:65 2019-01-16 08:53:30.409840: step 2193, loss = 0.70148 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:53:31.370749 ops/training.py:65 2019-01-16 08:53:31.370698: step 2194, loss = 0.72706 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:53:32.332621 ops/training.py:65 2019-01-16 08:53:32.332577: step 2195, loss = 0.67376 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:53:33.294291 ops/training.py:65 2019-01-16 08:53:33.294222: step 2196, loss = 0.71877 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:53:34.256306 ops/training.py:65 2019-01-16 08:53:34.256218: step 2197, loss = 0.72766 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:53:35.217596 ops/training.py:65 2019-01-16 08:53:35.217530: step 2198, loss = 0.68161 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:53:36.180503 ops/training.py:65 2019-01-16 08:53:36.180430: step 2199, loss = 0.67144 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:53:37.145235 ops/training.py:65 2019-01-16 08:53:37.145182: step 2200, loss = 0.63264 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:53:38.108707 ops/training.py:65 2019-01-16 08:53:38.108656: step 2201, loss = 0.70784 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:53:39.070792 ops/training.py:65 2019-01-16 08:53:39.070739: step 2202, loss = 0.70846 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:53:40.035265 ops/training.py:65 2019-01-16 08:53:40.035214: step 2203, loss = 0.71287 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:53:40.996629 ops/training.py:65 2019-01-16 08:53:40.996579: step 2204, loss = 0.71850 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:53:41.957434 ops/training.py:65 2019-01-16 08:53:41.957381: step 2205, loss = 0.68891 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:53:42.922650 ops/training.py:65 2019-01-16 08:53:42.922595: step 2206, loss = 0.70297 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:53:43.886651 ops/training.py:65 2019-01-16 08:53:43.886598: step 2207, loss = 0.66594 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:53:44.849068 ops/training.py:65 2019-01-16 08:53:44.849016: step 2208, loss = 0.70336 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:53:45.813274 ops/training.py:65 2019-01-16 08:53:45.813221: step 2209, loss = 0.71888 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:53:46.777087 ops/training.py:65 2019-01-16 08:53:46.777038: step 2210, loss = 0.68427 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:53:47.739168 ops/training.py:65 2019-01-16 08:53:47.739116: step 2211, loss = 0.68559 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:53:48.700538 ops/training.py:65 2019-01-16 08:53:48.700484: step 2212, loss = 0.68758 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:53:49.662077 ops/training.py:65 2019-01-16 08:53:49.662024: step 2213, loss = 0.71528 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:53:50.623602 ops/training.py:65 2019-01-16 08:53:50.623530: step 2214, loss = 0.69484 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:53:51.585296 ops/training.py:65 2019-01-16 08:53:51.585226: step 2215, loss = 0.69541 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:53:52.546986 ops/training.py:65 2019-01-16 08:53:52.546916: step 2216, loss = 0.68002 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:53:53.506890 ops/training.py:65 2019-01-16 08:53:53.506841: step 2217, loss = 0.70313 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:53:54.467792 ops/training.py:65 2019-01-16 08:53:54.467727: step 2218, loss = 0.70295 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:53:55.428578 ops/training.py:65 2019-01-16 08:53:55.428514: step 2219, loss = 0.70924 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:53:56.392257 ops/training.py:65 2019-01-16 08:53:56.392192: step 2220, loss = 0.70858 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:53:57.356214 ops/training.py:65 2019-01-16 08:53:57.356146: step 2221, loss = 0.70721 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:53:58.319099 ops/training.py:65 2019-01-16 08:53:58.319028: step 2222, loss = 0.74013 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:53:59.282184 ops/training.py:65 2019-01-16 08:53:59.282112: step 2223, loss = 0.72193 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:54:00.245336 ops/training.py:65 2019-01-16 08:54:00.245284: step 2224, loss = 0.70414 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:54:01.208946 ops/training.py:65 2019-01-16 08:54:01.208880: step 2225, loss = 0.67242 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:54:02.173256 ops/training.py:65 2019-01-16 08:54:02.173193: step 2226, loss = 0.63858 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:54:03.137888 ops/training.py:65 2019-01-16 08:54:03.137837: step 2227, loss = 0.72202 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:54:04.099926 ops/training.py:65 2019-01-16 08:54:04.099857: step 2228, loss = 0.73562 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:54:05.061236 ops/training.py:65 2019-01-16 08:54:05.061164: step 2229, loss = 0.73316 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:54:06.023543 ops/training.py:65 2019-01-16 08:54:06.023488: step 2230, loss = 0.71813 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:54:06.986601 ops/training.py:65 2019-01-16 08:54:06.986549: step 2231, loss = 0.72936 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:54:07.949091 ops/training.py:65 2019-01-16 08:54:07.949027: step 2232, loss = 0.70131 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:54:08.913959 ops/training.py:65 2019-01-16 08:54:08.913889: step 2233, loss = 0.71504 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:54:09.879117 ops/training.py:65 2019-01-16 08:54:09.879064: step 2234, loss = 0.68609 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:54:10.842616 ops/training.py:65 2019-01-16 08:54:10.842546: step 2235, loss = 0.71382 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:54:11.803878 ops/training.py:65 2019-01-16 08:54:11.803807: step 2236, loss = 0.65745 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:54:12.766977 ops/training.py:65 2019-01-16 08:54:12.766928: step 2237, loss = 0.68477 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:54:13.729180 ops/training.py:65 2019-01-16 08:54:13.729126: step 2238, loss = 0.75123 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:54:14.690995 ops/training.py:65 2019-01-16 08:54:14.690941: step 2239, loss = 0.69001 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:54:15.654911 ops/training.py:65 2019-01-16 08:54:15.654842: step 2240, loss = 0.64092 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 08:54:16.618377 ops/training.py:65 2019-01-16 08:54:16.618326: step 2241, loss = 0.71929 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:54:17.582505 ops/training.py:65 2019-01-16 08:54:17.582460: step 2242, loss = 0.69121 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:54:18.544295 ops/training.py:65 2019-01-16 08:54:18.544243: step 2243, loss = 0.64149 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:54:19.505701 ops/training.py:65 2019-01-16 08:54:19.505629: step 2244, loss = 0.68769 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:54:20.466999 ops/training.py:65 2019-01-16 08:54:20.466929: step 2245, loss = 0.69890 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:54:21.428175 ops/training.py:65 2019-01-16 08:54:21.428102: step 2246, loss = 0.69771 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:54:22.393050 ops/training.py:65 2019-01-16 08:54:22.392984: step 2247, loss = 0.77027 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:54:23.357384 ops/training.py:65 2019-01-16 08:54:23.357331: step 2248, loss = 0.70000 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:54:24.321658 ops/training.py:65 2019-01-16 08:54:24.321600: step 2249, loss = 0.71232 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:54:25.284279 ops/training.py:65 2019-01-16 08:54:25.284220: step 2250, loss = 0.70150 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:54:26.247410 ops/training.py:65 2019-01-16 08:54:26.247350: step 2251, loss = 0.74863 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:54:27.207436 ops/training.py:65 2019-01-16 08:54:27.207383: step 2252, loss = 0.68874 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:54:28.168460 ops/training.py:65 2019-01-16 08:54:28.168406: step 2253, loss = 0.73045 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:54:29.130341 ops/training.py:65 2019-01-16 08:54:29.130276: step 2254, loss = 0.72566 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:54:30.091678 ops/training.py:65 2019-01-16 08:54:30.091611: step 2255, loss = 0.71136 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:54:31.053409 ops/training.py:65 2019-01-16 08:54:31.053352: step 2256, loss = 0.68215 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:54:32.015212 ops/training.py:65 2019-01-16 08:54:32.015162: step 2257, loss = 0.76183 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:54:32.976701 ops/training.py:65 2019-01-16 08:54:32.976638: step 2258, loss = 0.69796 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:54:33.938285 ops/training.py:65 2019-01-16 08:54:33.938220: step 2259, loss = 0.73675 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:54:34.899707 ops/training.py:65 2019-01-16 08:54:34.899659: step 2260, loss = 0.71480 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:54:35.863511 ops/training.py:65 2019-01-16 08:54:35.863449: step 2261, loss = 0.69989 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:54:36.827814 ops/training.py:65 2019-01-16 08:54:36.827754: step 2262, loss = 0.77430 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.25
I0832 2019-01-16 08:54:37.791601 ops/training.py:65 2019-01-16 08:54:37.791549: step 2263, loss = 0.74185 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:54:38.753491 ops/training.py:65 2019-01-16 08:54:38.753439: step 2264, loss = 0.76251 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:54:39.715580 ops/training.py:65 2019-01-16 08:54:39.715508: step 2265, loss = 0.68192 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:54:40.679125 ops/training.py:65 2019-01-16 08:54:40.679052: step 2266, loss = 0.69831 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:54:41.641642 ops/training.py:65 2019-01-16 08:54:41.641570: step 2267, loss = 0.67943 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:54:42.606524 ops/training.py:65 2019-01-16 08:54:42.606470: step 2268, loss = 0.68200 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:54:43.569656 ops/training.py:65 2019-01-16 08:54:43.569587: step 2269, loss = 0.68256 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:54:44.533017 ops/training.py:65 2019-01-16 08:54:44.532944: step 2270, loss = 0.70252 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:54:45.495282 ops/training.py:65 2019-01-16 08:54:45.495214: step 2271, loss = 0.69611 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:54:46.457454 ops/training.py:65 2019-01-16 08:54:46.457401: step 2272, loss = 0.67509 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:54:47.419880 ops/training.py:65 2019-01-16 08:54:47.419827: step 2273, loss = 0.64670 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:54:48.382147 ops/training.py:65 2019-01-16 08:54:48.382079: step 2274, loss = 0.70867 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:54:49.343583 ops/training.py:65 2019-01-16 08:54:49.343517: step 2275, loss = 0.77363 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 08:54:50.304163 ops/training.py:65 2019-01-16 08:54:50.304097: step 2276, loss = 0.72999 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:54:51.262937 ops/training.py:65 2019-01-16 08:54:51.262873: step 2277, loss = 0.70990 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:54:52.220883 ops/training.py:65 2019-01-16 08:54:52.220815: step 2278, loss = 0.72287 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:54:53.180509 ops/training.py:65 2019-01-16 08:54:53.180441: step 2279, loss = 0.64117 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:54:54.139560 ops/training.py:65 2019-01-16 08:54:54.139499: step 2280, loss = 0.70080 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:54:55.102229 ops/training.py:65 2019-01-16 08:54:55.102165: step 2281, loss = 0.67333 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:54:56.064859 ops/training.py:65 2019-01-16 08:54:56.064798: step 2282, loss = 0.74432 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:54:57.027505 ops/training.py:65 2019-01-16 08:54:57.027455: step 2283, loss = 0.74630 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:54:57.987668 ops/training.py:65 2019-01-16 08:54:57.987604: step 2284, loss = 0.69985 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:54:58.951767 ops/training.py:65 2019-01-16 08:54:58.951701: step 2285, loss = 0.66918 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:54:59.912627 ops/training.py:65 2019-01-16 08:54:59.912561: step 2286, loss = 0.65718 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:55:00.872432 ops/training.py:65 2019-01-16 08:55:00.872365: step 2287, loss = 0.68581 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:55:01.835836 ops/training.py:65 2019-01-16 08:55:01.835788: step 2288, loss = 0.67693 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:55:02.800237 ops/training.py:65 2019-01-16 08:55:02.800166: step 2289, loss = 0.68111 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:55:03.762910 ops/training.py:65 2019-01-16 08:55:03.762841: step 2290, loss = 0.67809 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:55:04.724491 ops/training.py:65 2019-01-16 08:55:04.724425: step 2291, loss = 0.67745 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:55:05.684180 ops/training.py:65 2019-01-16 08:55:05.684113: step 2292, loss = 0.67450 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:55:06.644889 ops/training.py:65 2019-01-16 08:55:06.644821: step 2293, loss = 0.69409 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:55:07.604796 ops/training.py:65 2019-01-16 08:55:07.604751: step 2294, loss = 0.69296 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:55:08.565204 ops/training.py:65 2019-01-16 08:55:08.565151: step 2295, loss = 0.71241 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:55:09.529226 ops/training.py:65 2019-01-16 08:55:09.529160: step 2296, loss = 0.71139 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:55:10.491720 ops/training.py:65 2019-01-16 08:55:10.491669: step 2297, loss = 0.69719 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:55:11.453979 ops/training.py:65 2019-01-16 08:55:11.453914: step 2298, loss = 0.68586 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:55:12.415704 ops/training.py:65 2019-01-16 08:55:12.415642: step 2299, loss = 0.74677 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:55:13.377955 ops/training.py:65 2019-01-16 08:55:13.377910: step 2300, loss = 0.69301 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:55:14.340065 ops/training.py:65 2019-01-16 08:55:14.340001: step 2301, loss = 0.70999 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:55:15.300783 ops/training.py:65 2019-01-16 08:55:15.300716: step 2302, loss = 0.72220 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:55:16.262726 ops/training.py:65 2019-01-16 08:55:16.262682: step 2303, loss = 0.71378 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:55:17.222669 ops/training.py:65 2019-01-16 08:55:17.222619: step 2304, loss = 0.70567 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:55:18.182942 ops/training.py:65 2019-01-16 08:55:18.182886: step 2305, loss = 0.74065 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:55:19.143273 ops/training.py:65 2019-01-16 08:55:19.143215: step 2306, loss = 0.69944 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:55:20.103837 ops/training.py:65 2019-01-16 08:55:20.103786: step 2307, loss = 0.71050 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:55:21.065124 ops/training.py:65 2019-01-16 08:55:21.065069: step 2308, loss = 0.70779 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:55:22.026871 ops/training.py:65 2019-01-16 08:55:22.026808: step 2309, loss = 0.69541 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:55:22.990336 ops/training.py:65 2019-01-16 08:55:22.990273: step 2310, loss = 0.69332 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:55:23.954897 ops/training.py:65 2019-01-16 08:55:23.954837: step 2311, loss = 0.69266 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:55:24.919276 ops/training.py:65 2019-01-16 08:55:24.919213: step 2312, loss = 0.69861 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:55:25.880949 ops/training.py:65 2019-01-16 08:55:25.880893: step 2313, loss = 0.72998 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:55:26.841630 ops/training.py:65 2019-01-16 08:55:26.841578: step 2314, loss = 0.68515 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:55:27.803309 ops/training.py:65 2019-01-16 08:55:27.803251: step 2315, loss = 0.71435 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:55:28.766396 ops/training.py:65 2019-01-16 08:55:28.766338: step 2316, loss = 0.70033 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:55:29.728556 ops/training.py:65 2019-01-16 08:55:29.728500: step 2317, loss = 0.69756 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:55:30.690108 ops/training.py:65 2019-01-16 08:55:30.690051: step 2318, loss = 0.72433 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:55:31.653497 ops/training.py:65 2019-01-16 08:55:31.653426: step 2319, loss = 0.69966 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:55:32.614006 ops/training.py:65 2019-01-16 08:55:32.613947: step 2320, loss = 0.68508 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:55:33.573924 ops/training.py:65 2019-01-16 08:55:33.573863: step 2321, loss = 0.69819 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:55:34.534063 ops/training.py:65 2019-01-16 08:55:34.533991: step 2322, loss = 0.69166 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:55:35.497612 ops/training.py:65 2019-01-16 08:55:35.497553: step 2323, loss = 0.69817 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:55:36.461901 ops/training.py:65 2019-01-16 08:55:36.461843: step 2324, loss = 0.71795 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:55:37.425364 ops/training.py:65 2019-01-16 08:55:37.425310: step 2325, loss = 0.67728 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:55:38.387238 ops/training.py:65 2019-01-16 08:55:38.387177: step 2326, loss = 0.64816 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:55:39.349931 ops/training.py:65 2019-01-16 08:55:39.349866: step 2327, loss = 0.69917 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:55:40.312353 ops/training.py:65 2019-01-16 08:55:40.312293: step 2328, loss = 0.70550 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:55:41.274199 ops/training.py:65 2019-01-16 08:55:41.274144: step 2329, loss = 0.73549 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:55:42.235241 ops/training.py:65 2019-01-16 08:55:42.235187: step 2330, loss = 0.65566 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:55:43.196867 ops/training.py:65 2019-01-16 08:55:43.196811: step 2331, loss = 0.69871 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:55:44.158380 ops/training.py:65 2019-01-16 08:55:44.158323: step 2332, loss = 0.67922 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:55:45.119271 ops/training.py:65 2019-01-16 08:55:45.119213: step 2333, loss = 0.71442 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:55:46.081992 ops/training.py:65 2019-01-16 08:55:46.081935: step 2334, loss = 0.70572 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:55:47.047487 ops/training.py:65 2019-01-16 08:55:47.047441: step 2335, loss = 0.69389 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:55:48.010303 ops/training.py:65 2019-01-16 08:55:48.010247: step 2336, loss = 0.69493 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:55:48.974465 ops/training.py:65 2019-01-16 08:55:48.974407: step 2337, loss = 0.69261 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:55:49.935042 ops/training.py:65 2019-01-16 08:55:49.934982: step 2338, loss = 0.77775 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:55:50.896348 ops/training.py:65 2019-01-16 08:55:50.896292: step 2339, loss = 0.68167 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:55:51.858241 ops/training.py:65 2019-01-16 08:55:51.858188: step 2340, loss = 0.69578 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:55:52.823096 ops/training.py:65 2019-01-16 08:55:52.823040: step 2341, loss = 0.71679 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:55:53.784620 ops/training.py:65 2019-01-16 08:55:53.784549: step 2342, loss = 0.68067 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:55:54.748966 ops/training.py:65 2019-01-16 08:55:54.748898: step 2343, loss = 0.72625 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:55:55.714159 ops/training.py:65 2019-01-16 08:55:55.714094: step 2344, loss = 0.73377 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:55:56.677563 ops/training.py:65 2019-01-16 08:55:56.677501: step 2345, loss = 0.71573 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:55:57.638402 ops/training.py:65 2019-01-16 08:55:57.638330: step 2346, loss = 0.72549 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:55:58.600296 ops/training.py:65 2019-01-16 08:55:58.600245: step 2347, loss = 0.70928 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:55:59.562644 ops/training.py:65 2019-01-16 08:55:59.562591: step 2348, loss = 0.73871 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:56:00.524274 ops/training.py:65 2019-01-16 08:56:00.524221: step 2349, loss = 0.71099 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:56:01.486382 ops/training.py:65 2019-01-16 08:56:01.486332: step 2350, loss = 0.68091 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:56:02.448642 ops/training.py:65 2019-01-16 08:56:02.448592: step 2351, loss = 0.67051 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:56:03.410569 ops/training.py:65 2019-01-16 08:56:03.410522: step 2352, loss = 0.68369 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:56:04.373105 ops/training.py:65 2019-01-16 08:56:04.373050: step 2353, loss = 0.72123 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:56:05.335176 ops/training.py:65 2019-01-16 08:56:05.335129: step 2354, loss = 0.73800 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:56:06.298185 ops/training.py:65 2019-01-16 08:56:06.298133: step 2355, loss = 0.67453 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:56:07.260860 ops/training.py:65 2019-01-16 08:56:07.260807: step 2356, loss = 0.68781 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:56:08.222559 ops/training.py:65 2019-01-16 08:56:08.222514: step 2357, loss = 0.64116 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:56:09.184834 ops/training.py:65 2019-01-16 08:56:09.184780: step 2358, loss = 0.74906 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:56:10.146913 ops/training.py:65 2019-01-16 08:56:10.146863: step 2359, loss = 0.67156 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:56:11.109074 ops/training.py:65 2019-01-16 08:56:11.109028: step 2360, loss = 0.66853 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:56:12.073516 ops/training.py:65 2019-01-16 08:56:12.073450: step 2361, loss = 0.71418 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:56:13.033351 ops/training.py:65 2019-01-16 08:56:13.033290: step 2362, loss = 0.68459 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:56:13.997533 ops/training.py:65 2019-01-16 08:56:13.997477: step 2363, loss = 0.66770 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:56:14.962505 ops/training.py:65 2019-01-16 08:56:14.962450: step 2364, loss = 0.75392 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:56:15.925777 ops/training.py:65 2019-01-16 08:56:15.925721: step 2365, loss = 0.69518 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:56:16.887512 ops/training.py:65 2019-01-16 08:56:16.887459: step 2366, loss = 0.71945 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:56:17.849264 ops/training.py:65 2019-01-16 08:56:17.849210: step 2367, loss = 0.70059 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:56:18.811311 ops/training.py:65 2019-01-16 08:56:18.811258: step 2368, loss = 0.67757 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:56:19.773810 ops/training.py:65 2019-01-16 08:56:19.773754: step 2369, loss = 0.73455 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:56:20.736872 ops/training.py:65 2019-01-16 08:56:20.736804: step 2370, loss = 0.69420 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:56:21.697145 ops/training.py:65 2019-01-16 08:56:21.697089: step 2371, loss = 0.73292 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:56:22.658211 ops/training.py:65 2019-01-16 08:56:22.658156: step 2372, loss = 0.74875 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:56:23.618833 ops/training.py:65 2019-01-16 08:56:23.618780: step 2373, loss = 0.72129 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:56:24.579398 ops/training.py:65 2019-01-16 08:56:24.579347: step 2374, loss = 0.68827 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:56:25.542693 ops/training.py:65 2019-01-16 08:56:25.542631: step 2375, loss = 0.68616 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:56:26.505404 ops/training.py:65 2019-01-16 08:56:26.505358: step 2376, loss = 0.73009 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:56:27.465925 ops/training.py:65 2019-01-16 08:56:27.465869: step 2377, loss = 0.78110 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:56:28.432248 ops/training.py:65 2019-01-16 08:56:28.432190: step 2378, loss = 0.71450 (33.1 examples/sec; 0.965 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:56:29.396759 ops/training.py:65 2019-01-16 08:56:29.396695: step 2379, loss = 0.74969 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:56:30.358950 ops/training.py:65 2019-01-16 08:56:30.358893: step 2380, loss = 0.73362 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:56:31.319817 ops/training.py:65 2019-01-16 08:56:31.319762: step 2381, loss = 0.71363 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:56:32.280988 ops/training.py:65 2019-01-16 08:56:32.280931: step 2382, loss = 0.69231 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:56:33.247937 ops/training.py:65 2019-01-16 08:56:33.247873: step 2383, loss = 0.68811 (33.1 examples/sec; 0.966 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:56:34.211298 ops/training.py:65 2019-01-16 08:56:34.211244: step 2384, loss = 0.66181 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:56:35.175200 ops/training.py:65 2019-01-16 08:56:35.175142: step 2385, loss = 0.68571 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:56:36.138607 ops/training.py:65 2019-01-16 08:56:36.138550: step 2386, loss = 0.70060 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:56:37.100334 ops/training.py:65 2019-01-16 08:56:37.100287: step 2387, loss = 0.66189 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:56:38.061996 ops/training.py:65 2019-01-16 08:56:38.061938: step 2388, loss = 0.70828 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:56:39.023218 ops/training.py:65 2019-01-16 08:56:39.023159: step 2389, loss = 0.70477 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:56:39.986131 ops/training.py:65 2019-01-16 08:56:39.986071: step 2390, loss = 0.70209 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:56:40.947866 ops/training.py:65 2019-01-16 08:56:40.947807: step 2391, loss = 0.70992 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:56:41.909833 ops/training.py:65 2019-01-16 08:56:41.909774: step 2392, loss = 0.73811 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:56:42.871620 ops/training.py:65 2019-01-16 08:56:42.871562: step 2393, loss = 0.71682 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:56:43.833548 ops/training.py:65 2019-01-16 08:56:43.833493: step 2394, loss = 0.66551 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:56:44.795107 ops/training.py:65 2019-01-16 08:56:44.795056: step 2395, loss = 0.72705 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:56:45.756649 ops/training.py:65 2019-01-16 08:56:45.756577: step 2396, loss = 0.76298 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:56:46.717651 ops/training.py:65 2019-01-16 08:56:46.717586: step 2397, loss = 0.72075 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:56:47.679519 ops/training.py:65 2019-01-16 08:56:47.679459: step 2398, loss = 0.70589 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:56:48.641485 ops/training.py:65 2019-01-16 08:56:48.641415: step 2399, loss = 0.70508 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:56:49.602612 ops/training.py:65 2019-01-16 08:56:49.602551: step 2400, loss = 0.71514 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:56:50.564289 ops/training.py:65 2019-01-16 08:56:50.564230: step 2401, loss = 0.71643 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:56:51.525274 ops/training.py:65 2019-01-16 08:56:51.525212: step 2402, loss = 0.68323 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:56:52.487165 ops/training.py:65 2019-01-16 08:56:52.487104: step 2403, loss = 0.72240 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:56:53.448721 ops/training.py:65 2019-01-16 08:56:53.448661: step 2404, loss = 0.75548 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:56:54.409877 ops/training.py:65 2019-01-16 08:56:54.409821: step 2405, loss = 0.76923 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:56:55.371544 ops/training.py:65 2019-01-16 08:56:55.371483: step 2406, loss = 0.69755 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:56:56.333631 ops/training.py:65 2019-01-16 08:56:56.333571: step 2407, loss = 0.73236 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:56:57.294975 ops/training.py:65 2019-01-16 08:56:57.294920: step 2408, loss = 0.71687 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:56:58.256495 ops/training.py:65 2019-01-16 08:56:58.256437: step 2409, loss = 0.75610 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:56:59.217654 ops/training.py:65 2019-01-16 08:56:59.217597: step 2410, loss = 0.66834 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:57:00.178636 ops/training.py:65 2019-01-16 08:57:00.178583: step 2411, loss = 0.65440 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:57:01.140276 ops/training.py:65 2019-01-16 08:57:01.140230: step 2412, loss = 0.68672 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:57:02.102251 ops/training.py:65 2019-01-16 08:57:02.102200: step 2413, loss = 0.72496 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:57:03.063545 ops/training.py:65 2019-01-16 08:57:03.063498: step 2414, loss = 0.63836 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:57:04.024525 ops/training.py:65 2019-01-16 08:57:04.024470: step 2415, loss = 0.67727 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:57:04.986214 ops/training.py:65 2019-01-16 08:57:04.986158: step 2416, loss = 0.65551 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:57:05.948943 ops/training.py:65 2019-01-16 08:57:05.948890: step 2417, loss = 0.78152 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:57:06.910097 ops/training.py:65 2019-01-16 08:57:06.910047: step 2418, loss = 0.80632 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:57:07.872418 ops/training.py:65 2019-01-16 08:57:07.872366: step 2419, loss = 0.81777 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:57:08.835038 ops/training.py:65 2019-01-16 08:57:08.834980: step 2420, loss = 0.64415 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:57:09.797943 ops/training.py:65 2019-01-16 08:57:09.797887: step 2421, loss = 0.72836 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:57:10.759488 ops/training.py:65 2019-01-16 08:57:10.759450: step 2422, loss = 0.64525 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:57:11.721325 ops/training.py:65 2019-01-16 08:57:11.721261: step 2423, loss = 0.73098 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:57:12.683636 ops/training.py:65 2019-01-16 08:57:12.683578: step 2424, loss = 0.79869 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:57:13.644244 ops/training.py:65 2019-01-16 08:57:13.644187: step 2425, loss = 0.74695 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:57:14.605981 ops/training.py:65 2019-01-16 08:57:14.605929: step 2426, loss = 0.66238 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:57:15.568322 ops/training.py:65 2019-01-16 08:57:15.568264: step 2427, loss = 0.76406 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:57:16.530893 ops/training.py:65 2019-01-16 08:57:16.530837: step 2428, loss = 0.66617 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:57:17.491714 ops/training.py:65 2019-01-16 08:57:17.491657: step 2429, loss = 0.72698 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:57:18.455413 ops/training.py:65 2019-01-16 08:57:18.455361: step 2430, loss = 0.69231 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:57:19.418831 ops/training.py:65 2019-01-16 08:57:19.418776: step 2431, loss = 0.75652 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:57:20.381332 ops/training.py:65 2019-01-16 08:57:20.381282: step 2432, loss = 0.67613 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:57:21.342973 ops/training.py:65 2019-01-16 08:57:21.342933: step 2433, loss = 0.74493 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:57:22.304854 ops/training.py:65 2019-01-16 08:57:22.304799: step 2434, loss = 0.75320 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:57:23.266614 ops/training.py:65 2019-01-16 08:57:23.266557: step 2435, loss = 0.74014 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:57:24.228724 ops/training.py:65 2019-01-16 08:57:24.228678: step 2436, loss = 0.69177 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:57:25.189848 ops/training.py:65 2019-01-16 08:57:25.189795: step 2437, loss = 0.67522 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:57:26.151241 ops/training.py:65 2019-01-16 08:57:26.151184: step 2438, loss = 0.65745 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:57:27.112449 ops/training.py:65 2019-01-16 08:57:27.112393: step 2439, loss = 0.75696 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:57:28.072680 ops/training.py:65 2019-01-16 08:57:28.072610: step 2440, loss = 0.77169 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:57:29.038110 ops/training.py:65 2019-01-16 08:57:29.038035: step 2441, loss = 0.71799 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:57:30.002083 ops/training.py:65 2019-01-16 08:57:30.002012: step 2442, loss = 0.75077 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:57:30.964173 ops/training.py:65 2019-01-16 08:57:30.964102: step 2443, loss = 0.76280 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:57:31.925958 ops/training.py:65 2019-01-16 08:57:31.925905: step 2444, loss = 0.74515 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:57:32.888656 ops/training.py:65 2019-01-16 08:57:32.888590: step 2445, loss = 0.81496 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:57:33.850520 ops/training.py:65 2019-01-16 08:57:33.850442: step 2446, loss = 0.80500 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:57:34.812953 ops/training.py:65 2019-01-16 08:57:34.812884: step 2447, loss = 0.67007 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:57:35.775406 ops/training.py:65 2019-01-16 08:57:35.775330: step 2448, loss = 0.79052 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:57:36.738240 ops/training.py:65 2019-01-16 08:57:36.738170: step 2449, loss = 0.61019 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 08:57:37.700502 ops/training.py:65 2019-01-16 08:57:37.700426: step 2450, loss = 0.84614 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:57:38.662768 ops/training.py:65 2019-01-16 08:57:38.662695: step 2451, loss = 0.84993 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:57:39.625075 ops/training.py:65 2019-01-16 08:57:39.625021: step 2452, loss = 0.77224 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:57:40.585994 ops/training.py:65 2019-01-16 08:57:40.585939: step 2453, loss = 0.71327 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:57:41.548621 ops/training.py:65 2019-01-16 08:57:41.548567: step 2454, loss = 0.70468 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:57:42.511225 ops/training.py:65 2019-01-16 08:57:42.511156: step 2455, loss = 0.72526 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:57:43.474036 ops/training.py:65 2019-01-16 08:57:43.473967: step 2456, loss = 0.74327 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:57:44.436413 ops/training.py:65 2019-01-16 08:57:44.436358: step 2457, loss = 0.64472 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 08:57:45.399042 ops/training.py:65 2019-01-16 08:57:45.398990: step 2458, loss = 0.78655 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:57:46.360324 ops/training.py:65 2019-01-16 08:57:46.360274: step 2459, loss = 0.68720 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:57:47.322414 ops/training.py:65 2019-01-16 08:57:47.322365: step 2460, loss = 0.66157 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:57:48.285463 ops/training.py:65 2019-01-16 08:57:48.285407: step 2461, loss = 0.69716 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:57:49.247901 ops/training.py:65 2019-01-16 08:57:49.247850: step 2462, loss = 0.70799 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:57:50.209214 ops/training.py:65 2019-01-16 08:57:50.209153: step 2463, loss = 0.67883 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:57:51.168692 ops/training.py:65 2019-01-16 08:57:51.168637: step 2464, loss = 0.72451 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:57:52.129377 ops/training.py:65 2019-01-16 08:57:52.129309: step 2465, loss = 0.73753 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:57:53.089483 ops/training.py:65 2019-01-16 08:57:53.089413: step 2466, loss = 0.67378 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:57:54.048070 ops/training.py:65 2019-01-16 08:57:54.048002: step 2467, loss = 0.67868 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:57:55.006775 ops/training.py:65 2019-01-16 08:57:55.006683: step 2468, loss = 0.73266 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:57:55.969028 ops/training.py:65 2019-01-16 08:57:55.968977: step 2469, loss = 0.69515 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:57:56.933493 ops/training.py:65 2019-01-16 08:57:56.933439: step 2470, loss = 0.73267 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:57:57.897077 ops/training.py:65 2019-01-16 08:57:57.897003: step 2471, loss = 0.65574 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:57:58.859127 ops/training.py:65 2019-01-16 08:57:58.859074: step 2472, loss = 0.69681 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:57:59.821514 ops/training.py:65 2019-01-16 08:57:59.821458: step 2473, loss = 0.70908 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:58:00.783060 ops/training.py:65 2019-01-16 08:58:00.783013: step 2474, loss = 0.68610 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:58:01.743368 ops/training.py:65 2019-01-16 08:58:01.743296: step 2475, loss = 0.67423 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:58:02.704438 ops/training.py:65 2019-01-16 08:58:02.704369: step 2476, loss = 0.69509 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:58:03.669483 ops/training.py:65 2019-01-16 08:58:03.669413: step 2477, loss = 0.72103 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:58:04.633212 ops/training.py:65 2019-01-16 08:58:04.633140: step 2478, loss = 0.71228 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:58:05.596058 ops/training.py:65 2019-01-16 08:58:05.595981: step 2479, loss = 0.73308 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:58:06.558488 ops/training.py:65 2019-01-16 08:58:06.558410: step 2480, loss = 0.72086 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:58:07.521845 ops/training.py:65 2019-01-16 08:58:07.521774: step 2481, loss = 0.70446 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:58:08.483528 ops/training.py:65 2019-01-16 08:58:08.483468: step 2482, loss = 0.68181 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:58:09.447887 ops/training.py:65 2019-01-16 08:58:09.447837: step 2483, loss = 0.69490 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:58:10.410637 ops/training.py:65 2019-01-16 08:58:10.410567: step 2484, loss = 0.68882 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:58:11.377009 ops/training.py:65 2019-01-16 08:58:11.376939: step 2485, loss = 0.71554 (33.1 examples/sec; 0.965 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:58:12.341977 ops/training.py:65 2019-01-16 08:58:12.341906: step 2486, loss = 0.68870 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:58:13.307232 ops/training.py:65 2019-01-16 08:58:13.307165: step 2487, loss = 0.71742 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:58:14.269409 ops/training.py:65 2019-01-16 08:58:14.269341: step 2488, loss = 0.70828 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:58:15.231209 ops/training.py:65 2019-01-16 08:58:15.231137: step 2489, loss = 0.67088 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:58:16.192893 ops/training.py:65 2019-01-16 08:58:16.192823: step 2490, loss = 0.68326 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:58:17.158339 ops/training.py:65 2019-01-16 08:58:17.158288: step 2491, loss = 0.72256 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:58:18.122392 ops/training.py:65 2019-01-16 08:58:18.122327: step 2492, loss = 0.70651 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:58:19.084581 ops/training.py:65 2019-01-16 08:58:19.084491: step 2493, loss = 0.72862 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:58:20.046731 ops/training.py:65 2019-01-16 08:58:20.046663: step 2494, loss = 0.67143 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:58:21.009475 ops/training.py:65 2019-01-16 08:58:21.009404: step 2495, loss = 0.68561 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:58:21.972205 ops/training.py:65 2019-01-16 08:58:21.972136: step 2496, loss = 0.72418 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:58:22.934618 ops/training.py:65 2019-01-16 08:58:22.934545: step 2497, loss = 0.68993 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:58:23.897342 ops/training.py:65 2019-01-16 08:58:23.897275: step 2498, loss = 0.67736 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:58:24.859457 ops/training.py:65 2019-01-16 08:58:24.859385: step 2499, loss = 0.72154 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:58:25.820626 ops/training.py:65 2019-01-16 08:58:25.820554: step 2500, loss = 0.71665 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:58:26.780848 ops/training.py:65 2019-01-16 08:58:26.780791: step 2501, loss = 0.69839 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:58:27.740371 ops/training.py:65 2019-01-16 08:58:27.740306: step 2502, loss = 0.71446 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:58:28.701936 ops/training.py:65 2019-01-16 08:58:28.701864: step 2503, loss = 0.69619 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:58:29.663568 ops/training.py:65 2019-01-16 08:58:29.663505: step 2504, loss = 0.70782 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:58:30.622752 ops/training.py:65 2019-01-16 08:58:30.622688: step 2505, loss = 0.66103 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:58:31.585342 ops/training.py:65 2019-01-16 08:58:31.585272: step 2506, loss = 0.68931 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:58:32.548574 ops/training.py:65 2019-01-16 08:58:32.548521: step 2507, loss = 0.72046 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:58:33.509008 ops/training.py:65 2019-01-16 08:58:33.508938: step 2508, loss = 0.68438 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:58:34.472423 ops/training.py:65 2019-01-16 08:58:34.472354: step 2509, loss = 0.71498 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:58:35.434995 ops/training.py:65 2019-01-16 08:58:35.434924: step 2510, loss = 0.68623 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:58:36.397403 ops/training.py:65 2019-01-16 08:58:36.397334: step 2511, loss = 0.70010 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:58:37.359418 ops/training.py:65 2019-01-16 08:58:37.359350: step 2512, loss = 0.69596 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:58:38.320789 ops/training.py:65 2019-01-16 08:58:38.320726: step 2513, loss = 0.68446 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:58:39.282120 ops/training.py:65 2019-01-16 08:58:39.282046: step 2514, loss = 0.70728 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:58:40.243737 ops/training.py:65 2019-01-16 08:58:40.243669: step 2515, loss = 0.70967 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:58:41.206923 ops/training.py:65 2019-01-16 08:58:41.206854: step 2516, loss = 0.67008 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:58:42.168378 ops/training.py:65 2019-01-16 08:58:42.168321: step 2517, loss = 0.70307 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:58:43.131678 ops/training.py:65 2019-01-16 08:58:43.131619: step 2518, loss = 0.66938 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:58:44.096196 ops/training.py:65 2019-01-16 08:58:44.096130: step 2519, loss = 0.69628 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:58:45.059660 ops/training.py:65 2019-01-16 08:58:45.059594: step 2520, loss = 0.68516 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:58:46.022104 ops/training.py:65 2019-01-16 08:58:46.022036: step 2521, loss = 0.71569 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:58:46.983305 ops/training.py:65 2019-01-16 08:58:46.983254: step 2522, loss = 0.74201 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:58:47.944960 ops/training.py:65 2019-01-16 08:58:47.944894: step 2523, loss = 0.75304 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:58:48.906774 ops/training.py:65 2019-01-16 08:58:48.906732: step 2524, loss = 0.68215 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:58:49.867925 ops/training.py:65 2019-01-16 08:58:49.867888: step 2525, loss = 0.72553 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:58:50.829682 ops/training.py:65 2019-01-16 08:58:50.829618: step 2526, loss = 0.68922 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:58:51.791638 ops/training.py:65 2019-01-16 08:58:51.791600: step 2527, loss = 0.70101 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:58:52.754116 ops/training.py:65 2019-01-16 08:58:52.754051: step 2528, loss = 0.69306 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:58:53.716990 ops/training.py:65 2019-01-16 08:58:53.716924: step 2529, loss = 0.70984 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:58:54.678763 ops/training.py:65 2019-01-16 08:58:54.678726: step 2530, loss = 0.71067 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:58:55.640087 ops/training.py:65 2019-01-16 08:58:55.640050: step 2531, loss = 0.69165 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:58:56.602311 ops/training.py:65 2019-01-16 08:58:56.602277: step 2532, loss = 0.66337 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:58:57.564079 ops/training.py:65 2019-01-16 08:58:57.564020: step 2533, loss = 0.74084 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:58:58.525343 ops/training.py:65 2019-01-16 08:58:58.525302: step 2534, loss = 0.62241 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 08:58:59.487701 ops/training.py:65 2019-01-16 08:58:59.487664: step 2535, loss = 0.68067 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:59:00.449165 ops/training.py:65 2019-01-16 08:59:00.449130: step 2536, loss = 0.70050 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:59:01.410762 ops/training.py:65 2019-01-16 08:59:01.410714: step 2537, loss = 0.71021 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:59:02.372280 ops/training.py:65 2019-01-16 08:59:02.372246: step 2538, loss = 0.72585 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:59:03.334283 ops/training.py:65 2019-01-16 08:59:03.334248: step 2539, loss = 0.71869 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:59:04.295739 ops/training.py:65 2019-01-16 08:59:04.295687: step 2540, loss = 0.68331 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:59:05.257120 ops/training.py:65 2019-01-16 08:59:05.257069: step 2541, loss = 0.67770 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:59:06.217914 ops/training.py:65 2019-01-16 08:59:06.217870: step 2542, loss = 0.70506 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:59:07.178955 ops/training.py:65 2019-01-16 08:59:07.178897: step 2543, loss = 0.70096 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:59:08.141071 ops/training.py:65 2019-01-16 08:59:08.141030: step 2544, loss = 0.68230 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:59:09.102468 ops/training.py:65 2019-01-16 08:59:09.102431: step 2545, loss = 0.69298 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:59:10.063848 ops/training.py:65 2019-01-16 08:59:10.063815: step 2546, loss = 0.72669 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:59:11.025659 ops/training.py:65 2019-01-16 08:59:11.025614: step 2547, loss = 0.74693 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 08:59:11.987853 ops/training.py:65 2019-01-16 08:59:11.987815: step 2548, loss = 0.64729 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:59:12.950742 ops/training.py:65 2019-01-16 08:59:12.950701: step 2549, loss = 0.74592 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:59:13.912613 ops/training.py:65 2019-01-16 08:59:13.912575: step 2550, loss = 0.73742 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:59:14.875223 ops/training.py:65 2019-01-16 08:59:14.875187: step 2551, loss = 0.71005 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:59:15.837621 ops/training.py:65 2019-01-16 08:59:15.837574: step 2552, loss = 0.68516 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:59:16.798377 ops/training.py:65 2019-01-16 08:59:16.798305: step 2553, loss = 0.75327 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:59:17.759459 ops/training.py:65 2019-01-16 08:59:17.759394: step 2554, loss = 0.64236 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:59:18.723617 ops/training.py:65 2019-01-16 08:59:18.723574: step 2555, loss = 0.69846 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:59:19.687151 ops/training.py:65 2019-01-16 08:59:19.687108: step 2556, loss = 0.71952 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:59:20.650732 ops/training.py:65 2019-01-16 08:59:20.650674: step 2557, loss = 0.73642 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:59:21.614271 ops/training.py:65 2019-01-16 08:59:21.614220: step 2558, loss = 0.66835 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:59:22.575989 ops/training.py:65 2019-01-16 08:59:22.575952: step 2559, loss = 0.79637 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:59:23.537949 ops/training.py:65 2019-01-16 08:59:23.537898: step 2560, loss = 0.71561 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:59:24.500039 ops/training.py:65 2019-01-16 08:59:24.499991: step 2561, loss = 0.66779 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:59:25.462436 ops/training.py:65 2019-01-16 08:59:25.462390: step 2562, loss = 0.63743 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:59:26.423940 ops/training.py:65 2019-01-16 08:59:26.423897: step 2563, loss = 0.69743 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:59:27.385585 ops/training.py:65 2019-01-16 08:59:27.385530: step 2564, loss = 0.72180 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:59:28.347369 ops/training.py:65 2019-01-16 08:59:28.347312: step 2565, loss = 0.75911 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:59:29.307069 ops/training.py:65 2019-01-16 08:59:29.307008: step 2566, loss = 0.67583 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 08:59:30.267635 ops/training.py:65 2019-01-16 08:59:30.267564: step 2567, loss = 0.75038 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:59:31.227634 ops/training.py:65 2019-01-16 08:59:31.227576: step 2568, loss = 0.80984 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:59:32.186982 ops/training.py:65 2019-01-16 08:59:32.186930: step 2569, loss = 0.77049 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:59:33.151655 ops/training.py:65 2019-01-16 08:59:33.151598: step 2570, loss = 0.64392 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:59:34.113718 ops/training.py:65 2019-01-16 08:59:34.113674: step 2571, loss = 0.68633 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:59:35.074695 ops/training.py:65 2019-01-16 08:59:35.074656: step 2572, loss = 0.82824 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:59:36.036017 ops/training.py:65 2019-01-16 08:59:36.035951: step 2573, loss = 0.66166 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:59:37.000605 ops/training.py:65 2019-01-16 08:59:37.000536: step 2574, loss = 0.81709 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:59:37.965432 ops/training.py:65 2019-01-16 08:59:37.965367: step 2575, loss = 0.74092 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:59:38.927905 ops/training.py:65 2019-01-16 08:59:38.927853: step 2576, loss = 0.66182 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:59:39.889956 ops/training.py:65 2019-01-16 08:59:39.889919: step 2577, loss = 0.82912 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 08:59:40.851508 ops/training.py:65 2019-01-16 08:59:40.851473: step 2578, loss = 0.69974 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:59:41.813715 ops/training.py:65 2019-01-16 08:59:41.813652: step 2579, loss = 0.68021 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:59:42.776035 ops/training.py:65 2019-01-16 08:59:42.775987: step 2580, loss = 0.68843 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:59:43.736982 ops/training.py:65 2019-01-16 08:59:43.736928: step 2581, loss = 0.67022 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:59:44.698337 ops/training.py:65 2019-01-16 08:59:44.698278: step 2582, loss = 0.71673 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:59:45.663077 ops/training.py:65 2019-01-16 08:59:45.663016: step 2583, loss = 0.67086 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 08:59:46.627354 ops/training.py:65 2019-01-16 08:59:46.627297: step 2584, loss = 0.71147 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:59:47.590464 ops/training.py:65 2019-01-16 08:59:47.590406: step 2585, loss = 0.67882 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 08:59:48.552599 ops/training.py:65 2019-01-16 08:59:48.552559: step 2586, loss = 0.73728 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 08:59:49.515549 ops/training.py:65 2019-01-16 08:59:49.515518: step 2587, loss = 0.71111 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:59:50.477687 ops/training.py:65 2019-01-16 08:59:50.477656: step 2588, loss = 0.64180 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 08:59:51.439851 ops/training.py:65 2019-01-16 08:59:51.439821: step 2589, loss = 0.71625 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 08:59:52.402925 ops/training.py:65 2019-01-16 08:59:52.402890: step 2590, loss = 0.75817 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 08:59:53.364736 ops/training.py:65 2019-01-16 08:59:53.364700: step 2591, loss = 0.70778 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 08:59:54.326879 ops/training.py:65 2019-01-16 08:59:54.326837: step 2592, loss = 0.69314 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:59:55.289502 ops/training.py:65 2019-01-16 08:59:55.289436: step 2593, loss = 0.67411 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 08:59:56.251772 ops/training.py:65 2019-01-16 08:59:56.251735: step 2594, loss = 0.70853 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 08:59:57.212896 ops/training.py:65 2019-01-16 08:59:57.212844: step 2595, loss = 0.69578 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:59:58.173692 ops/training.py:65 2019-01-16 08:59:58.173653: step 2596, loss = 0.71199 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 08:59:59.133967 ops/training.py:65 2019-01-16 08:59:59.133930: step 2597, loss = 0.72481 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:00:00.094509 ops/training.py:65 2019-01-16 09:00:00.094472: step 2598, loss = 0.70131 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:00:01.054952 ops/training.py:65 2019-01-16 09:00:01.054916: step 2599, loss = 0.71441 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:00:02.015114 ops/training.py:65 2019-01-16 09:00:02.015071: step 2600, loss = 0.74388 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:00:02.975479 ops/training.py:65 2019-01-16 09:00:02.975443: step 2601, loss = 0.67695 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:00:03.936288 ops/training.py:65 2019-01-16 09:00:03.936252: step 2602, loss = 0.67914 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:00:04.899761 ops/training.py:65 2019-01-16 09:00:04.899724: step 2603, loss = 0.73568 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:00:05.861772 ops/training.py:65 2019-01-16 09:00:05.861736: step 2604, loss = 0.67323 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:00:06.823268 ops/training.py:65 2019-01-16 09:00:06.823234: step 2605, loss = 0.71203 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:00:07.784648 ops/training.py:65 2019-01-16 09:00:07.784612: step 2606, loss = 0.72915 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:00:08.745238 ops/training.py:65 2019-01-16 09:00:08.745191: step 2607, loss = 0.70083 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:00:09.705723 ops/training.py:65 2019-01-16 09:00:09.705674: step 2608, loss = 0.70753 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:00:10.668951 ops/training.py:65 2019-01-16 09:00:10.668915: step 2609, loss = 0.67731 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:00:11.631933 ops/training.py:65 2019-01-16 09:00:11.631898: step 2610, loss = 0.74486 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:00:12.594595 ops/training.py:65 2019-01-16 09:00:12.594560: step 2611, loss = 0.72325 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:00:13.555136 ops/training.py:65 2019-01-16 09:00:13.555099: step 2612, loss = 0.68063 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:00:14.516588 ops/training.py:65 2019-01-16 09:00:14.516552: step 2613, loss = 0.72591 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:00:15.478249 ops/training.py:65 2019-01-16 09:00:15.478213: step 2614, loss = 0.69017 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:00:16.439102 ops/training.py:65 2019-01-16 09:00:16.439067: step 2615, loss = 0.72540 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:00:17.401075 ops/training.py:65 2019-01-16 09:00:17.401002: step 2616, loss = 0.70892 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:00:18.364065 ops/training.py:65 2019-01-16 09:00:18.364023: step 2617, loss = 0.60554 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 09:00:19.326034 ops/training.py:65 2019-01-16 09:00:19.325996: step 2618, loss = 0.67858 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:00:20.288397 ops/training.py:65 2019-01-16 09:00:20.288362: step 2619, loss = 0.71762 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:00:21.248591 ops/training.py:65 2019-01-16 09:00:21.248525: step 2620, loss = 0.74264 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:00:22.209054 ops/training.py:65 2019-01-16 09:00:22.209019: step 2621, loss = 0.64542 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:00:23.174013 ops/training.py:65 2019-01-16 09:00:23.173981: step 2622, loss = 0.74708 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:00:24.138581 ops/training.py:65 2019-01-16 09:00:24.138527: step 2623, loss = 0.72565 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:00:25.101477 ops/training.py:65 2019-01-16 09:00:25.101414: step 2624, loss = 0.70080 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:00:26.063543 ops/training.py:65 2019-01-16 09:00:26.063476: step 2625, loss = 0.67488 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:00:27.026605 ops/training.py:65 2019-01-16 09:00:27.026540: step 2626, loss = 0.72426 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:00:27.987086 ops/training.py:65 2019-01-16 09:00:27.987028: step 2627, loss = 0.69033 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:00:28.947799 ops/training.py:65 2019-01-16 09:00:28.947727: step 2628, loss = 0.68709 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:00:29.908215 ops/training.py:65 2019-01-16 09:00:29.908141: step 2629, loss = 0.68335 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:00:30.871477 ops/training.py:65 2019-01-16 09:00:30.871423: step 2630, loss = 0.73278 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:00:31.834800 ops/training.py:65 2019-01-16 09:00:31.834740: step 2631, loss = 0.65701 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:00:32.798258 ops/training.py:65 2019-01-16 09:00:32.798215: step 2632, loss = 0.67917 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:00:33.759603 ops/training.py:65 2019-01-16 09:00:33.759563: step 2633, loss = 0.64839 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:00:34.720602 ops/training.py:65 2019-01-16 09:00:34.720562: step 2634, loss = 0.71016 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:00:35.682077 ops/training.py:65 2019-01-16 09:00:35.682013: step 2635, loss = 0.70548 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:00:36.647285 ops/training.py:65 2019-01-16 09:00:36.647219: step 2636, loss = 0.65514 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:00:37.611562 ops/training.py:65 2019-01-16 09:00:37.611502: step 2637, loss = 0.70929 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:00:38.573293 ops/training.py:65 2019-01-16 09:00:38.573234: step 2638, loss = 0.71844 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:00:39.534113 ops/training.py:65 2019-01-16 09:00:39.534048: step 2639, loss = 0.67618 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:00:40.495150 ops/training.py:65 2019-01-16 09:00:40.495098: step 2640, loss = 0.71414 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:00:41.459392 ops/training.py:65 2019-01-16 09:00:41.459332: step 2641, loss = 0.73192 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:00:42.422303 ops/training.py:65 2019-01-16 09:00:42.422262: step 2642, loss = 0.72076 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:00:43.384768 ops/training.py:65 2019-01-16 09:00:43.384732: step 2643, loss = 0.65017 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:00:44.346118 ops/training.py:65 2019-01-16 09:00:44.346081: step 2644, loss = 0.75860 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:00:45.306769 ops/training.py:65 2019-01-16 09:00:45.306731: step 2645, loss = 0.72322 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:00:46.267701 ops/training.py:65 2019-01-16 09:00:46.267663: step 2646, loss = 0.67522 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:00:47.228539 ops/training.py:65 2019-01-16 09:00:47.228500: step 2647, loss = 0.74703 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:00:48.188734 ops/training.py:65 2019-01-16 09:00:48.188693: step 2648, loss = 0.70203 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:00:49.149849 ops/training.py:65 2019-01-16 09:00:49.149785: step 2649, loss = 0.70441 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:00:50.111544 ops/training.py:65 2019-01-16 09:00:50.111479: step 2650, loss = 0.66940 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:00:51.072661 ops/training.py:65 2019-01-16 09:00:51.072613: step 2651, loss = 0.73086 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:00:52.032605 ops/training.py:65 2019-01-16 09:00:52.032546: step 2652, loss = 0.69217 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:00:52.994658 ops/training.py:65 2019-01-16 09:00:52.994588: step 2653, loss = 0.66309 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:00:53.955434 ops/training.py:65 2019-01-16 09:00:53.955360: step 2654, loss = 0.69335 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:00:54.916105 ops/training.py:65 2019-01-16 09:00:54.916034: step 2655, loss = 0.70576 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:00:55.876486 ops/training.py:65 2019-01-16 09:00:55.876417: step 2656, loss = 0.71720 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:00:56.836393 ops/training.py:65 2019-01-16 09:00:56.836328: step 2657, loss = 0.69646 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:00:57.800217 ops/training.py:65 2019-01-16 09:00:57.800163: step 2658, loss = 0.69460 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:00:58.760057 ops/training.py:65 2019-01-16 09:00:58.759990: step 2659, loss = 0.71748 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:00:59.724329 ops/training.py:65 2019-01-16 09:00:59.724259: step 2660, loss = 0.72139 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:01:00.687700 ops/training.py:65 2019-01-16 09:01:00.687625: step 2661, loss = 0.68497 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:01:01.651334 ops/training.py:65 2019-01-16 09:01:01.651260: step 2662, loss = 0.72405 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:01:02.612184 ops/training.py:65 2019-01-16 09:01:02.612114: step 2663, loss = 0.68852 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:01:03.575009 ops/training.py:65 2019-01-16 09:01:03.574935: step 2664, loss = 0.70372 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:01:04.537183 ops/training.py:65 2019-01-16 09:01:04.537110: step 2665, loss = 0.68412 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:01:05.498119 ops/training.py:65 2019-01-16 09:01:05.498075: step 2666, loss = 0.70126 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:01:06.458603 ops/training.py:65 2019-01-16 09:01:06.458565: step 2667, loss = 0.71281 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:01:07.420307 ops/training.py:65 2019-01-16 09:01:07.420268: step 2668, loss = 0.72108 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:01:08.381009 ops/training.py:65 2019-01-16 09:01:08.380948: step 2669, loss = 0.71987 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:01:09.342352 ops/training.py:65 2019-01-16 09:01:09.342284: step 2670, loss = 0.72225 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:01:10.305526 ops/training.py:65 2019-01-16 09:01:10.305453: step 2671, loss = 0.72537 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:01:11.266685 ops/training.py:65 2019-01-16 09:01:11.266624: step 2672, loss = 0.70702 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:01:12.229299 ops/training.py:65 2019-01-16 09:01:12.229261: step 2673, loss = 0.69254 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:01:13.193591 ops/training.py:65 2019-01-16 09:01:13.193546: step 2674, loss = 0.69247 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:01:14.157603 ops/training.py:65 2019-01-16 09:01:14.157556: step 2675, loss = 0.69191 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:01:15.120461 ops/training.py:65 2019-01-16 09:01:15.120410: step 2676, loss = 0.74624 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:01:16.082499 ops/training.py:65 2019-01-16 09:01:16.082442: step 2677, loss = 0.70845 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:01:17.044182 ops/training.py:65 2019-01-16 09:01:17.044138: step 2678, loss = 0.67917 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:01:18.006394 ops/training.py:65 2019-01-16 09:01:18.006352: step 2679, loss = 0.70372 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:01:18.967486 ops/training.py:65 2019-01-16 09:01:18.967432: step 2680, loss = 0.69355 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:01:19.928593 ops/training.py:65 2019-01-16 09:01:19.928526: step 2681, loss = 0.72220 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:01:20.889945 ops/training.py:65 2019-01-16 09:01:20.889894: step 2682, loss = 0.66854 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:01:21.850144 ops/training.py:65 2019-01-16 09:01:21.850109: step 2683, loss = 0.70797 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:01:22.810234 ops/training.py:65 2019-01-16 09:01:22.810198: step 2684, loss = 0.69331 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:01:23.770753 ops/training.py:65 2019-01-16 09:01:23.770717: step 2685, loss = 0.68897 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:01:24.734549 ops/training.py:65 2019-01-16 09:01:24.734516: step 2686, loss = 0.74751 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:01:25.698731 ops/training.py:65 2019-01-16 09:01:25.698699: step 2687, loss = 0.70162 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:01:26.661407 ops/training.py:65 2019-01-16 09:01:26.661360: step 2688, loss = 0.69246 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:01:27.622323 ops/training.py:65 2019-01-16 09:01:27.622267: step 2689, loss = 0.72966 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:01:28.587209 ops/training.py:65 2019-01-16 09:01:28.587150: step 2690, loss = 0.71379 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:01:29.551260 ops/training.py:65 2019-01-16 09:01:29.551212: step 2691, loss = 0.70107 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:01:30.512475 ops/training.py:65 2019-01-16 09:01:30.512408: step 2692, loss = 0.67043 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:01:31.478065 ops/training.py:65 2019-01-16 09:01:31.478012: step 2693, loss = 0.69687 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:01:32.442784 ops/training.py:65 2019-01-16 09:01:32.442724: step 2694, loss = 0.68640 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:01:33.403760 ops/training.py:65 2019-01-16 09:01:33.403683: step 2695, loss = 0.70706 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:01:34.364677 ops/training.py:65 2019-01-16 09:01:34.364618: step 2696, loss = 0.73309 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:01:35.329098 ops/training.py:65 2019-01-16 09:01:35.329040: step 2697, loss = 0.69955 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:01:36.292414 ops/training.py:65 2019-01-16 09:01:36.292359: step 2698, loss = 0.65698 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:01:37.254169 ops/training.py:65 2019-01-16 09:01:37.254128: step 2699, loss = 0.70268 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:01:38.215152 ops/training.py:65 2019-01-16 09:01:38.215091: step 2700, loss = 0.69726 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:01:39.175620 ops/training.py:65 2019-01-16 09:01:39.175552: step 2701, loss = 0.68857 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:01:40.136303 ops/training.py:65 2019-01-16 09:01:40.136229: step 2702, loss = 0.72465 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:01:41.096935 ops/training.py:65 2019-01-16 09:01:41.096875: step 2703, loss = 0.66728 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:01:42.056401 ops/training.py:65 2019-01-16 09:01:42.056333: step 2704, loss = 0.71392 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:01:43.015799 ops/training.py:65 2019-01-16 09:01:43.015709: step 2705, loss = 0.70932 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:01:43.979010 ops/training.py:65 2019-01-16 09:01:43.978964: step 2706, loss = 0.69689 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:01:44.943113 ops/training.py:65 2019-01-16 09:01:44.943055: step 2707, loss = 0.70572 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:01:45.905745 ops/training.py:65 2019-01-16 09:01:45.905702: step 2708, loss = 0.72471 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:01:46.866502 ops/training.py:65 2019-01-16 09:01:46.866462: step 2709, loss = 0.72808 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:01:47.827967 ops/training.py:65 2019-01-16 09:01:47.827909: step 2710, loss = 0.73905 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:01:48.790075 ops/training.py:65 2019-01-16 09:01:48.790018: step 2711, loss = 0.71317 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:01:49.751091 ops/training.py:65 2019-01-16 09:01:49.751038: step 2712, loss = 0.70676 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:01:50.713029 ops/training.py:65 2019-01-16 09:01:50.712975: step 2713, loss = 0.68328 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:01:51.673798 ops/training.py:65 2019-01-16 09:01:51.673739: step 2714, loss = 0.68640 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:01:52.634364 ops/training.py:65 2019-01-16 09:01:52.634305: step 2715, loss = 0.73468 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:01:53.595280 ops/training.py:65 2019-01-16 09:01:53.595223: step 2716, loss = 0.67830 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:01:54.556730 ops/training.py:65 2019-01-16 09:01:54.556686: step 2717, loss = 0.65681 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:01:55.520781 ops/training.py:65 2019-01-16 09:01:55.520720: step 2718, loss = 0.66917 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:01:56.481506 ops/training.py:65 2019-01-16 09:01:56.481451: step 2719, loss = 0.73357 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:01:57.442233 ops/training.py:65 2019-01-16 09:01:57.442177: step 2720, loss = 0.70609 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:01:58.403090 ops/training.py:65 2019-01-16 09:01:58.403036: step 2721, loss = 0.70056 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:01:59.364738 ops/training.py:65 2019-01-16 09:01:59.364681: step 2722, loss = 0.68328 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:02:00.326297 ops/training.py:65 2019-01-16 09:02:00.326247: step 2723, loss = 0.69596 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:02:01.287634 ops/training.py:65 2019-01-16 09:02:01.287587: step 2724, loss = 0.76746 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:02:02.248026 ops/training.py:65 2019-01-16 09:02:02.247974: step 2725, loss = 0.67717 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:02:03.211987 ops/training.py:65 2019-01-16 09:02:03.211944: step 2726, loss = 0.66086 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:02:04.173091 ops/training.py:65 2019-01-16 09:02:04.173039: step 2727, loss = 0.68238 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:02:05.137685 ops/training.py:65 2019-01-16 09:02:05.137635: step 2728, loss = 0.67714 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:02:06.101041 ops/training.py:65 2019-01-16 09:02:06.100995: step 2729, loss = 0.67519 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:02:07.064090 ops/training.py:65 2019-01-16 09:02:07.064053: step 2730, loss = 0.70764 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:02:08.024910 ops/training.py:65 2019-01-16 09:02:08.024876: step 2731, loss = 0.68087 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:02:08.984456 ops/training.py:65 2019-01-16 09:02:08.984411: step 2732, loss = 0.69726 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:02:09.947458 ops/training.py:65 2019-01-16 09:02:09.947421: step 2733, loss = 0.67526 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:02:10.909832 ops/training.py:65 2019-01-16 09:02:10.909795: step 2734, loss = 0.69842 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:02:11.871564 ops/training.py:65 2019-01-16 09:02:11.871527: step 2735, loss = 0.72157 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:02:12.832848 ops/training.py:65 2019-01-16 09:02:12.832793: step 2736, loss = 0.73702 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:02:13.793913 ops/training.py:65 2019-01-16 09:02:13.793857: step 2737, loss = 0.69721 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:02:14.754903 ops/training.py:65 2019-01-16 09:02:14.754850: step 2738, loss = 0.66015 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:02:15.716985 ops/training.py:65 2019-01-16 09:02:15.716929: step 2739, loss = 0.73732 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:02:16.679071 ops/training.py:65 2019-01-16 09:02:16.679008: step 2740, loss = 0.75397 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:02:17.640908 ops/training.py:65 2019-01-16 09:02:17.640856: step 2741, loss = 0.70317 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:02:18.602544 ops/training.py:65 2019-01-16 09:02:18.602480: step 2742, loss = 0.76210 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:02:19.565183 ops/training.py:65 2019-01-16 09:02:19.565115: step 2743, loss = 0.70735 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:02:20.526094 ops/training.py:65 2019-01-16 09:02:20.526043: step 2744, loss = 0.71263 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:02:21.487023 ops/training.py:65 2019-01-16 09:02:21.486964: step 2745, loss = 0.68347 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:02:22.447598 ops/training.py:65 2019-01-16 09:02:22.447543: step 2746, loss = 0.68759 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:02:23.413051 ops/training.py:65 2019-01-16 09:02:23.412999: step 2747, loss = 0.65896 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:02:24.377177 ops/training.py:65 2019-01-16 09:02:24.377124: step 2748, loss = 0.69103 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:02:25.340804 ops/training.py:65 2019-01-16 09:02:25.340749: step 2749, loss = 0.68349 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:02:26.301902 ops/training.py:65 2019-01-16 09:02:26.301854: step 2750, loss = 0.67363 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:02:27.264634 ops/training.py:65 2019-01-16 09:02:27.264580: step 2751, loss = 0.70017 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:02:28.226962 ops/training.py:65 2019-01-16 09:02:28.226893: step 2752, loss = 0.69969 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:02:29.189872 ops/training.py:65 2019-01-16 09:02:29.189822: step 2753, loss = 0.75896 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:02:30.155498 ops/training.py:65 2019-01-16 09:02:30.155442: step 2754, loss = 0.71036 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:02:31.120252 ops/training.py:65 2019-01-16 09:02:31.120194: step 2755, loss = 0.71571 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:02:32.083968 ops/training.py:65 2019-01-16 09:02:32.083917: step 2756, loss = 0.78414 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:02:33.046165 ops/training.py:65 2019-01-16 09:02:33.046113: step 2757, loss = 0.78310 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:02:34.007755 ops/training.py:65 2019-01-16 09:02:34.007699: step 2758, loss = 0.75774 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:02:34.969460 ops/training.py:65 2019-01-16 09:02:34.969402: step 2759, loss = 0.72921 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:02:35.934446 ops/training.py:65 2019-01-16 09:02:35.934396: step 2760, loss = 0.73738 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:02:36.899048 ops/training.py:65 2019-01-16 09:02:36.898995: step 2761, loss = 0.71199 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:02:37.863001 ops/training.py:65 2019-01-16 09:02:37.862953: step 2762, loss = 0.70449 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:02:38.826219 ops/training.py:65 2019-01-16 09:02:38.826148: step 2763, loss = 0.73928 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:02:39.788567 ops/training.py:65 2019-01-16 09:02:39.788496: step 2764, loss = 0.67151 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:02:40.750247 ops/training.py:65 2019-01-16 09:02:40.750178: step 2765, loss = 0.73914 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:02:41.712297 ops/training.py:65 2019-01-16 09:02:41.712232: step 2766, loss = 0.73533 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:02:42.671585 ops/training.py:65 2019-01-16 09:02:42.671519: step 2767, loss = 0.72967 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:02:43.634938 ops/training.py:65 2019-01-16 09:02:43.634872: step 2768, loss = 0.69941 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:02:44.597819 ops/training.py:65 2019-01-16 09:02:44.597765: step 2769, loss = 0.71267 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:02:45.560116 ops/training.py:65 2019-01-16 09:02:45.560046: step 2770, loss = 0.72384 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:02:46.522521 ops/training.py:65 2019-01-16 09:02:46.522472: step 2771, loss = 0.81266 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:02:47.484220 ops/training.py:65 2019-01-16 09:02:47.484164: step 2772, loss = 0.75367 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:02:48.445585 ops/training.py:65 2019-01-16 09:02:48.445510: step 2773, loss = 0.68823 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:02:49.410947 ops/training.py:65 2019-01-16 09:02:49.410876: step 2774, loss = 0.75928 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:02:50.375126 ops/training.py:65 2019-01-16 09:02:50.375071: step 2775, loss = 0.69185 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:02:51.338924 ops/training.py:65 2019-01-16 09:02:51.338875: step 2776, loss = 0.62009 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:02:52.301774 ops/training.py:65 2019-01-16 09:02:52.301718: step 2777, loss = 0.76263 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:02:53.263765 ops/training.py:65 2019-01-16 09:02:53.263710: step 2778, loss = 0.70864 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:02:54.225835 ops/training.py:65 2019-01-16 09:02:54.225777: step 2779, loss = 0.72589 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:02:55.186405 ops/training.py:65 2019-01-16 09:02:55.186352: step 2780, loss = 0.72582 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:02:56.148383 ops/training.py:65 2019-01-16 09:02:56.148327: step 2781, loss = 0.70636 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:02:57.110148 ops/training.py:65 2019-01-16 09:02:57.110090: step 2782, loss = 0.74936 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:02:58.072418 ops/training.py:65 2019-01-16 09:02:58.072348: step 2783, loss = 0.69145 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:02:59.036553 ops/training.py:65 2019-01-16 09:02:59.036498: step 2784, loss = 0.75993 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:02:59.997884 ops/training.py:65 2019-01-16 09:02:59.997828: step 2785, loss = 0.73576 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:03:00.958517 ops/training.py:65 2019-01-16 09:03:00.958442: step 2786, loss = 0.77981 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:03:01.925253 ops/training.py:65 2019-01-16 09:03:01.925198: step 2787, loss = 0.74788 (33.1 examples/sec; 0.965 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:03:02.889545 ops/training.py:65 2019-01-16 09:03:02.889475: step 2788, loss = 0.68599 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:03:03.851715 ops/training.py:65 2019-01-16 09:03:03.851644: step 2789, loss = 0.69731 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:03:04.812490 ops/training.py:65 2019-01-16 09:03:04.812426: step 2790, loss = 0.77522 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:03:05.776779 ops/training.py:65 2019-01-16 09:03:05.776719: step 2791, loss = 0.73033 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:03:06.737414 ops/training.py:65 2019-01-16 09:03:06.737339: step 2792, loss = 0.66467 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:03:07.697465 ops/training.py:65 2019-01-16 09:03:07.697405: step 2793, loss = 0.71861 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:03:08.657675 ops/training.py:65 2019-01-16 09:03:08.657607: step 2794, loss = 0.69373 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:03:09.618728 ops/training.py:65 2019-01-16 09:03:09.618654: step 2795, loss = 0.69564 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:03:10.583188 ops/training.py:65 2019-01-16 09:03:10.583140: step 2796, loss = 0.68188 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:03:11.547352 ops/training.py:65 2019-01-16 09:03:11.547285: step 2797, loss = 0.71145 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:03:12.510608 ops/training.py:65 2019-01-16 09:03:12.510541: step 2798, loss = 0.68184 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:03:13.471879 ops/training.py:65 2019-01-16 09:03:13.471815: step 2799, loss = 0.76097 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:03:14.433117 ops/training.py:65 2019-01-16 09:03:14.433064: step 2800, loss = 0.68267 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:03:15.395087 ops/training.py:65 2019-01-16 09:03:15.395015: step 2801, loss = 0.72193 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:03:16.360373 ops/training.py:65 2019-01-16 09:03:16.360332: step 2802, loss = 0.65521 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:03:17.323900 ops/training.py:65 2019-01-16 09:03:17.323857: step 2803, loss = 0.70940 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:03:18.286485 ops/training.py:65 2019-01-16 09:03:18.286447: step 2804, loss = 0.69856 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:03:19.247522 ops/training.py:65 2019-01-16 09:03:19.247483: step 2805, loss = 0.70267 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:03:20.208867 ops/training.py:65 2019-01-16 09:03:20.208817: step 2806, loss = 0.73506 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:03:21.173627 ops/training.py:65 2019-01-16 09:03:21.173584: step 2807, loss = 0.73291 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:03:22.135590 ops/training.py:65 2019-01-16 09:03:22.135551: step 2808, loss = 0.67901 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:03:23.098661 ops/training.py:65 2019-01-16 09:03:23.098616: step 2809, loss = 0.69185 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:03:24.060647 ops/training.py:65 2019-01-16 09:03:24.060594: step 2810, loss = 0.70216 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:03:25.022002 ops/training.py:65 2019-01-16 09:03:25.021938: step 2811, loss = 0.66202 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:03:25.983586 ops/training.py:65 2019-01-16 09:03:25.983527: step 2812, loss = 0.70627 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:03:26.946478 ops/training.py:65 2019-01-16 09:03:26.946423: step 2813, loss = 0.73660 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 09:03:27.906993 ops/training.py:65 2019-01-16 09:03:27.906930: step 2814, loss = 0.70559 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:03:28.868455 ops/training.py:65 2019-01-16 09:03:28.868401: step 2815, loss = 0.68892 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:03:29.829239 ops/training.py:65 2019-01-16 09:03:29.829189: step 2816, loss = 0.71000 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:03:30.789731 ops/training.py:65 2019-01-16 09:03:30.789696: step 2817, loss = 0.67045 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:03:31.751166 ops/training.py:65 2019-01-16 09:03:31.751128: step 2818, loss = 0.68305 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:03:32.712490 ops/training.py:65 2019-01-16 09:03:32.712451: step 2819, loss = 0.65828 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:03:33.673181 ops/training.py:65 2019-01-16 09:03:33.673142: step 2820, loss = 0.72645 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:03:34.635338 ops/training.py:65 2019-01-16 09:03:34.635286: step 2821, loss = 0.68812 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:03:35.597792 ops/training.py:65 2019-01-16 09:03:35.597736: step 2822, loss = 0.67098 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:03:36.560048 ops/training.py:65 2019-01-16 09:03:36.559999: step 2823, loss = 0.69326 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:03:37.525338 ops/training.py:65 2019-01-16 09:03:37.525289: step 2824, loss = 0.75057 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:03:38.487024 ops/training.py:65 2019-01-16 09:03:38.486975: step 2825, loss = 0.70326 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:03:39.450355 ops/training.py:65 2019-01-16 09:03:39.450307: step 2826, loss = 0.75885 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:03:40.412261 ops/training.py:65 2019-01-16 09:03:40.412209: step 2827, loss = 0.71560 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:03:41.372547 ops/training.py:65 2019-01-16 09:03:41.372497: step 2828, loss = 0.74671 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:03:42.337870 ops/training.py:65 2019-01-16 09:03:42.337823: step 2829, loss = 0.72404 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:03:43.301985 ops/training.py:65 2019-01-16 09:03:43.301938: step 2830, loss = 0.65199 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:03:44.262997 ops/training.py:65 2019-01-16 09:03:44.262958: step 2831, loss = 0.76640 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.25
I0832 2019-01-16 09:03:45.224324 ops/training.py:65 2019-01-16 09:03:45.224278: step 2832, loss = 0.71710 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:03:46.185062 ops/training.py:65 2019-01-16 09:03:46.185014: step 2833, loss = 0.69430 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:03:47.146083 ops/training.py:65 2019-01-16 09:03:47.146034: step 2834, loss = 0.71300 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:03:48.106580 ops/training.py:65 2019-01-16 09:03:48.106532: step 2835, loss = 0.70228 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:03:49.071794 ops/training.py:65 2019-01-16 09:03:49.071744: step 2836, loss = 0.68849 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:03:50.034215 ops/training.py:65 2019-01-16 09:03:50.034172: step 2837, loss = 0.71790 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:03:50.996903 ops/training.py:65 2019-01-16 09:03:50.996852: step 2838, loss = 0.73222 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:03:51.958128 ops/training.py:65 2019-01-16 09:03:51.958075: step 2839, loss = 0.68035 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:03:52.919629 ops/training.py:65 2019-01-16 09:03:52.919585: step 2840, loss = 0.69537 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:03:53.880831 ops/training.py:65 2019-01-16 09:03:53.880784: step 2841, loss = 0.70477 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:03:54.841931 ops/training.py:65 2019-01-16 09:03:54.841884: step 2842, loss = 0.67978 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:03:55.802837 ops/training.py:65 2019-01-16 09:03:55.802784: step 2843, loss = 0.68942 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:03:56.763944 ops/training.py:65 2019-01-16 09:03:56.763896: step 2844, loss = 0.68819 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:03:57.725636 ops/training.py:65 2019-01-16 09:03:57.725582: step 2845, loss = 0.69774 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:03:58.686810 ops/training.py:65 2019-01-16 09:03:58.686752: step 2846, loss = 0.68026 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:03:59.647426 ops/training.py:65 2019-01-16 09:03:59.647381: step 2847, loss = 0.66325 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:04:00.608713 ops/training.py:65 2019-01-16 09:04:00.608663: step 2848, loss = 0.70107 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:04:01.569961 ops/training.py:65 2019-01-16 09:04:01.569920: step 2849, loss = 0.67549 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:04:02.529892 ops/training.py:65 2019-01-16 09:04:02.529840: step 2850, loss = 0.66822 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:04:03.490800 ops/training.py:65 2019-01-16 09:04:03.490749: step 2851, loss = 0.67810 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:04:04.451178 ops/training.py:65 2019-01-16 09:04:04.451127: step 2852, loss = 0.69354 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:04:05.414902 ops/training.py:65 2019-01-16 09:04:05.414852: step 2853, loss = 0.68274 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:04:06.378599 ops/training.py:65 2019-01-16 09:04:06.378558: step 2854, loss = 0.67515 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:04:07.339754 ops/training.py:65 2019-01-16 09:04:07.339702: step 2855, loss = 0.70628 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:04:08.302055 ops/training.py:65 2019-01-16 09:04:08.302013: step 2856, loss = 0.69262 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:04:09.263359 ops/training.py:65 2019-01-16 09:04:09.263313: step 2857, loss = 0.67707 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:04:10.225500 ops/training.py:65 2019-01-16 09:04:10.225447: step 2858, loss = 0.67894 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:04:11.187957 ops/training.py:65 2019-01-16 09:04:11.187906: step 2859, loss = 0.68127 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:04:12.149917 ops/training.py:65 2019-01-16 09:04:12.149865: step 2860, loss = 0.68167 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:04:13.113183 ops/training.py:65 2019-01-16 09:04:13.113138: step 2861, loss = 0.73573 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:04:14.075393 ops/training.py:65 2019-01-16 09:04:14.075336: step 2862, loss = 0.69395 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:04:15.037100 ops/training.py:65 2019-01-16 09:04:15.037044: step 2863, loss = 0.67296 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:04:15.998365 ops/training.py:65 2019-01-16 09:04:15.998310: step 2864, loss = 0.69210 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:04:16.960428 ops/training.py:65 2019-01-16 09:04:16.960377: step 2865, loss = 0.68873 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:04:17.922268 ops/training.py:65 2019-01-16 09:04:17.922217: step 2866, loss = 0.67465 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:04:18.883484 ops/training.py:65 2019-01-16 09:04:18.883444: step 2867, loss = 0.68628 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:04:19.845218 ops/training.py:65 2019-01-16 09:04:19.845161: step 2868, loss = 0.68105 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:04:20.807962 ops/training.py:65 2019-01-16 09:04:20.807907: step 2869, loss = 0.67154 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:04:21.768545 ops/training.py:65 2019-01-16 09:04:21.768490: step 2870, loss = 0.68788 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:04:22.733235 ops/training.py:65 2019-01-16 09:04:22.733181: step 2871, loss = 0.70768 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:04:23.696591 ops/training.py:65 2019-01-16 09:04:23.696537: step 2872, loss = 0.67696 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:04:24.659147 ops/training.py:65 2019-01-16 09:04:24.659093: step 2873, loss = 0.69826 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:04:25.620320 ops/training.py:65 2019-01-16 09:04:25.620285: step 2874, loss = 0.71396 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:04:26.581508 ops/training.py:65 2019-01-16 09:04:26.581458: step 2875, loss = 0.70670 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:04:27.542420 ops/training.py:65 2019-01-16 09:04:27.542367: step 2876, loss = 0.71413 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:04:28.505122 ops/training.py:65 2019-01-16 09:04:28.505069: step 2877, loss = 0.71243 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:04:29.466215 ops/training.py:65 2019-01-16 09:04:29.466163: step 2878, loss = 0.69884 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:04:30.427045 ops/training.py:65 2019-01-16 09:04:30.426993: step 2879, loss = 0.67357 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:04:31.390961 ops/training.py:65 2019-01-16 09:04:31.390911: step 2880, loss = 0.70465 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:04:32.354479 ops/training.py:65 2019-01-16 09:04:32.354430: step 2881, loss = 0.67896 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:04:33.317381 ops/training.py:65 2019-01-16 09:04:33.317333: step 2882, loss = 0.69257 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:04:34.278722 ops/training.py:65 2019-01-16 09:04:34.278670: step 2883, loss = 0.72198 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:04:35.239974 ops/training.py:65 2019-01-16 09:04:35.239922: step 2884, loss = 0.71351 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:04:36.202129 ops/training.py:65 2019-01-16 09:04:36.202083: step 2885, loss = 0.69989 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:04:37.166940 ops/training.py:65 2019-01-16 09:04:37.166891: step 2886, loss = 0.70965 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:04:38.130155 ops/training.py:65 2019-01-16 09:04:38.130103: step 2887, loss = 0.67429 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:04:39.090911 ops/training.py:65 2019-01-16 09:04:39.090853: step 2888, loss = 0.70931 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:04:40.051123 ops/training.py:65 2019-01-16 09:04:40.051069: step 2889, loss = 0.71419 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:04:41.015995 ops/training.py:65 2019-01-16 09:04:41.015933: step 2890, loss = 0.68589 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:04:41.980222 ops/training.py:65 2019-01-16 09:04:41.980167: step 2891, loss = 0.72663 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:04:42.943492 ops/training.py:65 2019-01-16 09:04:42.943447: step 2892, loss = 0.69872 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:04:43.905204 ops/training.py:65 2019-01-16 09:04:43.905144: step 2893, loss = 0.67763 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:04:44.866536 ops/training.py:65 2019-01-16 09:04:44.866477: step 2894, loss = 0.71760 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:04:45.828487 ops/training.py:65 2019-01-16 09:04:45.828444: step 2895, loss = 0.68697 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:04:46.788365 ops/training.py:65 2019-01-16 09:04:46.788308: step 2896, loss = 0.70662 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:04:47.750179 ops/training.py:65 2019-01-16 09:04:47.750122: step 2897, loss = 0.68892 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:04:48.711840 ops/training.py:65 2019-01-16 09:04:48.711786: step 2898, loss = 0.70339 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:04:49.672938 ops/training.py:65 2019-01-16 09:04:49.672890: step 2899, loss = 0.68073 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:04:50.634405 ops/training.py:65 2019-01-16 09:04:50.634353: step 2900, loss = 0.69613 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:04:51.596101 ops/training.py:65 2019-01-16 09:04:51.596043: step 2901, loss = 0.69468 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:04:52.557492 ops/training.py:65 2019-01-16 09:04:52.557449: step 2902, loss = 0.70430 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:04:53.519424 ops/training.py:65 2019-01-16 09:04:53.519373: step 2903, loss = 0.72313 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:04:54.481347 ops/training.py:65 2019-01-16 09:04:54.481287: step 2904, loss = 0.68941 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:04:55.443781 ops/training.py:65 2019-01-16 09:04:55.443729: step 2905, loss = 0.69683 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:04:56.404960 ops/training.py:65 2019-01-16 09:04:56.404903: step 2906, loss = 0.71376 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:04:57.367085 ops/training.py:65 2019-01-16 09:04:57.367029: step 2907, loss = 0.68017 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:04:58.328381 ops/training.py:65 2019-01-16 09:04:58.328320: step 2908, loss = 0.71130 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:04:59.292483 ops/training.py:65 2019-01-16 09:04:59.292427: step 2909, loss = 0.68686 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:05:00.253721 ops/training.py:65 2019-01-16 09:05:00.253668: step 2910, loss = 0.73257 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:05:01.215851 ops/training.py:65 2019-01-16 09:05:01.215795: step 2911, loss = 0.67415 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:05:02.177286 ops/training.py:65 2019-01-16 09:05:02.177232: step 2912, loss = 0.69017 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:05:03.138486 ops/training.py:65 2019-01-16 09:05:03.138433: step 2913, loss = 0.70573 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:05:04.099344 ops/training.py:65 2019-01-16 09:05:04.099292: step 2914, loss = 0.68297 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:05:05.060127 ops/training.py:65 2019-01-16 09:05:05.060092: step 2915, loss = 0.63152 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:05:06.021815 ops/training.py:65 2019-01-16 09:05:06.021763: step 2916, loss = 0.74139 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:05:06.984848 ops/training.py:65 2019-01-16 09:05:06.984798: step 2917, loss = 0.69205 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:05:07.948708 ops/training.py:65 2019-01-16 09:05:07.948632: step 2918, loss = 0.69550 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:05:08.911215 ops/training.py:65 2019-01-16 09:05:08.911164: step 2919, loss = 0.70152 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:05:09.872688 ops/training.py:65 2019-01-16 09:05:09.872640: step 2920, loss = 0.72081 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:05:10.833254 ops/training.py:65 2019-01-16 09:05:10.833205: step 2921, loss = 0.65529 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:05:11.796166 ops/training.py:65 2019-01-16 09:05:11.796111: step 2922, loss = 0.77768 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:05:12.756998 ops/training.py:65 2019-01-16 09:05:12.756945: step 2923, loss = 0.65337 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:05:13.717386 ops/training.py:65 2019-01-16 09:05:13.717333: step 2924, loss = 0.74293 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:05:14.676631 ops/training.py:65 2019-01-16 09:05:14.676575: step 2925, loss = 0.72286 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:05:15.635983 ops/training.py:65 2019-01-16 09:05:15.635926: step 2926, loss = 0.71206 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:05:16.599210 ops/training.py:65 2019-01-16 09:05:16.599159: step 2927, loss = 0.67336 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:05:17.562885 ops/training.py:65 2019-01-16 09:05:17.562833: step 2928, loss = 0.77271 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:05:18.526217 ops/training.py:65 2019-01-16 09:05:18.526165: step 2929, loss = 0.69900 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:05:19.487069 ops/training.py:65 2019-01-16 09:05:19.486994: step 2930, loss = 0.71110 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:05:20.452502 ops/training.py:65 2019-01-16 09:05:20.452432: step 2931, loss = 0.67833 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:05:21.416301 ops/training.py:65 2019-01-16 09:05:21.416244: step 2932, loss = 0.72475 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:05:22.381871 ops/training.py:65 2019-01-16 09:05:22.381807: step 2933, loss = 0.69177 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:05:23.341604 ops/training.py:65 2019-01-16 09:05:23.341546: step 2934, loss = 0.73294 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:05:24.305630 ops/training.py:65 2019-01-16 09:05:24.305590: step 2935, loss = 0.75166 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:05:25.268050 ops/training.py:65 2019-01-16 09:05:25.267990: step 2936, loss = 0.70874 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:05:26.230810 ops/training.py:65 2019-01-16 09:05:26.230752: step 2937, loss = 0.69460 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:05:27.192834 ops/training.py:65 2019-01-16 09:05:27.192775: step 2938, loss = 0.70960 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:05:28.154034 ops/training.py:65 2019-01-16 09:05:28.153979: step 2939, loss = 0.69749 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:05:29.115906 ops/training.py:65 2019-01-16 09:05:29.115851: step 2940, loss = 0.67772 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:05:30.076713 ops/training.py:65 2019-01-16 09:05:30.076661: step 2941, loss = 0.66361 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 09:05:31.038556 ops/training.py:65 2019-01-16 09:05:31.038513: step 2942, loss = 0.72546 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:05:31.999374 ops/training.py:65 2019-01-16 09:05:31.999319: step 2943, loss = 0.74605 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.25
I0832 2019-01-16 09:05:32.960998 ops/training.py:65 2019-01-16 09:05:32.960944: step 2944, loss = 0.69849 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:05:33.922179 ops/training.py:65 2019-01-16 09:05:33.922121: step 2945, loss = 0.72722 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:05:34.883505 ops/training.py:65 2019-01-16 09:05:34.883441: step 2946, loss = 0.70125 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:05:35.844311 ops/training.py:65 2019-01-16 09:05:35.844272: step 2947, loss = 0.72589 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:05:36.808695 ops/training.py:65 2019-01-16 09:05:36.808657: step 2948, loss = 0.67027 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:05:37.771193 ops/training.py:65 2019-01-16 09:05:37.771149: step 2949, loss = 0.65514 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:05:38.733744 ops/training.py:65 2019-01-16 09:05:38.733706: step 2950, loss = 0.69888 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:05:39.695652 ops/training.py:65 2019-01-16 09:05:39.695614: step 2951, loss = 0.65778 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:05:40.657274 ops/training.py:65 2019-01-16 09:05:40.657235: step 2952, loss = 0.71849 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:05:41.619192 ops/training.py:65 2019-01-16 09:05:41.619149: step 2953, loss = 0.70713 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:05:42.581987 ops/training.py:65 2019-01-16 09:05:42.581941: step 2954, loss = 0.68031 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:05:43.546443 ops/training.py:65 2019-01-16 09:05:43.546398: step 2955, loss = 0.71435 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:05:44.510673 ops/training.py:65 2019-01-16 09:05:44.510622: step 2956, loss = 0.73964 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:05:45.475221 ops/training.py:65 2019-01-16 09:05:45.475183: step 2957, loss = 0.71828 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:05:46.437963 ops/training.py:65 2019-01-16 09:05:46.437927: step 2958, loss = 0.68645 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:05:47.401112 ops/training.py:65 2019-01-16 09:05:47.401072: step 2959, loss = 0.72741 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:05:48.363299 ops/training.py:65 2019-01-16 09:05:48.363262: step 2960, loss = 0.73560 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:05:49.324557 ops/training.py:65 2019-01-16 09:05:49.324519: step 2961, loss = 0.75602 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:05:50.285951 ops/training.py:65 2019-01-16 09:05:50.285905: step 2962, loss = 0.73167 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:05:51.245978 ops/training.py:65 2019-01-16 09:05:51.245918: step 2963, loss = 0.64263 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:05:52.205944 ops/training.py:65 2019-01-16 09:05:52.205881: step 2964, loss = 0.71526 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:05:53.165568 ops/training.py:65 2019-01-16 09:05:53.165496: step 2965, loss = 0.71094 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:05:54.124799 ops/training.py:65 2019-01-16 09:05:54.124727: step 2966, loss = 0.68765 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:05:55.084524 ops/training.py:65 2019-01-16 09:05:55.084432: step 2967, loss = 0.71652 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:05:56.043703 ops/training.py:65 2019-01-16 09:05:56.043634: step 2968, loss = 0.72460 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:05:57.003095 ops/training.py:65 2019-01-16 09:05:57.003033: step 2969, loss = 0.70690 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:05:57.967186 ops/training.py:65 2019-01-16 09:05:57.967132: step 2970, loss = 0.61928 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:05:58.929883 ops/training.py:65 2019-01-16 09:05:58.929830: step 2971, loss = 0.69449 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:05:59.891300 ops/training.py:65 2019-01-16 09:05:59.891246: step 2972, loss = 0.70293 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:06:00.852394 ops/training.py:65 2019-01-16 09:06:00.852343: step 2973, loss = 0.67153 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:06:01.813860 ops/training.py:65 2019-01-16 09:06:01.813812: step 2974, loss = 0.73105 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:06:02.775682 ops/training.py:65 2019-01-16 09:06:02.775632: step 2975, loss = 0.71134 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:06:03.736975 ops/training.py:65 2019-01-16 09:06:03.736920: step 2976, loss = 0.65132 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:06:04.698439 ops/training.py:65 2019-01-16 09:06:04.698382: step 2977, loss = 0.69322 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:06:05.659607 ops/training.py:65 2019-01-16 09:06:05.659558: step 2978, loss = 0.72957 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:06:06.621109 ops/training.py:65 2019-01-16 09:06:06.621052: step 2979, loss = 0.68539 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:06:07.582262 ops/training.py:65 2019-01-16 09:06:07.582208: step 2980, loss = 0.67407 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:06:08.543766 ops/training.py:65 2019-01-16 09:06:08.543692: step 2981, loss = 0.69392 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:06:09.504989 ops/training.py:65 2019-01-16 09:06:09.504932: step 2982, loss = 0.72924 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:06:10.469594 ops/training.py:65 2019-01-16 09:06:10.469543: step 2983, loss = 0.69426 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:06:11.434746 ops/training.py:65 2019-01-16 09:06:11.434692: step 2984, loss = 0.76482 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:06:12.398087 ops/training.py:65 2019-01-16 09:06:12.398033: step 2985, loss = 0.68350 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:06:13.361656 ops/training.py:65 2019-01-16 09:06:13.361584: step 2986, loss = 0.70431 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:06:14.326064 ops/training.py:65 2019-01-16 09:06:14.326002: step 2987, loss = 0.69189 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:06:15.289507 ops/training.py:65 2019-01-16 09:06:15.289456: step 2988, loss = 0.73973 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:06:16.250650 ops/training.py:65 2019-01-16 09:06:16.250602: step 2989, loss = 0.73612 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:06:17.212478 ops/training.py:65 2019-01-16 09:06:17.212431: step 2990, loss = 0.63199 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:06:18.174421 ops/training.py:65 2019-01-16 09:06:18.174373: step 2991, loss = 0.76710 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:06:19.135703 ops/training.py:65 2019-01-16 09:06:19.135648: step 2992, loss = 0.70445 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:06:20.100507 ops/training.py:65 2019-01-16 09:06:20.100453: step 2993, loss = 0.71611 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:06:21.061542 ops/training.py:65 2019-01-16 09:06:21.061487: step 2994, loss = 0.70620 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:06:22.025423 ops/training.py:65 2019-01-16 09:06:22.025373: step 2995, loss = 0.67068 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:06:22.989556 ops/training.py:65 2019-01-16 09:06:22.989509: step 2996, loss = 0.68312 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:06:23.951415 ops/training.py:65 2019-01-16 09:06:23.951343: step 2997, loss = 0.72270 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:06:24.912569 ops/training.py:65 2019-01-16 09:06:24.912499: step 2998, loss = 0.68376 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:06:25.873017 ops/training.py:65 2019-01-16 09:06:25.872922: step 2999, loss = 0.69519 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:06:26.835849 ops/training.py:65 2019-01-16 09:06:26.835790: step 3000, loss = 0.71498 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:06:27.799641 ops/training.py:65 2019-01-16 09:06:27.799577: step 3001, loss = 0.68669 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:06:28.763914 ops/training.py:65 2019-01-16 09:06:28.763842: step 3002, loss = 0.74276 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:06:29.726191 ops/training.py:65 2019-01-16 09:06:29.726126: step 3003, loss = 0.69144 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:06:30.689099 ops/training.py:65 2019-01-16 09:06:30.689029: step 3004, loss = 0.73347 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:06:31.654057 ops/training.py:65 2019-01-16 09:06:31.653998: step 3005, loss = 0.67811 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:06:32.615976 ops/training.py:65 2019-01-16 09:06:32.615919: step 3006, loss = 0.73009 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:06:33.580471 ops/training.py:65 2019-01-16 09:06:33.580401: step 3007, loss = 0.69725 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:06:34.543326 ops/training.py:65 2019-01-16 09:06:34.543275: step 3008, loss = 0.71462 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:06:35.508036 ops/training.py:65 2019-01-16 09:06:35.507986: step 3009, loss = 0.70883 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:06:36.471571 ops/training.py:65 2019-01-16 09:06:36.471517: step 3010, loss = 0.69090 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:06:37.435377 ops/training.py:65 2019-01-16 09:06:37.435305: step 3011, loss = 0.69592 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:06:38.398294 ops/training.py:65 2019-01-16 09:06:38.398223: step 3012, loss = 0.72329 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:06:39.360166 ops/training.py:65 2019-01-16 09:06:39.360103: step 3013, loss = 0.68408 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:06:40.321761 ops/training.py:65 2019-01-16 09:06:40.321672: step 3014, loss = 0.69886 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:06:41.282615 ops/training.py:65 2019-01-16 09:06:41.282566: step 3015, loss = 0.68667 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:06:42.244459 ops/training.py:65 2019-01-16 09:06:42.244406: step 3016, loss = 0.65841 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:06:43.206841 ops/training.py:65 2019-01-16 09:06:43.206786: step 3017, loss = 0.69660 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:06:44.173269 ops/training.py:65 2019-01-16 09:06:44.173220: step 3018, loss = 0.70447 (33.1 examples/sec; 0.965 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:06:45.137241 ops/training.py:65 2019-01-16 09:06:45.137190: step 3019, loss = 0.71250 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:06:46.100135 ops/training.py:65 2019-01-16 09:06:46.100067: step 3020, loss = 0.70660 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:06:47.061474 ops/training.py:65 2019-01-16 09:06:47.061399: step 3021, loss = 0.66341 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 09:06:48.024375 ops/training.py:65 2019-01-16 09:06:48.024308: step 3022, loss = 0.67075 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:06:48.986461 ops/training.py:65 2019-01-16 09:06:48.986388: step 3023, loss = 0.73362 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:06:49.950991 ops/training.py:65 2019-01-16 09:06:49.950922: step 3024, loss = 0.67881 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:06:50.913789 ops/training.py:65 2019-01-16 09:06:50.913718: step 3025, loss = 0.71906 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:06:51.876073 ops/training.py:65 2019-01-16 09:06:51.876006: step 3026, loss = 0.70224 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:06:52.838984 ops/training.py:65 2019-01-16 09:06:52.838908: step 3027, loss = 0.71454 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:06:53.803911 ops/training.py:65 2019-01-16 09:06:53.803853: step 3028, loss = 0.69177 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:06:54.766680 ops/training.py:65 2019-01-16 09:06:54.766628: step 3029, loss = 0.71497 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:06:55.730059 ops/training.py:65 2019-01-16 09:06:55.730004: step 3030, loss = 0.70833 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:06:56.692710 ops/training.py:65 2019-01-16 09:06:56.692658: step 3031, loss = 0.68153 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:06:57.654321 ops/training.py:65 2019-01-16 09:06:57.654266: step 3032, loss = 0.70094 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:06:58.615861 ops/training.py:65 2019-01-16 09:06:58.615789: step 3033, loss = 0.66901 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:06:59.580835 ops/training.py:65 2019-01-16 09:06:59.580789: step 3034, loss = 0.69133 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:07:00.544548 ops/training.py:65 2019-01-16 09:07:00.544480: step 3035, loss = 0.68498 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:07:01.507937 ops/training.py:65 2019-01-16 09:07:01.507886: step 3036, loss = 0.69985 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:07:02.471632 ops/training.py:65 2019-01-16 09:07:02.471561: step 3037, loss = 0.69267 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:07:03.432887 ops/training.py:65 2019-01-16 09:07:03.432834: step 3038, loss = 0.71752 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:07:04.394995 ops/training.py:65 2019-01-16 09:07:04.394933: step 3039, loss = 0.69285 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:07:05.358208 ops/training.py:65 2019-01-16 09:07:05.358142: step 3040, loss = 0.71693 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:07:06.321536 ops/training.py:65 2019-01-16 09:07:06.321490: step 3041, loss = 0.68397 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:07:07.284771 ops/training.py:65 2019-01-16 09:07:07.284715: step 3042, loss = 0.69620 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:07:08.246112 ops/training.py:65 2019-01-16 09:07:08.246053: step 3043, loss = 0.70055 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:07:09.207093 ops/training.py:65 2019-01-16 09:07:09.207047: step 3044, loss = 0.67257 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:07:10.167484 ops/training.py:65 2019-01-16 09:07:10.167414: step 3045, loss = 0.69904 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:07:11.128692 ops/training.py:65 2019-01-16 09:07:11.128619: step 3046, loss = 0.70357 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:07:12.092935 ops/training.py:65 2019-01-16 09:07:12.092868: step 3047, loss = 0.68727 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:07:13.056939 ops/training.py:65 2019-01-16 09:07:13.056894: step 3048, loss = 0.68319 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:07:14.018263 ops/training.py:65 2019-01-16 09:07:14.018205: step 3049, loss = 0.66365 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:07:14.981877 ops/training.py:65 2019-01-16 09:07:14.981821: step 3050, loss = 0.70036 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:07:15.944924 ops/training.py:65 2019-01-16 09:07:15.944864: step 3051, loss = 0.70104 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:07:16.907541 ops/training.py:65 2019-01-16 09:07:16.907494: step 3052, loss = 0.68582 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:07:17.869600 ops/training.py:65 2019-01-16 09:07:17.869549: step 3053, loss = 0.70252 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:07:18.831452 ops/training.py:65 2019-01-16 09:07:18.831402: step 3054, loss = 0.69111 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:07:19.793935 ops/training.py:65 2019-01-16 09:07:19.793883: step 3055, loss = 0.70991 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:07:20.755785 ops/training.py:65 2019-01-16 09:07:20.755737: step 3056, loss = 0.68191 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:07:21.716553 ops/training.py:65 2019-01-16 09:07:21.716501: step 3057, loss = 0.73055 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:07:22.677676 ops/training.py:65 2019-01-16 09:07:22.677606: step 3058, loss = 0.71933 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:07:23.639260 ops/training.py:65 2019-01-16 09:07:23.639190: step 3059, loss = 0.66182 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:07:24.600267 ops/training.py:65 2019-01-16 09:07:24.600215: step 3060, loss = 0.69525 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:07:25.561573 ops/training.py:65 2019-01-16 09:07:25.561524: step 3061, loss = 0.71541 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:07:26.523500 ops/training.py:65 2019-01-16 09:07:26.523450: step 3062, loss = 0.70258 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:07:27.485120 ops/training.py:65 2019-01-16 09:07:27.485045: step 3063, loss = 0.71791 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:07:28.446765 ops/training.py:65 2019-01-16 09:07:28.446691: step 3064, loss = 0.71051 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:07:29.408991 ops/training.py:65 2019-01-16 09:07:29.408939: step 3065, loss = 0.68512 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:07:30.373166 ops/training.py:65 2019-01-16 09:07:30.373112: step 3066, loss = 0.66493 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:07:31.337365 ops/training.py:65 2019-01-16 09:07:31.337311: step 3067, loss = 0.67517 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:07:32.301522 ops/training.py:65 2019-01-16 09:07:32.301469: step 3068, loss = 0.69742 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:07:33.262464 ops/training.py:65 2019-01-16 09:07:33.262395: step 3069, loss = 0.74833 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:07:34.224078 ops/training.py:65 2019-01-16 09:07:34.224010: step 3070, loss = 0.70144 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:07:35.188324 ops/training.py:65 2019-01-16 09:07:35.188270: step 3071, loss = 0.63776 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:07:36.152657 ops/training.py:65 2019-01-16 09:07:36.152607: step 3072, loss = 0.66602 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:07:37.115671 ops/training.py:65 2019-01-16 09:07:37.115622: step 3073, loss = 0.67004 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:07:38.077491 ops/training.py:65 2019-01-16 09:07:38.077437: step 3074, loss = 0.72894 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:07:39.038157 ops/training.py:65 2019-01-16 09:07:39.038087: step 3075, loss = 0.68200 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:07:40.002329 ops/training.py:65 2019-01-16 09:07:40.002258: step 3076, loss = 0.70554 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:07:40.963749 ops/training.py:65 2019-01-16 09:07:40.963681: step 3077, loss = 0.73521 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:07:41.923184 ops/training.py:65 2019-01-16 09:07:41.923129: step 3078, loss = 0.70183 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:07:42.889182 ops/training.py:65 2019-01-16 09:07:42.889130: step 3079, loss = 0.71435 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:07:43.854379 ops/training.py:65 2019-01-16 09:07:43.854323: step 3080, loss = 0.70180 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:07:44.818019 ops/training.py:65 2019-01-16 09:07:44.817969: step 3081, loss = 0.70122 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:07:45.780069 ops/training.py:65 2019-01-16 09:07:45.780005: step 3082, loss = 0.67690 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:07:46.741130 ops/training.py:65 2019-01-16 09:07:46.741073: step 3083, loss = 0.70512 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:07:47.700830 ops/training.py:65 2019-01-16 09:07:47.700784: step 3084, loss = 0.68196 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:07:48.661316 ops/training.py:65 2019-01-16 09:07:48.661258: step 3085, loss = 0.72367 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:07:49.625989 ops/training.py:65 2019-01-16 09:07:49.625919: step 3086, loss = 0.66165 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 09:07:50.589284 ops/training.py:65 2019-01-16 09:07:50.589227: step 3087, loss = 0.70951 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:07:51.553059 ops/training.py:65 2019-01-16 09:07:51.553001: step 3088, loss = 0.68663 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:07:52.514739 ops/training.py:65 2019-01-16 09:07:52.514678: step 3089, loss = 0.71444 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:07:53.479399 ops/training.py:65 2019-01-16 09:07:53.479340: step 3090, loss = 0.71874 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:07:54.441924 ops/training.py:65 2019-01-16 09:07:54.441850: step 3091, loss = 0.70540 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:07:55.406238 ops/training.py:65 2019-01-16 09:07:55.406174: step 3092, loss = 0.72305 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:07:56.367762 ops/training.py:65 2019-01-16 09:07:56.367690: step 3093, loss = 0.68100 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:07:57.329176 ops/training.py:65 2019-01-16 09:07:57.329125: step 3094, loss = 0.67775 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:07:58.290448 ops/training.py:65 2019-01-16 09:07:58.290396: step 3095, loss = 0.71397 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:07:59.251286 ops/training.py:65 2019-01-16 09:07:59.251232: step 3096, loss = 0.69074 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:08:00.212446 ops/training.py:65 2019-01-16 09:08:00.212399: step 3097, loss = 0.67459 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:08:01.174322 ops/training.py:65 2019-01-16 09:08:01.174272: step 3098, loss = 0.72888 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:08:02.136032 ops/training.py:65 2019-01-16 09:08:02.135981: step 3099, loss = 0.60357 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 09:08:03.100223 ops/training.py:65 2019-01-16 09:08:03.100169: step 3100, loss = 0.67503 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:08:04.062974 ops/training.py:65 2019-01-16 09:08:04.062921: step 3101, loss = 0.73112 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:08:05.025242 ops/training.py:65 2019-01-16 09:08:05.025189: step 3102, loss = 0.74223 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:08:05.986139 ops/training.py:65 2019-01-16 09:08:05.986089: step 3103, loss = 0.72673 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:08:06.947331 ops/training.py:65 2019-01-16 09:08:06.947282: step 3104, loss = 0.77252 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:08:07.908723 ops/training.py:65 2019-01-16 09:08:07.908670: step 3105, loss = 0.72402 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:08:08.873484 ops/training.py:65 2019-01-16 09:08:08.873428: step 3106, loss = 0.72472 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:08:09.836860 ops/training.py:65 2019-01-16 09:08:09.836811: step 3107, loss = 0.70074 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:08:10.799003 ops/training.py:65 2019-01-16 09:08:10.798943: step 3108, loss = 0.79696 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.25
I0832 2019-01-16 09:08:11.760192 ops/training.py:65 2019-01-16 09:08:11.760126: step 3109, loss = 0.69164 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:08:12.721324 ops/training.py:65 2019-01-16 09:08:12.721258: step 3110, loss = 0.66211 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:08:13.682026 ops/training.py:65 2019-01-16 09:08:13.681959: step 3111, loss = 0.73137 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:08:14.642035 ops/training.py:65 2019-01-16 09:08:14.641970: step 3112, loss = 0.68200 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:08:15.605289 ops/training.py:65 2019-01-16 09:08:15.605226: step 3113, loss = 0.69663 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:08:16.566604 ops/training.py:65 2019-01-16 09:08:16.566553: step 3114, loss = 0.70253 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:08:17.531689 ops/training.py:65 2019-01-16 09:08:17.531626: step 3115, loss = 0.70455 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:08:18.495302 ops/training.py:65 2019-01-16 09:08:18.495236: step 3116, loss = 0.67203 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:08:19.458226 ops/training.py:65 2019-01-16 09:08:19.458175: step 3117, loss = 0.69434 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:08:20.418155 ops/training.py:65 2019-01-16 09:08:20.418081: step 3118, loss = 0.66436 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:08:21.382751 ops/training.py:65 2019-01-16 09:08:21.382681: step 3119, loss = 0.69531 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:08:22.345852 ops/training.py:65 2019-01-16 09:08:22.345784: step 3120, loss = 0.72204 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:08:23.308844 ops/training.py:65 2019-01-16 09:08:23.308776: step 3121, loss = 0.64729 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:08:24.268611 ops/training.py:65 2019-01-16 09:08:24.268529: step 3122, loss = 0.69550 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:08:25.230964 ops/training.py:65 2019-01-16 09:08:25.230895: step 3123, loss = 0.72933 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:08:26.194269 ops/training.py:65 2019-01-16 09:08:26.194202: step 3124, loss = 0.72408 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:08:27.158027 ops/training.py:65 2019-01-16 09:08:27.157957: step 3125, loss = 0.70575 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:08:28.120560 ops/training.py:65 2019-01-16 09:08:28.120507: step 3126, loss = 0.68033 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:08:29.081539 ops/training.py:65 2019-01-16 09:08:29.081489: step 3127, loss = 0.72627 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:08:30.042192 ops/training.py:65 2019-01-16 09:08:30.042141: step 3128, loss = 0.70683 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:08:31.004442 ops/training.py:65 2019-01-16 09:08:31.004390: step 3129, loss = 0.67554 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:08:31.967327 ops/training.py:65 2019-01-16 09:08:31.967286: step 3130, loss = 0.71742 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:08:32.929026 ops/training.py:65 2019-01-16 09:08:32.928956: step 3131, loss = 0.65780 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:08:33.889407 ops/training.py:65 2019-01-16 09:08:33.889333: step 3132, loss = 0.69639 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:08:34.848738 ops/training.py:65 2019-01-16 09:08:34.848669: step 3133, loss = 0.68383 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:08:35.807559 ops/training.py:65 2019-01-16 09:08:35.807495: step 3134, loss = 0.69241 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:08:36.767099 ops/training.py:65 2019-01-16 09:08:36.767036: step 3135, loss = 0.73860 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:08:37.725501 ops/training.py:65 2019-01-16 09:08:37.725437: step 3136, loss = 0.63707 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 09:08:38.687246 ops/training.py:65 2019-01-16 09:08:38.687198: step 3137, loss = 0.71994 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:08:39.651861 ops/training.py:65 2019-01-16 09:08:39.651809: step 3138, loss = 0.74453 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.25
I0832 2019-01-16 09:08:40.613812 ops/training.py:65 2019-01-16 09:08:40.613761: step 3139, loss = 0.67866 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:08:41.573779 ops/training.py:65 2019-01-16 09:08:41.573722: step 3140, loss = 0.74802 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:08:42.534110 ops/training.py:65 2019-01-16 09:08:42.534058: step 3141, loss = 0.69707 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:08:43.498527 ops/training.py:65 2019-01-16 09:08:43.498472: step 3142, loss = 0.67758 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:08:44.462707 ops/training.py:65 2019-01-16 09:08:44.462651: step 3143, loss = 0.69845 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:08:45.424083 ops/training.py:65 2019-01-16 09:08:45.424014: step 3144, loss = 0.69738 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:08:46.384902 ops/training.py:65 2019-01-16 09:08:46.384833: step 3145, loss = 0.72762 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:08:47.349366 ops/training.py:65 2019-01-16 09:08:47.349299: step 3146, loss = 0.77474 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:08:48.313968 ops/training.py:65 2019-01-16 09:08:48.313895: step 3147, loss = 0.82734 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 09:08:49.276712 ops/training.py:65 2019-01-16 09:08:49.276629: step 3148, loss = 0.69871 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:08:50.237904 ops/training.py:65 2019-01-16 09:08:50.237834: step 3149, loss = 0.76310 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:08:51.199241 ops/training.py:65 2019-01-16 09:08:51.199181: step 3150, loss = 0.76857 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:08:52.160264 ops/training.py:65 2019-01-16 09:08:52.160190: step 3151, loss = 0.78044 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:08:53.121794 ops/training.py:65 2019-01-16 09:08:53.121731: step 3152, loss = 0.67486 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:08:54.083314 ops/training.py:65 2019-01-16 09:08:54.083242: step 3153, loss = 0.70878 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:08:55.045680 ops/training.py:65 2019-01-16 09:08:55.045613: step 3154, loss = 0.73676 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:08:56.007143 ops/training.py:65 2019-01-16 09:08:56.007088: step 3155, loss = 0.65104 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:08:56.967829 ops/training.py:65 2019-01-16 09:08:56.967766: step 3156, loss = 0.71699 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:08:57.932687 ops/training.py:65 2019-01-16 09:08:57.932629: step 3157, loss = 0.70189 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:08:58.894766 ops/training.py:65 2019-01-16 09:08:58.894698: step 3158, loss = 0.72762 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:08:59.857489 ops/training.py:65 2019-01-16 09:08:59.857436: step 3159, loss = 0.74533 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:09:00.823001 ops/training.py:65 2019-01-16 09:09:00.822932: step 3160, loss = 0.69004 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:09:01.785433 ops/training.py:65 2019-01-16 09:09:01.785369: step 3161, loss = 0.68341 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:09:02.748588 ops/training.py:65 2019-01-16 09:09:02.748531: step 3162, loss = 0.79297 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:09:03.711278 ops/training.py:65 2019-01-16 09:09:03.711205: step 3163, loss = 0.67544 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:09:04.674692 ops/training.py:65 2019-01-16 09:09:04.674630: step 3164, loss = 0.66152 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:09:05.638601 ops/training.py:65 2019-01-16 09:09:05.638536: step 3165, loss = 0.75871 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:09:06.601682 ops/training.py:65 2019-01-16 09:09:06.601618: step 3166, loss = 0.73790 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:09:07.564594 ops/training.py:65 2019-01-16 09:09:07.564530: step 3167, loss = 0.71751 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:09:08.529438 ops/training.py:65 2019-01-16 09:09:08.529381: step 3168, loss = 0.67560 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:09:09.490339 ops/training.py:65 2019-01-16 09:09:09.490283: step 3169, loss = 0.76166 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:09:10.450793 ops/training.py:65 2019-01-16 09:09:10.450744: step 3170, loss = 0.68798 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:09:11.411224 ops/training.py:65 2019-01-16 09:09:11.411166: step 3171, loss = 0.65152 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:09:12.371413 ops/training.py:65 2019-01-16 09:09:12.371352: step 3172, loss = 0.65858 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:09:13.331377 ops/training.py:65 2019-01-16 09:09:13.331318: step 3173, loss = 0.70707 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:09:14.291220 ops/training.py:65 2019-01-16 09:09:14.291160: step 3174, loss = 0.64052 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:09:15.251969 ops/training.py:65 2019-01-16 09:09:15.251909: step 3175, loss = 0.73932 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:09:16.212354 ops/training.py:65 2019-01-16 09:09:16.212287: step 3176, loss = 0.68956 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:09:17.177443 ops/training.py:65 2019-01-16 09:09:17.177391: step 3177, loss = 0.70060 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:09:18.139201 ops/training.py:65 2019-01-16 09:09:18.139135: step 3178, loss = 0.74231 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:09:19.101159 ops/training.py:65 2019-01-16 09:09:19.101099: step 3179, loss = 0.72964 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:09:20.062901 ops/training.py:65 2019-01-16 09:09:20.062853: step 3180, loss = 0.70866 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:09:21.024646 ops/training.py:65 2019-01-16 09:09:21.024574: step 3181, loss = 0.70310 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:09:21.986047 ops/training.py:65 2019-01-16 09:09:21.985980: step 3182, loss = 0.68675 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:09:22.947457 ops/training.py:65 2019-01-16 09:09:22.947385: step 3183, loss = 0.70067 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:09:23.910423 ops/training.py:65 2019-01-16 09:09:23.910352: step 3184, loss = 0.68747 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:09:24.872803 ops/training.py:65 2019-01-16 09:09:24.872730: step 3185, loss = 0.66475 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:09:25.834330 ops/training.py:65 2019-01-16 09:09:25.834268: step 3186, loss = 0.66296 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:09:26.795938 ops/training.py:65 2019-01-16 09:09:26.795894: step 3187, loss = 0.70954 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:09:27.757005 ops/training.py:65 2019-01-16 09:09:27.756948: step 3188, loss = 0.70627 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:09:28.719351 ops/training.py:65 2019-01-16 09:09:28.719294: step 3189, loss = 0.68283 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:09:29.680973 ops/training.py:65 2019-01-16 09:09:29.680915: step 3190, loss = 0.68070 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:09:30.642716 ops/training.py:65 2019-01-16 09:09:30.642657: step 3191, loss = 0.67364 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:09:31.604517 ops/training.py:65 2019-01-16 09:09:31.604463: step 3192, loss = 0.71494 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:09:32.565566 ops/training.py:65 2019-01-16 09:09:32.565506: step 3193, loss = 0.68225 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:09:33.526501 ops/training.py:65 2019-01-16 09:09:33.526437: step 3194, loss = 0.69724 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:09:34.487728 ops/training.py:65 2019-01-16 09:09:34.487673: step 3195, loss = 0.66811 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:09:35.449290 ops/training.py:65 2019-01-16 09:09:35.449225: step 3196, loss = 0.71686 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:09:36.410861 ops/training.py:65 2019-01-16 09:09:36.410804: step 3197, loss = 0.71153 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:09:37.372385 ops/training.py:65 2019-01-16 09:09:37.372317: step 3198, loss = 0.69236 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:09:38.333589 ops/training.py:65 2019-01-16 09:09:38.333531: step 3199, loss = 0.72516 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:09:39.294910 ops/training.py:65 2019-01-16 09:09:39.294844: step 3200, loss = 0.73709 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:09:40.255880 ops/training.py:65 2019-01-16 09:09:40.255812: step 3201, loss = 0.63744 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:09:41.219960 ops/training.py:65 2019-01-16 09:09:41.219909: step 3202, loss = 0.74020 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:09:42.183430 ops/training.py:65 2019-01-16 09:09:42.183376: step 3203, loss = 0.68123 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:09:43.144177 ops/training.py:65 2019-01-16 09:09:43.144129: step 3204, loss = 0.65759 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:09:44.108290 ops/training.py:65 2019-01-16 09:09:44.108232: step 3205, loss = 0.70100 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:09:45.070357 ops/training.py:65 2019-01-16 09:09:45.070302: step 3206, loss = 0.66135 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:09:46.031820 ops/training.py:65 2019-01-16 09:09:46.031754: step 3207, loss = 0.67005 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:09:46.993048 ops/training.py:65 2019-01-16 09:09:46.992992: step 3208, loss = 0.68722 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:09:47.954835 ops/training.py:65 2019-01-16 09:09:47.954769: step 3209, loss = 0.66780 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:09:48.916259 ops/training.py:65 2019-01-16 09:09:48.916190: step 3210, loss = 0.75756 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.25
I0832 2019-01-16 09:09:49.878166 ops/training.py:65 2019-01-16 09:09:49.878103: step 3211, loss = 0.68204 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:09:50.839248 ops/training.py:65 2019-01-16 09:09:50.839194: step 3212, loss = 0.71924 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:09:51.800908 ops/training.py:65 2019-01-16 09:09:51.800853: step 3213, loss = 0.71941 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:09:52.765525 ops/training.py:65 2019-01-16 09:09:52.765453: step 3214, loss = 0.68696 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:09:53.729485 ops/training.py:65 2019-01-16 09:09:53.729413: step 3215, loss = 0.69582 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:09:54.693031 ops/training.py:65 2019-01-16 09:09:54.692979: step 3216, loss = 0.68896 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:09:55.656084 ops/training.py:65 2019-01-16 09:09:55.656032: step 3217, loss = 0.69372 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:09:56.617009 ops/training.py:65 2019-01-16 09:09:56.616948: step 3218, loss = 0.68795 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:09:57.579040 ops/training.py:65 2019-01-16 09:09:57.578966: step 3219, loss = 0.67117 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:09:58.543759 ops/training.py:65 2019-01-16 09:09:58.543689: step 3220, loss = 0.66321 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:09:59.505470 ops/training.py:65 2019-01-16 09:09:59.505399: step 3221, loss = 0.71139 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:10:00.466403 ops/training.py:65 2019-01-16 09:10:00.466351: step 3222, loss = 0.72454 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:10:01.429519 ops/training.py:65 2019-01-16 09:10:01.429460: step 3223, loss = 0.74377 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:10:02.392569 ops/training.py:65 2019-01-16 09:10:02.392509: step 3224, loss = 0.68113 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:10:03.355767 ops/training.py:65 2019-01-16 09:10:03.355697: step 3225, loss = 0.69293 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:10:04.321227 ops/training.py:65 2019-01-16 09:10:04.321157: step 3226, loss = 0.75722 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:10:05.284744 ops/training.py:65 2019-01-16 09:10:05.284673: step 3227, loss = 0.66433 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:10:06.247151 ops/training.py:65 2019-01-16 09:10:06.247097: step 3228, loss = 0.72335 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:10:07.207876 ops/training.py:65 2019-01-16 09:10:07.207824: step 3229, loss = 0.70213 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:10:08.169735 ops/training.py:65 2019-01-16 09:10:08.169683: step 3230, loss = 0.67065 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:10:09.131419 ops/training.py:65 2019-01-16 09:10:09.131365: step 3231, loss = 0.68686 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:10:10.092521 ops/training.py:65 2019-01-16 09:10:10.092469: step 3232, loss = 0.69639 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:10:11.052908 ops/training.py:65 2019-01-16 09:10:11.052850: step 3233, loss = 0.70143 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:10:12.013141 ops/training.py:65 2019-01-16 09:10:12.013052: step 3234, loss = 0.68585 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:10:12.972183 ops/training.py:65 2019-01-16 09:10:12.972122: step 3235, loss = 0.68498 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:10:13.930377 ops/training.py:65 2019-01-16 09:10:13.930307: step 3236, loss = 0.65552 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:10:14.893214 ops/training.py:65 2019-01-16 09:10:14.893167: step 3237, loss = 0.66744 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:10:15.857105 ops/training.py:65 2019-01-16 09:10:15.857050: step 3238, loss = 0.69877 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:10:16.821021 ops/training.py:65 2019-01-16 09:10:16.820962: step 3239, loss = 0.68515 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:10:17.782823 ops/training.py:65 2019-01-16 09:10:17.782776: step 3240, loss = 0.69046 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:10:18.744173 ops/training.py:65 2019-01-16 09:10:18.744102: step 3241, loss = 0.72028 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:10:19.706078 ops/training.py:65 2019-01-16 09:10:19.706006: step 3242, loss = 0.66582 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:10:20.667244 ops/training.py:65 2019-01-16 09:10:20.667183: step 3243, loss = 0.69304 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:10:21.629870 ops/training.py:65 2019-01-16 09:10:21.629797: step 3244, loss = 0.69242 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:10:22.591765 ops/training.py:65 2019-01-16 09:10:22.591696: step 3245, loss = 0.73001 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:10:23.554395 ops/training.py:65 2019-01-16 09:10:23.554325: step 3246, loss = 0.68868 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:10:24.516569 ops/training.py:65 2019-01-16 09:10:24.516521: step 3247, loss = 0.67621 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:10:25.478980 ops/training.py:65 2019-01-16 09:10:25.478928: step 3248, loss = 0.72103 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:10:26.441444 ops/training.py:65 2019-01-16 09:10:26.441386: step 3249, loss = 0.74244 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:10:27.404007 ops/training.py:65 2019-01-16 09:10:27.403953: step 3250, loss = 0.72900 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:10:28.366283 ops/training.py:65 2019-01-16 09:10:28.366215: step 3251, loss = 0.67552 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:10:29.327917 ops/training.py:65 2019-01-16 09:10:29.327852: step 3252, loss = 0.71096 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:10:30.288028 ops/training.py:65 2019-01-16 09:10:30.287981: step 3253, loss = 0.72230 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:10:31.252214 ops/training.py:65 2019-01-16 09:10:31.252166: step 3254, loss = 0.68255 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:10:32.215336 ops/training.py:65 2019-01-16 09:10:32.215286: step 3255, loss = 0.68826 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:10:33.178161 ops/training.py:65 2019-01-16 09:10:33.178109: step 3256, loss = 0.68244 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:10:34.140853 ops/training.py:65 2019-01-16 09:10:34.140782: step 3257, loss = 0.72428 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:10:35.103119 ops/training.py:65 2019-01-16 09:10:35.103047: step 3258, loss = 0.68612 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:10:36.067763 ops/training.py:65 2019-01-16 09:10:36.067696: step 3259, loss = 0.71910 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:10:37.031481 ops/training.py:65 2019-01-16 09:10:37.031426: step 3260, loss = 0.72343 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:10:37.995040 ops/training.py:65 2019-01-16 09:10:37.994983: step 3261, loss = 0.67531 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:10:38.956028 ops/training.py:65 2019-01-16 09:10:38.955968: step 3262, loss = 0.69445 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:10:39.917088 ops/training.py:65 2019-01-16 09:10:39.917031: step 3263, loss = 0.68144 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:10:40.878703 ops/training.py:65 2019-01-16 09:10:40.878643: step 3264, loss = 0.71458 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:10:41.840678 ops/training.py:65 2019-01-16 09:10:41.840625: step 3265, loss = 0.71854 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:10:42.802323 ops/training.py:65 2019-01-16 09:10:42.802251: step 3266, loss = 0.69087 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:10:43.764085 ops/training.py:65 2019-01-16 09:10:43.764017: step 3267, loss = 0.66695 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:10:44.725573 ops/training.py:65 2019-01-16 09:10:44.725503: step 3268, loss = 0.68530 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:10:45.688399 ops/training.py:65 2019-01-16 09:10:45.688348: step 3269, loss = 0.73015 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:10:46.651270 ops/training.py:65 2019-01-16 09:10:46.651222: step 3270, loss = 0.70299 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:10:47.613741 ops/training.py:65 2019-01-16 09:10:47.613691: step 3271, loss = 0.69475 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:10:48.574864 ops/training.py:65 2019-01-16 09:10:48.574814: step 3272, loss = 0.71071 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:10:49.536712 ops/training.py:65 2019-01-16 09:10:49.536664: step 3273, loss = 0.68861 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:10:50.498990 ops/training.py:65 2019-01-16 09:10:50.498909: step 3274, loss = 0.73317 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:10:51.460450 ops/training.py:65 2019-01-16 09:10:51.460381: step 3275, loss = 0.67482 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:10:52.421288 ops/training.py:65 2019-01-16 09:10:52.421216: step 3276, loss = 0.70576 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:10:53.383026 ops/training.py:65 2019-01-16 09:10:53.382954: step 3277, loss = 0.70717 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:10:54.342602 ops/training.py:65 2019-01-16 09:10:54.342536: step 3278, loss = 0.73468 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:10:55.305941 ops/training.py:65 2019-01-16 09:10:55.305890: step 3279, loss = 0.72866 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:10:56.268522 ops/training.py:65 2019-01-16 09:10:56.268472: step 3280, loss = 0.72224 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:10:57.231196 ops/training.py:65 2019-01-16 09:10:57.231145: step 3281, loss = 0.68423 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:10:58.192963 ops/training.py:65 2019-01-16 09:10:58.192913: step 3282, loss = 0.71526 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:10:59.154741 ops/training.py:65 2019-01-16 09:10:59.154686: step 3283, loss = 0.67338 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:11:00.119823 ops/training.py:65 2019-01-16 09:11:00.119771: step 3284, loss = 0.72231 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:11:01.083628 ops/training.py:65 2019-01-16 09:11:01.083579: step 3285, loss = 0.70606 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:11:02.048133 ops/training.py:65 2019-01-16 09:11:02.048084: step 3286, loss = 0.65504 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:11:03.009621 ops/training.py:65 2019-01-16 09:11:03.009568: step 3287, loss = 0.69422 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:11:03.971994 ops/training.py:65 2019-01-16 09:11:03.971940: step 3288, loss = 0.69843 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:11:04.933597 ops/training.py:65 2019-01-16 09:11:04.933544: step 3289, loss = 0.70479 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:11:05.895548 ops/training.py:65 2019-01-16 09:11:05.895495: step 3290, loss = 0.73844 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:11:06.857406 ops/training.py:65 2019-01-16 09:11:06.857359: step 3291, loss = 0.72815 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:11:07.819203 ops/training.py:65 2019-01-16 09:11:07.819151: step 3292, loss = 0.68304 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:11:08.782215 ops/training.py:65 2019-01-16 09:11:08.782156: step 3293, loss = 0.72400 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:11:09.743875 ops/training.py:65 2019-01-16 09:11:09.743813: step 3294, loss = 0.69459 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:11:10.705027 ops/training.py:65 2019-01-16 09:11:10.704956: step 3295, loss = 0.70034 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:11:11.667523 ops/training.py:65 2019-01-16 09:11:11.667485: step 3296, loss = 0.66024 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:11:12.630168 ops/training.py:65 2019-01-16 09:11:12.630099: step 3297, loss = 0.73365 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:11:13.595697 ops/training.py:65 2019-01-16 09:11:13.595631: step 3298, loss = 0.70037 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:11:14.560370 ops/training.py:65 2019-01-16 09:11:14.560309: step 3299, loss = 0.69840 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:11:15.522132 ops/training.py:65 2019-01-16 09:11:15.522070: step 3300, loss = 0.69522 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:11:16.481457 ops/training.py:65 2019-01-16 09:11:16.481388: step 3301, loss = 0.71067 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:11:17.444272 ops/training.py:65 2019-01-16 09:11:17.444221: step 3302, loss = 0.68907 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:11:18.408046 ops/training.py:65 2019-01-16 09:11:18.407991: step 3303, loss = 0.69115 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:11:19.369864 ops/training.py:65 2019-01-16 09:11:19.369811: step 3304, loss = 0.69637 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:11:20.329647 ops/training.py:65 2019-01-16 09:11:20.329596: step 3305, loss = 0.72233 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:11:21.290296 ops/training.py:65 2019-01-16 09:11:21.290245: step 3306, loss = 0.69358 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:11:22.254860 ops/training.py:65 2019-01-16 09:11:22.254790: step 3307, loss = 0.70851 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:11:23.218740 ops/training.py:65 2019-01-16 09:11:23.218674: step 3308, loss = 0.68090 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:11:24.180034 ops/training.py:65 2019-01-16 09:11:24.179964: step 3309, loss = 0.68366 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:11:25.140915 ops/training.py:65 2019-01-16 09:11:25.140861: step 3310, loss = 0.70928 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:11:26.105151 ops/training.py:65 2019-01-16 09:11:26.105100: step 3311, loss = 0.69454 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:11:27.067891 ops/training.py:65 2019-01-16 09:11:27.067839: step 3312, loss = 0.68436 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:11:28.031709 ops/training.py:65 2019-01-16 09:11:28.031655: step 3313, loss = 0.70488 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:11:28.994287 ops/training.py:65 2019-01-16 09:11:28.994228: step 3314, loss = 0.67640 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:11:29.955708 ops/training.py:65 2019-01-16 09:11:29.955657: step 3315, loss = 0.68611 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:11:30.916670 ops/training.py:65 2019-01-16 09:11:30.916618: step 3316, loss = 0.68585 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:11:31.878893 ops/training.py:65 2019-01-16 09:11:31.878840: step 3317, loss = 0.72977 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:11:32.839231 ops/training.py:65 2019-01-16 09:11:32.839177: step 3318, loss = 0.65850 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:11:33.802275 ops/training.py:65 2019-01-16 09:11:33.802224: step 3319, loss = 0.69637 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:11:34.764342 ops/training.py:65 2019-01-16 09:11:34.764270: step 3320, loss = 0.69163 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:11:35.725299 ops/training.py:65 2019-01-16 09:11:35.725244: step 3321, loss = 0.69189 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:11:36.686345 ops/training.py:65 2019-01-16 09:11:36.686274: step 3322, loss = 0.70462 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:11:37.648885 ops/training.py:65 2019-01-16 09:11:37.648837: step 3323, loss = 0.70754 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:11:38.613131 ops/training.py:65 2019-01-16 09:11:38.613078: step 3324, loss = 0.66400 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:11:39.576231 ops/training.py:65 2019-01-16 09:11:39.576179: step 3325, loss = 0.69799 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:11:40.537237 ops/training.py:65 2019-01-16 09:11:40.537168: step 3326, loss = 0.66276 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:11:41.497756 ops/training.py:65 2019-01-16 09:11:41.497686: step 3327, loss = 0.71233 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:11:42.458491 ops/training.py:65 2019-01-16 09:11:42.458424: step 3328, loss = 0.69410 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:11:43.419703 ops/training.py:65 2019-01-16 09:11:43.419650: step 3329, loss = 0.70365 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:11:44.381080 ops/training.py:65 2019-01-16 09:11:44.381026: step 3330, loss = 0.72274 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:11:45.342608 ops/training.py:65 2019-01-16 09:11:45.342545: step 3331, loss = 0.71010 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:11:46.307548 ops/training.py:65 2019-01-16 09:11:46.307482: step 3332, loss = 0.69099 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:11:47.268313 ops/training.py:65 2019-01-16 09:11:47.268219: step 3333, loss = 0.67517 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:11:48.233825 ops/training.py:65 2019-01-16 09:11:48.233755: step 3334, loss = 0.64894 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:11:49.197316 ops/training.py:65 2019-01-16 09:11:49.197250: step 3335, loss = 0.72824 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:11:50.160098 ops/training.py:65 2019-01-16 09:11:50.160029: step 3336, loss = 0.68994 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:11:51.122226 ops/training.py:65 2019-01-16 09:11:51.122156: step 3337, loss = 0.69400 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:11:52.083973 ops/training.py:65 2019-01-16 09:11:52.083906: step 3338, loss = 0.68712 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:11:53.045808 ops/training.py:65 2019-01-16 09:11:53.045744: step 3339, loss = 0.76127 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.21875
I0832 2019-01-16 09:11:54.007334 ops/training.py:65 2019-01-16 09:11:54.007262: step 3340, loss = 0.73297 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:11:54.971685 ops/training.py:65 2019-01-16 09:11:54.971632: step 3341, loss = 0.66300 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:11:55.934423 ops/training.py:65 2019-01-16 09:11:55.934370: step 3342, loss = 0.68672 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:11:56.898030 ops/training.py:65 2019-01-16 09:11:56.897960: step 3343, loss = 0.69598 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:11:57.858996 ops/training.py:65 2019-01-16 09:11:57.858939: step 3344, loss = 0.71305 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:11:58.820357 ops/training.py:65 2019-01-16 09:11:58.820300: step 3345, loss = 0.72304 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:11:59.781301 ops/training.py:65 2019-01-16 09:11:59.781228: step 3346, loss = 0.72507 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:12:00.743013 ops/training.py:65 2019-01-16 09:12:00.742956: step 3347, loss = 0.69487 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:12:01.707807 ops/training.py:65 2019-01-16 09:12:01.707741: step 3348, loss = 0.70623 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:12:02.670089 ops/training.py:65 2019-01-16 09:12:02.670021: step 3349, loss = 0.66806 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:12:03.633418 ops/training.py:65 2019-01-16 09:12:03.633366: step 3350, loss = 0.72381 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:12:04.594737 ops/training.py:65 2019-01-16 09:12:04.594681: step 3351, loss = 0.73797 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:12:05.555671 ops/training.py:65 2019-01-16 09:12:05.555616: step 3352, loss = 0.68404 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:12:06.516981 ops/training.py:65 2019-01-16 09:12:06.516928: step 3353, loss = 0.70957 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:12:07.478562 ops/training.py:65 2019-01-16 09:12:07.478507: step 3354, loss = 0.72122 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:12:08.440172 ops/training.py:65 2019-01-16 09:12:08.440121: step 3355, loss = 0.74032 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:12:09.404973 ops/training.py:65 2019-01-16 09:12:09.404921: step 3356, loss = 0.69574 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:12:10.367660 ops/training.py:65 2019-01-16 09:12:10.367609: step 3357, loss = 0.71798 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:12:11.332735 ops/training.py:65 2019-01-16 09:12:11.332678: step 3358, loss = 0.69888 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:12:12.296602 ops/training.py:65 2019-01-16 09:12:12.296546: step 3359, loss = 0.73053 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:12:13.257819 ops/training.py:65 2019-01-16 09:12:13.257757: step 3360, loss = 0.69684 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:12:14.219497 ops/training.py:65 2019-01-16 09:12:14.219444: step 3361, loss = 0.69386 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:12:15.180825 ops/training.py:65 2019-01-16 09:12:15.180760: step 3362, loss = 0.68938 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:12:16.142878 ops/training.py:65 2019-01-16 09:12:16.142814: step 3363, loss = 0.79554 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:12:17.103771 ops/training.py:65 2019-01-16 09:12:17.103706: step 3364, loss = 0.73328 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:12:18.064286 ops/training.py:65 2019-01-16 09:12:18.064238: step 3365, loss = 0.64323 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:12:19.027057 ops/training.py:65 2019-01-16 09:12:19.026995: step 3366, loss = 0.69200 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:12:19.993036 ops/training.py:65 2019-01-16 09:12:19.992974: step 3367, loss = 0.70693 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:12:20.956870 ops/training.py:65 2019-01-16 09:12:20.956809: step 3368, loss = 0.71128 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:12:21.920522 ops/training.py:65 2019-01-16 09:12:21.920457: step 3369, loss = 0.76064 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:12:22.883046 ops/training.py:65 2019-01-16 09:12:22.882997: step 3370, loss = 0.70425 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:12:23.845703 ops/training.py:65 2019-01-16 09:12:23.845640: step 3371, loss = 0.69601 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:12:24.807847 ops/training.py:65 2019-01-16 09:12:24.807785: step 3372, loss = 0.68768 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:12:25.770209 ops/training.py:65 2019-01-16 09:12:25.770147: step 3373, loss = 0.66789 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:12:26.732591 ops/training.py:65 2019-01-16 09:12:26.732529: step 3374, loss = 0.68524 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:12:27.694460 ops/training.py:65 2019-01-16 09:12:27.694408: step 3375, loss = 0.63277 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:12:28.655203 ops/training.py:65 2019-01-16 09:12:28.655150: step 3376, loss = 0.64904 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:12:29.619636 ops/training.py:65 2019-01-16 09:12:29.619577: step 3377, loss = 0.78955 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:12:30.581950 ops/training.py:65 2019-01-16 09:12:30.581886: step 3378, loss = 0.75772 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:12:31.542921 ops/training.py:65 2019-01-16 09:12:31.542856: step 3379, loss = 0.75230 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:12:32.508539 ops/training.py:65 2019-01-16 09:12:32.508464: step 3380, loss = 0.69463 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:12:33.470825 ops/training.py:65 2019-01-16 09:12:33.470756: step 3381, loss = 0.63805 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:12:34.432368 ops/training.py:65 2019-01-16 09:12:34.432312: step 3382, loss = 0.65188 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:12:35.393990 ops/training.py:65 2019-01-16 09:12:35.393923: step 3383, loss = 0.72330 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:12:36.354777 ops/training.py:65 2019-01-16 09:12:36.354725: step 3384, loss = 0.76735 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:12:37.315063 ops/training.py:65 2019-01-16 09:12:37.315010: step 3385, loss = 0.70752 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:12:38.279955 ops/training.py:65 2019-01-16 09:12:38.279902: step 3386, loss = 0.72105 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:12:39.244246 ops/training.py:65 2019-01-16 09:12:39.244171: step 3387, loss = 0.83522 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:12:40.206419 ops/training.py:65 2019-01-16 09:12:40.206326: step 3388, loss = 0.73291 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:12:41.171852 ops/training.py:65 2019-01-16 09:12:41.171786: step 3389, loss = 0.67804 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:12:42.136389 ops/training.py:65 2019-01-16 09:12:42.136325: step 3390, loss = 0.70498 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:12:43.100487 ops/training.py:65 2019-01-16 09:12:43.100423: step 3391, loss = 0.69027 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:12:44.060594 ops/training.py:65 2019-01-16 09:12:44.060528: step 3392, loss = 0.68261 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:12:45.025882 ops/training.py:65 2019-01-16 09:12:45.025801: step 3393, loss = 0.70426 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:12:45.990075 ops/training.py:65 2019-01-16 09:12:45.990009: step 3394, loss = 0.74870 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:12:46.953324 ops/training.py:65 2019-01-16 09:12:46.953246: step 3395, loss = 0.66692 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:12:47.915204 ops/training.py:65 2019-01-16 09:12:47.915129: step 3396, loss = 0.74083 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:12:48.878365 ops/training.py:65 2019-01-16 09:12:48.878304: step 3397, loss = 0.75006 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:12:49.838538 ops/training.py:65 2019-01-16 09:12:49.838480: step 3398, loss = 0.75687 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:12:50.798587 ops/training.py:65 2019-01-16 09:12:50.798519: step 3399, loss = 0.64418 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:12:51.758446 ops/training.py:65 2019-01-16 09:12:51.758380: step 3400, loss = 0.70392 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:12:52.718214 ops/training.py:65 2019-01-16 09:12:52.718148: step 3401, loss = 0.72380 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:12:53.678819 ops/training.py:65 2019-01-16 09:12:53.678749: step 3402, loss = 0.71037 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:12:54.642652 ops/training.py:65 2019-01-16 09:12:54.642579: step 3403, loss = 0.69543 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:12:55.605998 ops/training.py:65 2019-01-16 09:12:55.605937: step 3404, loss = 0.74281 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:12:56.567334 ops/training.py:65 2019-01-16 09:12:56.567265: step 3405, loss = 0.72106 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:12:57.528975 ops/training.py:65 2019-01-16 09:12:57.528905: step 3406, loss = 0.76068 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:12:58.489157 ops/training.py:65 2019-01-16 09:12:58.489103: step 3407, loss = 0.73036 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:12:59.454118 ops/training.py:65 2019-01-16 09:12:59.454052: step 3408, loss = 0.68554 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:13:00.415277 ops/training.py:65 2019-01-16 09:13:00.415210: step 3409, loss = 0.69475 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:13:01.380069 ops/training.py:65 2019-01-16 09:13:01.379998: step 3410, loss = 0.76225 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:13:02.344009 ops/training.py:65 2019-01-16 09:13:02.343941: step 3411, loss = 0.71574 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:13:03.306423 ops/training.py:65 2019-01-16 09:13:03.306365: step 3412, loss = 0.72392 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:13:04.267760 ops/training.py:65 2019-01-16 09:13:04.267704: step 3413, loss = 0.70431 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:13:05.229609 ops/training.py:65 2019-01-16 09:13:05.229538: step 3414, loss = 0.72102 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:13:06.191330 ops/training.py:65 2019-01-16 09:13:06.191259: step 3415, loss = 0.72631 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:13:07.152179 ops/training.py:65 2019-01-16 09:13:07.152112: step 3416, loss = 0.74235 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:13:08.112848 ops/training.py:65 2019-01-16 09:13:08.112800: step 3417, loss = 0.74525 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 09:13:09.073138 ops/training.py:65 2019-01-16 09:13:09.073092: step 3418, loss = 0.71689 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:13:10.037597 ops/training.py:65 2019-01-16 09:13:10.037550: step 3419, loss = 0.68105 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:13:11.001453 ops/training.py:65 2019-01-16 09:13:11.001408: step 3420, loss = 0.70669 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:13:11.965157 ops/training.py:65 2019-01-16 09:13:11.965112: step 3421, loss = 0.70010 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:13:12.927428 ops/training.py:65 2019-01-16 09:13:12.927384: step 3422, loss = 0.67461 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:13:13.888600 ops/training.py:65 2019-01-16 09:13:13.888563: step 3423, loss = 0.71346 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:13:14.849982 ops/training.py:65 2019-01-16 09:13:14.849933: step 3424, loss = 0.68880 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:13:15.811169 ops/training.py:65 2019-01-16 09:13:15.811118: step 3425, loss = 0.70813 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:13:16.772726 ops/training.py:65 2019-01-16 09:13:16.772678: step 3426, loss = 0.67751 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:13:17.733510 ops/training.py:65 2019-01-16 09:13:17.733463: step 3427, loss = 0.69847 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:13:18.695774 ops/training.py:65 2019-01-16 09:13:18.695736: step 3428, loss = 0.68274 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:13:19.660649 ops/training.py:65 2019-01-16 09:13:19.660601: step 3429, loss = 0.71074 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:13:20.625659 ops/training.py:65 2019-01-16 09:13:20.625617: step 3430, loss = 0.69002 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:13:21.588898 ops/training.py:65 2019-01-16 09:13:21.588858: step 3431, loss = 0.72780 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:13:22.551264 ops/training.py:65 2019-01-16 09:13:22.551224: step 3432, loss = 0.71376 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:13:23.515596 ops/training.py:65 2019-01-16 09:13:23.515551: step 3433, loss = 0.68998 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:13:24.477121 ops/training.py:65 2019-01-16 09:13:24.477077: step 3434, loss = 0.71248 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:13:25.442058 ops/training.py:65 2019-01-16 09:13:25.442015: step 3435, loss = 0.70540 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:13:26.405949 ops/training.py:65 2019-01-16 09:13:26.405896: step 3436, loss = 0.72531 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:13:27.369144 ops/training.py:65 2019-01-16 09:13:27.369095: step 3437, loss = 0.67783 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:13:28.330845 ops/training.py:65 2019-01-16 09:13:28.330796: step 3438, loss = 0.70062 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:13:29.291009 ops/training.py:65 2019-01-16 09:13:29.290939: step 3439, loss = 0.70884 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:13:30.255199 ops/training.py:65 2019-01-16 09:13:30.255143: step 3440, loss = 0.67422 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:13:31.218523 ops/training.py:65 2019-01-16 09:13:31.218468: step 3441, loss = 0.70211 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:13:32.180660 ops/training.py:65 2019-01-16 09:13:32.180599: step 3442, loss = 0.68095 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:13:33.145201 ops/training.py:65 2019-01-16 09:13:33.145144: step 3443, loss = 0.70717 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:13:34.107419 ops/training.py:65 2019-01-16 09:13:34.107362: step 3444, loss = 0.69381 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:13:35.068688 ops/training.py:65 2019-01-16 09:13:35.068635: step 3445, loss = 0.67985 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:13:36.029819 ops/training.py:65 2019-01-16 09:13:36.029762: step 3446, loss = 0.70852 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:13:36.991760 ops/training.py:65 2019-01-16 09:13:36.991705: step 3447, loss = 0.67481 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:13:37.952644 ops/training.py:65 2019-01-16 09:13:37.952595: step 3448, loss = 0.70450 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:13:38.912184 ops/training.py:65 2019-01-16 09:13:38.912129: step 3449, loss = 0.67895 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:13:39.873457 ops/training.py:65 2019-01-16 09:13:39.873407: step 3450, loss = 0.70678 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:13:40.837687 ops/training.py:65 2019-01-16 09:13:40.837647: step 3451, loss = 0.65742 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:13:41.800078 ops/training.py:65 2019-01-16 09:13:41.800027: step 3452, loss = 0.70265 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:13:42.762600 ops/training.py:65 2019-01-16 09:13:42.762548: step 3453, loss = 0.69458 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:13:43.724170 ops/training.py:65 2019-01-16 09:13:43.724115: step 3454, loss = 0.69089 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:13:44.685904 ops/training.py:65 2019-01-16 09:13:44.685851: step 3455, loss = 0.69789 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:13:45.646397 ops/training.py:65 2019-01-16 09:13:45.646348: step 3456, loss = 0.69951 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:13:46.607232 ops/training.py:65 2019-01-16 09:13:46.607177: step 3457, loss = 0.68793 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:13:47.568232 ops/training.py:65 2019-01-16 09:13:47.568179: step 3458, loss = 0.69727 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:13:48.529303 ops/training.py:65 2019-01-16 09:13:48.529237: step 3459, loss = 0.72026 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:13:49.490887 ops/training.py:65 2019-01-16 09:13:49.490834: step 3460, loss = 0.69131 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:13:50.450731 ops/training.py:65 2019-01-16 09:13:50.450665: step 3461, loss = 0.71984 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:13:51.409483 ops/training.py:65 2019-01-16 09:13:51.409410: step 3462, loss = 0.71380 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:13:52.368513 ops/training.py:65 2019-01-16 09:13:52.368452: step 3463, loss = 0.66028 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:13:53.331422 ops/training.py:65 2019-01-16 09:13:53.331368: step 3464, loss = 0.67715 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:13:54.293314 ops/training.py:65 2019-01-16 09:13:54.293266: step 3465, loss = 0.70148 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:13:55.256161 ops/training.py:65 2019-01-16 09:13:55.256105: step 3466, loss = 0.72898 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:13:56.218485 ops/training.py:65 2019-01-16 09:13:56.218435: step 3467, loss = 0.68481 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:13:57.178235 ops/training.py:65 2019-01-16 09:13:57.178182: step 3468, loss = 0.70504 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:13:58.139223 ops/training.py:65 2019-01-16 09:13:58.139173: step 3469, loss = 0.72126 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:13:59.099166 ops/training.py:65 2019-01-16 09:13:59.099100: step 3470, loss = 0.70577 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:14:00.062686 ops/training.py:65 2019-01-16 09:14:00.062621: step 3471, loss = 0.71422 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:14:01.026122 ops/training.py:65 2019-01-16 09:14:01.026053: step 3472, loss = 0.70691 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:14:01.987524 ops/training.py:65 2019-01-16 09:14:01.987469: step 3473, loss = 0.61955 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 09:14:02.948541 ops/training.py:65 2019-01-16 09:14:02.948471: step 3474, loss = 0.64770 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:14:03.910125 ops/training.py:65 2019-01-16 09:14:03.910050: step 3475, loss = 0.63240 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:14:04.875856 ops/training.py:65 2019-01-16 09:14:04.875805: step 3476, loss = 0.71237 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:14:05.838761 ops/training.py:65 2019-01-16 09:14:05.838711: step 3477, loss = 0.71828 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:14:06.801717 ops/training.py:65 2019-01-16 09:14:06.801668: step 3478, loss = 0.71079 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:14:07.763491 ops/training.py:65 2019-01-16 09:14:07.763442: step 3479, loss = 0.73486 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:14:08.727295 ops/training.py:65 2019-01-16 09:14:08.727242: step 3480, loss = 0.63319 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:14:09.689705 ops/training.py:65 2019-01-16 09:14:09.689651: step 3481, loss = 0.67147 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:14:10.649030 ops/training.py:65 2019-01-16 09:14:10.648981: step 3482, loss = 0.65746 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:14:11.609342 ops/training.py:65 2019-01-16 09:14:11.609271: step 3483, loss = 0.74314 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:14:12.568926 ops/training.py:65 2019-01-16 09:14:12.568837: step 3484, loss = 0.72581 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:14:13.533999 ops/training.py:65 2019-01-16 09:14:13.533946: step 3485, loss = 0.71723 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:14:14.498396 ops/training.py:65 2019-01-16 09:14:14.498328: step 3486, loss = 0.73241 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:14:15.461657 ops/training.py:65 2019-01-16 09:14:15.461591: step 3487, loss = 0.70912 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:14:16.422466 ops/training.py:65 2019-01-16 09:14:16.422386: step 3488, loss = 0.69247 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:14:17.382542 ops/training.py:65 2019-01-16 09:14:17.382453: step 3489, loss = 0.67221 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:14:18.345991 ops/training.py:65 2019-01-16 09:14:18.345929: step 3490, loss = 0.70836 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:14:19.309706 ops/training.py:65 2019-01-16 09:14:19.309647: step 3491, loss = 0.69413 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:14:20.270930 ops/training.py:65 2019-01-16 09:14:20.270863: step 3492, loss = 0.70127 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:14:21.235841 ops/training.py:65 2019-01-16 09:14:21.235771: step 3493, loss = 0.72441 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:14:22.199949 ops/training.py:65 2019-01-16 09:14:22.199883: step 3494, loss = 0.70565 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:14:23.162442 ops/training.py:65 2019-01-16 09:14:23.162373: step 3495, loss = 0.68894 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:14:24.123651 ops/training.py:65 2019-01-16 09:14:24.123584: step 3496, loss = 0.75964 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:14:25.087861 ops/training.py:65 2019-01-16 09:14:25.087801: step 3497, loss = 0.73179 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:14:26.050643 ops/training.py:65 2019-01-16 09:14:26.050575: step 3498, loss = 0.69985 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:14:27.012203 ops/training.py:65 2019-01-16 09:14:27.012152: step 3499, loss = 0.67734 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:14:27.972449 ops/training.py:65 2019-01-16 09:14:27.972396: step 3500, loss = 0.70204 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:14:28.934325 ops/training.py:65 2019-01-16 09:14:28.934270: step 3501, loss = 0.68841 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:14:29.896041 ops/training.py:65 2019-01-16 09:14:29.895974: step 3502, loss = 0.71817 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:14:30.856573 ops/training.py:65 2019-01-16 09:14:30.856506: step 3503, loss = 0.71075 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:14:31.817761 ops/training.py:65 2019-01-16 09:14:31.817706: step 3504, loss = 0.68749 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:14:32.779975 ops/training.py:65 2019-01-16 09:14:32.779920: step 3505, loss = 0.71367 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:14:33.742289 ops/training.py:65 2019-01-16 09:14:33.742237: step 3506, loss = 0.73961 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:14:34.703727 ops/training.py:65 2019-01-16 09:14:34.703672: step 3507, loss = 0.69371 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:14:35.664912 ops/training.py:65 2019-01-16 09:14:35.664859: step 3508, loss = 0.69064 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:14:36.627099 ops/training.py:65 2019-01-16 09:14:36.627048: step 3509, loss = 0.65556 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 09:14:37.587629 ops/training.py:65 2019-01-16 09:14:37.587572: step 3510, loss = 0.73824 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:14:38.548859 ops/training.py:65 2019-01-16 09:14:38.548809: step 3511, loss = 0.69137 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:14:39.509662 ops/training.py:65 2019-01-16 09:14:39.509604: step 3512, loss = 0.68187 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:14:40.474614 ops/training.py:65 2019-01-16 09:14:40.474551: step 3513, loss = 0.68407 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:14:41.438474 ops/training.py:65 2019-01-16 09:14:41.438405: step 3514, loss = 0.71858 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:14:42.400985 ops/training.py:65 2019-01-16 09:14:42.400940: step 3515, loss = 0.68672 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:14:43.362564 ops/training.py:65 2019-01-16 09:14:43.362509: step 3516, loss = 0.71004 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:14:44.323915 ops/training.py:65 2019-01-16 09:14:44.323862: step 3517, loss = 0.67963 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:14:45.285037 ops/training.py:65 2019-01-16 09:14:45.284978: step 3518, loss = 0.71295 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:14:46.249221 ops/training.py:65 2019-01-16 09:14:46.249172: step 3519, loss = 0.70261 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:14:47.214469 ops/training.py:65 2019-01-16 09:14:47.214414: step 3520, loss = 0.71191 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:14:48.177349 ops/training.py:65 2019-01-16 09:14:48.177301: step 3521, loss = 0.69942 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:14:49.139557 ops/training.py:65 2019-01-16 09:14:49.139502: step 3522, loss = 0.68002 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:14:50.101110 ops/training.py:65 2019-01-16 09:14:50.101055: step 3523, loss = 0.74808 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:14:51.063401 ops/training.py:65 2019-01-16 09:14:51.063343: step 3524, loss = 0.74463 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:14:52.025419 ops/training.py:65 2019-01-16 09:14:52.025362: step 3525, loss = 0.71231 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:14:52.986771 ops/training.py:65 2019-01-16 09:14:52.986712: step 3526, loss = 0.67158 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:14:53.946783 ops/training.py:65 2019-01-16 09:14:53.946736: step 3527, loss = 0.67534 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:14:54.908226 ops/training.py:65 2019-01-16 09:14:54.908175: step 3528, loss = 0.70259 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:14:55.867057 ops/training.py:65 2019-01-16 09:14:55.867014: step 3529, loss = 0.72588 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:14:56.825818 ops/training.py:65 2019-01-16 09:14:56.825771: step 3530, loss = 0.68902 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:14:57.788735 ops/training.py:65 2019-01-16 09:14:57.788689: step 3531, loss = 0.72009 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:14:58.751480 ops/training.py:65 2019-01-16 09:14:58.751434: step 3532, loss = 0.66038 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:14:59.711973 ops/training.py:65 2019-01-16 09:14:59.711912: step 3533, loss = 0.73464 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:15:00.674017 ops/training.py:65 2019-01-16 09:15:00.673949: step 3534, loss = 0.71665 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:15:01.637926 ops/training.py:65 2019-01-16 09:15:01.637872: step 3535, loss = 0.71180 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:15:02.600227 ops/training.py:65 2019-01-16 09:15:02.600174: step 3536, loss = 0.71642 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:15:03.561174 ops/training.py:65 2019-01-16 09:15:03.561116: step 3537, loss = 0.68539 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:15:04.525196 ops/training.py:65 2019-01-16 09:15:04.525144: step 3538, loss = 0.71518 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:15:05.487945 ops/training.py:65 2019-01-16 09:15:05.487878: step 3539, loss = 0.74638 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:15:06.449955 ops/training.py:65 2019-01-16 09:15:06.449886: step 3540, loss = 0.69549 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:15:07.412282 ops/training.py:65 2019-01-16 09:15:07.412228: step 3541, loss = 0.69181 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:15:08.374188 ops/training.py:65 2019-01-16 09:15:08.374137: step 3542, loss = 0.69841 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:15:09.335156 ops/training.py:65 2019-01-16 09:15:09.335104: step 3543, loss = 0.71458 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:15:10.296783 ops/training.py:65 2019-01-16 09:15:10.296731: step 3544, loss = 0.71390 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:15:11.257614 ops/training.py:65 2019-01-16 09:15:11.257556: step 3545, loss = 0.69316 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:15:12.218512 ops/training.py:65 2019-01-16 09:15:12.218448: step 3546, loss = 0.67285 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:15:13.179392 ops/training.py:65 2019-01-16 09:15:13.179329: step 3547, loss = 0.72991 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:15:14.141346 ops/training.py:65 2019-01-16 09:15:14.141306: step 3548, loss = 0.73939 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:15:15.105905 ops/training.py:65 2019-01-16 09:15:15.105842: step 3549, loss = 0.69351 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:15:16.070089 ops/training.py:65 2019-01-16 09:15:16.070031: step 3550, loss = 0.68624 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:15:17.033869 ops/training.py:65 2019-01-16 09:15:17.033812: step 3551, loss = 0.69398 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:15:17.995813 ops/training.py:65 2019-01-16 09:15:17.995758: step 3552, loss = 0.65143 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:15:18.958140 ops/training.py:65 2019-01-16 09:15:18.958083: step 3553, loss = 0.70068 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:15:19.919700 ops/training.py:65 2019-01-16 09:15:19.919645: step 3554, loss = 0.65089 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 09:15:20.880613 ops/training.py:65 2019-01-16 09:15:20.880556: step 3555, loss = 0.74240 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:15:21.841561 ops/training.py:65 2019-01-16 09:15:21.841505: step 3556, loss = 0.69174 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:15:22.802366 ops/training.py:65 2019-01-16 09:15:22.802309: step 3557, loss = 0.74815 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:15:23.764492 ops/training.py:65 2019-01-16 09:15:23.764435: step 3558, loss = 0.73021 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:15:24.725321 ops/training.py:65 2019-01-16 09:15:24.725253: step 3559, loss = 0.77094 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:15:25.690227 ops/training.py:65 2019-01-16 09:15:25.690169: step 3560, loss = 0.72557 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:15:26.654084 ops/training.py:65 2019-01-16 09:15:26.654016: step 3561, loss = 0.80132 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:15:27.617428 ops/training.py:65 2019-01-16 09:15:27.617372: step 3562, loss = 0.66032 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:15:28.578359 ops/training.py:65 2019-01-16 09:15:28.578294: step 3563, loss = 0.83179 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:15:29.539039 ops/training.py:65 2019-01-16 09:15:29.538986: step 3564, loss = 0.73683 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:15:30.500145 ops/training.py:65 2019-01-16 09:15:30.500086: step 3565, loss = 0.76585 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:15:31.461538 ops/training.py:65 2019-01-16 09:15:31.461465: step 3566, loss = 0.75366 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:15:32.422699 ops/training.py:65 2019-01-16 09:15:32.422639: step 3567, loss = 0.70991 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:15:33.387721 ops/training.py:65 2019-01-16 09:15:33.387644: step 3568, loss = 0.80587 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:15:34.348614 ops/training.py:65 2019-01-16 09:15:34.348563: step 3569, loss = 0.61791 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:15:35.309104 ops/training.py:65 2019-01-16 09:15:35.309029: step 3570, loss = 0.71974 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:15:36.274158 ops/training.py:65 2019-01-16 09:15:36.274091: step 3571, loss = 0.72643 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:15:37.237893 ops/training.py:65 2019-01-16 09:15:37.237839: step 3572, loss = 0.66703 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:15:38.201780 ops/training.py:65 2019-01-16 09:15:38.201729: step 3573, loss = 0.69814 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:15:39.164778 ops/training.py:65 2019-01-16 09:15:39.164725: step 3574, loss = 0.66981 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:15:40.126562 ops/training.py:65 2019-01-16 09:15:40.126512: step 3575, loss = 0.69482 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:15:41.089028 ops/training.py:65 2019-01-16 09:15:41.088955: step 3576, loss = 0.72727 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:15:42.049805 ops/training.py:65 2019-01-16 09:15:42.049740: step 3577, loss = 0.71867 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:15:43.011841 ops/training.py:65 2019-01-16 09:15:43.011774: step 3578, loss = 0.67067 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:15:43.973940 ops/training.py:65 2019-01-16 09:15:43.973866: step 3579, loss = 0.72385 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:15:44.936414 ops/training.py:65 2019-01-16 09:15:44.936359: step 3580, loss = 0.67995 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:15:45.898178 ops/training.py:65 2019-01-16 09:15:45.898123: step 3581, loss = 0.73634 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:15:46.860489 ops/training.py:65 2019-01-16 09:15:46.860440: step 3582, loss = 0.74986 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:15:47.821992 ops/training.py:65 2019-01-16 09:15:47.821940: step 3583, loss = 0.82061 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:15:48.783917 ops/training.py:65 2019-01-16 09:15:48.783868: step 3584, loss = 0.66898 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:15:49.744903 ops/training.py:65 2019-01-16 09:15:49.744849: step 3585, loss = 0.72962 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:15:50.709953 ops/training.py:65 2019-01-16 09:15:50.709901: step 3586, loss = 0.71128 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:15:51.673525 ops/training.py:65 2019-01-16 09:15:51.673468: step 3587, loss = 0.74376 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:15:52.637136 ops/training.py:65 2019-01-16 09:15:52.637088: step 3588, loss = 0.69411 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:15:53.598518 ops/training.py:65 2019-01-16 09:15:53.598464: step 3589, loss = 0.64785 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:15:54.559755 ops/training.py:65 2019-01-16 09:15:54.559700: step 3590, loss = 0.65618 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:15:55.526104 ops/training.py:65 2019-01-16 09:15:55.526059: step 3591, loss = 0.72267 (33.1 examples/sec; 0.965 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:15:56.490728 ops/training.py:65 2019-01-16 09:15:56.490661: step 3592, loss = 0.73301 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:15:57.453534 ops/training.py:65 2019-01-16 09:15:57.453484: step 3593, loss = 0.71667 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:15:58.415282 ops/training.py:65 2019-01-16 09:15:58.415229: step 3594, loss = 0.67382 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:15:59.377649 ops/training.py:65 2019-01-16 09:15:59.377583: step 3595, loss = 0.74254 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:16:00.339844 ops/training.py:65 2019-01-16 09:16:00.339777: step 3596, loss = 0.73780 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:16:01.302162 ops/training.py:65 2019-01-16 09:16:01.302092: step 3597, loss = 0.78908 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:16:02.264068 ops/training.py:65 2019-01-16 09:16:02.263995: step 3598, loss = 0.68435 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:16:03.225638 ops/training.py:65 2019-01-16 09:16:03.225567: step 3599, loss = 0.64554 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:16:04.190436 ops/training.py:65 2019-01-16 09:16:04.190365: step 3600, loss = 0.65553 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:16:05.154655 ops/training.py:65 2019-01-16 09:16:05.154606: step 3601, loss = 0.75174 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:16:06.119164 ops/training.py:65 2019-01-16 09:16:06.119115: step 3602, loss = 0.69407 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:16:07.082632 ops/training.py:65 2019-01-16 09:16:07.082562: step 3603, loss = 0.68590 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:16:08.045742 ops/training.py:65 2019-01-16 09:16:08.045678: step 3604, loss = 0.72261 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:16:09.008375 ops/training.py:65 2019-01-16 09:16:09.008301: step 3605, loss = 0.72510 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:16:09.969527 ops/training.py:65 2019-01-16 09:16:09.969477: step 3606, loss = 0.63786 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:16:10.930886 ops/training.py:65 2019-01-16 09:16:10.930821: step 3607, loss = 0.69039 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:16:11.892682 ops/training.py:65 2019-01-16 09:16:11.892611: step 3608, loss = 0.67696 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:16:12.855530 ops/training.py:65 2019-01-16 09:16:12.855453: step 3609, loss = 0.68486 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:16:13.817473 ops/training.py:65 2019-01-16 09:16:13.817398: step 3610, loss = 0.70612 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:16:14.779791 ops/training.py:65 2019-01-16 09:16:14.779743: step 3611, loss = 0.69722 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:16:15.742781 ops/training.py:65 2019-01-16 09:16:15.742731: step 3612, loss = 0.67591 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:16:16.704298 ops/training.py:65 2019-01-16 09:16:16.704228: step 3613, loss = 0.71022 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:16:17.665466 ops/training.py:65 2019-01-16 09:16:17.665388: step 3614, loss = 0.71096 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:16:18.626849 ops/training.py:65 2019-01-16 09:16:18.626799: step 3615, loss = 0.69768 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:16:19.588218 ops/training.py:65 2019-01-16 09:16:19.588161: step 3616, loss = 0.68941 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:16:20.549358 ops/training.py:65 2019-01-16 09:16:20.549306: step 3617, loss = 0.70835 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:16:21.513888 ops/training.py:65 2019-01-16 09:16:21.513839: step 3618, loss = 0.70745 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:16:22.477962 ops/training.py:65 2019-01-16 09:16:22.477892: step 3619, loss = 0.66870 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:16:23.441627 ops/training.py:65 2019-01-16 09:16:23.441562: step 3620, loss = 0.67742 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:16:24.403048 ops/training.py:65 2019-01-16 09:16:24.402975: step 3621, loss = 0.69967 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:16:25.364329 ops/training.py:65 2019-01-16 09:16:25.364256: step 3622, loss = 0.70686 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:16:26.326437 ops/training.py:65 2019-01-16 09:16:26.326362: step 3623, loss = 0.70431 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:16:27.287128 ops/training.py:65 2019-01-16 09:16:27.287070: step 3624, loss = 0.69321 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:16:28.248093 ops/training.py:65 2019-01-16 09:16:28.248038: step 3625, loss = 0.68240 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:16:29.209382 ops/training.py:65 2019-01-16 09:16:29.209312: step 3626, loss = 0.69671 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:16:30.169679 ops/training.py:65 2019-01-16 09:16:30.169616: step 3627, loss = 0.70313 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:16:31.130339 ops/training.py:65 2019-01-16 09:16:31.130287: step 3628, loss = 0.74036 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:16:32.091928 ops/training.py:65 2019-01-16 09:16:32.091859: step 3629, loss = 0.66535 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:16:33.053642 ops/training.py:65 2019-01-16 09:16:33.053576: step 3630, loss = 0.68639 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:16:34.015636 ops/training.py:65 2019-01-16 09:16:34.015568: step 3631, loss = 0.66235 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:16:34.975594 ops/training.py:65 2019-01-16 09:16:34.975529: step 3632, loss = 0.69956 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:16:35.935208 ops/training.py:65 2019-01-16 09:16:35.935140: step 3633, loss = 0.67518 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:16:36.893911 ops/training.py:65 2019-01-16 09:16:36.893857: step 3634, loss = 0.74536 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:16:37.854362 ops/training.py:65 2019-01-16 09:16:37.854302: step 3635, loss = 0.71976 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:16:38.814328 ops/training.py:65 2019-01-16 09:16:38.814274: step 3636, loss = 0.72292 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:16:39.778258 ops/training.py:65 2019-01-16 09:16:39.778209: step 3637, loss = 0.69937 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:16:40.741485 ops/training.py:65 2019-01-16 09:16:40.741416: step 3638, loss = 0.72605 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:16:41.703527 ops/training.py:65 2019-01-16 09:16:41.703455: step 3639, loss = 0.71592 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:16:42.665094 ops/training.py:65 2019-01-16 09:16:42.665025: step 3640, loss = 0.70586 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:16:43.626890 ops/training.py:65 2019-01-16 09:16:43.626819: step 3641, loss = 0.69574 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:16:44.588786 ops/training.py:65 2019-01-16 09:16:44.588732: step 3642, loss = 0.71156 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:16:45.553075 ops/training.py:65 2019-01-16 09:16:45.553025: step 3643, loss = 0.72734 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:16:46.516832 ops/training.py:65 2019-01-16 09:16:46.516774: step 3644, loss = 0.67203 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:16:47.479851 ops/training.py:65 2019-01-16 09:16:47.479802: step 3645, loss = 0.76617 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.25
I0832 2019-01-16 09:16:48.441569 ops/training.py:65 2019-01-16 09:16:48.441497: step 3646, loss = 0.69213 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:16:49.402861 ops/training.py:65 2019-01-16 09:16:49.402790: step 3647, loss = 0.70498 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:16:50.368408 ops/training.py:65 2019-01-16 09:16:50.368341: step 3648, loss = 0.69480 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:16:51.330204 ops/training.py:65 2019-01-16 09:16:51.330135: step 3649, loss = 0.73002 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:16:52.291010 ops/training.py:65 2019-01-16 09:16:52.290946: step 3650, loss = 0.69718 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:16:53.255030 ops/training.py:65 2019-01-16 09:16:53.254982: step 3651, loss = 0.69992 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:16:54.218169 ops/training.py:65 2019-01-16 09:16:54.218118: step 3652, loss = 0.75681 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:16:55.180283 ops/training.py:65 2019-01-16 09:16:55.180230: step 3653, loss = 0.71803 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:16:56.141836 ops/training.py:65 2019-01-16 09:16:56.141782: step 3654, loss = 0.68353 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:16:57.103700 ops/training.py:65 2019-01-16 09:16:57.103650: step 3655, loss = 0.69115 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:16:58.062977 ops/training.py:65 2019-01-16 09:16:58.062906: step 3656, loss = 0.72850 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:16:59.027385 ops/training.py:65 2019-01-16 09:16:59.027333: step 3657, loss = 0.66427 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 09:16:59.986502 ops/training.py:65 2019-01-16 09:16:59.986441: step 3658, loss = 0.71842 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:17:00.951002 ops/training.py:65 2019-01-16 09:17:00.950935: step 3659, loss = 0.71210 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:17:01.914642 ops/training.py:65 2019-01-16 09:17:01.914589: step 3660, loss = 0.68238 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:17:02.876985 ops/training.py:65 2019-01-16 09:17:02.876935: step 3661, loss = 0.69779 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:17:03.838003 ops/training.py:65 2019-01-16 09:17:03.837955: step 3662, loss = 0.66742 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 09:17:04.800241 ops/training.py:65 2019-01-16 09:17:04.800175: step 3663, loss = 0.70842 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:17:05.761750 ops/training.py:65 2019-01-16 09:17:05.761684: step 3664, loss = 0.69306 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:17:06.722876 ops/training.py:65 2019-01-16 09:17:06.722826: step 3665, loss = 0.68997 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:17:07.683769 ops/training.py:65 2019-01-16 09:17:07.683718: step 3666, loss = 0.68138 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:17:08.644927 ops/training.py:65 2019-01-16 09:17:08.644872: step 3667, loss = 0.72677 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:17:09.605745 ops/training.py:65 2019-01-16 09:17:09.605693: step 3668, loss = 0.69216 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:17:10.566878 ops/training.py:65 2019-01-16 09:17:10.566824: step 3669, loss = 0.69749 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:17:11.530967 ops/training.py:65 2019-01-16 09:17:11.530912: step 3670, loss = 0.70520 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:17:12.495639 ops/training.py:65 2019-01-16 09:17:12.495589: step 3671, loss = 0.67155 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:17:13.458991 ops/training.py:65 2019-01-16 09:17:13.458938: step 3672, loss = 0.69628 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:17:14.420721 ops/training.py:65 2019-01-16 09:17:14.420661: step 3673, loss = 0.73819 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:17:15.382336 ops/training.py:65 2019-01-16 09:17:15.382282: step 3674, loss = 0.70080 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:17:16.344142 ops/training.py:65 2019-01-16 09:17:16.344085: step 3675, loss = 0.68447 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:17:17.304802 ops/training.py:65 2019-01-16 09:17:17.304739: step 3676, loss = 0.68248 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:17:18.266243 ops/training.py:65 2019-01-16 09:17:18.266191: step 3677, loss = 0.69722 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:17:19.226988 ops/training.py:65 2019-01-16 09:17:19.226937: step 3678, loss = 0.69373 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:17:20.186697 ops/training.py:65 2019-01-16 09:17:20.186625: step 3679, loss = 0.72751 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:17:21.146944 ops/training.py:65 2019-01-16 09:17:21.146877: step 3680, loss = 0.73396 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:17:22.111439 ops/training.py:65 2019-01-16 09:17:22.111380: step 3681, loss = 0.69266 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:17:23.075514 ops/training.py:65 2019-01-16 09:17:23.075462: step 3682, loss = 0.67550 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:17:24.035656 ops/training.py:65 2019-01-16 09:17:24.035587: step 3683, loss = 0.69416 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:17:24.995894 ops/training.py:65 2019-01-16 09:17:24.995834: step 3684, loss = 0.67502 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:17:25.956592 ops/training.py:65 2019-01-16 09:17:25.956523: step 3685, loss = 0.71899 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:17:26.917663 ops/training.py:65 2019-01-16 09:17:26.917601: step 3686, loss = 0.68874 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:17:27.880634 ops/training.py:65 2019-01-16 09:17:27.880577: step 3687, loss = 0.70577 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:17:28.844901 ops/training.py:65 2019-01-16 09:17:28.844838: step 3688, loss = 0.76570 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 09:17:29.806329 ops/training.py:65 2019-01-16 09:17:29.806265: step 3689, loss = 0.76038 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:17:30.766940 ops/training.py:65 2019-01-16 09:17:30.766874: step 3690, loss = 0.75603 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:17:31.727608 ops/training.py:65 2019-01-16 09:17:31.727545: step 3691, loss = 0.72092 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:17:32.689469 ops/training.py:65 2019-01-16 09:17:32.689401: step 3692, loss = 0.71040 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:17:33.651945 ops/training.py:65 2019-01-16 09:17:33.651876: step 3693, loss = 0.76032 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:17:34.612783 ops/training.py:65 2019-01-16 09:17:34.612736: step 3694, loss = 0.67771 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:17:35.573711 ops/training.py:65 2019-01-16 09:17:35.573660: step 3695, loss = 0.70229 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:17:36.534237 ops/training.py:65 2019-01-16 09:17:36.534170: step 3696, loss = 0.71535 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:17:37.498049 ops/training.py:65 2019-01-16 09:17:37.497981: step 3697, loss = 0.72493 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:17:38.460622 ops/training.py:65 2019-01-16 09:17:38.460566: step 3698, loss = 0.68728 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:17:39.422167 ops/training.py:65 2019-01-16 09:17:39.422097: step 3699, loss = 0.70177 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:17:40.383785 ops/training.py:65 2019-01-16 09:17:40.383691: step 3700, loss = 0.69706 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:17:41.347122 ops/training.py:65 2019-01-16 09:17:41.347075: step 3701, loss = 0.76620 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 09:17:42.309657 ops/training.py:65 2019-01-16 09:17:42.309614: step 3702, loss = 0.69407 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:17:43.271190 ops/training.py:65 2019-01-16 09:17:43.271142: step 3703, loss = 0.68448 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:17:44.232145 ops/training.py:65 2019-01-16 09:17:44.232094: step 3704, loss = 0.71683 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:17:45.193952 ops/training.py:65 2019-01-16 09:17:45.193900: step 3705, loss = 0.65971 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:17:46.156162 ops/training.py:65 2019-01-16 09:17:46.156108: step 3706, loss = 0.70649 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:17:47.117602 ops/training.py:65 2019-01-16 09:17:47.117549: step 3707, loss = 0.66196 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:17:48.078384 ops/training.py:65 2019-01-16 09:17:48.078335: step 3708, loss = 0.67911 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:17:49.040566 ops/training.py:65 2019-01-16 09:17:49.040507: step 3709, loss = 0.67792 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:17:50.002442 ops/training.py:65 2019-01-16 09:17:50.002377: step 3710, loss = 0.68154 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:17:50.963598 ops/training.py:65 2019-01-16 09:17:50.963550: step 3711, loss = 0.68432 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:17:51.925980 ops/training.py:65 2019-01-16 09:17:51.925919: step 3712, loss = 0.73023 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:17:52.887737 ops/training.py:65 2019-01-16 09:17:52.887673: step 3713, loss = 0.71239 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:17:53.849691 ops/training.py:65 2019-01-16 09:17:53.849621: step 3714, loss = 0.68945 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:17:54.811022 ops/training.py:65 2019-01-16 09:17:54.810965: step 3715, loss = 0.66003 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:17:55.772711 ops/training.py:65 2019-01-16 09:17:55.772658: step 3716, loss = 0.70967 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:17:56.734758 ops/training.py:65 2019-01-16 09:17:56.734696: step 3717, loss = 0.71505 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:17:57.697004 ops/training.py:65 2019-01-16 09:17:57.696946: step 3718, loss = 0.69613 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:17:58.657413 ops/training.py:65 2019-01-16 09:17:58.657353: step 3719, loss = 0.69188 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:17:59.621683 ops/training.py:65 2019-01-16 09:17:59.621625: step 3720, loss = 0.68030 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:18:00.585108 ops/training.py:65 2019-01-16 09:18:00.585059: step 3721, loss = 0.69661 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:18:01.547987 ops/training.py:65 2019-01-16 09:18:01.547928: step 3722, loss = 0.68352 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:18:02.509489 ops/training.py:65 2019-01-16 09:18:02.509422: step 3723, loss = 0.72193 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:18:03.470623 ops/training.py:65 2019-01-16 09:18:03.470557: step 3724, loss = 0.68400 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:18:04.432934 ops/training.py:65 2019-01-16 09:18:04.432881: step 3725, loss = 0.69681 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:18:05.393725 ops/training.py:65 2019-01-16 09:18:05.393662: step 3726, loss = 0.68053 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:18:06.354494 ops/training.py:65 2019-01-16 09:18:06.354430: step 3727, loss = 0.72702 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:18:07.317180 ops/training.py:65 2019-01-16 09:18:07.317118: step 3728, loss = 0.68684 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:18:08.277558 ops/training.py:65 2019-01-16 09:18:08.277494: step 3729, loss = 0.71744 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:18:09.242366 ops/training.py:65 2019-01-16 09:18:09.242303: step 3730, loss = 0.69566 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:18:10.207707 ops/training.py:65 2019-01-16 09:18:10.207641: step 3731, loss = 0.70092 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:18:11.171272 ops/training.py:65 2019-01-16 09:18:11.171207: step 3732, loss = 0.69480 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:18:12.133457 ops/training.py:65 2019-01-16 09:18:12.133378: step 3733, loss = 0.71304 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:18:13.095133 ops/training.py:65 2019-01-16 09:18:13.095070: step 3734, loss = 0.66681 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:18:14.059425 ops/training.py:65 2019-01-16 09:18:14.059331: step 3735, loss = 0.68955 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:18:15.023752 ops/training.py:65 2019-01-16 09:18:15.023689: step 3736, loss = 0.69322 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:18:15.987219 ops/training.py:65 2019-01-16 09:18:15.987129: step 3737, loss = 0.70678 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:18:16.949158 ops/training.py:65 2019-01-16 09:18:16.949099: step 3738, loss = 0.69294 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:18:17.910277 ops/training.py:65 2019-01-16 09:18:17.910232: step 3739, loss = 0.69050 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:18:18.872849 ops/training.py:65 2019-01-16 09:18:18.872799: step 3740, loss = 0.68257 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:18:19.834592 ops/training.py:65 2019-01-16 09:18:19.834530: step 3741, loss = 0.69393 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:18:20.796959 ops/training.py:65 2019-01-16 09:18:20.796891: step 3742, loss = 0.69796 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:18:21.758097 ops/training.py:65 2019-01-16 09:18:21.758038: step 3743, loss = 0.69310 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:18:22.719581 ops/training.py:65 2019-01-16 09:18:22.719518: step 3744, loss = 0.71999 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:18:23.682367 ops/training.py:65 2019-01-16 09:18:23.682317: step 3745, loss = 0.72637 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:18:24.643669 ops/training.py:65 2019-01-16 09:18:24.643606: step 3746, loss = 0.66671 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:18:25.605555 ops/training.py:65 2019-01-16 09:18:25.605495: step 3747, loss = 0.67816 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:18:26.568707 ops/training.py:65 2019-01-16 09:18:26.568652: step 3748, loss = 0.71724 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:18:27.530915 ops/training.py:65 2019-01-16 09:18:27.530864: step 3749, loss = 0.68136 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:18:28.489846 ops/training.py:65 2019-01-16 09:18:28.489797: step 3750, loss = 0.69497 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:18:29.452816 ops/training.py:65 2019-01-16 09:18:29.452776: step 3751, loss = 0.67932 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:18:30.416447 ops/training.py:65 2019-01-16 09:18:30.416396: step 3752, loss = 0.68307 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:18:31.379797 ops/training.py:65 2019-01-16 09:18:31.379749: step 3753, loss = 0.70330 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:18:32.340793 ops/training.py:65 2019-01-16 09:18:32.340759: step 3754, loss = 0.70519 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:18:33.302784 ops/training.py:65 2019-01-16 09:18:33.302747: step 3755, loss = 0.70119 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:18:34.264727 ops/training.py:65 2019-01-16 09:18:34.264693: step 3756, loss = 0.67283 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:18:35.226345 ops/training.py:65 2019-01-16 09:18:35.226307: step 3757, loss = 0.68902 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:18:36.188004 ops/training.py:65 2019-01-16 09:18:36.187968: step 3758, loss = 0.65027 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 09:18:37.149178 ops/training.py:65 2019-01-16 09:18:37.149126: step 3759, loss = 0.68015 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:18:38.110381 ops/training.py:65 2019-01-16 09:18:38.110332: step 3760, loss = 0.68211 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:18:39.072402 ops/training.py:65 2019-01-16 09:18:39.072352: step 3761, loss = 0.73230 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:18:40.038330 ops/training.py:65 2019-01-16 09:18:40.038280: step 3762, loss = 0.71966 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:18:41.002796 ops/training.py:65 2019-01-16 09:18:41.002747: step 3763, loss = 0.67014 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:18:41.965771 ops/training.py:65 2019-01-16 09:18:41.965725: step 3764, loss = 0.69670 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:18:42.926832 ops/training.py:65 2019-01-16 09:18:42.926796: step 3765, loss = 0.70618 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:18:43.892448 ops/training.py:65 2019-01-16 09:18:43.892410: step 3766, loss = 0.67819 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:18:44.856123 ops/training.py:65 2019-01-16 09:18:44.856076: step 3767, loss = 0.69123 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:18:45.819683 ops/training.py:65 2019-01-16 09:18:45.819643: step 3768, loss = 0.72785 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:18:46.781008 ops/training.py:65 2019-01-16 09:18:46.780974: step 3769, loss = 0.68667 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:18:47.743740 ops/training.py:65 2019-01-16 09:18:47.743689: step 3770, loss = 0.70510 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:18:48.707704 ops/training.py:65 2019-01-16 09:18:48.707646: step 3771, loss = 0.74189 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:18:49.669271 ops/training.py:65 2019-01-16 09:18:49.669216: step 3772, loss = 0.70868 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:18:50.628353 ops/training.py:65 2019-01-16 09:18:50.628299: step 3773, loss = 0.66723 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:18:51.592425 ops/training.py:65 2019-01-16 09:18:51.592378: step 3774, loss = 0.70213 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:18:52.556800 ops/training.py:65 2019-01-16 09:18:52.556754: step 3775, loss = 0.74483 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:18:53.518677 ops/training.py:65 2019-01-16 09:18:53.518622: step 3776, loss = 0.68028 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:18:54.480708 ops/training.py:65 2019-01-16 09:18:54.480656: step 3777, loss = 0.69589 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:18:55.442839 ops/training.py:65 2019-01-16 09:18:55.442795: step 3778, loss = 0.70366 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:18:56.404876 ops/training.py:65 2019-01-16 09:18:56.404838: step 3779, loss = 0.72300 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:18:57.366480 ops/training.py:65 2019-01-16 09:18:57.366427: step 3780, loss = 0.68826 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:18:58.327657 ops/training.py:65 2019-01-16 09:18:58.327599: step 3781, loss = 0.75046 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:18:59.289410 ops/training.py:65 2019-01-16 09:18:59.289361: step 3782, loss = 0.71185 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:19:00.251248 ops/training.py:65 2019-01-16 09:19:00.251200: step 3783, loss = 0.73138 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:19:01.212744 ops/training.py:65 2019-01-16 09:19:01.212695: step 3784, loss = 0.67189 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:19:02.174028 ops/training.py:65 2019-01-16 09:19:02.173992: step 3785, loss = 0.77546 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:19:03.135355 ops/training.py:65 2019-01-16 09:19:03.135310: step 3786, loss = 0.70893 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:19:04.095933 ops/training.py:65 2019-01-16 09:19:04.095892: step 3787, loss = 0.66661 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:19:05.057244 ops/training.py:65 2019-01-16 09:19:05.057197: step 3788, loss = 0.69671 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:19:06.018232 ops/training.py:65 2019-01-16 09:19:06.018188: step 3789, loss = 0.72462 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:19:06.981282 ops/training.py:65 2019-01-16 09:19:06.981234: step 3790, loss = 0.72836 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:19:07.944975 ops/training.py:65 2019-01-16 09:19:07.944924: step 3791, loss = 0.71445 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 09:19:08.909790 ops/training.py:65 2019-01-16 09:19:08.909740: step 3792, loss = 0.71638 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:19:09.871328 ops/training.py:65 2019-01-16 09:19:09.871284: step 3793, loss = 0.68594 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:19:10.832684 ops/training.py:65 2019-01-16 09:19:10.832611: step 3794, loss = 0.70917 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:19:11.796949 ops/training.py:65 2019-01-16 09:19:11.796881: step 3795, loss = 0.71799 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:19:12.760207 ops/training.py:65 2019-01-16 09:19:12.760150: step 3796, loss = 0.69622 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:19:13.722854 ops/training.py:65 2019-01-16 09:19:13.722796: step 3797, loss = 0.72912 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:19:14.684565 ops/training.py:65 2019-01-16 09:19:14.684510: step 3798, loss = 0.65366 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 09:19:15.645865 ops/training.py:65 2019-01-16 09:19:15.645813: step 3799, loss = 0.73466 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:19:16.606252 ops/training.py:65 2019-01-16 09:19:16.606202: step 3800, loss = 0.69844 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:19:17.566657 ops/training.py:65 2019-01-16 09:19:17.566607: step 3801, loss = 0.71670 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:19:18.528427 ops/training.py:65 2019-01-16 09:19:18.528372: step 3802, loss = 0.66122 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:19:19.490680 ops/training.py:65 2019-01-16 09:19:19.490627: step 3803, loss = 0.72077 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 09:19:20.451627 ops/training.py:65 2019-01-16 09:19:20.451574: step 3804, loss = 0.68677 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:19:21.413245 ops/training.py:65 2019-01-16 09:19:21.413190: step 3805, loss = 0.70043 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:19:22.374173 ops/training.py:65 2019-01-16 09:19:22.374115: step 3806, loss = 0.66413 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 09:19:23.339138 ops/training.py:65 2019-01-16 09:19:23.339089: step 3807, loss = 0.68676 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:19:24.304116 ops/training.py:65 2019-01-16 09:19:24.304056: step 3808, loss = 0.65616 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:19:25.267414 ops/training.py:65 2019-01-16 09:19:25.267355: step 3809, loss = 0.71886 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:19:26.228250 ops/training.py:65 2019-01-16 09:19:26.228211: step 3810, loss = 0.70139 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:19:27.190076 ops/training.py:65 2019-01-16 09:19:27.190033: step 3811, loss = 0.68798 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:19:28.152999 ops/training.py:65 2019-01-16 09:19:28.152943: step 3812, loss = 0.68002 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:19:29.115330 ops/training.py:65 2019-01-16 09:19:29.115279: step 3813, loss = 0.70921 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:19:30.077809 ops/training.py:65 2019-01-16 09:19:30.077759: step 3814, loss = 0.65493 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:19:31.039607 ops/training.py:65 2019-01-16 09:19:31.039546: step 3815, loss = 0.68753 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:19:32.001285 ops/training.py:65 2019-01-16 09:19:32.001227: step 3816, loss = 0.68937 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:19:32.961648 ops/training.py:65 2019-01-16 09:19:32.961608: step 3817, loss = 0.70301 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:19:33.923219 ops/training.py:65 2019-01-16 09:19:33.923160: step 3818, loss = 0.68256 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:19:34.884422 ops/training.py:65 2019-01-16 09:19:34.884365: step 3819, loss = 0.68120 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:19:35.846225 ops/training.py:65 2019-01-16 09:19:35.846182: step 3820, loss = 0.69743 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:19:36.808664 ops/training.py:65 2019-01-16 09:19:36.808608: step 3821, loss = 0.64398 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 09:19:37.769369 ops/training.py:65 2019-01-16 09:19:37.769317: step 3822, loss = 0.72044 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:19:38.730715 ops/training.py:65 2019-01-16 09:19:38.730658: step 3823, loss = 0.68121 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:19:39.692795 ops/training.py:65 2019-01-16 09:19:39.692751: step 3824, loss = 0.67468 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:19:40.654549 ops/training.py:65 2019-01-16 09:19:40.654496: step 3825, loss = 0.71588 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:19:41.616384 ops/training.py:65 2019-01-16 09:19:41.616328: step 3826, loss = 0.70177 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:19:42.578534 ops/training.py:65 2019-01-16 09:19:42.578477: step 3827, loss = 0.71049 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:19:43.541493 ops/training.py:65 2019-01-16 09:19:43.541437: step 3828, loss = 0.71236 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:19:44.501421 ops/training.py:65 2019-01-16 09:19:44.501380: step 3829, loss = 0.71703 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:19:45.461663 ops/training.py:65 2019-01-16 09:19:45.461615: step 3830, loss = 0.68043 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:19:46.422837 ops/training.py:65 2019-01-16 09:19:46.422789: step 3831, loss = 0.66673 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:19:47.384461 ops/training.py:65 2019-01-16 09:19:47.384414: step 3832, loss = 0.71327 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:19:48.346203 ops/training.py:65 2019-01-16 09:19:48.346149: step 3833, loss = 0.70656 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:19:49.307541 ops/training.py:65 2019-01-16 09:19:49.307497: step 3834, loss = 0.69285 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:19:50.269378 ops/training.py:65 2019-01-16 09:19:50.269336: step 3835, loss = 0.71288 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:19:51.230245 ops/training.py:65 2019-01-16 09:19:51.230189: step 3836, loss = 0.66972 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:19:52.192207 ops/training.py:65 2019-01-16 09:19:52.192150: step 3837, loss = 0.68357 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:19:53.155616 ops/training.py:65 2019-01-16 09:19:53.155576: step 3838, loss = 0.68519 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:19:54.118800 ops/training.py:65 2019-01-16 09:19:54.118751: step 3839, loss = 0.71195 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:19:55.080591 ops/training.py:65 2019-01-16 09:19:55.080543: step 3840, loss = 0.67852 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:19:56.041193 ops/training.py:65 2019-01-16 09:19:56.041152: step 3841, loss = 0.67419 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:19:57.002122 ops/training.py:65 2019-01-16 09:19:57.002066: step 3842, loss = 0.69115 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:19:57.962822 ops/training.py:65 2019-01-16 09:19:57.962770: step 3843, loss = 0.68903 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:19:58.923934 ops/training.py:65 2019-01-16 09:19:58.923876: step 3844, loss = 0.69130 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:19:59.886607 ops/training.py:65 2019-01-16 09:19:59.886549: step 3845, loss = 0.68821 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:20:00.846473 ops/training.py:65 2019-01-16 09:20:00.846400: step 3846, loss = 0.68332 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:20:01.807105 ops/training.py:65 2019-01-16 09:20:01.807033: step 3847, loss = 0.73456 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:20:02.771583 ops/training.py:65 2019-01-16 09:20:02.771524: step 3848, loss = 0.71009 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:20:03.733081 ops/training.py:65 2019-01-16 09:20:03.733028: step 3849, loss = 0.71668 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:20:04.692270 ops/training.py:65 2019-01-16 09:20:04.692221: step 3850, loss = 0.66698 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:20:05.651297 ops/training.py:65 2019-01-16 09:20:05.651246: step 3851, loss = 0.71247 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:20:06.609747 ops/training.py:65 2019-01-16 09:20:06.609695: step 3852, loss = 0.68514 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:20:07.572631 ops/training.py:65 2019-01-16 09:20:07.572557: step 3853, loss = 0.69159 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:20:08.535814 ops/training.py:65 2019-01-16 09:20:08.535734: step 3854, loss = 0.71880 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:20:09.498685 ops/training.py:65 2019-01-16 09:20:09.498625: step 3855, loss = 0.68726 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:20:10.462881 ops/training.py:65 2019-01-16 09:20:10.462829: step 3856, loss = 0.72107 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:20:11.425754 ops/training.py:65 2019-01-16 09:20:11.425681: step 3857, loss = 0.66817 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:20:12.387503 ops/training.py:65 2019-01-16 09:20:12.387430: step 3858, loss = 0.72701 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:20:13.349298 ops/training.py:65 2019-01-16 09:20:13.349226: step 3859, loss = 0.70940 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:20:14.310622 ops/training.py:65 2019-01-16 09:20:14.310568: step 3860, loss = 0.63251 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:20:15.272288 ops/training.py:65 2019-01-16 09:20:15.272218: step 3861, loss = 0.75671 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:20:16.235276 ops/training.py:65 2019-01-16 09:20:16.235200: step 3862, loss = 0.72973 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:20:17.196855 ops/training.py:65 2019-01-16 09:20:17.196803: step 3863, loss = 0.74980 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:20:18.158419 ops/training.py:65 2019-01-16 09:20:18.158362: step 3864, loss = 0.67386 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:20:19.119642 ops/training.py:65 2019-01-16 09:20:19.119572: step 3865, loss = 0.67739 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:20:20.081011 ops/training.py:65 2019-01-16 09:20:20.080938: step 3866, loss = 0.64300 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:20:21.041343 ops/training.py:65 2019-01-16 09:20:21.041272: step 3867, loss = 0.69873 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:20:22.002731 ops/training.py:65 2019-01-16 09:20:22.002661: step 3868, loss = 0.65385 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:20:22.963423 ops/training.py:65 2019-01-16 09:20:22.963371: step 3869, loss = 0.70445 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:20:23.924649 ops/training.py:65 2019-01-16 09:20:23.924600: step 3870, loss = 0.70708 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:20:24.886325 ops/training.py:65 2019-01-16 09:20:24.886269: step 3871, loss = 0.73564 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:20:25.848097 ops/training.py:65 2019-01-16 09:20:25.848046: step 3872, loss = 0.71196 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:20:26.808820 ops/training.py:65 2019-01-16 09:20:26.808765: step 3873, loss = 0.70358 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:20:27.768734 ops/training.py:65 2019-01-16 09:20:27.768682: step 3874, loss = 0.67017 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:20:28.729688 ops/training.py:65 2019-01-16 09:20:28.729635: step 3875, loss = 0.65545 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 09:20:29.693001 ops/training.py:65 2019-01-16 09:20:29.692947: step 3876, loss = 0.69440 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:20:30.656233 ops/training.py:65 2019-01-16 09:20:30.656177: step 3877, loss = 0.71231 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:20:31.619635 ops/training.py:65 2019-01-16 09:20:31.619561: step 3878, loss = 0.73567 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:20:32.582088 ops/training.py:65 2019-01-16 09:20:32.582018: step 3879, loss = 0.72122 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:20:33.543629 ops/training.py:65 2019-01-16 09:20:33.543572: step 3880, loss = 0.71209 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:20:34.505468 ops/training.py:65 2019-01-16 09:20:34.505399: step 3881, loss = 0.72677 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:20:35.467685 ops/training.py:65 2019-01-16 09:20:35.467617: step 3882, loss = 0.70752 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:20:36.429009 ops/training.py:65 2019-01-16 09:20:36.428934: step 3883, loss = 0.71611 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:20:37.389678 ops/training.py:65 2019-01-16 09:20:37.389629: step 3884, loss = 0.75465 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:20:38.350815 ops/training.py:65 2019-01-16 09:20:38.350746: step 3885, loss = 0.68966 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:20:39.312399 ops/training.py:65 2019-01-16 09:20:39.312329: step 3886, loss = 0.73730 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:20:40.273587 ops/training.py:65 2019-01-16 09:20:40.273517: step 3887, loss = 0.68622 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:20:41.233950 ops/training.py:65 2019-01-16 09:20:41.233881: step 3888, loss = 0.71570 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:20:42.194729 ops/training.py:65 2019-01-16 09:20:42.194676: step 3889, loss = 0.74948 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:20:43.155997 ops/training.py:65 2019-01-16 09:20:43.155947: step 3890, loss = 0.77098 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:20:44.117080 ops/training.py:65 2019-01-16 09:20:44.117032: step 3891, loss = 0.67399 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:20:45.078330 ops/training.py:65 2019-01-16 09:20:45.078277: step 3892, loss = 0.74169 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:20:46.039116 ops/training.py:65 2019-01-16 09:20:46.039063: step 3893, loss = 0.72719 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:20:46.999730 ops/training.py:65 2019-01-16 09:20:46.999681: step 3894, loss = 0.67625 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:20:47.962161 ops/training.py:65 2019-01-16 09:20:47.962114: step 3895, loss = 0.63893 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:20:48.923216 ops/training.py:65 2019-01-16 09:20:48.923158: step 3896, loss = 0.81854 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:20:49.883439 ops/training.py:65 2019-01-16 09:20:49.883371: step 3897, loss = 0.75950 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:20:50.845404 ops/training.py:65 2019-01-16 09:20:50.845352: step 3898, loss = 0.67726 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:20:51.805988 ops/training.py:65 2019-01-16 09:20:51.805940: step 3899, loss = 0.72473 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:20:52.767271 ops/training.py:65 2019-01-16 09:20:52.767220: step 3900, loss = 0.71508 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:20:53.729226 ops/training.py:65 2019-01-16 09:20:53.729175: step 3901, loss = 0.65106 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:20:54.690332 ops/training.py:65 2019-01-16 09:20:54.690280: step 3902, loss = 0.71694 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:20:55.651443 ops/training.py:65 2019-01-16 09:20:55.651396: step 3903, loss = 0.70980 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:20:56.612432 ops/training.py:65 2019-01-16 09:20:56.612383: step 3904, loss = 0.67230 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:20:57.573473 ops/training.py:65 2019-01-16 09:20:57.573425: step 3905, loss = 0.72002 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:20:58.534538 ops/training.py:65 2019-01-16 09:20:58.534482: step 3906, loss = 0.72533 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:20:59.497405 ops/training.py:65 2019-01-16 09:20:59.497334: step 3907, loss = 0.64959 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 09:21:00.459439 ops/training.py:65 2019-01-16 09:21:00.459368: step 3908, loss = 0.76282 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:21:01.420775 ops/training.py:65 2019-01-16 09:21:01.420721: step 3909, loss = 0.71167 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:21:02.380803 ops/training.py:65 2019-01-16 09:21:02.380750: step 3910, loss = 0.69655 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:21:03.342877 ops/training.py:65 2019-01-16 09:21:03.342820: step 3911, loss = 0.66443 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:21:04.304748 ops/training.py:65 2019-01-16 09:21:04.304694: step 3912, loss = 0.68020 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:21:05.266254 ops/training.py:65 2019-01-16 09:21:05.266206: step 3913, loss = 0.71794 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:21:06.230600 ops/training.py:65 2019-01-16 09:21:06.230548: step 3914, loss = 0.68625 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:21:07.193681 ops/training.py:65 2019-01-16 09:21:07.193607: step 3915, loss = 0.73145 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:21:08.154517 ops/training.py:65 2019-01-16 09:21:08.154452: step 3916, loss = 0.69286 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:21:09.113751 ops/training.py:65 2019-01-16 09:21:09.113680: step 3917, loss = 0.69836 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:21:10.073365 ops/training.py:65 2019-01-16 09:21:10.073301: step 3918, loss = 0.71473 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:21:11.031552 ops/training.py:65 2019-01-16 09:21:11.031481: step 3919, loss = 0.70128 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:21:11.989954 ops/training.py:65 2019-01-16 09:21:11.989884: step 3920, loss = 0.69798 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:21:12.948246 ops/training.py:65 2019-01-16 09:21:12.948176: step 3921, loss = 0.71207 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:21:13.907293 ops/training.py:65 2019-01-16 09:21:13.907218: step 3922, loss = 0.68545 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:21:14.868013 ops/training.py:65 2019-01-16 09:21:14.867944: step 3923, loss = 0.67442 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:21:15.827850 ops/training.py:65 2019-01-16 09:21:15.827780: step 3924, loss = 0.69887 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:21:16.787165 ops/training.py:65 2019-01-16 09:21:16.787101: step 3925, loss = 0.71207 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:21:17.745618 ops/training.py:65 2019-01-16 09:21:17.745558: step 3926, loss = 0.69393 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:21:18.708766 ops/training.py:65 2019-01-16 09:21:18.708708: step 3927, loss = 0.70282 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:21:19.672113 ops/training.py:65 2019-01-16 09:21:19.672057: step 3928, loss = 0.71977 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:21:20.633780 ops/training.py:65 2019-01-16 09:21:20.633724: step 3929, loss = 0.65788 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:21:21.593996 ops/training.py:65 2019-01-16 09:21:21.593947: step 3930, loss = 0.70293 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:21:22.555100 ops/training.py:65 2019-01-16 09:21:22.555038: step 3931, loss = 0.68640 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:21:23.516901 ops/training.py:65 2019-01-16 09:21:23.516845: step 3932, loss = 0.69388 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:21:24.798973 ops/training.py:65 2019-01-16 09:21:24.798906: step 3933, loss = 0.74110 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:21:25.761124 ops/training.py:65 2019-01-16 09:21:25.761074: step 3934, loss = 0.69373 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:21:26.722781 ops/training.py:65 2019-01-16 09:21:26.722738: step 3935, loss = 0.74055 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:21:27.684146 ops/training.py:65 2019-01-16 09:21:27.684098: step 3936, loss = 0.69648 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:21:28.645986 ops/training.py:65 2019-01-16 09:21:28.645927: step 3937, loss = 0.73642 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:21:29.607152 ops/training.py:65 2019-01-16 09:21:29.607101: step 3938, loss = 0.72840 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:21:30.567593 ops/training.py:65 2019-01-16 09:21:30.567537: step 3939, loss = 0.70649 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:21:31.532602 ops/training.py:65 2019-01-16 09:21:31.532556: step 3940, loss = 0.71732 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:21:32.496260 ops/training.py:65 2019-01-16 09:21:32.496218: step 3941, loss = 0.74666 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:21:33.458518 ops/training.py:65 2019-01-16 09:21:33.458462: step 3942, loss = 0.69566 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:21:34.419844 ops/training.py:65 2019-01-16 09:21:34.419789: step 3943, loss = 0.67912 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:21:35.381766 ops/training.py:65 2019-01-16 09:21:35.381710: step 3944, loss = 0.70221 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:21:36.343646 ops/training.py:65 2019-01-16 09:21:36.343600: step 3945, loss = 0.71035 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:21:37.306082 ops/training.py:65 2019-01-16 09:21:37.306008: step 3946, loss = 0.72490 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:21:38.267755 ops/training.py:65 2019-01-16 09:21:38.267696: step 3947, loss = 0.71726 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:21:39.227666 ops/training.py:65 2019-01-16 09:21:39.227597: step 3948, loss = 0.72573 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:21:40.190291 ops/training.py:65 2019-01-16 09:21:40.190222: step 3949, loss = 0.68833 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:21:41.150890 ops/training.py:65 2019-01-16 09:21:41.150822: step 3950, loss = 0.74501 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:21:42.109359 ops/training.py:65 2019-01-16 09:21:42.109291: step 3951, loss = 0.70295 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:21:43.073690 ops/training.py:65 2019-01-16 09:21:43.073623: step 3952, loss = 0.70604 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:21:44.037816 ops/training.py:65 2019-01-16 09:21:44.037750: step 3953, loss = 0.69442 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:21:44.999661 ops/training.py:65 2019-01-16 09:21:44.999591: step 3954, loss = 0.73588 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:21:45.962789 ops/training.py:65 2019-01-16 09:21:45.962733: step 3955, loss = 0.68124 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:21:46.924859 ops/training.py:65 2019-01-16 09:21:46.924805: step 3956, loss = 0.67253 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:21:47.885752 ops/training.py:65 2019-01-16 09:21:47.885694: step 3957, loss = 0.66535 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:21:48.844682 ops/training.py:65 2019-01-16 09:21:48.844622: step 3958, loss = 0.66513 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:21:49.803054 ops/training.py:65 2019-01-16 09:21:49.802994: step 3959, loss = 0.69507 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:21:50.766434 ops/training.py:65 2019-01-16 09:21:50.766374: step 3960, loss = 0.75817 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:21:51.727555 ops/training.py:65 2019-01-16 09:21:51.727496: step 3961, loss = 0.71473 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:21:52.690815 ops/training.py:65 2019-01-16 09:21:52.690755: step 3962, loss = 0.69884 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:21:53.655375 ops/training.py:65 2019-01-16 09:21:53.655317: step 3963, loss = 0.71158 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:21:54.618600 ops/training.py:65 2019-01-16 09:21:54.618544: step 3964, loss = 0.71374 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:21:55.580315 ops/training.py:65 2019-01-16 09:21:55.580275: step 3965, loss = 0.70005 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:21:56.542349 ops/training.py:65 2019-01-16 09:21:56.542291: step 3966, loss = 0.69895 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:21:57.503712 ops/training.py:65 2019-01-16 09:21:57.503658: step 3967, loss = 0.70947 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:21:58.465152 ops/training.py:65 2019-01-16 09:21:58.465094: step 3968, loss = 0.70735 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:21:59.427401 ops/training.py:65 2019-01-16 09:21:59.427344: step 3969, loss = 0.65256 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 09:22:00.388668 ops/training.py:65 2019-01-16 09:22:00.388615: step 3970, loss = 0.67874 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:22:01.348823 ops/training.py:65 2019-01-16 09:22:01.348773: step 3971, loss = 0.66654 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:22:02.310282 ops/training.py:65 2019-01-16 09:22:02.310245: step 3972, loss = 0.69723 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:22:03.271163 ops/training.py:65 2019-01-16 09:22:03.271111: step 3973, loss = 0.72147 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:22:04.233371 ops/training.py:65 2019-01-16 09:22:04.233318: step 3974, loss = 0.70172 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:22:05.195396 ops/training.py:65 2019-01-16 09:22:05.195360: step 3975, loss = 0.70086 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:22:06.161364 ops/training.py:65 2019-01-16 09:22:06.161307: step 3976, loss = 0.67357 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:22:07.124318 ops/training.py:65 2019-01-16 09:22:07.124264: step 3977, loss = 0.67837 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:22:08.089479 ops/training.py:65 2019-01-16 09:22:08.089423: step 3978, loss = 0.70867 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:22:09.052765 ops/training.py:65 2019-01-16 09:22:09.052707: step 3979, loss = 0.69645 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:22:10.013739 ops/training.py:65 2019-01-16 09:22:10.013683: step 3980, loss = 0.73880 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:22:10.979233 ops/training.py:65 2019-01-16 09:22:10.979171: step 3981, loss = 0.65430 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:22:11.942556 ops/training.py:65 2019-01-16 09:22:11.942481: step 3982, loss = 0.66202 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:22:12.906390 ops/training.py:65 2019-01-16 09:22:12.906315: step 3983, loss = 0.73968 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:22:13.869741 ops/training.py:65 2019-01-16 09:22:13.869666: step 3984, loss = 0.71200 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:22:14.830511 ops/training.py:65 2019-01-16 09:22:14.830438: step 3985, loss = 0.71575 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:22:15.792903 ops/training.py:65 2019-01-16 09:22:15.792852: step 3986, loss = 0.71379 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:22:16.754966 ops/training.py:65 2019-01-16 09:22:16.754916: step 3987, loss = 0.68707 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:22:17.715822 ops/training.py:65 2019-01-16 09:22:17.715754: step 3988, loss = 0.67112 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:22:18.680259 ops/training.py:65 2019-01-16 09:22:18.680188: step 3989, loss = 0.70526 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:22:19.643832 ops/training.py:65 2019-01-16 09:22:19.643756: step 3990, loss = 0.70286 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:22:20.607161 ops/training.py:65 2019-01-16 09:22:20.607097: step 3991, loss = 0.69197 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:22:21.569579 ops/training.py:65 2019-01-16 09:22:21.569505: step 3992, loss = 0.69027 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:22:22.530793 ops/training.py:65 2019-01-16 09:22:22.530721: step 3993, loss = 0.73006 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:22:23.492319 ops/training.py:65 2019-01-16 09:22:23.492243: step 3994, loss = 0.72839 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:22:24.454925 ops/training.py:65 2019-01-16 09:22:24.454877: step 3995, loss = 0.70365 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:22:25.416647 ops/training.py:65 2019-01-16 09:22:25.416588: step 3996, loss = 0.69756 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:22:26.378363 ops/training.py:65 2019-01-16 09:22:26.378301: step 3997, loss = 0.72253 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:22:27.339818 ops/training.py:65 2019-01-16 09:22:27.339760: step 3998, loss = 0.69877 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:22:28.301163 ops/training.py:65 2019-01-16 09:22:28.301105: step 3999, loss = 0.70932 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:27:07.476375 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I0832 2019-01-16 09:27:07.477282 ops/training.py:41 2019-01-16 09:27:07.477231: step 4000, loss = 0.70 (0.1 examples/sec; 278.212 sec/batch) | Training accuracy = 0.4375 | Validation accuracy = 0.51215 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_08_07_39_512188
I0832 2019-01-16 09:27:08.439361 ops/training.py:65 2019-01-16 09:27:08.439290: step 4001, loss = 0.68471 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:27:09.401516 ops/training.py:65 2019-01-16 09:27:09.401449: step 4002, loss = 0.73890 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:27:10.368826 ops/training.py:65 2019-01-16 09:27:10.368756: step 4003, loss = 0.67976 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:27:11.330278 ops/training.py:65 2019-01-16 09:27:11.330210: step 4004, loss = 0.69050 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:27:12.291823 ops/training.py:65 2019-01-16 09:27:12.291753: step 4005, loss = 0.68810 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:27:13.253656 ops/training.py:65 2019-01-16 09:27:13.253584: step 4006, loss = 0.70595 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:27:14.213628 ops/training.py:65 2019-01-16 09:27:14.213563: step 4007, loss = 0.67718 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:27:15.176271 ops/training.py:65 2019-01-16 09:27:15.176202: step 4008, loss = 0.66139 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:27:16.139991 ops/training.py:65 2019-01-16 09:27:16.139917: step 4009, loss = 0.71968 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:27:17.101251 ops/training.py:65 2019-01-16 09:27:17.101155: step 4010, loss = 0.70248 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:27:18.063488 ops/training.py:65 2019-01-16 09:27:18.063425: step 4011, loss = 0.69330 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:27:19.028534 ops/training.py:65 2019-01-16 09:27:19.028467: step 4012, loss = 0.63197 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 09:27:19.991884 ops/training.py:65 2019-01-16 09:27:19.991812: step 4013, loss = 0.69673 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:27:20.953894 ops/training.py:65 2019-01-16 09:27:20.953824: step 4014, loss = 0.69255 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:27:21.914796 ops/training.py:65 2019-01-16 09:27:21.914722: step 4015, loss = 0.71994 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:27:22.876631 ops/training.py:65 2019-01-16 09:27:22.876559: step 4016, loss = 0.69110 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:27:23.842098 ops/training.py:65 2019-01-16 09:27:23.842024: step 4017, loss = 0.71246 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:27:24.806954 ops/training.py:65 2019-01-16 09:27:24.806872: step 4018, loss = 0.71066 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:27:25.771961 ops/training.py:65 2019-01-16 09:27:25.771888: step 4019, loss = 0.73499 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:27:26.737051 ops/training.py:65 2019-01-16 09:27:26.736982: step 4020, loss = 0.72879 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:27:27.700862 ops/training.py:65 2019-01-16 09:27:27.700790: step 4021, loss = 0.65056 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:27:28.662387 ops/training.py:65 2019-01-16 09:27:28.662323: step 4022, loss = 0.67561 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:27:29.626451 ops/training.py:65 2019-01-16 09:27:29.626396: step 4023, loss = 0.69734 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:27:30.589037 ops/training.py:65 2019-01-16 09:27:30.588980: step 4024, loss = 0.64625 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:27:31.551967 ops/training.py:65 2019-01-16 09:27:31.551901: step 4025, loss = 0.67265 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:27:32.514012 ops/training.py:65 2019-01-16 09:27:32.513944: step 4026, loss = 0.69466 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:27:33.476965 ops/training.py:65 2019-01-16 09:27:33.476897: step 4027, loss = 0.71274 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:27:34.438871 ops/training.py:65 2019-01-16 09:27:34.438814: step 4028, loss = 0.70590 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:27:35.400159 ops/training.py:65 2019-01-16 09:27:35.400091: step 4029, loss = 0.69763 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:27:36.365368 ops/training.py:65 2019-01-16 09:27:36.365297: step 4030, loss = 0.69538 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:27:37.328180 ops/training.py:65 2019-01-16 09:27:37.328107: step 4031, loss = 0.70647 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:27:38.291196 ops/training.py:65 2019-01-16 09:27:38.291110: step 4032, loss = 0.71014 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:27:39.254486 ops/training.py:65 2019-01-16 09:27:39.254401: step 4033, loss = 0.69228 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:27:40.219233 ops/training.py:65 2019-01-16 09:27:40.219159: step 4034, loss = 0.70285 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:27:41.183146 ops/training.py:65 2019-01-16 09:27:41.183081: step 4035, loss = 0.69790 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:27:42.145972 ops/training.py:65 2019-01-16 09:27:42.145886: step 4036, loss = 0.70917 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:27:43.107111 ops/training.py:65 2019-01-16 09:27:43.107039: step 4037, loss = 0.66346 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:27:44.068317 ops/training.py:65 2019-01-16 09:27:44.068248: step 4038, loss = 0.67826 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:27:45.030357 ops/training.py:65 2019-01-16 09:27:45.030286: step 4039, loss = 0.69865 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:27:45.992313 ops/training.py:65 2019-01-16 09:27:45.992244: step 4040, loss = 0.64628 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:27:46.954685 ops/training.py:65 2019-01-16 09:27:46.954614: step 4041, loss = 0.64947 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:27:47.916736 ops/training.py:65 2019-01-16 09:27:47.916657: step 4042, loss = 0.73657 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:27:48.879406 ops/training.py:65 2019-01-16 09:27:48.879323: step 4043, loss = 0.62568 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:27:49.841481 ops/training.py:65 2019-01-16 09:27:49.841413: step 4044, loss = 0.71604 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:27:50.802391 ops/training.py:65 2019-01-16 09:27:50.802337: step 4045, loss = 0.75887 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:27:51.763620 ops/training.py:65 2019-01-16 09:27:51.763546: step 4046, loss = 0.76867 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:27:52.725354 ops/training.py:65 2019-01-16 09:27:52.725282: step 4047, loss = 0.72690 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:27:53.687338 ops/training.py:65 2019-01-16 09:27:53.687269: step 4048, loss = 0.65681 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:27:54.648705 ops/training.py:65 2019-01-16 09:27:54.648637: step 4049, loss = 0.75489 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:27:55.610265 ops/training.py:65 2019-01-16 09:27:55.610196: step 4050, loss = 0.70134 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:27:56.572413 ops/training.py:65 2019-01-16 09:27:56.572345: step 4051, loss = 0.65104 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:27:57.533711 ops/training.py:65 2019-01-16 09:27:57.533629: step 4052, loss = 0.65775 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:27:58.495723 ops/training.py:65 2019-01-16 09:27:58.495640: step 4053, loss = 0.66164 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:27:59.459016 ops/training.py:65 2019-01-16 09:27:59.458956: step 4054, loss = 0.67368 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:28:00.421913 ops/training.py:65 2019-01-16 09:28:00.421830: step 4055, loss = 0.69864 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:28:01.384474 ops/training.py:65 2019-01-16 09:28:01.384402: step 4056, loss = 0.65455 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:28:02.345798 ops/training.py:65 2019-01-16 09:28:02.345722: step 4057, loss = 0.73948 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:28:03.307230 ops/training.py:65 2019-01-16 09:28:03.307160: step 4058, loss = 0.72012 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:28:04.269264 ops/training.py:65 2019-01-16 09:28:04.269198: step 4059, loss = 0.78504 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:28:05.231115 ops/training.py:65 2019-01-16 09:28:05.231046: step 4060, loss = 0.69485 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:28:06.191965 ops/training.py:65 2019-01-16 09:28:06.191899: step 4061, loss = 0.69051 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:28:07.154109 ops/training.py:65 2019-01-16 09:28:07.154034: step 4062, loss = 0.70481 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:28:08.116735 ops/training.py:65 2019-01-16 09:28:08.116672: step 4063, loss = 0.72309 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:28:09.078566 ops/training.py:65 2019-01-16 09:28:09.078491: step 4064, loss = 0.75544 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:28:10.040320 ops/training.py:65 2019-01-16 09:28:10.040235: step 4065, loss = 0.74528 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:28:11.002367 ops/training.py:65 2019-01-16 09:28:11.002303: step 4066, loss = 0.67028 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:28:11.964992 ops/training.py:65 2019-01-16 09:28:11.964916: step 4067, loss = 0.69111 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:28:12.926838 ops/training.py:65 2019-01-16 09:28:12.926749: step 4068, loss = 0.71651 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:28:13.889215 ops/training.py:65 2019-01-16 09:28:13.889145: step 4069, loss = 0.74134 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:28:14.850750 ops/training.py:65 2019-01-16 09:28:14.850675: step 4070, loss = 0.65906 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:28:15.812425 ops/training.py:65 2019-01-16 09:28:15.812351: step 4071, loss = 0.64778 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:28:16.774029 ops/training.py:65 2019-01-16 09:28:16.773960: step 4072, loss = 0.64932 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:28:17.735614 ops/training.py:65 2019-01-16 09:28:17.735542: step 4073, loss = 0.73904 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:28:18.696802 ops/training.py:65 2019-01-16 09:28:18.696739: step 4074, loss = 0.67088 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:28:19.659045 ops/training.py:65 2019-01-16 09:28:19.658974: step 4075, loss = 0.78265 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 09:28:20.621386 ops/training.py:65 2019-01-16 09:28:20.621314: step 4076, loss = 0.71149 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:28:21.583046 ops/training.py:65 2019-01-16 09:28:21.582976: step 4077, loss = 0.78057 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 09:28:22.544578 ops/training.py:65 2019-01-16 09:28:22.544505: step 4078, loss = 0.70887 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:28:23.506728 ops/training.py:65 2019-01-16 09:28:23.506647: step 4079, loss = 0.77473 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:28:24.468955 ops/training.py:65 2019-01-16 09:28:24.468864: step 4080, loss = 0.72888 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:28:25.431167 ops/training.py:65 2019-01-16 09:28:25.431095: step 4081, loss = 0.69433 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:28:26.393126 ops/training.py:65 2019-01-16 09:28:26.392913: step 4082, loss = 0.71423 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:28:27.355568 ops/training.py:65 2019-01-16 09:28:27.355504: step 4083, loss = 0.68573 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:28:28.317166 ops/training.py:65 2019-01-16 09:28:28.317089: step 4084, loss = 0.71261 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:28:29.278699 ops/training.py:65 2019-01-16 09:28:29.278628: step 4085, loss = 0.71382 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:28:30.240813 ops/training.py:65 2019-01-16 09:28:30.240738: step 4086, loss = 0.67939 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:28:31.203289 ops/training.py:65 2019-01-16 09:28:31.203215: step 4087, loss = 0.70147 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:28:32.166572 ops/training.py:65 2019-01-16 09:28:32.166501: step 4088, loss = 0.70781 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:28:33.128696 ops/training.py:65 2019-01-16 09:28:33.128628: step 4089, loss = 0.67602 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:28:34.091231 ops/training.py:65 2019-01-16 09:28:34.091155: step 4090, loss = 0.66399 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:28:35.052264 ops/training.py:65 2019-01-16 09:28:35.052187: step 4091, loss = 0.66053 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:28:36.014734 ops/training.py:65 2019-01-16 09:28:36.014662: step 4092, loss = 0.70365 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:28:36.976416 ops/training.py:65 2019-01-16 09:28:36.976349: step 4093, loss = 0.69499 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:28:37.937796 ops/training.py:65 2019-01-16 09:28:37.937726: step 4094, loss = 0.67706 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:28:38.900035 ops/training.py:65 2019-01-16 09:28:38.899955: step 4095, loss = 0.71186 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:28:39.862152 ops/training.py:65 2019-01-16 09:28:39.862064: step 4096, loss = 0.66177 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:28:40.824536 ops/training.py:65 2019-01-16 09:28:40.824461: step 4097, loss = 0.71579 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:28:41.786323 ops/training.py:65 2019-01-16 09:28:41.786251: step 4098, loss = 0.68099 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:28:42.748057 ops/training.py:65 2019-01-16 09:28:42.747982: step 4099, loss = 0.68093 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:28:43.710555 ops/training.py:65 2019-01-16 09:28:43.710481: step 4100, loss = 0.70664 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:28:44.672576 ops/training.py:65 2019-01-16 09:28:44.672500: step 4101, loss = 0.66098 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:28:45.635143 ops/training.py:65 2019-01-16 09:28:45.635066: step 4102, loss = 0.66186 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:28:46.597130 ops/training.py:65 2019-01-16 09:28:46.597052: step 4103, loss = 0.73076 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:28:47.558625 ops/training.py:65 2019-01-16 09:28:47.558548: step 4104, loss = 0.70508 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:28:48.520339 ops/training.py:65 2019-01-16 09:28:48.520194: step 4105, loss = 0.74380 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:28:49.482914 ops/training.py:65 2019-01-16 09:28:49.482848: step 4106, loss = 0.62902 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:28:50.445015 ops/training.py:65 2019-01-16 09:28:50.444922: step 4107, loss = 0.74241 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:28:51.407586 ops/training.py:65 2019-01-16 09:28:51.407519: step 4108, loss = 0.69832 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:28:52.369701 ops/training.py:65 2019-01-16 09:28:52.369579: step 4109, loss = 0.73341 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:28:53.332424 ops/training.py:65 2019-01-16 09:28:53.332376: step 4110, loss = 0.67894 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:28:54.294325 ops/training.py:65 2019-01-16 09:28:54.294237: step 4111, loss = 0.66894 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:28:55.256487 ops/training.py:65 2019-01-16 09:28:55.256416: step 4112, loss = 0.67559 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:28:56.218429 ops/training.py:65 2019-01-16 09:28:56.218341: step 4113, loss = 0.68793 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:28:57.181221 ops/training.py:65 2019-01-16 09:28:57.181139: step 4114, loss = 0.68137 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:28:58.143708 ops/training.py:65 2019-01-16 09:28:58.143646: step 4115, loss = 0.71316 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:28:59.104635 ops/training.py:65 2019-01-16 09:28:59.104580: step 4116, loss = 0.72305 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:29:00.066133 ops/training.py:65 2019-01-16 09:29:00.066062: step 4117, loss = 0.67801 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:29:01.030295 ops/training.py:65 2019-01-16 09:29:01.030229: step 4118, loss = 0.73071 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:29:01.994010 ops/training.py:65 2019-01-16 09:29:01.993956: step 4119, loss = 0.68647 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:29:02.957711 ops/training.py:65 2019-01-16 09:29:02.957655: step 4120, loss = 0.70341 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:29:03.918880 ops/training.py:65 2019-01-16 09:29:03.918822: step 4121, loss = 0.66336 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:29:04.880493 ops/training.py:65 2019-01-16 09:29:04.880422: step 4122, loss = 0.70649 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:29:05.843500 ops/training.py:65 2019-01-16 09:29:05.843424: step 4123, loss = 0.71268 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:29:06.806636 ops/training.py:65 2019-01-16 09:29:06.806562: step 4124, loss = 0.74733 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:29:07.771558 ops/training.py:65 2019-01-16 09:29:07.771498: step 4125, loss = 0.68188 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:29:08.735579 ops/training.py:65 2019-01-16 09:29:08.735512: step 4126, loss = 0.68387 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:29:09.699339 ops/training.py:65 2019-01-16 09:29:09.699272: step 4127, loss = 0.74949 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:29:10.665404 ops/training.py:65 2019-01-16 09:29:10.665339: step 4128, loss = 0.67678 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:29:11.629689 ops/training.py:65 2019-01-16 09:29:11.629617: step 4129, loss = 0.70592 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:29:12.593304 ops/training.py:65 2019-01-16 09:29:12.593234: step 4130, loss = 0.70824 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:29:13.555496 ops/training.py:65 2019-01-16 09:29:13.555434: step 4131, loss = 0.69582 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:29:14.517188 ops/training.py:65 2019-01-16 09:29:14.517117: step 4132, loss = 0.68765 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:29:15.478589 ops/training.py:65 2019-01-16 09:29:15.478522: step 4133, loss = 0.69588 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:29:16.440514 ops/training.py:65 2019-01-16 09:29:16.440447: step 4134, loss = 0.70896 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:29:17.402109 ops/training.py:65 2019-01-16 09:29:17.402041: step 4135, loss = 0.74401 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:29:18.364047 ops/training.py:65 2019-01-16 09:29:18.363976: step 4136, loss = 0.68592 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:29:19.327288 ops/training.py:65 2019-01-16 09:29:19.327218: step 4137, loss = 0.65222 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:29:20.291273 ops/training.py:65 2019-01-16 09:29:20.291202: step 4138, loss = 0.69478 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:29:21.253411 ops/training.py:65 2019-01-16 09:29:21.253356: step 4139, loss = 0.71799 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:29:22.214128 ops/training.py:65 2019-01-16 09:29:22.214071: step 4140, loss = 0.70156 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:29:23.175121 ops/training.py:65 2019-01-16 09:29:23.175064: step 4141, loss = 0.70560 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:29:24.134975 ops/training.py:65 2019-01-16 09:29:24.134920: step 4142, loss = 0.69279 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:29:25.098699 ops/training.py:65 2019-01-16 09:29:25.098632: step 4143, loss = 0.72211 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:29:26.062570 ops/training.py:65 2019-01-16 09:29:26.062501: step 4144, loss = 0.69663 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:29:27.024273 ops/training.py:65 2019-01-16 09:29:27.024209: step 4145, loss = 0.69415 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:29:27.988438 ops/training.py:65 2019-01-16 09:29:27.988391: step 4146, loss = 0.67226 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:29:28.950158 ops/training.py:65 2019-01-16 09:29:28.950103: step 4147, loss = 0.71486 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:29:29.913802 ops/training.py:65 2019-01-16 09:29:29.913741: step 4148, loss = 0.68277 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:29:30.874809 ops/training.py:65 2019-01-16 09:29:30.874746: step 4149, loss = 0.68061 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:29:31.836727 ops/training.py:65 2019-01-16 09:29:31.836667: step 4150, loss = 0.68237 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:29:32.797943 ops/training.py:65 2019-01-16 09:29:32.797890: step 4151, loss = 0.65661 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 09:29:33.759816 ops/training.py:65 2019-01-16 09:29:33.759764: step 4152, loss = 0.68043 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:29:34.721239 ops/training.py:65 2019-01-16 09:29:34.721188: step 4153, loss = 0.70795 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:29:35.683893 ops/training.py:65 2019-01-16 09:29:35.683840: step 4154, loss = 0.68332 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:29:36.645400 ops/training.py:65 2019-01-16 09:29:36.645346: step 4155, loss = 0.69193 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:29:37.608495 ops/training.py:65 2019-01-16 09:29:37.608437: step 4156, loss = 0.68864 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:29:38.573369 ops/training.py:65 2019-01-16 09:29:38.573317: step 4157, loss = 0.71362 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:29:39.538736 ops/training.py:65 2019-01-16 09:29:39.538663: step 4158, loss = 0.71108 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:29:40.503347 ops/training.py:65 2019-01-16 09:29:40.503294: step 4159, loss = 0.70037 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:29:41.464395 ops/training.py:65 2019-01-16 09:29:41.464345: step 4160, loss = 0.69809 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:29:42.428766 ops/training.py:65 2019-01-16 09:29:42.428718: step 4161, loss = 0.67589 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:29:43.392545 ops/training.py:65 2019-01-16 09:29:43.392492: step 4162, loss = 0.66020 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:29:44.354685 ops/training.py:65 2019-01-16 09:29:44.354631: step 4163, loss = 0.70187 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:29:45.315644 ops/training.py:65 2019-01-16 09:29:45.315579: step 4164, loss = 0.75326 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 09:29:46.280560 ops/training.py:65 2019-01-16 09:29:46.280496: step 4165, loss = 0.69684 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:29:47.243920 ops/training.py:65 2019-01-16 09:29:47.243852: step 4166, loss = 0.68368 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:29:48.205896 ops/training.py:65 2019-01-16 09:29:48.205847: step 4167, loss = 0.71490 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:29:49.167306 ops/training.py:65 2019-01-16 09:29:49.167256: step 4168, loss = 0.74018 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:29:50.130268 ops/training.py:65 2019-01-16 09:29:50.130211: step 4169, loss = 0.72276 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:29:51.091462 ops/training.py:65 2019-01-16 09:29:51.091414: step 4170, loss = 0.75424 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:29:52.056119 ops/training.py:65 2019-01-16 09:29:52.056069: step 4171, loss = 0.72278 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:29:53.019421 ops/training.py:65 2019-01-16 09:29:53.019371: step 4172, loss = 0.69134 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:29:53.982072 ops/training.py:65 2019-01-16 09:29:53.982016: step 4173, loss = 0.62614 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:29:54.943704 ops/training.py:65 2019-01-16 09:29:54.943656: step 4174, loss = 0.68113 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:29:55.906803 ops/training.py:65 2019-01-16 09:29:55.906751: step 4175, loss = 0.70399 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:29:56.869414 ops/training.py:65 2019-01-16 09:29:56.869359: step 4176, loss = 0.64427 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:29:57.831161 ops/training.py:65 2019-01-16 09:29:57.831100: step 4177, loss = 0.67671 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:29:58.793281 ops/training.py:65 2019-01-16 09:29:58.793230: step 4178, loss = 0.75744 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:29:59.753406 ops/training.py:65 2019-01-16 09:29:59.753345: step 4179, loss = 0.70858 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:30:00.715094 ops/training.py:65 2019-01-16 09:30:00.715023: step 4180, loss = 0.68721 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:30:01.675758 ops/training.py:65 2019-01-16 09:30:01.675705: step 4181, loss = 0.73604 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:30:02.635980 ops/training.py:65 2019-01-16 09:30:02.635914: step 4182, loss = 0.67793 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:30:03.600272 ops/training.py:65 2019-01-16 09:30:03.600203: step 4183, loss = 0.71477 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:30:04.562600 ops/training.py:65 2019-01-16 09:30:04.562529: step 4184, loss = 0.75532 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:30:05.523444 ops/training.py:65 2019-01-16 09:30:05.523398: step 4185, loss = 0.66130 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:30:06.484552 ops/training.py:65 2019-01-16 09:30:06.484486: step 4186, loss = 0.71583 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:30:07.447640 ops/training.py:65 2019-01-16 09:30:07.447595: step 4187, loss = 0.69461 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:30:08.411308 ops/training.py:65 2019-01-16 09:30:08.411262: step 4188, loss = 0.70169 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:30:09.374473 ops/training.py:65 2019-01-16 09:30:09.374430: step 4189, loss = 0.69260 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:30:10.335502 ops/training.py:65 2019-01-16 09:30:10.335455: step 4190, loss = 0.68491 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:30:11.298878 ops/training.py:65 2019-01-16 09:30:11.298830: step 4191, loss = 0.69533 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:30:12.262931 ops/training.py:65 2019-01-16 09:30:12.262879: step 4192, loss = 0.66257 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:30:13.226665 ops/training.py:65 2019-01-16 09:30:13.226611: step 4193, loss = 0.69225 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:30:14.189581 ops/training.py:65 2019-01-16 09:30:14.189508: step 4194, loss = 0.68735 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:30:15.151182 ops/training.py:65 2019-01-16 09:30:15.151128: step 4195, loss = 0.72013 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:30:16.113222 ops/training.py:65 2019-01-16 09:30:16.113168: step 4196, loss = 0.68442 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:30:17.077415 ops/training.py:65 2019-01-16 09:30:17.077366: step 4197, loss = 0.65910 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:30:18.041686 ops/training.py:65 2019-01-16 09:30:18.041638: step 4198, loss = 0.70313 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:30:19.005040 ops/training.py:65 2019-01-16 09:30:19.004977: step 4199, loss = 0.73568 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:30:19.966725 ops/training.py:65 2019-01-16 09:30:19.966672: step 4200, loss = 0.70650 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:30:20.928051 ops/training.py:65 2019-01-16 09:30:20.928001: step 4201, loss = 0.69552 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:30:21.887863 ops/training.py:65 2019-01-16 09:30:21.887809: step 4202, loss = 0.73264 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:30:22.851235 ops/training.py:65 2019-01-16 09:30:22.851184: step 4203, loss = 0.69213 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:30:23.816214 ops/training.py:65 2019-01-16 09:30:23.816150: step 4204, loss = 0.67724 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:30:24.779436 ops/training.py:65 2019-01-16 09:30:24.779374: step 4205, loss = 0.72404 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:30:25.741471 ops/training.py:65 2019-01-16 09:30:25.741401: step 4206, loss = 0.71384 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:30:26.704403 ops/training.py:65 2019-01-16 09:30:26.704353: step 4207, loss = 0.71482 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:30:27.667081 ops/training.py:65 2019-01-16 09:30:27.667024: step 4208, loss = 0.66585 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:30:28.629046 ops/training.py:65 2019-01-16 09:30:28.628982: step 4209, loss = 0.71148 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:30:29.590550 ops/training.py:65 2019-01-16 09:30:29.590480: step 4210, loss = 0.70246 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:30:30.552345 ops/training.py:65 2019-01-16 09:30:30.552277: step 4211, loss = 0.72870 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:30:31.513606 ops/training.py:65 2019-01-16 09:30:31.513553: step 4212, loss = 0.69333 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:30:32.474912 ops/training.py:65 2019-01-16 09:30:32.474864: step 4213, loss = 0.70404 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:30:33.435791 ops/training.py:65 2019-01-16 09:30:33.435720: step 4214, loss = 0.73892 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:30:34.396214 ops/training.py:65 2019-01-16 09:30:34.396155: step 4215, loss = 0.74540 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:30:35.356543 ops/training.py:65 2019-01-16 09:30:35.356487: step 4216, loss = 0.71919 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:30:36.318213 ops/training.py:65 2019-01-16 09:30:36.318162: step 4217, loss = 0.67855 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:30:37.283270 ops/training.py:65 2019-01-16 09:30:37.283213: step 4218, loss = 0.76287 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:30:38.247307 ops/training.py:65 2019-01-16 09:30:38.247249: step 4219, loss = 0.72494 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:30:39.211016 ops/training.py:65 2019-01-16 09:30:39.210950: step 4220, loss = 0.69325 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:30:40.173016 ops/training.py:65 2019-01-16 09:30:40.172943: step 4221, loss = 0.68768 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:30:41.135751 ops/training.py:65 2019-01-16 09:30:41.135678: step 4222, loss = 0.62661 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 09:30:42.098582 ops/training.py:65 2019-01-16 09:30:42.098533: step 4223, loss = 0.76553 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:30:43.062658 ops/training.py:65 2019-01-16 09:30:43.062607: step 4224, loss = 0.72442 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:30:44.027226 ops/training.py:65 2019-01-16 09:30:44.027173: step 4225, loss = 0.69477 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:30:44.990161 ops/training.py:65 2019-01-16 09:30:44.990103: step 4226, loss = 0.72824 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:30:45.951375 ops/training.py:65 2019-01-16 09:30:45.951322: step 4227, loss = 0.75795 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:30:46.916016 ops/training.py:65 2019-01-16 09:30:46.915962: step 4228, loss = 0.67253 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:30:47.878150 ops/training.py:65 2019-01-16 09:30:47.878085: step 4229, loss = 0.76450 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:30:48.842558 ops/training.py:65 2019-01-16 09:30:48.842505: step 4230, loss = 0.75106 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:30:49.804777 ops/training.py:65 2019-01-16 09:30:49.804721: step 4231, loss = 0.66500 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:30:50.767253 ops/training.py:65 2019-01-16 09:30:50.767197: step 4232, loss = 0.68072 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:30:51.732287 ops/training.py:65 2019-01-16 09:30:51.732217: step 4233, loss = 0.74710 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:30:52.695818 ops/training.py:65 2019-01-16 09:30:52.695762: step 4234, loss = 0.75247 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:30:53.657355 ops/training.py:65 2019-01-16 09:30:53.657300: step 4235, loss = 0.84305 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 09:30:54.618012 ops/training.py:65 2019-01-16 09:30:54.617957: step 4236, loss = 0.78914 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:30:55.582804 ops/training.py:65 2019-01-16 09:30:55.582753: step 4237, loss = 0.72752 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:30:56.544480 ops/training.py:65 2019-01-16 09:30:56.544419: step 4238, loss = 0.64345 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:30:57.504504 ops/training.py:65 2019-01-16 09:30:57.504432: step 4239, loss = 0.74515 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:30:58.465410 ops/training.py:65 2019-01-16 09:30:58.465343: step 4240, loss = 0.64382 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:30:59.428342 ops/training.py:65 2019-01-16 09:30:59.428274: step 4241, loss = 0.77474 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:31:00.389216 ops/training.py:65 2019-01-16 09:31:00.389139: step 4242, loss = 0.68892 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:31:01.350102 ops/training.py:65 2019-01-16 09:31:01.350050: step 4243, loss = 0.76499 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:31:02.311160 ops/training.py:65 2019-01-16 09:31:02.311104: step 4244, loss = 0.73721 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:31:03.276835 ops/training.py:65 2019-01-16 09:31:03.276777: step 4245, loss = 0.70131 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:31:04.237917 ops/training.py:65 2019-01-16 09:31:04.237861: step 4246, loss = 0.81134 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:31:05.197824 ops/training.py:65 2019-01-16 09:31:05.197766: step 4247, loss = 0.71401 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:31:06.158416 ops/training.py:65 2019-01-16 09:31:06.158345: step 4248, loss = 0.69635 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:31:07.118952 ops/training.py:65 2019-01-16 09:31:07.118868: step 4249, loss = 0.74058 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:31:08.081538 ops/training.py:65 2019-01-16 09:31:08.081472: step 4250, loss = 0.71109 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:31:09.044029 ops/training.py:65 2019-01-16 09:31:09.043960: step 4251, loss = 0.69801 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:31:10.004821 ops/training.py:65 2019-01-16 09:31:10.004762: step 4252, loss = 0.73810 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:31:10.965454 ops/training.py:65 2019-01-16 09:31:10.965401: step 4253, loss = 0.72390 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:31:11.926466 ops/training.py:65 2019-01-16 09:31:11.926400: step 4254, loss = 0.67867 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:31:12.886531 ops/training.py:65 2019-01-16 09:31:12.886445: step 4255, loss = 0.71667 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:31:13.850677 ops/training.py:65 2019-01-16 09:31:13.850605: step 4256, loss = 0.68456 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:31:14.814300 ops/training.py:65 2019-01-16 09:31:14.814228: step 4257, loss = 0.69625 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:31:15.775183 ops/training.py:65 2019-01-16 09:31:15.775115: step 4258, loss = 0.72944 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:31:16.736153 ops/training.py:65 2019-01-16 09:31:16.736084: step 4259, loss = 0.68677 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:31:17.696594 ops/training.py:65 2019-01-16 09:31:17.696533: step 4260, loss = 0.66732 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:31:18.656406 ops/training.py:65 2019-01-16 09:31:18.656337: step 4261, loss = 0.66789 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:31:19.616458 ops/training.py:65 2019-01-16 09:31:19.616390: step 4262, loss = 0.65133 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:31:20.576079 ops/training.py:65 2019-01-16 09:31:20.576032: step 4263, loss = 0.69941 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:31:21.536428 ops/training.py:65 2019-01-16 09:31:21.536369: step 4264, loss = 0.72511 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:31:22.495819 ops/training.py:65 2019-01-16 09:31:22.495756: step 4265, loss = 0.66715 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:31:23.454265 ops/training.py:65 2019-01-16 09:31:23.454204: step 4266, loss = 0.70468 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:31:24.412796 ops/training.py:65 2019-01-16 09:31:24.412737: step 4267, loss = 0.66775 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:31:25.371673 ops/training.py:65 2019-01-16 09:31:25.371628: step 4268, loss = 0.71086 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:31:26.330268 ops/training.py:65 2019-01-16 09:31:26.330213: step 4269, loss = 0.64172 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:31:27.290549 ops/training.py:65 2019-01-16 09:31:27.290481: step 4270, loss = 0.69768 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:31:28.249608 ops/training.py:65 2019-01-16 09:31:28.249543: step 4271, loss = 0.68986 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:31:29.209260 ops/training.py:65 2019-01-16 09:31:29.209203: step 4272, loss = 0.64576 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:31:30.170015 ops/training.py:65 2019-01-16 09:31:30.169964: step 4273, loss = 0.72109 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:31:31.134987 ops/training.py:65 2019-01-16 09:31:31.134938: step 4274, loss = 0.71419 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:31:32.096417 ops/training.py:65 2019-01-16 09:31:32.096361: step 4275, loss = 0.68595 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:31:33.057835 ops/training.py:65 2019-01-16 09:31:33.057776: step 4276, loss = 0.68955 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:31:34.018856 ops/training.py:65 2019-01-16 09:31:34.018808: step 4277, loss = 0.70302 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:31:34.980749 ops/training.py:65 2019-01-16 09:31:34.980676: step 4278, loss = 0.73869 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:31:35.945586 ops/training.py:65 2019-01-16 09:31:35.945536: step 4279, loss = 0.71207 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:31:36.907361 ops/training.py:65 2019-01-16 09:31:36.907308: step 4280, loss = 0.69885 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:31:37.868818 ops/training.py:65 2019-01-16 09:31:37.868767: step 4281, loss = 0.65994 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:31:38.829057 ops/training.py:65 2019-01-16 09:31:38.828998: step 4282, loss = 0.69680 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:31:39.794644 ops/training.py:65 2019-01-16 09:31:39.794595: step 4283, loss = 0.68054 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:31:40.759580 ops/training.py:65 2019-01-16 09:31:40.759529: step 4284, loss = 0.67991 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:31:41.722454 ops/training.py:65 2019-01-16 09:31:41.722403: step 4285, loss = 0.71570 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:31:42.683659 ops/training.py:65 2019-01-16 09:31:42.683605: step 4286, loss = 0.68666 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:31:43.645701 ops/training.py:65 2019-01-16 09:31:43.645649: step 4287, loss = 0.68155 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:31:44.607825 ops/training.py:65 2019-01-16 09:31:44.607767: step 4288, loss = 0.70429 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:31:45.572710 ops/training.py:65 2019-01-16 09:31:45.572641: step 4289, loss = 0.72801 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:31:46.536970 ops/training.py:65 2019-01-16 09:31:46.536903: step 4290, loss = 0.68128 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:31:47.497447 ops/training.py:65 2019-01-16 09:31:47.497384: step 4291, loss = 0.67144 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:31:48.458718 ops/training.py:65 2019-01-16 09:31:48.458653: step 4292, loss = 0.65712 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:31:49.418704 ops/training.py:65 2019-01-16 09:31:49.418642: step 4293, loss = 0.71914 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:31:50.377441 ops/training.py:65 2019-01-16 09:31:50.377387: step 4294, loss = 0.70448 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:31:51.339838 ops/training.py:65 2019-01-16 09:31:51.339775: step 4295, loss = 0.67925 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:31:52.303088 ops/training.py:65 2019-01-16 09:31:52.303039: step 4296, loss = 0.72751 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:31:53.264218 ops/training.py:65 2019-01-16 09:31:53.264149: step 4297, loss = 0.67995 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:31:54.226018 ops/training.py:65 2019-01-16 09:31:54.225966: step 4298, loss = 0.67963 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:31:55.187781 ops/training.py:65 2019-01-16 09:31:55.187726: step 4299, loss = 0.68824 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:31:56.151273 ops/training.py:65 2019-01-16 09:31:56.151212: step 4300, loss = 0.72134 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:31:57.114440 ops/training.py:65 2019-01-16 09:31:57.114370: step 4301, loss = 0.67884 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:31:58.077134 ops/training.py:65 2019-01-16 09:31:58.077072: step 4302, loss = 0.71692 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:31:59.038032 ops/training.py:65 2019-01-16 09:31:59.037974: step 4303, loss = 0.70359 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:31:59.999537 ops/training.py:65 2019-01-16 09:31:59.999468: step 4304, loss = 0.69245 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:32:00.962979 ops/training.py:65 2019-01-16 09:32:00.962908: step 4305, loss = 0.70638 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:32:01.924099 ops/training.py:65 2019-01-16 09:32:01.924045: step 4306, loss = 0.68159 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:32:02.884565 ops/training.py:65 2019-01-16 09:32:02.884510: step 4307, loss = 0.70905 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:32:03.846661 ops/training.py:65 2019-01-16 09:32:03.846591: step 4308, loss = 0.67988 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:32:04.809518 ops/training.py:65 2019-01-16 09:32:04.809450: step 4309, loss = 0.73268 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:32:05.770966 ops/training.py:65 2019-01-16 09:32:05.770901: step 4310, loss = 0.67971 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:32:06.729191 ops/training.py:65 2019-01-16 09:32:06.729124: step 4311, loss = 0.74234 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:32:07.690780 ops/training.py:65 2019-01-16 09:32:07.690709: step 4312, loss = 0.70399 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:32:08.654100 ops/training.py:65 2019-01-16 09:32:08.654056: step 4313, loss = 0.67206 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:32:09.616897 ops/training.py:65 2019-01-16 09:32:09.616833: step 4314, loss = 0.66809 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:32:10.578960 ops/training.py:65 2019-01-16 09:32:10.578903: step 4315, loss = 0.68483 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:32:11.539448 ops/training.py:65 2019-01-16 09:32:11.539401: step 4316, loss = 0.69949 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:32:12.500742 ops/training.py:65 2019-01-16 09:32:12.500685: step 4317, loss = 0.69236 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:32:13.461794 ops/training.py:65 2019-01-16 09:32:13.461721: step 4318, loss = 0.66606 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:32:14.423126 ops/training.py:65 2019-01-16 09:32:14.423056: step 4319, loss = 0.68782 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:32:15.385584 ops/training.py:65 2019-01-16 09:32:15.385539: step 4320, loss = 0.69992 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:32:16.349163 ops/training.py:65 2019-01-16 09:32:16.349110: step 4321, loss = 0.67707 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:32:17.311755 ops/training.py:65 2019-01-16 09:32:17.311699: step 4322, loss = 0.70451 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:32:18.273836 ops/training.py:65 2019-01-16 09:32:18.273788: step 4323, loss = 0.67159 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:32:19.235466 ops/training.py:65 2019-01-16 09:32:19.235414: step 4324, loss = 0.68345 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:32:20.201451 ops/training.py:65 2019-01-16 09:32:20.201400: step 4325, loss = 0.68865 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:32:21.165438 ops/training.py:65 2019-01-16 09:32:21.165390: step 4326, loss = 0.67413 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:32:22.128628 ops/training.py:65 2019-01-16 09:32:22.128573: step 4327, loss = 0.75508 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:32:23.090152 ops/training.py:65 2019-01-16 09:32:23.090085: step 4328, loss = 0.67655 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:32:24.050966 ops/training.py:65 2019-01-16 09:32:24.050893: step 4329, loss = 0.70479 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:32:25.013140 ops/training.py:65 2019-01-16 09:32:25.013093: step 4330, loss = 0.66403 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:32:25.974223 ops/training.py:65 2019-01-16 09:32:25.974170: step 4331, loss = 0.68230 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:32:26.936098 ops/training.py:65 2019-01-16 09:32:26.936047: step 4332, loss = 0.67058 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:32:27.897366 ops/training.py:65 2019-01-16 09:32:27.897317: step 4333, loss = 0.69084 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:32:28.859414 ops/training.py:65 2019-01-16 09:32:28.859365: step 4334, loss = 0.68185 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:32:29.820690 ops/training.py:65 2019-01-16 09:32:29.820633: step 4335, loss = 0.71020 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:32:30.781652 ops/training.py:65 2019-01-16 09:32:30.781598: step 4336, loss = 0.69882 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:32:31.744264 ops/training.py:65 2019-01-16 09:32:31.744211: step 4337, loss = 0.65402 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:32:32.705567 ops/training.py:65 2019-01-16 09:32:32.705508: step 4338, loss = 0.69494 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:32:33.667309 ops/training.py:65 2019-01-16 09:32:33.667239: step 4339, loss = 0.69818 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:32:34.629212 ops/training.py:65 2019-01-16 09:32:34.629140: step 4340, loss = 0.68954 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:32:35.590850 ops/training.py:65 2019-01-16 09:32:35.590786: step 4341, loss = 0.72834 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:32:36.552909 ops/training.py:65 2019-01-16 09:32:36.552860: step 4342, loss = 0.72352 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:32:37.514041 ops/training.py:65 2019-01-16 09:32:37.513966: step 4343, loss = 0.71940 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:32:38.478527 ops/training.py:65 2019-01-16 09:32:38.478467: step 4344, loss = 0.72948 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:32:39.444407 ops/training.py:65 2019-01-16 09:32:39.444357: step 4345, loss = 0.69116 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:32:40.408557 ops/training.py:65 2019-01-16 09:32:40.408507: step 4346, loss = 0.71811 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:32:41.369911 ops/training.py:65 2019-01-16 09:32:41.369846: step 4347, loss = 0.73751 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:32:42.333997 ops/training.py:65 2019-01-16 09:32:42.333928: step 4348, loss = 0.80914 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:32:43.295213 ops/training.py:65 2019-01-16 09:32:43.295147: step 4349, loss = 0.76345 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:32:44.256246 ops/training.py:65 2019-01-16 09:32:44.256180: step 4350, loss = 0.70097 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:32:45.217567 ops/training.py:65 2019-01-16 09:32:45.217498: step 4351, loss = 0.63675 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:32:46.177299 ops/training.py:65 2019-01-16 09:32:46.177234: step 4352, loss = 0.84529 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:32:47.137553 ops/training.py:65 2019-01-16 09:32:47.137502: step 4353, loss = 0.65883 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:32:48.097547 ops/training.py:65 2019-01-16 09:32:48.097498: step 4354, loss = 0.73150 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:32:49.059145 ops/training.py:65 2019-01-16 09:32:49.059085: step 4355, loss = 0.74887 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:32:50.021318 ops/training.py:65 2019-01-16 09:32:50.021256: step 4356, loss = 0.86582 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:32:50.982119 ops/training.py:65 2019-01-16 09:32:50.982053: step 4357, loss = 0.79476 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:32:51.940619 ops/training.py:65 2019-01-16 09:32:51.940567: step 4358, loss = 0.85132 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:32:52.904707 ops/training.py:65 2019-01-16 09:32:52.904657: step 4359, loss = 0.84611 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:32:53.868727 ops/training.py:65 2019-01-16 09:32:53.868679: step 4360, loss = 0.64223 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:32:54.831743 ops/training.py:65 2019-01-16 09:32:54.831688: step 4361, loss = 0.71348 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:32:55.792184 ops/training.py:65 2019-01-16 09:32:55.792089: step 4362, loss = 0.72347 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:32:56.753940 ops/training.py:65 2019-01-16 09:32:56.753887: step 4363, loss = 0.78788 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:32:57.718861 ops/training.py:65 2019-01-16 09:32:57.718799: step 4364, loss = 0.72766 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:32:58.683325 ops/training.py:65 2019-01-16 09:32:58.683263: step 4365, loss = 0.81853 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:32:59.646140 ops/training.py:65 2019-01-16 09:32:59.646089: step 4366, loss = 0.76809 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:33:00.606042 ops/training.py:65 2019-01-16 09:33:00.605981: step 4367, loss = 0.67530 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:33:01.570119 ops/training.py:65 2019-01-16 09:33:01.570054: step 4368, loss = 0.66626 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:33:02.531936 ops/training.py:65 2019-01-16 09:33:02.531873: step 4369, loss = 0.68479 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:33:03.493549 ops/training.py:65 2019-01-16 09:33:03.493483: step 4370, loss = 0.69629 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:33:04.457731 ops/training.py:65 2019-01-16 09:33:04.457681: step 4371, loss = 0.79430 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:33:05.421326 ops/training.py:65 2019-01-16 09:33:05.421271: step 4372, loss = 0.67191 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:33:06.384925 ops/training.py:65 2019-01-16 09:33:06.384873: step 4373, loss = 0.74810 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:33:07.346725 ops/training.py:65 2019-01-16 09:33:07.346671: step 4374, loss = 0.67523 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:33:08.307482 ops/training.py:65 2019-01-16 09:33:08.307424: step 4375, loss = 0.70586 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:33:09.271214 ops/training.py:65 2019-01-16 09:33:09.271163: step 4376, loss = 0.69579 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:33:10.235418 ops/training.py:65 2019-01-16 09:33:10.235373: step 4377, loss = 0.71383 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:33:11.196455 ops/training.py:65 2019-01-16 09:33:11.196397: step 4378, loss = 0.79422 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:33:12.161962 ops/training.py:65 2019-01-16 09:33:12.161914: step 4379, loss = 0.69255 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:33:13.126462 ops/training.py:65 2019-01-16 09:33:13.126410: step 4380, loss = 0.75257 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:33:14.088149 ops/training.py:65 2019-01-16 09:33:14.088090: step 4381, loss = 0.71406 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:33:15.051857 ops/training.py:65 2019-01-16 09:33:15.051803: step 4382, loss = 0.71624 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:33:16.013890 ops/training.py:65 2019-01-16 09:33:16.013823: step 4383, loss = 0.72950 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:33:16.974831 ops/training.py:65 2019-01-16 09:33:16.974759: step 4384, loss = 0.68412 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:33:17.939467 ops/training.py:65 2019-01-16 09:33:17.939421: step 4385, loss = 0.70302 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:33:18.901780 ops/training.py:65 2019-01-16 09:33:18.901724: step 4386, loss = 0.78155 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:33:19.864524 ops/training.py:65 2019-01-16 09:33:19.864452: step 4387, loss = 0.68330 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:33:20.826773 ops/training.py:65 2019-01-16 09:33:20.826702: step 4388, loss = 0.67716 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:33:21.788579 ops/training.py:65 2019-01-16 09:33:21.788529: step 4389, loss = 0.74199 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:33:22.749563 ops/training.py:65 2019-01-16 09:33:22.749497: step 4390, loss = 0.70122 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:33:23.708876 ops/training.py:65 2019-01-16 09:33:23.708806: step 4391, loss = 0.72781 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:33:24.667875 ops/training.py:65 2019-01-16 09:33:24.667823: step 4392, loss = 0.72967 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:33:25.632153 ops/training.py:65 2019-01-16 09:33:25.632106: step 4393, loss = 0.78818 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 09:33:26.594176 ops/training.py:65 2019-01-16 09:33:26.594129: step 4394, loss = 0.74910 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:33:27.556513 ops/training.py:65 2019-01-16 09:33:27.556459: step 4395, loss = 0.79954 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:33:28.518062 ops/training.py:65 2019-01-16 09:33:28.518002: step 4396, loss = 0.69157 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:33:29.478184 ops/training.py:65 2019-01-16 09:33:29.478118: step 4397, loss = 0.68027 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:33:30.441632 ops/training.py:65 2019-01-16 09:33:30.441582: step 4398, loss = 0.71732 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:33:31.405190 ops/training.py:65 2019-01-16 09:33:31.405140: step 4399, loss = 0.69995 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:33:32.368655 ops/training.py:65 2019-01-16 09:33:32.368605: step 4400, loss = 0.68090 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:33:33.330679 ops/training.py:65 2019-01-16 09:33:33.330618: step 4401, loss = 0.69081 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:33:34.292032 ops/training.py:65 2019-01-16 09:33:34.291984: step 4402, loss = 0.67343 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:33:35.253261 ops/training.py:65 2019-01-16 09:33:35.253198: step 4403, loss = 0.62430 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:33:36.214409 ops/training.py:65 2019-01-16 09:33:36.214341: step 4404, loss = 0.70068 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:33:37.178368 ops/training.py:65 2019-01-16 09:33:37.178304: step 4405, loss = 0.75798 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:33:38.142879 ops/training.py:65 2019-01-16 09:33:38.142808: step 4406, loss = 0.80189 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.25
I0832 2019-01-16 09:33:39.104489 ops/training.py:65 2019-01-16 09:33:39.104438: step 4407, loss = 0.71038 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:33:40.069441 ops/training.py:65 2019-01-16 09:33:40.069394: step 4408, loss = 0.74419 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:33:41.031543 ops/training.py:65 2019-01-16 09:33:41.031493: step 4409, loss = 0.67893 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:33:41.996272 ops/training.py:65 2019-01-16 09:33:41.996222: step 4410, loss = 0.66011 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:33:42.958061 ops/training.py:65 2019-01-16 09:33:42.958005: step 4411, loss = 0.66398 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:33:43.919461 ops/training.py:65 2019-01-16 09:33:43.919413: step 4412, loss = 0.72068 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:33:44.884744 ops/training.py:65 2019-01-16 09:33:44.884692: step 4413, loss = 0.70827 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:33:45.848636 ops/training.py:65 2019-01-16 09:33:45.848581: step 4414, loss = 0.73164 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:33:46.810418 ops/training.py:65 2019-01-16 09:33:46.810363: step 4415, loss = 0.69283 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:33:47.771782 ops/training.py:65 2019-01-16 09:33:47.771713: step 4416, loss = 0.72303 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:33:48.733760 ops/training.py:65 2019-01-16 09:33:48.733692: step 4417, loss = 0.71061 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:33:49.697080 ops/training.py:65 2019-01-16 09:33:49.697030: step 4418, loss = 0.70546 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:33:50.657745 ops/training.py:65 2019-01-16 09:33:50.657696: step 4419, loss = 0.70425 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:33:51.618132 ops/training.py:65 2019-01-16 09:33:51.618077: step 4420, loss = 0.70137 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:33:52.578800 ops/training.py:65 2019-01-16 09:33:52.578731: step 4421, loss = 0.67978 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:33:53.542440 ops/training.py:65 2019-01-16 09:33:53.542396: step 4422, loss = 0.72345 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:33:54.503598 ops/training.py:65 2019-01-16 09:33:54.503546: step 4423, loss = 0.74105 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:33:55.468159 ops/training.py:65 2019-01-16 09:33:55.468112: step 4424, loss = 0.65662 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:33:56.430751 ops/training.py:65 2019-01-16 09:33:56.430688: step 4425, loss = 0.69645 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:33:57.396187 ops/training.py:65 2019-01-16 09:33:57.396139: step 4426, loss = 0.74974 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:33:58.359183 ops/training.py:65 2019-01-16 09:33:58.359129: step 4427, loss = 0.69442 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:33:59.320976 ops/training.py:65 2019-01-16 09:33:59.320924: step 4428, loss = 0.71185 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:34:00.282031 ops/training.py:65 2019-01-16 09:34:00.281966: step 4429, loss = 0.67882 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:34:01.246944 ops/training.py:65 2019-01-16 09:34:01.246886: step 4430, loss = 0.65318 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:34:02.211666 ops/training.py:65 2019-01-16 09:34:02.211600: step 4431, loss = 0.71489 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:34:03.175086 ops/training.py:65 2019-01-16 09:34:03.175033: step 4432, loss = 0.68484 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:34:04.137316 ops/training.py:65 2019-01-16 09:34:04.137250: step 4433, loss = 0.68308 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:34:05.098590 ops/training.py:65 2019-01-16 09:34:05.098516: step 4434, loss = 0.71158 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:34:06.059440 ops/training.py:65 2019-01-16 09:34:06.059367: step 4435, loss = 0.72709 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:34:07.023101 ops/training.py:65 2019-01-16 09:34:07.023051: step 4436, loss = 0.66871 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:34:07.986823 ops/training.py:65 2019-01-16 09:34:07.986773: step 4437, loss = 0.69415 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:34:08.947733 ops/training.py:65 2019-01-16 09:34:08.947676: step 4438, loss = 0.68641 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:34:09.908972 ops/training.py:65 2019-01-16 09:34:09.908903: step 4439, loss = 0.67376 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:34:10.869352 ops/training.py:65 2019-01-16 09:34:10.869282: step 4440, loss = 0.71211 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:34:11.833084 ops/training.py:65 2019-01-16 09:34:11.833036: step 4441, loss = 0.67638 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:34:12.796371 ops/training.py:65 2019-01-16 09:34:12.796324: step 4442, loss = 0.68173 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:34:13.756911 ops/training.py:65 2019-01-16 09:34:13.756852: step 4443, loss = 0.64760 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 09:34:14.718257 ops/training.py:65 2019-01-16 09:34:14.718184: step 4444, loss = 0.65327 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:34:15.683606 ops/training.py:65 2019-01-16 09:34:15.683539: step 4445, loss = 0.65307 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:34:16.647653 ops/training.py:65 2019-01-16 09:34:16.647604: step 4446, loss = 0.69125 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:34:17.609484 ops/training.py:65 2019-01-16 09:34:17.609424: step 4447, loss = 0.69410 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:34:18.571786 ops/training.py:65 2019-01-16 09:34:18.571710: step 4448, loss = 0.66701 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:34:19.533578 ops/training.py:65 2019-01-16 09:34:19.533529: step 4449, loss = 0.71094 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:34:20.494201 ops/training.py:65 2019-01-16 09:34:20.494147: step 4450, loss = 0.69072 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:34:21.458231 ops/training.py:65 2019-01-16 09:34:21.458184: step 4451, loss = 0.69280 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:34:22.421955 ops/training.py:65 2019-01-16 09:34:22.421884: step 4452, loss = 0.71988 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:34:23.385421 ops/training.py:65 2019-01-16 09:34:23.385347: step 4453, loss = 0.73356 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:34:24.347963 ops/training.py:65 2019-01-16 09:34:24.347909: step 4454, loss = 0.71120 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:34:25.313163 ops/training.py:65 2019-01-16 09:34:25.313105: step 4455, loss = 0.67709 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:34:26.277938 ops/training.py:65 2019-01-16 09:34:26.277869: step 4456, loss = 0.72194 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:34:27.241600 ops/training.py:65 2019-01-16 09:34:27.241526: step 4457, loss = 0.74587 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:34:28.203161 ops/training.py:65 2019-01-16 09:34:28.203099: step 4458, loss = 0.67812 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:34:29.166170 ops/training.py:65 2019-01-16 09:34:29.166113: step 4459, loss = 0.72857 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:34:30.128891 ops/training.py:65 2019-01-16 09:34:30.128818: step 4460, loss = 0.69909 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:34:31.090669 ops/training.py:65 2019-01-16 09:34:31.090599: step 4461, loss = 0.69974 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:34:32.050996 ops/training.py:65 2019-01-16 09:34:32.050927: step 4462, loss = 0.68575 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:34:33.014826 ops/training.py:65 2019-01-16 09:34:33.014778: step 4463, loss = 0.65559 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:34:33.979246 ops/training.py:65 2019-01-16 09:34:33.979188: step 4464, loss = 0.68679 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:34:34.942099 ops/training.py:65 2019-01-16 09:34:34.942030: step 4465, loss = 0.63266 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:34:35.904892 ops/training.py:65 2019-01-16 09:34:35.904825: step 4466, loss = 0.70826 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:34:36.866175 ops/training.py:65 2019-01-16 09:34:36.866122: step 4467, loss = 0.69774 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:34:37.827798 ops/training.py:65 2019-01-16 09:34:37.827749: step 4468, loss = 0.71063 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:34:38.789948 ops/training.py:65 2019-01-16 09:34:38.789899: step 4469, loss = 0.67945 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:34:39.751230 ops/training.py:65 2019-01-16 09:34:39.751175: step 4470, loss = 0.73139 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:34:40.712128 ops/training.py:65 2019-01-16 09:34:40.712073: step 4471, loss = 0.71960 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:34:41.671994 ops/training.py:65 2019-01-16 09:34:41.671944: step 4472, loss = 0.71704 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:34:42.637927 ops/training.py:65 2019-01-16 09:34:42.637876: step 4473, loss = 0.69750 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:34:43.599455 ops/training.py:65 2019-01-16 09:34:43.599399: step 4474, loss = 0.71872 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:34:44.559539 ops/training.py:65 2019-01-16 09:34:44.559490: step 4475, loss = 0.62684 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:34:45.520139 ops/training.py:65 2019-01-16 09:34:45.520087: step 4476, loss = 0.77908 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:34:46.481584 ops/training.py:65 2019-01-16 09:34:46.481529: step 4477, loss = 0.75135 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:34:47.442635 ops/training.py:65 2019-01-16 09:34:47.442577: step 4478, loss = 0.74302 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:34:48.403950 ops/training.py:65 2019-01-16 09:34:48.403899: step 4479, loss = 0.72674 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:34:49.365710 ops/training.py:65 2019-01-16 09:34:49.365650: step 4480, loss = 0.73020 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:34:50.326801 ops/training.py:65 2019-01-16 09:34:50.326731: step 4481, loss = 0.64465 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:34:51.287020 ops/training.py:65 2019-01-16 09:34:51.286953: step 4482, loss = 0.77465 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:34:52.246804 ops/training.py:65 2019-01-16 09:34:52.246743: step 4483, loss = 0.71865 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:34:53.206080 ops/training.py:65 2019-01-16 09:34:53.206013: step 4484, loss = 0.75269 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:34:54.165182 ops/training.py:65 2019-01-16 09:34:54.165137: step 4485, loss = 0.76627 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:34:55.124325 ops/training.py:65 2019-01-16 09:34:55.124275: step 4486, loss = 0.74188 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:34:56.083252 ops/training.py:65 2019-01-16 09:34:56.083184: step 4487, loss = 0.65411 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:34:57.047099 ops/training.py:65 2019-01-16 09:34:57.047054: step 4488, loss = 0.79214 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:34:58.010905 ops/training.py:65 2019-01-16 09:34:58.010856: step 4489, loss = 0.69763 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:34:58.971644 ops/training.py:65 2019-01-16 09:34:58.971586: step 4490, loss = 0.68859 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:34:59.936249 ops/training.py:65 2019-01-16 09:34:59.936191: step 4491, loss = 0.76124 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:35:00.900362 ops/training.py:65 2019-01-16 09:35:00.900317: step 4492, loss = 0.71851 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:35:01.861728 ops/training.py:65 2019-01-16 09:35:01.861684: step 4493, loss = 0.71344 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:35:02.823786 ops/training.py:65 2019-01-16 09:35:02.823744: step 4494, loss = 0.73418 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:35:03.786019 ops/training.py:65 2019-01-16 09:35:03.785965: step 4495, loss = 0.73045 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:35:04.748009 ops/training.py:65 2019-01-16 09:35:04.747966: step 4496, loss = 0.68536 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:35:05.708770 ops/training.py:65 2019-01-16 09:35:05.708722: step 4497, loss = 0.71100 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:35:06.669883 ops/training.py:65 2019-01-16 09:35:06.669828: step 4498, loss = 0.69254 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:35:07.629912 ops/training.py:65 2019-01-16 09:35:07.629860: step 4499, loss = 0.69686 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:35:08.590652 ops/training.py:65 2019-01-16 09:35:08.590593: step 4500, loss = 0.67718 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:35:09.551207 ops/training.py:65 2019-01-16 09:35:09.551138: step 4501, loss = 0.71315 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:35:10.514837 ops/training.py:65 2019-01-16 09:35:10.514781: step 4502, loss = 0.67640 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:35:11.478883 ops/training.py:65 2019-01-16 09:35:11.478826: step 4503, loss = 0.74800 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:35:12.442513 ops/training.py:65 2019-01-16 09:35:12.442444: step 4504, loss = 0.73886 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:35:13.402718 ops/training.py:65 2019-01-16 09:35:13.402669: step 4505, loss = 0.70872 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:35:14.363738 ops/training.py:65 2019-01-16 09:35:14.363664: step 4506, loss = 0.75924 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:35:15.328019 ops/training.py:65 2019-01-16 09:35:15.327929: step 4507, loss = 0.74870 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:35:16.290313 ops/training.py:65 2019-01-16 09:35:16.290254: step 4508, loss = 0.67706 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:35:17.251774 ops/training.py:65 2019-01-16 09:35:17.251720: step 4509, loss = 0.74932 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:35:18.212506 ops/training.py:65 2019-01-16 09:35:18.212453: step 4510, loss = 0.69457 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:35:19.173014 ops/training.py:65 2019-01-16 09:35:19.172956: step 4511, loss = 0.72273 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:35:20.134381 ops/training.py:65 2019-01-16 09:35:20.134330: step 4512, loss = 0.75017 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:35:21.094957 ops/training.py:65 2019-01-16 09:35:21.094903: step 4513, loss = 0.81143 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.25
I0832 2019-01-16 09:35:22.059760 ops/training.py:65 2019-01-16 09:35:22.059702: step 4514, loss = 0.67996 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:35:23.023191 ops/training.py:65 2019-01-16 09:35:23.023139: step 4515, loss = 0.69147 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:35:23.986973 ops/training.py:65 2019-01-16 09:35:23.986922: step 4516, loss = 0.69581 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:35:24.950091 ops/training.py:65 2019-01-16 09:35:24.950042: step 4517, loss = 0.70100 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:35:25.911489 ops/training.py:65 2019-01-16 09:35:25.911441: step 4518, loss = 0.72907 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:35:26.873492 ops/training.py:65 2019-01-16 09:35:26.873443: step 4519, loss = 0.71712 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:35:27.835706 ops/training.py:65 2019-01-16 09:35:27.835654: step 4520, loss = 0.73131 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:35:28.797452 ops/training.py:65 2019-01-16 09:35:28.797394: step 4521, loss = 0.67551 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:35:29.759236 ops/training.py:65 2019-01-16 09:35:29.759166: step 4522, loss = 0.70059 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:35:30.720891 ops/training.py:65 2019-01-16 09:35:30.720798: step 4523, loss = 0.79639 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:35:31.683230 ops/training.py:65 2019-01-16 09:35:31.683177: step 4524, loss = 0.70454 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:35:32.644609 ops/training.py:65 2019-01-16 09:35:32.644559: step 4525, loss = 0.68179 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:35:33.606306 ops/training.py:65 2019-01-16 09:35:33.606254: step 4526, loss = 0.68918 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:35:34.568118 ops/training.py:65 2019-01-16 09:35:34.568065: step 4527, loss = 0.72457 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:35:35.531392 ops/training.py:65 2019-01-16 09:35:35.531344: step 4528, loss = 0.72157 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:35:36.492350 ops/training.py:65 2019-01-16 09:35:36.492295: step 4529, loss = 0.74330 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:35:37.457892 ops/training.py:65 2019-01-16 09:35:37.457838: step 4530, loss = 0.70719 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:35:38.421464 ops/training.py:65 2019-01-16 09:35:38.421414: step 4531, loss = 0.70192 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:35:39.384853 ops/training.py:65 2019-01-16 09:35:39.384799: step 4532, loss = 0.73683 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:35:40.443833 ops/training.py:65 2019-01-16 09:35:40.443781: step 4533, loss = 0.71173 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:35:41.404378 ops/training.py:65 2019-01-16 09:35:41.404324: step 4534, loss = 0.73631 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:35:42.365683 ops/training.py:65 2019-01-16 09:35:42.365635: step 4535, loss = 0.75068 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:35:43.327065 ops/training.py:65 2019-01-16 09:35:43.327014: step 4536, loss = 0.70091 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:35:44.288215 ops/training.py:65 2019-01-16 09:35:44.288162: step 4537, loss = 0.70703 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:35:45.249359 ops/training.py:65 2019-01-16 09:35:45.249312: step 4538, loss = 0.69419 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:35:46.211005 ops/training.py:65 2019-01-16 09:35:46.210954: step 4539, loss = 0.66901 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:35:47.171165 ops/training.py:65 2019-01-16 09:35:47.171107: step 4540, loss = 0.72957 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:35:48.131925 ops/training.py:65 2019-01-16 09:35:48.131875: step 4541, loss = 0.70125 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:35:49.093748 ops/training.py:65 2019-01-16 09:35:49.093691: step 4542, loss = 0.71345 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:35:50.056684 ops/training.py:65 2019-01-16 09:35:50.056625: step 4543, loss = 0.70029 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:35:51.021336 ops/training.py:65 2019-01-16 09:35:51.021289: step 4544, loss = 0.66841 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:35:51.985100 ops/training.py:65 2019-01-16 09:35:51.985049: step 4545, loss = 0.70746 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:35:52.947949 ops/training.py:65 2019-01-16 09:35:52.947893: step 4546, loss = 0.71575 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:35:53.912505 ops/training.py:65 2019-01-16 09:35:53.912454: step 4547, loss = 0.68264 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:35:54.876743 ops/training.py:65 2019-01-16 09:35:54.876698: step 4548, loss = 0.68670 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:35:55.841129 ops/training.py:65 2019-01-16 09:35:55.841077: step 4549, loss = 0.67352 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:35:56.802489 ops/training.py:65 2019-01-16 09:35:56.802438: step 4550, loss = 0.69581 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:35:57.764088 ops/training.py:65 2019-01-16 09:35:57.764035: step 4551, loss = 0.69295 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:35:58.726488 ops/training.py:65 2019-01-16 09:35:58.726427: step 4552, loss = 0.72553 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:35:59.688328 ops/training.py:65 2019-01-16 09:35:59.688272: step 4553, loss = 0.68341 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:36:00.649220 ops/training.py:65 2019-01-16 09:36:00.649169: step 4554, loss = 0.69052 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:36:01.610531 ops/training.py:65 2019-01-16 09:36:01.610478: step 4555, loss = 0.69523 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:36:02.571261 ops/training.py:65 2019-01-16 09:36:02.571210: step 4556, loss = 0.70972 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:36:03.532857 ops/training.py:65 2019-01-16 09:36:03.532800: step 4557, loss = 0.69915 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:36:04.494181 ops/training.py:65 2019-01-16 09:36:04.494130: step 4558, loss = 0.69297 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:36:05.459859 ops/training.py:65 2019-01-16 09:36:05.459809: step 4559, loss = 0.69589 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:36:06.424383 ops/training.py:65 2019-01-16 09:36:06.424333: step 4560, loss = 0.68194 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:36:07.388011 ops/training.py:65 2019-01-16 09:36:07.387964: step 4561, loss = 0.67657 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:36:08.349695 ops/training.py:65 2019-01-16 09:36:08.349626: step 4562, loss = 0.66919 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:36:09.312007 ops/training.py:65 2019-01-16 09:36:09.311953: step 4563, loss = 0.68863 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:36:10.274744 ops/training.py:65 2019-01-16 09:36:10.274694: step 4564, loss = 0.70877 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:36:11.236599 ops/training.py:65 2019-01-16 09:36:11.236551: step 4565, loss = 0.68018 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:36:12.199036 ops/training.py:65 2019-01-16 09:36:12.198985: step 4566, loss = 0.69564 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:36:13.160689 ops/training.py:65 2019-01-16 09:36:13.160642: step 4567, loss = 0.71687 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:36:14.123610 ops/training.py:65 2019-01-16 09:36:14.123561: step 4568, loss = 0.69689 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:36:15.085935 ops/training.py:65 2019-01-16 09:36:15.085885: step 4569, loss = 0.69383 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:36:16.048386 ops/training.py:65 2019-01-16 09:36:16.048336: step 4570, loss = 0.68341 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:36:17.011517 ops/training.py:65 2019-01-16 09:36:17.011468: step 4571, loss = 0.69211 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:36:17.972921 ops/training.py:65 2019-01-16 09:36:17.972870: step 4572, loss = 0.68311 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:36:18.937617 ops/training.py:65 2019-01-16 09:36:18.937563: step 4573, loss = 0.69232 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:36:19.901006 ops/training.py:65 2019-01-16 09:36:19.900958: step 4574, loss = 0.71198 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:36:20.865402 ops/training.py:65 2019-01-16 09:36:20.865352: step 4575, loss = 0.68550 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:36:21.826456 ops/training.py:65 2019-01-16 09:36:21.826407: step 4576, loss = 0.69605 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:36:22.787894 ops/training.py:65 2019-01-16 09:36:22.787846: step 4577, loss = 0.70255 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:36:23.750299 ops/training.py:65 2019-01-16 09:36:23.750235: step 4578, loss = 0.67519 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:36:24.712248 ops/training.py:65 2019-01-16 09:36:24.712191: step 4579, loss = 0.67163 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:36:25.673988 ops/training.py:65 2019-01-16 09:36:25.673933: step 4580, loss = 0.68337 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:36:26.635567 ops/training.py:65 2019-01-16 09:36:26.635501: step 4581, loss = 0.68726 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:36:27.595572 ops/training.py:65 2019-01-16 09:36:27.595505: step 4582, loss = 0.67265 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:36:28.556030 ops/training.py:65 2019-01-16 09:36:28.555955: step 4583, loss = 0.71108 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:36:29.520058 ops/training.py:65 2019-01-16 09:36:29.519987: step 4584, loss = 0.70819 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:36:30.483198 ops/training.py:65 2019-01-16 09:36:30.483131: step 4585, loss = 0.67172 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:36:31.446376 ops/training.py:65 2019-01-16 09:36:31.446325: step 4586, loss = 0.69658 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:36:32.408501 ops/training.py:65 2019-01-16 09:36:32.408422: step 4587, loss = 0.66860 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:36:33.373166 ops/training.py:65 2019-01-16 09:36:33.373103: step 4588, loss = 0.69268 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:36:34.337094 ops/training.py:65 2019-01-16 09:36:34.337042: step 4589, loss = 0.70708 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:36:35.299324 ops/training.py:65 2019-01-16 09:36:35.299272: step 4590, loss = 0.71104 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:36:36.260023 ops/training.py:65 2019-01-16 09:36:36.259966: step 4591, loss = 0.69252 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:36:37.220134 ops/training.py:65 2019-01-16 09:36:37.220085: step 4592, loss = 0.69448 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:36:38.183604 ops/training.py:65 2019-01-16 09:36:38.183543: step 4593, loss = 0.68581 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:36:39.147760 ops/training.py:65 2019-01-16 09:36:39.147710: step 4594, loss = 0.72196 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:36:40.111713 ops/training.py:65 2019-01-16 09:36:40.111665: step 4595, loss = 0.67136 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:36:41.073770 ops/training.py:65 2019-01-16 09:36:41.073719: step 4596, loss = 0.68129 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:36:42.034937 ops/training.py:65 2019-01-16 09:36:42.034889: step 4597, loss = 0.71934 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:36:42.995027 ops/training.py:65 2019-01-16 09:36:42.994959: step 4598, loss = 0.71988 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:36:43.956264 ops/training.py:65 2019-01-16 09:36:43.956197: step 4599, loss = 0.71795 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:36:44.917773 ops/training.py:65 2019-01-16 09:36:44.917713: step 4600, loss = 0.68007 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:36:45.882047 ops/training.py:65 2019-01-16 09:36:45.881975: step 4601, loss = 0.70005 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:36:46.845739 ops/training.py:65 2019-01-16 09:36:46.845692: step 4602, loss = 0.69824 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:36:47.808931 ops/training.py:65 2019-01-16 09:36:47.808879: step 4603, loss = 0.68339 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:36:48.771350 ops/training.py:65 2019-01-16 09:36:48.771302: step 4604, loss = 0.70532 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:36:49.732757 ops/training.py:65 2019-01-16 09:36:49.732699: step 4605, loss = 0.69067 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:36:50.694375 ops/training.py:65 2019-01-16 09:36:50.694297: step 4606, loss = 0.69354 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:36:51.656342 ops/training.py:65 2019-01-16 09:36:51.656266: step 4607, loss = 0.66693 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:36:52.617903 ops/training.py:65 2019-01-16 09:36:52.617848: step 4608, loss = 0.66945 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:36:53.577983 ops/training.py:65 2019-01-16 09:36:53.577929: step 4609, loss = 0.68959 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:36:54.537813 ops/training.py:65 2019-01-16 09:36:54.537766: step 4610, loss = 0.68965 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:36:55.497617 ops/training.py:65 2019-01-16 09:36:55.497564: step 4611, loss = 0.71366 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:36:56.462187 ops/training.py:65 2019-01-16 09:36:56.462137: step 4612, loss = 0.71345 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:36:57.425484 ops/training.py:65 2019-01-16 09:36:57.425423: step 4613, loss = 0.68541 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:36:58.389390 ops/training.py:65 2019-01-16 09:36:58.389339: step 4614, loss = 0.72041 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:36:59.350204 ops/training.py:65 2019-01-16 09:36:59.350149: step 4615, loss = 0.66895 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:37:00.311756 ops/training.py:65 2019-01-16 09:37:00.311679: step 4616, loss = 0.67576 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:37:01.272474 ops/training.py:65 2019-01-16 09:37:01.272421: step 4617, loss = 0.70393 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:37:02.234252 ops/training.py:65 2019-01-16 09:37:02.234199: step 4618, loss = 0.65708 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:37:03.196131 ops/training.py:65 2019-01-16 09:37:03.196080: step 4619, loss = 0.70684 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:37:04.157859 ops/training.py:65 2019-01-16 09:37:04.157812: step 4620, loss = 0.71987 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:37:05.119665 ops/training.py:65 2019-01-16 09:37:05.119611: step 4621, loss = 0.67304 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:37:06.081961 ops/training.py:65 2019-01-16 09:37:06.081910: step 4622, loss = 0.67866 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:37:07.043013 ops/training.py:65 2019-01-16 09:37:07.042963: step 4623, loss = 0.70046 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:37:08.007228 ops/training.py:65 2019-01-16 09:37:08.007181: step 4624, loss = 0.66542 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:37:08.971375 ops/training.py:65 2019-01-16 09:37:08.971325: step 4625, loss = 0.71909 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:37:09.933985 ops/training.py:65 2019-01-16 09:37:09.933936: step 4626, loss = 0.69600 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:37:10.896018 ops/training.py:65 2019-01-16 09:37:10.895970: step 4627, loss = 0.71160 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:37:11.857924 ops/training.py:65 2019-01-16 09:37:11.857874: step 4628, loss = 0.70230 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:37:12.819446 ops/training.py:65 2019-01-16 09:37:12.819394: step 4629, loss = 0.69885 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:37:13.781104 ops/training.py:65 2019-01-16 09:37:13.781055: step 4630, loss = 0.71109 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:37:14.744465 ops/training.py:65 2019-01-16 09:37:14.744407: step 4631, loss = 0.70432 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:37:15.705572 ops/training.py:65 2019-01-16 09:37:15.705495: step 4632, loss = 0.69970 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:37:16.671214 ops/training.py:65 2019-01-16 09:37:16.671143: step 4633, loss = 0.71399 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:37:17.636496 ops/training.py:65 2019-01-16 09:37:17.636447: step 4634, loss = 0.67270 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:37:18.598623 ops/training.py:65 2019-01-16 09:37:18.598570: step 4635, loss = 0.73592 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:37:19.562916 ops/training.py:65 2019-01-16 09:37:19.562855: step 4636, loss = 0.74426 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:37:20.526526 ops/training.py:65 2019-01-16 09:37:20.526459: step 4637, loss = 0.67093 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:37:21.488724 ops/training.py:65 2019-01-16 09:37:21.488660: step 4638, loss = 0.72624 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:37:22.449228 ops/training.py:65 2019-01-16 09:37:22.449154: step 4639, loss = 0.71689 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:37:23.410133 ops/training.py:65 2019-01-16 09:37:23.410087: step 4640, loss = 0.71208 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:37:24.374125 ops/training.py:65 2019-01-16 09:37:24.374081: step 4641, loss = 0.60775 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:37:25.338584 ops/training.py:65 2019-01-16 09:37:25.338516: step 4642, loss = 0.74261 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:37:26.301070 ops/training.py:65 2019-01-16 09:37:26.301020: step 4643, loss = 0.71453 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:37:27.261588 ops/training.py:65 2019-01-16 09:37:27.261539: step 4644, loss = 0.72607 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:37:28.222799 ops/training.py:65 2019-01-16 09:37:28.222748: step 4645, loss = 0.75604 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:37:29.184498 ops/training.py:65 2019-01-16 09:37:29.184442: step 4646, loss = 0.66821 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:37:30.145897 ops/training.py:65 2019-01-16 09:37:30.145826: step 4647, loss = 0.67959 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:37:31.108045 ops/training.py:65 2019-01-16 09:37:31.107993: step 4648, loss = 0.68906 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:37:32.068979 ops/training.py:65 2019-01-16 09:37:32.068927: step 4649, loss = 0.70401 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:37:33.030584 ops/training.py:65 2019-01-16 09:37:33.030537: step 4650, loss = 0.73597 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:37:33.991296 ops/training.py:65 2019-01-16 09:37:33.991246: step 4651, loss = 0.70191 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:37:34.953025 ops/training.py:65 2019-01-16 09:37:34.952972: step 4652, loss = 0.69139 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:37:35.914898 ops/training.py:65 2019-01-16 09:37:35.914852: step 4653, loss = 0.63441 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:37:36.876150 ops/training.py:65 2019-01-16 09:37:36.876100: step 4654, loss = 0.67038 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:37:37.838068 ops/training.py:65 2019-01-16 09:37:37.838019: step 4655, loss = 0.68682 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:37:38.800450 ops/training.py:65 2019-01-16 09:37:38.800392: step 4656, loss = 0.72209 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:37:39.762838 ops/training.py:65 2019-01-16 09:37:39.762789: step 4657, loss = 0.76006 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:37:40.723904 ops/training.py:65 2019-01-16 09:37:40.723843: step 4658, loss = 0.69086 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:37:41.685650 ops/training.py:65 2019-01-16 09:37:41.685580: step 4659, loss = 0.65656 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 09:37:42.648046 ops/training.py:65 2019-01-16 09:37:42.647971: step 4660, loss = 0.72935 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:37:43.608960 ops/training.py:65 2019-01-16 09:37:43.608904: step 4661, loss = 0.72476 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:37:44.568016 ops/training.py:65 2019-01-16 09:37:44.567952: step 4662, loss = 0.67765 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:37:45.526294 ops/training.py:65 2019-01-16 09:37:45.526232: step 4663, loss = 0.72895 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:37:46.489368 ops/training.py:65 2019-01-16 09:37:46.489290: step 4664, loss = 0.70191 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:37:47.453295 ops/training.py:65 2019-01-16 09:37:47.453220: step 4665, loss = 0.70602 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:37:48.415990 ops/training.py:65 2019-01-16 09:37:48.415920: step 4666, loss = 0.69802 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:37:49.380928 ops/training.py:65 2019-01-16 09:37:49.380880: step 4667, loss = 0.70973 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:37:50.343385 ops/training.py:65 2019-01-16 09:37:50.343337: step 4668, loss = 0.72486 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:37:51.304664 ops/training.py:65 2019-01-16 09:37:51.304620: step 4669, loss = 0.66588 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:37:52.266468 ops/training.py:65 2019-01-16 09:37:52.266421: step 4670, loss = 0.68590 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:37:53.227036 ops/training.py:65 2019-01-16 09:37:53.226981: step 4671, loss = 0.70395 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:37:54.188571 ops/training.py:65 2019-01-16 09:37:54.188521: step 4672, loss = 0.70121 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:37:55.149107 ops/training.py:65 2019-01-16 09:37:55.149056: step 4673, loss = 0.72104 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:37:56.110089 ops/training.py:65 2019-01-16 09:37:56.110037: step 4674, loss = 0.67329 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:37:57.070451 ops/training.py:65 2019-01-16 09:37:57.070399: step 4675, loss = 0.70337 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:37:58.030600 ops/training.py:65 2019-01-16 09:37:58.030545: step 4676, loss = 0.69018 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:37:58.991999 ops/training.py:65 2019-01-16 09:37:58.991947: step 4677, loss = 0.68448 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:37:59.951664 ops/training.py:65 2019-01-16 09:37:59.951591: step 4678, loss = 0.69530 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:38:00.912748 ops/training.py:65 2019-01-16 09:38:00.912680: step 4679, loss = 0.68968 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:38:01.873208 ops/training.py:65 2019-01-16 09:38:01.873136: step 4680, loss = 0.70787 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:38:02.836830 ops/training.py:65 2019-01-16 09:38:02.836784: step 4681, loss = 0.72270 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:38:03.800784 ops/training.py:65 2019-01-16 09:38:03.800731: step 4682, loss = 0.68497 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:38:04.762843 ops/training.py:65 2019-01-16 09:38:04.762791: step 4683, loss = 0.71436 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:38:05.724167 ops/training.py:65 2019-01-16 09:38:05.724098: step 4684, loss = 0.69445 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:38:06.685712 ops/training.py:65 2019-01-16 09:38:06.685639: step 4685, loss = 0.71679 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:38:07.647044 ops/training.py:65 2019-01-16 09:38:07.646977: step 4686, loss = 0.69446 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:38:08.609824 ops/training.py:65 2019-01-16 09:38:08.609775: step 4687, loss = 0.69278 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:38:09.571544 ops/training.py:65 2019-01-16 09:38:09.571497: step 4688, loss = 0.69782 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:38:10.533120 ops/training.py:65 2019-01-16 09:38:10.533069: step 4689, loss = 0.69863 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:38:11.494363 ops/training.py:65 2019-01-16 09:38:11.494316: step 4690, loss = 0.70862 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:38:12.456123 ops/training.py:65 2019-01-16 09:38:12.456073: step 4691, loss = 0.69915 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:38:13.417389 ops/training.py:65 2019-01-16 09:38:13.417339: step 4692, loss = 0.69224 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:38:14.379354 ops/training.py:65 2019-01-16 09:38:14.379306: step 4693, loss = 0.69935 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:38:15.340437 ops/training.py:65 2019-01-16 09:38:15.340388: step 4694, loss = 0.70124 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:38:16.302970 ops/training.py:65 2019-01-16 09:38:16.302918: step 4695, loss = 0.70372 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:38:17.264645 ops/training.py:65 2019-01-16 09:38:17.264597: step 4696, loss = 0.69656 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:38:18.226020 ops/training.py:65 2019-01-16 09:38:18.225968: step 4697, loss = 0.71449 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:38:19.188564 ops/training.py:65 2019-01-16 09:38:19.188492: step 4698, loss = 0.68211 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:38:20.150435 ops/training.py:65 2019-01-16 09:38:20.150362: step 4699, loss = 0.67463 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:38:21.111748 ops/training.py:65 2019-01-16 09:38:21.111696: step 4700, loss = 0.71957 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:38:22.072361 ops/training.py:65 2019-01-16 09:38:22.072293: step 4701, loss = 0.68438 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:38:23.034615 ops/training.py:65 2019-01-16 09:38:23.034553: step 4702, loss = 0.70569 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:38:23.996376 ops/training.py:65 2019-01-16 09:38:23.996310: step 4703, loss = 0.69549 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:38:24.957010 ops/training.py:65 2019-01-16 09:38:24.956938: step 4704, loss = 0.70562 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:38:25.917798 ops/training.py:65 2019-01-16 09:38:25.917739: step 4705, loss = 0.68926 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:38:26.879477 ops/training.py:65 2019-01-16 09:38:26.879429: step 4706, loss = 0.69659 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:38:27.841434 ops/training.py:65 2019-01-16 09:38:27.841386: step 4707, loss = 0.68768 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:38:28.802677 ops/training.py:65 2019-01-16 09:38:28.802611: step 4708, loss = 0.68447 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:38:29.766789 ops/training.py:65 2019-01-16 09:38:29.766739: step 4709, loss = 0.70081 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:38:30.730627 ops/training.py:65 2019-01-16 09:38:30.730577: step 4710, loss = 0.69345 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:38:31.691690 ops/training.py:65 2019-01-16 09:38:31.691625: step 4711, loss = 0.69977 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:38:32.652936 ops/training.py:65 2019-01-16 09:38:32.652877: step 4712, loss = 0.70393 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:38:33.617640 ops/training.py:65 2019-01-16 09:38:33.617593: step 4713, loss = 0.67606 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:38:34.581210 ops/training.py:65 2019-01-16 09:38:34.581162: step 4714, loss = 0.71724 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:38:35.543828 ops/training.py:65 2019-01-16 09:38:35.543778: step 4715, loss = 0.64500 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:38:36.505910 ops/training.py:65 2019-01-16 09:38:36.505862: step 4716, loss = 0.70446 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:38:37.468135 ops/training.py:65 2019-01-16 09:38:37.468086: step 4717, loss = 0.69364 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:38:38.429136 ops/training.py:65 2019-01-16 09:38:38.429083: step 4718, loss = 0.69930 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:38:39.393462 ops/training.py:65 2019-01-16 09:38:39.393418: step 4719, loss = 0.69100 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:38:40.356552 ops/training.py:65 2019-01-16 09:38:40.356499: step 4720, loss = 0.66914 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:38:41.320671 ops/training.py:65 2019-01-16 09:38:41.320623: step 4721, loss = 0.68792 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:38:42.284156 ops/training.py:65 2019-01-16 09:38:42.284106: step 4722, loss = 0.70365 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:38:43.247679 ops/training.py:65 2019-01-16 09:38:43.247628: step 4723, loss = 0.69574 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:38:44.209577 ops/training.py:65 2019-01-16 09:38:44.209522: step 4724, loss = 0.71169 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:38:45.174312 ops/training.py:65 2019-01-16 09:38:45.174259: step 4725, loss = 0.70581 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:38:46.137701 ops/training.py:65 2019-01-16 09:38:46.137655: step 4726, loss = 0.69936 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:38:47.101148 ops/training.py:65 2019-01-16 09:38:47.101098: step 4727, loss = 0.71383 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:38:48.063149 ops/training.py:65 2019-01-16 09:38:48.063103: step 4728, loss = 0.65082 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 09:38:49.023579 ops/training.py:65 2019-01-16 09:38:49.023519: step 4729, loss = 0.68494 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:38:49.983907 ops/training.py:65 2019-01-16 09:38:49.983836: step 4730, loss = 0.75764 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.21875
I0832 2019-01-16 09:38:50.943645 ops/training.py:65 2019-01-16 09:38:50.943573: step 4731, loss = 0.69531 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:38:51.902813 ops/training.py:65 2019-01-16 09:38:51.902762: step 4732, loss = 0.69024 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:38:52.866044 ops/training.py:65 2019-01-16 09:38:52.865999: step 4733, loss = 0.70608 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:38:53.830339 ops/training.py:65 2019-01-16 09:38:53.830291: step 4734, loss = 0.72368 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:38:54.793941 ops/training.py:65 2019-01-16 09:38:54.793893: step 4735, loss = 0.67827 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:38:55.755293 ops/training.py:65 2019-01-16 09:38:55.755246: step 4736, loss = 0.69310 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:38:56.715816 ops/training.py:65 2019-01-16 09:38:56.715765: step 4737, loss = 0.71373 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:38:57.680165 ops/training.py:65 2019-01-16 09:38:57.680116: step 4738, loss = 0.71812 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:38:58.642856 ops/training.py:65 2019-01-16 09:38:58.642808: step 4739, loss = 0.71896 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:38:59.606928 ops/training.py:65 2019-01-16 09:38:59.606875: step 4740, loss = 0.69288 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:39:00.570500 ops/training.py:65 2019-01-16 09:39:00.570423: step 4741, loss = 0.65280 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:39:01.533690 ops/training.py:65 2019-01-16 09:39:01.533637: step 4742, loss = 0.69955 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:39:02.494342 ops/training.py:65 2019-01-16 09:39:02.494291: step 4743, loss = 0.71243 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:39:03.456345 ops/training.py:65 2019-01-16 09:39:03.456292: step 4744, loss = 0.67844 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:39:04.418761 ops/training.py:65 2019-01-16 09:39:04.418709: step 4745, loss = 0.69873 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:39:05.380214 ops/training.py:65 2019-01-16 09:39:05.380165: step 4746, loss = 0.69002 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:39:06.342634 ops/training.py:65 2019-01-16 09:39:06.342586: step 4747, loss = 0.66095 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:39:07.303858 ops/training.py:65 2019-01-16 09:39:07.303807: step 4748, loss = 0.74703 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:39:08.265918 ops/training.py:65 2019-01-16 09:39:08.265867: step 4749, loss = 0.69675 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:39:09.227361 ops/training.py:65 2019-01-16 09:39:09.227311: step 4750, loss = 0.69243 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:39:10.189332 ops/training.py:65 2019-01-16 09:39:10.189279: step 4751, loss = 0.76369 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:39:11.151339 ops/training.py:65 2019-01-16 09:39:11.151289: step 4752, loss = 0.65402 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:39:12.113844 ops/training.py:65 2019-01-16 09:39:12.113787: step 4753, loss = 0.65352 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 09:39:13.076557 ops/training.py:65 2019-01-16 09:39:13.076483: step 4754, loss = 0.74906 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:39:14.038143 ops/training.py:65 2019-01-16 09:39:14.038070: step 4755, loss = 0.69474 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:39:15.001748 ops/training.py:65 2019-01-16 09:39:15.001703: step 4756, loss = 0.72420 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:39:15.965836 ops/training.py:65 2019-01-16 09:39:15.965787: step 4757, loss = 0.69060 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:39:16.928573 ops/training.py:65 2019-01-16 09:39:16.928519: step 4758, loss = 0.75024 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:39:17.892996 ops/training.py:65 2019-01-16 09:39:17.892946: step 4759, loss = 0.68220 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:39:18.856069 ops/training.py:65 2019-01-16 09:39:18.856000: step 4760, loss = 0.65805 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:39:19.817163 ops/training.py:65 2019-01-16 09:39:19.817093: step 4761, loss = 0.69861 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:39:20.780248 ops/training.py:65 2019-01-16 09:39:20.780201: step 4762, loss = 0.68935 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:39:21.742281 ops/training.py:65 2019-01-16 09:39:21.742232: step 4763, loss = 0.73042 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:39:22.703808 ops/training.py:65 2019-01-16 09:39:22.703757: step 4764, loss = 0.68357 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:39:23.666425 ops/training.py:65 2019-01-16 09:39:23.666367: step 4765, loss = 0.69026 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:39:24.628704 ops/training.py:65 2019-01-16 09:39:24.628651: step 4766, loss = 0.69195 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:39:25.590852 ops/training.py:65 2019-01-16 09:39:25.590801: step 4767, loss = 0.74878 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:39:26.552611 ops/training.py:65 2019-01-16 09:39:26.552556: step 4768, loss = 0.66538 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:39:27.512491 ops/training.py:65 2019-01-16 09:39:27.512441: step 4769, loss = 0.67129 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:39:28.476708 ops/training.py:65 2019-01-16 09:39:28.476661: step 4770, loss = 0.69463 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:39:29.440139 ops/training.py:65 2019-01-16 09:39:29.440086: step 4771, loss = 0.64258 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:39:30.402692 ops/training.py:65 2019-01-16 09:39:30.402621: step 4772, loss = 0.67916 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:39:31.364334 ops/training.py:65 2019-01-16 09:39:31.364261: step 4773, loss = 0.73532 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:39:32.326966 ops/training.py:65 2019-01-16 09:39:32.326911: step 4774, loss = 0.70279 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:39:33.290931 ops/training.py:65 2019-01-16 09:39:33.290860: step 4775, loss = 0.66734 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:39:34.254800 ops/training.py:65 2019-01-16 09:39:34.254727: step 4776, loss = 0.70730 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:39:35.218368 ops/training.py:65 2019-01-16 09:39:35.218289: step 4777, loss = 0.73137 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:39:36.180366 ops/training.py:65 2019-01-16 09:39:36.180284: step 4778, loss = 0.68525 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:39:37.141767 ops/training.py:65 2019-01-16 09:39:37.141695: step 4779, loss = 0.74752 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:39:38.103145 ops/training.py:65 2019-01-16 09:39:38.103085: step 4780, loss = 0.75695 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:39:39.065223 ops/training.py:65 2019-01-16 09:39:39.065166: step 4781, loss = 0.79000 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:39:40.030278 ops/training.py:65 2019-01-16 09:39:40.030229: step 4782, loss = 0.72592 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:39:40.994106 ops/training.py:65 2019-01-16 09:39:40.994049: step 4783, loss = 0.79738 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:39:41.958780 ops/training.py:65 2019-01-16 09:39:41.958720: step 4784, loss = 0.68585 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:39:42.922773 ops/training.py:65 2019-01-16 09:39:42.922700: step 4785, loss = 0.73152 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:39:43.886564 ops/training.py:65 2019-01-16 09:39:43.886511: step 4786, loss = 0.68822 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:39:44.848524 ops/training.py:65 2019-01-16 09:39:44.848432: step 4787, loss = 0.74584 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:39:45.810717 ops/training.py:65 2019-01-16 09:39:45.810650: step 4788, loss = 0.69774 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:39:46.772697 ops/training.py:65 2019-01-16 09:39:46.772647: step 4789, loss = 0.69453 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:39:47.733902 ops/training.py:65 2019-01-16 09:39:47.733852: step 4790, loss = 0.66132 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:39:48.695347 ops/training.py:65 2019-01-16 09:39:48.695297: step 4791, loss = 0.69239 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:39:49.656792 ops/training.py:65 2019-01-16 09:39:49.656744: step 4792, loss = 0.72548 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:39:50.618623 ops/training.py:65 2019-01-16 09:39:50.618575: step 4793, loss = 0.68041 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:39:51.579846 ops/training.py:65 2019-01-16 09:39:51.579796: step 4794, loss = 0.70141 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:39:52.541006 ops/training.py:65 2019-01-16 09:39:52.540951: step 4795, loss = 0.74454 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:39:53.505448 ops/training.py:65 2019-01-16 09:39:53.505378: step 4796, loss = 0.70830 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:39:54.469083 ops/training.py:65 2019-01-16 09:39:54.469013: step 4797, loss = 0.64875 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:39:55.432210 ops/training.py:65 2019-01-16 09:39:55.432139: step 4798, loss = 0.67713 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:39:56.394088 ops/training.py:65 2019-01-16 09:39:56.394034: step 4799, loss = 0.71417 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:39:57.355307 ops/training.py:65 2019-01-16 09:39:57.355232: step 4800, loss = 0.69118 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:39:58.316743 ops/training.py:65 2019-01-16 09:39:58.316682: step 4801, loss = 0.71844 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:39:59.277938 ops/training.py:65 2019-01-16 09:39:59.277892: step 4802, loss = 0.70853 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:40:00.239236 ops/training.py:65 2019-01-16 09:40:00.239190: step 4803, loss = 0.72496 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:40:01.201165 ops/training.py:65 2019-01-16 09:40:01.201111: step 4804, loss = 0.70346 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:40:02.163251 ops/training.py:65 2019-01-16 09:40:02.163191: step 4805, loss = 0.71254 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:40:03.127619 ops/training.py:65 2019-01-16 09:40:03.127550: step 4806, loss = 0.70403 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:40:04.092156 ops/training.py:65 2019-01-16 09:40:04.092080: step 4807, loss = 0.71466 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:40:05.056102 ops/training.py:65 2019-01-16 09:40:05.056029: step 4808, loss = 0.71100 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:40:06.017993 ops/training.py:65 2019-01-16 09:40:06.017941: step 4809, loss = 0.69064 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:40:06.979629 ops/training.py:65 2019-01-16 09:40:06.979574: step 4810, loss = 0.71119 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:40:07.941227 ops/training.py:65 2019-01-16 09:40:07.941174: step 4811, loss = 0.68873 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:40:08.902843 ops/training.py:65 2019-01-16 09:40:08.902793: step 4812, loss = 0.67770 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:40:09.865819 ops/training.py:65 2019-01-16 09:40:09.865765: step 4813, loss = 0.67352 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:40:10.827928 ops/training.py:65 2019-01-16 09:40:10.827845: step 4814, loss = 0.69361 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:40:11.789789 ops/training.py:65 2019-01-16 09:40:11.789722: step 4815, loss = 0.67034 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:40:12.751557 ops/training.py:65 2019-01-16 09:40:12.751507: step 4816, loss = 0.73486 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:40:13.713710 ops/training.py:65 2019-01-16 09:40:13.713648: step 4817, loss = 0.69177 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:40:14.679341 ops/training.py:65 2019-01-16 09:40:14.679270: step 4818, loss = 0.69269 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:40:15.643855 ops/training.py:65 2019-01-16 09:40:15.643783: step 4819, loss = 0.68723 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:40:16.607744 ops/training.py:65 2019-01-16 09:40:16.607687: step 4820, loss = 0.65572 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:40:17.570034 ops/training.py:65 2019-01-16 09:40:17.569980: step 4821, loss = 0.73427 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:40:18.533349 ops/training.py:65 2019-01-16 09:40:18.533302: step 4822, loss = 0.67208 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:40:19.495529 ops/training.py:65 2019-01-16 09:40:19.495480: step 4823, loss = 0.68411 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:40:20.457467 ops/training.py:65 2019-01-16 09:40:20.457410: step 4824, loss = 0.72873 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:40:21.419138 ops/training.py:65 2019-01-16 09:40:21.419089: step 4825, loss = 0.77386 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:40:22.380294 ops/training.py:65 2019-01-16 09:40:22.380244: step 4826, loss = 0.72335 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:40:23.341322 ops/training.py:65 2019-01-16 09:40:23.341259: step 4827, loss = 0.69315 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:40:24.303487 ops/training.py:65 2019-01-16 09:40:24.303431: step 4828, loss = 0.69725 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:40:25.264779 ops/training.py:65 2019-01-16 09:40:25.264724: step 4829, loss = 0.77093 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:40:26.226563 ops/training.py:65 2019-01-16 09:40:26.226496: step 4830, loss = 0.65366 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:40:27.187715 ops/training.py:65 2019-01-16 09:40:27.187644: step 4831, loss = 0.67467 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:40:28.148157 ops/training.py:65 2019-01-16 09:40:28.148107: step 4832, loss = 0.74122 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:40:29.109055 ops/training.py:65 2019-01-16 09:40:29.109003: step 4833, loss = 0.73859 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:40:30.069817 ops/training.py:65 2019-01-16 09:40:30.069753: step 4834, loss = 0.68496 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:40:31.031385 ops/training.py:65 2019-01-16 09:40:31.031332: step 4835, loss = 0.69370 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:40:31.992030 ops/training.py:65 2019-01-16 09:40:31.991977: step 4836, loss = 0.64757 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:40:32.952979 ops/training.py:65 2019-01-16 09:40:32.952924: step 4837, loss = 0.73297 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:40:33.914490 ops/training.py:65 2019-01-16 09:40:33.914443: step 4838, loss = 0.73112 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:40:34.876308 ops/training.py:65 2019-01-16 09:40:34.876247: step 4839, loss = 0.76736 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:40:35.838358 ops/training.py:65 2019-01-16 09:40:35.838288: step 4840, loss = 0.67993 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:40:36.799818 ops/training.py:65 2019-01-16 09:40:36.799762: step 4841, loss = 0.66393 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:40:37.761943 ops/training.py:65 2019-01-16 09:40:37.761895: step 4842, loss = 0.67802 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:40:38.722803 ops/training.py:65 2019-01-16 09:40:38.722754: step 4843, loss = 0.72568 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:40:39.684119 ops/training.py:65 2019-01-16 09:40:39.684066: step 4844, loss = 0.65302 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:40:40.646088 ops/training.py:65 2019-01-16 09:40:40.646039: step 4845, loss = 0.67351 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:40:41.607460 ops/training.py:65 2019-01-16 09:40:41.607409: step 4846, loss = 0.67339 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:40:42.568553 ops/training.py:65 2019-01-16 09:40:42.568504: step 4847, loss = 0.69669 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:40:43.530241 ops/training.py:65 2019-01-16 09:40:43.530192: step 4848, loss = 0.73681 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:40:44.491291 ops/training.py:65 2019-01-16 09:40:44.491243: step 4849, loss = 0.70839 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:40:45.451707 ops/training.py:65 2019-01-16 09:40:45.451656: step 4850, loss = 0.74714 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:40:46.412933 ops/training.py:65 2019-01-16 09:40:46.412876: step 4851, loss = 0.67411 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:40:47.377247 ops/training.py:65 2019-01-16 09:40:47.377198: step 4852, loss = 0.74474 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:40:48.339003 ops/training.py:65 2019-01-16 09:40:48.338953: step 4853, loss = 0.70521 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:40:49.301251 ops/training.py:65 2019-01-16 09:40:49.301197: step 4854, loss = 0.70525 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:40:50.263104 ops/training.py:65 2019-01-16 09:40:50.263033: step 4855, loss = 0.71369 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:40:51.224758 ops/training.py:65 2019-01-16 09:40:51.224687: step 4856, loss = 0.70944 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:40:52.185875 ops/training.py:65 2019-01-16 09:40:52.185807: step 4857, loss = 0.69302 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:40:53.147199 ops/training.py:65 2019-01-16 09:40:53.147150: step 4858, loss = 0.68332 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:40:54.107690 ops/training.py:65 2019-01-16 09:40:54.107642: step 4859, loss = 0.70285 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:40:55.068700 ops/training.py:65 2019-01-16 09:40:55.068641: step 4860, loss = 0.69265 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:40:56.030455 ops/training.py:65 2019-01-16 09:40:56.030383: step 4861, loss = 0.70702 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:40:56.992309 ops/training.py:65 2019-01-16 09:40:56.992260: step 4862, loss = 0.70352 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:40:57.953779 ops/training.py:65 2019-01-16 09:40:57.953730: step 4863, loss = 0.68678 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:40:58.915054 ops/training.py:65 2019-01-16 09:40:58.914996: step 4864, loss = 0.68638 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:40:59.875986 ops/training.py:65 2019-01-16 09:40:59.875918: step 4865, loss = 0.71660 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:41:00.836810 ops/training.py:65 2019-01-16 09:41:00.836740: step 4866, loss = 0.72615 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:41:01.798277 ops/training.py:65 2019-01-16 09:41:01.798225: step 4867, loss = 0.65460 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:41:02.759603 ops/training.py:65 2019-01-16 09:41:02.759549: step 4868, loss = 0.68425 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:41:03.722099 ops/training.py:65 2019-01-16 09:41:03.722048: step 4869, loss = 0.69728 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:41:04.684471 ops/training.py:65 2019-01-16 09:41:04.684417: step 4870, loss = 0.72226 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:41:05.648341 ops/training.py:65 2019-01-16 09:41:05.648289: step 4871, loss = 0.68524 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:41:06.611848 ops/training.py:65 2019-01-16 09:41:06.611799: step 4872, loss = 0.65756 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:41:07.573685 ops/training.py:65 2019-01-16 09:41:07.573629: step 4873, loss = 0.71696 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:41:08.536290 ops/training.py:65 2019-01-16 09:41:08.536233: step 4874, loss = 0.73391 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:41:09.498620 ops/training.py:65 2019-01-16 09:41:09.498568: step 4875, loss = 0.71390 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:41:10.460771 ops/training.py:65 2019-01-16 09:41:10.460716: step 4876, loss = 0.73427 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:41:11.423169 ops/training.py:65 2019-01-16 09:41:11.423100: step 4877, loss = 0.67876 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:41:12.385261 ops/training.py:65 2019-01-16 09:41:12.385211: step 4878, loss = 0.73016 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:41:13.345505 ops/training.py:65 2019-01-16 09:41:13.345442: step 4879, loss = 0.71698 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:41:14.308509 ops/training.py:65 2019-01-16 09:41:14.308451: step 4880, loss = 0.72666 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:41:15.270917 ops/training.py:65 2019-01-16 09:41:15.270870: step 4881, loss = 0.65726 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:41:16.232400 ops/training.py:65 2019-01-16 09:41:16.232348: step 4882, loss = 0.71143 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:41:17.196880 ops/training.py:65 2019-01-16 09:41:17.196830: step 4883, loss = 0.69576 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:41:18.160639 ops/training.py:65 2019-01-16 09:41:18.160588: step 4884, loss = 0.68119 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:41:19.121787 ops/training.py:65 2019-01-16 09:41:19.121735: step 4885, loss = 0.69510 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:41:20.085472 ops/training.py:65 2019-01-16 09:41:20.085422: step 4886, loss = 0.67129 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:41:21.048339 ops/training.py:65 2019-01-16 09:41:21.048286: step 4887, loss = 0.71716 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:41:22.010259 ops/training.py:65 2019-01-16 09:41:22.010206: step 4888, loss = 0.69638 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:41:22.970620 ops/training.py:65 2019-01-16 09:41:22.970564: step 4889, loss = 0.67655 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:41:23.931010 ops/training.py:65 2019-01-16 09:41:23.930954: step 4890, loss = 0.69904 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:41:24.895423 ops/training.py:65 2019-01-16 09:41:24.895377: step 4891, loss = 0.71238 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:41:25.857564 ops/training.py:65 2019-01-16 09:41:25.857514: step 4892, loss = 0.69758 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:41:26.818249 ops/training.py:65 2019-01-16 09:41:26.818185: step 4893, loss = 0.70336 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:41:27.779325 ops/training.py:65 2019-01-16 09:41:27.779270: step 4894, loss = 0.69167 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:41:28.741034 ops/training.py:65 2019-01-16 09:41:28.740982: step 4895, loss = 0.65425 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:41:29.704851 ops/training.py:65 2019-01-16 09:41:29.704795: step 4896, loss = 0.69690 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:41:30.665370 ops/training.py:65 2019-01-16 09:41:30.665299: step 4897, loss = 0.65755 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:41:31.626368 ops/training.py:65 2019-01-16 09:41:31.626319: step 4898, loss = 0.68372 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:41:32.586569 ops/training.py:65 2019-01-16 09:41:32.586514: step 4899, loss = 0.70657 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:41:33.548307 ops/training.py:65 2019-01-16 09:41:33.548250: step 4900, loss = 0.71213 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:41:34.512466 ops/training.py:65 2019-01-16 09:41:34.512417: step 4901, loss = 0.69988 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:41:35.475265 ops/training.py:65 2019-01-16 09:41:35.475212: step 4902, loss = 0.70772 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:41:36.437378 ops/training.py:65 2019-01-16 09:41:36.437307: step 4903, loss = 0.70922 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:41:37.398641 ops/training.py:65 2019-01-16 09:41:37.398567: step 4904, loss = 0.67934 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:41:38.360914 ops/training.py:65 2019-01-16 09:41:38.360844: step 4905, loss = 0.69695 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:41:39.321680 ops/training.py:65 2019-01-16 09:41:39.321604: step 4906, loss = 0.70875 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:41:40.283019 ops/training.py:65 2019-01-16 09:41:40.282942: step 4907, loss = 0.68411 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:41:41.247640 ops/training.py:65 2019-01-16 09:41:41.247591: step 4908, loss = 0.71029 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:41:42.211606 ops/training.py:65 2019-01-16 09:41:42.211547: step 4909, loss = 0.69775 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:41:43.173249 ops/training.py:65 2019-01-16 09:41:43.173189: step 4910, loss = 0.69118 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:41:44.134101 ops/training.py:65 2019-01-16 09:41:44.134052: step 4911, loss = 0.66506 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:41:45.094942 ops/training.py:65 2019-01-16 09:41:45.094886: step 4912, loss = 0.67545 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:41:46.055805 ops/training.py:65 2019-01-16 09:41:46.055746: step 4913, loss = 0.66417 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:41:47.016259 ops/training.py:65 2019-01-16 09:41:47.016213: step 4914, loss = 0.64968 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:41:47.980890 ops/training.py:65 2019-01-16 09:41:47.980841: step 4915, loss = 0.71414 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:41:48.944204 ops/training.py:65 2019-01-16 09:41:48.944115: step 4916, loss = 0.65462 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:41:49.907062 ops/training.py:65 2019-01-16 09:41:49.906992: step 4917, loss = 0.71671 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:41:50.868825 ops/training.py:65 2019-01-16 09:41:50.868777: step 4918, loss = 0.68963 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:41:51.829326 ops/training.py:65 2019-01-16 09:41:51.829271: step 4919, loss = 0.78599 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:41:52.790084 ops/training.py:65 2019-01-16 09:41:52.790026: step 4920, loss = 0.64109 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:41:53.754060 ops/training.py:65 2019-01-16 09:41:53.754009: step 4921, loss = 0.74974 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:41:54.718511 ops/training.py:65 2019-01-16 09:41:54.718440: step 4922, loss = 0.71581 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:41:55.682865 ops/training.py:65 2019-01-16 09:41:55.682794: step 4923, loss = 0.71731 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:41:56.644957 ops/training.py:65 2019-01-16 09:41:56.644908: step 4924, loss = 0.77299 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:41:57.604901 ops/training.py:65 2019-01-16 09:41:57.604848: step 4925, loss = 0.69692 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:41:58.569209 ops/training.py:65 2019-01-16 09:41:58.569153: step 4926, loss = 0.71068 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:41:59.532482 ops/training.py:65 2019-01-16 09:41:59.532430: step 4927, loss = 0.74451 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:42:00.496194 ops/training.py:65 2019-01-16 09:42:00.496137: step 4928, loss = 0.74727 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:42:01.458293 ops/training.py:65 2019-01-16 09:42:01.458237: step 4929, loss = 0.77253 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:42:02.419998 ops/training.py:65 2019-01-16 09:42:02.419937: step 4930, loss = 0.71866 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:42:03.382036 ops/training.py:65 2019-01-16 09:42:03.381988: step 4931, loss = 0.74125 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:42:04.343874 ops/training.py:65 2019-01-16 09:42:04.343822: step 4932, loss = 0.73495 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:42:05.305655 ops/training.py:65 2019-01-16 09:42:05.305599: step 4933, loss = 0.70624 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:42:06.270232 ops/training.py:65 2019-01-16 09:42:06.270185: step 4934, loss = 0.66593 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:42:07.235684 ops/training.py:65 2019-01-16 09:42:07.235634: step 4935, loss = 0.73744 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:42:08.198934 ops/training.py:65 2019-01-16 09:42:08.198884: step 4936, loss = 0.73381 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:42:09.161232 ops/training.py:65 2019-01-16 09:42:09.161174: step 4937, loss = 0.70155 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:42:10.125935 ops/training.py:65 2019-01-16 09:42:10.125887: step 4938, loss = 0.70529 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:42:11.087185 ops/training.py:65 2019-01-16 09:42:11.087132: step 4939, loss = 0.68067 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:42:12.048199 ops/training.py:65 2019-01-16 09:42:12.048146: step 4940, loss = 0.78364 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:42:13.008344 ops/training.py:65 2019-01-16 09:42:13.008294: step 4941, loss = 0.71235 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:42:13.972613 ops/training.py:65 2019-01-16 09:42:13.972562: step 4942, loss = 0.69110 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:42:14.937200 ops/training.py:65 2019-01-16 09:42:14.937148: step 4943, loss = 0.71311 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:42:15.899454 ops/training.py:65 2019-01-16 09:42:15.899406: step 4944, loss = 0.71301 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:42:16.862014 ops/training.py:65 2019-01-16 09:42:16.861961: step 4945, loss = 0.71422 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:42:17.822426 ops/training.py:65 2019-01-16 09:42:17.822370: step 4946, loss = 0.72066 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:42:18.783555 ops/training.py:65 2019-01-16 09:42:18.783508: step 4947, loss = 0.82143 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:42:19.747463 ops/training.py:65 2019-01-16 09:42:19.747393: step 4948, loss = 0.70706 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:42:20.710017 ops/training.py:65 2019-01-16 09:42:20.709945: step 4949, loss = 0.66209 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 09:42:21.671133 ops/training.py:65 2019-01-16 09:42:21.671070: step 4950, loss = 0.71055 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:42:22.632594 ops/training.py:65 2019-01-16 09:42:22.632541: step 4951, loss = 0.68021 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:42:23.598156 ops/training.py:65 2019-01-16 09:42:23.598106: step 4952, loss = 0.67156 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:42:24.563307 ops/training.py:65 2019-01-16 09:42:24.563258: step 4953, loss = 0.71821 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:42:25.526956 ops/training.py:65 2019-01-16 09:42:25.526902: step 4954, loss = 0.69562 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:42:26.489155 ops/training.py:65 2019-01-16 09:42:26.489084: step 4955, loss = 0.73034 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:42:27.451109 ops/training.py:65 2019-01-16 09:42:27.451038: step 4956, loss = 0.71597 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:42:28.412742 ops/training.py:65 2019-01-16 09:42:28.412693: step 4957, loss = 0.73706 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:42:29.373903 ops/training.py:65 2019-01-16 09:42:29.373848: step 4958, loss = 0.64761 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:42:30.335519 ops/training.py:65 2019-01-16 09:42:30.335446: step 4959, loss = 0.68485 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:42:31.297426 ops/training.py:65 2019-01-16 09:42:31.297351: step 4960, loss = 0.70049 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:42:32.260317 ops/training.py:65 2019-01-16 09:42:32.260262: step 4961, loss = 0.71983 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:42:33.224746 ops/training.py:65 2019-01-16 09:42:33.224695: step 4962, loss = 0.67041 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:42:34.188359 ops/training.py:65 2019-01-16 09:42:34.188306: step 4963, loss = 0.67290 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:42:35.151598 ops/training.py:65 2019-01-16 09:42:35.151551: step 4964, loss = 0.69473 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:42:36.113025 ops/training.py:65 2019-01-16 09:42:36.112971: step 4965, loss = 0.70628 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:42:37.074448 ops/training.py:65 2019-01-16 09:42:37.074396: step 4966, loss = 0.65769 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:42:38.035262 ops/training.py:65 2019-01-16 09:42:38.035214: step 4967, loss = 0.71715 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:42:38.997440 ops/training.py:65 2019-01-16 09:42:38.997391: step 4968, loss = 0.68122 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:42:39.960301 ops/training.py:65 2019-01-16 09:42:39.960251: step 4969, loss = 0.73125 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:42:40.921686 ops/training.py:65 2019-01-16 09:42:40.921637: step 4970, loss = 0.69725 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:42:41.883105 ops/training.py:65 2019-01-16 09:42:41.883056: step 4971, loss = 0.73135 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:42:42.843598 ops/training.py:65 2019-01-16 09:42:42.843544: step 4972, loss = 0.69960 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:42:43.808794 ops/training.py:65 2019-01-16 09:42:43.808739: step 4973, loss = 0.71344 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:42:44.773739 ops/training.py:65 2019-01-16 09:42:44.773668: step 4974, loss = 0.67113 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:42:45.737533 ops/training.py:65 2019-01-16 09:42:45.737460: step 4975, loss = 0.66584 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:42:46.698463 ops/training.py:65 2019-01-16 09:42:46.698410: step 4976, loss = 0.69794 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:42:47.660641 ops/training.py:65 2019-01-16 09:42:47.660592: step 4977, loss = 0.69462 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:42:48.622338 ops/training.py:65 2019-01-16 09:42:48.622281: step 4978, loss = 0.70487 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:42:49.584028 ops/training.py:65 2019-01-16 09:42:49.583968: step 4979, loss = 0.70087 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:42:50.546132 ops/training.py:65 2019-01-16 09:42:50.546064: step 4980, loss = 0.69963 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:42:51.507697 ops/training.py:65 2019-01-16 09:42:51.507634: step 4981, loss = 0.69107 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:42:52.466825 ops/training.py:65 2019-01-16 09:42:52.466761: step 4982, loss = 0.67175 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:42:53.426034 ops/training.py:65 2019-01-16 09:42:53.425947: step 4983, loss = 0.70787 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:42:54.385775 ops/training.py:65 2019-01-16 09:42:54.385726: step 4984, loss = 0.71036 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:42:55.344601 ops/training.py:65 2019-01-16 09:42:55.344536: step 4985, loss = 0.70275 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:42:56.307191 ops/training.py:65 2019-01-16 09:42:56.307142: step 4986, loss = 0.68286 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:42:57.271371 ops/training.py:65 2019-01-16 09:42:57.271317: step 4987, loss = 0.69676 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:42:58.234529 ops/training.py:65 2019-01-16 09:42:58.234479: step 4988, loss = 0.68490 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:42:59.196153 ops/training.py:65 2019-01-16 09:42:59.196099: step 4989, loss = 0.69461 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:43:00.156608 ops/training.py:65 2019-01-16 09:43:00.156550: step 4990, loss = 0.68705 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:43:01.121350 ops/training.py:65 2019-01-16 09:43:01.121281: step 4991, loss = 0.67848 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:43:02.085247 ops/training.py:65 2019-01-16 09:43:02.085187: step 4992, loss = 0.69075 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:43:03.048410 ops/training.py:65 2019-01-16 09:43:03.048355: step 4993, loss = 0.64981 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:43:04.010865 ops/training.py:65 2019-01-16 09:43:04.010814: step 4994, loss = 0.66846 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:43:04.972323 ops/training.py:65 2019-01-16 09:43:04.972271: step 4995, loss = 0.65612 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 09:43:05.935186 ops/training.py:65 2019-01-16 09:43:05.935130: step 4996, loss = 0.69372 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:43:06.900028 ops/training.py:65 2019-01-16 09:43:06.899978: step 4997, loss = 0.71012 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:43:07.864205 ops/training.py:65 2019-01-16 09:43:07.864156: step 4998, loss = 0.65484 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:43:08.827590 ops/training.py:65 2019-01-16 09:43:08.827535: step 4999, loss = 0.70498 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:43:09.789825 ops/training.py:65 2019-01-16 09:43:09.789752: step 5000, loss = 0.68614 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:43:10.752242 ops/training.py:65 2019-01-16 09:43:10.752174: step 5001, loss = 0.73065 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:43:11.713397 ops/training.py:65 2019-01-16 09:43:11.713346: step 5002, loss = 0.69402 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:43:12.674956 ops/training.py:65 2019-01-16 09:43:12.674905: step 5003, loss = 0.68084 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:43:13.636129 ops/training.py:65 2019-01-16 09:43:13.636077: step 5004, loss = 0.74499 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:43:14.596721 ops/training.py:65 2019-01-16 09:43:14.596665: step 5005, loss = 0.70275 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:43:15.556854 ops/training.py:65 2019-01-16 09:43:15.556798: step 5006, loss = 0.70218 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:43:16.521234 ops/training.py:65 2019-01-16 09:43:16.521186: step 5007, loss = 0.66486 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:43:17.485507 ops/training.py:65 2019-01-16 09:43:17.485456: step 5008, loss = 0.73279 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:43:18.446172 ops/training.py:65 2019-01-16 09:43:18.446116: step 5009, loss = 0.71430 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:43:19.407090 ops/training.py:65 2019-01-16 09:43:19.407022: step 5010, loss = 0.71981 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:43:20.368876 ops/training.py:65 2019-01-16 09:43:20.368810: step 5011, loss = 0.70309 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:43:21.329569 ops/training.py:65 2019-01-16 09:43:21.329483: step 5012, loss = 0.66737 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:43:22.293218 ops/training.py:65 2019-01-16 09:43:22.293175: step 5013, loss = 0.68559 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:43:23.259414 ops/training.py:65 2019-01-16 09:43:23.259366: step 5014, loss = 0.69205 (33.1 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:43:24.222749 ops/training.py:65 2019-01-16 09:43:24.222699: step 5015, loss = 0.69289 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:43:25.184457 ops/training.py:65 2019-01-16 09:43:25.184406: step 5016, loss = 0.71185 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:43:26.145749 ops/training.py:65 2019-01-16 09:43:26.145692: step 5017, loss = 0.70522 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:43:27.106431 ops/training.py:65 2019-01-16 09:43:27.106357: step 5018, loss = 0.69835 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:43:28.067996 ops/training.py:65 2019-01-16 09:43:28.067933: step 5019, loss = 0.69489 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:43:29.029441 ops/training.py:65 2019-01-16 09:43:29.029390: step 5020, loss = 0.70385 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:43:29.989654 ops/training.py:65 2019-01-16 09:43:29.989599: step 5021, loss = 0.70941 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:43:30.953526 ops/training.py:65 2019-01-16 09:43:30.953459: step 5022, loss = 0.66991 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:43:31.914045 ops/training.py:65 2019-01-16 09:43:31.913993: step 5023, loss = 0.71816 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:43:32.878666 ops/training.py:65 2019-01-16 09:43:32.878614: step 5024, loss = 0.73836 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:43:33.842326 ops/training.py:65 2019-01-16 09:43:33.842273: step 5025, loss = 0.67723 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:43:34.803172 ops/training.py:65 2019-01-16 09:43:34.803110: step 5026, loss = 0.68917 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:43:35.767715 ops/training.py:65 2019-01-16 09:43:35.767664: step 5027, loss = 0.74800 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:43:36.731930 ops/training.py:65 2019-01-16 09:43:36.731878: step 5028, loss = 0.68338 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:43:37.694667 ops/training.py:65 2019-01-16 09:43:37.694615: step 5029, loss = 0.68999 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:43:38.656036 ops/training.py:65 2019-01-16 09:43:38.655977: step 5030, loss = 0.69584 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:43:39.617447 ops/training.py:65 2019-01-16 09:43:39.617377: step 5031, loss = 0.72139 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:43:40.578851 ops/training.py:65 2019-01-16 09:43:40.578778: step 5032, loss = 0.68381 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:43:41.539471 ops/training.py:65 2019-01-16 09:43:41.539416: step 5033, loss = 0.71876 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:43:42.500775 ops/training.py:65 2019-01-16 09:43:42.500702: step 5034, loss = 0.71035 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:43:43.462982 ops/training.py:65 2019-01-16 09:43:43.462913: step 5035, loss = 0.69231 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:43:44.424307 ops/training.py:65 2019-01-16 09:43:44.424239: step 5036, loss = 0.68367 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:43:45.387001 ops/training.py:65 2019-01-16 09:43:45.386933: step 5037, loss = 0.70331 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:43:46.348608 ops/training.py:65 2019-01-16 09:43:46.348557: step 5038, loss = 0.71182 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:43:47.309926 ops/training.py:65 2019-01-16 09:43:47.309872: step 5039, loss = 0.70154 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:43:48.271829 ops/training.py:65 2019-01-16 09:43:48.271779: step 5040, loss = 0.68970 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:43:49.234056 ops/training.py:65 2019-01-16 09:43:49.234007: step 5041, loss = 0.67014 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:43:50.195556 ops/training.py:65 2019-01-16 09:43:50.195489: step 5042, loss = 0.67694 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:43:51.156467 ops/training.py:65 2019-01-16 09:43:51.156404: step 5043, loss = 0.69148 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:43:52.117685 ops/training.py:65 2019-01-16 09:43:52.117610: step 5044, loss = 0.71598 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:43:53.077856 ops/training.py:65 2019-01-16 09:43:53.077782: step 5045, loss = 0.68135 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:43:54.042582 ops/training.py:65 2019-01-16 09:43:54.042533: step 5046, loss = 0.71625 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:43:55.005430 ops/training.py:65 2019-01-16 09:43:55.005376: step 5047, loss = 0.71300 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:43:55.967985 ops/training.py:65 2019-01-16 09:43:55.967931: step 5048, loss = 0.73752 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:43:56.929293 ops/training.py:65 2019-01-16 09:43:56.929234: step 5049, loss = 0.73465 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:43:57.890312 ops/training.py:65 2019-01-16 09:43:57.890262: step 5050, loss = 0.71072 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:43:58.852418 ops/training.py:65 2019-01-16 09:43:58.852363: step 5051, loss = 0.66703 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:43:59.813979 ops/training.py:65 2019-01-16 09:43:59.813918: step 5052, loss = 0.71349 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:44:00.775842 ops/training.py:65 2019-01-16 09:44:00.775775: step 5053, loss = 0.71526 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:44:01.740069 ops/training.py:65 2019-01-16 09:44:01.740015: step 5054, loss = 0.69017 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:44:02.704963 ops/training.py:65 2019-01-16 09:44:02.704898: step 5055, loss = 0.74128 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:44:03.667893 ops/training.py:65 2019-01-16 09:44:03.667837: step 5056, loss = 0.69250 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:44:04.630154 ops/training.py:65 2019-01-16 09:44:04.630104: step 5057, loss = 0.68022 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:44:05.591862 ops/training.py:65 2019-01-16 09:44:05.591810: step 5058, loss = 0.71018 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:44:06.553899 ops/training.py:65 2019-01-16 09:44:06.553842: step 5059, loss = 0.68479 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:44:07.515784 ops/training.py:65 2019-01-16 09:44:07.515732: step 5060, loss = 0.70203 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:44:08.477717 ops/training.py:65 2019-01-16 09:44:08.477666: step 5061, loss = 0.68223 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:44:09.439563 ops/training.py:65 2019-01-16 09:44:09.439510: step 5062, loss = 0.69518 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:44:10.400895 ops/training.py:65 2019-01-16 09:44:10.400846: step 5063, loss = 0.70041 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:44:11.362672 ops/training.py:65 2019-01-16 09:44:11.362623: step 5064, loss = 0.68671 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:44:12.325403 ops/training.py:65 2019-01-16 09:44:12.325351: step 5065, loss = 0.68847 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:44:13.286921 ops/training.py:65 2019-01-16 09:44:13.286871: step 5066, loss = 0.68397 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:44:14.248607 ops/training.py:65 2019-01-16 09:44:14.248556: step 5067, loss = 0.72782 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:44:15.210454 ops/training.py:65 2019-01-16 09:44:15.210401: step 5068, loss = 0.74059 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:44:16.172819 ops/training.py:65 2019-01-16 09:44:16.172768: step 5069, loss = 0.71237 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:44:17.134986 ops/training.py:65 2019-01-16 09:44:17.134934: step 5070, loss = 0.68265 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:44:18.096739 ops/training.py:65 2019-01-16 09:44:18.096685: step 5071, loss = 0.72789 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:44:19.058549 ops/training.py:65 2019-01-16 09:44:19.058476: step 5072, loss = 0.69419 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:44:20.021065 ops/training.py:65 2019-01-16 09:44:20.021014: step 5073, loss = 0.69341 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:44:20.983333 ops/training.py:65 2019-01-16 09:44:20.983278: step 5074, loss = 0.75586 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:44:21.943758 ops/training.py:65 2019-01-16 09:44:21.943706: step 5075, loss = 0.72818 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:44:22.904392 ops/training.py:65 2019-01-16 09:44:22.904342: step 5076, loss = 0.70104 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:44:23.864379 ops/training.py:65 2019-01-16 09:44:23.864326: step 5077, loss = 0.68985 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:44:24.829535 ops/training.py:65 2019-01-16 09:44:24.829475: step 5078, loss = 0.68830 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:44:25.792644 ops/training.py:65 2019-01-16 09:44:25.792594: step 5079, loss = 0.67785 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:44:26.754576 ops/training.py:65 2019-01-16 09:44:26.754527: step 5080, loss = 0.72308 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:44:27.720096 ops/training.py:65 2019-01-16 09:44:27.720039: step 5081, loss = 0.74136 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:44:28.684106 ops/training.py:65 2019-01-16 09:44:28.684054: step 5082, loss = 0.68786 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:44:29.646069 ops/training.py:65 2019-01-16 09:44:29.646018: step 5083, loss = 0.75830 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:44:30.608351 ops/training.py:65 2019-01-16 09:44:30.608281: step 5084, loss = 0.68235 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:44:31.570891 ops/training.py:65 2019-01-16 09:44:31.570818: step 5085, loss = 0.78766 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:44:32.533816 ops/training.py:65 2019-01-16 09:44:32.533766: step 5086, loss = 0.71505 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:44:33.498323 ops/training.py:65 2019-01-16 09:44:33.498273: step 5087, loss = 0.66496 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:44:34.461864 ops/training.py:65 2019-01-16 09:44:34.461816: step 5088, loss = 0.68800 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:44:35.424923 ops/training.py:65 2019-01-16 09:44:35.424875: step 5089, loss = 0.71871 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:44:36.387327 ops/training.py:65 2019-01-16 09:44:36.387278: step 5090, loss = 0.76809 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:44:37.348631 ops/training.py:65 2019-01-16 09:44:37.348580: step 5091, loss = 0.68171 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:44:38.308575 ops/training.py:65 2019-01-16 09:44:38.308521: step 5092, loss = 0.64262 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 09:44:39.272469 ops/training.py:65 2019-01-16 09:44:39.272420: step 5093, loss = 0.68525 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:44:40.235777 ops/training.py:65 2019-01-16 09:44:40.235727: step 5094, loss = 0.67615 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:44:41.195984 ops/training.py:65 2019-01-16 09:44:41.195928: step 5095, loss = 0.72383 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:44:42.155607 ops/training.py:65 2019-01-16 09:44:42.155548: step 5096, loss = 0.70376 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:44:43.121492 ops/training.py:65 2019-01-16 09:44:43.121443: step 5097, loss = 0.71636 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:44:44.086313 ops/training.py:65 2019-01-16 09:44:44.086261: step 5098, loss = 0.64756 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:44:45.048886 ops/training.py:65 2019-01-16 09:44:45.048837: step 5099, loss = 0.75980 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:44:46.010442 ops/training.py:65 2019-01-16 09:44:46.010394: step 5100, loss = 0.69295 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:44:46.972228 ops/training.py:65 2019-01-16 09:44:46.972176: step 5101, loss = 0.77371 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:44:47.933618 ops/training.py:65 2019-01-16 09:44:47.933567: step 5102, loss = 0.74669 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:44:48.895000 ops/training.py:65 2019-01-16 09:44:48.894948: step 5103, loss = 0.70852 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:44:49.856365 ops/training.py:65 2019-01-16 09:44:49.856293: step 5104, loss = 0.75003 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:44:50.817528 ops/training.py:65 2019-01-16 09:44:50.817465: step 5105, loss = 0.74900 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:44:51.778426 ops/training.py:65 2019-01-16 09:44:51.778379: step 5106, loss = 0.71803 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:44:52.739481 ops/training.py:65 2019-01-16 09:44:52.739427: step 5107, loss = 0.68679 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:44:53.701128 ops/training.py:65 2019-01-16 09:44:53.701056: step 5108, loss = 0.68928 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:44:54.665005 ops/training.py:65 2019-01-16 09:44:54.664939: step 5109, loss = 0.69432 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:44:55.629317 ops/training.py:65 2019-01-16 09:44:55.629266: step 5110, loss = 0.70667 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:44:56.593302 ops/training.py:65 2019-01-16 09:44:56.593250: step 5111, loss = 0.71113 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:44:57.555019 ops/training.py:65 2019-01-16 09:44:57.554963: step 5112, loss = 0.72819 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:44:58.516265 ops/training.py:65 2019-01-16 09:44:58.516195: step 5113, loss = 0.71156 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:44:59.477689 ops/training.py:65 2019-01-16 09:44:59.477632: step 5114, loss = 0.70966 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:45:00.438123 ops/training.py:65 2019-01-16 09:45:00.438066: step 5115, loss = 0.68409 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:45:01.401739 ops/training.py:65 2019-01-16 09:45:01.401672: step 5116, loss = 0.68653 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:45:02.364928 ops/training.py:65 2019-01-16 09:45:02.364860: step 5117, loss = 0.67854 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:45:03.327881 ops/training.py:65 2019-01-16 09:45:03.327811: step 5118, loss = 0.67638 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:45:04.290009 ops/training.py:65 2019-01-16 09:45:04.289955: step 5119, loss = 0.67906 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:45:05.252098 ops/training.py:65 2019-01-16 09:45:05.252046: step 5120, loss = 0.70928 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:45:06.216686 ops/training.py:65 2019-01-16 09:45:06.216630: step 5121, loss = 0.69615 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:45:07.180088 ops/training.py:65 2019-01-16 09:45:07.180040: step 5122, loss = 0.66498 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:45:08.140699 ops/training.py:65 2019-01-16 09:45:08.140647: step 5123, loss = 0.70336 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:45:09.105654 ops/training.py:65 2019-01-16 09:45:09.105604: step 5124, loss = 0.69478 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:45:10.069192 ops/training.py:65 2019-01-16 09:45:10.069138: step 5125, loss = 0.69052 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:45:11.030128 ops/training.py:65 2019-01-16 09:45:11.030078: step 5126, loss = 0.66230 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 09:45:11.990997 ops/training.py:65 2019-01-16 09:45:11.990943: step 5127, loss = 0.69312 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:45:12.952054 ops/training.py:65 2019-01-16 09:45:12.951995: step 5128, loss = 0.67999 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:45:13.913241 ops/training.py:65 2019-01-16 09:45:13.913180: step 5129, loss = 0.69096 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:45:14.876647 ops/training.py:65 2019-01-16 09:45:14.876575: step 5130, loss = 0.71411 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:45:15.840255 ops/training.py:65 2019-01-16 09:45:15.840192: step 5131, loss = 0.68129 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:45:16.803854 ops/training.py:65 2019-01-16 09:45:16.803797: step 5132, loss = 0.72076 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:45:17.767444 ops/training.py:65 2019-01-16 09:45:17.767379: step 5133, loss = 0.67183 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:45:18.730121 ops/training.py:65 2019-01-16 09:45:18.730052: step 5134, loss = 0.69236 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:45:19.690442 ops/training.py:65 2019-01-16 09:45:19.690375: step 5135, loss = 0.73161 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:45:20.653367 ops/training.py:65 2019-01-16 09:45:20.653312: step 5136, loss = 0.69852 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:45:21.616201 ops/training.py:65 2019-01-16 09:45:21.616134: step 5137, loss = 0.68098 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:45:22.577275 ops/training.py:65 2019-01-16 09:45:22.577205: step 5138, loss = 0.69897 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:45:23.541409 ops/training.py:65 2019-01-16 09:45:23.541346: step 5139, loss = 0.69558 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:45:24.503306 ops/training.py:65 2019-01-16 09:45:24.503257: step 5140, loss = 0.71145 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:45:25.465006 ops/training.py:65 2019-01-16 09:45:25.464954: step 5141, loss = 0.66671 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:45:26.426994 ops/training.py:65 2019-01-16 09:45:26.426946: step 5142, loss = 0.66257 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:45:27.388895 ops/training.py:65 2019-01-16 09:45:27.388845: step 5143, loss = 0.69980 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:45:28.350498 ops/training.py:65 2019-01-16 09:45:28.350443: step 5144, loss = 0.67452 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:45:29.313409 ops/training.py:65 2019-01-16 09:45:29.313354: step 5145, loss = 0.74547 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:45:30.277754 ops/training.py:65 2019-01-16 09:45:30.277687: step 5146, loss = 0.70319 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:45:31.240687 ops/training.py:65 2019-01-16 09:45:31.240617: step 5147, loss = 0.69384 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:45:32.204003 ops/training.py:65 2019-01-16 09:45:32.203946: step 5148, loss = 0.69269 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:45:33.165297 ops/training.py:65 2019-01-16 09:45:33.165249: step 5149, loss = 0.68361 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:45:34.126260 ops/training.py:65 2019-01-16 09:45:34.126209: step 5150, loss = 0.69746 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:45:35.087668 ops/training.py:65 2019-01-16 09:45:35.087615: step 5151, loss = 0.68007 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:45:36.048200 ops/training.py:65 2019-01-16 09:45:36.048148: step 5152, loss = 0.69957 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:45:37.009708 ops/training.py:65 2019-01-16 09:45:37.009650: step 5153, loss = 0.68338 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:45:37.971418 ops/training.py:65 2019-01-16 09:45:37.971368: step 5154, loss = 0.71144 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:45:38.933063 ops/training.py:65 2019-01-16 09:45:38.933007: step 5155, loss = 0.69815 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:45:39.895113 ops/training.py:65 2019-01-16 09:45:39.895041: step 5156, loss = 0.71122 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:45:40.855280 ops/training.py:65 2019-01-16 09:45:40.855179: step 5157, loss = 0.69905 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:45:41.820066 ops/training.py:65 2019-01-16 09:45:41.820014: step 5158, loss = 0.69056 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:45:42.784993 ops/training.py:65 2019-01-16 09:45:42.784944: step 5159, loss = 0.71672 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:45:43.748239 ops/training.py:65 2019-01-16 09:45:43.748183: step 5160, loss = 0.69333 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:45:44.712452 ops/training.py:65 2019-01-16 09:45:44.712402: step 5161, loss = 0.69161 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:45:45.675074 ops/training.py:65 2019-01-16 09:45:45.675027: step 5162, loss = 0.66364 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:45:46.637681 ops/training.py:65 2019-01-16 09:45:46.637630: step 5163, loss = 0.69636 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:45:47.599302 ops/training.py:65 2019-01-16 09:45:47.599249: step 5164, loss = 0.69097 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:45:48.560448 ops/training.py:65 2019-01-16 09:45:48.560401: step 5165, loss = 0.67789 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:45:49.521942 ops/training.py:65 2019-01-16 09:45:49.521890: step 5166, loss = 0.68473 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:45:50.483734 ops/training.py:65 2019-01-16 09:45:50.483683: step 5167, loss = 0.69813 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:45:51.444892 ops/training.py:65 2019-01-16 09:45:51.444839: step 5168, loss = 0.65024 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 09:45:52.407013 ops/training.py:65 2019-01-16 09:45:52.406963: step 5169, loss = 0.70422 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:45:53.367979 ops/training.py:65 2019-01-16 09:45:53.367927: step 5170, loss = 0.70834 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:45:54.328629 ops/training.py:65 2019-01-16 09:45:54.328577: step 5171, loss = 0.65219 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:45:55.291021 ops/training.py:65 2019-01-16 09:45:55.290951: step 5172, loss = 0.74615 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:45:56.253634 ops/training.py:65 2019-01-16 09:45:56.253569: step 5173, loss = 0.71749 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:45:57.215782 ops/training.py:65 2019-01-16 09:45:57.215713: step 5174, loss = 0.66399 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:45:58.177516 ops/training.py:65 2019-01-16 09:45:58.177454: step 5175, loss = 0.72080 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:45:59.141913 ops/training.py:65 2019-01-16 09:45:59.141842: step 5176, loss = 0.69775 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:46:00.105370 ops/training.py:65 2019-01-16 09:46:00.105315: step 5177, loss = 0.72067 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:46:01.067341 ops/training.py:65 2019-01-16 09:46:01.067270: step 5178, loss = 0.65718 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:46:02.029107 ops/training.py:65 2019-01-16 09:46:02.029058: step 5179, loss = 0.68381 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:46:02.990449 ops/training.py:65 2019-01-16 09:46:02.990398: step 5180, loss = 0.67641 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:46:03.951967 ops/training.py:65 2019-01-16 09:46:03.951914: step 5181, loss = 0.70023 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:46:04.913198 ops/training.py:65 2019-01-16 09:46:04.913148: step 5182, loss = 0.66716 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:46:05.875232 ops/training.py:65 2019-01-16 09:46:05.875181: step 5183, loss = 0.69640 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:46:06.835895 ops/training.py:65 2019-01-16 09:46:06.835837: step 5184, loss = 0.70913 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:46:07.796705 ops/training.py:65 2019-01-16 09:46:07.796657: step 5185, loss = 0.67673 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:46:08.760911 ops/training.py:65 2019-01-16 09:46:08.760860: step 5186, loss = 0.68404 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:46:09.724567 ops/training.py:65 2019-01-16 09:46:09.724514: step 5187, loss = 0.70477 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:46:10.687315 ops/training.py:65 2019-01-16 09:46:10.687264: step 5188, loss = 0.66273 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:46:11.649431 ops/training.py:65 2019-01-16 09:46:11.649358: step 5189, loss = 0.69482 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:46:12.612299 ops/training.py:65 2019-01-16 09:46:12.612242: step 5190, loss = 0.69204 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:46:13.574205 ops/training.py:65 2019-01-16 09:46:13.574149: step 5191, loss = 0.68198 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:46:14.535928 ops/training.py:65 2019-01-16 09:46:14.535860: step 5192, loss = 0.64853 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:46:15.496760 ops/training.py:65 2019-01-16 09:46:15.496693: step 5193, loss = 0.68815 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:46:16.458295 ops/training.py:65 2019-01-16 09:46:16.458223: step 5194, loss = 0.71637 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:46:17.419593 ops/training.py:65 2019-01-16 09:46:17.419544: step 5195, loss = 0.72130 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:46:18.380693 ops/training.py:65 2019-01-16 09:46:18.380644: step 5196, loss = 0.67378 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:46:19.342304 ops/training.py:65 2019-01-16 09:46:19.342253: step 5197, loss = 0.72636 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:46:20.303321 ops/training.py:65 2019-01-16 09:46:20.303258: step 5198, loss = 0.67577 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:46:21.263966 ops/training.py:65 2019-01-16 09:46:21.263909: step 5199, loss = 0.66868 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:46:22.224345 ops/training.py:65 2019-01-16 09:46:22.224275: step 5200, loss = 0.71297 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:46:23.185418 ops/training.py:65 2019-01-16 09:46:23.185351: step 5201, loss = 0.71624 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:46:24.146651 ops/training.py:65 2019-01-16 09:46:24.146590: step 5202, loss = 0.68810 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:46:25.107469 ops/training.py:65 2019-01-16 09:46:25.107400: step 5203, loss = 0.67850 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:46:26.068463 ops/training.py:65 2019-01-16 09:46:26.068402: step 5204, loss = 0.70353 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:46:27.029148 ops/training.py:65 2019-01-16 09:46:27.029100: step 5205, loss = 0.70894 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:46:27.990243 ops/training.py:65 2019-01-16 09:46:27.990191: step 5206, loss = 0.72488 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:46:28.952009 ops/training.py:65 2019-01-16 09:46:28.951953: step 5207, loss = 0.70310 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:46:29.916078 ops/training.py:65 2019-01-16 09:46:29.916023: step 5208, loss = 0.67906 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:46:30.878939 ops/training.py:65 2019-01-16 09:46:30.878887: step 5209, loss = 0.71004 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:46:31.842939 ops/training.py:65 2019-01-16 09:46:31.842888: step 5210, loss = 0.69651 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:46:32.806295 ops/training.py:65 2019-01-16 09:46:32.806242: step 5211, loss = 0.68726 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:46:33.769015 ops/training.py:65 2019-01-16 09:46:33.768961: step 5212, loss = 0.66416 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:46:34.730134 ops/training.py:65 2019-01-16 09:46:34.730073: step 5213, loss = 0.70514 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:46:35.691488 ops/training.py:65 2019-01-16 09:46:35.691428: step 5214, loss = 0.67632 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:46:36.653453 ops/training.py:65 2019-01-16 09:46:36.653384: step 5215, loss = 0.73876 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:46:37.614788 ops/training.py:65 2019-01-16 09:46:37.614722: step 5216, loss = 0.72529 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:46:38.576658 ops/training.py:65 2019-01-16 09:46:38.576598: step 5217, loss = 0.69669 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:46:39.537989 ops/training.py:65 2019-01-16 09:46:39.537928: step 5218, loss = 0.67321 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:46:40.498865 ops/training.py:65 2019-01-16 09:46:40.498816: step 5219, loss = 0.68042 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:46:41.459162 ops/training.py:65 2019-01-16 09:46:41.459100: step 5220, loss = 0.70135 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:46:42.420693 ops/training.py:65 2019-01-16 09:46:42.420621: step 5221, loss = 0.68801 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:46:43.383673 ops/training.py:65 2019-01-16 09:46:43.383584: step 5222, loss = 0.70363 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:46:44.346766 ops/training.py:65 2019-01-16 09:46:44.346692: step 5223, loss = 0.68663 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:46:45.311527 ops/training.py:65 2019-01-16 09:46:45.311477: step 5224, loss = 0.68402 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:46:46.272372 ops/training.py:65 2019-01-16 09:46:46.272312: step 5225, loss = 0.67047 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:46:47.236829 ops/training.py:65 2019-01-16 09:46:47.236771: step 5226, loss = 0.71900 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:46:48.201248 ops/training.py:65 2019-01-16 09:46:48.201196: step 5227, loss = 0.66694 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:46:49.164480 ops/training.py:65 2019-01-16 09:46:49.164432: step 5228, loss = 0.66249 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:46:50.125352 ops/training.py:65 2019-01-16 09:46:50.125294: step 5229, loss = 0.69881 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:46:51.090891 ops/training.py:65 2019-01-16 09:46:51.090819: step 5230, loss = 0.71349 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:46:52.053417 ops/training.py:65 2019-01-16 09:46:52.053346: step 5231, loss = 0.70191 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:46:53.015100 ops/training.py:65 2019-01-16 09:46:53.015030: step 5232, loss = 0.68292 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:46:53.980439 ops/training.py:65 2019-01-16 09:46:53.980366: step 5233, loss = 0.71822 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:46:54.944702 ops/training.py:65 2019-01-16 09:46:54.944632: step 5234, loss = 0.67540 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:46:55.908186 ops/training.py:65 2019-01-16 09:46:55.908114: step 5235, loss = 0.69102 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:46:56.869882 ops/training.py:65 2019-01-16 09:46:56.869832: step 5236, loss = 0.68572 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:46:57.831315 ops/training.py:65 2019-01-16 09:46:57.831265: step 5237, loss = 0.70814 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:46:58.793067 ops/training.py:65 2019-01-16 09:46:58.793019: step 5238, loss = 0.70239 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:46:59.754191 ops/training.py:65 2019-01-16 09:46:59.754140: step 5239, loss = 0.70702 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:47:00.715144 ops/training.py:65 2019-01-16 09:47:00.715069: step 5240, loss = 0.68698 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:47:01.677109 ops/training.py:65 2019-01-16 09:47:01.677034: step 5241, loss = 0.69211 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:47:02.643325 ops/training.py:65 2019-01-16 09:47:02.643258: step 5242, loss = 0.71342 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:47:03.605176 ops/training.py:65 2019-01-16 09:47:03.605105: step 5243, loss = 0.70010 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:47:04.566151 ops/training.py:65 2019-01-16 09:47:04.566079: step 5244, loss = 0.68280 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:47:05.526859 ops/training.py:65 2019-01-16 09:47:05.526792: step 5245, loss = 0.68568 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:47:06.485565 ops/training.py:65 2019-01-16 09:47:06.485497: step 5246, loss = 0.70068 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:47:07.448580 ops/training.py:65 2019-01-16 09:47:07.448520: step 5247, loss = 0.68630 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:47:08.410988 ops/training.py:65 2019-01-16 09:47:08.410930: step 5248, loss = 0.68810 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:47:09.372065 ops/training.py:65 2019-01-16 09:47:09.372024: step 5249, loss = 0.68018 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:47:10.333709 ops/training.py:65 2019-01-16 09:47:10.333652: step 5250, loss = 0.70733 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:47:11.294925 ops/training.py:65 2019-01-16 09:47:11.294867: step 5251, loss = 0.66315 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:47:12.256694 ops/training.py:65 2019-01-16 09:47:12.256649: step 5252, loss = 0.67241 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:47:13.216268 ops/training.py:65 2019-01-16 09:47:13.216201: step 5253, loss = 0.69026 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:47:14.181776 ops/training.py:65 2019-01-16 09:47:14.181720: step 5254, loss = 0.69115 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:47:15.145319 ops/training.py:65 2019-01-16 09:47:15.145269: step 5255, loss = 0.67316 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:47:16.109270 ops/training.py:65 2019-01-16 09:47:16.109216: step 5256, loss = 0.70923 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 09:47:17.070716 ops/training.py:65 2019-01-16 09:47:17.070654: step 5257, loss = 0.71499 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:47:18.032173 ops/training.py:65 2019-01-16 09:47:18.032108: step 5258, loss = 0.69417 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:47:18.994465 ops/training.py:65 2019-01-16 09:47:18.994407: step 5259, loss = 0.68862 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:47:19.956340 ops/training.py:65 2019-01-16 09:47:19.956273: step 5260, loss = 0.67926 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:47:20.917952 ops/training.py:65 2019-01-16 09:47:20.917878: step 5261, loss = 0.68725 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:47:21.879943 ops/training.py:65 2019-01-16 09:47:21.879875: step 5262, loss = 0.69468 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:47:22.839909 ops/training.py:65 2019-01-16 09:47:22.839841: step 5263, loss = 0.69088 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:47:23.798443 ops/training.py:65 2019-01-16 09:47:23.798370: step 5264, loss = 0.69244 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:47:24.757323 ops/training.py:65 2019-01-16 09:47:24.757274: step 5265, loss = 0.70847 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:47:25.717073 ops/training.py:65 2019-01-16 09:47:25.717012: step 5266, loss = 0.69896 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:47:26.681156 ops/training.py:65 2019-01-16 09:47:26.681088: step 5267, loss = 0.70739 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:47:27.645201 ops/training.py:65 2019-01-16 09:47:27.645148: step 5268, loss = 0.70368 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:47:28.607425 ops/training.py:65 2019-01-16 09:47:28.607371: step 5269, loss = 0.66108 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:47:29.567865 ops/training.py:65 2019-01-16 09:47:29.567812: step 5270, loss = 0.66483 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:47:30.532412 ops/training.py:65 2019-01-16 09:47:30.532356: step 5271, loss = 0.71557 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:47:31.496758 ops/training.py:65 2019-01-16 09:47:31.496704: step 5272, loss = 0.67312 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:47:32.459891 ops/training.py:65 2019-01-16 09:47:32.459837: step 5273, loss = 0.69389 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:47:33.422230 ops/training.py:65 2019-01-16 09:47:33.422170: step 5274, loss = 0.69406 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:47:34.384677 ops/training.py:65 2019-01-16 09:47:34.384607: step 5275, loss = 0.71451 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:47:35.345909 ops/training.py:65 2019-01-16 09:47:35.345840: step 5276, loss = 0.71466 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:47:36.307020 ops/training.py:65 2019-01-16 09:47:36.306947: step 5277, loss = 0.69780 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:47:37.269112 ops/training.py:65 2019-01-16 09:47:37.269062: step 5278, loss = 0.68738 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:47:38.231268 ops/training.py:65 2019-01-16 09:47:38.231216: step 5279, loss = 0.70863 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:47:39.193082 ops/training.py:65 2019-01-16 09:47:39.193032: step 5280, loss = 0.69363 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:47:40.155015 ops/training.py:65 2019-01-16 09:47:40.154966: step 5281, loss = 0.69137 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:47:41.116701 ops/training.py:65 2019-01-16 09:47:41.116649: step 5282, loss = 0.66735 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:47:42.079008 ops/training.py:65 2019-01-16 09:47:42.078957: step 5283, loss = 0.70786 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:47:43.040680 ops/training.py:65 2019-01-16 09:47:43.040627: step 5284, loss = 0.69028 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:47:44.002988 ops/training.py:65 2019-01-16 09:47:44.002938: step 5285, loss = 0.66825 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:47:44.965109 ops/training.py:65 2019-01-16 09:47:44.965056: step 5286, loss = 0.70166 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:47:45.926162 ops/training.py:65 2019-01-16 09:47:45.926097: step 5287, loss = 0.70533 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:47:46.887757 ops/training.py:65 2019-01-16 09:47:46.887700: step 5288, loss = 0.69461 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:47:47.849897 ops/training.py:65 2019-01-16 09:47:47.849826: step 5289, loss = 0.66839 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:47:48.814340 ops/training.py:65 2019-01-16 09:47:48.814278: step 5290, loss = 0.70979 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:47:49.777741 ops/training.py:65 2019-01-16 09:47:49.777688: step 5291, loss = 0.68048 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:47:50.739979 ops/training.py:65 2019-01-16 09:47:50.739915: step 5292, loss = 0.69577 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:47:51.700647 ops/training.py:65 2019-01-16 09:47:51.700592: step 5293, loss = 0.67668 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:47:52.661772 ops/training.py:65 2019-01-16 09:47:52.661698: step 5294, loss = 0.74383 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:47:53.622349 ops/training.py:65 2019-01-16 09:47:53.622297: step 5295, loss = 0.71096 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:47:54.585968 ops/training.py:65 2019-01-16 09:47:54.585922: step 5296, loss = 0.69193 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:47:55.548895 ops/training.py:65 2019-01-16 09:47:55.548843: step 5297, loss = 0.71671 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:47:56.511002 ops/training.py:65 2019-01-16 09:47:56.510952: step 5298, loss = 0.64756 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:47:57.472814 ops/training.py:65 2019-01-16 09:47:57.472762: step 5299, loss = 0.70404 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:47:58.434231 ops/training.py:65 2019-01-16 09:47:58.434171: step 5300, loss = 0.66818 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:47:59.395021 ops/training.py:65 2019-01-16 09:47:59.394950: step 5301, loss = 0.69051 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:48:00.356668 ops/training.py:65 2019-01-16 09:48:00.356596: step 5302, loss = 0.73678 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:48:01.318095 ops/training.py:65 2019-01-16 09:48:01.318024: step 5303, loss = 0.71065 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:48:02.278166 ops/training.py:65 2019-01-16 09:48:02.278112: step 5304, loss = 0.67695 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:48:03.238969 ops/training.py:65 2019-01-16 09:48:03.238916: step 5305, loss = 0.71981 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:48:04.199874 ops/training.py:65 2019-01-16 09:48:04.199820: step 5306, loss = 0.67794 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:48:05.160510 ops/training.py:65 2019-01-16 09:48:05.160458: step 5307, loss = 0.69501 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:48:06.124791 ops/training.py:65 2019-01-16 09:48:06.124738: step 5308, loss = 0.68227 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:48:07.087992 ops/training.py:65 2019-01-16 09:48:07.087939: step 5309, loss = 0.66065 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:48:08.051423 ops/training.py:65 2019-01-16 09:48:08.051371: step 5310, loss = 0.68801 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:48:09.013698 ops/training.py:65 2019-01-16 09:48:09.013643: step 5311, loss = 0.70747 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:48:09.975628 ops/training.py:65 2019-01-16 09:48:09.975575: step 5312, loss = 0.65518 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:48:10.937956 ops/training.py:65 2019-01-16 09:48:10.937902: step 5313, loss = 0.68560 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:48:11.900394 ops/training.py:65 2019-01-16 09:48:11.900344: step 5314, loss = 0.71599 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:48:12.862926 ops/training.py:65 2019-01-16 09:48:12.862876: step 5315, loss = 0.68276 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:48:13.826146 ops/training.py:65 2019-01-16 09:48:13.826083: step 5316, loss = 0.67580 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:48:14.788267 ops/training.py:65 2019-01-16 09:48:14.788194: step 5317, loss = 0.73776 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:48:15.748765 ops/training.py:65 2019-01-16 09:48:15.748697: step 5318, loss = 0.68585 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:48:16.712537 ops/training.py:65 2019-01-16 09:48:16.712469: step 5319, loss = 0.70399 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:48:17.676212 ops/training.py:65 2019-01-16 09:48:17.676140: step 5320, loss = 0.70889 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:48:18.638782 ops/training.py:65 2019-01-16 09:48:18.638710: step 5321, loss = 0.68737 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:48:19.602960 ops/training.py:65 2019-01-16 09:48:19.602893: step 5322, loss = 0.70061 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:48:20.566118 ops/training.py:65 2019-01-16 09:48:20.566041: step 5323, loss = 0.69974 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:48:21.531389 ops/training.py:65 2019-01-16 09:48:21.531316: step 5324, loss = 0.70909 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:48:22.494271 ops/training.py:65 2019-01-16 09:48:22.494195: step 5325, loss = 0.66586 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:48:23.456758 ops/training.py:65 2019-01-16 09:48:23.456701: step 5326, loss = 0.68216 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:48:24.417442 ops/training.py:65 2019-01-16 09:48:24.417390: step 5327, loss = 0.71027 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:48:25.377647 ops/training.py:65 2019-01-16 09:48:25.377591: step 5328, loss = 0.69486 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:48:26.342795 ops/training.py:65 2019-01-16 09:48:26.342724: step 5329, loss = 0.69959 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:48:27.303483 ops/training.py:65 2019-01-16 09:48:27.303410: step 5330, loss = 0.68383 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:48:28.263995 ops/training.py:65 2019-01-16 09:48:28.263943: step 5331, loss = 0.71568 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:48:29.226029 ops/training.py:65 2019-01-16 09:48:29.225957: step 5332, loss = 0.69942 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:48:30.190381 ops/training.py:65 2019-01-16 09:48:30.190323: step 5333, loss = 0.69211 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:48:31.152387 ops/training.py:65 2019-01-16 09:48:31.152312: step 5334, loss = 0.68450 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:48:32.115614 ops/training.py:65 2019-01-16 09:48:32.115558: step 5335, loss = 0.69860 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:48:33.078336 ops/training.py:65 2019-01-16 09:48:33.078284: step 5336, loss = 0.69731 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:48:34.042989 ops/training.py:65 2019-01-16 09:48:34.042927: step 5337, loss = 0.71397 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:48:35.005214 ops/training.py:65 2019-01-16 09:48:35.005144: step 5338, loss = 0.66207 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:48:35.970490 ops/training.py:65 2019-01-16 09:48:35.970416: step 5339, loss = 0.70068 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:48:36.934576 ops/training.py:65 2019-01-16 09:48:36.934518: step 5340, loss = 0.67371 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:48:37.899179 ops/training.py:65 2019-01-16 09:48:37.899112: step 5341, loss = 0.73647 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:48:38.862867 ops/training.py:65 2019-01-16 09:48:38.862813: step 5342, loss = 0.69847 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:48:39.824962 ops/training.py:65 2019-01-16 09:48:39.824886: step 5343, loss = 0.68332 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:48:40.786552 ops/training.py:65 2019-01-16 09:48:40.786479: step 5344, loss = 0.69557 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:48:41.748990 ops/training.py:65 2019-01-16 09:48:41.748918: step 5345, loss = 0.72966 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:48:42.711157 ops/training.py:65 2019-01-16 09:48:42.711104: step 5346, loss = 0.74965 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:48:43.672083 ops/training.py:65 2019-01-16 09:48:43.672029: step 5347, loss = 0.70701 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:48:44.633455 ops/training.py:65 2019-01-16 09:48:44.633405: step 5348, loss = 0.71561 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:48:45.595214 ops/training.py:65 2019-01-16 09:48:45.595165: step 5349, loss = 0.68676 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:48:46.556775 ops/training.py:65 2019-01-16 09:48:46.556724: step 5350, loss = 0.69977 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:48:47.518478 ops/training.py:65 2019-01-16 09:48:47.518428: step 5351, loss = 0.68068 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:48:48.480652 ops/training.py:65 2019-01-16 09:48:48.480594: step 5352, loss = 0.68781 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:48:49.442748 ops/training.py:65 2019-01-16 09:48:49.442675: step 5353, loss = 0.66912 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 09:48:50.404464 ops/training.py:65 2019-01-16 09:48:50.404395: step 5354, loss = 0.68551 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:48:51.365722 ops/training.py:65 2019-01-16 09:48:51.365631: step 5355, loss = 0.69408 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:48:52.328927 ops/training.py:65 2019-01-16 09:48:52.328852: step 5356, loss = 0.67637 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:48:53.290579 ops/training.py:65 2019-01-16 09:48:53.290533: step 5357, loss = 0.66546 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:48:54.252130 ops/training.py:65 2019-01-16 09:48:54.252068: step 5358, loss = 0.68271 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:48:55.213681 ops/training.py:65 2019-01-16 09:48:55.213606: step 5359, loss = 0.71578 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:48:56.174450 ops/training.py:65 2019-01-16 09:48:56.174374: step 5360, loss = 0.72302 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:48:57.135346 ops/training.py:65 2019-01-16 09:48:57.135273: step 5361, loss = 0.70146 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:48:58.096161 ops/training.py:65 2019-01-16 09:48:58.096096: step 5362, loss = 0.72620 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:48:59.056279 ops/training.py:65 2019-01-16 09:48:59.056216: step 5363, loss = 0.68842 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:49:00.015496 ops/training.py:65 2019-01-16 09:49:00.015444: step 5364, loss = 0.69448 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:49:00.977612 ops/training.py:65 2019-01-16 09:49:00.977561: step 5365, loss = 0.69595 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:49:01.940936 ops/training.py:65 2019-01-16 09:49:01.940867: step 5366, loss = 0.66829 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:49:02.904872 ops/training.py:65 2019-01-16 09:49:02.904807: step 5367, loss = 0.69959 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:49:03.868977 ops/training.py:65 2019-01-16 09:49:03.868899: step 5368, loss = 0.74192 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 09:49:04.831145 ops/training.py:65 2019-01-16 09:49:04.831080: step 5369, loss = 0.71041 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:49:05.792654 ops/training.py:65 2019-01-16 09:49:05.792583: step 5370, loss = 0.70791 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:49:06.754022 ops/training.py:65 2019-01-16 09:49:06.753974: step 5371, loss = 0.67205 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:49:07.715734 ops/training.py:65 2019-01-16 09:49:07.715678: step 5372, loss = 0.67561 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:49:08.678579 ops/training.py:65 2019-01-16 09:49:08.678521: step 5373, loss = 0.69214 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:49:09.640276 ops/training.py:65 2019-01-16 09:49:09.640225: step 5374, loss = 0.69752 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:49:10.602490 ops/training.py:65 2019-01-16 09:49:10.602442: step 5375, loss = 0.67315 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:49:11.565101 ops/training.py:65 2019-01-16 09:49:11.565049: step 5376, loss = 0.71798 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:49:12.527688 ops/training.py:65 2019-01-16 09:49:12.527618: step 5377, loss = 0.73136 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:49:13.489165 ops/training.py:65 2019-01-16 09:49:13.489094: step 5378, loss = 0.68157 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:49:14.450198 ops/training.py:65 2019-01-16 09:49:14.450128: step 5379, loss = 0.68537 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:49:15.411560 ops/training.py:65 2019-01-16 09:49:15.411490: step 5380, loss = 0.68398 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:49:16.605113 ops/training.py:65 2019-01-16 09:49:16.605060: step 5381, loss = 0.74207 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:49:17.566421 ops/training.py:65 2019-01-16 09:49:17.566352: step 5382, loss = 0.66049 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:49:18.527985 ops/training.py:65 2019-01-16 09:49:18.527934: step 5383, loss = 0.69693 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:49:19.493260 ops/training.py:65 2019-01-16 09:49:19.493211: step 5384, loss = 0.68119 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:49:20.457261 ops/training.py:65 2019-01-16 09:49:20.457212: step 5385, loss = 0.70261 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:49:21.420601 ops/training.py:65 2019-01-16 09:49:21.420531: step 5386, loss = 0.68140 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:49:22.381627 ops/training.py:65 2019-01-16 09:49:22.381536: step 5387, loss = 0.71015 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:49:23.343828 ops/training.py:65 2019-01-16 09:49:23.343776: step 5388, loss = 0.73722 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:49:24.305713 ops/training.py:65 2019-01-16 09:49:24.305660: step 5389, loss = 0.66730 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:49:25.268118 ops/training.py:65 2019-01-16 09:49:25.268061: step 5390, loss = 0.72338 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:49:26.536966 ops/training.py:65 2019-01-16 09:49:26.536891: step 5391, loss = 0.73544 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:49:27.502029 ops/training.py:65 2019-01-16 09:49:27.501959: step 5392, loss = 0.69965 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:49:28.463371 ops/training.py:65 2019-01-16 09:49:28.463298: step 5393, loss = 0.65520 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:49:29.428433 ops/training.py:65 2019-01-16 09:49:29.428382: step 5394, loss = 0.71978 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:49:30.392736 ops/training.py:65 2019-01-16 09:49:30.392687: step 5395, loss = 0.68328 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:49:31.354969 ops/training.py:65 2019-01-16 09:49:31.354895: step 5396, loss = 0.66962 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:49:32.320026 ops/training.py:65 2019-01-16 09:49:32.319948: step 5397, loss = 0.69040 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:49:33.283626 ops/training.py:65 2019-01-16 09:49:33.283552: step 5398, loss = 0.74405 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 09:49:34.247020 ops/training.py:65 2019-01-16 09:49:34.246947: step 5399, loss = 0.74532 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:49:35.209114 ops/training.py:65 2019-01-16 09:49:35.209043: step 5400, loss = 0.69724 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:49:36.170743 ops/training.py:65 2019-01-16 09:49:36.170683: step 5401, loss = 0.69719 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:49:37.132027 ops/training.py:65 2019-01-16 09:49:37.131955: step 5402, loss = 0.70975 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:49:38.093755 ops/training.py:65 2019-01-16 09:49:38.093685: step 5403, loss = 0.71404 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:49:39.056214 ops/training.py:65 2019-01-16 09:49:39.056158: step 5404, loss = 0.70638 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:49:40.018167 ops/training.py:65 2019-01-16 09:49:40.018116: step 5405, loss = 0.69760 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:49:40.979476 ops/training.py:65 2019-01-16 09:49:40.979424: step 5406, loss = 0.70320 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:49:41.940429 ops/training.py:65 2019-01-16 09:49:41.940375: step 5407, loss = 0.67446 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:49:42.903102 ops/training.py:65 2019-01-16 09:49:42.903029: step 5408, loss = 0.69846 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:49:43.865878 ops/training.py:65 2019-01-16 09:49:43.865803: step 5409, loss = 0.68622 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:49:44.827589 ops/training.py:65 2019-01-16 09:49:44.827515: step 5410, loss = 0.71541 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:49:45.789157 ops/training.py:65 2019-01-16 09:49:45.789081: step 5411, loss = 0.64556 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:49:46.749748 ops/training.py:65 2019-01-16 09:49:46.749691: step 5412, loss = 0.68365 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:49:47.710565 ops/training.py:65 2019-01-16 09:49:47.710508: step 5413, loss = 0.67571 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:49:48.671348 ops/training.py:65 2019-01-16 09:49:48.671296: step 5414, loss = 0.69990 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:49:49.632978 ops/training.py:65 2019-01-16 09:49:49.632925: step 5415, loss = 0.66303 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:49:50.596970 ops/training.py:65 2019-01-16 09:49:50.596915: step 5416, loss = 0.71949 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:49:51.559579 ops/training.py:65 2019-01-16 09:49:51.559516: step 5417, loss = 0.66878 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:49:52.522288 ops/training.py:65 2019-01-16 09:49:52.522198: step 5418, loss = 0.68570 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:49:53.483784 ops/training.py:65 2019-01-16 09:49:53.483693: step 5419, loss = 0.70692 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:49:54.445401 ops/training.py:65 2019-01-16 09:49:54.445321: step 5420, loss = 0.65317 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:49:55.406668 ops/training.py:65 2019-01-16 09:49:55.406599: step 5421, loss = 0.72614 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:49:56.367742 ops/training.py:65 2019-01-16 09:49:56.367669: step 5422, loss = 0.69351 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:49:57.328510 ops/training.py:65 2019-01-16 09:49:57.328439: step 5423, loss = 0.68028 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:49:58.289983 ops/training.py:65 2019-01-16 09:49:58.289919: step 5424, loss = 0.69197 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:49:59.250884 ops/training.py:65 2019-01-16 09:49:59.250834: step 5425, loss = 0.70895 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:50:00.212326 ops/training.py:65 2019-01-16 09:50:00.212271: step 5426, loss = 0.68886 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:50:01.173255 ops/training.py:65 2019-01-16 09:50:01.173185: step 5427, loss = 0.68729 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:50:02.133733 ops/training.py:65 2019-01-16 09:50:02.133678: step 5428, loss = 0.67472 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:50:03.095312 ops/training.py:65 2019-01-16 09:50:03.095218: step 5429, loss = 0.69910 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:50:04.057834 ops/training.py:65 2019-01-16 09:50:04.057758: step 5430, loss = 0.67879 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:50:05.019377 ops/training.py:65 2019-01-16 09:50:05.019328: step 5431, loss = 0.68347 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:50:05.981993 ops/training.py:65 2019-01-16 09:50:05.981922: step 5432, loss = 0.72545 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:50:06.947162 ops/training.py:65 2019-01-16 09:50:06.947102: step 5433, loss = 0.66475 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:50:07.910775 ops/training.py:65 2019-01-16 09:50:07.910709: step 5434, loss = 0.65959 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 09:50:08.873395 ops/training.py:65 2019-01-16 09:50:08.873334: step 5435, loss = 0.63451 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:50:09.834374 ops/training.py:65 2019-01-16 09:50:09.834297: step 5436, loss = 0.69315 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:50:10.798395 ops/training.py:65 2019-01-16 09:50:10.798319: step 5437, loss = 0.67419 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:50:11.760850 ops/training.py:65 2019-01-16 09:50:11.760778: step 5438, loss = 0.71507 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:50:12.723275 ops/training.py:65 2019-01-16 09:50:12.723217: step 5439, loss = 0.71857 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:50:13.684103 ops/training.py:65 2019-01-16 09:50:13.684046: step 5440, loss = 0.69311 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:50:14.645064 ops/training.py:65 2019-01-16 09:50:14.645016: step 5441, loss = 0.73723 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:50:15.608924 ops/training.py:65 2019-01-16 09:50:15.608876: step 5442, loss = 0.77181 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.25
I0832 2019-01-16 09:50:16.570993 ops/training.py:65 2019-01-16 09:50:16.570939: step 5443, loss = 0.68314 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:50:17.533418 ops/training.py:65 2019-01-16 09:50:17.533364: step 5444, loss = 0.67887 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:50:18.497135 ops/training.py:65 2019-01-16 09:50:18.497066: step 5445, loss = 0.67737 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:50:19.459408 ops/training.py:65 2019-01-16 09:50:19.459335: step 5446, loss = 0.66880 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:50:20.420449 ops/training.py:65 2019-01-16 09:50:20.420397: step 5447, loss = 0.68616 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:50:21.381096 ops/training.py:65 2019-01-16 09:50:21.381046: step 5448, loss = 0.68637 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:50:22.342499 ops/training.py:65 2019-01-16 09:50:22.342445: step 5449, loss = 0.68712 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:50:23.308266 ops/training.py:65 2019-01-16 09:50:23.308192: step 5450, loss = 0.68891 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:50:24.272687 ops/training.py:65 2019-01-16 09:50:24.272636: step 5451, loss = 0.71195 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:50:25.236519 ops/training.py:65 2019-01-16 09:50:25.236469: step 5452, loss = 0.71885 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:50:26.197483 ops/training.py:65 2019-01-16 09:50:26.197429: step 5453, loss = 0.72344 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:50:27.158337 ops/training.py:65 2019-01-16 09:50:27.158284: step 5454, loss = 0.71668 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:50:28.121115 ops/training.py:65 2019-01-16 09:50:28.121063: step 5455, loss = 0.69778 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:50:29.085165 ops/training.py:65 2019-01-16 09:50:29.085112: step 5456, loss = 0.70550 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:50:30.046542 ops/training.py:65 2019-01-16 09:50:30.046470: step 5457, loss = 0.67424 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:50:31.007781 ops/training.py:65 2019-01-16 09:50:31.007708: step 5458, loss = 0.67965 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:50:31.970045 ops/training.py:65 2019-01-16 09:50:31.969968: step 5459, loss = 0.70470 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:50:32.931758 ops/training.py:65 2019-01-16 09:50:32.931686: step 5460, loss = 0.67592 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:50:33.894398 ops/training.py:65 2019-01-16 09:50:33.894338: step 5461, loss = 0.71646 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:50:34.855262 ops/training.py:65 2019-01-16 09:50:34.855206: step 5462, loss = 0.71493 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:50:35.815943 ops/training.py:65 2019-01-16 09:50:35.815871: step 5463, loss = 0.72994 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:50:36.775769 ops/training.py:65 2019-01-16 09:50:36.775715: step 5464, loss = 0.73847 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:50:37.740058 ops/training.py:65 2019-01-16 09:50:37.740006: step 5465, loss = 0.71249 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:50:38.702498 ops/training.py:65 2019-01-16 09:50:38.702444: step 5466, loss = 0.71229 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:50:39.665658 ops/training.py:65 2019-01-16 09:50:39.665606: step 5467, loss = 0.75846 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:50:40.626704 ops/training.py:65 2019-01-16 09:50:40.626649: step 5468, loss = 0.65844 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:50:41.587771 ops/training.py:65 2019-01-16 09:50:41.587710: step 5469, loss = 0.68319 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:50:42.548803 ops/training.py:65 2019-01-16 09:50:42.548741: step 5470, loss = 0.65276 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:50:43.509820 ops/training.py:65 2019-01-16 09:50:43.509757: step 5471, loss = 0.70175 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:50:44.473216 ops/training.py:65 2019-01-16 09:50:44.473159: step 5472, loss = 0.67919 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:50:45.433823 ops/training.py:65 2019-01-16 09:50:45.433764: step 5473, loss = 0.70729 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:50:46.399215 ops/training.py:65 2019-01-16 09:50:46.399156: step 5474, loss = 0.69671 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:50:47.362657 ops/training.py:65 2019-01-16 09:50:47.362600: step 5475, loss = 0.68735 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:50:48.325786 ops/training.py:65 2019-01-16 09:50:48.325726: step 5476, loss = 0.67228 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:50:49.288046 ops/training.py:65 2019-01-16 09:50:49.287989: step 5477, loss = 0.69807 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:50:50.250195 ops/training.py:65 2019-01-16 09:50:50.250154: step 5478, loss = 0.69893 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:50:51.211734 ops/training.py:65 2019-01-16 09:50:51.211676: step 5479, loss = 0.70537 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:50:52.174244 ops/training.py:65 2019-01-16 09:50:52.174186: step 5480, loss = 0.69196 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:50:53.135587 ops/training.py:65 2019-01-16 09:50:53.135528: step 5481, loss = 0.70433 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:50:54.097148 ops/training.py:65 2019-01-16 09:50:54.097090: step 5482, loss = 0.69703 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:50:55.058792 ops/training.py:65 2019-01-16 09:50:55.058733: step 5483, loss = 0.67392 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:50:56.019868 ops/training.py:65 2019-01-16 09:50:56.019810: step 5484, loss = 0.69609 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:50:56.980080 ops/training.py:65 2019-01-16 09:50:56.980018: step 5485, loss = 0.69074 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:50:57.940697 ops/training.py:65 2019-01-16 09:50:57.940640: step 5486, loss = 0.68792 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:50:58.901220 ops/training.py:65 2019-01-16 09:50:58.901162: step 5487, loss = 0.68011 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:50:59.860588 ops/training.py:65 2019-01-16 09:50:59.860529: step 5488, loss = 0.69499 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:51:00.821333 ops/training.py:65 2019-01-16 09:51:00.821277: step 5489, loss = 0.68909 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:51:01.785306 ops/training.py:65 2019-01-16 09:51:01.785251: step 5490, loss = 0.68530 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:51:02.748711 ops/training.py:65 2019-01-16 09:51:02.748659: step 5491, loss = 0.68316 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:51:03.708136 ops/training.py:65 2019-01-16 09:51:03.708083: step 5492, loss = 0.70972 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:51:04.671396 ops/training.py:65 2019-01-16 09:51:04.671344: step 5493, loss = 0.68092 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:51:05.634079 ops/training.py:65 2019-01-16 09:51:05.634033: step 5494, loss = 0.68921 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:51:06.595406 ops/training.py:65 2019-01-16 09:51:06.595352: step 5495, loss = 0.69388 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:51:07.557748 ops/training.py:65 2019-01-16 09:51:07.557691: step 5496, loss = 0.71160 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:51:08.519093 ops/training.py:65 2019-01-16 09:51:08.519022: step 5497, loss = 0.69334 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:51:09.483041 ops/training.py:65 2019-01-16 09:51:09.482965: step 5498, loss = 0.64950 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 09:51:10.445887 ops/training.py:65 2019-01-16 09:51:10.445830: step 5499, loss = 0.66980 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:51:11.410472 ops/training.py:65 2019-01-16 09:51:11.410408: step 5500, loss = 0.72909 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:51:12.372725 ops/training.py:65 2019-01-16 09:51:12.372656: step 5501, loss = 0.71221 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:51:13.336659 ops/training.py:65 2019-01-16 09:51:13.336589: step 5502, loss = 0.69367 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:51:14.298504 ops/training.py:65 2019-01-16 09:51:14.298438: step 5503, loss = 0.70158 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:51:15.263190 ops/training.py:65 2019-01-16 09:51:15.263135: step 5504, loss = 0.73786 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:51:16.227265 ops/training.py:65 2019-01-16 09:51:16.227206: step 5505, loss = 0.69071 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:51:17.190216 ops/training.py:65 2019-01-16 09:51:17.190158: step 5506, loss = 0.70865 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:51:18.151985 ops/training.py:65 2019-01-16 09:51:18.151929: step 5507, loss = 0.67109 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:51:19.113305 ops/training.py:65 2019-01-16 09:51:19.113264: step 5508, loss = 0.69188 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:51:20.074955 ops/training.py:65 2019-01-16 09:51:20.074893: step 5509, loss = 0.68802 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:51:21.035287 ops/training.py:65 2019-01-16 09:51:21.035229: step 5510, loss = 0.66960 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:51:21.996414 ops/training.py:65 2019-01-16 09:51:21.996357: step 5511, loss = 0.70414 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:51:22.958656 ops/training.py:65 2019-01-16 09:51:22.958598: step 5512, loss = 0.70300 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:51:23.920238 ops/training.py:65 2019-01-16 09:51:23.920179: step 5513, loss = 0.69118 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:51:24.881629 ops/training.py:65 2019-01-16 09:51:24.881578: step 5514, loss = 0.69940 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:51:25.842798 ops/training.py:65 2019-01-16 09:51:25.842741: step 5515, loss = 0.68558 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:51:26.804214 ops/training.py:65 2019-01-16 09:51:26.804156: step 5516, loss = 0.71761 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:51:27.765523 ops/training.py:65 2019-01-16 09:51:27.765460: step 5517, loss = 0.72465 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:51:28.726085 ops/training.py:65 2019-01-16 09:51:28.726044: step 5518, loss = 0.67069 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:51:29.687290 ops/training.py:65 2019-01-16 09:51:29.687233: step 5519, loss = 0.69630 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:51:30.648954 ops/training.py:65 2019-01-16 09:51:30.648900: step 5520, loss = 0.68431 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:51:31.610555 ops/training.py:65 2019-01-16 09:51:31.610499: step 5521, loss = 0.70764 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:51:32.572332 ops/training.py:65 2019-01-16 09:51:32.572277: step 5522, loss = 0.71154 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:51:33.533045 ops/training.py:65 2019-01-16 09:51:33.532970: step 5523, loss = 0.67304 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:51:34.498833 ops/training.py:65 2019-01-16 09:51:34.498766: step 5524, loss = 0.70380 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:51:35.461665 ops/training.py:65 2019-01-16 09:51:35.461608: step 5525, loss = 0.70788 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:51:36.424551 ops/training.py:65 2019-01-16 09:51:36.424490: step 5526, loss = 0.68849 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:51:37.387003 ops/training.py:65 2019-01-16 09:51:37.386946: step 5527, loss = 0.70662 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:51:38.348361 ops/training.py:65 2019-01-16 09:51:38.348302: step 5528, loss = 0.68838 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:51:39.308456 ops/training.py:65 2019-01-16 09:51:39.308401: step 5529, loss = 0.64540 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 09:51:40.269168 ops/training.py:65 2019-01-16 09:51:40.269113: step 5530, loss = 0.70110 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:51:41.233142 ops/training.py:65 2019-01-16 09:51:41.233085: step 5531, loss = 0.70747 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:51:42.196678 ops/training.py:65 2019-01-16 09:51:42.196621: step 5532, loss = 0.74471 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:51:43.159523 ops/training.py:65 2019-01-16 09:51:43.159466: step 5533, loss = 0.74071 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:51:44.121161 ops/training.py:65 2019-01-16 09:51:44.121123: step 5534, loss = 0.66776 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:51:45.083385 ops/training.py:65 2019-01-16 09:51:45.083342: step 5535, loss = 0.68046 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:51:46.045741 ops/training.py:65 2019-01-16 09:51:46.045683: step 5536, loss = 0.70471 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:51:47.006920 ops/training.py:65 2019-01-16 09:51:47.006862: step 5537, loss = 0.68304 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:51:47.968862 ops/training.py:65 2019-01-16 09:51:47.968804: step 5538, loss = 0.74629 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:51:48.930997 ops/training.py:65 2019-01-16 09:51:48.930935: step 5539, loss = 0.69031 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:51:49.892347 ops/training.py:65 2019-01-16 09:51:49.892293: step 5540, loss = 0.68189 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:51:50.856376 ops/training.py:65 2019-01-16 09:51:50.856320: step 5541, loss = 0.67205 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:51:51.819750 ops/training.py:65 2019-01-16 09:51:51.819695: step 5542, loss = 0.67000 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:51:52.780531 ops/training.py:65 2019-01-16 09:51:52.780475: step 5543, loss = 0.73137 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:51:53.745443 ops/training.py:65 2019-01-16 09:51:53.745402: step 5544, loss = 0.71176 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:51:54.710958 ops/training.py:65 2019-01-16 09:51:54.710901: step 5545, loss = 0.71154 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:51:55.675079 ops/training.py:65 2019-01-16 09:51:55.675024: step 5546, loss = 0.68847 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:51:56.635460 ops/training.py:65 2019-01-16 09:51:56.635402: step 5547, loss = 0.69418 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:51:57.597405 ops/training.py:65 2019-01-16 09:51:57.597348: step 5548, loss = 0.68861 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:51:58.558488 ops/training.py:65 2019-01-16 09:51:58.558431: step 5549, loss = 0.68683 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:51:59.522912 ops/training.py:65 2019-01-16 09:51:59.522858: step 5550, loss = 0.67735 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:52:00.487102 ops/training.py:65 2019-01-16 09:52:00.487041: step 5551, loss = 0.69969 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:52:01.449825 ops/training.py:65 2019-01-16 09:52:01.449773: step 5552, loss = 0.70210 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:52:02.410846 ops/training.py:65 2019-01-16 09:52:02.410794: step 5553, loss = 0.69757 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:52:03.372592 ops/training.py:65 2019-01-16 09:52:03.372539: step 5554, loss = 0.67102 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:52:04.333941 ops/training.py:65 2019-01-16 09:52:04.333888: step 5555, loss = 0.68434 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:52:05.294867 ops/training.py:65 2019-01-16 09:52:05.294805: step 5556, loss = 0.68226 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:52:06.256387 ops/training.py:65 2019-01-16 09:52:06.256332: step 5557, loss = 0.71752 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:52:07.217717 ops/training.py:65 2019-01-16 09:52:07.217651: step 5558, loss = 0.71462 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:52:08.179876 ops/training.py:65 2019-01-16 09:52:08.179820: step 5559, loss = 0.70955 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:52:09.140849 ops/training.py:65 2019-01-16 09:52:09.140794: step 5560, loss = 0.72107 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:52:10.101771 ops/training.py:65 2019-01-16 09:52:10.101732: step 5561, loss = 0.66038 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:52:11.065257 ops/training.py:65 2019-01-16 09:52:11.065201: step 5562, loss = 0.66151 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:52:12.029300 ops/training.py:65 2019-01-16 09:52:12.029246: step 5563, loss = 0.67991 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:52:12.992650 ops/training.py:65 2019-01-16 09:52:12.992603: step 5564, loss = 0.65485 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:52:13.956904 ops/training.py:65 2019-01-16 09:52:13.956844: step 5565, loss = 0.67914 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:52:14.917180 ops/training.py:65 2019-01-16 09:52:14.917124: step 5566, loss = 0.70642 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:52:15.880713 ops/training.py:65 2019-01-16 09:52:15.880658: step 5567, loss = 0.66204 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:52:16.845365 ops/training.py:65 2019-01-16 09:52:16.845309: step 5568, loss = 0.69778 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:52:17.805853 ops/training.py:65 2019-01-16 09:52:17.805797: step 5569, loss = 0.64752 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:52:18.768926 ops/training.py:65 2019-01-16 09:52:18.768871: step 5570, loss = 0.66183 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:52:19.732864 ops/training.py:65 2019-01-16 09:52:19.732810: step 5571, loss = 0.76196 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:52:20.696436 ops/training.py:65 2019-01-16 09:52:20.696382: step 5572, loss = 0.73897 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:52:21.658203 ops/training.py:65 2019-01-16 09:52:21.658148: step 5573, loss = 0.69403 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:52:22.619178 ops/training.py:65 2019-01-16 09:52:22.619121: step 5574, loss = 0.72058 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:52:23.581878 ops/training.py:65 2019-01-16 09:52:23.581822: step 5575, loss = 0.71585 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:52:24.543087 ops/training.py:65 2019-01-16 09:52:24.543046: step 5576, loss = 0.65185 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:52:25.504488 ops/training.py:65 2019-01-16 09:52:25.504448: step 5577, loss = 0.73423 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:52:26.466157 ops/training.py:65 2019-01-16 09:52:26.466102: step 5578, loss = 0.66386 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:52:27.427567 ops/training.py:65 2019-01-16 09:52:27.427509: step 5579, loss = 0.70458 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:52:28.389376 ops/training.py:65 2019-01-16 09:52:28.389320: step 5580, loss = 0.71386 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:52:29.350879 ops/training.py:65 2019-01-16 09:52:29.350822: step 5581, loss = 0.67838 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:52:30.311490 ops/training.py:65 2019-01-16 09:52:30.311434: step 5582, loss = 0.69272 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:52:31.273477 ops/training.py:65 2019-01-16 09:52:31.273422: step 5583, loss = 0.66906 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:52:32.233881 ops/training.py:65 2019-01-16 09:52:32.233833: step 5584, loss = 0.71637 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:52:33.195433 ops/training.py:65 2019-01-16 09:52:33.195371: step 5585, loss = 0.72352 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:52:34.158257 ops/training.py:65 2019-01-16 09:52:34.158195: step 5586, loss = 0.66379 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:52:35.118298 ops/training.py:65 2019-01-16 09:52:35.118251: step 5587, loss = 0.72317 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:52:36.083060 ops/training.py:65 2019-01-16 09:52:36.082995: step 5588, loss = 0.68500 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:52:37.046135 ops/training.py:65 2019-01-16 09:52:37.046075: step 5589, loss = 0.73199 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:52:38.006467 ops/training.py:65 2019-01-16 09:52:38.006413: step 5590, loss = 0.69201 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:52:38.970272 ops/training.py:65 2019-01-16 09:52:38.970224: step 5591, loss = 0.69912 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:52:39.933749 ops/training.py:65 2019-01-16 09:52:39.933694: step 5592, loss = 0.67081 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:52:40.894752 ops/training.py:65 2019-01-16 09:52:40.894698: step 5593, loss = 0.70381 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:52:41.855986 ops/training.py:65 2019-01-16 09:52:41.855932: step 5594, loss = 0.73424 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:52:42.817955 ops/training.py:65 2019-01-16 09:52:42.817897: step 5595, loss = 0.72682 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:52:43.778895 ops/training.py:65 2019-01-16 09:52:43.778840: step 5596, loss = 0.68072 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:52:44.739738 ops/training.py:65 2019-01-16 09:52:44.739700: step 5597, loss = 0.70769 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:52:45.701485 ops/training.py:65 2019-01-16 09:52:45.701433: step 5598, loss = 0.71558 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:52:46.662596 ops/training.py:65 2019-01-16 09:52:46.662534: step 5599, loss = 0.79110 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:52:47.622143 ops/training.py:65 2019-01-16 09:52:47.622071: step 5600, loss = 0.68258 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:52:48.581185 ops/training.py:65 2019-01-16 09:52:48.581122: step 5601, loss = 0.69471 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:52:49.544753 ops/training.py:65 2019-01-16 09:52:49.544694: step 5602, loss = 0.69706 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:52:50.511237 ops/training.py:65 2019-01-16 09:52:50.511178: step 5603, loss = 0.70723 (33.1 examples/sec; 0.966 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:52:51.475182 ops/training.py:65 2019-01-16 09:52:51.475131: step 5604, loss = 0.74617 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:52:52.439905 ops/training.py:65 2019-01-16 09:52:52.439847: step 5605, loss = 0.74582 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:52:53.403332 ops/training.py:65 2019-01-16 09:52:53.403275: step 5606, loss = 0.69204 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:52:54.365274 ops/training.py:65 2019-01-16 09:52:54.365219: step 5607, loss = 0.69089 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:52:55.327806 ops/training.py:65 2019-01-16 09:52:55.327749: step 5608, loss = 0.71535 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:52:56.293281 ops/training.py:65 2019-01-16 09:52:56.293223: step 5609, loss = 0.75177 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:52:57.257674 ops/training.py:65 2019-01-16 09:52:57.257618: step 5610, loss = 0.69219 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:52:58.221208 ops/training.py:65 2019-01-16 09:52:58.221167: step 5611, loss = 0.70693 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:52:59.181952 ops/training.py:65 2019-01-16 09:52:59.181895: step 5612, loss = 0.70568 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:53:00.142838 ops/training.py:65 2019-01-16 09:53:00.142780: step 5613, loss = 0.70715 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:53:01.104244 ops/training.py:65 2019-01-16 09:53:01.104182: step 5614, loss = 0.69508 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:53:02.066646 ops/training.py:65 2019-01-16 09:53:02.066594: step 5615, loss = 0.70748 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:53:03.028046 ops/training.py:65 2019-01-16 09:53:03.027991: step 5616, loss = 0.65844 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:53:03.989005 ops/training.py:65 2019-01-16 09:53:03.988951: step 5617, loss = 0.70166 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:53:04.950001 ops/training.py:65 2019-01-16 09:53:04.949928: step 5618, loss = 0.67210 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:53:05.910721 ops/training.py:65 2019-01-16 09:53:05.910649: step 5619, loss = 0.69220 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:53:06.874536 ops/training.py:65 2019-01-16 09:53:06.874462: step 5620, loss = 0.68763 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:53:07.839073 ops/training.py:65 2019-01-16 09:53:07.839001: step 5621, loss = 0.70431 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:53:08.803535 ops/training.py:65 2019-01-16 09:53:08.803459: step 5622, loss = 0.74362 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:53:09.765273 ops/training.py:65 2019-01-16 09:53:09.765216: step 5623, loss = 0.66719 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:53:10.726630 ops/training.py:65 2019-01-16 09:53:10.726557: step 5624, loss = 0.71816 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:53:11.687796 ops/training.py:65 2019-01-16 09:53:11.687727: step 5625, loss = 0.70269 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:53:12.652345 ops/training.py:65 2019-01-16 09:53:12.652284: step 5626, loss = 0.68344 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:53:13.616041 ops/training.py:65 2019-01-16 09:53:13.615994: step 5627, loss = 0.66981 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:53:14.578249 ops/training.py:65 2019-01-16 09:53:14.578203: step 5628, loss = 0.71567 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:53:15.539433 ops/training.py:65 2019-01-16 09:53:15.539381: step 5629, loss = 0.70875 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:53:16.502250 ops/training.py:65 2019-01-16 09:53:16.502191: step 5630, loss = 0.69827 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:53:17.465380 ops/training.py:65 2019-01-16 09:53:17.465325: step 5631, loss = 0.69429 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:53:18.428233 ops/training.py:65 2019-01-16 09:53:18.428181: step 5632, loss = 0.72291 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:53:19.389977 ops/training.py:65 2019-01-16 09:53:19.389923: step 5633, loss = 0.68213 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:53:20.352160 ops/training.py:65 2019-01-16 09:53:20.352085: step 5634, loss = 0.69399 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:53:21.313262 ops/training.py:65 2019-01-16 09:53:21.313192: step 5635, loss = 0.70900 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:53:22.274692 ops/training.py:65 2019-01-16 09:53:22.274632: step 5636, loss = 0.69233 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:53:23.235811 ops/training.py:65 2019-01-16 09:53:23.235765: step 5637, loss = 0.67330 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:53:24.197747 ops/training.py:65 2019-01-16 09:53:24.197681: step 5638, loss = 0.69105 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:53:25.159327 ops/training.py:65 2019-01-16 09:53:25.159269: step 5639, loss = 0.69350 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:53:26.121212 ops/training.py:65 2019-01-16 09:53:26.121149: step 5640, loss = 0.69331 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:53:27.083072 ops/training.py:65 2019-01-16 09:53:27.083026: step 5641, loss = 0.68375 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:53:28.045194 ops/training.py:65 2019-01-16 09:53:28.045149: step 5642, loss = 0.69831 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:53:29.006900 ops/training.py:65 2019-01-16 09:53:29.006849: step 5643, loss = 0.68771 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:53:29.967250 ops/training.py:65 2019-01-16 09:53:29.967190: step 5644, loss = 0.65588 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:53:30.927809 ops/training.py:65 2019-01-16 09:53:30.927748: step 5645, loss = 0.68057 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:53:31.888909 ops/training.py:65 2019-01-16 09:53:31.888853: step 5646, loss = 0.70753 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:53:32.851026 ops/training.py:65 2019-01-16 09:53:32.850978: step 5647, loss = 0.68141 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:53:33.813374 ops/training.py:65 2019-01-16 09:53:33.813316: step 5648, loss = 0.68016 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:53:34.774645 ops/training.py:65 2019-01-16 09:53:34.774587: step 5649, loss = 0.70116 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:53:35.737699 ops/training.py:65 2019-01-16 09:53:35.737641: step 5650, loss = 0.68624 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:53:36.697682 ops/training.py:65 2019-01-16 09:53:36.697618: step 5651, loss = 0.68335 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:53:37.661831 ops/training.py:65 2019-01-16 09:53:37.661773: step 5652, loss = 0.68553 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:53:38.625762 ops/training.py:65 2019-01-16 09:53:38.625704: step 5653, loss = 0.71267 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:53:39.588810 ops/training.py:65 2019-01-16 09:53:39.588754: step 5654, loss = 0.68517 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:53:40.553369 ops/training.py:65 2019-01-16 09:53:40.553311: step 5655, loss = 0.69619 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:53:41.514151 ops/training.py:65 2019-01-16 09:53:41.514095: step 5656, loss = 0.70800 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:53:42.479302 ops/training.py:65 2019-01-16 09:53:42.479262: step 5657, loss = 0.67666 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:53:43.444317 ops/training.py:65 2019-01-16 09:53:43.444260: step 5658, loss = 0.69371 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:53:44.408056 ops/training.py:65 2019-01-16 09:53:44.407999: step 5659, loss = 0.73262 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:53:45.369478 ops/training.py:65 2019-01-16 09:53:45.369425: step 5660, loss = 0.68923 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:53:46.334293 ops/training.py:65 2019-01-16 09:53:46.334229: step 5661, loss = 0.70372 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:53:47.294467 ops/training.py:65 2019-01-16 09:53:47.294405: step 5662, loss = 0.66359 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:53:48.253768 ops/training.py:65 2019-01-16 09:53:48.253708: step 5663, loss = 0.70810 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:53:49.216107 ops/training.py:65 2019-01-16 09:53:49.216058: step 5664, loss = 0.72311 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:53:50.180336 ops/training.py:65 2019-01-16 09:53:50.180282: step 5665, loss = 0.68203 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:53:51.143768 ops/training.py:65 2019-01-16 09:53:51.143708: step 5666, loss = 0.68876 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:53:52.106426 ops/training.py:65 2019-01-16 09:53:52.106381: step 5667, loss = 0.67723 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:53:53.068075 ops/training.py:65 2019-01-16 09:53:53.068022: step 5668, loss = 0.70717 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:53:54.030702 ops/training.py:65 2019-01-16 09:53:54.030641: step 5669, loss = 0.66481 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:53:54.993685 ops/training.py:65 2019-01-16 09:53:54.993642: step 5670, loss = 0.72672 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:53:55.954956 ops/training.py:65 2019-01-16 09:53:55.954905: step 5671, loss = 0.69732 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:53:56.917581 ops/training.py:65 2019-01-16 09:53:56.917535: step 5672, loss = 0.68294 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:53:57.878711 ops/training.py:65 2019-01-16 09:53:57.878665: step 5673, loss = 0.70354 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:53:58.840866 ops/training.py:65 2019-01-16 09:53:58.840804: step 5674, loss = 0.65387 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:53:59.802581 ops/training.py:65 2019-01-16 09:53:59.802518: step 5675, loss = 0.69937 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:54:00.764650 ops/training.py:65 2019-01-16 09:54:00.764586: step 5676, loss = 0.70247 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:54:01.725688 ops/training.py:65 2019-01-16 09:54:01.725632: step 5677, loss = 0.70281 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:54:02.687035 ops/training.py:65 2019-01-16 09:54:02.686978: step 5678, loss = 0.69250 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:54:03.648490 ops/training.py:65 2019-01-16 09:54:03.648435: step 5679, loss = 0.68227 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:54:04.610402 ops/training.py:65 2019-01-16 09:54:04.610361: step 5680, loss = 0.67117 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:54:05.571188 ops/training.py:65 2019-01-16 09:54:05.571134: step 5681, loss = 0.67754 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:54:06.531371 ops/training.py:65 2019-01-16 09:54:06.531311: step 5682, loss = 0.67107 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:54:07.492162 ops/training.py:65 2019-01-16 09:54:07.492090: step 5683, loss = 0.68046 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:54:08.453690 ops/training.py:65 2019-01-16 09:54:08.453624: step 5684, loss = 0.68306 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:54:09.415340 ops/training.py:65 2019-01-16 09:54:09.415301: step 5685, loss = 0.69998 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:54:10.376635 ops/training.py:65 2019-01-16 09:54:10.376594: step 5686, loss = 0.70750 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:54:11.337933 ops/training.py:65 2019-01-16 09:54:11.337897: step 5687, loss = 0.66514 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:54:12.298823 ops/training.py:65 2019-01-16 09:54:12.298785: step 5688, loss = 0.70088 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:54:13.261494 ops/training.py:65 2019-01-16 09:54:13.261458: step 5689, loss = 0.67482 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:54:14.222704 ops/training.py:65 2019-01-16 09:54:14.222641: step 5690, loss = 0.70161 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:54:15.183827 ops/training.py:65 2019-01-16 09:54:15.183789: step 5691, loss = 0.73037 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:54:16.145024 ops/training.py:65 2019-01-16 09:54:16.144987: step 5692, loss = 0.68167 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:54:17.106101 ops/training.py:65 2019-01-16 09:54:17.106065: step 5693, loss = 0.71273 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:54:18.065959 ops/training.py:65 2019-01-16 09:54:18.065921: step 5694, loss = 0.65919 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:54:19.029656 ops/training.py:65 2019-01-16 09:54:19.029620: step 5695, loss = 0.65519 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:54:19.993261 ops/training.py:65 2019-01-16 09:54:19.993221: step 5696, loss = 0.68940 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:54:20.956352 ops/training.py:65 2019-01-16 09:54:20.956294: step 5697, loss = 0.69866 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:54:21.918328 ops/training.py:65 2019-01-16 09:54:21.918274: step 5698, loss = 0.68319 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:54:22.879774 ops/training.py:65 2019-01-16 09:54:22.879726: step 5699, loss = 0.72195 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:54:23.839232 ops/training.py:65 2019-01-16 09:54:23.839185: step 5700, loss = 0.70259 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:54:24.800133 ops/training.py:65 2019-01-16 09:54:24.800082: step 5701, loss = 0.68326 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:54:25.764403 ops/training.py:65 2019-01-16 09:54:25.764351: step 5702, loss = 0.68164 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:54:26.727835 ops/training.py:65 2019-01-16 09:54:26.727790: step 5703, loss = 0.69869 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:54:27.692947 ops/training.py:65 2019-01-16 09:54:27.692911: step 5704, loss = 0.72278 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:54:28.656539 ops/training.py:65 2019-01-16 09:54:28.656499: step 5705, loss = 0.69605 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:54:29.619084 ops/training.py:65 2019-01-16 09:54:29.619047: step 5706, loss = 0.69777 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:54:30.579657 ops/training.py:65 2019-01-16 09:54:30.579603: step 5707, loss = 0.70936 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:54:31.543507 ops/training.py:65 2019-01-16 09:54:31.543467: step 5708, loss = 0.68544 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:54:32.505194 ops/training.py:65 2019-01-16 09:54:32.505120: step 5709, loss = 0.70944 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:54:33.469005 ops/training.py:65 2019-01-16 09:54:33.468947: step 5710, loss = 0.69479 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:54:34.431880 ops/training.py:65 2019-01-16 09:54:34.431809: step 5711, loss = 0.70883 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:54:35.393668 ops/training.py:65 2019-01-16 09:54:35.393598: step 5712, loss = 0.68090 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:54:36.355319 ops/training.py:65 2019-01-16 09:54:36.355248: step 5713, loss = 0.69850 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:54:37.316609 ops/training.py:65 2019-01-16 09:54:37.316542: step 5714, loss = 0.71062 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:54:38.278389 ops/training.py:65 2019-01-16 09:54:38.278327: step 5715, loss = 0.70115 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:54:39.239427 ops/training.py:65 2019-01-16 09:54:39.239355: step 5716, loss = 0.67102 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:54:40.201173 ops/training.py:65 2019-01-16 09:54:40.201103: step 5717, loss = 0.66322 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:54:41.164388 ops/training.py:65 2019-01-16 09:54:41.164321: step 5718, loss = 0.70123 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:54:42.125751 ops/training.py:65 2019-01-16 09:54:42.125684: step 5719, loss = 0.68514 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:54:43.087060 ops/training.py:65 2019-01-16 09:54:43.086990: step 5720, loss = 0.72310 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:54:44.048576 ops/training.py:65 2019-01-16 09:54:44.048503: step 5721, loss = 0.71606 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:54:45.010419 ops/training.py:65 2019-01-16 09:54:45.010336: step 5722, loss = 0.70236 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:54:45.972389 ops/training.py:65 2019-01-16 09:54:45.972315: step 5723, loss = 0.74397 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:54:46.932685 ops/training.py:65 2019-01-16 09:54:46.932613: step 5724, loss = 0.69278 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:54:47.893479 ops/training.py:65 2019-01-16 09:54:47.893406: step 5725, loss = 0.72304 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:54:48.855808 ops/training.py:65 2019-01-16 09:54:48.855713: step 5726, loss = 0.66752 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:54:49.818925 ops/training.py:65 2019-01-16 09:54:49.818837: step 5727, loss = 0.71083 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:54:50.781301 ops/training.py:65 2019-01-16 09:54:50.781223: step 5728, loss = 0.72195 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:54:51.742871 ops/training.py:65 2019-01-16 09:54:51.742770: step 5729, loss = 0.69469 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:54:52.705704 ops/training.py:65 2019-01-16 09:54:52.705616: step 5730, loss = 0.71394 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:54:53.668501 ops/training.py:65 2019-01-16 09:54:53.668338: step 5731, loss = 0.69970 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:54:54.632110 ops/training.py:65 2019-01-16 09:54:54.632034: step 5732, loss = 0.68993 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:54:55.593835 ops/training.py:65 2019-01-16 09:54:55.593748: step 5733, loss = 0.71322 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:54:56.555646 ops/training.py:65 2019-01-16 09:54:56.555576: step 5734, loss = 0.68328 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:54:57.517120 ops/training.py:65 2019-01-16 09:54:57.517046: step 5735, loss = 0.68996 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:54:58.478725 ops/training.py:65 2019-01-16 09:54:58.478655: step 5736, loss = 0.67897 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:54:59.440217 ops/training.py:65 2019-01-16 09:54:59.440138: step 5737, loss = 0.71489 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:55:00.401958 ops/training.py:65 2019-01-16 09:55:00.401888: step 5738, loss = 0.73324 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:55:01.363510 ops/training.py:65 2019-01-16 09:55:01.363437: step 5739, loss = 0.71693 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:55:02.326914 ops/training.py:65 2019-01-16 09:55:02.326846: step 5740, loss = 0.69251 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:55:03.288525 ops/training.py:65 2019-01-16 09:55:03.288421: step 5741, loss = 0.67418 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:55:04.251845 ops/training.py:65 2019-01-16 09:55:04.251779: step 5742, loss = 0.68620 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:55:05.213529 ops/training.py:65 2019-01-16 09:55:05.213472: step 5743, loss = 0.68517 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:55:06.174364 ops/training.py:65 2019-01-16 09:55:06.174290: step 5744, loss = 0.69395 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:55:07.135909 ops/training.py:65 2019-01-16 09:55:07.135850: step 5745, loss = 0.71525 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:55:08.097675 ops/training.py:65 2019-01-16 09:55:08.097604: step 5746, loss = 0.70737 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:55:09.058436 ops/training.py:65 2019-01-16 09:55:09.058359: step 5747, loss = 0.73165 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:55:10.019062 ops/training.py:65 2019-01-16 09:55:10.018989: step 5748, loss = 0.67910 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:55:10.980066 ops/training.py:65 2019-01-16 09:55:10.979995: step 5749, loss = 0.68573 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:55:11.941486 ops/training.py:65 2019-01-16 09:55:11.941414: step 5750, loss = 0.68046 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:55:12.902490 ops/training.py:65 2019-01-16 09:55:12.902419: step 5751, loss = 0.67778 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:55:13.863888 ops/training.py:65 2019-01-16 09:55:13.863816: step 5752, loss = 0.66945 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:55:14.825549 ops/training.py:65 2019-01-16 09:55:14.825471: step 5753, loss = 0.69439 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:55:15.789598 ops/training.py:65 2019-01-16 09:55:15.789514: step 5754, loss = 0.66034 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:55:16.751584 ops/training.py:65 2019-01-16 09:55:16.751494: step 5755, loss = 0.69243 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:55:17.716160 ops/training.py:65 2019-01-16 09:55:17.716093: step 5756, loss = 0.69176 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:55:18.680307 ops/training.py:65 2019-01-16 09:55:18.680236: step 5757, loss = 0.68318 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:55:19.644299 ops/training.py:65 2019-01-16 09:55:19.644227: step 5758, loss = 0.69402 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:55:20.606150 ops/training.py:65 2019-01-16 09:55:20.606073: step 5759, loss = 0.68463 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:55:21.567799 ops/training.py:65 2019-01-16 09:55:21.567720: step 5760, loss = 0.69748 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:55:22.530054 ops/training.py:65 2019-01-16 09:55:22.529962: step 5761, loss = 0.70318 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:55:23.492198 ops/training.py:65 2019-01-16 09:55:23.492122: step 5762, loss = 0.69724 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:55:24.453252 ops/training.py:65 2019-01-16 09:55:24.453177: step 5763, loss = 0.70517 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:55:25.418327 ops/training.py:65 2019-01-16 09:55:25.418240: step 5764, loss = 0.69145 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:55:26.383530 ops/training.py:65 2019-01-16 09:55:26.383447: step 5765, loss = 0.68437 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:55:27.347317 ops/training.py:65 2019-01-16 09:55:27.347243: step 5766, loss = 0.70629 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:55:28.309779 ops/training.py:65 2019-01-16 09:55:28.309712: step 5767, loss = 0.67342 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:55:29.272213 ops/training.py:65 2019-01-16 09:55:29.272127: step 5768, loss = 0.74030 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:55:30.234779 ops/training.py:65 2019-01-16 09:55:30.234714: step 5769, loss = 0.70798 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:55:31.197020 ops/training.py:65 2019-01-16 09:55:31.196958: step 5770, loss = 0.71641 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:55:32.160107 ops/training.py:65 2019-01-16 09:55:32.160033: step 5771, loss = 0.67650 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:55:33.123250 ops/training.py:65 2019-01-16 09:55:33.123179: step 5772, loss = 0.67738 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:55:34.088579 ops/training.py:65 2019-01-16 09:55:34.088494: step 5773, loss = 0.71133 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:55:35.053714 ops/training.py:65 2019-01-16 09:55:35.053627: step 5774, loss = 0.65859 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:55:36.017853 ops/training.py:65 2019-01-16 09:55:36.017794: step 5775, loss = 0.69559 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:55:36.980246 ops/training.py:65 2019-01-16 09:55:36.980187: step 5776, loss = 0.69395 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:55:37.941107 ops/training.py:65 2019-01-16 09:55:37.941033: step 5777, loss = 0.71559 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:55:38.902520 ops/training.py:65 2019-01-16 09:55:38.902449: step 5778, loss = 0.69679 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:55:39.863851 ops/training.py:65 2019-01-16 09:55:39.863764: step 5779, loss = 0.69369 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:55:40.826460 ops/training.py:65 2019-01-16 09:55:40.826375: step 5780, loss = 0.67392 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:55:41.791685 ops/training.py:65 2019-01-16 09:55:41.791611: step 5781, loss = 0.69500 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:55:42.755257 ops/training.py:65 2019-01-16 09:55:42.755175: step 5782, loss = 0.68486 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:55:43.718815 ops/training.py:65 2019-01-16 09:55:43.718725: step 5783, loss = 0.72534 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:55:44.682592 ops/training.py:65 2019-01-16 09:55:44.682499: step 5784, loss = 0.74739 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 09:55:45.646084 ops/training.py:65 2019-01-16 09:55:45.646011: step 5785, loss = 0.67484 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:55:46.607097 ops/training.py:65 2019-01-16 09:55:46.607006: step 5786, loss = 0.68842 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:55:47.572701 ops/training.py:65 2019-01-16 09:55:47.572421: step 5787, loss = 0.72128 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:55:48.537670 ops/training.py:65 2019-01-16 09:55:48.537603: step 5788, loss = 0.67839 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:55:49.497459 ops/training.py:65 2019-01-16 09:55:49.497372: step 5789, loss = 0.74035 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:55:50.463259 ops/training.py:65 2019-01-16 09:55:50.463176: step 5790, loss = 0.73683 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:55:51.428184 ops/training.py:65 2019-01-16 09:55:51.428108: step 5791, loss = 0.67045 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:55:52.388892 ops/training.py:65 2019-01-16 09:55:52.388819: step 5792, loss = 0.72491 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:55:53.348847 ops/training.py:65 2019-01-16 09:55:53.348775: step 5793, loss = 0.71883 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:55:54.309091 ops/training.py:65 2019-01-16 09:55:54.309021: step 5794, loss = 0.71559 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:55:55.268299 ops/training.py:65 2019-01-16 09:55:55.268226: step 5795, loss = 0.70337 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:55:56.226467 ops/training.py:65 2019-01-16 09:55:56.226398: step 5796, loss = 0.71141 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:55:57.185470 ops/training.py:65 2019-01-16 09:55:57.185413: step 5797, loss = 0.69180 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:55:58.144070 ops/training.py:65 2019-01-16 09:55:58.144005: step 5798, loss = 0.69320 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:55:59.102807 ops/training.py:65 2019-01-16 09:55:59.102718: step 5799, loss = 0.69075 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:56:00.068205 ops/training.py:65 2019-01-16 09:56:00.068137: step 5800, loss = 0.70468 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:56:01.030653 ops/training.py:65 2019-01-16 09:56:01.030597: step 5801, loss = 0.70807 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:56:01.995323 ops/training.py:65 2019-01-16 09:56:01.995240: step 5802, loss = 0.69749 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:56:02.958950 ops/training.py:65 2019-01-16 09:56:02.958879: step 5803, loss = 0.71088 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:56:03.921458 ops/training.py:65 2019-01-16 09:56:03.921384: step 5804, loss = 0.71052 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:56:04.882051 ops/training.py:65 2019-01-16 09:56:04.881986: step 5805, loss = 0.73629 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:56:05.842479 ops/training.py:65 2019-01-16 09:56:05.842403: step 5806, loss = 0.68294 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:56:06.807395 ops/training.py:65 2019-01-16 09:56:06.807337: step 5807, loss = 0.66468 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:56:07.771899 ops/training.py:65 2019-01-16 09:56:07.771840: step 5808, loss = 0.67747 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:56:08.734646 ops/training.py:65 2019-01-16 09:56:08.734579: step 5809, loss = 0.67506 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:56:09.696585 ops/training.py:65 2019-01-16 09:56:09.696519: step 5810, loss = 0.67297 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:56:10.657224 ops/training.py:65 2019-01-16 09:56:10.657145: step 5811, loss = 0.70903 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:56:11.617304 ops/training.py:65 2019-01-16 09:56:11.617229: step 5812, loss = 0.72220 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:56:12.581082 ops/training.py:65 2019-01-16 09:56:12.581010: step 5813, loss = 0.72795 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:56:13.544300 ops/training.py:65 2019-01-16 09:56:13.544226: step 5814, loss = 0.68448 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:56:14.508580 ops/training.py:65 2019-01-16 09:56:14.508505: step 5815, loss = 0.69247 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:56:15.470879 ops/training.py:65 2019-01-16 09:56:15.470802: step 5816, loss = 0.72326 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:56:16.434442 ops/training.py:65 2019-01-16 09:56:16.434355: step 5817, loss = 0.66138 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:56:17.397766 ops/training.py:65 2019-01-16 09:56:17.397695: step 5818, loss = 0.70052 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:56:18.358229 ops/training.py:65 2019-01-16 09:56:18.358160: step 5819, loss = 0.75476 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:56:19.319913 ops/training.py:65 2019-01-16 09:56:19.319844: step 5820, loss = 0.71127 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:56:20.284243 ops/training.py:65 2019-01-16 09:56:20.284175: step 5821, loss = 0.65987 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:56:21.248861 ops/training.py:65 2019-01-16 09:56:21.248779: step 5822, loss = 0.69342 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:56:22.214305 ops/training.py:65 2019-01-16 09:56:22.214231: step 5823, loss = 0.71257 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:56:23.177121 ops/training.py:65 2019-01-16 09:56:23.177049: step 5824, loss = 0.70863 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:56:24.138641 ops/training.py:65 2019-01-16 09:56:24.138572: step 5825, loss = 0.66962 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:56:25.100567 ops/training.py:65 2019-01-16 09:56:25.100496: step 5826, loss = 0.70117 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:56:26.062288 ops/training.py:65 2019-01-16 09:56:26.062214: step 5827, loss = 0.70233 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:56:27.023784 ops/training.py:65 2019-01-16 09:56:27.023711: step 5828, loss = 0.71644 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:56:27.985776 ops/training.py:65 2019-01-16 09:56:27.985709: step 5829, loss = 0.65669 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:56:28.948103 ops/training.py:65 2019-01-16 09:56:28.948028: step 5830, loss = 0.68169 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:56:29.912077 ops/training.py:65 2019-01-16 09:56:29.912008: step 5831, loss = 0.67236 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:56:30.876925 ops/training.py:65 2019-01-16 09:56:30.876866: step 5832, loss = 0.78558 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:56:31.841070 ops/training.py:65 2019-01-16 09:56:31.841002: step 5833, loss = 0.67573 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:56:32.802317 ops/training.py:65 2019-01-16 09:56:32.802246: step 5834, loss = 0.67273 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:56:33.763799 ops/training.py:65 2019-01-16 09:56:33.763724: step 5835, loss = 0.70266 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:56:34.725392 ops/training.py:65 2019-01-16 09:56:34.725323: step 5836, loss = 0.69195 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:56:35.688309 ops/training.py:65 2019-01-16 09:56:35.688239: step 5837, loss = 0.70344 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:56:36.650583 ops/training.py:65 2019-01-16 09:56:36.650514: step 5838, loss = 0.71202 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:56:37.610217 ops/training.py:65 2019-01-16 09:56:37.610147: step 5839, loss = 0.68753 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:56:38.574244 ops/training.py:65 2019-01-16 09:56:38.574181: step 5840, loss = 0.69723 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:56:39.537413 ops/training.py:65 2019-01-16 09:56:39.537340: step 5841, loss = 0.70528 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:56:40.500099 ops/training.py:65 2019-01-16 09:56:40.500030: step 5842, loss = 0.71358 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:56:41.461813 ops/training.py:65 2019-01-16 09:56:41.461741: step 5843, loss = 0.69222 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:56:42.424289 ops/training.py:65 2019-01-16 09:56:42.424219: step 5844, loss = 0.66317 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:56:43.387043 ops/training.py:65 2019-01-16 09:56:43.386969: step 5845, loss = 0.70932 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:56:44.349579 ops/training.py:65 2019-01-16 09:56:44.349507: step 5846, loss = 0.72271 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:56:45.312169 ops/training.py:65 2019-01-16 09:56:45.312098: step 5847, loss = 0.68768 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:56:46.274632 ops/training.py:65 2019-01-16 09:56:46.274564: step 5848, loss = 0.71459 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:56:47.237447 ops/training.py:65 2019-01-16 09:56:47.237378: step 5849, loss = 0.62833 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:56:48.198961 ops/training.py:65 2019-01-16 09:56:48.198897: step 5850, loss = 0.72981 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:56:49.164304 ops/training.py:65 2019-01-16 09:56:49.164233: step 5851, loss = 0.67673 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 09:56:50.126641 ops/training.py:65 2019-01-16 09:56:50.126570: step 5852, loss = 0.73791 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 09:56:51.092028 ops/training.py:65 2019-01-16 09:56:51.091965: step 5853, loss = 0.69311 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:56:52.055960 ops/training.py:65 2019-01-16 09:56:52.055888: step 5854, loss = 0.68484 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:56:53.017882 ops/training.py:65 2019-01-16 09:56:53.017815: step 5855, loss = 0.72660 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 09:56:53.980005 ops/training.py:65 2019-01-16 09:56:53.979921: step 5856, loss = 0.67723 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:56:54.942913 ops/training.py:65 2019-01-16 09:56:54.942842: step 5857, loss = 0.75363 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 09:56:55.905563 ops/training.py:65 2019-01-16 09:56:55.905491: step 5858, loss = 0.74418 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:56:56.867662 ops/training.py:65 2019-01-16 09:56:56.867592: step 5859, loss = 0.69679 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:56:57.829561 ops/training.py:65 2019-01-16 09:56:57.829490: step 5860, loss = 0.68727 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:56:58.793801 ops/training.py:65 2019-01-16 09:56:58.793735: step 5861, loss = 0.67177 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:56:59.755318 ops/training.py:65 2019-01-16 09:56:59.755249: step 5862, loss = 0.70461 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:57:00.717739 ops/training.py:65 2019-01-16 09:57:00.717679: step 5863, loss = 0.68820 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:57:01.679502 ops/training.py:65 2019-01-16 09:57:01.679434: step 5864, loss = 0.73032 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:57:02.641166 ops/training.py:65 2019-01-16 09:57:02.641098: step 5865, loss = 0.73274 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:57:03.602853 ops/training.py:65 2019-01-16 09:57:03.602784: step 5866, loss = 0.68166 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:57:04.565246 ops/training.py:65 2019-01-16 09:57:04.565172: step 5867, loss = 0.69704 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:57:05.526017 ops/training.py:65 2019-01-16 09:57:05.525945: step 5868, loss = 0.70580 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:57:06.488980 ops/training.py:65 2019-01-16 09:57:06.488922: step 5869, loss = 0.69209 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:57:07.453308 ops/training.py:65 2019-01-16 09:57:07.453237: step 5870, loss = 0.71307 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:57:08.417533 ops/training.py:65 2019-01-16 09:57:08.417468: step 5871, loss = 0.70923 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:57:09.380240 ops/training.py:65 2019-01-16 09:57:09.380167: step 5872, loss = 0.73006 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:57:10.342384 ops/training.py:65 2019-01-16 09:57:10.342310: step 5873, loss = 0.70893 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:57:11.304501 ops/training.py:65 2019-01-16 09:57:11.304431: step 5874, loss = 0.68151 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:57:12.266975 ops/training.py:65 2019-01-16 09:57:12.266906: step 5875, loss = 0.67445 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:57:13.229205 ops/training.py:65 2019-01-16 09:57:13.229134: step 5876, loss = 0.68576 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:57:14.192457 ops/training.py:65 2019-01-16 09:57:14.192395: step 5877, loss = 0.68226 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:57:15.154729 ops/training.py:65 2019-01-16 09:57:15.154659: step 5878, loss = 0.68679 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:57:16.116761 ops/training.py:65 2019-01-16 09:57:16.116692: step 5879, loss = 0.67992 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:57:17.077405 ops/training.py:65 2019-01-16 09:57:17.077335: step 5880, loss = 0.74016 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.25
I0832 2019-01-16 09:57:18.037245 ops/training.py:65 2019-01-16 09:57:18.037191: step 5881, loss = 0.67156 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:57:19.002354 ops/training.py:65 2019-01-16 09:57:19.002284: step 5882, loss = 0.69371 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:57:19.966025 ops/training.py:65 2019-01-16 09:57:19.965955: step 5883, loss = 0.68185 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:57:20.929410 ops/training.py:65 2019-01-16 09:57:20.929339: step 5884, loss = 0.69428 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:57:21.892228 ops/training.py:65 2019-01-16 09:57:21.892158: step 5885, loss = 0.72484 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:57:22.853349 ops/training.py:65 2019-01-16 09:57:22.853278: step 5886, loss = 0.66590 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:57:23.815897 ops/training.py:65 2019-01-16 09:57:23.815829: step 5887, loss = 0.69161 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:57:24.778398 ops/training.py:65 2019-01-16 09:57:24.778327: step 5888, loss = 0.66913 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:57:25.740489 ops/training.py:65 2019-01-16 09:57:25.740420: step 5889, loss = 0.69303 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:57:26.702252 ops/training.py:65 2019-01-16 09:57:26.702181: step 5890, loss = 0.63238 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 09:57:27.664658 ops/training.py:65 2019-01-16 09:57:27.664589: step 5891, loss = 0.65412 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:57:28.627586 ops/training.py:65 2019-01-16 09:57:28.627534: step 5892, loss = 0.74103 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:57:29.588751 ops/training.py:65 2019-01-16 09:57:29.588695: step 5893, loss = 0.68256 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:57:30.550072 ops/training.py:65 2019-01-16 09:57:30.550018: step 5894, loss = 0.72435 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:57:31.511374 ops/training.py:65 2019-01-16 09:57:31.511303: step 5895, loss = 0.68249 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:57:32.472474 ops/training.py:65 2019-01-16 09:57:32.472401: step 5896, loss = 0.70382 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:57:33.434142 ops/training.py:65 2019-01-16 09:57:33.434085: step 5897, loss = 0.65343 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:57:34.396037 ops/training.py:65 2019-01-16 09:57:34.395979: step 5898, loss = 0.67496 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:57:35.357801 ops/training.py:65 2019-01-16 09:57:35.357724: step 5899, loss = 0.68043 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:57:36.320981 ops/training.py:65 2019-01-16 09:57:36.320906: step 5900, loss = 0.68726 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:57:37.283991 ops/training.py:65 2019-01-16 09:57:37.283930: step 5901, loss = 0.69687 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:57:38.245045 ops/training.py:65 2019-01-16 09:57:38.244993: step 5902, loss = 0.67214 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:57:39.210446 ops/training.py:65 2019-01-16 09:57:39.210392: step 5903, loss = 0.69926 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:57:40.175182 ops/training.py:65 2019-01-16 09:57:40.175110: step 5904, loss = 0.64576 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 09:57:41.139930 ops/training.py:65 2019-01-16 09:57:41.139857: step 5905, loss = 0.76479 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:57:42.102519 ops/training.py:65 2019-01-16 09:57:42.102449: step 5906, loss = 0.75065 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:57:43.064805 ops/training.py:65 2019-01-16 09:57:43.064754: step 5907, loss = 0.68792 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:57:44.027598 ops/training.py:65 2019-01-16 09:57:44.027546: step 5908, loss = 0.72010 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:57:44.990041 ops/training.py:65 2019-01-16 09:57:44.989959: step 5909, loss = 0.69852 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:57:45.952250 ops/training.py:65 2019-01-16 09:57:45.952178: step 5910, loss = 0.68614 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:57:46.915067 ops/training.py:65 2019-01-16 09:57:46.914996: step 5911, loss = 0.69356 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:57:47.877482 ops/training.py:65 2019-01-16 09:57:47.877408: step 5912, loss = 0.72078 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:57:48.840597 ops/training.py:65 2019-01-16 09:57:48.840522: step 5913, loss = 0.69698 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:57:49.803037 ops/training.py:65 2019-01-16 09:57:49.802986: step 5914, loss = 0.69040 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:57:50.765021 ops/training.py:65 2019-01-16 09:57:50.764948: step 5915, loss = 0.72015 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:57:51.726689 ops/training.py:65 2019-01-16 09:57:51.726620: step 5916, loss = 0.73425 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:57:52.688675 ops/training.py:65 2019-01-16 09:57:52.688603: step 5917, loss = 0.70473 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:57:53.652679 ops/training.py:65 2019-01-16 09:57:53.652605: step 5918, loss = 0.70779 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:57:54.617489 ops/training.py:65 2019-01-16 09:57:54.617419: step 5919, loss = 0.66905 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:57:55.581393 ops/training.py:65 2019-01-16 09:57:55.581319: step 5920, loss = 0.66405 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:57:56.543434 ops/training.py:65 2019-01-16 09:57:56.543363: step 5921, loss = 0.69073 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:57:57.505450 ops/training.py:65 2019-01-16 09:57:57.505380: step 5922, loss = 0.70244 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:57:58.470886 ops/training.py:65 2019-01-16 09:57:58.470818: step 5923, loss = 0.67086 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:57:59.434868 ops/training.py:65 2019-01-16 09:57:59.434801: step 5924, loss = 0.71670 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:58:00.396739 ops/training.py:65 2019-01-16 09:58:00.396680: step 5925, loss = 0.67533 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:58:01.356751 ops/training.py:65 2019-01-16 09:58:01.356695: step 5926, loss = 0.65708 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 09:58:02.317371 ops/training.py:65 2019-01-16 09:58:02.317311: step 5927, loss = 0.71080 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:58:03.282146 ops/training.py:65 2019-01-16 09:58:03.282075: step 5928, loss = 0.67363 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:58:04.246831 ops/training.py:65 2019-01-16 09:58:04.246759: step 5929, loss = 0.74309 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:58:05.210030 ops/training.py:65 2019-01-16 09:58:05.209952: step 5930, loss = 0.73969 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 09:58:06.172260 ops/training.py:65 2019-01-16 09:58:06.172190: step 5931, loss = 0.69740 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:58:07.134874 ops/training.py:65 2019-01-16 09:58:07.134806: step 5932, loss = 0.70771 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:58:08.097724 ops/training.py:65 2019-01-16 09:58:08.097643: step 5933, loss = 0.68575 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:58:09.059883 ops/training.py:65 2019-01-16 09:58:09.059827: step 5934, loss = 0.70874 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:58:10.021119 ops/training.py:65 2019-01-16 09:58:10.021062: step 5935, loss = 0.69950 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:58:10.985676 ops/training.py:65 2019-01-16 09:58:10.985622: step 5936, loss = 0.73432 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:58:11.948595 ops/training.py:65 2019-01-16 09:58:11.948523: step 5937, loss = 0.68702 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:58:12.910256 ops/training.py:65 2019-01-16 09:58:12.910201: step 5938, loss = 0.72469 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:58:13.872092 ops/training.py:65 2019-01-16 09:58:13.872036: step 5939, loss = 0.72696 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:58:14.833195 ops/training.py:65 2019-01-16 09:58:14.833147: step 5940, loss = 0.69024 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:58:15.795034 ops/training.py:65 2019-01-16 09:58:15.794978: step 5941, loss = 0.66741 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:58:16.756438 ops/training.py:65 2019-01-16 09:58:16.756382: step 5942, loss = 0.67425 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:58:17.720534 ops/training.py:65 2019-01-16 09:58:17.720485: step 5943, loss = 0.67875 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:58:18.684557 ops/training.py:65 2019-01-16 09:58:18.684504: step 5944, loss = 0.74874 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:58:19.648107 ops/training.py:65 2019-01-16 09:58:19.648056: step 5945, loss = 0.71337 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:58:20.610026 ops/training.py:65 2019-01-16 09:58:20.609963: step 5946, loss = 0.72081 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:58:21.571123 ops/training.py:65 2019-01-16 09:58:21.571071: step 5947, loss = 0.69406 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:58:22.532633 ops/training.py:65 2019-01-16 09:58:22.532583: step 5948, loss = 0.68980 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:58:23.493108 ops/training.py:65 2019-01-16 09:58:23.493035: step 5949, loss = 0.69039 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:58:24.456591 ops/training.py:65 2019-01-16 09:58:24.456525: step 5950, loss = 0.66843 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:58:25.421168 ops/training.py:65 2019-01-16 09:58:25.421114: step 5951, loss = 0.72563 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:58:26.384703 ops/training.py:65 2019-01-16 09:58:26.384647: step 5952, loss = 0.72208 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:58:27.347094 ops/training.py:65 2019-01-16 09:58:27.347004: step 5953, loss = 0.69671 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:58:28.309551 ops/training.py:65 2019-01-16 09:58:28.309489: step 5954, loss = 0.68425 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:58:29.272546 ops/training.py:65 2019-01-16 09:58:29.272491: step 5955, loss = 0.73181 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:58:30.237287 ops/training.py:65 2019-01-16 09:58:30.237236: step 5956, loss = 0.78206 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 09:58:31.199884 ops/training.py:65 2019-01-16 09:58:31.199829: step 5957, loss = 0.71076 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:58:32.160558 ops/training.py:65 2019-01-16 09:58:32.160482: step 5958, loss = 0.65921 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:58:33.124703 ops/training.py:65 2019-01-16 09:58:33.124637: step 5959, loss = 0.71551 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:58:34.086212 ops/training.py:65 2019-01-16 09:58:34.086160: step 5960, loss = 0.67112 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:58:35.050918 ops/training.py:65 2019-01-16 09:58:35.050837: step 5961, loss = 0.78503 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:58:36.014963 ops/training.py:65 2019-01-16 09:58:36.014908: step 5962, loss = 0.71834 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:58:36.977584 ops/training.py:65 2019-01-16 09:58:36.977502: step 5963, loss = 0.69630 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:58:37.939921 ops/training.py:65 2019-01-16 09:58:37.939860: step 5964, loss = 0.71921 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:58:38.902550 ops/training.py:65 2019-01-16 09:58:38.902487: step 5965, loss = 0.73167 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:58:39.865941 ops/training.py:65 2019-01-16 09:58:39.865873: step 5966, loss = 0.69334 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:58:40.826895 ops/training.py:65 2019-01-16 09:58:40.826824: step 5967, loss = 0.76732 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:58:41.791469 ops/training.py:65 2019-01-16 09:58:41.791416: step 5968, loss = 0.71572 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:58:42.755066 ops/training.py:65 2019-01-16 09:58:42.754993: step 5969, loss = 0.74185 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:58:43.718009 ops/training.py:65 2019-01-16 09:58:43.717938: step 5970, loss = 0.73460 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:58:44.682357 ops/training.py:65 2019-01-16 09:58:44.682285: step 5971, loss = 0.66579 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:58:45.645175 ops/training.py:65 2019-01-16 09:58:45.645103: step 5972, loss = 0.75081 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:58:46.606739 ops/training.py:65 2019-01-16 09:58:46.606687: step 5973, loss = 0.69698 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:58:47.570791 ops/training.py:65 2019-01-16 09:58:47.570738: step 5974, loss = 0.75066 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:58:48.533706 ops/training.py:65 2019-01-16 09:58:48.533651: step 5975, loss = 0.69540 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:58:49.495530 ops/training.py:65 2019-01-16 09:58:49.495441: step 5976, loss = 0.68496 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:58:50.458110 ops/training.py:65 2019-01-16 09:58:50.458055: step 5977, loss = 0.65475 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 09:58:51.422664 ops/training.py:65 2019-01-16 09:58:51.422606: step 5978, loss = 0.68657 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:58:52.386414 ops/training.py:65 2019-01-16 09:58:52.386360: step 5979, loss = 0.68273 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 09:58:53.349884 ops/training.py:65 2019-01-16 09:58:53.349832: step 5980, loss = 0.71353 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 09:58:54.311872 ops/training.py:65 2019-01-16 09:58:54.311807: step 5981, loss = 0.71774 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:58:55.274147 ops/training.py:65 2019-01-16 09:58:55.274080: step 5982, loss = 0.68483 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:58:56.236377 ops/training.py:65 2019-01-16 09:58:56.236303: step 5983, loss = 0.67493 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:58:57.198738 ops/training.py:65 2019-01-16 09:58:57.198669: step 5984, loss = 0.70207 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 09:58:58.160262 ops/training.py:65 2019-01-16 09:58:58.160195: step 5985, loss = 0.71867 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:58:59.122054 ops/training.py:65 2019-01-16 09:58:59.122008: step 5986, loss = 0.66753 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:59:00.083230 ops/training.py:65 2019-01-16 09:59:00.083158: step 5987, loss = 0.69528 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:59:01.043840 ops/training.py:65 2019-01-16 09:59:01.043785: step 5988, loss = 0.70549 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:59:02.004028 ops/training.py:65 2019-01-16 09:59:02.003956: step 5989, loss = 0.73197 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 09:59:02.964026 ops/training.py:65 2019-01-16 09:59:02.963962: step 5990, loss = 0.65395 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 09:59:03.923576 ops/training.py:65 2019-01-16 09:59:03.923512: step 5991, loss = 0.70930 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 09:59:04.887636 ops/training.py:65 2019-01-16 09:59:04.887588: step 5992, loss = 0.68965 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 09:59:05.849752 ops/training.py:65 2019-01-16 09:59:05.849688: step 5993, loss = 0.65500 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 09:59:06.811678 ops/training.py:65 2019-01-16 09:59:06.811601: step 5994, loss = 0.66331 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 09:59:07.773843 ops/training.py:65 2019-01-16 09:59:07.773795: step 5995, loss = 0.69385 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 09:59:08.736690 ops/training.py:65 2019-01-16 09:59:08.736640: step 5996, loss = 0.75711 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.1875
I0832 2019-01-16 09:59:09.698207 ops/training.py:65 2019-01-16 09:59:09.698159: step 5997, loss = 0.67743 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:59:10.659768 ops/training.py:65 2019-01-16 09:59:10.659697: step 5998, loss = 0.68554 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 09:59:11.622961 ops/training.py:65 2019-01-16 09:59:11.622909: step 5999, loss = 0.70958 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:03:50.877519 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I0832 2019-01-16 10:03:50.878369 ops/training.py:41 2019-01-16 10:03:50.878321: step 6000, loss = 0.71 (0.1 examples/sec; 278.291 sec/batch) | Training accuracy = 0.5 | Validation accuracy = 0.5082 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_08_07_39_512188
I0832 2019-01-16 10:03:51.845314 ops/training.py:65 2019-01-16 10:03:51.845247: step 6001, loss = 0.73628 (33.1 examples/sec; 0.966 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:03:52.808499 ops/training.py:65 2019-01-16 10:03:52.808450: step 6002, loss = 0.71833 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:03:53.771615 ops/training.py:65 2019-01-16 10:03:53.771560: step 6003, loss = 0.71292 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:03:54.734492 ops/training.py:65 2019-01-16 10:03:54.734420: step 6004, loss = 0.67985 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:03:55.699007 ops/training.py:65 2019-01-16 10:03:55.698929: step 6005, loss = 0.66503 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:03:56.661884 ops/training.py:65 2019-01-16 10:03:56.661815: step 6006, loss = 0.68391 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:03:57.625750 ops/training.py:65 2019-01-16 10:03:57.625680: step 6007, loss = 0.73600 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:03:58.587916 ops/training.py:65 2019-01-16 10:03:58.587850: step 6008, loss = 0.69275 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:03:59.550800 ops/training.py:65 2019-01-16 10:03:59.550750: step 6009, loss = 0.68566 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:04:00.512647 ops/training.py:65 2019-01-16 10:04:00.512585: step 6010, loss = 0.68085 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:04:01.474716 ops/training.py:65 2019-01-16 10:04:01.474659: step 6011, loss = 0.71209 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:04:02.435207 ops/training.py:65 2019-01-16 10:04:02.435137: step 6012, loss = 0.70953 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:04:03.396671 ops/training.py:65 2019-01-16 10:04:03.396600: step 6013, loss = 0.65305 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:04:04.358569 ops/training.py:65 2019-01-16 10:04:04.358495: step 6014, loss = 0.75783 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:04:05.322379 ops/training.py:65 2019-01-16 10:04:05.322305: step 6015, loss = 0.69585 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:04:06.284180 ops/training.py:65 2019-01-16 10:04:06.284110: step 6016, loss = 0.68777 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:04:07.245833 ops/training.py:65 2019-01-16 10:04:07.245763: step 6017, loss = 0.66673 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:04:08.208215 ops/training.py:65 2019-01-16 10:04:08.208152: step 6018, loss = 0.66551 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:04:09.170709 ops/training.py:65 2019-01-16 10:04:09.170639: step 6019, loss = 0.68343 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:04:10.131577 ops/training.py:65 2019-01-16 10:04:10.131525: step 6020, loss = 0.68754 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:04:11.093248 ops/training.py:65 2019-01-16 10:04:11.093195: step 6021, loss = 0.68537 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:04:12.058971 ops/training.py:65 2019-01-16 10:04:12.058920: step 6022, loss = 0.69642 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:04:13.024098 ops/training.py:65 2019-01-16 10:04:13.024026: step 6023, loss = 0.62345 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:04:13.988955 ops/training.py:65 2019-01-16 10:04:13.988884: step 6024, loss = 0.68433 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:04:14.951271 ops/training.py:65 2019-01-16 10:04:14.951223: step 6025, loss = 0.67271 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:04:15.913608 ops/training.py:65 2019-01-16 10:04:15.913558: step 6026, loss = 0.72818 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:04:16.876748 ops/training.py:65 2019-01-16 10:04:16.876693: step 6027, loss = 0.67956 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:04:17.841233 ops/training.py:65 2019-01-16 10:04:17.841182: step 6028, loss = 0.70018 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:04:18.806161 ops/training.py:65 2019-01-16 10:04:18.806108: step 6029, loss = 0.79218 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:04:19.769809 ops/training.py:65 2019-01-16 10:04:19.769753: step 6030, loss = 0.67981 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:04:20.731500 ops/training.py:65 2019-01-16 10:04:20.731430: step 6031, loss = 0.70933 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:04:21.695672 ops/training.py:65 2019-01-16 10:04:21.695602: step 6032, loss = 0.70088 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:04:22.657644 ops/training.py:65 2019-01-16 10:04:22.657569: step 6033, loss = 0.72050 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:04:23.619534 ops/training.py:65 2019-01-16 10:04:23.619469: step 6034, loss = 0.73714 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:04:24.582176 ops/training.py:65 2019-01-16 10:04:24.582105: step 6035, loss = 0.68573 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:04:25.547339 ops/training.py:65 2019-01-16 10:04:25.547268: step 6036, loss = 0.76298 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:04:26.511289 ops/training.py:65 2019-01-16 10:04:26.511232: step 6037, loss = 0.69404 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:04:27.475317 ops/training.py:65 2019-01-16 10:04:27.475244: step 6038, loss = 0.71570 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:04:28.440325 ops/training.py:65 2019-01-16 10:04:28.440276: step 6039, loss = 0.68416 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:04:29.403625 ops/training.py:65 2019-01-16 10:04:29.403554: step 6040, loss = 0.67072 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:04:30.366620 ops/training.py:65 2019-01-16 10:04:30.366548: step 6041, loss = 0.71368 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:04:31.327837 ops/training.py:65 2019-01-16 10:04:31.327784: step 6042, loss = 0.70029 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:04:32.289112 ops/training.py:65 2019-01-16 10:04:32.289040: step 6043, loss = 0.73820 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:04:33.250785 ops/training.py:65 2019-01-16 10:04:33.250716: step 6044, loss = 0.70526 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:04:34.212895 ops/training.py:65 2019-01-16 10:04:34.212844: step 6045, loss = 0.72653 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:04:35.175311 ops/training.py:65 2019-01-16 10:04:35.175259: step 6046, loss = 0.69634 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:04:36.137185 ops/training.py:65 2019-01-16 10:04:36.137131: step 6047, loss = 0.70977 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:04:37.098496 ops/training.py:65 2019-01-16 10:04:37.098425: step 6048, loss = 0.70108 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:04:38.060551 ops/training.py:65 2019-01-16 10:04:38.060502: step 6049, loss = 0.71512 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:04:39.022842 ops/training.py:65 2019-01-16 10:04:39.022785: step 6050, loss = 0.68165 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:04:39.984172 ops/training.py:65 2019-01-16 10:04:39.984115: step 6051, loss = 0.67504 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:04:40.948973 ops/training.py:65 2019-01-16 10:04:40.948923: step 6052, loss = 0.70053 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:04:41.913196 ops/training.py:65 2019-01-16 10:04:41.913145: step 6053, loss = 0.68790 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:04:42.876184 ops/training.py:65 2019-01-16 10:04:42.876130: step 6054, loss = 0.67682 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:04:43.837662 ops/training.py:65 2019-01-16 10:04:43.837610: step 6055, loss = 0.71643 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:04:44.801894 ops/training.py:65 2019-01-16 10:04:44.801844: step 6056, loss = 0.68666 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:04:45.764901 ops/training.py:65 2019-01-16 10:04:45.764854: step 6057, loss = 0.68968 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:04:46.728592 ops/training.py:65 2019-01-16 10:04:46.728522: step 6058, loss = 0.67885 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:04:47.692314 ops/training.py:65 2019-01-16 10:04:47.692260: step 6059, loss = 0.67206 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:04:48.657238 ops/training.py:65 2019-01-16 10:04:48.657188: step 6060, loss = 0.67524 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:04:49.621594 ops/training.py:65 2019-01-16 10:04:49.621525: step 6061, loss = 0.66491 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:04:50.585433 ops/training.py:65 2019-01-16 10:04:50.585366: step 6062, loss = 0.70890 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:04:51.547777 ops/training.py:65 2019-01-16 10:04:51.547726: step 6063, loss = 0.72084 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:04:52.509664 ops/training.py:65 2019-01-16 10:04:52.509606: step 6064, loss = 0.70994 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:04:53.470873 ops/training.py:65 2019-01-16 10:04:53.470802: step 6065, loss = 0.67648 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:04:54.432703 ops/training.py:65 2019-01-16 10:04:54.432652: step 6066, loss = 0.70870 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:04:55.394734 ops/training.py:65 2019-01-16 10:04:55.394680: step 6067, loss = 0.72286 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:04:56.356564 ops/training.py:65 2019-01-16 10:04:56.356507: step 6068, loss = 0.71266 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:04:57.318589 ops/training.py:65 2019-01-16 10:04:57.318537: step 6069, loss = 0.70137 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:04:58.279982 ops/training.py:65 2019-01-16 10:04:58.279919: step 6070, loss = 0.75153 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:04:59.240867 ops/training.py:65 2019-01-16 10:04:59.240784: step 6071, loss = 0.70733 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:05:00.204295 ops/training.py:65 2019-01-16 10:05:00.204223: step 6072, loss = 0.74595 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 10:05:01.167664 ops/training.py:65 2019-01-16 10:05:01.167612: step 6073, loss = 0.66679 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:05:02.128678 ops/training.py:65 2019-01-16 10:05:02.128610: step 6074, loss = 0.68326 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:05:03.089207 ops/training.py:65 2019-01-16 10:05:03.089139: step 6075, loss = 0.69199 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:05:04.050432 ops/training.py:65 2019-01-16 10:05:04.050360: step 6076, loss = 0.72829 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:05:05.011054 ops/training.py:65 2019-01-16 10:05:05.010986: step 6077, loss = 0.70677 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:05:05.973014 ops/training.py:65 2019-01-16 10:05:05.972946: step 6078, loss = 0.67953 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:05:06.934075 ops/training.py:65 2019-01-16 10:05:06.934021: step 6079, loss = 0.71216 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:05:07.898245 ops/training.py:65 2019-01-16 10:05:07.898192: step 6080, loss = 0.67014 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:05:08.861304 ops/training.py:65 2019-01-16 10:05:08.861248: step 6081, loss = 0.73725 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:05:09.825004 ops/training.py:65 2019-01-16 10:05:09.824955: step 6082, loss = 0.71112 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:05:10.786568 ops/training.py:65 2019-01-16 10:05:10.786515: step 6083, loss = 0.67276 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:05:11.748144 ops/training.py:65 2019-01-16 10:05:11.748087: step 6084, loss = 0.75111 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:05:12.711496 ops/training.py:65 2019-01-16 10:05:12.711446: step 6085, loss = 0.73777 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:05:13.672985 ops/training.py:65 2019-01-16 10:05:13.672928: step 6086, loss = 0.69283 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:05:14.635943 ops/training.py:65 2019-01-16 10:05:14.635880: step 6087, loss = 0.73701 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:05:15.600261 ops/training.py:65 2019-01-16 10:05:15.600189: step 6088, loss = 0.72048 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:05:16.562764 ops/training.py:65 2019-01-16 10:05:16.562695: step 6089, loss = 0.71578 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:05:17.525372 ops/training.py:65 2019-01-16 10:05:17.525306: step 6090, loss = 0.66695 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:05:18.486271 ops/training.py:65 2019-01-16 10:05:18.486208: step 6091, loss = 0.68261 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:05:19.447089 ops/training.py:65 2019-01-16 10:05:19.447020: step 6092, loss = 0.76814 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:05:20.409292 ops/training.py:65 2019-01-16 10:05:20.409220: step 6093, loss = 0.65309 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:05:21.371867 ops/training.py:65 2019-01-16 10:05:21.371813: step 6094, loss = 0.70991 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:05:22.332875 ops/training.py:65 2019-01-16 10:05:22.332803: step 6095, loss = 0.63008 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:05:23.294061 ops/training.py:65 2019-01-16 10:05:23.293992: step 6096, loss = 0.64243 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:05:24.256177 ops/training.py:65 2019-01-16 10:05:24.256121: step 6097, loss = 0.70921 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:05:25.217674 ops/training.py:65 2019-01-16 10:05:25.217627: step 6098, loss = 0.74094 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:05:26.180645 ops/training.py:65 2019-01-16 10:05:26.180593: step 6099, loss = 0.68756 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:05:27.143922 ops/training.py:65 2019-01-16 10:05:27.143870: step 6100, loss = 0.64956 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:05:28.109553 ops/training.py:65 2019-01-16 10:05:28.109504: step 6101, loss = 0.70467 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:05:29.072473 ops/training.py:65 2019-01-16 10:05:29.072403: step 6102, loss = 0.67758 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:05:30.036984 ops/training.py:65 2019-01-16 10:05:30.036912: step 6103, loss = 0.67819 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:05:31.000505 ops/training.py:65 2019-01-16 10:05:31.000433: step 6104, loss = 0.69437 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:05:31.962643 ops/training.py:65 2019-01-16 10:05:31.962571: step 6105, loss = 0.67762 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:05:32.926311 ops/training.py:65 2019-01-16 10:05:32.926242: step 6106, loss = 0.72638 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:05:33.889332 ops/training.py:65 2019-01-16 10:05:33.889263: step 6107, loss = 0.68174 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:05:34.852066 ops/training.py:65 2019-01-16 10:05:34.851997: step 6108, loss = 0.72929 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:05:35.812964 ops/training.py:65 2019-01-16 10:05:35.812910: step 6109, loss = 0.70418 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:05:36.774407 ops/training.py:65 2019-01-16 10:05:36.774350: step 6110, loss = 0.66955 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:05:37.734839 ops/training.py:65 2019-01-16 10:05:37.734785: step 6111, loss = 0.68337 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:05:38.695472 ops/training.py:65 2019-01-16 10:05:38.695419: step 6112, loss = 0.73703 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:05:39.657031 ops/training.py:65 2019-01-16 10:05:39.656979: step 6113, loss = 0.67731 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:05:40.617644 ops/training.py:65 2019-01-16 10:05:40.617590: step 6114, loss = 0.69511 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:05:41.581292 ops/training.py:65 2019-01-16 10:05:41.581244: step 6115, loss = 0.70385 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:05:42.543757 ops/training.py:65 2019-01-16 10:05:42.543685: step 6116, loss = 0.67415 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:05:43.505768 ops/training.py:65 2019-01-16 10:05:43.505695: step 6117, loss = 0.66329 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:05:44.467736 ops/training.py:65 2019-01-16 10:05:44.467666: step 6118, loss = 0.62258 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:05:45.429521 ops/training.py:65 2019-01-16 10:05:45.429451: step 6119, loss = 0.73075 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:05:46.390433 ops/training.py:65 2019-01-16 10:05:46.390363: step 6120, loss = 0.70479 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:05:47.350117 ops/training.py:65 2019-01-16 10:05:47.350030: step 6121, loss = 0.69522 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:05:48.310709 ops/training.py:65 2019-01-16 10:05:48.310647: step 6122, loss = 0.72434 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:05:49.270636 ops/training.py:65 2019-01-16 10:05:49.270565: step 6123, loss = 0.68631 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:05:50.234142 ops/training.py:65 2019-01-16 10:05:50.234075: step 6124, loss = 0.70671 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:05:51.195739 ops/training.py:65 2019-01-16 10:05:51.195687: step 6125, loss = 0.70929 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:05:52.157430 ops/training.py:65 2019-01-16 10:05:52.157379: step 6126, loss = 0.65272 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:05:53.119159 ops/training.py:65 2019-01-16 10:05:53.119105: step 6127, loss = 0.69804 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:05:54.080436 ops/training.py:65 2019-01-16 10:05:54.080385: step 6128, loss = 0.71683 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:05:55.041011 ops/training.py:65 2019-01-16 10:05:55.040957: step 6129, loss = 0.74894 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:05:56.001608 ops/training.py:65 2019-01-16 10:05:56.001558: step 6130, loss = 0.69103 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:05:56.962691 ops/training.py:65 2019-01-16 10:05:56.962637: step 6131, loss = 0.71230 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:05:57.924087 ops/training.py:65 2019-01-16 10:05:57.924029: step 6132, loss = 0.71811 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:05:58.885968 ops/training.py:65 2019-01-16 10:05:58.885901: step 6133, loss = 0.69842 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:05:59.847876 ops/training.py:65 2019-01-16 10:05:59.847808: step 6134, loss = 0.70093 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:06:00.809347 ops/training.py:65 2019-01-16 10:06:00.809271: step 6135, loss = 0.68880 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:06:01.770510 ops/training.py:65 2019-01-16 10:06:01.770439: step 6136, loss = 0.67974 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:06:02.732008 ops/training.py:65 2019-01-16 10:06:02.731936: step 6137, loss = 0.71310 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:06:03.695192 ops/training.py:65 2019-01-16 10:06:03.695142: step 6138, loss = 0.71060 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:06:04.660847 ops/training.py:65 2019-01-16 10:06:04.660795: step 6139, loss = 0.67542 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:06:05.624280 ops/training.py:65 2019-01-16 10:06:05.624209: step 6140, loss = 0.67048 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:06:06.587017 ops/training.py:65 2019-01-16 10:06:06.586944: step 6141, loss = 0.69428 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:06:07.548835 ops/training.py:65 2019-01-16 10:06:07.548783: step 6142, loss = 0.68525 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:06:08.511259 ops/training.py:65 2019-01-16 10:06:08.511210: step 6143, loss = 0.67633 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:06:09.472935 ops/training.py:65 2019-01-16 10:06:09.472878: step 6144, loss = 0.70977 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:06:10.438783 ops/training.py:65 2019-01-16 10:06:10.438712: step 6145, loss = 0.72845 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:06:11.402611 ops/training.py:65 2019-01-16 10:06:11.402539: step 6146, loss = 0.66332 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:06:12.366180 ops/training.py:65 2019-01-16 10:06:12.366108: step 6147, loss = 0.70785 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:06:13.328558 ops/training.py:65 2019-01-16 10:06:13.328484: step 6148, loss = 0.71558 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:06:14.291337 ops/training.py:65 2019-01-16 10:06:14.291264: step 6149, loss = 0.71058 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:06:15.252386 ops/training.py:65 2019-01-16 10:06:15.252317: step 6150, loss = 0.67754 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:06:16.213816 ops/training.py:65 2019-01-16 10:06:16.213744: step 6151, loss = 0.70290 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:06:17.178202 ops/training.py:65 2019-01-16 10:06:17.178153: step 6152, loss = 0.67752 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:06:18.140980 ops/training.py:65 2019-01-16 10:06:18.140924: step 6153, loss = 0.67470 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:06:19.102784 ops/training.py:65 2019-01-16 10:06:19.102706: step 6154, loss = 0.69833 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:06:20.063702 ops/training.py:65 2019-01-16 10:06:20.063637: step 6155, loss = 0.66795 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:06:21.026700 ops/training.py:65 2019-01-16 10:06:21.026653: step 6156, loss = 0.71738 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:06:21.991003 ops/training.py:65 2019-01-16 10:06:21.990951: step 6157, loss = 0.71266 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:06:22.953613 ops/training.py:65 2019-01-16 10:06:22.953563: step 6158, loss = 0.72426 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:06:23.916363 ops/training.py:65 2019-01-16 10:06:23.916310: step 6159, loss = 0.67453 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:06:24.877737 ops/training.py:65 2019-01-16 10:06:24.877682: step 6160, loss = 0.68609 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:06:25.838794 ops/training.py:65 2019-01-16 10:06:25.838742: step 6161, loss = 0.72254 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:06:26.800378 ops/training.py:65 2019-01-16 10:06:26.800308: step 6162, loss = 0.70363 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:06:27.764317 ops/training.py:65 2019-01-16 10:06:27.764246: step 6163, loss = 0.71437 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:06:28.726997 ops/training.py:65 2019-01-16 10:06:28.726935: step 6164, loss = 0.67426 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:06:29.689748 ops/training.py:65 2019-01-16 10:06:29.689695: step 6165, loss = 0.68744 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:06:30.651165 ops/training.py:65 2019-01-16 10:06:30.651091: step 6166, loss = 0.69173 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:06:31.612274 ops/training.py:65 2019-01-16 10:06:31.612220: step 6167, loss = 0.71066 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:06:32.572233 ops/training.py:65 2019-01-16 10:06:32.572166: step 6168, loss = 0.69383 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:06:33.536830 ops/training.py:65 2019-01-16 10:06:33.536759: step 6169, loss = 0.70330 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:06:34.499453 ops/training.py:65 2019-01-16 10:06:34.499380: step 6170, loss = 0.69875 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:06:35.459675 ops/training.py:65 2019-01-16 10:06:35.459630: step 6171, loss = 0.69317 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:06:36.419931 ops/training.py:65 2019-01-16 10:06:36.419862: step 6172, loss = 0.71641 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:06:37.382329 ops/training.py:65 2019-01-16 10:06:37.382268: step 6173, loss = 0.67290 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:06:38.344694 ops/training.py:65 2019-01-16 10:06:38.344631: step 6174, loss = 0.71726 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:06:39.306775 ops/training.py:65 2019-01-16 10:06:39.306727: step 6175, loss = 0.70492 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:06:40.267876 ops/training.py:65 2019-01-16 10:06:40.267821: step 6176, loss = 0.69483 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:06:41.230015 ops/training.py:65 2019-01-16 10:06:41.229958: step 6177, loss = 0.66941 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:06:42.194034 ops/training.py:65 2019-01-16 10:06:42.193962: step 6178, loss = 0.71551 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:06:43.155311 ops/training.py:65 2019-01-16 10:06:43.155243: step 6179, loss = 0.69422 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:06:44.120353 ops/training.py:65 2019-01-16 10:06:44.120283: step 6180, loss = 0.67530 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:06:45.084075 ops/training.py:65 2019-01-16 10:06:45.084030: step 6181, loss = 0.69919 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:06:46.046265 ops/training.py:65 2019-01-16 10:06:46.046215: step 6182, loss = 0.67568 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:06:47.006992 ops/training.py:65 2019-01-16 10:06:47.006937: step 6183, loss = 0.66664 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:06:47.967990 ops/training.py:65 2019-01-16 10:06:47.967939: step 6184, loss = 0.68058 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:06:48.929425 ops/training.py:65 2019-01-16 10:06:48.929369: step 6185, loss = 0.71782 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:06:50.001701 ops/training.py:65 2019-01-16 10:06:50.001644: step 6186, loss = 0.70461 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:06:50.962348 ops/training.py:65 2019-01-16 10:06:50.962288: step 6187, loss = 0.68631 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:06:51.922421 ops/training.py:65 2019-01-16 10:06:51.922368: step 6188, loss = 0.69158 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:06:52.881847 ops/training.py:65 2019-01-16 10:06:52.881776: step 6189, loss = 0.67102 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:06:53.842344 ops/training.py:65 2019-01-16 10:06:53.842273: step 6190, loss = 0.67942 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:06:54.802564 ops/training.py:65 2019-01-16 10:06:54.802498: step 6191, loss = 0.67497 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:06:55.764304 ops/training.py:65 2019-01-16 10:06:55.764237: step 6192, loss = 0.67930 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:06:56.724774 ops/training.py:65 2019-01-16 10:06:56.724704: step 6193, loss = 0.69717 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:06:57.686945 ops/training.py:65 2019-01-16 10:06:57.686899: step 6194, loss = 0.71476 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:06:58.649104 ops/training.py:65 2019-01-16 10:06:58.649053: step 6195, loss = 0.73862 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:06:59.614556 ops/training.py:65 2019-01-16 10:06:59.614506: step 6196, loss = 0.70974 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:07:00.576287 ops/training.py:65 2019-01-16 10:07:00.576231: step 6197, loss = 0.72897 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:07:01.538881 ops/training.py:65 2019-01-16 10:07:01.538810: step 6198, loss = 0.74349 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:07:02.501545 ops/training.py:65 2019-01-16 10:07:02.501471: step 6199, loss = 0.70602 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:07:03.466316 ops/training.py:65 2019-01-16 10:07:03.466263: step 6200, loss = 0.68817 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:07:04.429555 ops/training.py:65 2019-01-16 10:07:04.429506: step 6201, loss = 0.75820 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 10:07:05.391629 ops/training.py:65 2019-01-16 10:07:05.391560: step 6202, loss = 0.69826 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:07:06.353394 ops/training.py:65 2019-01-16 10:07:06.353319: step 6203, loss = 0.68994 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:07:07.316010 ops/training.py:65 2019-01-16 10:07:07.315940: step 6204, loss = 0.68760 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:07:08.277474 ops/training.py:65 2019-01-16 10:07:08.277408: step 6205, loss = 0.67607 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:07:09.239656 ops/training.py:65 2019-01-16 10:07:09.239581: step 6206, loss = 0.63886 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:07:10.204672 ops/training.py:65 2019-01-16 10:07:10.204614: step 6207, loss = 0.72445 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:07:11.167703 ops/training.py:65 2019-01-16 10:07:11.167649: step 6208, loss = 0.67801 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:07:12.131647 ops/training.py:65 2019-01-16 10:07:12.131591: step 6209, loss = 0.73575 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:07:13.097237 ops/training.py:65 2019-01-16 10:07:13.097184: step 6210, loss = 0.74017 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:07:14.061890 ops/training.py:65 2019-01-16 10:07:14.061840: step 6211, loss = 0.68612 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:07:15.023825 ops/training.py:65 2019-01-16 10:07:15.023773: step 6212, loss = 0.69808 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:07:15.985077 ops/training.py:65 2019-01-16 10:07:15.985020: step 6213, loss = 0.68624 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:07:16.946666 ops/training.py:65 2019-01-16 10:07:16.946613: step 6214, loss = 0.68750 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:07:17.908184 ops/training.py:65 2019-01-16 10:07:17.908130: step 6215, loss = 0.68983 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:07:18.870191 ops/training.py:65 2019-01-16 10:07:18.870138: step 6216, loss = 0.71908 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:07:19.832999 ops/training.py:65 2019-01-16 10:07:19.832951: step 6217, loss = 0.67680 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:07:20.794258 ops/training.py:65 2019-01-16 10:07:20.794205: step 6218, loss = 0.70070 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:07:21.755437 ops/training.py:65 2019-01-16 10:07:21.755383: step 6219, loss = 0.67579 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:07:22.716201 ops/training.py:65 2019-01-16 10:07:22.716144: step 6220, loss = 0.70898 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:07:23.677829 ops/training.py:65 2019-01-16 10:07:23.677777: step 6221, loss = 0.69549 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:07:24.639323 ops/training.py:65 2019-01-16 10:07:24.639271: step 6222, loss = 0.67038 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:07:25.604367 ops/training.py:65 2019-01-16 10:07:25.604314: step 6223, loss = 0.69993 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:07:26.568475 ops/training.py:65 2019-01-16 10:07:26.568426: step 6224, loss = 0.71092 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:07:27.531132 ops/training.py:65 2019-01-16 10:07:27.531083: step 6225, loss = 0.74458 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:07:28.491933 ops/training.py:65 2019-01-16 10:07:28.491879: step 6226, loss = 0.69309 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:07:29.452938 ops/training.py:65 2019-01-16 10:07:29.452870: step 6227, loss = 0.70313 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:07:30.415199 ops/training.py:65 2019-01-16 10:07:30.415132: step 6228, loss = 0.72412 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:07:31.379708 ops/training.py:65 2019-01-16 10:07:31.379652: step 6229, loss = 0.69910 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:07:32.341848 ops/training.py:65 2019-01-16 10:07:32.341779: step 6230, loss = 0.67103 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:07:33.302526 ops/training.py:65 2019-01-16 10:07:33.302476: step 6231, loss = 0.71141 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:07:34.263906 ops/training.py:65 2019-01-16 10:07:34.263841: step 6232, loss = 0.72597 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:07:35.224227 ops/training.py:65 2019-01-16 10:07:35.224165: step 6233, loss = 0.69500 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:07:36.184247 ops/training.py:65 2019-01-16 10:07:36.184206: step 6234, loss = 0.68891 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:07:37.145166 ops/training.py:65 2019-01-16 10:07:37.145106: step 6235, loss = 0.68739 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:07:38.106125 ops/training.py:65 2019-01-16 10:07:38.106077: step 6236, loss = 0.69791 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:07:39.066745 ops/training.py:65 2019-01-16 10:07:39.066683: step 6237, loss = 0.70780 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:07:40.030983 ops/training.py:65 2019-01-16 10:07:40.030924: step 6238, loss = 0.67684 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:07:40.995146 ops/training.py:65 2019-01-16 10:07:40.995083: step 6239, loss = 0.70469 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:07:41.956358 ops/training.py:65 2019-01-16 10:07:41.956283: step 6240, loss = 0.70757 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:07:42.916641 ops/training.py:65 2019-01-16 10:07:42.916570: step 6241, loss = 0.67736 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:07:43.876676 ops/training.py:65 2019-01-16 10:07:43.876607: step 6242, loss = 0.71386 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:07:44.835024 ops/training.py:65 2019-01-16 10:07:44.834955: step 6243, loss = 0.66353 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:07:45.793938 ops/training.py:65 2019-01-16 10:07:45.793890: step 6244, loss = 0.67803 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:07:46.757305 ops/training.py:65 2019-01-16 10:07:46.757251: step 6245, loss = 0.71870 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:07:47.720646 ops/training.py:65 2019-01-16 10:07:47.720592: step 6246, loss = 0.69284 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:07:48.683960 ops/training.py:65 2019-01-16 10:07:48.683907: step 6247, loss = 0.66049 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:07:49.647829 ops/training.py:65 2019-01-16 10:07:49.647742: step 6248, loss = 0.69528 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:07:50.614243 ops/training.py:65 2019-01-16 10:07:50.614183: step 6249, loss = 0.68185 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:07:51.579684 ops/training.py:65 2019-01-16 10:07:51.579610: step 6250, loss = 0.66970 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:07:52.544084 ops/training.py:65 2019-01-16 10:07:52.544009: step 6251, loss = 0.67272 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:07:53.506549 ops/training.py:65 2019-01-16 10:07:53.506471: step 6252, loss = 0.77334 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:07:54.469579 ops/training.py:65 2019-01-16 10:07:54.469508: step 6253, loss = 0.68007 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:07:55.429925 ops/training.py:65 2019-01-16 10:07:55.429856: step 6254, loss = 0.71043 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:07:56.394077 ops/training.py:65 2019-01-16 10:07:56.394011: step 6255, loss = 0.69822 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:07:57.355767 ops/training.py:65 2019-01-16 10:07:57.355698: step 6256, loss = 0.71263 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:07:58.317298 ops/training.py:65 2019-01-16 10:07:58.317227: step 6257, loss = 0.66672 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:07:59.277941 ops/training.py:65 2019-01-16 10:07:59.277875: step 6258, loss = 0.71577 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:08:00.236940 ops/training.py:65 2019-01-16 10:08:00.236854: step 6259, loss = 0.74131 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:08:01.196926 ops/training.py:65 2019-01-16 10:08:01.196870: step 6260, loss = 0.68403 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:08:02.159527 ops/training.py:65 2019-01-16 10:08:02.159456: step 6261, loss = 0.68153 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:08:03.122979 ops/training.py:65 2019-01-16 10:08:03.122925: step 6262, loss = 0.70395 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:08:04.086977 ops/training.py:65 2019-01-16 10:08:04.086912: step 6263, loss = 0.64512 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:08:05.047609 ops/training.py:65 2019-01-16 10:08:05.047553: step 6264, loss = 0.70372 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:08:06.008829 ops/training.py:65 2019-01-16 10:08:06.008737: step 6265, loss = 0.69812 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:08:06.973831 ops/training.py:65 2019-01-16 10:08:06.973759: step 6266, loss = 0.70974 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:08:07.937552 ops/training.py:65 2019-01-16 10:08:07.937504: step 6267, loss = 0.68040 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:08:08.897677 ops/training.py:65 2019-01-16 10:08:08.897602: step 6268, loss = 0.68703 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:08:09.859324 ops/training.py:65 2019-01-16 10:08:09.859267: step 6269, loss = 0.68349 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:08:10.821323 ops/training.py:65 2019-01-16 10:08:10.821269: step 6270, loss = 0.69908 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:08:11.783537 ops/training.py:65 2019-01-16 10:08:11.783485: step 6271, loss = 0.68276 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:08:12.747891 ops/training.py:65 2019-01-16 10:08:12.747839: step 6272, loss = 0.69818 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:08:13.709165 ops/training.py:65 2019-01-16 10:08:13.709109: step 6273, loss = 0.66399 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:08:14.670912 ops/training.py:65 2019-01-16 10:08:14.670861: step 6274, loss = 0.68221 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:08:15.633070 ops/training.py:65 2019-01-16 10:08:15.633011: step 6275, loss = 0.69376 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:08:16.595867 ops/training.py:65 2019-01-16 10:08:16.595814: step 6276, loss = 0.67342 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:08:17.558313 ops/training.py:65 2019-01-16 10:08:17.558262: step 6277, loss = 0.69352 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:08:18.523646 ops/training.py:65 2019-01-16 10:08:18.523592: step 6278, loss = 0.69304 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:08:19.486282 ops/training.py:65 2019-01-16 10:08:19.486229: step 6279, loss = 0.66829 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:08:20.447685 ops/training.py:65 2019-01-16 10:08:20.447639: step 6280, loss = 0.67415 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:08:21.408893 ops/training.py:65 2019-01-16 10:08:21.408840: step 6281, loss = 0.65144 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:08:22.369884 ops/training.py:65 2019-01-16 10:08:22.369830: step 6282, loss = 0.68640 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:08:23.332322 ops/training.py:65 2019-01-16 10:08:23.332267: step 6283, loss = 0.68292 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:08:24.296565 ops/training.py:65 2019-01-16 10:08:24.296517: step 6284, loss = 0.66702 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:08:25.259143 ops/training.py:65 2019-01-16 10:08:25.259096: step 6285, loss = 0.68263 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:08:26.222055 ops/training.py:65 2019-01-16 10:08:26.221984: step 6286, loss = 0.66817 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:08:27.185221 ops/training.py:65 2019-01-16 10:08:27.185170: step 6287, loss = 0.68985 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:08:28.148622 ops/training.py:65 2019-01-16 10:08:28.148569: step 6288, loss = 0.68400 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:08:29.109698 ops/training.py:65 2019-01-16 10:08:29.109641: step 6289, loss = 0.67101 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:08:30.073758 ops/training.py:65 2019-01-16 10:08:30.073710: step 6290, loss = 0.70711 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:08:31.036432 ops/training.py:65 2019-01-16 10:08:31.036380: step 6291, loss = 0.69710 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:08:31.999838 ops/training.py:65 2019-01-16 10:08:31.999764: step 6292, loss = 0.68788 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:08:32.962258 ops/training.py:65 2019-01-16 10:08:32.962185: step 6293, loss = 0.70084 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:08:33.924946 ops/training.py:65 2019-01-16 10:08:33.924895: step 6294, loss = 0.64765 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:08:34.886368 ops/training.py:65 2019-01-16 10:08:34.886293: step 6295, loss = 0.70114 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:08:35.850225 ops/training.py:65 2019-01-16 10:08:35.850159: step 6296, loss = 0.68658 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:08:36.813258 ops/training.py:65 2019-01-16 10:08:36.813208: step 6297, loss = 0.70878 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:08:37.775757 ops/training.py:65 2019-01-16 10:08:37.775690: step 6298, loss = 0.69045 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:08:38.737278 ops/training.py:65 2019-01-16 10:08:38.737221: step 6299, loss = 0.70113 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:08:39.698897 ops/training.py:65 2019-01-16 10:08:39.698854: step 6300, loss = 0.67560 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:08:40.661235 ops/training.py:65 2019-01-16 10:08:40.661177: step 6301, loss = 0.70642 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:08:41.626028 ops/training.py:65 2019-01-16 10:08:41.625970: step 6302, loss = 0.69426 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:08:42.589099 ops/training.py:65 2019-01-16 10:08:42.589043: step 6303, loss = 0.67992 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:08:43.552037 ops/training.py:65 2019-01-16 10:08:43.551996: step 6304, loss = 0.69216 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:08:44.513442 ops/training.py:65 2019-01-16 10:08:44.513384: step 6305, loss = 0.68492 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:08:45.475184 ops/training.py:65 2019-01-16 10:08:45.475119: step 6306, loss = 0.67305 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:08:46.436047 ops/training.py:65 2019-01-16 10:08:46.435989: step 6307, loss = 0.68057 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:08:47.398320 ops/training.py:65 2019-01-16 10:08:47.398269: step 6308, loss = 0.68465 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:08:48.362814 ops/training.py:65 2019-01-16 10:08:48.362769: step 6309, loss = 0.69603 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:08:49.326891 ops/training.py:65 2019-01-16 10:08:49.326841: step 6310, loss = 0.66393 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:08:50.289182 ops/training.py:65 2019-01-16 10:08:50.289134: step 6311, loss = 0.70160 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:08:51.250228 ops/training.py:65 2019-01-16 10:08:51.250180: step 6312, loss = 0.70379 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:08:52.209858 ops/training.py:65 2019-01-16 10:08:52.209807: step 6313, loss = 0.66368 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:08:53.174210 ops/training.py:65 2019-01-16 10:08:53.174150: step 6314, loss = 0.72852 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:08:54.135699 ops/training.py:65 2019-01-16 10:08:54.135639: step 6315, loss = 0.70585 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:08:55.098888 ops/training.py:65 2019-01-16 10:08:55.098827: step 6316, loss = 0.70146 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:08:56.059733 ops/training.py:65 2019-01-16 10:08:56.059686: step 6317, loss = 0.72405 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:08:57.021012 ops/training.py:65 2019-01-16 10:08:57.020960: step 6318, loss = 0.72500 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:08:57.984683 ops/training.py:65 2019-01-16 10:08:57.984636: step 6319, loss = 0.68374 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:08:58.947723 ops/training.py:65 2019-01-16 10:08:58.947674: step 6320, loss = 0.68213 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:08:59.910581 ops/training.py:65 2019-01-16 10:08:59.910525: step 6321, loss = 0.69777 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:09:00.873201 ops/training.py:65 2019-01-16 10:09:00.873141: step 6322, loss = 0.71886 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:09:01.837122 ops/training.py:65 2019-01-16 10:09:01.837063: step 6323, loss = 0.70009 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:09:02.800459 ops/training.py:65 2019-01-16 10:09:02.800391: step 6324, loss = 0.71236 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:09:03.761844 ops/training.py:65 2019-01-16 10:09:03.761780: step 6325, loss = 0.70864 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:09:04.723536 ops/training.py:65 2019-01-16 10:09:04.723466: step 6326, loss = 0.63923 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 10:09:05.684538 ops/training.py:65 2019-01-16 10:09:05.684486: step 6327, loss = 0.69897 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:09:06.645868 ops/training.py:65 2019-01-16 10:09:06.645800: step 6328, loss = 0.69028 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:09:07.607834 ops/training.py:65 2019-01-16 10:09:07.607767: step 6329, loss = 0.72837 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:09:08.567410 ops/training.py:65 2019-01-16 10:09:08.567343: step 6330, loss = 0.72401 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:09:09.525879 ops/training.py:65 2019-01-16 10:09:09.525809: step 6331, loss = 0.68957 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:09:10.485727 ops/training.py:65 2019-01-16 10:09:10.485658: step 6332, loss = 0.74255 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:09:11.445467 ops/training.py:65 2019-01-16 10:09:11.445400: step 6333, loss = 0.70963 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:09:12.405344 ops/training.py:65 2019-01-16 10:09:12.405274: step 6334, loss = 0.74673 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:09:13.366483 ops/training.py:65 2019-01-16 10:09:13.366416: step 6335, loss = 0.72807 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:09:14.325665 ops/training.py:65 2019-01-16 10:09:14.325611: step 6336, loss = 0.70256 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:09:15.287189 ops/training.py:65 2019-01-16 10:09:15.287136: step 6337, loss = 0.71116 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:09:16.248666 ops/training.py:65 2019-01-16 10:09:16.248614: step 6338, loss = 0.68787 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:09:17.214053 ops/training.py:65 2019-01-16 10:09:17.213989: step 6339, loss = 0.68988 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:09:18.176156 ops/training.py:65 2019-01-16 10:09:18.176105: step 6340, loss = 0.69360 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:09:19.137413 ops/training.py:65 2019-01-16 10:09:19.137360: step 6341, loss = 0.66341 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:09:20.099928 ops/training.py:65 2019-01-16 10:09:20.099872: step 6342, loss = 0.69408 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:09:21.063245 ops/training.py:65 2019-01-16 10:09:21.063199: step 6343, loss = 0.68365 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:09:22.027386 ops/training.py:65 2019-01-16 10:09:22.027338: step 6344, loss = 0.66759 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:09:22.990935 ops/training.py:65 2019-01-16 10:09:22.990880: step 6345, loss = 0.72737 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:09:23.953159 ops/training.py:65 2019-01-16 10:09:23.953102: step 6346, loss = 0.69113 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:09:24.913667 ops/training.py:65 2019-01-16 10:09:24.913612: step 6347, loss = 0.68649 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:09:25.876002 ops/training.py:65 2019-01-16 10:09:25.875949: step 6348, loss = 0.74253 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:09:26.840764 ops/training.py:65 2019-01-16 10:09:26.840710: step 6349, loss = 0.71879 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:09:27.804006 ops/training.py:65 2019-01-16 10:09:27.803956: step 6350, loss = 0.69732 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:09:28.766413 ops/training.py:65 2019-01-16 10:09:28.766355: step 6351, loss = 0.70324 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:09:29.726931 ops/training.py:65 2019-01-16 10:09:29.726879: step 6352, loss = 0.73919 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:09:30.687664 ops/training.py:65 2019-01-16 10:09:30.687618: step 6353, loss = 0.67896 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:09:31.649463 ops/training.py:65 2019-01-16 10:09:31.649410: step 6354, loss = 0.69884 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:09:32.610923 ops/training.py:65 2019-01-16 10:09:32.610847: step 6355, loss = 0.72362 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:09:33.575502 ops/training.py:65 2019-01-16 10:09:33.575449: step 6356, loss = 0.65803 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:09:34.539140 ops/training.py:65 2019-01-16 10:09:34.539089: step 6357, loss = 0.71152 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:09:35.500023 ops/training.py:65 2019-01-16 10:09:35.499960: step 6358, loss = 0.68894 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:09:36.461624 ops/training.py:65 2019-01-16 10:09:36.461552: step 6359, loss = 0.70626 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:09:37.422795 ops/training.py:65 2019-01-16 10:09:37.422727: step 6360, loss = 0.70574 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:09:38.388214 ops/training.py:65 2019-01-16 10:09:38.388141: step 6361, loss = 0.70166 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:09:39.349588 ops/training.py:65 2019-01-16 10:09:39.349513: step 6362, loss = 0.68684 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:09:40.311971 ops/training.py:65 2019-01-16 10:09:40.311922: step 6363, loss = 0.68440 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:09:41.275982 ops/training.py:65 2019-01-16 10:09:41.275929: step 6364, loss = 0.70377 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:09:42.237619 ops/training.py:65 2019-01-16 10:09:42.237564: step 6365, loss = 0.70166 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:09:43.202283 ops/training.py:65 2019-01-16 10:09:43.202233: step 6366, loss = 0.70520 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:09:44.164801 ops/training.py:65 2019-01-16 10:09:44.164751: step 6367, loss = 0.69346 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:09:45.126658 ops/training.py:65 2019-01-16 10:09:45.126602: step 6368, loss = 0.73460 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:09:46.090793 ops/training.py:65 2019-01-16 10:09:46.090734: step 6369, loss = 0.71102 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:09:47.054748 ops/training.py:65 2019-01-16 10:09:47.054679: step 6370, loss = 0.71707 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:09:48.018393 ops/training.py:65 2019-01-16 10:09:48.018328: step 6371, loss = 0.69529 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:09:48.980976 ops/training.py:65 2019-01-16 10:09:48.980919: step 6372, loss = 0.69747 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:09:49.946447 ops/training.py:65 2019-01-16 10:09:49.946373: step 6373, loss = 0.66159 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:09:50.911015 ops/training.py:65 2019-01-16 10:09:50.910941: step 6374, loss = 0.68526 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:09:51.873880 ops/training.py:65 2019-01-16 10:09:51.873805: step 6375, loss = 0.71974 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:09:52.839512 ops/training.py:65 2019-01-16 10:09:52.839452: step 6376, loss = 0.71507 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:09:53.803852 ops/training.py:65 2019-01-16 10:09:53.803802: step 6377, loss = 0.68189 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:09:54.766078 ops/training.py:65 2019-01-16 10:09:54.766022: step 6378, loss = 0.71346 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:09:55.728870 ops/training.py:65 2019-01-16 10:09:55.728817: step 6379, loss = 0.70164 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:09:56.691358 ops/training.py:65 2019-01-16 10:09:56.691305: step 6380, loss = 0.71749 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:09:57.653341 ops/training.py:65 2019-01-16 10:09:57.653268: step 6381, loss = 0.67305 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:09:58.615234 ops/training.py:65 2019-01-16 10:09:58.615161: step 6382, loss = 0.68158 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:09:59.579958 ops/training.py:65 2019-01-16 10:09:59.579890: step 6383, loss = 0.68362 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:10:00.543026 ops/training.py:65 2019-01-16 10:10:00.542950: step 6384, loss = 0.64893 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:10:01.505129 ops/training.py:65 2019-01-16 10:10:01.505073: step 6385, loss = 0.76788 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:10:02.464802 ops/training.py:65 2019-01-16 10:10:02.464742: step 6386, loss = 0.67936 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:10:03.427099 ops/training.py:65 2019-01-16 10:10:03.427028: step 6387, loss = 0.77728 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:10:04.391158 ops/training.py:65 2019-01-16 10:10:04.391106: step 6388, loss = 0.71100 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:10:05.354030 ops/training.py:65 2019-01-16 10:10:05.353970: step 6389, loss = 0.75479 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:10:06.316681 ops/training.py:65 2019-01-16 10:10:06.316612: step 6390, loss = 0.75314 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:10:07.279614 ops/training.py:65 2019-01-16 10:10:07.279537: step 6391, loss = 0.77819 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:10:08.243844 ops/training.py:65 2019-01-16 10:10:08.243795: step 6392, loss = 0.74159 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:10:09.206809 ops/training.py:65 2019-01-16 10:10:09.206737: step 6393, loss = 0.69798 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:10:10.170065 ops/training.py:65 2019-01-16 10:10:10.169994: step 6394, loss = 0.71324 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:10:11.132279 ops/training.py:65 2019-01-16 10:10:11.132207: step 6395, loss = 0.70136 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:10:12.093363 ops/training.py:65 2019-01-16 10:10:12.093316: step 6396, loss = 0.78167 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:10:13.054958 ops/training.py:65 2019-01-16 10:10:13.054906: step 6397, loss = 0.74802 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:10:14.016020 ops/training.py:65 2019-01-16 10:10:14.015968: step 6398, loss = 0.65411 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:10:14.977236 ops/training.py:65 2019-01-16 10:10:14.977185: step 6399, loss = 0.63197 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:10:15.939514 ops/training.py:65 2019-01-16 10:10:15.939462: step 6400, loss = 0.69980 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:10:16.900832 ops/training.py:65 2019-01-16 10:10:16.900743: step 6401, loss = 0.72627 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:10:17.863157 ops/training.py:65 2019-01-16 10:10:17.863084: step 6402, loss = 0.69477 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:10:18.825174 ops/training.py:65 2019-01-16 10:10:18.825100: step 6403, loss = 0.85536 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.21875
I0832 2019-01-16 10:10:19.787831 ops/training.py:65 2019-01-16 10:10:19.787758: step 6404, loss = 0.66312 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:10:20.750347 ops/training.py:65 2019-01-16 10:10:20.750278: step 6405, loss = 0.71650 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:10:21.711554 ops/training.py:65 2019-01-16 10:10:21.711505: step 6406, loss = 0.74151 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:10:22.672593 ops/training.py:65 2019-01-16 10:10:22.672541: step 6407, loss = 0.69706 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:10:23.634157 ops/training.py:65 2019-01-16 10:10:23.634102: step 6408, loss = 0.74970 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:10:24.597642 ops/training.py:65 2019-01-16 10:10:24.597591: step 6409, loss = 0.69839 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:10:25.560400 ops/training.py:65 2019-01-16 10:10:25.560348: step 6410, loss = 0.67150 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:10:26.524899 ops/training.py:65 2019-01-16 10:10:26.524847: step 6411, loss = 0.76763 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:10:27.487141 ops/training.py:65 2019-01-16 10:10:27.487065: step 6412, loss = 0.73582 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:10:28.448749 ops/training.py:65 2019-01-16 10:10:28.448693: step 6413, loss = 0.70084 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:10:29.409371 ops/training.py:65 2019-01-16 10:10:29.409319: step 6414, loss = 0.71002 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:10:30.369707 ops/training.py:65 2019-01-16 10:10:30.369637: step 6415, loss = 0.77479 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:10:31.333292 ops/training.py:65 2019-01-16 10:10:31.333244: step 6416, loss = 0.70833 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:10:32.297418 ops/training.py:65 2019-01-16 10:10:32.297346: step 6417, loss = 0.73228 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:10:33.259488 ops/training.py:65 2019-01-16 10:10:33.259414: step 6418, loss = 0.67578 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:10:34.221731 ops/training.py:65 2019-01-16 10:10:34.221674: step 6419, loss = 0.68495 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:10:35.185343 ops/training.py:65 2019-01-16 10:10:35.185294: step 6420, loss = 0.72651 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:10:36.147531 ops/training.py:65 2019-01-16 10:10:36.147477: step 6421, loss = 0.68990 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:10:37.108511 ops/training.py:65 2019-01-16 10:10:37.108444: step 6422, loss = 0.74424 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:10:38.068942 ops/training.py:65 2019-01-16 10:10:38.068884: step 6423, loss = 0.70851 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:10:39.028916 ops/training.py:65 2019-01-16 10:10:39.028854: step 6424, loss = 0.68266 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:10:39.991029 ops/training.py:65 2019-01-16 10:10:39.990966: step 6425, loss = 0.74323 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:10:40.951562 ops/training.py:65 2019-01-16 10:10:40.951493: step 6426, loss = 0.71808 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:10:41.914352 ops/training.py:65 2019-01-16 10:10:41.914283: step 6427, loss = 0.73186 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:10:42.876520 ops/training.py:65 2019-01-16 10:10:42.876460: step 6428, loss = 0.72366 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:10:43.840385 ops/training.py:65 2019-01-16 10:10:43.840327: step 6429, loss = 0.68426 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:10:44.805977 ops/training.py:65 2019-01-16 10:10:44.805931: step 6430, loss = 0.67947 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:10:45.768190 ops/training.py:65 2019-01-16 10:10:45.768134: step 6431, loss = 0.69484 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:10:46.729640 ops/training.py:65 2019-01-16 10:10:46.729582: step 6432, loss = 0.66118 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:10:47.691005 ops/training.py:65 2019-01-16 10:10:47.690964: step 6433, loss = 0.70634 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:10:48.652260 ops/training.py:65 2019-01-16 10:10:48.652205: step 6434, loss = 0.68154 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:10:49.613074 ops/training.py:65 2019-01-16 10:10:49.613017: step 6435, loss = 0.75122 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:10:50.575033 ops/training.py:65 2019-01-16 10:10:50.574978: step 6436, loss = 0.71075 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:10:51.537929 ops/training.py:65 2019-01-16 10:10:51.537874: step 6437, loss = 0.70286 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:10:52.500687 ops/training.py:65 2019-01-16 10:10:52.500633: step 6438, loss = 0.72499 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:10:53.462299 ops/training.py:65 2019-01-16 10:10:53.462243: step 6439, loss = 0.73797 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:10:54.424136 ops/training.py:65 2019-01-16 10:10:54.424082: step 6440, loss = 0.68549 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:10:55.385484 ops/training.py:65 2019-01-16 10:10:55.385421: step 6441, loss = 0.68235 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:10:56.346099 ops/training.py:65 2019-01-16 10:10:56.346008: step 6442, loss = 0.65951 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:10:57.309729 ops/training.py:65 2019-01-16 10:10:57.309666: step 6443, loss = 0.71251 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:10:58.273450 ops/training.py:65 2019-01-16 10:10:58.273391: step 6444, loss = 0.66128 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:10:59.234571 ops/training.py:65 2019-01-16 10:10:59.234498: step 6445, loss = 0.63431 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:11:00.194143 ops/training.py:65 2019-01-16 10:11:00.194067: step 6446, loss = 0.69656 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:11:01.158012 ops/training.py:65 2019-01-16 10:11:01.157952: step 6447, loss = 0.72845 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:11:02.119491 ops/training.py:65 2019-01-16 10:11:02.119423: step 6448, loss = 0.74436 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:11:03.080480 ops/training.py:65 2019-01-16 10:11:03.080426: step 6449, loss = 0.62597 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:11:04.042204 ops/training.py:65 2019-01-16 10:11:04.042151: step 6450, loss = 0.73357 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:11:05.004703 ops/training.py:65 2019-01-16 10:11:05.004647: step 6451, loss = 0.74275 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:11:05.968380 ops/training.py:65 2019-01-16 10:11:05.968327: step 6452, loss = 0.71528 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:11:06.930881 ops/training.py:65 2019-01-16 10:11:06.930829: step 6453, loss = 0.69879 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:11:07.892356 ops/training.py:65 2019-01-16 10:11:07.892304: step 6454, loss = 0.70615 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:11:08.853886 ops/training.py:65 2019-01-16 10:11:08.853834: step 6455, loss = 0.68451 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:11:09.815081 ops/training.py:65 2019-01-16 10:11:09.815041: step 6456, loss = 0.70198 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:11:10.776400 ops/training.py:65 2019-01-16 10:11:10.776339: step 6457, loss = 0.71272 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:11:11.737866 ops/training.py:65 2019-01-16 10:11:11.737812: step 6458, loss = 0.73397 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:11:12.699179 ops/training.py:65 2019-01-16 10:11:12.699125: step 6459, loss = 0.73752 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:11:13.659769 ops/training.py:65 2019-01-16 10:11:13.659726: step 6460, loss = 0.65819 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:11:14.621254 ops/training.py:65 2019-01-16 10:11:14.621195: step 6461, loss = 0.69248 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:11:15.581814 ops/training.py:65 2019-01-16 10:11:15.581756: step 6462, loss = 0.74865 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:11:16.541995 ops/training.py:65 2019-01-16 10:11:16.541938: step 6463, loss = 0.68490 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:11:17.503606 ops/training.py:65 2019-01-16 10:11:17.503566: step 6464, loss = 0.70808 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:11:18.465464 ops/training.py:65 2019-01-16 10:11:18.465410: step 6465, loss = 0.70855 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:11:19.426744 ops/training.py:65 2019-01-16 10:11:19.426688: step 6466, loss = 0.72925 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:11:20.387525 ops/training.py:65 2019-01-16 10:11:20.387473: step 6467, loss = 0.65901 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:11:21.349183 ops/training.py:65 2019-01-16 10:11:21.349124: step 6468, loss = 0.67232 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:11:22.312709 ops/training.py:65 2019-01-16 10:11:22.312654: step 6469, loss = 0.71158 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:11:23.277491 ops/training.py:65 2019-01-16 10:11:23.277438: step 6470, loss = 0.69958 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:11:24.240045 ops/training.py:65 2019-01-16 10:11:24.239992: step 6471, loss = 0.65835 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:11:25.200503 ops/training.py:65 2019-01-16 10:11:25.200452: step 6472, loss = 0.68436 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:11:26.161154 ops/training.py:65 2019-01-16 10:11:26.161091: step 6473, loss = 0.70802 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:11:27.121801 ops/training.py:65 2019-01-16 10:11:27.121722: step 6474, loss = 0.66530 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:11:28.082173 ops/training.py:65 2019-01-16 10:11:28.082119: step 6475, loss = 0.71025 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:11:29.046820 ops/training.py:65 2019-01-16 10:11:29.046755: step 6476, loss = 0.68454 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:11:30.008909 ops/training.py:65 2019-01-16 10:11:30.008839: step 6477, loss = 0.69777 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:11:30.973756 ops/training.py:65 2019-01-16 10:11:30.973690: step 6478, loss = 0.68154 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:11:31.937274 ops/training.py:65 2019-01-16 10:11:31.937217: step 6479, loss = 0.72690 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:11:32.899386 ops/training.py:65 2019-01-16 10:11:32.899325: step 6480, loss = 0.71113 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:11:33.860158 ops/training.py:65 2019-01-16 10:11:33.860105: step 6481, loss = 0.70166 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:11:34.821868 ops/training.py:65 2019-01-16 10:11:34.821815: step 6482, loss = 0.67618 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:11:35.787001 ops/training.py:65 2019-01-16 10:11:35.786946: step 6483, loss = 0.68389 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:11:36.749943 ops/training.py:65 2019-01-16 10:11:36.749891: step 6484, loss = 0.71831 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:11:37.711562 ops/training.py:65 2019-01-16 10:11:37.711510: step 6485, loss = 0.67232 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:11:38.673110 ops/training.py:65 2019-01-16 10:11:38.673068: step 6486, loss = 0.70939 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:11:39.636263 ops/training.py:65 2019-01-16 10:11:39.636208: step 6487, loss = 0.69089 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:11:40.600740 ops/training.py:65 2019-01-16 10:11:40.600684: step 6488, loss = 0.70013 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:11:41.562803 ops/training.py:65 2019-01-16 10:11:41.562737: step 6489, loss = 0.70151 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:11:42.524871 ops/training.py:65 2019-01-16 10:11:42.524828: step 6490, loss = 0.77280 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:11:43.485785 ops/training.py:65 2019-01-16 10:11:43.485725: step 6491, loss = 0.69428 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:11:44.446763 ops/training.py:65 2019-01-16 10:11:44.446705: step 6492, loss = 0.68149 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:11:45.405994 ops/training.py:65 2019-01-16 10:11:45.405921: step 6493, loss = 0.72797 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:11:46.365869 ops/training.py:65 2019-01-16 10:11:46.365795: step 6494, loss = 0.68572 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:11:47.330897 ops/training.py:65 2019-01-16 10:11:47.330835: step 6495, loss = 0.65063 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:11:48.295397 ops/training.py:65 2019-01-16 10:11:48.295343: step 6496, loss = 0.70070 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:11:49.259310 ops/training.py:65 2019-01-16 10:11:49.259258: step 6497, loss = 0.68857 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:11:50.222233 ops/training.py:65 2019-01-16 10:11:50.222186: step 6498, loss = 0.68183 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:11:51.183356 ops/training.py:65 2019-01-16 10:11:51.183307: step 6499, loss = 0.68405 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:11:52.145029 ops/training.py:65 2019-01-16 10:11:52.144971: step 6500, loss = 0.69203 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:11:53.106566 ops/training.py:65 2019-01-16 10:11:53.106509: step 6501, loss = 0.68912 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:11:54.066829 ops/training.py:65 2019-01-16 10:11:54.066766: step 6502, loss = 0.69554 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:11:55.027060 ops/training.py:65 2019-01-16 10:11:55.026988: step 6503, loss = 0.71003 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:11:55.987404 ops/training.py:65 2019-01-16 10:11:55.987314: step 6504, loss = 0.69030 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:11:56.947845 ops/training.py:65 2019-01-16 10:11:56.947770: step 6505, loss = 0.71335 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:11:57.907534 ops/training.py:65 2019-01-16 10:11:57.907465: step 6506, loss = 0.73616 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:11:58.866585 ops/training.py:65 2019-01-16 10:11:58.866521: step 6507, loss = 0.66748 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:11:59.826291 ops/training.py:65 2019-01-16 10:11:59.826226: step 6508, loss = 0.71253 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:12:00.784922 ops/training.py:65 2019-01-16 10:12:00.784855: step 6509, loss = 0.69228 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:12:01.743660 ops/training.py:65 2019-01-16 10:12:01.743591: step 6510, loss = 0.67866 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:12:02.706159 ops/training.py:65 2019-01-16 10:12:02.706087: step 6511, loss = 0.70311 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:12:03.668357 ops/training.py:65 2019-01-16 10:12:03.668284: step 6512, loss = 0.71825 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:12:04.629235 ops/training.py:65 2019-01-16 10:12:04.629185: step 6513, loss = 0.66946 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:12:05.589152 ops/training.py:65 2019-01-16 10:12:05.589088: step 6514, loss = 0.68909 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:12:06.552680 ops/training.py:65 2019-01-16 10:12:06.552607: step 6515, loss = 0.70709 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:12:07.513544 ops/training.py:65 2019-01-16 10:12:07.513471: step 6516, loss = 0.72537 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:12:08.473794 ops/training.py:65 2019-01-16 10:12:08.473702: step 6517, loss = 0.68770 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:12:09.437202 ops/training.py:65 2019-01-16 10:12:09.437141: step 6518, loss = 0.69521 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:12:10.399872 ops/training.py:65 2019-01-16 10:12:10.399828: step 6519, loss = 0.67037 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:12:11.362184 ops/training.py:65 2019-01-16 10:12:11.362129: step 6520, loss = 0.70185 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:12:12.322935 ops/training.py:65 2019-01-16 10:12:12.322879: step 6521, loss = 0.66929 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:12:13.283546 ops/training.py:65 2019-01-16 10:12:13.283491: step 6522, loss = 0.69632 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:12:14.247182 ops/training.py:65 2019-01-16 10:12:14.247141: step 6523, loss = 0.71707 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:12:15.211527 ops/training.py:65 2019-01-16 10:12:15.211472: step 6524, loss = 0.68856 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:12:16.172787 ops/training.py:65 2019-01-16 10:12:16.172715: step 6525, loss = 0.71465 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:12:17.137535 ops/training.py:65 2019-01-16 10:12:17.137463: step 6526, loss = 0.70768 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:12:18.100563 ops/training.py:65 2019-01-16 10:12:18.100505: step 6527, loss = 0.71455 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:12:19.061316 ops/training.py:65 2019-01-16 10:12:19.061244: step 6528, loss = 0.66164 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:12:20.021355 ops/training.py:65 2019-01-16 10:12:20.021279: step 6529, loss = 0.71113 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:12:20.985007 ops/training.py:65 2019-01-16 10:12:20.984947: step 6530, loss = 0.69483 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:12:21.948001 ops/training.py:65 2019-01-16 10:12:21.947943: step 6531, loss = 0.69404 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:12:22.908143 ops/training.py:65 2019-01-16 10:12:22.908075: step 6532, loss = 0.70249 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:12:23.867465 ops/training.py:65 2019-01-16 10:12:23.867398: step 6533, loss = 0.69101 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:12:24.830161 ops/training.py:65 2019-01-16 10:12:24.830090: step 6534, loss = 0.66966 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:12:25.793687 ops/training.py:65 2019-01-16 10:12:25.793622: step 6535, loss = 0.68324 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:12:26.756488 ops/training.py:65 2019-01-16 10:12:26.756424: step 6536, loss = 0.68857 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:12:27.717723 ops/training.py:65 2019-01-16 10:12:27.717652: step 6537, loss = 0.66424 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:12:28.679161 ops/training.py:65 2019-01-16 10:12:28.679096: step 6538, loss = 0.73264 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:12:29.639235 ops/training.py:65 2019-01-16 10:12:29.639160: step 6539, loss = 0.69422 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:12:30.599562 ops/training.py:65 2019-01-16 10:12:30.599478: step 6540, loss = 0.68931 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:12:31.562217 ops/training.py:65 2019-01-16 10:12:31.562163: step 6541, loss = 0.69648 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:12:32.525942 ops/training.py:65 2019-01-16 10:12:32.525869: step 6542, loss = 0.69493 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:12:33.487196 ops/training.py:65 2019-01-16 10:12:33.487135: step 6543, loss = 0.71263 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:12:34.448496 ops/training.py:65 2019-01-16 10:12:34.448437: step 6544, loss = 0.69700 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:12:35.410253 ops/training.py:65 2019-01-16 10:12:35.410191: step 6545, loss = 0.68667 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:12:36.374204 ops/training.py:65 2019-01-16 10:12:36.374149: step 6546, loss = 0.67945 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:12:37.337501 ops/training.py:65 2019-01-16 10:12:37.337447: step 6547, loss = 0.70100 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:12:38.299072 ops/training.py:65 2019-01-16 10:12:38.299008: step 6548, loss = 0.65965 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:12:39.260004 ops/training.py:65 2019-01-16 10:12:39.259923: step 6549, loss = 0.70796 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:12:40.223417 ops/training.py:65 2019-01-16 10:12:40.223363: step 6550, loss = 0.68434 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:12:41.186706 ops/training.py:65 2019-01-16 10:12:41.186638: step 6551, loss = 0.69785 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:12:42.147654 ops/training.py:65 2019-01-16 10:12:42.147581: step 6552, loss = 0.65713 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:12:43.109149 ops/training.py:65 2019-01-16 10:12:43.109099: step 6553, loss = 0.69701 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:12:44.072220 ops/training.py:65 2019-01-16 10:12:44.072157: step 6554, loss = 0.68297 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:12:45.037013 ops/training.py:65 2019-01-16 10:12:45.036940: step 6555, loss = 0.67297 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:12:46.001067 ops/training.py:65 2019-01-16 10:12:46.000996: step 6556, loss = 0.71228 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:12:46.962481 ops/training.py:65 2019-01-16 10:12:46.962409: step 6557, loss = 0.68700 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:12:47.926542 ops/training.py:65 2019-01-16 10:12:47.926471: step 6558, loss = 0.68827 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:12:48.891120 ops/training.py:65 2019-01-16 10:12:48.891072: step 6559, loss = 0.65515 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:12:49.853840 ops/training.py:65 2019-01-16 10:12:49.853787: step 6560, loss = 0.69733 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:12:50.815282 ops/training.py:65 2019-01-16 10:12:50.815214: step 6561, loss = 0.68198 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:12:51.780900 ops/training.py:65 2019-01-16 10:12:51.780850: step 6562, loss = 0.69381 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:12:52.744274 ops/training.py:65 2019-01-16 10:12:52.744224: step 6563, loss = 0.71693 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:12:53.706610 ops/training.py:65 2019-01-16 10:12:53.706555: step 6564, loss = 0.68300 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:12:54.667874 ops/training.py:65 2019-01-16 10:12:54.667819: step 6565, loss = 0.70194 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:12:55.629343 ops/training.py:65 2019-01-16 10:12:55.629285: step 6566, loss = 0.73200 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:12:56.590855 ops/training.py:65 2019-01-16 10:12:56.590798: step 6567, loss = 0.70395 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:12:57.551500 ops/training.py:65 2019-01-16 10:12:57.551439: step 6568, loss = 0.75150 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:12:58.512363 ops/training.py:65 2019-01-16 10:12:58.512310: step 6569, loss = 0.69986 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:12:59.474838 ops/training.py:65 2019-01-16 10:12:59.474776: step 6570, loss = 0.68344 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:13:00.435260 ops/training.py:65 2019-01-16 10:13:00.435204: step 6571, loss = 0.72198 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:13:01.395709 ops/training.py:65 2019-01-16 10:13:01.395649: step 6572, loss = 0.68085 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:13:02.356850 ops/training.py:65 2019-01-16 10:13:02.356800: step 6573, loss = 0.69040 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:13:03.322060 ops/training.py:65 2019-01-16 10:13:03.322008: step 6574, loss = 0.71024 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:13:04.284784 ops/training.py:65 2019-01-16 10:13:04.284721: step 6575, loss = 0.68918 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:13:05.247122 ops/training.py:65 2019-01-16 10:13:05.247063: step 6576, loss = 0.66710 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:13:06.208058 ops/training.py:65 2019-01-16 10:13:06.207995: step 6577, loss = 0.66869 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:13:07.168381 ops/training.py:65 2019-01-16 10:13:07.168320: step 6578, loss = 0.69347 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:13:08.129099 ops/training.py:65 2019-01-16 10:13:08.129042: step 6579, loss = 0.69714 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:13:09.092302 ops/training.py:65 2019-01-16 10:13:09.092241: step 6580, loss = 0.67124 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:13:10.057074 ops/training.py:65 2019-01-16 10:13:10.057012: step 6581, loss = 0.70749 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:13:11.018578 ops/training.py:65 2019-01-16 10:13:11.018516: step 6582, loss = 0.67583 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:13:11.984184 ops/training.py:65 2019-01-16 10:13:11.984133: step 6583, loss = 0.73121 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:13:12.948224 ops/training.py:65 2019-01-16 10:13:12.948168: step 6584, loss = 0.69280 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:13:13.911430 ops/training.py:65 2019-01-16 10:13:13.911364: step 6585, loss = 0.70776 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:13:14.873073 ops/training.py:65 2019-01-16 10:13:14.873020: step 6586, loss = 0.71926 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:13:15.834270 ops/training.py:65 2019-01-16 10:13:15.834218: step 6587, loss = 0.68999 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:13:16.795715 ops/training.py:65 2019-01-16 10:13:16.795652: step 6588, loss = 0.68824 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:13:17.757466 ops/training.py:65 2019-01-16 10:13:17.757394: step 6589, loss = 0.68978 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:13:18.719411 ops/training.py:65 2019-01-16 10:13:18.719343: step 6590, loss = 0.68385 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:13:19.681497 ops/training.py:65 2019-01-16 10:13:19.681430: step 6591, loss = 0.70010 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:13:20.642495 ops/training.py:65 2019-01-16 10:13:20.642434: step 6592, loss = 0.69146 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:13:21.604219 ops/training.py:65 2019-01-16 10:13:21.604160: step 6593, loss = 0.72733 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:13:22.566141 ops/training.py:65 2019-01-16 10:13:22.566070: step 6594, loss = 0.73248 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:13:23.526910 ops/training.py:65 2019-01-16 10:13:23.526844: step 6595, loss = 0.69751 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:13:24.487548 ops/training.py:65 2019-01-16 10:13:24.487482: step 6596, loss = 0.71896 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:13:25.448439 ops/training.py:65 2019-01-16 10:13:25.448369: step 6597, loss = 0.71585 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:13:26.409949 ops/training.py:65 2019-01-16 10:13:26.409893: step 6598, loss = 0.69365 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:13:27.370438 ops/training.py:65 2019-01-16 10:13:27.370391: step 6599, loss = 0.71276 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:13:28.332260 ops/training.py:65 2019-01-16 10:13:28.332185: step 6600, loss = 0.71278 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:13:29.293041 ops/training.py:65 2019-01-16 10:13:29.292966: step 6601, loss = 0.64691 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:13:30.253148 ops/training.py:65 2019-01-16 10:13:30.253082: step 6602, loss = 0.72654 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:13:31.214928 ops/training.py:65 2019-01-16 10:13:31.214877: step 6603, loss = 0.74330 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:13:32.179468 ops/training.py:65 2019-01-16 10:13:32.179403: step 6604, loss = 0.66737 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:13:33.143553 ops/training.py:65 2019-01-16 10:13:33.143485: step 6605, loss = 0.67371 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:13:34.107029 ops/training.py:65 2019-01-16 10:13:34.106980: step 6606, loss = 0.68705 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:13:35.071110 ops/training.py:65 2019-01-16 10:13:35.071049: step 6607, loss = 0.74737 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:13:36.032672 ops/training.py:65 2019-01-16 10:13:36.032615: step 6608, loss = 0.67128 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:13:36.997666 ops/training.py:65 2019-01-16 10:13:36.997607: step 6609, loss = 0.70629 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:13:37.961267 ops/training.py:65 2019-01-16 10:13:37.961205: step 6610, loss = 0.69258 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:13:38.926341 ops/training.py:65 2019-01-16 10:13:38.926278: step 6611, loss = 0.70750 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:13:39.889628 ops/training.py:65 2019-01-16 10:13:39.889570: step 6612, loss = 0.68565 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:13:40.850894 ops/training.py:65 2019-01-16 10:13:40.850835: step 6613, loss = 0.72692 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:13:41.812233 ops/training.py:65 2019-01-16 10:13:41.812166: step 6614, loss = 0.72629 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:13:42.775510 ops/training.py:65 2019-01-16 10:13:42.775446: step 6615, loss = 0.67427 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:13:43.740287 ops/training.py:65 2019-01-16 10:13:43.740227: step 6616, loss = 0.68037 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:13:44.704225 ops/training.py:65 2019-01-16 10:13:44.704166: step 6617, loss = 0.68318 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:13:45.668819 ops/training.py:65 2019-01-16 10:13:45.668760: step 6618, loss = 0.71987 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:13:46.631547 ops/training.py:65 2019-01-16 10:13:46.631499: step 6619, loss = 0.70761 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:13:47.593838 ops/training.py:65 2019-01-16 10:13:47.593778: step 6620, loss = 0.71022 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:13:48.557045 ops/training.py:65 2019-01-16 10:13:48.556979: step 6621, loss = 0.73740 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:13:49.518532 ops/training.py:65 2019-01-16 10:13:49.518491: step 6622, loss = 0.66164 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:13:50.479926 ops/training.py:65 2019-01-16 10:13:50.479884: step 6623, loss = 0.67250 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:13:51.442509 ops/training.py:65 2019-01-16 10:13:51.442467: step 6624, loss = 0.67286 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:13:52.402936 ops/training.py:65 2019-01-16 10:13:52.402892: step 6625, loss = 0.71125 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:13:53.365667 ops/training.py:65 2019-01-16 10:13:53.365613: step 6626, loss = 0.75820 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:13:54.326116 ops/training.py:65 2019-01-16 10:13:54.326058: step 6627, loss = 0.71361 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:13:55.289848 ops/training.py:65 2019-01-16 10:13:55.289789: step 6628, loss = 0.68227 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:13:56.253155 ops/training.py:65 2019-01-16 10:13:56.253096: step 6629, loss = 0.74531 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:13:57.215262 ops/training.py:65 2019-01-16 10:13:57.215203: step 6630, loss = 0.71944 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:13:58.176969 ops/training.py:65 2019-01-16 10:13:58.176911: step 6631, loss = 0.69499 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:13:59.137771 ops/training.py:65 2019-01-16 10:13:59.137727: step 6632, loss = 0.69726 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:14:00.103445 ops/training.py:65 2019-01-16 10:14:00.103373: step 6633, loss = 0.69785 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:14:01.068768 ops/training.py:65 2019-01-16 10:14:01.068709: step 6634, loss = 0.64259 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:14:02.030009 ops/training.py:65 2019-01-16 10:14:02.029940: step 6635, loss = 0.75508 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:14:02.990341 ops/training.py:65 2019-01-16 10:14:02.990270: step 6636, loss = 0.71609 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:14:03.954366 ops/training.py:65 2019-01-16 10:14:03.954308: step 6637, loss = 0.75063 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:14:04.916684 ops/training.py:65 2019-01-16 10:14:04.916625: step 6638, loss = 0.66926 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:14:05.878966 ops/training.py:65 2019-01-16 10:14:05.878908: step 6639, loss = 0.65938 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:14:06.844558 ops/training.py:65 2019-01-16 10:14:06.844502: step 6640, loss = 0.66195 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:14:07.806299 ops/training.py:65 2019-01-16 10:14:07.806243: step 6641, loss = 0.69050 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:14:08.767890 ops/training.py:65 2019-01-16 10:14:08.767852: step 6642, loss = 0.74267 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:14:09.732150 ops/training.py:65 2019-01-16 10:14:09.732095: step 6643, loss = 0.70769 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:14:10.695198 ops/training.py:65 2019-01-16 10:14:10.695143: step 6644, loss = 0.69647 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:14:11.659337 ops/training.py:65 2019-01-16 10:14:11.659282: step 6645, loss = 0.72371 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:14:12.621879 ops/training.py:65 2019-01-16 10:14:12.621829: step 6646, loss = 0.71849 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:14:13.583035 ops/training.py:65 2019-01-16 10:14:13.582983: step 6647, loss = 0.68663 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:14:14.544696 ops/training.py:65 2019-01-16 10:14:14.544642: step 6648, loss = 0.64309 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:14:15.505540 ops/training.py:65 2019-01-16 10:14:15.505485: step 6649, loss = 0.66889 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:14:16.467062 ops/training.py:65 2019-01-16 10:14:16.467008: step 6650, loss = 0.66589 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:14:17.427750 ops/training.py:65 2019-01-16 10:14:17.427695: step 6651, loss = 0.67927 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:14:18.388147 ops/training.py:65 2019-01-16 10:14:18.388111: step 6652, loss = 0.70434 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:14:19.349729 ops/training.py:65 2019-01-16 10:14:19.349673: step 6653, loss = 0.74277 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:14:20.310989 ops/training.py:65 2019-01-16 10:14:20.310933: step 6654, loss = 0.73634 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:14:21.272055 ops/training.py:65 2019-01-16 10:14:21.272000: step 6655, loss = 0.71763 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:14:22.232965 ops/training.py:65 2019-01-16 10:14:22.232910: step 6656, loss = 0.68957 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:14:23.194211 ops/training.py:65 2019-01-16 10:14:23.194156: step 6657, loss = 0.72473 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 10:14:24.155123 ops/training.py:65 2019-01-16 10:14:24.155068: step 6658, loss = 0.70616 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:14:25.116404 ops/training.py:65 2019-01-16 10:14:25.116359: step 6659, loss = 0.68148 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:14:26.077604 ops/training.py:65 2019-01-16 10:14:26.077548: step 6660, loss = 0.72378 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:14:27.039017 ops/training.py:65 2019-01-16 10:14:27.038962: step 6661, loss = 0.70908 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:14:28.000426 ops/training.py:65 2019-01-16 10:14:28.000379: step 6662, loss = 0.70010 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:14:28.962362 ops/training.py:65 2019-01-16 10:14:28.962306: step 6663, loss = 0.71267 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:14:29.923686 ops/training.py:65 2019-01-16 10:14:29.923630: step 6664, loss = 0.68991 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:14:30.884569 ops/training.py:65 2019-01-16 10:14:30.884515: step 6665, loss = 0.68313 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:14:31.846229 ops/training.py:65 2019-01-16 10:14:31.846162: step 6666, loss = 0.71122 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:14:32.806108 ops/training.py:65 2019-01-16 10:14:32.806031: step 6667, loss = 0.66460 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:14:33.768092 ops/training.py:65 2019-01-16 10:14:33.768027: step 6668, loss = 0.66202 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:14:34.732022 ops/training.py:65 2019-01-16 10:14:34.731965: step 6669, loss = 0.69487 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:14:35.694726 ops/training.py:65 2019-01-16 10:14:35.694673: step 6670, loss = 0.67836 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:14:36.656822 ops/training.py:65 2019-01-16 10:14:36.656768: step 6671, loss = 0.71342 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:14:37.620018 ops/training.py:65 2019-01-16 10:14:37.619957: step 6672, loss = 0.67120 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:14:38.584172 ops/training.py:65 2019-01-16 10:14:38.584115: step 6673, loss = 0.69115 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:14:39.548176 ops/training.py:65 2019-01-16 10:14:39.548121: step 6674, loss = 0.70115 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:14:40.510017 ops/training.py:65 2019-01-16 10:14:40.509955: step 6675, loss = 0.66378 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:14:41.470257 ops/training.py:65 2019-01-16 10:14:41.470207: step 6676, loss = 0.67668 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:14:42.432237 ops/training.py:65 2019-01-16 10:14:42.432182: step 6677, loss = 0.68136 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:14:43.393890 ops/training.py:65 2019-01-16 10:14:43.393832: step 6678, loss = 0.70125 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:14:44.356301 ops/training.py:65 2019-01-16 10:14:44.356244: step 6679, loss = 0.68378 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:14:45.318523 ops/training.py:65 2019-01-16 10:14:45.318470: step 6680, loss = 0.70090 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:14:46.282853 ops/training.py:65 2019-01-16 10:14:46.282802: step 6681, loss = 0.66909 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:14:47.245216 ops/training.py:65 2019-01-16 10:14:47.245163: step 6682, loss = 0.71362 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:14:48.207249 ops/training.py:65 2019-01-16 10:14:48.207197: step 6683, loss = 0.68745 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:14:49.168321 ops/training.py:65 2019-01-16 10:14:49.168267: step 6684, loss = 0.69208 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:14:50.129805 ops/training.py:65 2019-01-16 10:14:50.129751: step 6685, loss = 0.69655 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:14:51.091359 ops/training.py:65 2019-01-16 10:14:51.091305: step 6686, loss = 0.68941 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:14:52.053161 ops/training.py:65 2019-01-16 10:14:52.053102: step 6687, loss = 0.70196 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:14:53.014762 ops/training.py:65 2019-01-16 10:14:53.014702: step 6688, loss = 0.68390 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:14:53.976148 ops/training.py:65 2019-01-16 10:14:53.976091: step 6689, loss = 0.67762 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:14:54.937022 ops/training.py:65 2019-01-16 10:14:54.936964: step 6690, loss = 0.71658 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:14:55.897909 ops/training.py:65 2019-01-16 10:14:55.897850: step 6691, loss = 0.67966 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:14:56.860988 ops/training.py:65 2019-01-16 10:14:56.860936: step 6692, loss = 0.69597 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:14:57.824743 ops/training.py:65 2019-01-16 10:14:57.824688: step 6693, loss = 0.70574 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:14:58.787554 ops/training.py:65 2019-01-16 10:14:58.787499: step 6694, loss = 0.68253 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:14:59.749495 ops/training.py:65 2019-01-16 10:14:59.749441: step 6695, loss = 0.68630 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:15:00.709782 ops/training.py:65 2019-01-16 10:15:00.709743: step 6696, loss = 0.70077 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:15:01.672095 ops/training.py:65 2019-01-16 10:15:01.672034: step 6697, loss = 0.67134 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:15:02.636824 ops/training.py:65 2019-01-16 10:15:02.636756: step 6698, loss = 0.71865 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:15:03.600791 ops/training.py:65 2019-01-16 10:15:03.600729: step 6699, loss = 0.69116 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:15:04.561493 ops/training.py:65 2019-01-16 10:15:04.561421: step 6700, loss = 0.72188 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:15:05.524741 ops/training.py:65 2019-01-16 10:15:05.524684: step 6701, loss = 0.67375 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:15:06.486795 ops/training.py:65 2019-01-16 10:15:06.486752: step 6702, loss = 0.69896 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:15:07.447198 ops/training.py:65 2019-01-16 10:15:07.447141: step 6703, loss = 0.63806 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:15:08.407685 ops/training.py:65 2019-01-16 10:15:08.407630: step 6704, loss = 0.71018 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:15:09.367651 ops/training.py:65 2019-01-16 10:15:09.367597: step 6705, loss = 0.66072 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:15:10.329128 ops/training.py:65 2019-01-16 10:15:10.329071: step 6706, loss = 0.73707 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:15:11.292528 ops/training.py:65 2019-01-16 10:15:11.292456: step 6707, loss = 0.69004 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:15:12.253406 ops/training.py:65 2019-01-16 10:15:12.253330: step 6708, loss = 0.69650 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:15:13.216897 ops/training.py:65 2019-01-16 10:15:13.216848: step 6709, loss = 0.68929 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:15:14.182804 ops/training.py:65 2019-01-16 10:15:14.182733: step 6710, loss = 0.69134 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:15:15.143651 ops/training.py:65 2019-01-16 10:15:15.143580: step 6711, loss = 0.68361 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:15:16.108051 ops/training.py:65 2019-01-16 10:15:16.107993: step 6712, loss = 0.67441 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:15:17.071066 ops/training.py:65 2019-01-16 10:15:17.071007: step 6713, loss = 0.68725 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:15:18.032610 ops/training.py:65 2019-01-16 10:15:18.032552: step 6714, loss = 0.69292 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:15:18.992274 ops/training.py:65 2019-01-16 10:15:18.992232: step 6715, loss = 0.67697 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:15:19.953763 ops/training.py:65 2019-01-16 10:15:19.953703: step 6716, loss = 0.71135 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:15:20.914708 ops/training.py:65 2019-01-16 10:15:20.914646: step 6717, loss = 0.71971 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:15:21.876475 ops/training.py:65 2019-01-16 10:15:21.876414: step 6718, loss = 0.70173 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:15:22.839766 ops/training.py:65 2019-01-16 10:15:22.839700: step 6719, loss = 0.73294 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:15:23.803112 ops/training.py:65 2019-01-16 10:15:23.803050: step 6720, loss = 0.73852 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:15:24.767600 ops/training.py:65 2019-01-16 10:15:24.767538: step 6721, loss = 0.67047 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:15:25.728759 ops/training.py:65 2019-01-16 10:15:25.728720: step 6722, loss = 0.70778 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:15:26.690477 ops/training.py:65 2019-01-16 10:15:26.690419: step 6723, loss = 0.68577 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:15:27.653819 ops/training.py:65 2019-01-16 10:15:27.653760: step 6724, loss = 0.67604 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:15:28.614837 ops/training.py:65 2019-01-16 10:15:28.614773: step 6725, loss = 0.69744 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:15:29.577202 ops/training.py:65 2019-01-16 10:15:29.577139: step 6726, loss = 0.66048 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:15:30.539443 ops/training.py:65 2019-01-16 10:15:30.539377: step 6727, loss = 0.73504 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:15:31.499039 ops/training.py:65 2019-01-16 10:15:31.498966: step 6728, loss = 0.67127 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:15:32.457541 ops/training.py:65 2019-01-16 10:15:32.457466: step 6729, loss = 0.71127 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:15:33.417461 ops/training.py:65 2019-01-16 10:15:33.417391: step 6730, loss = 0.69001 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:15:34.376584 ops/training.py:65 2019-01-16 10:15:34.376519: step 6731, loss = 0.70769 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:15:35.334959 ops/training.py:65 2019-01-16 10:15:35.334912: step 6732, loss = 0.69539 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:15:36.294113 ops/training.py:65 2019-01-16 10:15:36.294042: step 6733, loss = 0.67797 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:15:37.251980 ops/training.py:65 2019-01-16 10:15:37.251926: step 6734, loss = 0.71016 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:15:38.212223 ops/training.py:65 2019-01-16 10:15:38.212162: step 6735, loss = 0.69568 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:15:39.172236 ops/training.py:65 2019-01-16 10:15:39.172166: step 6736, loss = 0.68462 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:15:40.133715 ops/training.py:65 2019-01-16 10:15:40.133651: step 6737, loss = 0.70403 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:15:41.098881 ops/training.py:65 2019-01-16 10:15:41.098816: step 6738, loss = 0.68198 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:15:42.061962 ops/training.py:65 2019-01-16 10:15:42.061904: step 6739, loss = 0.67250 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:15:43.024553 ops/training.py:65 2019-01-16 10:15:43.024500: step 6740, loss = 0.67880 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:15:43.985949 ops/training.py:65 2019-01-16 10:15:43.985891: step 6741, loss = 0.68509 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:15:44.949609 ops/training.py:65 2019-01-16 10:15:44.949566: step 6742, loss = 0.67965 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:15:45.912990 ops/training.py:65 2019-01-16 10:15:45.912950: step 6743, loss = 0.70232 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:15:46.877187 ops/training.py:65 2019-01-16 10:15:46.877145: step 6744, loss = 0.69184 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:15:47.839700 ops/training.py:65 2019-01-16 10:15:47.839653: step 6745, loss = 0.69937 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:15:48.803076 ops/training.py:65 2019-01-16 10:15:48.803029: step 6746, loss = 0.69227 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:15:49.765767 ops/training.py:65 2019-01-16 10:15:49.765704: step 6747, loss = 0.69622 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:15:50.727091 ops/training.py:65 2019-01-16 10:15:50.727030: step 6748, loss = 0.69804 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:15:51.688452 ops/training.py:65 2019-01-16 10:15:51.688393: step 6749, loss = 0.68200 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:15:52.650035 ops/training.py:65 2019-01-16 10:15:52.649994: step 6750, loss = 0.65933 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:15:53.612233 ops/training.py:65 2019-01-16 10:15:53.612196: step 6751, loss = 0.69361 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:15:54.572858 ops/training.py:65 2019-01-16 10:15:54.572804: step 6752, loss = 0.68298 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:15:55.534687 ops/training.py:65 2019-01-16 10:15:55.534627: step 6753, loss = 0.67380 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:15:56.495097 ops/training.py:65 2019-01-16 10:15:56.495037: step 6754, loss = 0.66884 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:15:57.459773 ops/training.py:65 2019-01-16 10:15:57.459708: step 6755, loss = 0.67707 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:15:58.421766 ops/training.py:65 2019-01-16 10:15:58.421707: step 6756, loss = 0.68691 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:15:59.386551 ops/training.py:65 2019-01-16 10:15:59.386494: step 6757, loss = 0.69651 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:16:00.348632 ops/training.py:65 2019-01-16 10:16:00.348574: step 6758, loss = 0.68765 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:16:01.309831 ops/training.py:65 2019-01-16 10:16:01.309795: step 6759, loss = 0.70762 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:16:02.270353 ops/training.py:65 2019-01-16 10:16:02.270308: step 6760, loss = 0.69776 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:16:03.231136 ops/training.py:65 2019-01-16 10:16:03.231085: step 6761, loss = 0.72400 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:16:04.192014 ops/training.py:65 2019-01-16 10:16:04.191974: step 6762, loss = 0.71510 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:16:05.153079 ops/training.py:65 2019-01-16 10:16:05.153026: step 6763, loss = 0.73643 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:16:06.117226 ops/training.py:65 2019-01-16 10:16:06.117179: step 6764, loss = 0.74561 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:16:07.080111 ops/training.py:65 2019-01-16 10:16:07.080057: step 6765, loss = 0.71338 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:16:08.040489 ops/training.py:65 2019-01-16 10:16:08.040435: step 6766, loss = 0.73837 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:16:09.003123 ops/training.py:65 2019-01-16 10:16:09.003068: step 6767, loss = 0.71058 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:16:09.966422 ops/training.py:65 2019-01-16 10:16:09.966371: step 6768, loss = 0.71021 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:16:10.929556 ops/training.py:65 2019-01-16 10:16:10.929485: step 6769, loss = 0.71747 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:16:11.891450 ops/training.py:65 2019-01-16 10:16:11.891377: step 6770, loss = 0.70069 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:16:12.852904 ops/training.py:65 2019-01-16 10:16:12.852824: step 6771, loss = 0.69574 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:16:13.815054 ops/training.py:65 2019-01-16 10:16:13.815006: step 6772, loss = 0.67406 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:16:14.776474 ops/training.py:65 2019-01-16 10:16:14.776425: step 6773, loss = 0.68543 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:16:15.739034 ops/training.py:65 2019-01-16 10:16:15.738977: step 6774, loss = 0.69175 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:16:16.702889 ops/training.py:65 2019-01-16 10:16:16.702836: step 6775, loss = 0.67610 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:16:17.665911 ops/training.py:65 2019-01-16 10:16:17.665848: step 6776, loss = 0.70418 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:16:18.630721 ops/training.py:65 2019-01-16 10:16:18.630653: step 6777, loss = 0.67593 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:16:19.593197 ops/training.py:65 2019-01-16 10:16:19.593124: step 6778, loss = 0.68849 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:16:20.557681 ops/training.py:65 2019-01-16 10:16:20.557633: step 6779, loss = 0.70022 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:16:21.520087 ops/training.py:65 2019-01-16 10:16:21.520033: step 6780, loss = 0.69750 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:16:22.480831 ops/training.py:65 2019-01-16 10:16:22.480755: step 6781, loss = 0.69856 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:16:23.442944 ops/training.py:65 2019-01-16 10:16:23.442869: step 6782, loss = 0.67139 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:16:24.404633 ops/training.py:65 2019-01-16 10:16:24.404564: step 6783, loss = 0.68941 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:16:25.366230 ops/training.py:65 2019-01-16 10:16:25.366165: step 6784, loss = 0.67255 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:16:26.325990 ops/training.py:65 2019-01-16 10:16:26.325916: step 6785, loss = 0.67469 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:16:27.284811 ops/training.py:65 2019-01-16 10:16:27.284744: step 6786, loss = 0.72673 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:16:28.245506 ops/training.py:65 2019-01-16 10:16:28.245454: step 6787, loss = 0.68483 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:16:29.206102 ops/training.py:65 2019-01-16 10:16:29.206046: step 6788, loss = 0.68646 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:16:30.169320 ops/training.py:65 2019-01-16 10:16:30.169255: step 6789, loss = 0.69294 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:16:31.131126 ops/training.py:65 2019-01-16 10:16:31.131055: step 6790, loss = 0.70332 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:16:32.092070 ops/training.py:65 2019-01-16 10:16:32.092002: step 6791, loss = 0.68903 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:16:33.052519 ops/training.py:65 2019-01-16 10:16:33.052470: step 6792, loss = 0.68855 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:16:34.014214 ops/training.py:65 2019-01-16 10:16:34.014146: step 6793, loss = 0.67644 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:16:34.975622 ops/training.py:65 2019-01-16 10:16:34.975550: step 6794, loss = 0.69381 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:16:35.936483 ops/training.py:65 2019-01-16 10:16:35.936417: step 6795, loss = 0.69806 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:16:36.896411 ops/training.py:65 2019-01-16 10:16:36.896359: step 6796, loss = 0.69665 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:16:37.859920 ops/training.py:65 2019-01-16 10:16:37.859864: step 6797, loss = 0.70868 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:16:38.823772 ops/training.py:65 2019-01-16 10:16:38.823711: step 6798, loss = 0.66412 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:16:39.786501 ops/training.py:65 2019-01-16 10:16:39.786441: step 6799, loss = 0.70234 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:16:40.750346 ops/training.py:65 2019-01-16 10:16:40.750289: step 6800, loss = 0.69624 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:16:41.711845 ops/training.py:65 2019-01-16 10:16:41.711786: step 6801, loss = 0.69496 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:16:42.673686 ops/training.py:65 2019-01-16 10:16:42.673636: step 6802, loss = 0.69014 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:16:43.636592 ops/training.py:65 2019-01-16 10:16:43.636530: step 6803, loss = 0.67958 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:16:44.599065 ops/training.py:65 2019-01-16 10:16:44.599005: step 6804, loss = 0.68509 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:16:45.560278 ops/training.py:65 2019-01-16 10:16:45.560225: step 6805, loss = 0.70343 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:16:46.521011 ops/training.py:65 2019-01-16 10:16:46.520957: step 6806, loss = 0.70905 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:16:47.481572 ops/training.py:65 2019-01-16 10:16:47.481512: step 6807, loss = 0.67682 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:16:48.443250 ops/training.py:65 2019-01-16 10:16:48.443199: step 6808, loss = 0.68357 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:16:49.405309 ops/training.py:65 2019-01-16 10:16:49.405253: step 6809, loss = 0.71757 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:16:50.367462 ops/training.py:65 2019-01-16 10:16:50.367399: step 6810, loss = 0.68313 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:16:51.330431 ops/training.py:65 2019-01-16 10:16:51.330378: step 6811, loss = 0.69586 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:16:52.291269 ops/training.py:65 2019-01-16 10:16:52.291220: step 6812, loss = 0.67661 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:16:53.252112 ops/training.py:65 2019-01-16 10:16:53.252065: step 6813, loss = 0.69326 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:16:54.211800 ops/training.py:65 2019-01-16 10:16:54.211752: step 6814, loss = 0.69938 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:16:55.170647 ops/training.py:65 2019-01-16 10:16:55.170598: step 6815, loss = 0.69758 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:16:56.132911 ops/training.py:65 2019-01-16 10:16:56.132853: step 6816, loss = 0.70043 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:16:57.095271 ops/training.py:65 2019-01-16 10:16:57.095221: step 6817, loss = 0.65598 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:16:58.057075 ops/training.py:65 2019-01-16 10:16:58.057022: step 6818, loss = 0.69341 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:16:59.019634 ops/training.py:65 2019-01-16 10:16:59.019581: step 6819, loss = 0.69601 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:16:59.982669 ops/training.py:65 2019-01-16 10:16:59.982611: step 6820, loss = 0.69991 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:17:00.945374 ops/training.py:65 2019-01-16 10:17:00.945315: step 6821, loss = 0.70044 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:17:01.909104 ops/training.py:65 2019-01-16 10:17:01.909058: step 6822, loss = 0.69877 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:17:02.872004 ops/training.py:65 2019-01-16 10:17:02.871947: step 6823, loss = 0.68949 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:17:03.835965 ops/training.py:65 2019-01-16 10:17:03.835914: step 6824, loss = 0.70722 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:17:04.799529 ops/training.py:65 2019-01-16 10:17:04.799482: step 6825, loss = 0.68638 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:17:05.762134 ops/training.py:65 2019-01-16 10:17:05.762079: step 6826, loss = 0.67443 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:17:06.725305 ops/training.py:65 2019-01-16 10:17:06.725247: step 6827, loss = 0.70108 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:17:07.687863 ops/training.py:65 2019-01-16 10:17:07.687792: step 6828, loss = 0.67178 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:17:08.650911 ops/training.py:65 2019-01-16 10:17:08.650853: step 6829, loss = 0.68978 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:17:09.612543 ops/training.py:65 2019-01-16 10:17:09.612481: step 6830, loss = 0.70278 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:17:10.575616 ops/training.py:65 2019-01-16 10:17:10.575566: step 6831, loss = 0.70222 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:17:11.537892 ops/training.py:65 2019-01-16 10:17:11.537818: step 6832, loss = 0.70540 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:17:12.501324 ops/training.py:65 2019-01-16 10:17:12.501246: step 6833, loss = 0.68399 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:17:13.465703 ops/training.py:65 2019-01-16 10:17:13.465636: step 6834, loss = 0.72043 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:17:14.426219 ops/training.py:65 2019-01-16 10:17:14.426171: step 6835, loss = 0.68590 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:17:15.388989 ops/training.py:65 2019-01-16 10:17:15.388935: step 6836, loss = 0.68612 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:17:16.351140 ops/training.py:65 2019-01-16 10:17:16.351087: step 6837, loss = 0.68013 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:17:17.313375 ops/training.py:65 2019-01-16 10:17:17.313312: step 6838, loss = 0.68734 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:17:18.277806 ops/training.py:65 2019-01-16 10:17:18.277759: step 6839, loss = 0.68766 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:17:19.240127 ops/training.py:65 2019-01-16 10:17:19.240074: step 6840, loss = 0.68938 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:17:20.204603 ops/training.py:65 2019-01-16 10:17:20.204543: step 6841, loss = 0.69645 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:17:21.165519 ops/training.py:65 2019-01-16 10:17:21.165442: step 6842, loss = 0.67500 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:17:22.129762 ops/training.py:65 2019-01-16 10:17:22.129694: step 6843, loss = 0.69365 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:17:23.093282 ops/training.py:65 2019-01-16 10:17:23.093215: step 6844, loss = 0.69231 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:17:24.056329 ops/training.py:65 2019-01-16 10:17:24.056279: step 6845, loss = 0.66828 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:17:25.018521 ops/training.py:65 2019-01-16 10:17:25.018447: step 6846, loss = 0.66264 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:17:25.981112 ops/training.py:65 2019-01-16 10:17:25.981040: step 6847, loss = 0.67883 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:17:26.945039 ops/training.py:65 2019-01-16 10:17:26.944977: step 6848, loss = 0.67784 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:17:27.908059 ops/training.py:65 2019-01-16 10:17:27.908006: step 6849, loss = 0.69216 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:17:28.870519 ops/training.py:65 2019-01-16 10:17:28.870464: step 6850, loss = 0.66969 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:17:29.832205 ops/training.py:65 2019-01-16 10:17:29.832156: step 6851, loss = 0.67610 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:17:30.793324 ops/training.py:65 2019-01-16 10:17:30.793275: step 6852, loss = 0.70514 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:17:31.758050 ops/training.py:65 2019-01-16 10:17:31.758002: step 6853, loss = 0.73417 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:17:32.721810 ops/training.py:65 2019-01-16 10:17:32.721739: step 6854, loss = 0.68149 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:17:33.683178 ops/training.py:65 2019-01-16 10:17:33.683108: step 6855, loss = 0.68019 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:17:34.644193 ops/training.py:65 2019-01-16 10:17:34.644127: step 6856, loss = 0.70253 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:17:35.604312 ops/training.py:65 2019-01-16 10:17:35.604247: step 6857, loss = 0.69594 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:17:36.565446 ops/training.py:65 2019-01-16 10:17:36.565391: step 6858, loss = 0.68048 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:17:37.528579 ops/training.py:65 2019-01-16 10:17:37.528522: step 6859, loss = 0.72562 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:17:38.489887 ops/training.py:65 2019-01-16 10:17:38.489815: step 6860, loss = 0.72393 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:17:39.453052 ops/training.py:65 2019-01-16 10:17:39.452985: step 6861, loss = 0.71011 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:17:40.414304 ops/training.py:65 2019-01-16 10:17:40.414255: step 6862, loss = 0.71450 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:17:41.376162 ops/training.py:65 2019-01-16 10:17:41.376093: step 6863, loss = 0.70576 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:17:42.337317 ops/training.py:65 2019-01-16 10:17:42.337245: step 6864, loss = 0.69944 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:17:43.296954 ops/training.py:65 2019-01-16 10:17:43.296885: step 6865, loss = 0.72627 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:17:44.260146 ops/training.py:65 2019-01-16 10:17:44.260083: step 6866, loss = 0.69536 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:17:45.222955 ops/training.py:65 2019-01-16 10:17:45.222903: step 6867, loss = 0.70616 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:17:46.185269 ops/training.py:65 2019-01-16 10:17:46.185215: step 6868, loss = 0.68523 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:17:47.145973 ops/training.py:65 2019-01-16 10:17:47.145905: step 6869, loss = 0.68926 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:17:48.106787 ops/training.py:65 2019-01-16 10:17:48.106719: step 6870, loss = 0.71143 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:17:49.066968 ops/training.py:65 2019-01-16 10:17:49.066896: step 6871, loss = 0.70652 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:17:50.027897 ops/training.py:65 2019-01-16 10:17:50.027828: step 6872, loss = 0.65919 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:17:50.988310 ops/training.py:65 2019-01-16 10:17:50.988246: step 6873, loss = 0.70127 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:17:51.949579 ops/training.py:65 2019-01-16 10:17:51.949510: step 6874, loss = 0.65523 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:17:52.910018 ops/training.py:65 2019-01-16 10:17:52.909969: step 6875, loss = 0.69725 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:17:53.872335 ops/training.py:65 2019-01-16 10:17:53.872271: step 6876, loss = 0.71249 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:17:54.832255 ops/training.py:65 2019-01-16 10:17:54.832192: step 6877, loss = 0.71477 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:17:55.797265 ops/training.py:65 2019-01-16 10:17:55.797204: step 6878, loss = 0.71650 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:17:56.760522 ops/training.py:65 2019-01-16 10:17:56.760480: step 6879, loss = 0.68469 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:17:57.723816 ops/training.py:65 2019-01-16 10:17:57.723753: step 6880, loss = 0.65067 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:17:58.684887 ops/training.py:65 2019-01-16 10:17:58.684812: step 6881, loss = 0.68868 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:17:59.645603 ops/training.py:65 2019-01-16 10:17:59.645532: step 6882, loss = 0.67973 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:18:00.609725 ops/training.py:65 2019-01-16 10:18:00.609665: step 6883, loss = 0.67530 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:18:01.572725 ops/training.py:65 2019-01-16 10:18:01.572675: step 6884, loss = 0.70178 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:18:02.533396 ops/training.py:65 2019-01-16 10:18:02.533338: step 6885, loss = 0.64909 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:18:03.498005 ops/training.py:65 2019-01-16 10:18:03.497941: step 6886, loss = 0.70054 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:18:04.461141 ops/training.py:65 2019-01-16 10:18:04.461088: step 6887, loss = 0.67894 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:18:05.421806 ops/training.py:65 2019-01-16 10:18:05.421751: step 6888, loss = 0.66527 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:18:06.383705 ops/training.py:65 2019-01-16 10:18:06.383653: step 6889, loss = 0.64934 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:18:07.348376 ops/training.py:65 2019-01-16 10:18:07.348328: step 6890, loss = 0.68367 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:18:08.313110 ops/training.py:65 2019-01-16 10:18:08.313044: step 6891, loss = 0.71563 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:18:09.277731 ops/training.py:65 2019-01-16 10:18:09.277664: step 6892, loss = 0.71638 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:18:10.240397 ops/training.py:65 2019-01-16 10:18:10.240343: step 6893, loss = 0.69544 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:18:11.201837 ops/training.py:65 2019-01-16 10:18:11.201787: step 6894, loss = 0.68556 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:18:12.163891 ops/training.py:65 2019-01-16 10:18:12.163821: step 6895, loss = 0.72293 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:18:13.125591 ops/training.py:65 2019-01-16 10:18:13.125538: step 6896, loss = 0.72755 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:18:14.087159 ops/training.py:65 2019-01-16 10:18:14.087103: step 6897, loss = 0.66907 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:18:15.051032 ops/training.py:65 2019-01-16 10:18:15.050979: step 6898, loss = 0.71022 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:18:16.015163 ops/training.py:65 2019-01-16 10:18:16.015116: step 6899, loss = 0.70809 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:18:16.978969 ops/training.py:65 2019-01-16 10:18:16.978918: step 6900, loss = 0.70521 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:18:17.939817 ops/training.py:65 2019-01-16 10:18:17.939745: step 6901, loss = 0.69382 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:18:18.904306 ops/training.py:65 2019-01-16 10:18:18.904239: step 6902, loss = 0.70071 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:18:19.868281 ops/training.py:65 2019-01-16 10:18:19.868213: step 6903, loss = 0.70200 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:18:20.832108 ops/training.py:65 2019-01-16 10:18:20.832042: step 6904, loss = 0.66982 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:18:21.794215 ops/training.py:65 2019-01-16 10:18:21.794168: step 6905, loss = 0.67954 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:18:22.755943 ops/training.py:65 2019-01-16 10:18:22.755895: step 6906, loss = 0.69717 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:18:23.718276 ops/training.py:65 2019-01-16 10:18:23.718227: step 6907, loss = 0.65719 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:18:24.677867 ops/training.py:65 2019-01-16 10:18:24.677796: step 6908, loss = 0.71236 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:18:25.642490 ops/training.py:65 2019-01-16 10:18:25.642436: step 6909, loss = 0.68526 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:18:26.604716 ops/training.py:65 2019-01-16 10:18:26.604676: step 6910, loss = 0.70352 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:18:27.568281 ops/training.py:65 2019-01-16 10:18:27.568241: step 6911, loss = 0.71511 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:18:28.531070 ops/training.py:65 2019-01-16 10:18:28.531013: step 6912, loss = 0.65637 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:18:29.493137 ops/training.py:65 2019-01-16 10:18:29.493093: step 6913, loss = 0.70895 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:18:30.453857 ops/training.py:65 2019-01-16 10:18:30.453809: step 6914, loss = 0.69369 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:18:31.414335 ops/training.py:65 2019-01-16 10:18:31.414284: step 6915, loss = 0.70310 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:18:32.379036 ops/training.py:65 2019-01-16 10:18:32.378972: step 6916, loss = 0.67359 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:18:33.343137 ops/training.py:65 2019-01-16 10:18:33.343071: step 6917, loss = 0.70072 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:18:34.306302 ops/training.py:65 2019-01-16 10:18:34.306255: step 6918, loss = 0.68805 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:18:35.268269 ops/training.py:65 2019-01-16 10:18:35.268211: step 6919, loss = 0.69095 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:18:36.229785 ops/training.py:65 2019-01-16 10:18:36.229723: step 6920, loss = 0.71496 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:18:37.192333 ops/training.py:65 2019-01-16 10:18:37.192263: step 6921, loss = 0.69127 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:18:38.154195 ops/training.py:65 2019-01-16 10:18:38.154148: step 6922, loss = 0.68951 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:18:39.115514 ops/training.py:65 2019-01-16 10:18:39.115457: step 6923, loss = 0.70248 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:18:40.077095 ops/training.py:65 2019-01-16 10:18:40.077028: step 6924, loss = 0.73835 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 10:18:41.039028 ops/training.py:65 2019-01-16 10:18:41.038960: step 6925, loss = 0.72693 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:18:42.001789 ops/training.py:65 2019-01-16 10:18:42.001718: step 6926, loss = 0.67379 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:18:42.963535 ops/training.py:65 2019-01-16 10:18:42.963468: step 6927, loss = 0.69227 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:18:43.924409 ops/training.py:65 2019-01-16 10:18:43.924360: step 6928, loss = 0.68855 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:18:44.888509 ops/training.py:65 2019-01-16 10:18:44.888441: step 6929, loss = 0.69414 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:18:45.851639 ops/training.py:65 2019-01-16 10:18:45.851571: step 6930, loss = 0.69955 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:18:46.813732 ops/training.py:65 2019-01-16 10:18:46.813668: step 6931, loss = 0.71415 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:18:47.774580 ops/training.py:65 2019-01-16 10:18:47.774509: step 6932, loss = 0.67772 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:18:48.736676 ops/training.py:65 2019-01-16 10:18:48.736609: step 6933, loss = 0.70542 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:18:49.697884 ops/training.py:65 2019-01-16 10:18:49.697828: step 6934, loss = 0.68885 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:18:50.662376 ops/training.py:65 2019-01-16 10:18:50.662306: step 6935, loss = 0.70225 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:18:51.625852 ops/training.py:65 2019-01-16 10:18:51.625779: step 6936, loss = 0.70060 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:18:52.589308 ops/training.py:65 2019-01-16 10:18:52.589252: step 6937, loss = 0.68835 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:18:53.550916 ops/training.py:65 2019-01-16 10:18:53.550868: step 6938, loss = 0.70788 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:18:54.512273 ops/training.py:65 2019-01-16 10:18:54.512208: step 6939, loss = 0.70990 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:18:55.473379 ops/training.py:65 2019-01-16 10:18:55.473311: step 6940, loss = 0.69761 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:18:56.434936 ops/training.py:65 2019-01-16 10:18:56.434863: step 6941, loss = 0.71251 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:18:57.396356 ops/training.py:65 2019-01-16 10:18:57.396289: step 6942, loss = 0.69672 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:18:58.358848 ops/training.py:65 2019-01-16 10:18:58.358781: step 6943, loss = 0.71024 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:18:59.320958 ops/training.py:65 2019-01-16 10:18:59.320891: step 6944, loss = 0.68475 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:19:00.283251 ops/training.py:65 2019-01-16 10:19:00.283179: step 6945, loss = 0.68433 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:19:01.243863 ops/training.py:65 2019-01-16 10:19:01.243807: step 6946, loss = 0.69440 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:19:02.207784 ops/training.py:65 2019-01-16 10:19:02.207731: step 6947, loss = 0.69923 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:19:03.170715 ops/training.py:65 2019-01-16 10:19:03.170655: step 6948, loss = 0.67929 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:19:04.134348 ops/training.py:65 2019-01-16 10:19:04.134277: step 6949, loss = 0.67185 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:19:05.095167 ops/training.py:65 2019-01-16 10:19:05.095100: step 6950, loss = 0.68636 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:19:06.055278 ops/training.py:65 2019-01-16 10:19:06.055213: step 6951, loss = 0.72384 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:19:07.016612 ops/training.py:65 2019-01-16 10:19:07.016561: step 6952, loss = 0.70917 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:19:07.977447 ops/training.py:65 2019-01-16 10:19:07.977396: step 6953, loss = 0.68692 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:19:08.939195 ops/training.py:65 2019-01-16 10:19:08.939144: step 6954, loss = 0.67389 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:19:09.900182 ops/training.py:65 2019-01-16 10:19:09.900133: step 6955, loss = 0.71013 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:19:10.861071 ops/training.py:65 2019-01-16 10:19:10.861022: step 6956, loss = 0.69477 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:19:11.823511 ops/training.py:65 2019-01-16 10:19:11.823461: step 6957, loss = 0.71700 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:19:12.784681 ops/training.py:65 2019-01-16 10:19:12.784632: step 6958, loss = 0.70887 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:19:13.745197 ops/training.py:65 2019-01-16 10:19:13.745144: step 6959, loss = 0.71160 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:19:14.705728 ops/training.py:65 2019-01-16 10:19:14.705662: step 6960, loss = 0.68656 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:19:15.666774 ops/training.py:65 2019-01-16 10:19:15.666706: step 6961, loss = 0.69827 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:19:16.627925 ops/training.py:65 2019-01-16 10:19:16.627854: step 6962, loss = 0.71840 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:19:17.588803 ops/training.py:65 2019-01-16 10:19:17.588736: step 6963, loss = 0.69726 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:19:18.550194 ops/training.py:65 2019-01-16 10:19:18.550122: step 6964, loss = 0.73035 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:19:19.511883 ops/training.py:65 2019-01-16 10:19:19.511830: step 6965, loss = 0.66473 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:19:20.473391 ops/training.py:65 2019-01-16 10:19:20.473327: step 6966, loss = 0.70198 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:19:21.434475 ops/training.py:65 2019-01-16 10:19:21.434403: step 6967, loss = 0.77074 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 10:19:22.393739 ops/training.py:65 2019-01-16 10:19:22.393699: step 6968, loss = 0.68113 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:19:23.353996 ops/training.py:65 2019-01-16 10:19:23.353928: step 6969, loss = 0.66032 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:19:24.317286 ops/training.py:65 2019-01-16 10:19:24.317222: step 6970, loss = 0.69028 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:19:25.279848 ops/training.py:65 2019-01-16 10:19:25.279773: step 6971, loss = 0.73535 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:19:26.241612 ops/training.py:65 2019-01-16 10:19:26.241560: step 6972, loss = 0.62905 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:19:27.204349 ops/training.py:65 2019-01-16 10:19:27.204284: step 6973, loss = 0.74534 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:19:28.167079 ops/training.py:65 2019-01-16 10:19:28.167018: step 6974, loss = 0.67735 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:19:29.130265 ops/training.py:65 2019-01-16 10:19:29.130215: step 6975, loss = 0.67039 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:19:30.091078 ops/training.py:65 2019-01-16 10:19:30.091026: step 6976, loss = 0.71805 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:19:31.054702 ops/training.py:65 2019-01-16 10:19:31.054649: step 6977, loss = 0.72255 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:19:32.016518 ops/training.py:65 2019-01-16 10:19:32.016472: step 6978, loss = 0.70097 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:19:32.977133 ops/training.py:65 2019-01-16 10:19:32.977069: step 6979, loss = 0.66065 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:19:33.938084 ops/training.py:65 2019-01-16 10:19:33.938020: step 6980, loss = 0.69366 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:19:34.900368 ops/training.py:65 2019-01-16 10:19:34.900305: step 6981, loss = 0.65057 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:19:35.862721 ops/training.py:65 2019-01-16 10:19:35.862677: step 6982, loss = 0.67382 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:19:36.823485 ops/training.py:65 2019-01-16 10:19:36.823421: step 6983, loss = 0.72644 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:19:37.785265 ops/training.py:65 2019-01-16 10:19:37.785198: step 6984, loss = 0.67838 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:19:38.746745 ops/training.py:65 2019-01-16 10:19:38.746701: step 6985, loss = 0.69832 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:19:39.708472 ops/training.py:65 2019-01-16 10:19:39.708429: step 6986, loss = 0.73309 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:19:40.669342 ops/training.py:65 2019-01-16 10:19:40.669283: step 6987, loss = 0.71033 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:19:41.631073 ops/training.py:65 2019-01-16 10:19:41.631033: step 6988, loss = 0.74293 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:19:42.591826 ops/training.py:65 2019-01-16 10:19:42.591769: step 6989, loss = 0.62179 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:19:43.553491 ops/training.py:65 2019-01-16 10:19:43.553432: step 6990, loss = 0.80785 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:19:44.515929 ops/training.py:65 2019-01-16 10:19:44.515870: step 6991, loss = 0.82962 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:19:45.477293 ops/training.py:65 2019-01-16 10:19:45.477234: step 6992, loss = 0.72459 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:19:46.438778 ops/training.py:65 2019-01-16 10:19:46.438720: step 6993, loss = 0.83476 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:19:47.399722 ops/training.py:65 2019-01-16 10:19:47.399665: step 6994, loss = 0.79487 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:19:48.361209 ops/training.py:65 2019-01-16 10:19:48.361151: step 6995, loss = 0.78740 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:19:49.322115 ops/training.py:65 2019-01-16 10:19:49.322060: step 6996, loss = 0.68378 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:19:50.283382 ops/training.py:65 2019-01-16 10:19:50.283324: step 6997, loss = 0.72176 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:19:51.243590 ops/training.py:65 2019-01-16 10:19:51.243514: step 6998, loss = 0.67696 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:19:52.207134 ops/training.py:65 2019-01-16 10:19:52.207068: step 6999, loss = 0.80184 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:19:53.170926 ops/training.py:65 2019-01-16 10:19:53.170862: step 7000, loss = 0.74070 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:19:54.133447 ops/training.py:65 2019-01-16 10:19:54.133376: step 7001, loss = 0.68719 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:19:55.097986 ops/training.py:65 2019-01-16 10:19:55.097920: step 7002, loss = 0.73708 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:19:56.060153 ops/training.py:65 2019-01-16 10:19:56.060093: step 7003, loss = 0.68133 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:19:57.021958 ops/training.py:65 2019-01-16 10:19:57.021897: step 7004, loss = 0.70953 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:19:57.982362 ops/training.py:65 2019-01-16 10:19:57.982300: step 7005, loss = 0.70949 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:19:58.944319 ops/training.py:65 2019-01-16 10:19:58.944258: step 7006, loss = 0.67407 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:19:59.905658 ops/training.py:65 2019-01-16 10:19:59.905594: step 7007, loss = 0.61912 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:20:00.866276 ops/training.py:65 2019-01-16 10:20:00.866216: step 7008, loss = 0.77296 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:20:01.826715 ops/training.py:65 2019-01-16 10:20:01.826650: step 7009, loss = 0.68814 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:20:02.787192 ops/training.py:65 2019-01-16 10:20:02.787117: step 7010, loss = 0.71734 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:20:03.749490 ops/training.py:65 2019-01-16 10:20:03.749413: step 7011, loss = 0.73308 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:20:04.714443 ops/training.py:65 2019-01-16 10:20:04.714375: step 7012, loss = 0.68664 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:20:05.676892 ops/training.py:65 2019-01-16 10:20:05.676821: step 7013, loss = 0.70776 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:20:06.640745 ops/training.py:65 2019-01-16 10:20:06.640672: step 7014, loss = 0.77919 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:20:07.602884 ops/training.py:65 2019-01-16 10:20:07.602812: step 7015, loss = 0.68683 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:20:08.565568 ops/training.py:65 2019-01-16 10:20:08.565510: step 7016, loss = 0.67786 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:20:09.525601 ops/training.py:65 2019-01-16 10:20:09.525528: step 7017, loss = 0.74797 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:20:10.485220 ops/training.py:65 2019-01-16 10:20:10.485172: step 7018, loss = 0.66207 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:20:11.445531 ops/training.py:65 2019-01-16 10:20:11.445478: step 7019, loss = 0.76584 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:20:12.409800 ops/training.py:65 2019-01-16 10:20:12.409737: step 7020, loss = 0.72191 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:20:13.372333 ops/training.py:65 2019-01-16 10:20:13.372269: step 7021, loss = 0.70846 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:20:14.334421 ops/training.py:65 2019-01-16 10:20:14.334375: step 7022, loss = 0.67454 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:20:15.296812 ops/training.py:65 2019-01-16 10:20:15.296758: step 7023, loss = 0.68782 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:20:16.258449 ops/training.py:65 2019-01-16 10:20:16.258385: step 7024, loss = 0.74161 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:20:17.220024 ops/training.py:65 2019-01-16 10:20:17.219963: step 7025, loss = 0.66468 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:20:18.181817 ops/training.py:65 2019-01-16 10:20:18.181761: step 7026, loss = 0.65130 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:20:19.145260 ops/training.py:65 2019-01-16 10:20:19.145207: step 7027, loss = 0.67253 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:20:20.107006 ops/training.py:65 2019-01-16 10:20:20.106957: step 7028, loss = 0.69658 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:20:21.069384 ops/training.py:65 2019-01-16 10:20:21.069331: step 7029, loss = 0.66806 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:20:22.033443 ops/training.py:65 2019-01-16 10:20:22.033390: step 7030, loss = 0.68453 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:20:22.997263 ops/training.py:65 2019-01-16 10:20:22.997208: step 7031, loss = 0.63664 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:20:23.960209 ops/training.py:65 2019-01-16 10:20:23.960148: step 7032, loss = 0.67654 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:20:24.921832 ops/training.py:65 2019-01-16 10:20:24.921778: step 7033, loss = 0.70659 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:20:25.883826 ops/training.py:65 2019-01-16 10:20:25.883764: step 7034, loss = 0.68677 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:20:26.848516 ops/training.py:65 2019-01-16 10:20:26.848461: step 7035, loss = 0.69338 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:20:27.810812 ops/training.py:65 2019-01-16 10:20:27.810751: step 7036, loss = 0.69845 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:20:28.772523 ops/training.py:65 2019-01-16 10:20:28.772466: step 7037, loss = 0.70788 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:20:29.734393 ops/training.py:65 2019-01-16 10:20:29.734336: step 7038, loss = 0.70501 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:20:30.698849 ops/training.py:65 2019-01-16 10:20:30.698804: step 7039, loss = 0.72721 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:20:31.662036 ops/training.py:65 2019-01-16 10:20:31.661972: step 7040, loss = 0.69420 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:20:32.625832 ops/training.py:65 2019-01-16 10:20:32.625783: step 7041, loss = 0.67746 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:20:33.589930 ops/training.py:65 2019-01-16 10:20:33.589858: step 7042, loss = 0.74020 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:20:34.553136 ops/training.py:65 2019-01-16 10:20:34.553082: step 7043, loss = 0.69204 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:20:35.515331 ops/training.py:65 2019-01-16 10:20:35.515268: step 7044, loss = 0.68998 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:20:36.476366 ops/training.py:65 2019-01-16 10:20:36.476305: step 7045, loss = 0.71226 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:20:37.437616 ops/training.py:65 2019-01-16 10:20:37.437560: step 7046, loss = 0.67577 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:20:38.398129 ops/training.py:65 2019-01-16 10:20:38.398070: step 7047, loss = 0.66704 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:20:39.361538 ops/training.py:65 2019-01-16 10:20:39.361491: step 7048, loss = 0.67949 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:20:40.324969 ops/training.py:65 2019-01-16 10:20:40.324903: step 7049, loss = 0.67785 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:20:41.285774 ops/training.py:65 2019-01-16 10:20:41.285702: step 7050, loss = 0.71636 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:20:42.245702 ops/training.py:65 2019-01-16 10:20:42.245634: step 7051, loss = 0.69258 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:20:43.208121 ops/training.py:65 2019-01-16 10:20:43.208060: step 7052, loss = 0.68967 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:20:44.169954 ops/training.py:65 2019-01-16 10:20:44.169885: step 7053, loss = 0.67705 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:20:45.130813 ops/training.py:65 2019-01-16 10:20:45.130747: step 7054, loss = 0.69600 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:20:46.090788 ops/training.py:65 2019-01-16 10:20:46.090726: step 7055, loss = 0.64948 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:20:47.052855 ops/training.py:65 2019-01-16 10:20:47.052793: step 7056, loss = 0.67595 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:20:48.014355 ops/training.py:65 2019-01-16 10:20:48.014297: step 7057, loss = 0.70986 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:20:48.974619 ops/training.py:65 2019-01-16 10:20:48.974577: step 7058, loss = 0.67358 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:20:49.937091 ops/training.py:65 2019-01-16 10:20:49.937032: step 7059, loss = 0.69265 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:20:50.900549 ops/training.py:65 2019-01-16 10:20:50.900491: step 7060, loss = 0.68251 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:20:51.863498 ops/training.py:65 2019-01-16 10:20:51.863434: step 7061, loss = 0.67298 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:20:52.824794 ops/training.py:65 2019-01-16 10:20:52.824722: step 7062, loss = 0.72644 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:20:53.788192 ops/training.py:65 2019-01-16 10:20:53.788131: step 7063, loss = 0.69307 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:20:54.750122 ops/training.py:65 2019-01-16 10:20:54.750065: step 7064, loss = 0.72494 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:20:55.712045 ops/training.py:65 2019-01-16 10:20:55.711986: step 7065, loss = 0.67767 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:20:56.677418 ops/training.py:65 2019-01-16 10:20:56.677350: step 7066, loss = 0.68899 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:20:57.640264 ops/training.py:65 2019-01-16 10:20:57.640203: step 7067, loss = 0.68046 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:20:58.602842 ops/training.py:65 2019-01-16 10:20:58.602771: step 7068, loss = 0.71163 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:20:59.565162 ops/training.py:65 2019-01-16 10:20:59.565107: step 7069, loss = 0.69265 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:21:00.525907 ops/training.py:65 2019-01-16 10:21:00.525850: step 7070, loss = 0.69045 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:21:01.483863 ops/training.py:65 2019-01-16 10:21:01.483812: step 7071, loss = 0.70520 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:21:02.441427 ops/training.py:65 2019-01-16 10:21:02.441366: step 7072, loss = 0.70263 (33.5 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:21:03.400715 ops/training.py:65 2019-01-16 10:21:03.400643: step 7073, loss = 0.67209 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:21:04.363785 ops/training.py:65 2019-01-16 10:21:04.363726: step 7074, loss = 0.74630 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:21:05.324633 ops/training.py:65 2019-01-16 10:21:05.324576: step 7075, loss = 0.68146 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:21:06.285948 ops/training.py:65 2019-01-16 10:21:06.285889: step 7076, loss = 0.69500 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:21:07.251729 ops/training.py:65 2019-01-16 10:21:07.251671: step 7077, loss = 0.67989 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:21:08.214498 ops/training.py:65 2019-01-16 10:21:08.214446: step 7078, loss = 0.64333 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:21:09.177098 ops/training.py:65 2019-01-16 10:21:09.177039: step 7079, loss = 0.66502 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:21:10.138903 ops/training.py:65 2019-01-16 10:21:10.138847: step 7080, loss = 0.69185 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:21:11.099721 ops/training.py:65 2019-01-16 10:21:11.099666: step 7081, loss = 0.72060 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:21:12.060825 ops/training.py:65 2019-01-16 10:21:12.060785: step 7082, loss = 0.66461 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:21:13.021187 ops/training.py:65 2019-01-16 10:21:13.021126: step 7083, loss = 0.77640 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 10:21:13.982200 ops/training.py:65 2019-01-16 10:21:13.982143: step 7084, loss = 0.65111 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:21:14.943285 ops/training.py:65 2019-01-16 10:21:14.943244: step 7085, loss = 0.65558 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:21:15.906565 ops/training.py:65 2019-01-16 10:21:15.906494: step 7086, loss = 0.75007 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:21:16.866551 ops/training.py:65 2019-01-16 10:21:16.866487: step 7087, loss = 0.64519 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:21:17.830678 ops/training.py:65 2019-01-16 10:21:17.830606: step 7088, loss = 0.66837 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:21:18.793647 ops/training.py:65 2019-01-16 10:21:18.793596: step 7089, loss = 0.73339 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 10:21:19.753930 ops/training.py:65 2019-01-16 10:21:19.753866: step 7090, loss = 0.70516 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:21:20.715360 ops/training.py:65 2019-01-16 10:21:20.715310: step 7091, loss = 0.71319 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:21:21.677023 ops/training.py:65 2019-01-16 10:21:21.676950: step 7092, loss = 0.65146 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:21:22.639120 ops/training.py:65 2019-01-16 10:21:22.639050: step 7093, loss = 0.64060 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:21:23.601176 ops/training.py:65 2019-01-16 10:21:23.601101: step 7094, loss = 0.68540 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:21:24.565035 ops/training.py:65 2019-01-16 10:21:24.564987: step 7095, loss = 0.68435 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:21:25.527606 ops/training.py:65 2019-01-16 10:21:25.527540: step 7096, loss = 0.67326 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:21:26.490255 ops/training.py:65 2019-01-16 10:21:26.490183: step 7097, loss = 0.69254 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:21:27.452377 ops/training.py:65 2019-01-16 10:21:27.452309: step 7098, loss = 0.67664 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:21:28.416719 ops/training.py:65 2019-01-16 10:21:28.416652: step 7099, loss = 0.69422 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:21:29.380091 ops/training.py:65 2019-01-16 10:21:29.380023: step 7100, loss = 0.70880 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:21:30.342121 ops/training.py:65 2019-01-16 10:21:30.342058: step 7101, loss = 0.67104 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:21:31.302605 ops/training.py:65 2019-01-16 10:21:31.302538: step 7102, loss = 0.69992 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:21:32.263283 ops/training.py:65 2019-01-16 10:21:32.263226: step 7103, loss = 0.70950 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:21:33.224389 ops/training.py:65 2019-01-16 10:21:33.224321: step 7104, loss = 0.72440 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:21:34.185335 ops/training.py:65 2019-01-16 10:21:34.185278: step 7105, loss = 0.71691 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:21:35.146652 ops/training.py:65 2019-01-16 10:21:35.146567: step 7106, loss = 0.72074 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:21:36.110455 ops/training.py:65 2019-01-16 10:21:36.110383: step 7107, loss = 0.65482 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:21:37.073379 ops/training.py:65 2019-01-16 10:21:37.073311: step 7108, loss = 0.72593 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:21:38.036220 ops/training.py:65 2019-01-16 10:21:38.036153: step 7109, loss = 0.74255 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:21:39.000246 ops/training.py:65 2019-01-16 10:21:39.000171: step 7110, loss = 0.72763 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:21:39.962137 ops/training.py:65 2019-01-16 10:21:39.962070: step 7111, loss = 0.69250 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:21:40.922385 ops/training.py:65 2019-01-16 10:21:40.922320: step 7112, loss = 0.69682 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:21:41.883031 ops/training.py:65 2019-01-16 10:21:41.882967: step 7113, loss = 0.68694 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:21:42.846395 ops/training.py:65 2019-01-16 10:21:42.846320: step 7114, loss = 0.70322 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:21:43.809025 ops/training.py:65 2019-01-16 10:21:43.808966: step 7115, loss = 0.64947 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:21:44.773363 ops/training.py:65 2019-01-16 10:21:44.773300: step 7116, loss = 0.66643 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:21:45.736211 ops/training.py:65 2019-01-16 10:21:45.736145: step 7117, loss = 0.77744 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 10:21:46.697648 ops/training.py:65 2019-01-16 10:21:46.697579: step 7118, loss = 0.73554 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:21:47.660247 ops/training.py:65 2019-01-16 10:21:47.660173: step 7119, loss = 0.62980 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 10:21:48.623447 ops/training.py:65 2019-01-16 10:21:48.623383: step 7120, loss = 0.71532 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:21:49.585739 ops/training.py:65 2019-01-16 10:21:49.585673: step 7121, loss = 0.76572 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:21:50.547489 ops/training.py:65 2019-01-16 10:21:50.547441: step 7122, loss = 0.70057 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:21:51.511524 ops/training.py:65 2019-01-16 10:21:51.511468: step 7123, loss = 0.76769 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 10:21:52.473642 ops/training.py:65 2019-01-16 10:21:52.473585: step 7124, loss = 0.70651 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:21:53.435070 ops/training.py:65 2019-01-16 10:21:53.435004: step 7125, loss = 0.66420 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:21:54.397470 ops/training.py:65 2019-01-16 10:21:54.397416: step 7126, loss = 0.71717 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:21:55.358517 ops/training.py:65 2019-01-16 10:21:55.358453: step 7127, loss = 0.67977 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:21:56.321962 ops/training.py:65 2019-01-16 10:21:56.321899: step 7128, loss = 0.68770 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:21:57.283964 ops/training.py:65 2019-01-16 10:21:57.283900: step 7129, loss = 0.70692 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:21:58.247720 ops/training.py:65 2019-01-16 10:21:58.247663: step 7130, loss = 0.69202 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:21:59.208301 ops/training.py:65 2019-01-16 10:21:59.208234: step 7131, loss = 0.67434 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:22:00.168665 ops/training.py:65 2019-01-16 10:22:00.168602: step 7132, loss = 0.72911 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:22:01.129580 ops/training.py:65 2019-01-16 10:22:01.129522: step 7133, loss = 0.69529 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:22:02.090364 ops/training.py:65 2019-01-16 10:22:02.090311: step 7134, loss = 0.73847 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:22:03.051947 ops/training.py:65 2019-01-16 10:22:03.051877: step 7135, loss = 0.73971 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:22:04.014173 ops/training.py:65 2019-01-16 10:22:04.014095: step 7136, loss = 0.70808 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:22:04.974759 ops/training.py:65 2019-01-16 10:22:04.974691: step 7137, loss = 0.69473 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:22:05.937915 ops/training.py:65 2019-01-16 10:22:05.937867: step 7138, loss = 0.67757 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:22:06.901592 ops/training.py:65 2019-01-16 10:22:06.901545: step 7139, loss = 0.70855 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:22:07.863198 ops/training.py:65 2019-01-16 10:22:07.863140: step 7140, loss = 0.69198 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:22:08.823713 ops/training.py:65 2019-01-16 10:22:08.823666: step 7141, loss = 0.69879 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:22:09.785034 ops/training.py:65 2019-01-16 10:22:09.784992: step 7142, loss = 0.58178 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:22:10.746583 ops/training.py:65 2019-01-16 10:22:10.746530: step 7143, loss = 0.67736 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:22:11.708402 ops/training.py:65 2019-01-16 10:22:11.708357: step 7144, loss = 0.72559 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:22:12.671222 ops/training.py:65 2019-01-16 10:22:12.671182: step 7145, loss = 0.69655 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:22:13.633936 ops/training.py:65 2019-01-16 10:22:13.633898: step 7146, loss = 0.72782 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:22:14.596693 ops/training.py:65 2019-01-16 10:22:14.596656: step 7147, loss = 0.68333 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:22:15.557127 ops/training.py:65 2019-01-16 10:22:15.557061: step 7148, loss = 0.66179 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:22:16.521660 ops/training.py:65 2019-01-16 10:22:16.521619: step 7149, loss = 0.67669 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:22:17.484090 ops/training.py:65 2019-01-16 10:22:17.484030: step 7150, loss = 0.68016 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:22:18.446337 ops/training.py:65 2019-01-16 10:22:18.446277: step 7151, loss = 0.71036 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:22:19.407420 ops/training.py:65 2019-01-16 10:22:19.407359: step 7152, loss = 0.71223 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:22:20.368198 ops/training.py:65 2019-01-16 10:22:20.368134: step 7153, loss = 0.62470 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:22:21.328260 ops/training.py:65 2019-01-16 10:22:21.328212: step 7154, loss = 0.67005 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:22:22.288006 ops/training.py:65 2019-01-16 10:22:22.287964: step 7155, loss = 0.71970 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:22:23.247991 ops/training.py:65 2019-01-16 10:22:23.247954: step 7156, loss = 0.67092 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:22:24.208890 ops/training.py:65 2019-01-16 10:22:24.208836: step 7157, loss = 0.68561 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:22:25.170386 ops/training.py:65 2019-01-16 10:22:25.170346: step 7158, loss = 0.66489 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:22:26.131889 ops/training.py:65 2019-01-16 10:22:26.131817: step 7159, loss = 0.66307 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:22:27.095975 ops/training.py:65 2019-01-16 10:22:27.095913: step 7160, loss = 0.68577 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:22:28.057979 ops/training.py:65 2019-01-16 10:22:28.057914: step 7161, loss = 0.68828 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:22:29.020289 ops/training.py:65 2019-01-16 10:22:29.020225: step 7162, loss = 0.67020 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:22:29.983135 ops/training.py:65 2019-01-16 10:22:29.983089: step 7163, loss = 0.65572 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:22:30.945870 ops/training.py:65 2019-01-16 10:22:30.945798: step 7164, loss = 0.67307 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:22:31.907887 ops/training.py:65 2019-01-16 10:22:31.907818: step 7165, loss = 0.70016 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:22:32.871691 ops/training.py:65 2019-01-16 10:22:32.871634: step 7166, loss = 0.72482 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:22:33.833356 ops/training.py:65 2019-01-16 10:22:33.833292: step 7167, loss = 0.66502 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:22:34.795932 ops/training.py:65 2019-01-16 10:22:34.795861: step 7168, loss = 0.66496 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:22:35.760118 ops/training.py:65 2019-01-16 10:22:35.760049: step 7169, loss = 0.69940 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:22:36.723246 ops/training.py:65 2019-01-16 10:22:36.723177: step 7170, loss = 0.67305 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:22:37.686468 ops/training.py:65 2019-01-16 10:22:37.686366: step 7171, loss = 0.67720 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:22:38.650223 ops/training.py:65 2019-01-16 10:22:38.650158: step 7172, loss = 0.67537 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:22:39.612199 ops/training.py:65 2019-01-16 10:22:39.612132: step 7173, loss = 0.66762 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:22:40.573610 ops/training.py:65 2019-01-16 10:22:40.573545: step 7174, loss = 0.71516 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:22:41.536652 ops/training.py:65 2019-01-16 10:22:41.536584: step 7175, loss = 0.66220 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:22:42.499849 ops/training.py:65 2019-01-16 10:22:42.499778: step 7176, loss = 0.70077 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:22:43.489088 ops/training.py:65 2019-01-16 10:22:43.489020: step 7177, loss = 0.70305 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:22:44.450423 ops/training.py:65 2019-01-16 10:22:44.450360: step 7178, loss = 0.71758 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:22:45.411692 ops/training.py:65 2019-01-16 10:22:45.411620: step 7179, loss = 0.69626 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:22:46.375229 ops/training.py:65 2019-01-16 10:22:46.375162: step 7180, loss = 0.70236 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:22:47.338183 ops/training.py:65 2019-01-16 10:22:47.338116: step 7181, loss = 0.69110 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:22:48.299628 ops/training.py:65 2019-01-16 10:22:48.299567: step 7182, loss = 0.71478 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:22:49.264053 ops/training.py:65 2019-01-16 10:22:49.263987: step 7183, loss = 0.69262 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:22:50.226405 ops/training.py:65 2019-01-16 10:22:50.226335: step 7184, loss = 0.67470 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:22:51.188516 ops/training.py:65 2019-01-16 10:22:51.188443: step 7185, loss = 0.68638 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:22:52.149126 ops/training.py:65 2019-01-16 10:22:52.149055: step 7186, loss = 0.70168 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:22:53.112471 ops/training.py:65 2019-01-16 10:22:53.112418: step 7187, loss = 0.68473 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:22:54.074570 ops/training.py:65 2019-01-16 10:22:54.074519: step 7188, loss = 0.72511 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:22:55.035889 ops/training.py:65 2019-01-16 10:22:55.035838: step 7189, loss = 0.71789 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:22:55.996938 ops/training.py:65 2019-01-16 10:22:55.996892: step 7190, loss = 0.68126 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:22:56.962071 ops/training.py:65 2019-01-16 10:22:56.962033: step 7191, loss = 0.71080 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:22:57.926177 ops/training.py:65 2019-01-16 10:22:57.926118: step 7192, loss = 0.80677 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.25
I0832 2019-01-16 10:22:58.889378 ops/training.py:65 2019-01-16 10:22:58.889314: step 7193, loss = 0.63680 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:22:59.853883 ops/training.py:65 2019-01-16 10:22:59.853832: step 7194, loss = 0.67785 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:23:00.817783 ops/training.py:65 2019-01-16 10:23:00.817734: step 7195, loss = 0.76110 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:23:01.780202 ops/training.py:65 2019-01-16 10:23:01.780152: step 7196, loss = 0.69020 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:23:02.743198 ops/training.py:65 2019-01-16 10:23:02.743119: step 7197, loss = 0.75168 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:23:03.704603 ops/training.py:65 2019-01-16 10:23:03.704531: step 7198, loss = 0.68208 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:23:04.664941 ops/training.py:65 2019-01-16 10:23:04.664867: step 7199, loss = 0.64461 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:23:05.627988 ops/training.py:65 2019-01-16 10:23:05.627922: step 7200, loss = 0.68008 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:23:06.591175 ops/training.py:65 2019-01-16 10:23:06.591099: step 7201, loss = 0.71924 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:23:07.552605 ops/training.py:65 2019-01-16 10:23:07.552538: step 7202, loss = 0.73427 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:23:08.514172 ops/training.py:65 2019-01-16 10:23:08.514107: step 7203, loss = 0.70353 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:23:09.475532 ops/training.py:65 2019-01-16 10:23:09.475464: step 7204, loss = 0.69541 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:23:10.437026 ops/training.py:65 2019-01-16 10:23:10.436947: step 7205, loss = 0.70744 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:23:11.398244 ops/training.py:65 2019-01-16 10:23:11.398169: step 7206, loss = 0.66937 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:23:12.358804 ops/training.py:65 2019-01-16 10:23:12.358735: step 7207, loss = 0.68285 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:23:13.323062 ops/training.py:65 2019-01-16 10:23:13.322994: step 7208, loss = 0.69536 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:23:14.285983 ops/training.py:65 2019-01-16 10:23:14.285916: step 7209, loss = 0.65572 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:23:15.249617 ops/training.py:65 2019-01-16 10:23:15.249542: step 7210, loss = 0.72863 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:23:16.212878 ops/training.py:65 2019-01-16 10:23:16.212806: step 7211, loss = 0.64518 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:23:17.174805 ops/training.py:65 2019-01-16 10:23:17.174737: step 7212, loss = 0.76139 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:23:18.137665 ops/training.py:65 2019-01-16 10:23:18.137601: step 7213, loss = 0.70779 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:23:19.100354 ops/training.py:65 2019-01-16 10:23:19.100283: step 7214, loss = 0.65504 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:23:20.063436 ops/training.py:65 2019-01-16 10:23:20.063377: step 7215, loss = 0.73889 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:23:21.023718 ops/training.py:65 2019-01-16 10:23:21.023658: step 7216, loss = 0.74711 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:23:21.985546 ops/training.py:65 2019-01-16 10:23:21.985492: step 7217, loss = 0.67239 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:23:22.948409 ops/training.py:65 2019-01-16 10:23:22.948333: step 7218, loss = 0.65091 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:23:23.910807 ops/training.py:65 2019-01-16 10:23:23.910733: step 7219, loss = 0.71742 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:23:24.875842 ops/training.py:65 2019-01-16 10:23:24.875772: step 7220, loss = 0.64807 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:23:25.840016 ops/training.py:65 2019-01-16 10:23:25.839943: step 7221, loss = 0.67120 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:23:26.803209 ops/training.py:65 2019-01-16 10:23:26.803140: step 7222, loss = 0.70432 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:23:27.765886 ops/training.py:65 2019-01-16 10:23:27.765814: step 7223, loss = 0.71872 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:23:28.729120 ops/training.py:65 2019-01-16 10:23:28.729055: step 7224, loss = 0.68422 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:23:29.692839 ops/training.py:65 2019-01-16 10:23:29.692773: step 7225, loss = 0.67573 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:23:30.656070 ops/training.py:65 2019-01-16 10:23:30.656007: step 7226, loss = 0.69429 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:23:31.618766 ops/training.py:65 2019-01-16 10:23:31.618697: step 7227, loss = 0.75648 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:23:32.580854 ops/training.py:65 2019-01-16 10:23:32.580799: step 7228, loss = 0.73652 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:23:33.542524 ops/training.py:65 2019-01-16 10:23:33.542457: step 7229, loss = 0.72264 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:23:34.505834 ops/training.py:65 2019-01-16 10:23:34.505771: step 7230, loss = 0.67859 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:23:35.468958 ops/training.py:65 2019-01-16 10:23:35.468893: step 7231, loss = 0.66205 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:23:36.430388 ops/training.py:65 2019-01-16 10:23:36.430320: step 7232, loss = 0.68303 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:23:37.391397 ops/training.py:65 2019-01-16 10:23:37.391331: step 7233, loss = 0.70458 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:23:38.351993 ops/training.py:65 2019-01-16 10:23:38.351935: step 7234, loss = 0.75393 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:23:39.312930 ops/training.py:65 2019-01-16 10:23:39.312864: step 7235, loss = 0.73624 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:23:40.274333 ops/training.py:65 2019-01-16 10:23:40.274264: step 7236, loss = 0.67242 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:23:41.236279 ops/training.py:65 2019-01-16 10:23:41.236207: step 7237, loss = 0.69215 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:23:42.198016 ops/training.py:65 2019-01-16 10:23:42.197944: step 7238, loss = 0.71907 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:23:43.159904 ops/training.py:65 2019-01-16 10:23:43.159841: step 7239, loss = 0.67406 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:23:44.123855 ops/training.py:65 2019-01-16 10:23:44.123778: step 7240, loss = 0.73806 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:23:45.085006 ops/training.py:65 2019-01-16 10:23:45.084948: step 7241, loss = 0.71006 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:23:46.044889 ops/training.py:65 2019-01-16 10:23:46.044832: step 7242, loss = 0.66842 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:23:47.007714 ops/training.py:65 2019-01-16 10:23:47.007662: step 7243, loss = 0.68359 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:23:47.972842 ops/training.py:65 2019-01-16 10:23:47.972774: step 7244, loss = 0.69486 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:23:48.937009 ops/training.py:65 2019-01-16 10:23:48.936942: step 7245, loss = 0.66181 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:23:49.899987 ops/training.py:65 2019-01-16 10:23:49.899914: step 7246, loss = 0.71992 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:23:50.864550 ops/training.py:65 2019-01-16 10:23:50.864487: step 7247, loss = 0.71811 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:23:51.828981 ops/training.py:65 2019-01-16 10:23:51.828916: step 7248, loss = 0.67016 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:23:52.790899 ops/training.py:65 2019-01-16 10:23:52.790829: step 7249, loss = 0.70277 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:23:53.755731 ops/training.py:65 2019-01-16 10:23:53.755666: step 7250, loss = 0.64219 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:23:54.717233 ops/training.py:65 2019-01-16 10:23:54.717165: step 7251, loss = 0.70490 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:23:55.681785 ops/training.py:65 2019-01-16 10:23:55.681722: step 7252, loss = 0.66635 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:23:56.645898 ops/training.py:65 2019-01-16 10:23:56.645827: step 7253, loss = 0.68240 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:23:57.608544 ops/training.py:65 2019-01-16 10:23:57.608475: step 7254, loss = 0.73039 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:23:58.570092 ops/training.py:65 2019-01-16 10:23:58.570029: step 7255, loss = 0.66627 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:23:59.534490 ops/training.py:65 2019-01-16 10:23:59.534436: step 7256, loss = 0.66339 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:24:00.496775 ops/training.py:65 2019-01-16 10:24:00.496709: step 7257, loss = 0.63293 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 10:24:01.459405 ops/training.py:65 2019-01-16 10:24:01.459349: step 7258, loss = 0.69722 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:24:02.420294 ops/training.py:65 2019-01-16 10:24:02.420240: step 7259, loss = 0.74361 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:24:03.381592 ops/training.py:65 2019-01-16 10:24:03.381525: step 7260, loss = 0.70166 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:24:04.343038 ops/training.py:65 2019-01-16 10:24:04.342968: step 7261, loss = 0.73048 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:24:05.306738 ops/training.py:65 2019-01-16 10:24:05.306674: step 7262, loss = 0.66068 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:24:06.267415 ops/training.py:65 2019-01-16 10:24:06.267326: step 7263, loss = 0.69596 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:24:07.231739 ops/training.py:65 2019-01-16 10:24:07.231669: step 7264, loss = 0.68033 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:24:08.192963 ops/training.py:65 2019-01-16 10:24:08.192897: step 7265, loss = 0.67855 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:24:09.158456 ops/training.py:65 2019-01-16 10:24:09.158383: step 7266, loss = 0.68604 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:24:10.121245 ops/training.py:65 2019-01-16 10:24:10.121165: step 7267, loss = 0.63846 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:24:11.085717 ops/training.py:65 2019-01-16 10:24:11.085644: step 7268, loss = 0.67378 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:24:12.047893 ops/training.py:65 2019-01-16 10:24:12.047821: step 7269, loss = 0.67902 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:24:13.009386 ops/training.py:65 2019-01-16 10:24:13.009322: step 7270, loss = 0.66551 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:24:13.970081 ops/training.py:65 2019-01-16 10:24:13.970008: step 7271, loss = 0.71482 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:24:14.931755 ops/training.py:65 2019-01-16 10:24:14.931682: step 7272, loss = 0.67656 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:24:15.892857 ops/training.py:65 2019-01-16 10:24:15.892784: step 7273, loss = 0.69174 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:24:16.855777 ops/training.py:65 2019-01-16 10:24:16.855711: step 7274, loss = 0.68573 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:24:17.818551 ops/training.py:65 2019-01-16 10:24:17.818479: step 7275, loss = 0.69706 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:24:18.779426 ops/training.py:65 2019-01-16 10:24:18.779358: step 7276, loss = 0.71420 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:24:19.740879 ops/training.py:65 2019-01-16 10:24:19.740813: step 7277, loss = 0.72197 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:24:20.701212 ops/training.py:65 2019-01-16 10:24:20.701148: step 7278, loss = 0.67023 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:24:21.662584 ops/training.py:65 2019-01-16 10:24:21.662511: step 7279, loss = 0.72679 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:24:22.624569 ops/training.py:65 2019-01-16 10:24:22.624498: step 7280, loss = 0.66819 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:24:23.586111 ops/training.py:65 2019-01-16 10:24:23.586042: step 7281, loss = 0.68498 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:24:24.547420 ops/training.py:65 2019-01-16 10:24:24.547348: step 7282, loss = 0.68662 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:24:25.509706 ops/training.py:65 2019-01-16 10:24:25.509642: step 7283, loss = 0.71277 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:24:26.470176 ops/training.py:65 2019-01-16 10:24:26.470110: step 7284, loss = 0.66585 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:24:27.435254 ops/training.py:65 2019-01-16 10:24:27.435181: step 7285, loss = 0.71098 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:24:28.398683 ops/training.py:65 2019-01-16 10:24:28.398618: step 7286, loss = 0.69602 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:24:29.360928 ops/training.py:65 2019-01-16 10:24:29.360859: step 7287, loss = 0.71726 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:24:30.321475 ops/training.py:65 2019-01-16 10:24:30.321407: step 7288, loss = 0.69741 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:24:31.281671 ops/training.py:65 2019-01-16 10:24:31.281617: step 7289, loss = 0.68684 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:24:32.245163 ops/training.py:65 2019-01-16 10:24:32.245110: step 7290, loss = 0.66303 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:24:33.209083 ops/training.py:65 2019-01-16 10:24:33.209018: step 7291, loss = 0.66497 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:24:34.173309 ops/training.py:65 2019-01-16 10:24:34.173234: step 7292, loss = 0.75628 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:24:35.134258 ops/training.py:65 2019-01-16 10:24:35.134170: step 7293, loss = 0.71328 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:24:36.096131 ops/training.py:65 2019-01-16 10:24:36.096060: step 7294, loss = 0.64805 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:24:37.057911 ops/training.py:65 2019-01-16 10:24:37.057837: step 7295, loss = 0.76613 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 10:24:38.019244 ops/training.py:65 2019-01-16 10:24:38.019180: step 7296, loss = 0.68261 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:24:38.981250 ops/training.py:65 2019-01-16 10:24:38.981180: step 7297, loss = 0.72093 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:24:39.942680 ops/training.py:65 2019-01-16 10:24:39.942607: step 7298, loss = 0.70907 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:24:40.903955 ops/training.py:65 2019-01-16 10:24:40.903883: step 7299, loss = 0.76483 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.25
I0832 2019-01-16 10:24:41.864486 ops/training.py:65 2019-01-16 10:24:41.864422: step 7300, loss = 0.66723 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:24:42.825594 ops/training.py:65 2019-01-16 10:24:42.825520: step 7301, loss = 0.71593 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:24:43.787571 ops/training.py:65 2019-01-16 10:24:43.787494: step 7302, loss = 0.72212 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:24:44.749087 ops/training.py:65 2019-01-16 10:24:44.749014: step 7303, loss = 0.67629 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:24:45.710177 ops/training.py:65 2019-01-16 10:24:45.710105: step 7304, loss = 0.70039 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:24:46.671334 ops/training.py:65 2019-01-16 10:24:46.671257: step 7305, loss = 0.70645 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:24:47.633555 ops/training.py:65 2019-01-16 10:24:47.633479: step 7306, loss = 0.73368 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:24:48.594929 ops/training.py:65 2019-01-16 10:24:48.594865: step 7307, loss = 0.72472 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:24:49.556350 ops/training.py:65 2019-01-16 10:24:49.556287: step 7308, loss = 0.68526 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:24:50.517123 ops/training.py:65 2019-01-16 10:24:50.517057: step 7309, loss = 0.68475 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:24:51.479215 ops/training.py:65 2019-01-16 10:24:51.479150: step 7310, loss = 0.66487 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:24:52.440491 ops/training.py:65 2019-01-16 10:24:52.440427: step 7311, loss = 0.69967 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:24:53.401987 ops/training.py:65 2019-01-16 10:24:53.401903: step 7312, loss = 0.64360 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 10:24:54.362144 ops/training.py:65 2019-01-16 10:24:54.362079: step 7313, loss = 0.66884 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:24:55.327861 ops/training.py:65 2019-01-16 10:24:55.327790: step 7314, loss = 0.69416 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:24:56.292229 ops/training.py:65 2019-01-16 10:24:56.292158: step 7315, loss = 0.66639 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:24:57.254696 ops/training.py:65 2019-01-16 10:24:57.254628: step 7316, loss = 0.65834 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:24:58.216943 ops/training.py:65 2019-01-16 10:24:58.216877: step 7317, loss = 0.65518 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:24:59.182876 ops/training.py:65 2019-01-16 10:24:59.182801: step 7318, loss = 0.69633 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:25:00.143890 ops/training.py:65 2019-01-16 10:25:00.143817: step 7319, loss = 0.71062 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:25:01.103890 ops/training.py:65 2019-01-16 10:25:01.103823: step 7320, loss = 0.70767 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:25:02.067361 ops/training.py:65 2019-01-16 10:25:02.067311: step 7321, loss = 0.68253 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:25:03.029997 ops/training.py:65 2019-01-16 10:25:03.029933: step 7322, loss = 0.69984 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:25:03.992958 ops/training.py:65 2019-01-16 10:25:03.992885: step 7323, loss = 0.69574 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:25:04.954876 ops/training.py:65 2019-01-16 10:25:04.954813: step 7324, loss = 0.68438 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:25:05.916831 ops/training.py:65 2019-01-16 10:25:05.916763: step 7325, loss = 0.68347 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:25:06.877790 ops/training.py:65 2019-01-16 10:25:06.877722: step 7326, loss = 0.68999 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:25:07.839449 ops/training.py:65 2019-01-16 10:25:07.839377: step 7327, loss = 0.69460 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:25:08.800960 ops/training.py:65 2019-01-16 10:25:08.800895: step 7328, loss = 0.66056 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:25:09.762549 ops/training.py:65 2019-01-16 10:25:09.762482: step 7329, loss = 0.68164 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:25:10.723265 ops/training.py:65 2019-01-16 10:25:10.723204: step 7330, loss = 0.67500 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:25:11.684940 ops/training.py:65 2019-01-16 10:25:11.684869: step 7331, loss = 0.68962 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:25:12.647416 ops/training.py:65 2019-01-16 10:25:12.647345: step 7332, loss = 0.70687 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:25:13.608697 ops/training.py:65 2019-01-16 10:25:13.608632: step 7333, loss = 0.70082 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:25:14.570258 ops/training.py:65 2019-01-16 10:25:14.570195: step 7334, loss = 0.70443 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:25:15.533459 ops/training.py:65 2019-01-16 10:25:15.533395: step 7335, loss = 0.71032 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:25:16.495027 ops/training.py:65 2019-01-16 10:25:16.494956: step 7336, loss = 0.72099 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:25:17.456711 ops/training.py:65 2019-01-16 10:25:17.456646: step 7337, loss = 0.67546 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:25:18.417515 ops/training.py:65 2019-01-16 10:25:18.417451: step 7338, loss = 0.70402 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:25:19.380234 ops/training.py:65 2019-01-16 10:25:19.380168: step 7339, loss = 0.68048 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:25:20.340976 ops/training.py:65 2019-01-16 10:25:20.340908: step 7340, loss = 0.70132 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:25:21.302613 ops/training.py:65 2019-01-16 10:25:21.302545: step 7341, loss = 0.71232 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:25:22.263673 ops/training.py:65 2019-01-16 10:25:22.263602: step 7342, loss = 0.65532 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:25:23.225333 ops/training.py:65 2019-01-16 10:25:23.225265: step 7343, loss = 0.67685 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:25:24.186939 ops/training.py:65 2019-01-16 10:25:24.186867: step 7344, loss = 0.65624 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:25:25.148616 ops/training.py:65 2019-01-16 10:25:25.148550: step 7345, loss = 0.67373 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:25:26.110067 ops/training.py:65 2019-01-16 10:25:26.110002: step 7346, loss = 0.65792 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:25:27.071080 ops/training.py:65 2019-01-16 10:25:27.071014: step 7347, loss = 0.64889 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:25:28.032650 ops/training.py:65 2019-01-16 10:25:28.032585: step 7348, loss = 0.66264 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:25:28.994201 ops/training.py:65 2019-01-16 10:25:28.994134: step 7349, loss = 0.78656 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 10:25:29.955223 ops/training.py:65 2019-01-16 10:25:29.955162: step 7350, loss = 0.72186 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:25:30.916201 ops/training.py:65 2019-01-16 10:25:30.916135: step 7351, loss = 0.63902 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:25:31.879361 ops/training.py:65 2019-01-16 10:25:31.879290: step 7352, loss = 0.70385 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:25:32.840405 ops/training.py:65 2019-01-16 10:25:32.840333: step 7353, loss = 0.66163 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:25:33.800595 ops/training.py:65 2019-01-16 10:25:33.800524: step 7354, loss = 0.71904 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:25:34.761835 ops/training.py:65 2019-01-16 10:25:34.761783: step 7355, loss = 0.72761 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:25:35.722478 ops/training.py:65 2019-01-16 10:25:35.722420: step 7356, loss = 0.65002 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:25:36.684094 ops/training.py:65 2019-01-16 10:25:36.684044: step 7357, loss = 0.68580 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:25:37.645261 ops/training.py:65 2019-01-16 10:25:37.645205: step 7358, loss = 0.66436 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:25:38.610094 ops/training.py:65 2019-01-16 10:25:38.610028: step 7359, loss = 0.68155 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:25:39.571460 ops/training.py:65 2019-01-16 10:25:39.571401: step 7360, loss = 0.65955 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:25:40.531854 ops/training.py:65 2019-01-16 10:25:40.531801: step 7361, loss = 0.65657 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:25:41.496426 ops/training.py:65 2019-01-16 10:25:41.496380: step 7362, loss = 0.66427 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:25:42.459552 ops/training.py:65 2019-01-16 10:25:42.459500: step 7363, loss = 0.70062 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:25:43.423493 ops/training.py:65 2019-01-16 10:25:43.423439: step 7364, loss = 0.71266 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:25:44.386000 ops/training.py:65 2019-01-16 10:25:44.385933: step 7365, loss = 0.72529 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:25:45.347943 ops/training.py:65 2019-01-16 10:25:45.347873: step 7366, loss = 0.64884 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:25:46.308681 ops/training.py:65 2019-01-16 10:25:46.308613: step 7367, loss = 0.64893 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:25:47.269808 ops/training.py:65 2019-01-16 10:25:47.269741: step 7368, loss = 0.68874 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:25:48.231953 ops/training.py:65 2019-01-16 10:25:48.231903: step 7369, loss = 0.71052 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:25:49.193104 ops/training.py:65 2019-01-16 10:25:49.193050: step 7370, loss = 0.72162 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:25:50.155527 ops/training.py:65 2019-01-16 10:25:50.155469: step 7371, loss = 0.66578 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:25:51.119850 ops/training.py:65 2019-01-16 10:25:51.119801: step 7372, loss = 0.70436 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:25:52.083075 ops/training.py:65 2019-01-16 10:25:52.083024: step 7373, loss = 0.64848 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:25:53.046631 ops/training.py:65 2019-01-16 10:25:53.046579: step 7374, loss = 0.71796 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:25:54.007529 ops/training.py:65 2019-01-16 10:25:54.007478: step 7375, loss = 0.68934 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:25:54.968815 ops/training.py:65 2019-01-16 10:25:54.968765: step 7376, loss = 0.64475 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:25:55.930196 ops/training.py:65 2019-01-16 10:25:55.930148: step 7377, loss = 0.68436 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:25:56.891400 ops/training.py:65 2019-01-16 10:25:56.891334: step 7378, loss = 0.69831 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:25:57.852771 ops/training.py:65 2019-01-16 10:25:57.852719: step 7379, loss = 0.67816 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:25:58.813662 ops/training.py:65 2019-01-16 10:25:58.813612: step 7380, loss = 0.66521 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:25:59.774542 ops/training.py:65 2019-01-16 10:25:59.774486: step 7381, loss = 0.70380 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:26:00.736384 ops/training.py:65 2019-01-16 10:26:00.736316: step 7382, loss = 0.73379 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:26:01.701896 ops/training.py:65 2019-01-16 10:26:01.701842: step 7383, loss = 0.71299 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:26:02.666919 ops/training.py:65 2019-01-16 10:26:02.666861: step 7384, loss = 0.72459 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:26:03.630350 ops/training.py:65 2019-01-16 10:26:03.630281: step 7385, loss = 0.71011 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:26:04.592281 ops/training.py:65 2019-01-16 10:26:04.592219: step 7386, loss = 0.64068 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:26:05.553324 ops/training.py:65 2019-01-16 10:26:05.553260: step 7387, loss = 0.71027 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:26:06.514258 ops/training.py:65 2019-01-16 10:26:06.514213: step 7388, loss = 0.69174 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:26:07.475535 ops/training.py:65 2019-01-16 10:26:07.475484: step 7389, loss = 0.77593 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:26:08.439998 ops/training.py:65 2019-01-16 10:26:08.439944: step 7390, loss = 0.71700 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:26:09.403921 ops/training.py:65 2019-01-16 10:26:09.403872: step 7391, loss = 0.70733 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:26:10.365296 ops/training.py:65 2019-01-16 10:26:10.365244: step 7392, loss = 0.76741 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:26:11.327090 ops/training.py:65 2019-01-16 10:26:11.327035: step 7393, loss = 0.66173 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:26:12.289124 ops/training.py:65 2019-01-16 10:26:12.289071: step 7394, loss = 0.71072 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:26:13.251610 ops/training.py:65 2019-01-16 10:26:13.251560: step 7395, loss = 0.73421 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:26:14.212975 ops/training.py:65 2019-01-16 10:26:14.212922: step 7396, loss = 0.66737 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:26:15.174941 ops/training.py:65 2019-01-16 10:26:15.174887: step 7397, loss = 0.71133 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:26:16.138994 ops/training.py:65 2019-01-16 10:26:16.138947: step 7398, loss = 0.72768 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:26:17.103264 ops/training.py:65 2019-01-16 10:26:17.103214: step 7399, loss = 0.67917 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:26:18.066145 ops/training.py:65 2019-01-16 10:26:18.066095: step 7400, loss = 0.70499 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:26:19.027268 ops/training.py:65 2019-01-16 10:26:19.027216: step 7401, loss = 0.68070 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:26:19.987938 ops/training.py:65 2019-01-16 10:26:19.987884: step 7402, loss = 0.69834 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:26:20.949345 ops/training.py:65 2019-01-16 10:26:20.949294: step 7403, loss = 0.71936 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:26:21.910629 ops/training.py:65 2019-01-16 10:26:21.910574: step 7404, loss = 0.69762 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:26:22.872019 ops/training.py:65 2019-01-16 10:26:22.871971: step 7405, loss = 0.69392 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:26:23.834070 ops/training.py:65 2019-01-16 10:26:23.834021: step 7406, loss = 0.68086 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:26:24.795440 ops/training.py:65 2019-01-16 10:26:24.795386: step 7407, loss = 0.72604 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:26:25.757106 ops/training.py:65 2019-01-16 10:26:25.757039: step 7408, loss = 0.68113 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:26:26.717619 ops/training.py:65 2019-01-16 10:26:26.717555: step 7409, loss = 0.73616 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:26:27.677184 ops/training.py:65 2019-01-16 10:26:27.677121: step 7410, loss = 0.70413 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:26:28.640361 ops/training.py:65 2019-01-16 10:26:28.640309: step 7411, loss = 0.69487 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:26:29.604304 ops/training.py:65 2019-01-16 10:26:29.604249: step 7412, loss = 0.66202 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:26:30.566635 ops/training.py:65 2019-01-16 10:26:30.566581: step 7413, loss = 0.70980 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:26:31.529034 ops/training.py:65 2019-01-16 10:26:31.528981: step 7414, loss = 0.73823 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:26:32.490057 ops/training.py:65 2019-01-16 10:26:32.490003: step 7415, loss = 0.70356 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:26:33.451112 ops/training.py:65 2019-01-16 10:26:33.451061: step 7416, loss = 0.72337 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:26:34.412978 ops/training.py:65 2019-01-16 10:26:34.412926: step 7417, loss = 0.64217 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:26:35.374658 ops/training.py:65 2019-01-16 10:26:35.374605: step 7418, loss = 0.61903 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:26:36.335832 ops/training.py:65 2019-01-16 10:26:36.335775: step 7419, loss = 0.71512 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:26:37.297000 ops/training.py:65 2019-01-16 10:26:37.296942: step 7420, loss = 0.65538 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:26:38.259339 ops/training.py:65 2019-01-16 10:26:38.259286: step 7421, loss = 0.68250 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:26:39.222177 ops/training.py:65 2019-01-16 10:26:39.222125: step 7422, loss = 0.68646 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:26:40.182742 ops/training.py:65 2019-01-16 10:26:40.182683: step 7423, loss = 0.70286 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:26:41.146770 ops/training.py:65 2019-01-16 10:26:41.146714: step 7424, loss = 0.68055 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:26:42.110153 ops/training.py:65 2019-01-16 10:26:42.110099: step 7425, loss = 0.70291 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:26:43.073270 ops/training.py:65 2019-01-16 10:26:43.073220: step 7426, loss = 0.66872 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:26:44.034802 ops/training.py:65 2019-01-16 10:26:44.034736: step 7427, loss = 0.69336 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:26:44.997520 ops/training.py:65 2019-01-16 10:26:44.997455: step 7428, loss = 0.71086 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:26:45.958712 ops/training.py:65 2019-01-16 10:26:45.958659: step 7429, loss = 0.65982 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:26:46.920144 ops/training.py:65 2019-01-16 10:26:46.920092: step 7430, loss = 0.71365 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:26:47.881726 ops/training.py:65 2019-01-16 10:26:47.881676: step 7431, loss = 0.69381 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:26:48.844005 ops/training.py:65 2019-01-16 10:26:48.843950: step 7432, loss = 0.63408 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 10:26:49.805615 ops/training.py:65 2019-01-16 10:26:49.805563: step 7433, loss = 0.64551 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:26:50.770704 ops/training.py:65 2019-01-16 10:26:50.770655: step 7434, loss = 0.68589 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:26:51.735062 ops/training.py:65 2019-01-16 10:26:51.735005: step 7435, loss = 0.65925 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:26:52.698307 ops/training.py:65 2019-01-16 10:26:52.698237: step 7436, loss = 0.64748 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:26:53.660210 ops/training.py:65 2019-01-16 10:26:53.660134: step 7437, loss = 0.64425 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:26:54.622239 ops/training.py:65 2019-01-16 10:26:54.622182: step 7438, loss = 0.73359 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:26:55.583808 ops/training.py:65 2019-01-16 10:26:55.583739: step 7439, loss = 0.73800 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:26:56.546516 ops/training.py:65 2019-01-16 10:26:56.546444: step 7440, loss = 0.68347 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:26:57.507746 ops/training.py:65 2019-01-16 10:26:57.507675: step 7441, loss = 0.73574 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:26:58.469184 ops/training.py:65 2019-01-16 10:26:58.469103: step 7442, loss = 0.74077 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:26:59.431209 ops/training.py:65 2019-01-16 10:26:59.431152: step 7443, loss = 0.71496 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:27:00.393553 ops/training.py:65 2019-01-16 10:27:00.393475: step 7444, loss = 0.76509 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:27:01.354948 ops/training.py:65 2019-01-16 10:27:01.354878: step 7445, loss = 0.64481 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:27:02.316889 ops/training.py:65 2019-01-16 10:27:02.316819: step 7446, loss = 0.66998 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:27:03.279810 ops/training.py:65 2019-01-16 10:27:03.279746: step 7447, loss = 0.64149 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:27:04.241060 ops/training.py:65 2019-01-16 10:27:04.240993: step 7448, loss = 0.70368 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:27:05.201659 ops/training.py:65 2019-01-16 10:27:05.201607: step 7449, loss = 0.67686 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:27:06.162387 ops/training.py:65 2019-01-16 10:27:06.162319: step 7450, loss = 0.71117 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:27:07.123774 ops/training.py:65 2019-01-16 10:27:07.123698: step 7451, loss = 0.69025 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:27:08.088759 ops/training.py:65 2019-01-16 10:27:08.088683: step 7452, loss = 0.70616 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:27:09.052616 ops/training.py:65 2019-01-16 10:27:09.052532: step 7453, loss = 0.67581 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:27:10.016385 ops/training.py:65 2019-01-16 10:27:10.016332: step 7454, loss = 0.71303 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:27:10.977497 ops/training.py:65 2019-01-16 10:27:10.977425: step 7455, loss = 0.62921 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:27:11.941280 ops/training.py:65 2019-01-16 10:27:11.941231: step 7456, loss = 0.66800 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:27:12.902989 ops/training.py:65 2019-01-16 10:27:12.902919: step 7457, loss = 0.64057 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:27:13.863928 ops/training.py:65 2019-01-16 10:27:13.863873: step 7458, loss = 0.72824 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:27:14.825057 ops/training.py:65 2019-01-16 10:27:14.825004: step 7459, loss = 0.70862 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:27:15.786803 ops/training.py:65 2019-01-16 10:27:15.786750: step 7460, loss = 0.71310 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:27:16.748413 ops/training.py:65 2019-01-16 10:27:16.748366: step 7461, loss = 0.69161 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:27:17.709021 ops/training.py:65 2019-01-16 10:27:17.708961: step 7462, loss = 0.66471 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:27:18.670361 ops/training.py:65 2019-01-16 10:27:18.670301: step 7463, loss = 0.77275 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:27:19.632237 ops/training.py:65 2019-01-16 10:27:19.632177: step 7464, loss = 0.64937 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:27:20.594229 ops/training.py:65 2019-01-16 10:27:20.594177: step 7465, loss = 0.62051 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 10:27:21.553565 ops/training.py:65 2019-01-16 10:27:21.553507: step 7466, loss = 0.71766 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:27:22.518309 ops/training.py:65 2019-01-16 10:27:22.518249: step 7467, loss = 0.63419 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:27:23.483488 ops/training.py:65 2019-01-16 10:27:23.483441: step 7468, loss = 0.73850 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:27:24.447747 ops/training.py:65 2019-01-16 10:27:24.447688: step 7469, loss = 0.69266 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:27:25.409855 ops/training.py:65 2019-01-16 10:27:25.409794: step 7470, loss = 0.73444 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:27:26.371332 ops/training.py:65 2019-01-16 10:27:26.371289: step 7471, loss = 0.66249 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:27:27.333867 ops/training.py:65 2019-01-16 10:27:27.333819: step 7472, loss = 0.73396 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:27:28.296477 ops/training.py:65 2019-01-16 10:27:28.296420: step 7473, loss = 0.67079 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:27:29.258516 ops/training.py:65 2019-01-16 10:27:29.258464: step 7474, loss = 0.75297 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:27:30.219675 ops/training.py:65 2019-01-16 10:27:30.219617: step 7475, loss = 0.67896 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:27:31.181576 ops/training.py:65 2019-01-16 10:27:31.181517: step 7476, loss = 0.64998 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:27:32.143393 ops/training.py:65 2019-01-16 10:27:32.143350: step 7477, loss = 0.65476 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:27:33.108154 ops/training.py:65 2019-01-16 10:27:33.108093: step 7478, loss = 0.71374 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:27:34.070904 ops/training.py:65 2019-01-16 10:27:34.070847: step 7479, loss = 0.66680 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:27:35.031893 ops/training.py:65 2019-01-16 10:27:35.031838: step 7480, loss = 0.68458 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:27:35.992814 ops/training.py:65 2019-01-16 10:27:35.992773: step 7481, loss = 0.67600 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:27:36.954510 ops/training.py:65 2019-01-16 10:27:36.954459: step 7482, loss = 0.71697 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:27:37.916221 ops/training.py:65 2019-01-16 10:27:37.916166: step 7483, loss = 0.71084 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:27:38.878426 ops/training.py:65 2019-01-16 10:27:38.878384: step 7484, loss = 0.69788 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:27:39.841297 ops/training.py:65 2019-01-16 10:27:39.841237: step 7485, loss = 0.68476 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:27:40.804819 ops/training.py:65 2019-01-16 10:27:40.804762: step 7486, loss = 0.70171 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:27:41.769663 ops/training.py:65 2019-01-16 10:27:41.769605: step 7487, loss = 0.67165 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:27:42.733433 ops/training.py:65 2019-01-16 10:27:42.733389: step 7488, loss = 0.70181 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:27:43.695765 ops/training.py:65 2019-01-16 10:27:43.695709: step 7489, loss = 0.70787 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:27:44.656467 ops/training.py:65 2019-01-16 10:27:44.656395: step 7490, loss = 0.66243 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:27:45.620928 ops/training.py:65 2019-01-16 10:27:45.620885: step 7491, loss = 0.67915 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:27:46.585256 ops/training.py:65 2019-01-16 10:27:46.585198: step 7492, loss = 0.65627 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:27:47.549438 ops/training.py:65 2019-01-16 10:27:47.549380: step 7493, loss = 0.69865 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:27:48.511899 ops/training.py:65 2019-01-16 10:27:48.511855: step 7494, loss = 0.69199 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:27:49.472703 ops/training.py:65 2019-01-16 10:27:49.472636: step 7495, loss = 0.69557 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:27:50.434087 ops/training.py:65 2019-01-16 10:27:50.434011: step 7496, loss = 0.67345 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:27:51.395168 ops/training.py:65 2019-01-16 10:27:51.395096: step 7497, loss = 0.65348 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:27:52.354280 ops/training.py:65 2019-01-16 10:27:52.354212: step 7498, loss = 0.65486 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:27:53.317409 ops/training.py:65 2019-01-16 10:27:53.317345: step 7499, loss = 0.67553 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:27:54.277439 ops/training.py:65 2019-01-16 10:27:54.277381: step 7500, loss = 0.69971 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:27:55.242831 ops/training.py:65 2019-01-16 10:27:55.242787: step 7501, loss = 0.69409 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:27:56.206409 ops/training.py:65 2019-01-16 10:27:56.206350: step 7502, loss = 0.71726 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:27:57.169866 ops/training.py:65 2019-01-16 10:27:57.169808: step 7503, loss = 0.69056 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:27:58.131911 ops/training.py:65 2019-01-16 10:27:58.131854: step 7504, loss = 0.69280 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:27:59.094373 ops/training.py:65 2019-01-16 10:27:59.094316: step 7505, loss = 0.68821 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:28:00.056835 ops/training.py:65 2019-01-16 10:28:00.056777: step 7506, loss = 0.70264 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:28:01.018487 ops/training.py:65 2019-01-16 10:28:01.018431: step 7507, loss = 0.69788 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:28:01.979847 ops/training.py:65 2019-01-16 10:28:01.979792: step 7508, loss = 0.65870 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:28:02.941063 ops/training.py:65 2019-01-16 10:28:02.940996: step 7509, loss = 0.70493 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:28:03.902802 ops/training.py:65 2019-01-16 10:28:03.902745: step 7510, loss = 0.62613 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:28:04.864720 ops/training.py:65 2019-01-16 10:28:04.864672: step 7511, loss = 0.73759 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:28:05.825764 ops/training.py:65 2019-01-16 10:28:05.825718: step 7512, loss = 0.68124 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:28:06.786494 ops/training.py:65 2019-01-16 10:28:06.786437: step 7513, loss = 0.66988 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:28:07.747639 ops/training.py:65 2019-01-16 10:28:07.747593: step 7514, loss = 0.64161 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:28:08.709413 ops/training.py:65 2019-01-16 10:28:08.709372: step 7515, loss = 0.72688 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:28:09.671477 ops/training.py:65 2019-01-16 10:28:09.671421: step 7516, loss = 0.73772 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:28:10.633730 ops/training.py:65 2019-01-16 10:28:10.633684: step 7517, loss = 0.74987 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:28:11.595956 ops/training.py:65 2019-01-16 10:28:11.595902: step 7518, loss = 0.65461 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:28:12.558274 ops/training.py:65 2019-01-16 10:28:12.558225: step 7519, loss = 0.70972 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:28:13.520761 ops/training.py:65 2019-01-16 10:28:13.520714: step 7520, loss = 0.72938 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:28:14.482214 ops/training.py:65 2019-01-16 10:28:14.482163: step 7521, loss = 0.62679 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:28:15.443175 ops/training.py:65 2019-01-16 10:28:15.443122: step 7522, loss = 0.69089 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:28:16.404697 ops/training.py:65 2019-01-16 10:28:16.404649: step 7523, loss = 0.60429 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:28:17.366663 ops/training.py:65 2019-01-16 10:28:17.366612: step 7524, loss = 0.64226 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:28:18.329687 ops/training.py:65 2019-01-16 10:28:18.329636: step 7525, loss = 0.65626 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:28:19.293562 ops/training.py:65 2019-01-16 10:28:19.293510: step 7526, loss = 0.74723 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:28:20.255573 ops/training.py:65 2019-01-16 10:28:20.255522: step 7527, loss = 0.73374 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:28:21.217518 ops/training.py:65 2019-01-16 10:28:21.217466: step 7528, loss = 0.67625 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:28:22.179870 ops/training.py:65 2019-01-16 10:28:22.179817: step 7529, loss = 0.71663 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:28:23.141425 ops/training.py:65 2019-01-16 10:28:23.141365: step 7530, loss = 0.65707 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:28:24.104079 ops/training.py:65 2019-01-16 10:28:24.104026: step 7531, loss = 0.66069 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:28:25.066054 ops/training.py:65 2019-01-16 10:28:25.065990: step 7532, loss = 0.68767 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:28:26.027966 ops/training.py:65 2019-01-16 10:28:26.027904: step 7533, loss = 0.72609 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:28:26.989262 ops/training.py:65 2019-01-16 10:28:26.989211: step 7534, loss = 0.73902 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:28:27.950898 ops/training.py:65 2019-01-16 10:28:27.950829: step 7535, loss = 0.70331 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:28:28.910604 ops/training.py:65 2019-01-16 10:28:28.910529: step 7536, loss = 0.67015 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:28:29.871248 ops/training.py:65 2019-01-16 10:28:29.871201: step 7537, loss = 0.69113 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:28:30.831408 ops/training.py:65 2019-01-16 10:28:30.831342: step 7538, loss = 0.68831 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:28:31.789819 ops/training.py:65 2019-01-16 10:28:31.789755: step 7539, loss = 0.68686 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:28:32.752879 ops/training.py:65 2019-01-16 10:28:32.752824: step 7540, loss = 0.66713 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:28:33.717498 ops/training.py:65 2019-01-16 10:28:33.717437: step 7541, loss = 0.71035 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:28:34.677717 ops/training.py:65 2019-01-16 10:28:34.677648: step 7542, loss = 0.70618 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:28:35.642916 ops/training.py:65 2019-01-16 10:28:35.642857: step 7543, loss = 0.70255 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:28:36.605534 ops/training.py:65 2019-01-16 10:28:36.605474: step 7544, loss = 0.64674 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:28:37.568636 ops/training.py:65 2019-01-16 10:28:37.568579: step 7545, loss = 0.73258 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:28:38.530505 ops/training.py:65 2019-01-16 10:28:38.530448: step 7546, loss = 0.69911 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:28:39.491932 ops/training.py:65 2019-01-16 10:28:39.491884: step 7547, loss = 0.66012 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:28:40.452939 ops/training.py:65 2019-01-16 10:28:40.452885: step 7548, loss = 0.65614 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:28:41.412848 ops/training.py:65 2019-01-16 10:28:41.412777: step 7549, loss = 0.71213 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:28:42.377716 ops/training.py:65 2019-01-16 10:28:42.377671: step 7550, loss = 0.70612 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:28:43.341332 ops/training.py:65 2019-01-16 10:28:43.341266: step 7551, loss = 0.69020 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:28:44.305189 ops/training.py:65 2019-01-16 10:28:44.305122: step 7552, loss = 0.69336 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:28:45.267611 ops/training.py:65 2019-01-16 10:28:45.267535: step 7553, loss = 0.76749 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:28:46.229744 ops/training.py:65 2019-01-16 10:28:46.229679: step 7554, loss = 0.65383 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:28:47.191329 ops/training.py:65 2019-01-16 10:28:47.191262: step 7555, loss = 0.67458 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:28:48.154147 ops/training.py:65 2019-01-16 10:28:48.154080: step 7556, loss = 0.63556 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:28:49.116387 ops/training.py:65 2019-01-16 10:28:49.116333: step 7557, loss = 0.68624 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:28:50.077969 ops/training.py:65 2019-01-16 10:28:50.077917: step 7558, loss = 0.66958 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:28:51.039823 ops/training.py:65 2019-01-16 10:28:51.039770: step 7559, loss = 0.68014 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:28:52.001589 ops/training.py:65 2019-01-16 10:28:52.001542: step 7560, loss = 0.68011 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:28:52.963827 ops/training.py:65 2019-01-16 10:28:52.963752: step 7561, loss = 0.72923 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:28:53.924727 ops/training.py:65 2019-01-16 10:28:53.924658: step 7562, loss = 0.60484 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:28:54.886327 ops/training.py:65 2019-01-16 10:28:54.886261: step 7563, loss = 0.68415 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:28:55.848209 ops/training.py:65 2019-01-16 10:28:55.848142: step 7564, loss = 0.70936 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:28:56.809276 ops/training.py:65 2019-01-16 10:28:56.809212: step 7565, loss = 0.71018 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:28:57.771648 ops/training.py:65 2019-01-16 10:28:57.771572: step 7566, loss = 0.69875 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:28:58.732372 ops/training.py:65 2019-01-16 10:28:58.732324: step 7567, loss = 0.69910 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:28:59.694466 ops/training.py:65 2019-01-16 10:28:59.694419: step 7568, loss = 0.69378 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:29:00.655913 ops/training.py:65 2019-01-16 10:29:00.655863: step 7569, loss = 0.69436 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:29:01.617313 ops/training.py:65 2019-01-16 10:29:01.617268: step 7570, loss = 0.67419 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:29:02.578535 ops/training.py:65 2019-01-16 10:29:02.578480: step 7571, loss = 0.72379 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:29:03.540613 ops/training.py:65 2019-01-16 10:29:03.540551: step 7572, loss = 0.65449 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:29:04.502505 ops/training.py:65 2019-01-16 10:29:04.502446: step 7573, loss = 0.65306 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:29:05.464671 ops/training.py:65 2019-01-16 10:29:05.464619: step 7574, loss = 0.71184 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:29:06.425050 ops/training.py:65 2019-01-16 10:29:06.424994: step 7575, loss = 0.69950 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:29:07.390603 ops/training.py:65 2019-01-16 10:29:07.390539: step 7576, loss = 0.70873 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:29:08.351372 ops/training.py:65 2019-01-16 10:29:08.351304: step 7577, loss = 0.72978 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:29:09.309565 ops/training.py:65 2019-01-16 10:29:09.309505: step 7578, loss = 0.69894 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:29:10.273534 ops/training.py:65 2019-01-16 10:29:10.273480: step 7579, loss = 0.67824 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:29:11.237634 ops/training.py:65 2019-01-16 10:29:11.237578: step 7580, loss = 0.75637 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:29:12.201006 ops/training.py:65 2019-01-16 10:29:12.200947: step 7581, loss = 0.69257 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:29:13.162846 ops/training.py:65 2019-01-16 10:29:13.162798: step 7582, loss = 0.71800 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:29:14.124220 ops/training.py:65 2019-01-16 10:29:14.124172: step 7583, loss = 0.70045 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:29:15.085092 ops/training.py:65 2019-01-16 10:29:15.085039: step 7584, loss = 0.68754 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:29:16.046820 ops/training.py:65 2019-01-16 10:29:16.046770: step 7585, loss = 0.70530 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:29:17.007330 ops/training.py:65 2019-01-16 10:29:17.007265: step 7586, loss = 0.66930 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:29:17.969109 ops/training.py:65 2019-01-16 10:29:17.969058: step 7587, loss = 0.71408 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:29:18.932242 ops/training.py:65 2019-01-16 10:29:18.932190: step 7588, loss = 0.70650 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:29:19.896320 ops/training.py:65 2019-01-16 10:29:19.896273: step 7589, loss = 0.71017 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:29:20.859396 ops/training.py:65 2019-01-16 10:29:20.859330: step 7590, loss = 0.66051 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:29:21.820685 ops/training.py:65 2019-01-16 10:29:21.820620: step 7591, loss = 0.66176 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:29:22.783080 ops/training.py:65 2019-01-16 10:29:22.783007: step 7592, loss = 0.67020 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:29:23.742737 ops/training.py:65 2019-01-16 10:29:23.742692: step 7593, loss = 0.64721 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:29:24.704087 ops/training.py:65 2019-01-16 10:29:24.704036: step 7594, loss = 0.69946 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:29:25.668509 ops/training.py:65 2019-01-16 10:29:25.668459: step 7595, loss = 0.69296 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:29:26.632539 ops/training.py:65 2019-01-16 10:29:26.632486: step 7596, loss = 0.64617 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:29:27.596407 ops/training.py:65 2019-01-16 10:29:27.596354: step 7597, loss = 0.71002 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:29:28.558387 ops/training.py:65 2019-01-16 10:29:28.558334: step 7598, loss = 0.70852 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:29:29.519141 ops/training.py:65 2019-01-16 10:29:29.519086: step 7599, loss = 0.69793 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:29:30.480227 ops/training.py:65 2019-01-16 10:29:30.480177: step 7600, loss = 0.78716 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:29:31.441940 ops/training.py:65 2019-01-16 10:29:31.441887: step 7601, loss = 0.64967 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:29:32.403240 ops/training.py:65 2019-01-16 10:29:32.403186: step 7602, loss = 0.66834 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:29:33.368577 ops/training.py:65 2019-01-16 10:29:33.368508: step 7603, loss = 0.66637 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:29:34.332391 ops/training.py:65 2019-01-16 10:29:34.332332: step 7604, loss = 0.72187 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:29:35.296236 ops/training.py:65 2019-01-16 10:29:35.296179: step 7605, loss = 0.67166 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:29:36.257426 ops/training.py:65 2019-01-16 10:29:36.257377: step 7606, loss = 0.71862 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:29:37.219720 ops/training.py:65 2019-01-16 10:29:37.219654: step 7607, loss = 0.66906 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:29:38.181095 ops/training.py:65 2019-01-16 10:29:38.181037: step 7608, loss = 0.67781 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:29:39.145874 ops/training.py:65 2019-01-16 10:29:39.145805: step 7609, loss = 0.65749 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:29:40.111540 ops/training.py:65 2019-01-16 10:29:40.111489: step 7610, loss = 0.66983 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:29:41.074701 ops/training.py:65 2019-01-16 10:29:41.074637: step 7611, loss = 0.65350 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:29:42.036012 ops/training.py:65 2019-01-16 10:29:42.035948: step 7612, loss = 0.63397 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:29:42.998507 ops/training.py:65 2019-01-16 10:29:42.998461: step 7613, loss = 0.67415 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:29:43.959027 ops/training.py:65 2019-01-16 10:29:43.958973: step 7614, loss = 0.68389 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:29:44.922380 ops/training.py:65 2019-01-16 10:29:44.922333: step 7615, loss = 0.72100 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:29:45.885421 ops/training.py:65 2019-01-16 10:29:45.885373: step 7616, loss = 0.67243 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:29:46.846960 ops/training.py:65 2019-01-16 10:29:46.846909: step 7617, loss = 0.67592 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:29:47.809239 ops/training.py:65 2019-01-16 10:29:47.809182: step 7618, loss = 0.76295 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:29:48.773850 ops/training.py:65 2019-01-16 10:29:48.773801: step 7619, loss = 0.73230 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:29:49.735898 ops/training.py:65 2019-01-16 10:29:49.735845: step 7620, loss = 0.70103 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:29:50.697034 ops/training.py:65 2019-01-16 10:29:50.696984: step 7621, loss = 0.69868 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:29:51.660805 ops/training.py:65 2019-01-16 10:29:51.660748: step 7622, loss = 0.67082 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:29:52.623880 ops/training.py:65 2019-01-16 10:29:52.623830: step 7623, loss = 0.70220 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:29:53.586289 ops/training.py:65 2019-01-16 10:29:53.586234: step 7624, loss = 0.69523 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:29:54.547704 ops/training.py:65 2019-01-16 10:29:54.547655: step 7625, loss = 0.67255 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:29:55.509526 ops/training.py:65 2019-01-16 10:29:55.509457: step 7626, loss = 0.69247 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:29:56.471195 ops/training.py:65 2019-01-16 10:29:56.471139: step 7627, loss = 0.69563 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:29:57.431140 ops/training.py:65 2019-01-16 10:29:57.431082: step 7628, loss = 0.71089 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:29:58.394435 ops/training.py:65 2019-01-16 10:29:58.394385: step 7629, loss = 0.77387 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.25
I0832 2019-01-16 10:29:59.357744 ops/training.py:65 2019-01-16 10:29:59.357693: step 7630, loss = 0.69066 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:30:00.320645 ops/training.py:65 2019-01-16 10:30:00.320576: step 7631, loss = 0.65760 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:30:01.284041 ops/training.py:65 2019-01-16 10:30:01.283987: step 7632, loss = 0.73129 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:30:02.245240 ops/training.py:65 2019-01-16 10:30:02.245179: step 7633, loss = 0.69426 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:30:03.206205 ops/training.py:65 2019-01-16 10:30:03.206150: step 7634, loss = 0.69416 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:30:04.166913 ops/training.py:65 2019-01-16 10:30:04.166839: step 7635, loss = 0.65243 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:30:05.131294 ops/training.py:65 2019-01-16 10:30:05.131228: step 7636, loss = 0.77825 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:30:06.094603 ops/training.py:65 2019-01-16 10:30:06.094538: step 7637, loss = 0.67180 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:30:07.057705 ops/training.py:65 2019-01-16 10:30:07.057639: step 7638, loss = 0.71189 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:30:08.018968 ops/training.py:65 2019-01-16 10:30:08.018900: step 7639, loss = 0.67860 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:30:08.980155 ops/training.py:65 2019-01-16 10:30:08.980099: step 7640, loss = 0.72656 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:30:09.941058 ops/training.py:65 2019-01-16 10:30:09.940994: step 7641, loss = 0.72332 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:30:10.900732 ops/training.py:65 2019-01-16 10:30:10.900659: step 7642, loss = 0.71255 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:30:11.864726 ops/training.py:65 2019-01-16 10:30:11.864679: step 7643, loss = 0.67522 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:30:12.828567 ops/training.py:65 2019-01-16 10:30:12.828505: step 7644, loss = 0.67544 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:30:13.792288 ops/training.py:65 2019-01-16 10:30:13.792216: step 7645, loss = 0.70246 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:30:14.753117 ops/training.py:65 2019-01-16 10:30:14.753066: step 7646, loss = 0.68308 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:30:15.714114 ops/training.py:65 2019-01-16 10:30:15.714064: step 7647, loss = 0.70443 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:30:16.677711 ops/training.py:65 2019-01-16 10:30:16.677660: step 7648, loss = 0.70519 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:30:17.642323 ops/training.py:65 2019-01-16 10:30:17.642264: step 7649, loss = 0.71903 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:30:18.606171 ops/training.py:65 2019-01-16 10:30:18.606106: step 7650, loss = 0.72161 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:30:19.568485 ops/training.py:65 2019-01-16 10:30:19.568437: step 7651, loss = 0.70424 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:30:20.530776 ops/training.py:65 2019-01-16 10:30:20.530726: step 7652, loss = 0.66827 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:30:21.492606 ops/training.py:65 2019-01-16 10:30:21.492535: step 7653, loss = 0.70352 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:30:22.455546 ops/training.py:65 2019-01-16 10:30:22.455479: step 7654, loss = 0.67657 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:30:23.417422 ops/training.py:65 2019-01-16 10:30:23.417369: step 7655, loss = 0.69504 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:30:24.378841 ops/training.py:65 2019-01-16 10:30:24.378794: step 7656, loss = 0.68278 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:30:25.339236 ops/training.py:65 2019-01-16 10:30:25.339186: step 7657, loss = 0.69980 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:30:26.299538 ops/training.py:65 2019-01-16 10:30:26.299490: step 7658, loss = 0.71646 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:30:27.259918 ops/training.py:65 2019-01-16 10:30:27.259871: step 7659, loss = 0.63555 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:30:28.223546 ops/training.py:65 2019-01-16 10:30:28.223496: step 7660, loss = 0.71735 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:30:29.186998 ops/training.py:65 2019-01-16 10:30:29.186931: step 7661, loss = 0.63765 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:30:30.148990 ops/training.py:65 2019-01-16 10:30:30.148929: step 7662, loss = 0.68965 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:30:31.110757 ops/training.py:65 2019-01-16 10:30:31.110699: step 7663, loss = 0.68251 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:30:32.071859 ops/training.py:65 2019-01-16 10:30:32.071802: step 7664, loss = 0.64811 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:30:33.037416 ops/training.py:65 2019-01-16 10:30:33.037359: step 7665, loss = 0.73393 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:30:34.000229 ops/training.py:65 2019-01-16 10:30:34.000161: step 7666, loss = 0.66627 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:30:34.963308 ops/training.py:65 2019-01-16 10:30:34.963260: step 7667, loss = 0.64665 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:30:35.925871 ops/training.py:65 2019-01-16 10:30:35.925824: step 7668, loss = 0.66059 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:30:36.887568 ops/training.py:65 2019-01-16 10:30:36.887521: step 7669, loss = 0.70812 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:30:37.848019 ops/training.py:65 2019-01-16 10:30:37.847966: step 7670, loss = 0.76529 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:30:38.809737 ops/training.py:65 2019-01-16 10:30:38.809679: step 7671, loss = 0.72042 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:30:39.770204 ops/training.py:65 2019-01-16 10:30:39.770146: step 7672, loss = 0.68413 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:30:40.731662 ops/training.py:65 2019-01-16 10:30:40.731610: step 7673, loss = 0.80391 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 10:30:41.692586 ops/training.py:65 2019-01-16 10:30:41.692532: step 7674, loss = 0.64606 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:30:42.653413 ops/training.py:65 2019-01-16 10:30:42.653356: step 7675, loss = 0.62345 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:30:43.614675 ops/training.py:65 2019-01-16 10:30:43.614622: step 7676, loss = 0.69752 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:30:44.577129 ops/training.py:65 2019-01-16 10:30:44.577075: step 7677, loss = 0.68212 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:30:45.537887 ops/training.py:65 2019-01-16 10:30:45.537837: step 7678, loss = 0.62508 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:30:46.498464 ops/training.py:65 2019-01-16 10:30:46.498398: step 7679, loss = 0.71508 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:30:47.460437 ops/training.py:65 2019-01-16 10:30:47.460375: step 7680, loss = 0.65519 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:30:48.424428 ops/training.py:65 2019-01-16 10:30:48.424365: step 7681, loss = 0.75036 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:30:49.386387 ops/training.py:65 2019-01-16 10:30:49.386320: step 7682, loss = 0.75648 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:30:50.347906 ops/training.py:65 2019-01-16 10:30:50.347836: step 7683, loss = 0.65402 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:30:51.312260 ops/training.py:65 2019-01-16 10:30:51.312195: step 7684, loss = 0.71561 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:30:52.274081 ops/training.py:65 2019-01-16 10:30:52.274008: step 7685, loss = 0.65470 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:30:53.238087 ops/training.py:65 2019-01-16 10:30:53.238039: step 7686, loss = 0.65415 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:30:54.200758 ops/training.py:65 2019-01-16 10:30:54.200706: step 7687, loss = 0.70535 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:30:55.162423 ops/training.py:65 2019-01-16 10:30:55.162352: step 7688, loss = 0.63012 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:30:56.124519 ops/training.py:65 2019-01-16 10:30:56.124469: step 7689, loss = 0.72772 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:30:57.085229 ops/training.py:65 2019-01-16 10:30:57.085181: step 7690, loss = 0.73803 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:30:58.047573 ops/training.py:65 2019-01-16 10:30:58.047521: step 7691, loss = 0.73848 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:30:59.008221 ops/training.py:65 2019-01-16 10:30:59.008174: step 7692, loss = 0.71751 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:30:59.968872 ops/training.py:65 2019-01-16 10:30:59.968824: step 7693, loss = 0.74871 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:31:00.929989 ops/training.py:65 2019-01-16 10:31:00.929932: step 7694, loss = 0.68798 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:31:01.890786 ops/training.py:65 2019-01-16 10:31:01.890739: step 7695, loss = 0.65332 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:31:02.851940 ops/training.py:65 2019-01-16 10:31:02.851874: step 7696, loss = 0.77132 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:31:03.813214 ops/training.py:65 2019-01-16 10:31:03.813143: step 7697, loss = 0.70272 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:31:04.777971 ops/training.py:65 2019-01-16 10:31:04.777920: step 7698, loss = 0.66335 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:31:05.738269 ops/training.py:65 2019-01-16 10:31:05.738216: step 7699, loss = 0.61960 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:31:06.698168 ops/training.py:65 2019-01-16 10:31:06.698108: step 7700, loss = 0.69747 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:31:07.659928 ops/training.py:65 2019-01-16 10:31:07.659872: step 7701, loss = 0.72586 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:31:08.624982 ops/training.py:65 2019-01-16 10:31:08.624937: step 7702, loss = 0.67043 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:31:09.588737 ops/training.py:65 2019-01-16 10:31:09.588671: step 7703, loss = 0.63766 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:31:10.551069 ops/training.py:65 2019-01-16 10:31:10.551006: step 7704, loss = 0.70287 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:31:11.512793 ops/training.py:65 2019-01-16 10:31:11.512719: step 7705, loss = 0.73909 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:31:12.474229 ops/training.py:65 2019-01-16 10:31:12.474164: step 7706, loss = 0.69235 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:31:13.436345 ops/training.py:65 2019-01-16 10:31:13.436278: step 7707, loss = 0.68132 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:31:14.396517 ops/training.py:65 2019-01-16 10:31:14.396463: step 7708, loss = 0.65683 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:31:15.359869 ops/training.py:65 2019-01-16 10:31:15.359799: step 7709, loss = 0.67552 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:31:16.324319 ops/training.py:65 2019-01-16 10:31:16.324269: step 7710, loss = 0.70705 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:31:17.287944 ops/training.py:65 2019-01-16 10:31:17.287883: step 7711, loss = 0.66070 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:31:18.248157 ops/training.py:65 2019-01-16 10:31:18.248109: step 7712, loss = 0.60272 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:31:19.208417 ops/training.py:65 2019-01-16 10:31:19.208349: step 7713, loss = 0.72642 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:31:20.168088 ops/training.py:65 2019-01-16 10:31:20.168023: step 7714, loss = 0.69877 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:31:21.125788 ops/training.py:65 2019-01-16 10:31:21.125725: step 7715, loss = 0.71673 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:31:22.084709 ops/training.py:65 2019-01-16 10:31:22.084653: step 7716, loss = 0.67411 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:31:23.043781 ops/training.py:65 2019-01-16 10:31:23.043715: step 7717, loss = 0.66380 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:31:24.003775 ops/training.py:65 2019-01-16 10:31:24.003703: step 7718, loss = 0.66565 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:31:24.968302 ops/training.py:65 2019-01-16 10:31:24.968250: step 7719, loss = 0.71144 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:31:25.931262 ops/training.py:65 2019-01-16 10:31:25.931204: step 7720, loss = 0.72543 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:31:26.894613 ops/training.py:65 2019-01-16 10:31:26.894552: step 7721, loss = 0.70769 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:31:27.856578 ops/training.py:65 2019-01-16 10:31:27.856527: step 7722, loss = 0.72468 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:31:28.820001 ops/training.py:65 2019-01-16 10:31:28.819937: step 7723, loss = 0.76311 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:31:29.783627 ops/training.py:65 2019-01-16 10:31:29.783577: step 7724, loss = 0.69169 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:31:30.745497 ops/training.py:65 2019-01-16 10:31:30.745442: step 7725, loss = 0.69941 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:31:31.707634 ops/training.py:65 2019-01-16 10:31:31.707575: step 7726, loss = 0.67021 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:31:32.667654 ops/training.py:65 2019-01-16 10:31:32.667603: step 7727, loss = 0.61851 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:31:33.631664 ops/training.py:65 2019-01-16 10:31:33.631603: step 7728, loss = 0.73962 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:31:34.593571 ops/training.py:65 2019-01-16 10:31:34.593508: step 7729, loss = 0.65581 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:31:35.554582 ops/training.py:65 2019-01-16 10:31:35.554517: step 7730, loss = 0.62988 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 10:31:36.515668 ops/training.py:65 2019-01-16 10:31:36.515596: step 7731, loss = 0.65934 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:31:37.477313 ops/training.py:65 2019-01-16 10:31:37.477255: step 7732, loss = 0.67579 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:31:38.439008 ops/training.py:65 2019-01-16 10:31:38.438936: step 7733, loss = 0.67618 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:31:39.399706 ops/training.py:65 2019-01-16 10:31:39.399650: step 7734, loss = 0.65357 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:31:40.359968 ops/training.py:65 2019-01-16 10:31:40.359914: step 7735, loss = 0.71018 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:31:41.324569 ops/training.py:65 2019-01-16 10:31:41.324518: step 7736, loss = 0.65656 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:31:42.286493 ops/training.py:65 2019-01-16 10:31:42.286425: step 7737, loss = 0.70247 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:31:43.247767 ops/training.py:65 2019-01-16 10:31:43.247709: step 7738, loss = 0.71145 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:31:44.209122 ops/training.py:65 2019-01-16 10:31:44.209070: step 7739, loss = 0.69480 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:31:45.169072 ops/training.py:65 2019-01-16 10:31:45.169020: step 7740, loss = 0.66207 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:31:46.128653 ops/training.py:65 2019-01-16 10:31:46.128599: step 7741, loss = 0.66730 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:31:47.088185 ops/training.py:65 2019-01-16 10:31:47.088136: step 7742, loss = 0.70311 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:31:48.052851 ops/training.py:65 2019-01-16 10:31:48.052803: step 7743, loss = 0.70543 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:31:49.016460 ops/training.py:65 2019-01-16 10:31:49.016408: step 7744, loss = 0.69774 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:31:49.980008 ops/training.py:65 2019-01-16 10:31:49.979955: step 7745, loss = 0.70427 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:31:50.941401 ops/training.py:65 2019-01-16 10:31:50.941353: step 7746, loss = 0.65691 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:31:51.904119 ops/training.py:65 2019-01-16 10:31:51.904068: step 7747, loss = 0.68448 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:31:52.865558 ops/training.py:65 2019-01-16 10:31:52.865502: step 7748, loss = 0.66661 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:31:53.826178 ops/training.py:65 2019-01-16 10:31:53.826131: step 7749, loss = 0.71172 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:31:54.787429 ops/training.py:65 2019-01-16 10:31:54.787379: step 7750, loss = 0.62084 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:31:55.748971 ops/training.py:65 2019-01-16 10:31:55.748921: step 7751, loss = 0.68741 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:31:56.709746 ops/training.py:65 2019-01-16 10:31:56.709695: step 7752, loss = 0.67031 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:31:57.671099 ops/training.py:65 2019-01-16 10:31:57.671048: step 7753, loss = 0.69840 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:31:58.631541 ops/training.py:65 2019-01-16 10:31:58.631494: step 7754, loss = 0.68549 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:31:59.592387 ops/training.py:65 2019-01-16 10:31:59.592343: step 7755, loss = 0.67181 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:32:00.553506 ops/training.py:65 2019-01-16 10:32:00.553456: step 7756, loss = 0.70220 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:32:01.515120 ops/training.py:65 2019-01-16 10:32:01.515066: step 7757, loss = 0.69789 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:32:02.475939 ops/training.py:65 2019-01-16 10:32:02.475884: step 7758, loss = 0.70465 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:32:03.436974 ops/training.py:65 2019-01-16 10:32:03.436925: step 7759, loss = 0.63572 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:32:04.398406 ops/training.py:65 2019-01-16 10:32:04.398356: step 7760, loss = 0.70100 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:32:05.359007 ops/training.py:65 2019-01-16 10:32:05.358951: step 7761, loss = 0.74473 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:32:06.319168 ops/training.py:65 2019-01-16 10:32:06.319116: step 7762, loss = 0.65000 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:32:07.279733 ops/training.py:65 2019-01-16 10:32:07.279663: step 7763, loss = 0.68052 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:32:08.241577 ops/training.py:65 2019-01-16 10:32:08.241512: step 7764, loss = 0.68416 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:32:09.203442 ops/training.py:65 2019-01-16 10:32:09.203378: step 7765, loss = 0.62785 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:32:10.165998 ops/training.py:65 2019-01-16 10:32:10.165931: step 7766, loss = 0.71326 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:32:11.126438 ops/training.py:65 2019-01-16 10:32:11.126365: step 7767, loss = 0.73001 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:32:12.086984 ops/training.py:65 2019-01-16 10:32:12.086914: step 7768, loss = 0.67430 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:32:13.046759 ops/training.py:65 2019-01-16 10:32:13.046703: step 7769, loss = 0.68180 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:32:14.010635 ops/training.py:65 2019-01-16 10:32:14.010584: step 7770, loss = 0.64494 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:32:14.973958 ops/training.py:65 2019-01-16 10:32:14.973908: step 7771, loss = 0.70486 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:32:15.937050 ops/training.py:65 2019-01-16 10:32:15.937003: step 7772, loss = 0.64647 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:32:16.899566 ops/training.py:65 2019-01-16 10:32:16.899513: step 7773, loss = 0.65722 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:32:17.860162 ops/training.py:65 2019-01-16 10:32:17.860088: step 7774, loss = 0.67743 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:32:18.824338 ops/training.py:65 2019-01-16 10:32:18.824290: step 7775, loss = 0.68200 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:32:19.787682 ops/training.py:65 2019-01-16 10:32:19.787636: step 7776, loss = 0.66805 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:32:20.751298 ops/training.py:65 2019-01-16 10:32:20.751241: step 7777, loss = 0.70505 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:32:21.712703 ops/training.py:65 2019-01-16 10:32:21.712648: step 7778, loss = 0.66324 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:32:22.674857 ops/training.py:65 2019-01-16 10:32:22.674807: step 7779, loss = 0.68488 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:32:23.636845 ops/training.py:65 2019-01-16 10:32:23.636798: step 7780, loss = 0.65591 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:32:24.599341 ops/training.py:65 2019-01-16 10:32:24.599289: step 7781, loss = 0.63842 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:32:25.560090 ops/training.py:65 2019-01-16 10:32:25.560043: step 7782, loss = 0.79394 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:32:26.521735 ops/training.py:65 2019-01-16 10:32:26.521685: step 7783, loss = 0.65798 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:32:27.485045 ops/training.py:65 2019-01-16 10:32:27.484995: step 7784, loss = 0.78302 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:32:28.447213 ops/training.py:65 2019-01-16 10:32:28.447146: step 7785, loss = 0.64654 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:32:29.409342 ops/training.py:65 2019-01-16 10:32:29.409276: step 7786, loss = 0.70767 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:32:30.371599 ops/training.py:65 2019-01-16 10:32:30.371523: step 7787, loss = 0.67990 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:32:31.333974 ops/training.py:65 2019-01-16 10:32:31.333929: step 7788, loss = 0.70615 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:32:32.295163 ops/training.py:65 2019-01-16 10:32:32.295113: step 7789, loss = 0.66708 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:32:33.255916 ops/training.py:65 2019-01-16 10:32:33.255864: step 7790, loss = 0.73948 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:32:34.217338 ops/training.py:65 2019-01-16 10:32:34.217271: step 7791, loss = 0.60587 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:32:35.178330 ops/training.py:65 2019-01-16 10:32:35.178263: step 7792, loss = 0.69185 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:32:36.139187 ops/training.py:65 2019-01-16 10:32:36.139120: step 7793, loss = 0.67834 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:32:37.100638 ops/training.py:65 2019-01-16 10:32:37.100574: step 7794, loss = 0.68176 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:32:38.061762 ops/training.py:65 2019-01-16 10:32:38.061712: step 7795, loss = 0.72880 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:32:39.023237 ops/training.py:65 2019-01-16 10:32:39.023167: step 7796, loss = 0.63804 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:32:39.982898 ops/training.py:65 2019-01-16 10:32:39.982828: step 7797, loss = 0.65844 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:32:40.942549 ops/training.py:65 2019-01-16 10:32:40.942480: step 7798, loss = 0.71040 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:32:41.905490 ops/training.py:65 2019-01-16 10:32:41.905430: step 7799, loss = 0.71239 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:32:42.866990 ops/training.py:65 2019-01-16 10:32:42.866914: step 7800, loss = 0.70889 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:32:43.831513 ops/training.py:65 2019-01-16 10:32:43.831464: step 7801, loss = 0.67994 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:32:44.795271 ops/training.py:65 2019-01-16 10:32:44.795221: step 7802, loss = 0.65371 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:32:45.758636 ops/training.py:65 2019-01-16 10:32:45.758585: step 7803, loss = 0.69840 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:32:46.719949 ops/training.py:65 2019-01-16 10:32:46.719897: step 7804, loss = 0.70178 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:32:47.681898 ops/training.py:65 2019-01-16 10:32:47.681844: step 7805, loss = 0.71623 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:32:48.643103 ops/training.py:65 2019-01-16 10:32:48.643033: step 7806, loss = 0.78366 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:32:49.605254 ops/training.py:65 2019-01-16 10:32:49.605190: step 7807, loss = 0.71757 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:32:50.566111 ops/training.py:65 2019-01-16 10:32:50.566057: step 7808, loss = 0.69773 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:32:51.528618 ops/training.py:65 2019-01-16 10:32:51.528563: step 7809, loss = 0.65524 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:32:52.490796 ops/training.py:65 2019-01-16 10:32:52.490740: step 7810, loss = 0.69600 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:32:53.452147 ops/training.py:65 2019-01-16 10:32:53.452076: step 7811, loss = 0.74394 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:32:54.417547 ops/training.py:65 2019-01-16 10:32:54.417495: step 7812, loss = 0.65368 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:32:55.379006 ops/training.py:65 2019-01-16 10:32:55.378951: step 7813, loss = 0.58160 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 10:32:56.343880 ops/training.py:65 2019-01-16 10:32:56.343829: step 7814, loss = 0.66041 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:32:57.307125 ops/training.py:65 2019-01-16 10:32:57.307057: step 7815, loss = 0.67905 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:32:58.270872 ops/training.py:65 2019-01-16 10:32:58.270808: step 7816, loss = 0.70273 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:32:59.233646 ops/training.py:65 2019-01-16 10:32:59.233594: step 7817, loss = 0.64386 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:33:00.196068 ops/training.py:65 2019-01-16 10:33:00.196021: step 7818, loss = 0.66269 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:33:01.158089 ops/training.py:65 2019-01-16 10:33:01.158039: step 7819, loss = 0.71980 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:33:02.119997 ops/training.py:65 2019-01-16 10:33:02.119943: step 7820, loss = 0.69978 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:33:03.082827 ops/training.py:65 2019-01-16 10:33:03.082780: step 7821, loss = 0.70744 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:33:04.044795 ops/training.py:65 2019-01-16 10:33:04.044723: step 7822, loss = 0.70855 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:33:05.006175 ops/training.py:65 2019-01-16 10:33:05.006109: step 7823, loss = 0.69511 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:33:05.968261 ops/training.py:65 2019-01-16 10:33:05.968192: step 7824, loss = 0.67945 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:33:06.929074 ops/training.py:65 2019-01-16 10:33:06.929026: step 7825, loss = 0.70401 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:33:07.890767 ops/training.py:65 2019-01-16 10:33:07.890709: step 7826, loss = 0.65111 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:33:08.852731 ops/training.py:65 2019-01-16 10:33:08.852670: step 7827, loss = 0.69303 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:33:09.814303 ops/training.py:65 2019-01-16 10:33:09.814253: step 7828, loss = 0.67193 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:33:10.775867 ops/training.py:65 2019-01-16 10:33:10.775810: step 7829, loss = 0.67528 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:33:11.736890 ops/training.py:65 2019-01-16 10:33:11.736837: step 7830, loss = 0.62806 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:33:12.702310 ops/training.py:65 2019-01-16 10:33:12.702242: step 7831, loss = 0.66634 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:33:13.666791 ops/training.py:65 2019-01-16 10:33:13.666724: step 7832, loss = 0.73694 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:33:14.630270 ops/training.py:65 2019-01-16 10:33:14.630203: step 7833, loss = 0.61392 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:33:15.591769 ops/training.py:65 2019-01-16 10:33:15.591702: step 7834, loss = 0.72103 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:33:16.553834 ops/training.py:65 2019-01-16 10:33:16.553784: step 7835, loss = 0.63555 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:33:17.515561 ops/training.py:65 2019-01-16 10:33:17.515511: step 7836, loss = 0.66344 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:33:18.477449 ops/training.py:65 2019-01-16 10:33:18.477399: step 7837, loss = 0.72403 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:33:19.440603 ops/training.py:65 2019-01-16 10:33:19.440535: step 7838, loss = 0.69264 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:33:20.401815 ops/training.py:65 2019-01-16 10:33:20.401750: step 7839, loss = 0.66701 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:33:21.363728 ops/training.py:65 2019-01-16 10:33:21.363661: step 7840, loss = 0.65609 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:33:22.325080 ops/training.py:65 2019-01-16 10:33:22.325030: step 7841, loss = 0.70933 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:33:23.287532 ops/training.py:65 2019-01-16 10:33:23.287484: step 7842, loss = 0.65255 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:33:24.249634 ops/training.py:65 2019-01-16 10:33:24.249570: step 7843, loss = 0.70633 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:33:25.211672 ops/training.py:65 2019-01-16 10:33:25.211617: step 7844, loss = 0.70446 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:33:26.173813 ops/training.py:65 2019-01-16 10:33:26.173765: step 7845, loss = 0.65929 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:33:27.135596 ops/training.py:65 2019-01-16 10:33:27.135547: step 7846, loss = 0.68285 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:33:28.096143 ops/training.py:65 2019-01-16 10:33:28.096089: step 7847, loss = 0.65691 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:33:29.059420 ops/training.py:65 2019-01-16 10:33:29.059368: step 7848, loss = 0.64257 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:33:30.020662 ops/training.py:65 2019-01-16 10:33:30.020607: step 7849, loss = 0.68520 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:33:30.985634 ops/training.py:65 2019-01-16 10:33:30.985588: step 7850, loss = 0.65236 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:33:31.949682 ops/training.py:65 2019-01-16 10:33:31.949635: step 7851, loss = 0.68469 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:33:32.913775 ops/training.py:65 2019-01-16 10:33:32.913719: step 7852, loss = 0.63545 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:33:33.874404 ops/training.py:65 2019-01-16 10:33:33.874333: step 7853, loss = 0.70792 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:33:34.836047 ops/training.py:65 2019-01-16 10:33:34.836001: step 7854, loss = 0.65938 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:33:35.800963 ops/training.py:65 2019-01-16 10:33:35.800913: step 7855, loss = 0.59798 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 10:33:36.764685 ops/training.py:65 2019-01-16 10:33:36.764618: step 7856, loss = 0.67027 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:33:37.726418 ops/training.py:65 2019-01-16 10:33:37.726360: step 7857, loss = 0.60207 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 10:33:38.691706 ops/training.py:65 2019-01-16 10:33:38.691647: step 7858, loss = 0.68097 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:33:39.656466 ops/training.py:65 2019-01-16 10:33:39.656401: step 7859, loss = 0.66250 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:33:40.619453 ops/training.py:65 2019-01-16 10:33:40.619400: step 7860, loss = 0.62073 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:33:41.581045 ops/training.py:65 2019-01-16 10:33:41.580991: step 7861, loss = 0.60979 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:33:42.544412 ops/training.py:65 2019-01-16 10:33:42.544339: step 7862, loss = 0.66869 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:33:43.506911 ops/training.py:65 2019-01-16 10:33:43.506835: step 7863, loss = 0.80167 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 10:33:44.471213 ops/training.py:65 2019-01-16 10:33:44.471146: step 7864, loss = 0.63780 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:33:45.435410 ops/training.py:65 2019-01-16 10:33:45.435338: step 7865, loss = 0.67809 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:33:46.396075 ops/training.py:65 2019-01-16 10:33:46.396022: step 7866, loss = 0.73991 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:33:47.357870 ops/training.py:65 2019-01-16 10:33:47.357809: step 7867, loss = 0.63027 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:33:48.322502 ops/training.py:65 2019-01-16 10:33:48.322450: step 7868, loss = 0.71680 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:33:49.288051 ops/training.py:65 2019-01-16 10:33:49.288002: step 7869, loss = 0.73374 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:33:50.250865 ops/training.py:65 2019-01-16 10:33:50.250806: step 7870, loss = 0.67268 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:33:51.213190 ops/training.py:65 2019-01-16 10:33:51.213132: step 7871, loss = 0.75587 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:33:52.172986 ops/training.py:65 2019-01-16 10:33:52.172922: step 7872, loss = 0.72119 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:33:53.137816 ops/training.py:65 2019-01-16 10:33:53.137766: step 7873, loss = 0.70186 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:33:54.101459 ops/training.py:65 2019-01-16 10:33:54.101378: step 7874, loss = 0.64319 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:33:55.064878 ops/training.py:65 2019-01-16 10:33:55.064811: step 7875, loss = 0.68495 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:33:56.026880 ops/training.py:65 2019-01-16 10:33:56.026814: step 7876, loss = 0.66932 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:33:56.989142 ops/training.py:65 2019-01-16 10:33:56.989078: step 7877, loss = 0.66225 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:33:57.950951 ops/training.py:65 2019-01-16 10:33:57.950874: step 7878, loss = 0.70869 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:33:58.913562 ops/training.py:65 2019-01-16 10:33:58.913510: step 7879, loss = 0.65328 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:33:59.875091 ops/training.py:65 2019-01-16 10:33:59.875033: step 7880, loss = 0.69266 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:34:00.837115 ops/training.py:65 2019-01-16 10:34:00.837065: step 7881, loss = 0.72756 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:34:01.797761 ops/training.py:65 2019-01-16 10:34:01.797714: step 7882, loss = 0.63891 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:34:02.760418 ops/training.py:65 2019-01-16 10:34:02.760348: step 7883, loss = 0.67752 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:34:03.722927 ops/training.py:65 2019-01-16 10:34:03.722860: step 7884, loss = 0.67885 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:34:04.685978 ops/training.py:65 2019-01-16 10:34:04.685922: step 7885, loss = 0.64804 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:34:05.647623 ops/training.py:65 2019-01-16 10:34:05.647569: step 7886, loss = 0.62921 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:34:06.613170 ops/training.py:65 2019-01-16 10:34:06.613123: step 7887, loss = 0.69727 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:34:07.577575 ops/training.py:65 2019-01-16 10:34:07.577524: step 7888, loss = 0.67043 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:34:08.541382 ops/training.py:65 2019-01-16 10:34:08.541335: step 7889, loss = 0.67506 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:34:09.503112 ops/training.py:65 2019-01-16 10:34:09.503061: step 7890, loss = 0.72448 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:34:10.463866 ops/training.py:65 2019-01-16 10:34:10.463813: step 7891, loss = 0.69187 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:34:11.428510 ops/training.py:65 2019-01-16 10:34:11.428455: step 7892, loss = 0.63880 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:34:12.394032 ops/training.py:65 2019-01-16 10:34:12.393979: step 7893, loss = 0.68013 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:34:13.358622 ops/training.py:65 2019-01-16 10:34:13.358575: step 7894, loss = 0.68066 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:34:14.321103 ops/training.py:65 2019-01-16 10:34:14.321056: step 7895, loss = 0.74361 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:34:15.283104 ops/training.py:65 2019-01-16 10:34:15.283044: step 7896, loss = 0.62387 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:34:16.244517 ops/training.py:65 2019-01-16 10:34:16.244465: step 7897, loss = 0.66774 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:34:17.205476 ops/training.py:65 2019-01-16 10:34:17.205422: step 7898, loss = 0.58283 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 10:34:18.166567 ops/training.py:65 2019-01-16 10:34:18.166516: step 7899, loss = 0.68508 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:34:19.127353 ops/training.py:65 2019-01-16 10:34:19.127298: step 7900, loss = 0.70929 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:34:20.088799 ops/training.py:65 2019-01-16 10:34:20.088750: step 7901, loss = 0.71011 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:34:21.049849 ops/training.py:65 2019-01-16 10:34:21.049796: step 7902, loss = 0.62949 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:34:22.010800 ops/training.py:65 2019-01-16 10:34:22.010735: step 7903, loss = 0.67657 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:34:22.970390 ops/training.py:65 2019-01-16 10:34:22.970339: step 7904, loss = 0.69589 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:34:23.932882 ops/training.py:65 2019-01-16 10:34:23.932825: step 7905, loss = 0.66599 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:34:24.898071 ops/training.py:65 2019-01-16 10:34:24.898021: step 7906, loss = 0.64352 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:34:25.869940 ops/training.py:65 2019-01-16 10:34:25.869873: step 7907, loss = 0.68075 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:34:26.831814 ops/training.py:65 2019-01-16 10:34:26.831753: step 7908, loss = 0.65016 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:34:27.794455 ops/training.py:65 2019-01-16 10:34:27.794396: step 7909, loss = 0.72179 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:34:28.755123 ops/training.py:65 2019-01-16 10:34:28.755075: step 7910, loss = 0.69111 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:34:29.719137 ops/training.py:65 2019-01-16 10:34:29.719091: step 7911, loss = 0.60323 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:34:30.682275 ops/training.py:65 2019-01-16 10:34:30.682225: step 7912, loss = 0.69060 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:34:31.646394 ops/training.py:65 2019-01-16 10:34:31.646340: step 7913, loss = 0.70347 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:34:32.608231 ops/training.py:65 2019-01-16 10:34:32.608172: step 7914, loss = 0.67786 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:34:33.571141 ops/training.py:65 2019-01-16 10:34:33.571077: step 7915, loss = 0.66420 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:34:34.533365 ops/training.py:65 2019-01-16 10:34:34.533300: step 7916, loss = 0.69337 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:34:35.495339 ops/training.py:65 2019-01-16 10:34:35.495290: step 7917, loss = 0.59363 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:34:36.455922 ops/training.py:65 2019-01-16 10:34:36.455870: step 7918, loss = 0.71767 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:34:37.420187 ops/training.py:65 2019-01-16 10:34:37.420137: step 7919, loss = 0.68570 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:34:38.385383 ops/training.py:65 2019-01-16 10:34:38.385336: step 7920, loss = 0.69139 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:34:39.349756 ops/training.py:65 2019-01-16 10:34:39.349704: step 7921, loss = 0.68938 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:34:40.311072 ops/training.py:65 2019-01-16 10:34:40.311017: step 7922, loss = 0.65071 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:34:41.274239 ops/training.py:65 2019-01-16 10:34:41.274182: step 7923, loss = 0.63914 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:34:42.236361 ops/training.py:65 2019-01-16 10:34:42.236291: step 7924, loss = 0.67305 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:34:43.199494 ops/training.py:65 2019-01-16 10:34:43.199433: step 7925, loss = 0.66645 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:34:44.164013 ops/training.py:65 2019-01-16 10:34:44.163941: step 7926, loss = 0.69169 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:34:45.126836 ops/training.py:65 2019-01-16 10:34:45.126786: step 7927, loss = 0.63097 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:34:46.087853 ops/training.py:65 2019-01-16 10:34:46.087800: step 7928, loss = 0.66062 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:34:47.049233 ops/training.py:65 2019-01-16 10:34:47.049178: step 7929, loss = 0.64764 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:34:48.009532 ops/training.py:65 2019-01-16 10:34:48.009485: step 7930, loss = 0.69039 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:34:48.970725 ops/training.py:65 2019-01-16 10:34:48.970673: step 7931, loss = 0.68797 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:34:49.936266 ops/training.py:65 2019-01-16 10:34:49.936216: step 7932, loss = 0.69020 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:34:50.900652 ops/training.py:65 2019-01-16 10:34:50.900605: step 7933, loss = 0.72070 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:34:51.864469 ops/training.py:65 2019-01-16 10:34:51.864420: step 7934, loss = 0.76820 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:34:52.826285 ops/training.py:65 2019-01-16 10:34:52.826231: step 7935, loss = 0.75853 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:34:53.787426 ops/training.py:65 2019-01-16 10:34:53.787372: step 7936, loss = 0.67408 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:34:54.749587 ops/training.py:65 2019-01-16 10:34:54.749537: step 7937, loss = 0.64911 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:34:55.714205 ops/training.py:65 2019-01-16 10:34:55.714157: step 7938, loss = 0.69187 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:34:56.677878 ops/training.py:65 2019-01-16 10:34:56.677825: step 7939, loss = 0.73281 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:34:57.641361 ops/training.py:65 2019-01-16 10:34:57.641311: step 7940, loss = 0.68273 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:34:58.603176 ops/training.py:65 2019-01-16 10:34:58.603128: step 7941, loss = 0.64189 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:34:59.564494 ops/training.py:65 2019-01-16 10:34:59.564443: step 7942, loss = 0.65785 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:35:00.524878 ops/training.py:65 2019-01-16 10:35:00.524830: step 7943, loss = 0.66802 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:35:01.486951 ops/training.py:65 2019-01-16 10:35:01.486905: step 7944, loss = 0.69669 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:35:02.448085 ops/training.py:65 2019-01-16 10:35:02.448035: step 7945, loss = 0.58437 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 10:35:03.410321 ops/training.py:65 2019-01-16 10:35:03.410260: step 7946, loss = 0.64018 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:35:04.373333 ops/training.py:65 2019-01-16 10:35:04.373268: step 7947, loss = 0.70537 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:35:05.336106 ops/training.py:65 2019-01-16 10:35:05.336035: step 7948, loss = 0.61544 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:35:06.297588 ops/training.py:65 2019-01-16 10:35:06.297515: step 7949, loss = 0.62902 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:35:07.258147 ops/training.py:65 2019-01-16 10:35:07.258098: step 7950, loss = 0.66526 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:35:08.218847 ops/training.py:65 2019-01-16 10:35:08.218797: step 7951, loss = 0.74939 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:35:09.183429 ops/training.py:65 2019-01-16 10:35:09.183377: step 7952, loss = 0.63333 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:35:10.147649 ops/training.py:65 2019-01-16 10:35:10.147602: step 7953, loss = 0.62983 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:35:11.112450 ops/training.py:65 2019-01-16 10:35:11.112399: step 7954, loss = 0.69255 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:35:12.075166 ops/training.py:65 2019-01-16 10:35:12.075113: step 7955, loss = 0.65863 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:35:13.036786 ops/training.py:65 2019-01-16 10:35:13.036739: step 7956, loss = 0.71183 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:35:13.998598 ops/training.py:65 2019-01-16 10:35:13.998544: step 7957, loss = 0.68349 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:35:14.960307 ops/training.py:65 2019-01-16 10:35:14.960256: step 7958, loss = 0.68883 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:35:15.922511 ops/training.py:65 2019-01-16 10:35:15.922456: step 7959, loss = 0.72003 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:35:16.885419 ops/training.py:65 2019-01-16 10:35:16.885353: step 7960, loss = 0.66920 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:35:17.851148 ops/training.py:65 2019-01-16 10:35:17.851075: step 7961, loss = 0.70606 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:35:18.815235 ops/training.py:65 2019-01-16 10:35:18.815180: step 7962, loss = 0.66206 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:35:19.776191 ops/training.py:65 2019-01-16 10:35:19.776138: step 7963, loss = 0.67877 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:35:20.736501 ops/training.py:65 2019-01-16 10:35:20.736430: step 7964, loss = 0.68097 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:35:21.696350 ops/training.py:65 2019-01-16 10:35:21.696277: step 7965, loss = 0.60978 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:35:22.656885 ops/training.py:65 2019-01-16 10:35:22.656818: step 7966, loss = 0.72424 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:35:23.619923 ops/training.py:65 2019-01-16 10:35:23.619858: step 7967, loss = 0.59328 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:35:24.583413 ops/training.py:65 2019-01-16 10:35:24.583350: step 7968, loss = 0.63312 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:35:25.545997 ops/training.py:65 2019-01-16 10:35:25.545944: step 7969, loss = 0.72944 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:35:26.510355 ops/training.py:65 2019-01-16 10:35:26.510305: step 7970, loss = 0.70659 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:35:27.472140 ops/training.py:65 2019-01-16 10:35:27.472089: step 7971, loss = 0.67817 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:35:28.432901 ops/training.py:65 2019-01-16 10:35:28.432848: step 7972, loss = 0.66563 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:35:29.393546 ops/training.py:65 2019-01-16 10:35:29.393497: step 7973, loss = 0.68685 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:35:30.354365 ops/training.py:65 2019-01-16 10:35:30.354311: step 7974, loss = 0.72927 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:35:31.318841 ops/training.py:65 2019-01-16 10:35:31.318787: step 7975, loss = 0.76241 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:35:32.281892 ops/training.py:65 2019-01-16 10:35:32.281839: step 7976, loss = 0.71653 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:35:33.244923 ops/training.py:65 2019-01-16 10:35:33.244868: step 7977, loss = 0.67684 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:35:34.206159 ops/training.py:65 2019-01-16 10:35:34.206078: step 7978, loss = 0.67539 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:35:35.167463 ops/training.py:65 2019-01-16 10:35:35.167385: step 7979, loss = 0.69398 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:35:36.128163 ops/training.py:65 2019-01-16 10:35:36.128097: step 7980, loss = 0.62657 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:35:37.093723 ops/training.py:65 2019-01-16 10:35:37.093643: step 7981, loss = 0.69181 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:35:38.055674 ops/training.py:65 2019-01-16 10:35:38.055626: step 7982, loss = 0.64465 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:35:39.018669 ops/training.py:65 2019-01-16 10:35:39.018603: step 7983, loss = 0.69305 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:35:39.982262 ops/training.py:65 2019-01-16 10:35:39.982196: step 7984, loss = 0.69039 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:35:40.945811 ops/training.py:65 2019-01-16 10:35:40.945747: step 7985, loss = 0.65495 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:35:41.908210 ops/training.py:65 2019-01-16 10:35:41.908144: step 7986, loss = 0.68593 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:35:42.867678 ops/training.py:65 2019-01-16 10:35:42.867611: step 7987, loss = 0.70933 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:35:43.830640 ops/training.py:65 2019-01-16 10:35:43.830574: step 7988, loss = 0.69106 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:35:44.793048 ops/training.py:65 2019-01-16 10:35:44.792997: step 7989, loss = 0.64030 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:35:45.754043 ops/training.py:65 2019-01-16 10:35:45.753998: step 7990, loss = 0.60965 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:35:46.714205 ops/training.py:65 2019-01-16 10:35:46.714154: step 7991, loss = 0.67598 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:35:47.673457 ops/training.py:65 2019-01-16 10:35:47.673402: step 7992, loss = 0.62344 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:35:48.634188 ops/training.py:65 2019-01-16 10:35:48.634135: step 7993, loss = 0.64589 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:35:49.594274 ops/training.py:65 2019-01-16 10:35:49.594212: step 7994, loss = 0.73678 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:35:50.554368 ops/training.py:65 2019-01-16 10:35:50.554309: step 7995, loss = 0.69651 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:35:51.519486 ops/training.py:65 2019-01-16 10:35:51.519418: step 7996, loss = 0.61555 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:35:52.481438 ops/training.py:65 2019-01-16 10:35:52.481376: step 7997, loss = 0.75052 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:35:53.444652 ops/training.py:65 2019-01-16 10:35:53.444591: step 7998, loss = 0.62787 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:35:54.405761 ops/training.py:65 2019-01-16 10:35:54.405708: step 7999, loss = 0.69866 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:40:33.621442 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I0832 2019-01-16 10:40:33.622278 ops/training.py:41 2019-01-16 10:40:33.622228: step 8000, loss = 0.69 (0.1 examples/sec; 278.254 sec/batch) | Training accuracy = 0.5625 | Validation accuracy = 0.56645 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_08_07_39_512188
I0832 2019-01-16 10:40:34.585018 ops/training.py:65 2019-01-16 10:40:34.584966: step 8001, loss = 0.68892 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:40:35.548898 ops/training.py:65 2019-01-16 10:40:35.548836: step 8002, loss = 0.65542 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:40:36.510320 ops/training.py:65 2019-01-16 10:40:36.510274: step 8003, loss = 0.68184 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:40:37.470873 ops/training.py:65 2019-01-16 10:40:37.470822: step 8004, loss = 0.66952 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:40:38.430496 ops/training.py:65 2019-01-16 10:40:38.430446: step 8005, loss = 0.63402 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:40:39.391676 ops/training.py:65 2019-01-16 10:40:39.391617: step 8006, loss = 0.69795 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:40:40.352036 ops/training.py:65 2019-01-16 10:40:40.351978: step 8007, loss = 0.66856 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:40:41.312893 ops/training.py:65 2019-01-16 10:40:41.312835: step 8008, loss = 0.67511 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:40:42.276668 ops/training.py:65 2019-01-16 10:40:42.276620: step 8009, loss = 0.63835 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:40:43.239837 ops/training.py:65 2019-01-16 10:40:43.239784: step 8010, loss = 0.62185 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:40:44.201777 ops/training.py:65 2019-01-16 10:40:44.201718: step 8011, loss = 0.66153 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:40:45.164951 ops/training.py:65 2019-01-16 10:40:45.164889: step 8012, loss = 0.66972 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:40:46.127564 ops/training.py:65 2019-01-16 10:40:46.127499: step 8013, loss = 0.63637 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:40:47.089720 ops/training.py:65 2019-01-16 10:40:47.089673: step 8014, loss = 0.66798 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:40:48.051749 ops/training.py:65 2019-01-16 10:40:48.051706: step 8015, loss = 0.69995 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:40:49.014994 ops/training.py:65 2019-01-16 10:40:49.014949: step 8016, loss = 0.68589 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:40:49.978428 ops/training.py:65 2019-01-16 10:40:49.978373: step 8017, loss = 0.72609 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:40:50.939468 ops/training.py:65 2019-01-16 10:40:50.939412: step 8018, loss = 0.73319 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:40:51.901303 ops/training.py:65 2019-01-16 10:40:51.901236: step 8019, loss = 0.69742 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:40:52.863464 ops/training.py:65 2019-01-16 10:40:52.863410: step 8020, loss = 0.71446 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:40:53.826108 ops/training.py:65 2019-01-16 10:40:53.826049: step 8021, loss = 0.73110 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:40:54.788360 ops/training.py:65 2019-01-16 10:40:54.788296: step 8022, loss = 0.65595 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:40:55.752927 ops/training.py:65 2019-01-16 10:40:55.752873: step 8023, loss = 0.72609 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:40:56.715777 ops/training.py:65 2019-01-16 10:40:56.715729: step 8024, loss = 0.68605 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:40:57.679158 ops/training.py:65 2019-01-16 10:40:57.679098: step 8025, loss = 0.66784 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:40:58.640891 ops/training.py:65 2019-01-16 10:40:58.640830: step 8026, loss = 0.65272 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:40:59.602279 ops/training.py:65 2019-01-16 10:40:59.602231: step 8027, loss = 0.65092 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:41:00.563006 ops/training.py:65 2019-01-16 10:41:00.562952: step 8028, loss = 0.72658 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:41:01.524239 ops/training.py:65 2019-01-16 10:41:01.524184: step 8029, loss = 0.67977 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:41:02.485346 ops/training.py:65 2019-01-16 10:41:02.485280: step 8030, loss = 0.70953 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:41:03.447575 ops/training.py:65 2019-01-16 10:41:03.447521: step 8031, loss = 0.70984 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:41:04.409324 ops/training.py:65 2019-01-16 10:41:04.409259: step 8032, loss = 0.67249 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:41:05.370277 ops/training.py:65 2019-01-16 10:41:05.370209: step 8033, loss = 0.63234 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:41:06.331491 ops/training.py:65 2019-01-16 10:41:06.331444: step 8034, loss = 0.68027 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:41:07.294212 ops/training.py:65 2019-01-16 10:41:07.294161: step 8035, loss = 0.74791 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:41:08.255391 ops/training.py:65 2019-01-16 10:41:08.255337: step 8036, loss = 0.67739 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:41:09.217988 ops/training.py:65 2019-01-16 10:41:09.217940: step 8037, loss = 0.62831 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:41:10.179580 ops/training.py:65 2019-01-16 10:41:10.179508: step 8038, loss = 0.64946 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:41:11.139617 ops/training.py:65 2019-01-16 10:41:11.139547: step 8039, loss = 0.71643 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:41:12.100093 ops/training.py:65 2019-01-16 10:41:12.100051: step 8040, loss = 0.65044 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:41:13.060745 ops/training.py:65 2019-01-16 10:41:13.060685: step 8041, loss = 0.68686 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:41:14.024204 ops/training.py:65 2019-01-16 10:41:14.024152: step 8042, loss = 0.69738 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:41:14.988190 ops/training.py:65 2019-01-16 10:41:14.988136: step 8043, loss = 0.75589 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:41:15.949613 ops/training.py:65 2019-01-16 10:41:15.949561: step 8044, loss = 0.67178 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:41:16.913807 ops/training.py:65 2019-01-16 10:41:16.913756: step 8045, loss = 0.63949 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:41:17.877733 ops/training.py:65 2019-01-16 10:41:17.877679: step 8046, loss = 0.69110 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:41:18.841044 ops/training.py:65 2019-01-16 10:41:18.840991: step 8047, loss = 0.62748 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:41:19.802439 ops/training.py:65 2019-01-16 10:41:19.802379: step 8048, loss = 0.66732 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:41:20.763892 ops/training.py:65 2019-01-16 10:41:20.763831: step 8049, loss = 0.73357 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:41:21.725250 ops/training.py:65 2019-01-16 10:41:21.725196: step 8050, loss = 0.74259 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:41:22.686385 ops/training.py:65 2019-01-16 10:41:22.686334: step 8051, loss = 0.70093 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:41:23.647114 ops/training.py:65 2019-01-16 10:41:23.647062: step 8052, loss = 0.73450 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:41:24.607596 ops/training.py:65 2019-01-16 10:41:24.607543: step 8053, loss = 0.75060 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:41:25.568165 ops/training.py:65 2019-01-16 10:41:25.568113: step 8054, loss = 0.71167 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:41:26.528950 ops/training.py:65 2019-01-16 10:41:26.528900: step 8055, loss = 0.65358 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:41:27.489843 ops/training.py:65 2019-01-16 10:41:27.489782: step 8056, loss = 0.74403 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:41:28.450253 ops/training.py:65 2019-01-16 10:41:28.450200: step 8057, loss = 0.72353 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:41:29.410917 ops/training.py:65 2019-01-16 10:41:29.410861: step 8058, loss = 0.66939 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:41:30.373158 ops/training.py:65 2019-01-16 10:41:30.373092: step 8059, loss = 0.69091 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:41:31.333325 ops/training.py:65 2019-01-16 10:41:31.333273: step 8060, loss = 0.68646 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:41:32.294004 ops/training.py:65 2019-01-16 10:41:32.293951: step 8061, loss = 0.74365 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:41:33.255148 ops/training.py:65 2019-01-16 10:41:33.255091: step 8062, loss = 0.66760 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:41:34.217633 ops/training.py:65 2019-01-16 10:41:34.217584: step 8063, loss = 0.67728 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:41:35.178716 ops/training.py:65 2019-01-16 10:41:35.178663: step 8064, loss = 0.71202 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:41:36.139394 ops/training.py:65 2019-01-16 10:41:36.139334: step 8065, loss = 0.67851 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:41:37.100188 ops/training.py:65 2019-01-16 10:41:37.100125: step 8066, loss = 0.68687 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:41:38.062357 ops/training.py:65 2019-01-16 10:41:38.062292: step 8067, loss = 0.68098 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:41:39.022919 ops/training.py:65 2019-01-16 10:41:39.022848: step 8068, loss = 0.71446 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:41:39.985383 ops/training.py:65 2019-01-16 10:41:39.985327: step 8069, loss = 0.72404 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:41:40.946476 ops/training.py:65 2019-01-16 10:41:40.946408: step 8070, loss = 0.68560 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:41:41.907363 ops/training.py:65 2019-01-16 10:41:41.907310: step 8071, loss = 0.69053 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:41:42.869712 ops/training.py:65 2019-01-16 10:41:42.869647: step 8072, loss = 0.77350 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:41:43.833964 ops/training.py:65 2019-01-16 10:41:43.833898: step 8073, loss = 0.68557 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:41:44.796999 ops/training.py:65 2019-01-16 10:41:44.796944: step 8074, loss = 0.68825 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:41:45.760510 ops/training.py:65 2019-01-16 10:41:45.760455: step 8075, loss = 0.67581 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:41:46.721663 ops/training.py:65 2019-01-16 10:41:46.721603: step 8076, loss = 0.65914 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:41:47.682097 ops/training.py:65 2019-01-16 10:41:47.682034: step 8077, loss = 0.69781 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:41:48.642201 ops/training.py:65 2019-01-16 10:41:48.642140: step 8078, loss = 0.68421 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:41:49.605837 ops/training.py:65 2019-01-16 10:41:49.605789: step 8079, loss = 0.63156 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:41:50.566493 ops/training.py:65 2019-01-16 10:41:50.566434: step 8080, loss = 0.70343 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:41:51.528606 ops/training.py:65 2019-01-16 10:41:51.528551: step 8081, loss = 0.75643 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:41:52.490464 ops/training.py:65 2019-01-16 10:41:52.490406: step 8082, loss = 0.70834 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:41:53.451642 ops/training.py:65 2019-01-16 10:41:53.451584: step 8083, loss = 0.69411 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:41:54.416773 ops/training.py:65 2019-01-16 10:41:54.416723: step 8084, loss = 0.62359 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:41:55.380662 ops/training.py:65 2019-01-16 10:41:55.380590: step 8085, loss = 0.63758 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:41:56.343553 ops/training.py:65 2019-01-16 10:41:56.343480: step 8086, loss = 0.75400 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:41:57.305280 ops/training.py:65 2019-01-16 10:41:57.305208: step 8087, loss = 0.70277 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:41:58.267613 ops/training.py:65 2019-01-16 10:41:58.267548: step 8088, loss = 0.73683 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:41:59.231779 ops/training.py:65 2019-01-16 10:41:59.231714: step 8089, loss = 0.72588 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:42:00.194480 ops/training.py:65 2019-01-16 10:42:00.194404: step 8090, loss = 0.62689 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:42:01.155064 ops/training.py:65 2019-01-16 10:42:01.154997: step 8091, loss = 0.66484 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:42:02.116023 ops/training.py:65 2019-01-16 10:42:02.115972: step 8092, loss = 0.72636 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:42:03.076788 ops/training.py:65 2019-01-16 10:42:03.076739: step 8093, loss = 0.67614 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:42:04.038560 ops/training.py:65 2019-01-16 10:42:04.038488: step 8094, loss = 0.63722 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:42:05.001136 ops/training.py:65 2019-01-16 10:42:05.001075: step 8095, loss = 0.69503 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:42:05.963079 ops/training.py:65 2019-01-16 10:42:05.963014: step 8096, loss = 0.67924 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:42:06.924977 ops/training.py:65 2019-01-16 10:42:06.924928: step 8097, loss = 0.60361 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:42:07.886451 ops/training.py:65 2019-01-16 10:42:07.886400: step 8098, loss = 0.67082 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:42:08.848602 ops/training.py:65 2019-01-16 10:42:08.848549: step 8099, loss = 0.68332 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:42:09.810109 ops/training.py:65 2019-01-16 10:42:09.810054: step 8100, loss = 0.65802 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:42:10.772725 ops/training.py:65 2019-01-16 10:42:10.772654: step 8101, loss = 0.62926 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:42:11.738253 ops/training.py:65 2019-01-16 10:42:11.738187: step 8102, loss = 0.71178 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:42:12.701377 ops/training.py:65 2019-01-16 10:42:12.701323: step 8103, loss = 0.71489 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:42:13.663754 ops/training.py:65 2019-01-16 10:42:13.663684: step 8104, loss = 0.67403 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:42:14.628185 ops/training.py:65 2019-01-16 10:42:14.628119: step 8105, loss = 0.70635 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:42:15.592532 ops/training.py:65 2019-01-16 10:42:15.592468: step 8106, loss = 0.66804 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:42:16.554828 ops/training.py:65 2019-01-16 10:42:16.554774: step 8107, loss = 0.65264 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:42:17.519066 ops/training.py:65 2019-01-16 10:42:17.519003: step 8108, loss = 0.67135 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:42:18.481281 ops/training.py:65 2019-01-16 10:42:18.481215: step 8109, loss = 0.66107 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:42:19.443605 ops/training.py:65 2019-01-16 10:42:19.443554: step 8110, loss = 0.63088 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:42:20.405159 ops/training.py:65 2019-01-16 10:42:20.405107: step 8111, loss = 0.58838 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 10:42:21.369012 ops/training.py:65 2019-01-16 10:42:21.368959: step 8112, loss = 0.66753 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:42:22.331837 ops/training.py:65 2019-01-16 10:42:22.331772: step 8113, loss = 0.65807 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:42:23.294958 ops/training.py:65 2019-01-16 10:42:23.294891: step 8114, loss = 0.71849 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:42:24.255935 ops/training.py:65 2019-01-16 10:42:24.255884: step 8115, loss = 0.67526 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:42:25.218820 ops/training.py:65 2019-01-16 10:42:25.218758: step 8116, loss = 0.76534 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:42:26.182869 ops/training.py:65 2019-01-16 10:42:26.182819: step 8117, loss = 0.68343 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:42:27.144943 ops/training.py:65 2019-01-16 10:42:27.144872: step 8118, loss = 0.73385 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:42:28.108809 ops/training.py:65 2019-01-16 10:42:28.108741: step 8119, loss = 0.72367 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:42:29.071471 ops/training.py:65 2019-01-16 10:42:29.071402: step 8120, loss = 0.76997 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:42:30.033678 ops/training.py:65 2019-01-16 10:42:30.033611: step 8121, loss = 0.66409 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:42:30.996117 ops/training.py:65 2019-01-16 10:42:30.996048: step 8122, loss = 0.62411 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:42:31.956990 ops/training.py:65 2019-01-16 10:42:31.956948: step 8123, loss = 0.69597 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:42:32.917713 ops/training.py:65 2019-01-16 10:42:32.917641: step 8124, loss = 0.67241 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:42:33.878955 ops/training.py:65 2019-01-16 10:42:33.878903: step 8125, loss = 0.66078 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:42:34.842877 ops/training.py:65 2019-01-16 10:42:34.842810: step 8126, loss = 0.72259 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:42:35.804807 ops/training.py:65 2019-01-16 10:42:35.804755: step 8127, loss = 0.62707 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:42:36.766458 ops/training.py:65 2019-01-16 10:42:36.766405: step 8128, loss = 0.64990 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:42:37.730092 ops/training.py:65 2019-01-16 10:42:37.730016: step 8129, loss = 0.65200 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:42:38.691140 ops/training.py:65 2019-01-16 10:42:38.691088: step 8130, loss = 0.69233 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:42:39.653619 ops/training.py:65 2019-01-16 10:42:39.653563: step 8131, loss = 0.67827 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:42:40.615719 ops/training.py:65 2019-01-16 10:42:40.615649: step 8132, loss = 0.65755 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:42:41.578119 ops/training.py:65 2019-01-16 10:42:41.578072: step 8133, loss = 0.69547 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:42:42.539316 ops/training.py:65 2019-01-16 10:42:42.539246: step 8134, loss = 0.64287 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:42:43.501919 ops/training.py:65 2019-01-16 10:42:43.501845: step 8135, loss = 0.67892 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:42:44.462198 ops/training.py:65 2019-01-16 10:42:44.462131: step 8136, loss = 0.71153 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:42:45.422110 ops/training.py:65 2019-01-16 10:42:45.422044: step 8137, loss = 0.70583 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:42:46.381890 ops/training.py:65 2019-01-16 10:42:46.381798: step 8138, loss = 0.67472 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:42:47.343982 ops/training.py:65 2019-01-16 10:42:47.343910: step 8139, loss = 0.62381 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:42:48.306197 ops/training.py:65 2019-01-16 10:42:48.306129: step 8140, loss = 0.75014 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:42:49.269034 ops/training.py:65 2019-01-16 10:42:49.268981: step 8141, loss = 0.74882 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:42:50.230614 ops/training.py:65 2019-01-16 10:42:50.230557: step 8142, loss = 0.77284 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:42:51.193360 ops/training.py:65 2019-01-16 10:42:51.193316: step 8143, loss = 0.70634 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:42:52.153716 ops/training.py:65 2019-01-16 10:42:52.153647: step 8144, loss = 0.68077 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:42:53.113604 ops/training.py:65 2019-01-16 10:42:53.113537: step 8145, loss = 0.65734 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:42:54.075723 ops/training.py:65 2019-01-16 10:42:54.075673: step 8146, loss = 0.63071 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:42:55.037544 ops/training.py:65 2019-01-16 10:42:55.037481: step 8147, loss = 0.70216 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:42:55.998715 ops/training.py:65 2019-01-16 10:42:55.998646: step 8148, loss = 0.69518 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:42:56.961275 ops/training.py:65 2019-01-16 10:42:56.961204: step 8149, loss = 0.72767 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:42:57.924330 ops/training.py:65 2019-01-16 10:42:57.924256: step 8150, loss = 0.68796 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:42:58.887209 ops/training.py:65 2019-01-16 10:42:58.887137: step 8151, loss = 0.74049 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:42:59.848712 ops/training.py:65 2019-01-16 10:42:59.848640: step 8152, loss = 0.60071 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:43:00.812480 ops/training.py:65 2019-01-16 10:43:00.812422: step 8153, loss = 0.68272 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:43:01.775011 ops/training.py:65 2019-01-16 10:43:01.774954: step 8154, loss = 0.69371 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:43:02.737881 ops/training.py:65 2019-01-16 10:43:02.737807: step 8155, loss = 0.78483 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:43:03.701390 ops/training.py:65 2019-01-16 10:43:03.701333: step 8156, loss = 0.66853 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:43:04.665215 ops/training.py:65 2019-01-16 10:43:04.665149: step 8157, loss = 0.79679 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 10:43:05.628006 ops/training.py:65 2019-01-16 10:43:05.627940: step 8158, loss = 0.66311 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:43:06.589453 ops/training.py:65 2019-01-16 10:43:06.589372: step 8159, loss = 0.75476 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:43:07.551528 ops/training.py:65 2019-01-16 10:43:07.551465: step 8160, loss = 0.71665 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:43:08.511967 ops/training.py:65 2019-01-16 10:43:08.511916: step 8161, loss = 0.69322 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:43:09.471959 ops/training.py:65 2019-01-16 10:43:09.471912: step 8162, loss = 0.65325 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:43:10.433912 ops/training.py:65 2019-01-16 10:43:10.433850: step 8163, loss = 0.68982 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:43:11.400689 ops/training.py:65 2019-01-16 10:43:11.400624: step 8164, loss = 0.65180 (33.1 examples/sec; 0.966 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:43:12.364000 ops/training.py:65 2019-01-16 10:43:12.363948: step 8165, loss = 0.63035 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:43:13.329431 ops/training.py:65 2019-01-16 10:43:13.329381: step 8166, loss = 0.60117 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:43:14.291992 ops/training.py:65 2019-01-16 10:43:14.291940: step 8167, loss = 0.73700 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:43:15.253256 ops/training.py:65 2019-01-16 10:43:15.253200: step 8168, loss = 0.72310 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:43:16.214485 ops/training.py:65 2019-01-16 10:43:16.214432: step 8169, loss = 0.62072 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:43:17.175972 ops/training.py:65 2019-01-16 10:43:17.175919: step 8170, loss = 0.72445 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:43:18.138386 ops/training.py:65 2019-01-16 10:43:18.138332: step 8171, loss = 0.65750 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:43:19.101215 ops/training.py:65 2019-01-16 10:43:19.101159: step 8172, loss = 0.63858 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:43:20.064127 ops/training.py:65 2019-01-16 10:43:20.064073: step 8173, loss = 0.72187 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:43:21.026981 ops/training.py:65 2019-01-16 10:43:21.026919: step 8174, loss = 0.66853 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:43:21.987248 ops/training.py:65 2019-01-16 10:43:21.987181: step 8175, loss = 0.65671 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:43:22.950790 ops/training.py:65 2019-01-16 10:43:22.950719: step 8176, loss = 0.69877 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:43:23.914653 ops/training.py:65 2019-01-16 10:43:23.914602: step 8177, loss = 0.71670 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:43:24.878581 ops/training.py:65 2019-01-16 10:43:24.878521: step 8178, loss = 0.64502 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:43:25.840988 ops/training.py:65 2019-01-16 10:43:25.840921: step 8179, loss = 0.67694 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:43:26.802569 ops/training.py:65 2019-01-16 10:43:26.802505: step 8180, loss = 0.65647 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:43:27.765548 ops/training.py:65 2019-01-16 10:43:27.765476: step 8181, loss = 0.67784 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:43:28.726232 ops/training.py:65 2019-01-16 10:43:28.726177: step 8182, loss = 0.71077 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:43:29.689554 ops/training.py:65 2019-01-16 10:43:29.689505: step 8183, loss = 0.67189 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:43:30.652801 ops/training.py:65 2019-01-16 10:43:30.652752: step 8184, loss = 0.65328 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:43:31.616098 ops/training.py:65 2019-01-16 10:43:31.616045: step 8185, loss = 0.67946 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:43:32.577588 ops/training.py:65 2019-01-16 10:43:32.577541: step 8186, loss = 0.67116 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:43:33.539038 ops/training.py:65 2019-01-16 10:43:33.538982: step 8187, loss = 0.64294 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:43:34.500632 ops/training.py:65 2019-01-16 10:43:34.500564: step 8188, loss = 0.68234 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:43:35.464677 ops/training.py:65 2019-01-16 10:43:35.464622: step 8189, loss = 0.61399 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:43:36.428201 ops/training.py:65 2019-01-16 10:43:36.428142: step 8190, loss = 0.70192 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:43:37.389746 ops/training.py:65 2019-01-16 10:43:37.389694: step 8191, loss = 0.70750 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:43:38.351178 ops/training.py:65 2019-01-16 10:43:38.351123: step 8192, loss = 0.74206 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:43:39.315225 ops/training.py:65 2019-01-16 10:43:39.315166: step 8193, loss = 0.73338 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:43:40.280346 ops/training.py:65 2019-01-16 10:43:40.280293: step 8194, loss = 0.63364 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:43:41.243763 ops/training.py:65 2019-01-16 10:43:41.243697: step 8195, loss = 0.66701 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:43:42.205121 ops/training.py:65 2019-01-16 10:43:42.205057: step 8196, loss = 0.66978 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:43:43.166250 ops/training.py:65 2019-01-16 10:43:43.166186: step 8197, loss = 0.74854 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:43:44.129875 ops/training.py:65 2019-01-16 10:43:44.129800: step 8198, loss = 0.65239 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:43:45.091847 ops/training.py:65 2019-01-16 10:43:45.091786: step 8199, loss = 0.67920 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:43:46.053050 ops/training.py:65 2019-01-16 10:43:46.052981: step 8200, loss = 0.66766 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:43:47.016889 ops/training.py:65 2019-01-16 10:43:47.016825: step 8201, loss = 0.68813 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:43:47.980994 ops/training.py:65 2019-01-16 10:43:47.980942: step 8202, loss = 0.63803 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:43:48.943966 ops/training.py:65 2019-01-16 10:43:48.943916: step 8203, loss = 0.66645 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:43:49.906746 ops/training.py:65 2019-01-16 10:43:49.906692: step 8204, loss = 0.71212 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:43:50.868471 ops/training.py:65 2019-01-16 10:43:50.868420: step 8205, loss = 0.74822 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:43:51.830201 ops/training.py:65 2019-01-16 10:43:51.830140: step 8206, loss = 0.65141 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:43:52.791582 ops/training.py:65 2019-01-16 10:43:52.791529: step 8207, loss = 0.59892 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:43:53.753067 ops/training.py:65 2019-01-16 10:43:53.753009: step 8208, loss = 0.66078 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:43:54.717250 ops/training.py:65 2019-01-16 10:43:54.717184: step 8209, loss = 0.62150 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:43:55.681435 ops/training.py:65 2019-01-16 10:43:55.681369: step 8210, loss = 0.63299 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:43:56.645292 ops/training.py:65 2019-01-16 10:43:56.645248: step 8211, loss = 0.64220 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:43:57.605388 ops/training.py:65 2019-01-16 10:43:57.605324: step 8212, loss = 0.69620 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:43:58.565062 ops/training.py:65 2019-01-16 10:43:58.564997: step 8213, loss = 0.65155 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:43:59.526033 ops/training.py:65 2019-01-16 10:43:59.525967: step 8214, loss = 0.68688 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:44:00.487676 ops/training.py:65 2019-01-16 10:44:00.487615: step 8215, loss = 0.63198 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:44:01.452160 ops/training.py:65 2019-01-16 10:44:01.452088: step 8216, loss = 0.68378 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:44:02.412353 ops/training.py:65 2019-01-16 10:44:02.412305: step 8217, loss = 0.65320 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:44:03.376575 ops/training.py:65 2019-01-16 10:44:03.376510: step 8218, loss = 0.68938 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:44:04.340252 ops/training.py:65 2019-01-16 10:44:04.340191: step 8219, loss = 0.73175 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:44:05.303329 ops/training.py:65 2019-01-16 10:44:05.303263: step 8220, loss = 0.70114 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:44:06.263383 ops/training.py:65 2019-01-16 10:44:06.263310: step 8221, loss = 0.77687 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:44:07.223630 ops/training.py:65 2019-01-16 10:44:07.223560: step 8222, loss = 0.66157 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:44:08.183628 ops/training.py:65 2019-01-16 10:44:08.183573: step 8223, loss = 0.71737 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:44:09.143465 ops/training.py:65 2019-01-16 10:44:09.143409: step 8224, loss = 0.67754 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:44:10.108116 ops/training.py:65 2019-01-16 10:44:10.108052: step 8225, loss = 0.66918 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:44:11.071925 ops/training.py:65 2019-01-16 10:44:11.071869: step 8226, loss = 0.70943 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:44:12.036648 ops/training.py:65 2019-01-16 10:44:12.036591: step 8227, loss = 0.70283 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:44:12.997807 ops/training.py:65 2019-01-16 10:44:12.997748: step 8228, loss = 0.66743 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:44:13.959308 ops/training.py:65 2019-01-16 10:44:13.959247: step 8229, loss = 0.74057 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:44:14.920183 ops/training.py:65 2019-01-16 10:44:14.920138: step 8230, loss = 0.66173 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:44:15.881347 ops/training.py:65 2019-01-16 10:44:15.881284: step 8231, loss = 0.66641 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:44:16.842552 ops/training.py:65 2019-01-16 10:44:16.842498: step 8232, loss = 0.69078 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:44:17.804248 ops/training.py:65 2019-01-16 10:44:17.804207: step 8233, loss = 0.74191 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:44:18.766063 ops/training.py:65 2019-01-16 10:44:18.766005: step 8234, loss = 0.69295 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:44:19.727329 ops/training.py:65 2019-01-16 10:44:19.727271: step 8235, loss = 0.79070 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:44:20.688461 ops/training.py:65 2019-01-16 10:44:20.688397: step 8236, loss = 0.71475 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:44:21.650450 ops/training.py:65 2019-01-16 10:44:21.650379: step 8237, loss = 0.62528 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:44:22.611785 ops/training.py:65 2019-01-16 10:44:22.611713: step 8238, loss = 0.69331 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:44:23.573839 ops/training.py:65 2019-01-16 10:44:23.573773: step 8239, loss = 0.68936 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:44:24.535753 ops/training.py:65 2019-01-16 10:44:24.535685: step 8240, loss = 0.74193 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:44:25.497327 ops/training.py:65 2019-01-16 10:44:25.497262: step 8241, loss = 0.69727 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:44:26.458824 ops/training.py:65 2019-01-16 10:44:26.458750: step 8242, loss = 0.64765 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:44:27.419034 ops/training.py:65 2019-01-16 10:44:27.418980: step 8243, loss = 0.61616 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:44:28.379710 ops/training.py:65 2019-01-16 10:44:28.379648: step 8244, loss = 0.74851 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:44:29.343887 ops/training.py:65 2019-01-16 10:44:29.343820: step 8245, loss = 0.66357 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:44:30.308294 ops/training.py:65 2019-01-16 10:44:30.308224: step 8246, loss = 0.66784 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:44:31.271648 ops/training.py:65 2019-01-16 10:44:31.271591: step 8247, loss = 0.70482 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:44:32.234155 ops/training.py:65 2019-01-16 10:44:32.234085: step 8248, loss = 0.65097 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:44:33.196818 ops/training.py:65 2019-01-16 10:44:33.196774: step 8249, loss = 0.67885 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:44:34.158661 ops/training.py:65 2019-01-16 10:44:34.158591: step 8250, loss = 0.64966 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:44:35.118360 ops/training.py:65 2019-01-16 10:44:35.118288: step 8251, loss = 0.71010 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:44:36.083671 ops/training.py:65 2019-01-16 10:44:36.083603: step 8252, loss = 0.70090 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:44:37.047749 ops/training.py:65 2019-01-16 10:44:37.047674: step 8253, loss = 0.68732 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:44:38.010830 ops/training.py:65 2019-01-16 10:44:38.010759: step 8254, loss = 0.71241 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:44:38.973087 ops/training.py:65 2019-01-16 10:44:38.973014: step 8255, loss = 0.64909 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:44:39.934824 ops/training.py:65 2019-01-16 10:44:39.934756: step 8256, loss = 0.66760 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:44:40.895995 ops/training.py:65 2019-01-16 10:44:40.895930: step 8257, loss = 0.64908 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:44:41.857504 ops/training.py:65 2019-01-16 10:44:41.857438: step 8258, loss = 0.63367 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:44:42.819872 ops/training.py:65 2019-01-16 10:44:42.819825: step 8259, loss = 0.70236 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:44:43.780890 ops/training.py:65 2019-01-16 10:44:43.780818: step 8260, loss = 0.66118 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:44:44.741799 ops/training.py:65 2019-01-16 10:44:44.741726: step 8261, loss = 0.66688 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:44:45.702186 ops/training.py:65 2019-01-16 10:44:45.702134: step 8262, loss = 0.74505 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:44:46.661311 ops/training.py:65 2019-01-16 10:44:46.661242: step 8263, loss = 0.69002 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:44:47.619993 ops/training.py:65 2019-01-16 10:44:47.619918: step 8264, loss = 0.63558 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:44:48.579712 ops/training.py:65 2019-01-16 10:44:48.579652: step 8265, loss = 0.62929 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:44:49.542432 ops/training.py:65 2019-01-16 10:44:49.542390: step 8266, loss = 0.66869 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:44:50.505169 ops/training.py:65 2019-01-16 10:44:50.505130: step 8267, loss = 0.65654 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:44:51.467526 ops/training.py:65 2019-01-16 10:44:51.467471: step 8268, loss = 0.57641 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 10:44:52.429590 ops/training.py:65 2019-01-16 10:44:52.429536: step 8269, loss = 0.65196 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:44:53.393887 ops/training.py:65 2019-01-16 10:44:53.393837: step 8270, loss = 0.69567 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:44:54.357844 ops/training.py:65 2019-01-16 10:44:54.357779: step 8271, loss = 0.70840 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:44:55.321070 ops/training.py:65 2019-01-16 10:44:55.320996: step 8272, loss = 0.61921 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:44:56.282886 ops/training.py:65 2019-01-16 10:44:56.282828: step 8273, loss = 0.68074 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:44:57.243923 ops/training.py:65 2019-01-16 10:44:57.243871: step 8274, loss = 0.64012 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:44:58.207641 ops/training.py:65 2019-01-16 10:44:58.207587: step 8275, loss = 0.71560 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:44:59.171797 ops/training.py:65 2019-01-16 10:44:59.171749: step 8276, loss = 0.65995 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:45:00.133288 ops/training.py:65 2019-01-16 10:45:00.133235: step 8277, loss = 0.63527 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:45:01.094448 ops/training.py:65 2019-01-16 10:45:01.094385: step 8278, loss = 0.81719 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:45:02.054998 ops/training.py:65 2019-01-16 10:45:02.054952: step 8279, loss = 0.64712 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:45:03.017594 ops/training.py:65 2019-01-16 10:45:03.017543: step 8280, loss = 0.70298 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:45:03.979651 ops/training.py:65 2019-01-16 10:45:03.979603: step 8281, loss = 0.72557 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:45:04.941666 ops/training.py:65 2019-01-16 10:45:04.941618: step 8282, loss = 0.64308 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:45:05.902452 ops/training.py:65 2019-01-16 10:45:05.902406: step 8283, loss = 0.73885 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:45:06.862801 ops/training.py:65 2019-01-16 10:45:06.862749: step 8284, loss = 0.70790 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:45:07.824082 ops/training.py:65 2019-01-16 10:45:07.824009: step 8285, loss = 0.73239 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:45:08.786871 ops/training.py:65 2019-01-16 10:45:08.786812: step 8286, loss = 0.69881 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:45:09.749079 ops/training.py:65 2019-01-16 10:45:09.749026: step 8287, loss = 0.64223 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:45:10.710334 ops/training.py:65 2019-01-16 10:45:10.710291: step 8288, loss = 0.69757 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:45:11.671526 ops/training.py:65 2019-01-16 10:45:11.671468: step 8289, loss = 0.68864 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:45:12.632861 ops/training.py:65 2019-01-16 10:45:12.632813: step 8290, loss = 0.66653 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:45:13.594040 ops/training.py:65 2019-01-16 10:45:13.593990: step 8291, loss = 0.73067 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:45:14.555707 ops/training.py:65 2019-01-16 10:45:14.555653: step 8292, loss = 0.66810 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:45:15.516363 ops/training.py:65 2019-01-16 10:45:15.516311: step 8293, loss = 0.65454 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:45:16.477005 ops/training.py:65 2019-01-16 10:45:16.476951: step 8294, loss = 0.72460 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:45:17.438422 ops/training.py:65 2019-01-16 10:45:17.438369: step 8295, loss = 0.66322 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:45:18.398991 ops/training.py:65 2019-01-16 10:45:18.398940: step 8296, loss = 0.63681 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:45:19.360954 ops/training.py:65 2019-01-16 10:45:19.360900: step 8297, loss = 0.65876 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:45:20.324625 ops/training.py:65 2019-01-16 10:45:20.324579: step 8298, loss = 0.73629 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:45:21.288484 ops/training.py:65 2019-01-16 10:45:21.288423: step 8299, loss = 0.67085 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:45:22.251731 ops/training.py:65 2019-01-16 10:45:22.251672: step 8300, loss = 0.71507 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:45:23.215317 ops/training.py:65 2019-01-16 10:45:23.215267: step 8301, loss = 0.68279 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:45:24.180756 ops/training.py:65 2019-01-16 10:45:24.180716: step 8302, loss = 0.67708 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:45:25.144647 ops/training.py:65 2019-01-16 10:45:25.144606: step 8303, loss = 0.68683 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:45:26.105365 ops/training.py:65 2019-01-16 10:45:26.105316: step 8304, loss = 0.67835 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:45:27.066752 ops/training.py:65 2019-01-16 10:45:27.066684: step 8305, loss = 0.72269 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:45:28.029512 ops/training.py:65 2019-01-16 10:45:28.029445: step 8306, loss = 0.68906 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:45:28.992334 ops/training.py:65 2019-01-16 10:45:28.992262: step 8307, loss = 0.74776 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:45:29.953293 ops/training.py:65 2019-01-16 10:45:29.953231: step 8308, loss = 0.63846 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:45:30.914832 ops/training.py:65 2019-01-16 10:45:30.914766: step 8309, loss = 0.62107 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:45:31.876843 ops/training.py:65 2019-01-16 10:45:31.876776: step 8310, loss = 0.68537 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:45:32.839651 ops/training.py:65 2019-01-16 10:45:32.839578: step 8311, loss = 0.69922 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:45:33.803564 ops/training.py:65 2019-01-16 10:45:33.803493: step 8312, loss = 0.70859 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:45:34.767288 ops/training.py:65 2019-01-16 10:45:34.767216: step 8313, loss = 0.69785 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:45:35.732785 ops/training.py:65 2019-01-16 10:45:35.732736: step 8314, loss = 0.73404 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:45:36.697477 ops/training.py:65 2019-01-16 10:45:36.697423: step 8315, loss = 0.64881 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:45:37.660015 ops/training.py:65 2019-01-16 10:45:37.659956: step 8316, loss = 0.70083 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:45:38.621169 ops/training.py:65 2019-01-16 10:45:38.621120: step 8317, loss = 0.77169 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:45:39.582524 ops/training.py:65 2019-01-16 10:45:39.582472: step 8318, loss = 0.64875 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:45:40.543621 ops/training.py:65 2019-01-16 10:45:40.543556: step 8319, loss = 0.66510 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:45:41.504746 ops/training.py:65 2019-01-16 10:45:41.504675: step 8320, loss = 0.63932 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:45:42.465735 ops/training.py:65 2019-01-16 10:45:42.465668: step 8321, loss = 0.64909 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:45:43.426445 ops/training.py:65 2019-01-16 10:45:43.426382: step 8322, loss = 0.66503 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:45:44.387500 ops/training.py:65 2019-01-16 10:45:44.387449: step 8323, loss = 0.60796 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:45:45.348202 ops/training.py:65 2019-01-16 10:45:45.348150: step 8324, loss = 0.62204 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:45:46.308718 ops/training.py:65 2019-01-16 10:45:46.308667: step 8325, loss = 0.65376 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:45:47.269799 ops/training.py:65 2019-01-16 10:45:47.269749: step 8326, loss = 0.65218 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:45:48.232803 ops/training.py:65 2019-01-16 10:45:48.232736: step 8327, loss = 0.66201 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:45:49.195897 ops/training.py:65 2019-01-16 10:45:49.195823: step 8328, loss = 0.68102 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:45:50.156536 ops/training.py:65 2019-01-16 10:45:50.156470: step 8329, loss = 0.70374 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:45:51.118272 ops/training.py:65 2019-01-16 10:45:51.118228: step 8330, loss = 0.67532 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:45:52.081327 ops/training.py:65 2019-01-16 10:45:52.081274: step 8331, loss = 0.70383 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:45:53.044374 ops/training.py:65 2019-01-16 10:45:53.044327: step 8332, loss = 0.66143 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:45:54.006910 ops/training.py:65 2019-01-16 10:45:54.006856: step 8333, loss = 0.63020 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:45:54.971606 ops/training.py:65 2019-01-16 10:45:54.971543: step 8334, loss = 0.64174 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:45:55.935440 ops/training.py:65 2019-01-16 10:45:55.935375: step 8335, loss = 0.62685 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:45:56.897542 ops/training.py:65 2019-01-16 10:45:56.897476: step 8336, loss = 0.62379 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:45:57.862825 ops/training.py:65 2019-01-16 10:45:57.862758: step 8337, loss = 0.72150 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:45:58.826245 ops/training.py:65 2019-01-16 10:45:58.826179: step 8338, loss = 0.68228 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:45:59.788681 ops/training.py:65 2019-01-16 10:45:59.788613: step 8339, loss = 0.69299 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:46:00.750279 ops/training.py:65 2019-01-16 10:46:00.750210: step 8340, loss = 0.73405 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:46:01.710897 ops/training.py:65 2019-01-16 10:46:01.710841: step 8341, loss = 0.66577 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:46:02.673974 ops/training.py:65 2019-01-16 10:46:02.673920: step 8342, loss = 0.58397 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:46:03.635575 ops/training.py:65 2019-01-16 10:46:03.635519: step 8343, loss = 0.69188 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:46:04.598074 ops/training.py:65 2019-01-16 10:46:04.598001: step 8344, loss = 0.62862 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:46:05.561043 ops/training.py:65 2019-01-16 10:46:05.560983: step 8345, loss = 0.66302 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:46:06.522356 ops/training.py:65 2019-01-16 10:46:06.522286: step 8346, loss = 0.69846 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:46:07.485472 ops/training.py:65 2019-01-16 10:46:07.485408: step 8347, loss = 0.60222 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:46:08.446195 ops/training.py:65 2019-01-16 10:46:08.446133: step 8348, loss = 0.73208 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:46:09.406133 ops/training.py:65 2019-01-16 10:46:09.406070: step 8349, loss = 0.66458 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:46:10.367752 ops/training.py:65 2019-01-16 10:46:10.367686: step 8350, loss = 0.72105 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:46:11.329999 ops/training.py:65 2019-01-16 10:46:11.329936: step 8351, loss = 0.63958 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:46:12.292351 ops/training.py:65 2019-01-16 10:46:12.292278: step 8352, loss = 0.63642 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:46:13.255765 ops/training.py:65 2019-01-16 10:46:13.255691: step 8353, loss = 0.69342 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:46:14.217592 ops/training.py:65 2019-01-16 10:46:14.217525: step 8354, loss = 0.74395 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:46:15.179693 ops/training.py:65 2019-01-16 10:46:15.179624: step 8355, loss = 0.68532 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:46:16.140149 ops/training.py:65 2019-01-16 10:46:16.140086: step 8356, loss = 0.64972 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:46:17.100902 ops/training.py:65 2019-01-16 10:46:17.100843: step 8357, loss = 0.69666 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:46:18.064282 ops/training.py:65 2019-01-16 10:46:18.064229: step 8358, loss = 0.67735 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:46:19.028614 ops/training.py:65 2019-01-16 10:46:19.028545: step 8359, loss = 0.67533 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:46:19.993184 ops/training.py:65 2019-01-16 10:46:19.993116: step 8360, loss = 0.69733 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:46:20.954306 ops/training.py:65 2019-01-16 10:46:20.954251: step 8361, loss = 0.65895 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:46:21.915851 ops/training.py:65 2019-01-16 10:46:21.915796: step 8362, loss = 0.56039 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:46:22.879568 ops/training.py:65 2019-01-16 10:46:22.879511: step 8363, loss = 0.64994 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:46:23.842796 ops/training.py:65 2019-01-16 10:46:23.842740: step 8364, loss = 0.62920 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:46:24.805043 ops/training.py:65 2019-01-16 10:46:24.804950: step 8365, loss = 0.67744 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:46:25.769250 ops/training.py:65 2019-01-16 10:46:25.769198: step 8366, loss = 0.65175 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:46:26.733508 ops/training.py:65 2019-01-16 10:46:26.733458: step 8367, loss = 0.71331 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:46:27.696358 ops/training.py:65 2019-01-16 10:46:27.696307: step 8368, loss = 0.62493 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:46:28.657908 ops/training.py:65 2019-01-16 10:46:28.657860: step 8369, loss = 0.70271 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:46:29.618276 ops/training.py:65 2019-01-16 10:46:29.618214: step 8370, loss = 0.69596 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:46:30.578102 ops/training.py:65 2019-01-16 10:46:30.578038: step 8371, loss = 0.63471 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:46:31.541235 ops/training.py:65 2019-01-16 10:46:31.541184: step 8372, loss = 0.66019 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:46:32.506403 ops/training.py:65 2019-01-16 10:46:32.506336: step 8373, loss = 0.67765 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:46:33.468990 ops/training.py:65 2019-01-16 10:46:33.468929: step 8374, loss = 0.64263 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:46:34.430414 ops/training.py:65 2019-01-16 10:46:34.430356: step 8375, loss = 0.61556 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:46:35.391723 ops/training.py:65 2019-01-16 10:46:35.391668: step 8376, loss = 0.74388 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:46:36.351997 ops/training.py:65 2019-01-16 10:46:36.351935: step 8377, loss = 0.67090 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:46:37.313258 ops/training.py:65 2019-01-16 10:46:37.313190: step 8378, loss = 0.73511 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:46:38.273904 ops/training.py:65 2019-01-16 10:46:38.273853: step 8379, loss = 0.68597 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:46:39.235069 ops/training.py:65 2019-01-16 10:46:39.235023: step 8380, loss = 0.72796 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:46:40.194944 ops/training.py:65 2019-01-16 10:46:40.194903: step 8381, loss = 0.63975 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:46:41.155432 ops/training.py:65 2019-01-16 10:46:41.155385: step 8382, loss = 0.67562 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:46:42.115613 ops/training.py:65 2019-01-16 10:46:42.115566: step 8383, loss = 0.72945 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:46:43.076171 ops/training.py:65 2019-01-16 10:46:43.076112: step 8384, loss = 0.67474 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:46:44.036477 ops/training.py:65 2019-01-16 10:46:44.036435: step 8385, loss = 0.64345 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:46:44.996908 ops/training.py:65 2019-01-16 10:46:44.996850: step 8386, loss = 0.64323 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:46:45.958507 ops/training.py:65 2019-01-16 10:46:45.958449: step 8387, loss = 0.70310 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:46:46.923180 ops/training.py:65 2019-01-16 10:46:46.923134: step 8388, loss = 0.71331 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:46:47.886794 ops/training.py:65 2019-01-16 10:46:47.886746: step 8389, loss = 0.70742 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:46:48.850616 ops/training.py:65 2019-01-16 10:46:48.850553: step 8390, loss = 0.71514 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:46:49.813399 ops/training.py:65 2019-01-16 10:46:49.813331: step 8391, loss = 0.69002 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:46:50.774642 ops/training.py:65 2019-01-16 10:46:50.774595: step 8392, loss = 0.69687 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:46:51.736107 ops/training.py:65 2019-01-16 10:46:51.736059: step 8393, loss = 0.59579 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:46:52.697208 ops/training.py:65 2019-01-16 10:46:52.697151: step 8394, loss = 0.65117 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:46:53.657438 ops/training.py:65 2019-01-16 10:46:53.657397: step 8395, loss = 0.66350 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:46:54.617987 ops/training.py:65 2019-01-16 10:46:54.617929: step 8396, loss = 0.60915 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:46:55.579947 ops/training.py:65 2019-01-16 10:46:55.579908: step 8397, loss = 0.67746 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:46:56.542242 ops/training.py:65 2019-01-16 10:46:56.542188: step 8398, loss = 0.72265 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:46:57.503423 ops/training.py:65 2019-01-16 10:46:57.503366: step 8399, loss = 0.66177 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:46:58.464014 ops/training.py:65 2019-01-16 10:46:58.463959: step 8400, loss = 0.67943 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:46:59.425470 ops/training.py:65 2019-01-16 10:46:59.425409: step 8401, loss = 0.67415 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:47:00.385951 ops/training.py:65 2019-01-16 10:47:00.385894: step 8402, loss = 0.69255 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:47:01.347073 ops/training.py:65 2019-01-16 10:47:01.347022: step 8403, loss = 0.71010 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:47:02.307983 ops/training.py:65 2019-01-16 10:47:02.307912: step 8404, loss = 0.64862 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:47:03.269022 ops/training.py:65 2019-01-16 10:47:03.268950: step 8405, loss = 0.76270 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:47:04.228710 ops/training.py:65 2019-01-16 10:47:04.228644: step 8406, loss = 0.72530 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:47:05.190033 ops/training.py:65 2019-01-16 10:47:05.189948: step 8407, loss = 0.70015 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:47:06.153669 ops/training.py:65 2019-01-16 10:47:06.153623: step 8408, loss = 0.72110 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:47:07.117882 ops/training.py:65 2019-01-16 10:47:07.117833: step 8409, loss = 0.72248 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:47:08.083012 ops/training.py:65 2019-01-16 10:47:08.082942: step 8410, loss = 0.65875 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:47:09.045797 ops/training.py:65 2019-01-16 10:47:09.045726: step 8411, loss = 0.63304 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:47:10.006828 ops/training.py:65 2019-01-16 10:47:10.006779: step 8412, loss = 0.71755 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:47:10.967924 ops/training.py:65 2019-01-16 10:47:10.967861: step 8413, loss = 0.67772 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:47:11.930252 ops/training.py:65 2019-01-16 10:47:11.930184: step 8414, loss = 0.70064 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:47:12.890820 ops/training.py:65 2019-01-16 10:47:12.890764: step 8415, loss = 0.63851 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:47:13.854414 ops/training.py:65 2019-01-16 10:47:13.854364: step 8416, loss = 0.64823 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:47:14.816626 ops/training.py:65 2019-01-16 10:47:14.816554: step 8417, loss = 0.71212 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:47:15.778624 ops/training.py:65 2019-01-16 10:47:15.778576: step 8418, loss = 0.66945 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:47:16.738652 ops/training.py:65 2019-01-16 10:47:16.738602: step 8419, loss = 0.65134 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:47:17.699720 ops/training.py:65 2019-01-16 10:47:17.699666: step 8420, loss = 0.70131 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:47:18.660248 ops/training.py:65 2019-01-16 10:47:18.660184: step 8421, loss = 0.59877 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 10:47:19.620787 ops/training.py:65 2019-01-16 10:47:19.620725: step 8422, loss = 0.65377 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:47:20.582418 ops/training.py:65 2019-01-16 10:47:20.582375: step 8423, loss = 0.64475 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:47:21.543276 ops/training.py:65 2019-01-16 10:47:21.543231: step 8424, loss = 0.71664 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:47:22.503220 ops/training.py:65 2019-01-16 10:47:22.503160: step 8425, loss = 0.60358 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:47:23.463372 ops/training.py:65 2019-01-16 10:47:23.463298: step 8426, loss = 0.63642 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:47:24.427290 ops/training.py:65 2019-01-16 10:47:24.427224: step 8427, loss = 0.63648 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:47:25.390606 ops/training.py:65 2019-01-16 10:47:25.390549: step 8428, loss = 0.73304 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:47:26.355081 ops/training.py:65 2019-01-16 10:47:26.355027: step 8429, loss = 0.61989 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:47:27.316905 ops/training.py:65 2019-01-16 10:47:27.316848: step 8430, loss = 0.69796 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:47:28.277213 ops/training.py:65 2019-01-16 10:47:28.277158: step 8431, loss = 0.63419 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:47:29.238495 ops/training.py:65 2019-01-16 10:47:29.238429: step 8432, loss = 0.72073 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:47:30.198139 ops/training.py:65 2019-01-16 10:47:30.198075: step 8433, loss = 0.65889 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:47:31.163197 ops/training.py:65 2019-01-16 10:47:31.163143: step 8434, loss = 0.64842 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:47:32.124982 ops/training.py:65 2019-01-16 10:47:32.124910: step 8435, loss = 0.60469 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:47:33.088226 ops/training.py:65 2019-01-16 10:47:33.088175: step 8436, loss = 0.68714 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:47:34.050705 ops/training.py:65 2019-01-16 10:47:34.050649: step 8437, loss = 0.61457 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:47:35.013658 ops/training.py:65 2019-01-16 10:47:35.013611: step 8438, loss = 0.66839 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:47:35.975242 ops/training.py:65 2019-01-16 10:47:35.975195: step 8439, loss = 0.68676 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:47:36.935936 ops/training.py:65 2019-01-16 10:47:36.935883: step 8440, loss = 0.63699 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:47:37.899737 ops/training.py:65 2019-01-16 10:47:37.899678: step 8441, loss = 0.68161 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:47:38.863775 ops/training.py:65 2019-01-16 10:47:38.863730: step 8442, loss = 0.62348 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:47:39.825991 ops/training.py:65 2019-01-16 10:47:39.825920: step 8443, loss = 0.72373 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:47:40.788677 ops/training.py:65 2019-01-16 10:47:40.788618: step 8444, loss = 0.71454 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:47:41.749874 ops/training.py:65 2019-01-16 10:47:41.749824: step 8445, loss = 0.70235 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:47:42.710845 ops/training.py:65 2019-01-16 10:47:42.710781: step 8446, loss = 0.65278 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:47:43.676590 ops/training.py:65 2019-01-16 10:47:43.676531: step 8447, loss = 0.63210 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:47:44.639528 ops/training.py:65 2019-01-16 10:47:44.639463: step 8448, loss = 0.70210 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:47:45.601547 ops/training.py:65 2019-01-16 10:47:45.601492: step 8449, loss = 0.73205 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:47:46.562823 ops/training.py:65 2019-01-16 10:47:46.562753: step 8450, loss = 0.71616 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:47:47.523590 ops/training.py:65 2019-01-16 10:47:47.523532: step 8451, loss = 0.73432 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:47:48.484372 ops/training.py:65 2019-01-16 10:47:48.484317: step 8452, loss = 0.73732 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:47:49.444256 ops/training.py:65 2019-01-16 10:47:49.444204: step 8453, loss = 0.55369 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:47:50.404259 ops/training.py:65 2019-01-16 10:47:50.404200: step 8454, loss = 0.63816 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:47:51.367379 ops/training.py:65 2019-01-16 10:47:51.367328: step 8455, loss = 0.72729 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:47:52.330153 ops/training.py:65 2019-01-16 10:47:52.330092: step 8456, loss = 0.72322 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:47:53.291369 ops/training.py:65 2019-01-16 10:47:53.291300: step 8457, loss = 0.66756 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:47:54.254749 ops/training.py:65 2019-01-16 10:47:54.254702: step 8458, loss = 0.73277 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:47:55.215373 ops/training.py:65 2019-01-16 10:47:55.215309: step 8459, loss = 0.68480 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:47:56.176422 ops/training.py:65 2019-01-16 10:47:56.176361: step 8460, loss = 0.71497 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:47:57.137024 ops/training.py:65 2019-01-16 10:47:57.136959: step 8461, loss = 0.76450 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:47:58.097380 ops/training.py:65 2019-01-16 10:47:58.097333: step 8462, loss = 0.64657 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:47:59.058229 ops/training.py:65 2019-01-16 10:47:59.058176: step 8463, loss = 0.70827 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:48:00.019498 ops/training.py:65 2019-01-16 10:48:00.019446: step 8464, loss = 0.63976 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:48:00.981581 ops/training.py:65 2019-01-16 10:48:00.981513: step 8465, loss = 0.59294 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:48:01.942320 ops/training.py:65 2019-01-16 10:48:01.942253: step 8466, loss = 0.62318 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:48:02.906801 ops/training.py:65 2019-01-16 10:48:02.906731: step 8467, loss = 0.69281 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:48:03.870836 ops/training.py:65 2019-01-16 10:48:03.870779: step 8468, loss = 0.71751 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:48:04.833585 ops/training.py:65 2019-01-16 10:48:04.833523: step 8469, loss = 0.54589 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 10:48:05.794575 ops/training.py:65 2019-01-16 10:48:05.794521: step 8470, loss = 0.62814 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:48:06.755755 ops/training.py:65 2019-01-16 10:48:06.755702: step 8471, loss = 0.71708 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:48:07.718430 ops/training.py:65 2019-01-16 10:48:07.718377: step 8472, loss = 0.67344 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:48:08.678961 ops/training.py:65 2019-01-16 10:48:08.678913: step 8473, loss = 0.59844 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:48:09.640059 ops/training.py:65 2019-01-16 10:48:09.640002: step 8474, loss = 0.71690 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:48:10.601095 ops/training.py:65 2019-01-16 10:48:10.601041: step 8475, loss = 0.65547 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:48:11.562739 ops/training.py:65 2019-01-16 10:48:11.562687: step 8476, loss = 0.63881 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:48:12.524143 ops/training.py:65 2019-01-16 10:48:12.524091: step 8477, loss = 0.60473 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:48:13.485176 ops/training.py:65 2019-01-16 10:48:13.485128: step 8478, loss = 0.59230 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:48:14.446873 ops/training.py:65 2019-01-16 10:48:14.446824: step 8479, loss = 0.61480 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:48:15.408637 ops/training.py:65 2019-01-16 10:48:15.408585: step 8480, loss = 0.77312 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:48:16.369581 ops/training.py:65 2019-01-16 10:48:16.369531: step 8481, loss = 0.67086 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:48:17.331204 ops/training.py:65 2019-01-16 10:48:17.331156: step 8482, loss = 0.65816 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:48:18.292205 ops/training.py:65 2019-01-16 10:48:18.292156: step 8483, loss = 0.69405 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:48:19.252766 ops/training.py:65 2019-01-16 10:48:19.252711: step 8484, loss = 0.76620 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:48:20.213829 ops/training.py:65 2019-01-16 10:48:20.213778: step 8485, loss = 0.75113 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:48:21.174530 ops/training.py:65 2019-01-16 10:48:21.174476: step 8486, loss = 0.65691 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:48:22.138617 ops/training.py:65 2019-01-16 10:48:22.138566: step 8487, loss = 0.63296 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:48:23.102696 ops/training.py:65 2019-01-16 10:48:23.102646: step 8488, loss = 0.67295 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:48:24.065694 ops/training.py:65 2019-01-16 10:48:24.065638: step 8489, loss = 0.77173 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:48:25.026272 ops/training.py:65 2019-01-16 10:48:25.026217: step 8490, loss = 0.66472 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:48:25.987100 ops/training.py:65 2019-01-16 10:48:25.987051: step 8491, loss = 0.64067 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:48:26.947927 ops/training.py:65 2019-01-16 10:48:26.947878: step 8492, loss = 0.71387 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:48:27.909788 ops/training.py:65 2019-01-16 10:48:27.909732: step 8493, loss = 0.59670 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:48:28.870591 ops/training.py:65 2019-01-16 10:48:28.870541: step 8494, loss = 0.71284 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:48:29.831531 ops/training.py:65 2019-01-16 10:48:29.831480: step 8495, loss = 0.67979 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:48:30.792725 ops/training.py:65 2019-01-16 10:48:30.792677: step 8496, loss = 0.68838 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:48:31.753930 ops/training.py:65 2019-01-16 10:48:31.753875: step 8497, loss = 0.64816 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:48:32.714786 ops/training.py:65 2019-01-16 10:48:32.714735: step 8498, loss = 0.66749 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:48:33.675158 ops/training.py:65 2019-01-16 10:48:33.675104: step 8499, loss = 0.57442 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 10:48:34.636283 ops/training.py:65 2019-01-16 10:48:34.636232: step 8500, loss = 0.63182 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:48:35.597359 ops/training.py:65 2019-01-16 10:48:35.597308: step 8501, loss = 0.63795 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:48:36.557310 ops/training.py:65 2019-01-16 10:48:36.557258: step 8502, loss = 0.71806 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:48:37.518609 ops/training.py:65 2019-01-16 10:48:37.518559: step 8503, loss = 0.69592 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:48:38.479108 ops/training.py:65 2019-01-16 10:48:38.479058: step 8504, loss = 0.66042 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:48:39.441056 ops/training.py:65 2019-01-16 10:48:39.441009: step 8505, loss = 0.65490 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:48:40.402823 ops/training.py:65 2019-01-16 10:48:40.402765: step 8506, loss = 0.74671 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:48:41.365057 ops/training.py:65 2019-01-16 10:48:41.364993: step 8507, loss = 0.66943 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:48:42.326113 ops/training.py:65 2019-01-16 10:48:42.326061: step 8508, loss = 0.58471 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:48:43.287184 ops/training.py:65 2019-01-16 10:48:43.287134: step 8509, loss = 0.64535 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:48:44.247416 ops/training.py:65 2019-01-16 10:48:44.247365: step 8510, loss = 0.64525 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:48:45.209700 ops/training.py:65 2019-01-16 10:48:45.209648: step 8511, loss = 0.73124 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:48:46.171428 ops/training.py:65 2019-01-16 10:48:46.171377: step 8512, loss = 0.62988 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:48:47.132628 ops/training.py:65 2019-01-16 10:48:47.132568: step 8513, loss = 0.61455 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:48:48.093497 ops/training.py:65 2019-01-16 10:48:48.093446: step 8514, loss = 0.64079 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:48:49.054869 ops/training.py:65 2019-01-16 10:48:49.054812: step 8515, loss = 0.67691 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:48:50.015833 ops/training.py:65 2019-01-16 10:48:50.015760: step 8516, loss = 0.74490 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:48:50.976497 ops/training.py:65 2019-01-16 10:48:50.976422: step 8517, loss = 0.62258 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:48:51.941291 ops/training.py:65 2019-01-16 10:48:51.941225: step 8518, loss = 0.63138 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:48:52.904039 ops/training.py:65 2019-01-16 10:48:52.903965: step 8519, loss = 0.71512 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:48:53.868445 ops/training.py:65 2019-01-16 10:48:53.868375: step 8520, loss = 0.64938 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:48:54.829653 ops/training.py:65 2019-01-16 10:48:54.829605: step 8521, loss = 0.67267 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:48:55.791342 ops/training.py:65 2019-01-16 10:48:55.791290: step 8522, loss = 0.72461 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:48:56.752110 ops/training.py:65 2019-01-16 10:48:56.752063: step 8523, loss = 0.63927 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:48:57.713360 ops/training.py:65 2019-01-16 10:48:57.713313: step 8524, loss = 0.70915 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:48:58.677427 ops/training.py:65 2019-01-16 10:48:58.677377: step 8525, loss = 0.74030 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:48:59.638828 ops/training.py:65 2019-01-16 10:48:59.638768: step 8526, loss = 0.75065 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:49:00.598657 ops/training.py:65 2019-01-16 10:49:00.598601: step 8527, loss = 0.70292 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:49:01.563824 ops/training.py:65 2019-01-16 10:49:01.563775: step 8528, loss = 0.65370 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:49:02.525575 ops/training.py:65 2019-01-16 10:49:02.525515: step 8529, loss = 0.60381 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:49:03.487768 ops/training.py:65 2019-01-16 10:49:03.487704: step 8530, loss = 0.60815 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:49:04.451520 ops/training.py:65 2019-01-16 10:49:04.451459: step 8531, loss = 0.59811 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:49:05.414879 ops/training.py:65 2019-01-16 10:49:05.414809: step 8532, loss = 0.65663 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:49:06.378299 ops/training.py:65 2019-01-16 10:49:06.378248: step 8533, loss = 0.60440 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:49:07.339119 ops/training.py:65 2019-01-16 10:49:07.339069: step 8534, loss = 0.54675 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:49:08.299819 ops/training.py:65 2019-01-16 10:49:08.299767: step 8535, loss = 0.68246 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:49:09.262441 ops/training.py:65 2019-01-16 10:49:09.262388: step 8536, loss = 0.69921 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:49:10.225850 ops/training.py:65 2019-01-16 10:49:10.225796: step 8537, loss = 0.66383 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:49:11.189416 ops/training.py:65 2019-01-16 10:49:11.189369: step 8538, loss = 0.71598 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:49:12.154515 ops/training.py:65 2019-01-16 10:49:12.154466: step 8539, loss = 0.69294 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:49:13.115971 ops/training.py:65 2019-01-16 10:49:13.115913: step 8540, loss = 0.63437 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:49:14.077955 ops/training.py:65 2019-01-16 10:49:14.077886: step 8541, loss = 0.75400 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:49:15.041760 ops/training.py:65 2019-01-16 10:49:15.041694: step 8542, loss = 0.74462 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:49:16.005401 ops/training.py:65 2019-01-16 10:49:16.005333: step 8543, loss = 0.53370 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 10:49:16.968043 ops/training.py:65 2019-01-16 10:49:16.967995: step 8544, loss = 0.72752 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:49:17.928711 ops/training.py:65 2019-01-16 10:49:17.928661: step 8545, loss = 0.72971 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:49:18.889265 ops/training.py:65 2019-01-16 10:49:18.889211: step 8546, loss = 0.60481 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:49:19.849979 ops/training.py:65 2019-01-16 10:49:19.849913: step 8547, loss = 0.63855 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:49:20.810811 ops/training.py:65 2019-01-16 10:49:20.810757: step 8548, loss = 0.74873 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:49:21.771988 ops/training.py:65 2019-01-16 10:49:21.771936: step 8549, loss = 0.73181 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:49:22.733616 ops/training.py:65 2019-01-16 10:49:22.733560: step 8550, loss = 0.73156 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:49:23.694372 ops/training.py:65 2019-01-16 10:49:23.694320: step 8551, loss = 0.69143 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:49:24.655591 ops/training.py:65 2019-01-16 10:49:24.655538: step 8552, loss = 0.64074 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:49:25.616876 ops/training.py:65 2019-01-16 10:49:25.616814: step 8553, loss = 0.70863 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:49:26.580527 ops/training.py:65 2019-01-16 10:49:26.580481: step 8554, loss = 0.66203 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:49:27.541800 ops/training.py:65 2019-01-16 10:49:27.541750: step 8555, loss = 0.64537 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:49:28.506300 ops/training.py:65 2019-01-16 10:49:28.506236: step 8556, loss = 0.62131 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:49:29.469614 ops/training.py:65 2019-01-16 10:49:29.469568: step 8557, loss = 0.62016 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:49:30.432235 ops/training.py:65 2019-01-16 10:49:30.432185: step 8558, loss = 0.65537 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:49:31.393282 ops/training.py:65 2019-01-16 10:49:31.393229: step 8559, loss = 0.58784 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:49:32.357716 ops/training.py:65 2019-01-16 10:49:32.357661: step 8560, loss = 0.71891 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:49:33.322475 ops/training.py:65 2019-01-16 10:49:33.322427: step 8561, loss = 0.66859 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:49:34.284345 ops/training.py:65 2019-01-16 10:49:34.284290: step 8562, loss = 0.73690 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:49:35.246348 ops/training.py:65 2019-01-16 10:49:35.246295: step 8563, loss = 0.59979 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:49:36.207584 ops/training.py:65 2019-01-16 10:49:36.207536: step 8564, loss = 0.62684 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:49:37.168706 ops/training.py:65 2019-01-16 10:49:37.168654: step 8565, loss = 0.62437 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:49:38.130177 ops/training.py:65 2019-01-16 10:49:38.130128: step 8566, loss = 0.66772 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:49:39.092090 ops/training.py:65 2019-01-16 10:49:39.092038: step 8567, loss = 0.64578 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:49:40.053009 ops/training.py:65 2019-01-16 10:49:40.052956: step 8568, loss = 0.71498 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:49:41.014095 ops/training.py:65 2019-01-16 10:49:41.014040: step 8569, loss = 0.61774 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:49:41.974483 ops/training.py:65 2019-01-16 10:49:41.974429: step 8570, loss = 0.64684 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:49:42.935086 ops/training.py:65 2019-01-16 10:49:42.935033: step 8571, loss = 0.61401 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:49:43.897075 ops/training.py:65 2019-01-16 10:49:43.897005: step 8572, loss = 0.70090 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:49:44.861461 ops/training.py:65 2019-01-16 10:49:44.861403: step 8573, loss = 0.74074 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:49:45.824577 ops/training.py:65 2019-01-16 10:49:45.824530: step 8574, loss = 0.63080 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:49:46.786575 ops/training.py:65 2019-01-16 10:49:46.786522: step 8575, loss = 0.71739 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:49:47.749086 ops/training.py:65 2019-01-16 10:49:47.749035: step 8576, loss = 0.62660 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:49:48.711668 ops/training.py:65 2019-01-16 10:49:48.711618: step 8577, loss = 0.62545 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:49:49.677210 ops/training.py:65 2019-01-16 10:49:49.677155: step 8578, loss = 0.62136 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:49:50.641497 ops/training.py:65 2019-01-16 10:49:50.641444: step 8579, loss = 0.68751 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:49:51.603463 ops/training.py:65 2019-01-16 10:49:51.603412: step 8580, loss = 0.61511 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:49:52.565275 ops/training.py:65 2019-01-16 10:49:52.565226: step 8581, loss = 0.61153 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:49:53.527161 ops/training.py:65 2019-01-16 10:49:53.527106: step 8582, loss = 0.63633 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:49:54.486863 ops/training.py:65 2019-01-16 10:49:54.486805: step 8583, loss = 0.63577 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:49:55.450769 ops/training.py:65 2019-01-16 10:49:55.450696: step 8584, loss = 0.64491 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:49:56.412963 ops/training.py:65 2019-01-16 10:49:56.412891: step 8585, loss = 0.63380 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:49:57.374096 ops/training.py:65 2019-01-16 10:49:57.374036: step 8586, loss = 0.62996 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:49:58.335658 ops/training.py:65 2019-01-16 10:49:58.335595: step 8587, loss = 0.72564 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:49:59.296959 ops/training.py:65 2019-01-16 10:49:59.296894: step 8588, loss = 0.71570 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:50:00.257935 ops/training.py:65 2019-01-16 10:50:00.257878: step 8589, loss = 0.66190 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:50:01.219028 ops/training.py:65 2019-01-16 10:50:01.218980: step 8590, loss = 0.67221 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:50:02.179374 ops/training.py:65 2019-01-16 10:50:02.179322: step 8591, loss = 0.64700 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:50:03.139770 ops/training.py:65 2019-01-16 10:50:03.139717: step 8592, loss = 0.59613 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:50:04.100680 ops/training.py:65 2019-01-16 10:50:04.100625: step 8593, loss = 0.71102 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:50:05.061082 ops/training.py:65 2019-01-16 10:50:05.061011: step 8594, loss = 0.70058 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:50:06.022141 ops/training.py:65 2019-01-16 10:50:06.022074: step 8595, loss = 0.75108 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:50:06.982606 ops/training.py:65 2019-01-16 10:50:06.982552: step 8596, loss = 0.61392 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:50:07.943167 ops/training.py:65 2019-01-16 10:50:07.943118: step 8597, loss = 0.70308 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:50:08.903821 ops/training.py:65 2019-01-16 10:50:08.903749: step 8598, loss = 0.64958 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:50:09.864602 ops/training.py:65 2019-01-16 10:50:09.864530: step 8599, loss = 0.70195 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:50:10.829160 ops/training.py:65 2019-01-16 10:50:10.829098: step 8600, loss = 0.68918 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:50:11.794136 ops/training.py:65 2019-01-16 10:50:11.794070: step 8601, loss = 0.72617 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:50:12.756966 ops/training.py:65 2019-01-16 10:50:12.756894: step 8602, loss = 0.71431 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:50:13.718711 ops/training.py:65 2019-01-16 10:50:13.718642: step 8603, loss = 0.81466 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:50:14.680704 ops/training.py:65 2019-01-16 10:50:14.680634: step 8604, loss = 0.67007 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:50:15.643031 ops/training.py:65 2019-01-16 10:50:15.642969: step 8605, loss = 0.69780 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:50:16.606790 ops/training.py:65 2019-01-16 10:50:16.606723: step 8606, loss = 0.60411 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:50:17.570353 ops/training.py:65 2019-01-16 10:50:17.570284: step 8607, loss = 0.59312 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 10:50:18.533158 ops/training.py:65 2019-01-16 10:50:18.533096: step 8608, loss = 0.67508 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:50:19.494633 ops/training.py:65 2019-01-16 10:50:19.494567: step 8609, loss = 0.64763 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:50:20.455035 ops/training.py:65 2019-01-16 10:50:20.454964: step 8610, loss = 0.77952 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:50:21.415448 ops/training.py:65 2019-01-16 10:50:21.415378: step 8611, loss = 0.63357 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:50:22.379949 ops/training.py:65 2019-01-16 10:50:22.379885: step 8612, loss = 0.77640 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:50:23.344239 ops/training.py:65 2019-01-16 10:50:23.344173: step 8613, loss = 0.70192 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:50:24.307379 ops/training.py:65 2019-01-16 10:50:24.307311: step 8614, loss = 0.65922 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:50:25.268834 ops/training.py:65 2019-01-16 10:50:25.268773: step 8615, loss = 0.68973 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:50:26.230234 ops/training.py:65 2019-01-16 10:50:26.230170: step 8616, loss = 0.64845 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:50:27.190832 ops/training.py:65 2019-01-16 10:50:27.190769: step 8617, loss = 0.67014 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:50:28.152774 ops/training.py:65 2019-01-16 10:50:28.152717: step 8618, loss = 0.60860 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:50:29.115537 ops/training.py:65 2019-01-16 10:50:29.115468: step 8619, loss = 0.68263 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:50:30.077157 ops/training.py:65 2019-01-16 10:50:30.077089: step 8620, loss = 0.67802 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:50:31.038803 ops/training.py:65 2019-01-16 10:50:31.038731: step 8621, loss = 0.63532 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:50:32.000905 ops/training.py:65 2019-01-16 10:50:32.000830: step 8622, loss = 0.68903 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:50:32.962069 ops/training.py:65 2019-01-16 10:50:32.962001: step 8623, loss = 0.67676 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:50:33.925113 ops/training.py:65 2019-01-16 10:50:33.925054: step 8624, loss = 0.69051 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:50:34.886482 ops/training.py:65 2019-01-16 10:50:34.886418: step 8625, loss = 0.71230 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:50:35.848023 ops/training.py:65 2019-01-16 10:50:35.847955: step 8626, loss = 0.85821 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:50:36.809165 ops/training.py:65 2019-01-16 10:50:36.809099: step 8627, loss = 0.77978 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:50:37.770563 ops/training.py:65 2019-01-16 10:50:37.770488: step 8628, loss = 0.71288 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:50:38.733348 ops/training.py:65 2019-01-16 10:50:38.733282: step 8629, loss = 0.67365 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:50:39.694540 ops/training.py:65 2019-01-16 10:50:39.694469: step 8630, loss = 0.67763 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:50:40.657562 ops/training.py:65 2019-01-16 10:50:40.657498: step 8631, loss = 0.70463 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:50:41.619808 ops/training.py:65 2019-01-16 10:50:41.619738: step 8632, loss = 0.70962 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:50:42.582592 ops/training.py:65 2019-01-16 10:50:42.582524: step 8633, loss = 0.72435 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:50:43.543206 ops/training.py:65 2019-01-16 10:50:43.543137: step 8634, loss = 0.64847 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:50:44.504059 ops/training.py:65 2019-01-16 10:50:44.503992: step 8635, loss = 0.70553 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:50:45.468408 ops/training.py:65 2019-01-16 10:50:45.468343: step 8636, loss = 0.64618 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:50:46.431647 ops/training.py:65 2019-01-16 10:50:46.431579: step 8637, loss = 0.69546 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:50:47.394875 ops/training.py:65 2019-01-16 10:50:47.394803: step 8638, loss = 0.71541 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:50:48.355320 ops/training.py:65 2019-01-16 10:50:48.355256: step 8639, loss = 0.65938 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:50:49.317211 ops/training.py:65 2019-01-16 10:50:49.317148: step 8640, loss = 0.58561 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:50:50.278885 ops/training.py:65 2019-01-16 10:50:50.278800: step 8641, loss = 0.65374 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:50:51.241419 ops/training.py:65 2019-01-16 10:50:51.241342: step 8642, loss = 0.64384 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:50:52.202720 ops/training.py:65 2019-01-16 10:50:52.202649: step 8643, loss = 0.71564 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:50:53.163325 ops/training.py:65 2019-01-16 10:50:53.163257: step 8644, loss = 0.58743 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:50:54.124430 ops/training.py:65 2019-01-16 10:50:54.124360: step 8645, loss = 0.63803 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:50:55.084834 ops/training.py:65 2019-01-16 10:50:55.084764: step 8646, loss = 0.70373 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:50:56.047701 ops/training.py:65 2019-01-16 10:50:56.047629: step 8647, loss = 0.73110 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:50:57.010588 ops/training.py:65 2019-01-16 10:50:57.010525: step 8648, loss = 0.68450 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:50:57.972705 ops/training.py:65 2019-01-16 10:50:57.972625: step 8649, loss = 0.68335 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:50:58.935412 ops/training.py:65 2019-01-16 10:50:58.935338: step 8650, loss = 0.60337 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:50:59.895794 ops/training.py:65 2019-01-16 10:50:59.895723: step 8651, loss = 0.75712 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:51:00.857321 ops/training.py:65 2019-01-16 10:51:00.857234: step 8652, loss = 0.68290 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:51:01.819815 ops/training.py:65 2019-01-16 10:51:01.819744: step 8653, loss = 0.71227 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:51:02.781533 ops/training.py:65 2019-01-16 10:51:02.781465: step 8654, loss = 0.69975 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:51:03.743525 ops/training.py:65 2019-01-16 10:51:03.743458: step 8655, loss = 0.71331 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:51:04.703628 ops/training.py:65 2019-01-16 10:51:04.703568: step 8656, loss = 0.61456 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:51:05.667703 ops/training.py:65 2019-01-16 10:51:05.667642: step 8657, loss = 0.67372 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:51:06.631042 ops/training.py:65 2019-01-16 10:51:06.630956: step 8658, loss = 0.64817 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:51:07.593711 ops/training.py:65 2019-01-16 10:51:07.593619: step 8659, loss = 0.60824 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:51:08.556488 ops/training.py:65 2019-01-16 10:51:08.556419: step 8660, loss = 0.73055 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:51:09.518789 ops/training.py:65 2019-01-16 10:51:09.518716: step 8661, loss = 0.73879 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:51:10.479896 ops/training.py:65 2019-01-16 10:51:10.479817: step 8662, loss = 0.61524 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:51:11.441816 ops/training.py:65 2019-01-16 10:51:11.441739: step 8663, loss = 0.62751 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:51:12.403024 ops/training.py:65 2019-01-16 10:51:12.402955: step 8664, loss = 0.68441 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:51:13.364576 ops/training.py:65 2019-01-16 10:51:13.364508: step 8665, loss = 0.71151 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:51:14.326281 ops/training.py:65 2019-01-16 10:51:14.326216: step 8666, loss = 0.65513 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:51:15.290209 ops/training.py:65 2019-01-16 10:51:15.290137: step 8667, loss = 0.62144 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:51:16.255723 ops/training.py:65 2019-01-16 10:51:16.255654: step 8668, loss = 0.65078 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:51:17.218932 ops/training.py:65 2019-01-16 10:51:17.218868: step 8669, loss = 0.65954 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:51:18.181750 ops/training.py:65 2019-01-16 10:51:18.181688: step 8670, loss = 0.56621 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:51:19.142954 ops/training.py:65 2019-01-16 10:51:19.142884: step 8671, loss = 0.77430 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:51:20.103924 ops/training.py:65 2019-01-16 10:51:20.103862: step 8672, loss = 0.62995 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:51:21.065177 ops/training.py:65 2019-01-16 10:51:21.065106: step 8673, loss = 0.66252 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:51:22.028405 ops/training.py:65 2019-01-16 10:51:22.028342: step 8674, loss = 0.59840 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:51:22.993082 ops/training.py:65 2019-01-16 10:51:22.993016: step 8675, loss = 0.64008 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:51:23.956549 ops/training.py:65 2019-01-16 10:51:23.956476: step 8676, loss = 0.68720 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:51:24.917803 ops/training.py:65 2019-01-16 10:51:24.917733: step 8677, loss = 0.66816 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:51:25.880741 ops/training.py:65 2019-01-16 10:51:25.880677: step 8678, loss = 0.67613 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:51:26.843868 ops/training.py:65 2019-01-16 10:51:26.843802: step 8679, loss = 0.61826 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:51:27.806600 ops/training.py:65 2019-01-16 10:51:27.806529: step 8680, loss = 0.68772 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:51:28.767545 ops/training.py:65 2019-01-16 10:51:28.767481: step 8681, loss = 0.80161 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:51:29.728066 ops/training.py:65 2019-01-16 10:51:29.727999: step 8682, loss = 0.68838 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:51:30.690087 ops/training.py:65 2019-01-16 10:51:30.690025: step 8683, loss = 0.70407 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:51:31.652419 ops/training.py:65 2019-01-16 10:51:31.652346: step 8684, loss = 0.60306 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:51:32.613855 ops/training.py:65 2019-01-16 10:51:32.613787: step 8685, loss = 0.61562 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:51:33.578232 ops/training.py:65 2019-01-16 10:51:33.578169: step 8686, loss = 0.55827 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 10:51:34.543519 ops/training.py:65 2019-01-16 10:51:34.543464: step 8687, loss = 0.66082 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:51:35.506697 ops/training.py:65 2019-01-16 10:51:35.506634: step 8688, loss = 0.65995 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:51:36.466867 ops/training.py:65 2019-01-16 10:51:36.466797: step 8689, loss = 0.71523 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:51:37.428273 ops/training.py:65 2019-01-16 10:51:37.428207: step 8690, loss = 0.61103 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 10:51:38.394177 ops/training.py:65 2019-01-16 10:51:38.394114: step 8691, loss = 0.55366 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:51:39.359316 ops/training.py:65 2019-01-16 10:51:39.359263: step 8692, loss = 0.65633 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:51:40.322785 ops/training.py:65 2019-01-16 10:51:40.322720: step 8693, loss = 0.70266 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:51:41.287358 ops/training.py:65 2019-01-16 10:51:41.287295: step 8694, loss = 0.60276 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 10:51:42.250994 ops/training.py:65 2019-01-16 10:51:42.250928: step 8695, loss = 0.69176 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:51:43.211748 ops/training.py:65 2019-01-16 10:51:43.211681: step 8696, loss = 0.64425 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:51:44.172277 ops/training.py:65 2019-01-16 10:51:44.172207: step 8697, loss = 0.57034 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:51:45.135860 ops/training.py:65 2019-01-16 10:51:45.135813: step 8698, loss = 0.67522 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:51:46.097546 ops/training.py:65 2019-01-16 10:51:46.097491: step 8699, loss = 0.70534 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:51:47.058808 ops/training.py:65 2019-01-16 10:51:47.058760: step 8700, loss = 0.63427 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:51:48.020680 ops/training.py:65 2019-01-16 10:51:48.020630: step 8701, loss = 0.59322 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:51:48.980991 ops/training.py:65 2019-01-16 10:51:48.980925: step 8702, loss = 0.74720 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:51:49.942218 ops/training.py:65 2019-01-16 10:51:49.942146: step 8703, loss = 0.62681 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:51:50.902198 ops/training.py:65 2019-01-16 10:51:50.902127: step 8704, loss = 0.70210 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:51:51.865983 ops/training.py:65 2019-01-16 10:51:51.865931: step 8705, loss = 0.65976 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:51:52.830458 ops/training.py:65 2019-01-16 10:51:52.830388: step 8706, loss = 0.64198 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:51:53.793980 ops/training.py:65 2019-01-16 10:51:53.793918: step 8707, loss = 0.75148 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:51:54.755398 ops/training.py:65 2019-01-16 10:51:54.755335: step 8708, loss = 0.64606 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:51:55.716804 ops/training.py:65 2019-01-16 10:51:55.716736: step 8709, loss = 0.69237 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:51:56.678258 ops/training.py:65 2019-01-16 10:51:56.678191: step 8710, loss = 0.64660 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:51:57.641156 ops/training.py:65 2019-01-16 10:51:57.641088: step 8711, loss = 0.65729 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:51:58.602863 ops/training.py:65 2019-01-16 10:51:58.602801: step 8712, loss = 0.66631 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:51:59.565158 ops/training.py:65 2019-01-16 10:51:59.565093: step 8713, loss = 0.70116 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:52:00.526036 ops/training.py:65 2019-01-16 10:52:00.525970: step 8714, loss = 0.68934 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:52:01.486870 ops/training.py:65 2019-01-16 10:52:01.486815: step 8715, loss = 0.77542 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:52:02.447799 ops/training.py:65 2019-01-16 10:52:02.447735: step 8716, loss = 0.76674 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:52:03.408662 ops/training.py:65 2019-01-16 10:52:03.408599: step 8717, loss = 0.70203 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:52:04.368842 ops/training.py:65 2019-01-16 10:52:04.368781: step 8718, loss = 0.62534 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:52:05.329027 ops/training.py:65 2019-01-16 10:52:05.328959: step 8719, loss = 0.74146 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:52:06.293488 ops/training.py:65 2019-01-16 10:52:06.293422: step 8720, loss = 0.68122 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:52:07.257105 ops/training.py:65 2019-01-16 10:52:07.257034: step 8721, loss = 0.78380 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:52:08.222061 ops/training.py:65 2019-01-16 10:52:08.221993: step 8722, loss = 0.69986 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:52:09.185990 ops/training.py:65 2019-01-16 10:52:09.185924: step 8723, loss = 0.70557 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:52:10.150076 ops/training.py:65 2019-01-16 10:52:10.150006: step 8724, loss = 0.60677 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:52:11.115656 ops/training.py:65 2019-01-16 10:52:11.115586: step 8725, loss = 0.67334 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:52:12.078719 ops/training.py:65 2019-01-16 10:52:12.078647: step 8726, loss = 0.69919 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:52:13.039688 ops/training.py:65 2019-01-16 10:52:13.039620: step 8727, loss = 0.83053 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:52:14.001866 ops/training.py:65 2019-01-16 10:52:14.001807: step 8728, loss = 0.69301 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:52:14.962472 ops/training.py:65 2019-01-16 10:52:14.962418: step 8729, loss = 0.65451 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:52:15.923650 ops/training.py:65 2019-01-16 10:52:15.923600: step 8730, loss = 0.72808 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:52:16.887198 ops/training.py:65 2019-01-16 10:52:16.887130: step 8731, loss = 0.68204 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:52:17.849816 ops/training.py:65 2019-01-16 10:52:17.849740: step 8732, loss = 0.62476 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:52:18.810314 ops/training.py:65 2019-01-16 10:52:18.810249: step 8733, loss = 0.80102 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 10:52:19.771218 ops/training.py:65 2019-01-16 10:52:19.771152: step 8734, loss = 0.73080 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:52:20.733851 ops/training.py:65 2019-01-16 10:52:20.733785: step 8735, loss = 0.71823 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:52:21.696729 ops/training.py:65 2019-01-16 10:52:21.696643: step 8736, loss = 0.65777 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:52:22.660739 ops/training.py:65 2019-01-16 10:52:22.660666: step 8737, loss = 0.67367 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:52:23.625926 ops/training.py:65 2019-01-16 10:52:23.625854: step 8738, loss = 0.64916 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:52:24.587681 ops/training.py:65 2019-01-16 10:52:24.587615: step 8739, loss = 0.67859 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:52:25.550285 ops/training.py:65 2019-01-16 10:52:25.550238: step 8740, loss = 0.61508 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:52:26.511511 ops/training.py:65 2019-01-16 10:52:26.511457: step 8741, loss = 0.63993 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:52:27.474732 ops/training.py:65 2019-01-16 10:52:27.474666: step 8742, loss = 0.68470 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:52:28.436438 ops/training.py:65 2019-01-16 10:52:28.436379: step 8743, loss = 0.68727 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:52:29.398133 ops/training.py:65 2019-01-16 10:52:29.398070: step 8744, loss = 0.67178 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:52:30.359005 ops/training.py:65 2019-01-16 10:52:30.358939: step 8745, loss = 0.65942 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:52:31.319831 ops/training.py:65 2019-01-16 10:52:31.319757: step 8746, loss = 0.61337 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:52:32.281572 ops/training.py:65 2019-01-16 10:52:32.281504: step 8747, loss = 0.63332 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:52:33.245923 ops/training.py:65 2019-01-16 10:52:33.245858: step 8748, loss = 0.61676 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:52:34.208023 ops/training.py:65 2019-01-16 10:52:34.207967: step 8749, loss = 0.63135 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:52:35.170274 ops/training.py:65 2019-01-16 10:52:35.170204: step 8750, loss = 0.65872 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:52:36.133031 ops/training.py:65 2019-01-16 10:52:36.132944: step 8751, loss = 0.61156 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:52:37.095927 ops/training.py:65 2019-01-16 10:52:37.095841: step 8752, loss = 0.70130 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:52:38.059193 ops/training.py:65 2019-01-16 10:52:38.059131: step 8753, loss = 0.63062 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:52:39.019478 ops/training.py:65 2019-01-16 10:52:39.019416: step 8754, loss = 0.72111 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:52:39.985374 ops/training.py:65 2019-01-16 10:52:39.985311: step 8755, loss = 0.65299 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:52:40.945810 ops/training.py:65 2019-01-16 10:52:40.945740: step 8756, loss = 0.69715 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:52:41.906602 ops/training.py:65 2019-01-16 10:52:41.906537: step 8757, loss = 0.66981 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:52:42.866964 ops/training.py:65 2019-01-16 10:52:42.866899: step 8758, loss = 0.70836 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:52:43.828294 ops/training.py:65 2019-01-16 10:52:43.828226: step 8759, loss = 0.66640 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:52:44.788942 ops/training.py:65 2019-01-16 10:52:44.788873: step 8760, loss = 0.69621 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:52:45.751695 ops/training.py:65 2019-01-16 10:52:45.751628: step 8761, loss = 0.69353 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:52:46.713318 ops/training.py:65 2019-01-16 10:52:46.713252: step 8762, loss = 0.64437 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:52:47.676692 ops/training.py:65 2019-01-16 10:52:47.676623: step 8763, loss = 0.63467 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:52:48.638589 ops/training.py:65 2019-01-16 10:52:48.638527: step 8764, loss = 0.63353 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:52:49.603901 ops/training.py:65 2019-01-16 10:52:49.603836: step 8765, loss = 0.65918 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:52:50.565632 ops/training.py:65 2019-01-16 10:52:50.565564: step 8766, loss = 0.68827 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:52:51.527529 ops/training.py:65 2019-01-16 10:52:51.527460: step 8767, loss = 0.64105 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:52:52.490778 ops/training.py:65 2019-01-16 10:52:52.490709: step 8768, loss = 0.70728 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:52:53.453439 ops/training.py:65 2019-01-16 10:52:53.453370: step 8769, loss = 0.64057 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:52:54.415231 ops/training.py:65 2019-01-16 10:52:54.415168: step 8770, loss = 0.65258 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:52:55.376252 ops/training.py:65 2019-01-16 10:52:55.376183: step 8771, loss = 0.72573 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:52:56.337895 ops/training.py:65 2019-01-16 10:52:56.337830: step 8772, loss = 0.69068 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:52:57.298484 ops/training.py:65 2019-01-16 10:52:57.298416: step 8773, loss = 0.65761 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:52:58.259162 ops/training.py:65 2019-01-16 10:52:58.259100: step 8774, loss = 0.62355 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:52:59.218742 ops/training.py:65 2019-01-16 10:52:59.218680: step 8775, loss = 0.62340 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:53:00.179851 ops/training.py:65 2019-01-16 10:53:00.179781: step 8776, loss = 0.72232 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:53:01.143553 ops/training.py:65 2019-01-16 10:53:01.143488: step 8777, loss = 0.63153 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:53:02.106836 ops/training.py:65 2019-01-16 10:53:02.106781: step 8778, loss = 0.61078 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:53:03.070166 ops/training.py:65 2019-01-16 10:53:03.070101: step 8779, loss = 0.52042 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 10:53:04.030153 ops/training.py:65 2019-01-16 10:53:04.030099: step 8780, loss = 0.55568 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:53:04.992151 ops/training.py:65 2019-01-16 10:53:04.992079: step 8781, loss = 0.71918 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:53:05.953994 ops/training.py:65 2019-01-16 10:53:05.953927: step 8782, loss = 0.74094 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:53:06.915378 ops/training.py:65 2019-01-16 10:53:06.915321: step 8783, loss = 0.61251 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:53:07.876960 ops/training.py:65 2019-01-16 10:53:07.876903: step 8784, loss = 0.62578 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:53:08.838653 ops/training.py:65 2019-01-16 10:53:08.838587: step 8785, loss = 0.68409 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:53:09.800242 ops/training.py:65 2019-01-16 10:53:09.800185: step 8786, loss = 0.72849 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:53:10.762095 ops/training.py:65 2019-01-16 10:53:10.762023: step 8787, loss = 0.62491 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:53:11.725227 ops/training.py:65 2019-01-16 10:53:11.725162: step 8788, loss = 0.61762 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:53:12.687992 ops/training.py:65 2019-01-16 10:53:12.687919: step 8789, loss = 0.56765 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 10:53:13.648001 ops/training.py:65 2019-01-16 10:53:13.647945: step 8790, loss = 0.74409 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:53:14.607136 ops/training.py:65 2019-01-16 10:53:14.607083: step 8791, loss = 0.76187 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:53:15.565312 ops/training.py:65 2019-01-16 10:53:15.565263: step 8792, loss = 0.64090 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:53:16.523920 ops/training.py:65 2019-01-16 10:53:16.523865: step 8793, loss = 0.57609 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 10:53:17.486940 ops/training.py:65 2019-01-16 10:53:17.486889: step 8794, loss = 0.76126 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:53:18.450536 ops/training.py:65 2019-01-16 10:53:18.450490: step 8795, loss = 0.68743 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:53:19.413111 ops/training.py:65 2019-01-16 10:53:19.413062: step 8796, loss = 0.67275 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:53:20.374003 ops/training.py:65 2019-01-16 10:53:20.373949: step 8797, loss = 0.59628 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:53:21.333790 ops/training.py:65 2019-01-16 10:53:21.333728: step 8798, loss = 0.57308 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:53:22.295061 ops/training.py:65 2019-01-16 10:53:22.295018: step 8799, loss = 0.68079 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:53:23.255408 ops/training.py:65 2019-01-16 10:53:23.255349: step 8800, loss = 0.63161 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:53:24.216701 ops/training.py:65 2019-01-16 10:53:24.216648: step 8801, loss = 0.54874 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 10:53:25.177911 ops/training.py:65 2019-01-16 10:53:25.177845: step 8802, loss = 0.63948 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:53:26.138816 ops/training.py:65 2019-01-16 10:53:26.138752: step 8803, loss = 0.65335 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:53:27.098818 ops/training.py:65 2019-01-16 10:53:27.098751: step 8804, loss = 0.63856 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:53:28.060184 ops/training.py:65 2019-01-16 10:53:28.060125: step 8805, loss = 0.65678 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:53:29.021401 ops/training.py:65 2019-01-16 10:53:29.021340: step 8806, loss = 0.66251 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:53:29.981876 ops/training.py:65 2019-01-16 10:53:29.981811: step 8807, loss = 0.72100 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:53:30.945397 ops/training.py:65 2019-01-16 10:53:30.945327: step 8808, loss = 0.74093 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:53:31.908910 ops/training.py:65 2019-01-16 10:53:31.908824: step 8809, loss = 0.66044 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:53:32.873615 ops/training.py:65 2019-01-16 10:53:32.873562: step 8810, loss = 0.74363 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:53:33.835440 ops/training.py:65 2019-01-16 10:53:33.835376: step 8811, loss = 0.79604 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:53:34.797448 ops/training.py:65 2019-01-16 10:53:34.797378: step 8812, loss = 0.67532 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:53:35.760910 ops/training.py:65 2019-01-16 10:53:35.760857: step 8813, loss = 0.57090 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 10:53:36.722947 ops/training.py:65 2019-01-16 10:53:36.722885: step 8814, loss = 0.65779 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:53:37.683592 ops/training.py:65 2019-01-16 10:53:37.683542: step 8815, loss = 0.67787 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:53:38.643997 ops/training.py:65 2019-01-16 10:53:38.643926: step 8816, loss = 0.68144 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:53:39.606841 ops/training.py:65 2019-01-16 10:53:39.606783: step 8817, loss = 0.66120 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:53:40.568444 ops/training.py:65 2019-01-16 10:53:40.568394: step 8818, loss = 0.67882 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:53:41.529796 ops/training.py:65 2019-01-16 10:53:41.529725: step 8819, loss = 0.70716 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:53:42.489967 ops/training.py:65 2019-01-16 10:53:42.489905: step 8820, loss = 0.64280 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:53:43.449543 ops/training.py:65 2019-01-16 10:53:43.449471: step 8821, loss = 0.69645 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:53:44.411245 ops/training.py:65 2019-01-16 10:53:44.411179: step 8822, loss = 0.64908 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:53:45.372499 ops/training.py:65 2019-01-16 10:53:45.372433: step 8823, loss = 0.65712 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:53:46.334636 ops/training.py:65 2019-01-16 10:53:46.334574: step 8824, loss = 0.66296 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:53:47.296184 ops/training.py:65 2019-01-16 10:53:47.296114: step 8825, loss = 0.66361 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:53:48.258300 ops/training.py:65 2019-01-16 10:53:48.258247: step 8826, loss = 0.68925 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:53:49.220677 ops/training.py:65 2019-01-16 10:53:49.220629: step 8827, loss = 0.72989 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:53:50.182710 ops/training.py:65 2019-01-16 10:53:50.182655: step 8828, loss = 0.61584 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:53:51.144745 ops/training.py:65 2019-01-16 10:53:51.144674: step 8829, loss = 0.62094 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:53:52.107058 ops/training.py:65 2019-01-16 10:53:52.107003: step 8830, loss = 0.69172 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:53:53.069936 ops/training.py:65 2019-01-16 10:53:53.069885: step 8831, loss = 0.63570 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:53:54.033230 ops/training.py:65 2019-01-16 10:53:54.033176: step 8832, loss = 0.63845 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:53:54.995363 ops/training.py:65 2019-01-16 10:53:54.995313: step 8833, loss = 0.78086 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:53:55.956004 ops/training.py:65 2019-01-16 10:53:55.955954: step 8834, loss = 0.60617 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:53:56.916575 ops/training.py:65 2019-01-16 10:53:56.916521: step 8835, loss = 0.76189 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:53:57.877500 ops/training.py:65 2019-01-16 10:53:57.877451: step 8836, loss = 0.74846 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:53:58.837552 ops/training.py:65 2019-01-16 10:53:58.837503: step 8837, loss = 0.59265 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:53:59.797871 ops/training.py:65 2019-01-16 10:53:59.797819: step 8838, loss = 0.70069 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:54:00.758868 ops/training.py:65 2019-01-16 10:54:00.758791: step 8839, loss = 0.70544 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:54:01.719097 ops/training.py:65 2019-01-16 10:54:01.719040: step 8840, loss = 0.62119 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:54:02.679697 ops/training.py:65 2019-01-16 10:54:02.679638: step 8841, loss = 0.68728 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:54:03.639333 ops/training.py:65 2019-01-16 10:54:03.639284: step 8842, loss = 0.66928 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:54:04.600801 ops/training.py:65 2019-01-16 10:54:04.600739: step 8843, loss = 0.70063 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:54:05.563008 ops/training.py:65 2019-01-16 10:54:05.562951: step 8844, loss = 0.80129 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:54:06.525341 ops/training.py:65 2019-01-16 10:54:06.525283: step 8845, loss = 0.57361 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:54:07.486197 ops/training.py:65 2019-01-16 10:54:07.486125: step 8846, loss = 0.55324 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:54:08.448327 ops/training.py:65 2019-01-16 10:54:08.448278: step 8847, loss = 0.60090 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:54:09.412298 ops/training.py:65 2019-01-16 10:54:09.412252: step 8848, loss = 0.66441 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:54:10.375254 ops/training.py:65 2019-01-16 10:54:10.375214: step 8849, loss = 0.64369 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:54:11.337487 ops/training.py:65 2019-01-16 10:54:11.337437: step 8850, loss = 0.61114 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:54:12.298622 ops/training.py:65 2019-01-16 10:54:12.298574: step 8851, loss = 0.65966 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:54:13.257419 ops/training.py:65 2019-01-16 10:54:13.257367: step 8852, loss = 0.60022 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:54:14.220284 ops/training.py:65 2019-01-16 10:54:14.220220: step 8853, loss = 0.56950 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:54:15.183146 ops/training.py:65 2019-01-16 10:54:15.183096: step 8854, loss = 0.67875 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:54:16.146011 ops/training.py:65 2019-01-16 10:54:16.145959: step 8855, loss = 0.67770 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:54:17.106678 ops/training.py:65 2019-01-16 10:54:17.106598: step 8856, loss = 0.63616 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:54:18.067923 ops/training.py:65 2019-01-16 10:54:18.067855: step 8857, loss = 0.68078 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:54:19.031440 ops/training.py:65 2019-01-16 10:54:19.031382: step 8858, loss = 0.71656 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:54:19.994328 ops/training.py:65 2019-01-16 10:54:19.994262: step 8859, loss = 0.59884 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:54:20.957042 ops/training.py:65 2019-01-16 10:54:20.956971: step 8860, loss = 0.59424 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:54:21.917390 ops/training.py:65 2019-01-16 10:54:21.917328: step 8861, loss = 0.62985 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:54:22.878685 ops/training.py:65 2019-01-16 10:54:22.878614: step 8862, loss = 0.73529 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:54:23.841241 ops/training.py:65 2019-01-16 10:54:23.841191: step 8863, loss = 0.55946 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:54:24.802978 ops/training.py:65 2019-01-16 10:54:24.802891: step 8864, loss = 0.66338 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:54:25.765101 ops/training.py:65 2019-01-16 10:54:25.765055: step 8865, loss = 0.63303 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:54:26.728167 ops/training.py:65 2019-01-16 10:54:26.728120: step 8866, loss = 0.69233 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:54:27.689913 ops/training.py:65 2019-01-16 10:54:27.689860: step 8867, loss = 0.69746 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:54:28.650761 ops/training.py:65 2019-01-16 10:54:28.650712: step 8868, loss = 0.68808 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:54:29.611621 ops/training.py:65 2019-01-16 10:54:29.611575: step 8869, loss = 0.70422 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:54:30.571880 ops/training.py:65 2019-01-16 10:54:30.571815: step 8870, loss = 0.66106 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:54:31.533761 ops/training.py:65 2019-01-16 10:54:31.533688: step 8871, loss = 0.71970 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:54:32.495409 ops/training.py:65 2019-01-16 10:54:32.495352: step 8872, loss = 0.54527 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:54:33.457028 ops/training.py:65 2019-01-16 10:54:33.456973: step 8873, loss = 0.61817 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:54:34.417251 ops/training.py:65 2019-01-16 10:54:34.417196: step 8874, loss = 0.63772 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:54:35.377857 ops/training.py:65 2019-01-16 10:54:35.377786: step 8875, loss = 0.55360 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:54:36.339093 ops/training.py:65 2019-01-16 10:54:36.339044: step 8876, loss = 0.59345 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:54:37.299855 ops/training.py:65 2019-01-16 10:54:37.299803: step 8877, loss = 0.63098 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:54:38.264545 ops/training.py:65 2019-01-16 10:54:38.264493: step 8878, loss = 0.63645 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:54:39.228120 ops/training.py:65 2019-01-16 10:54:39.228059: step 8879, loss = 0.71201 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:54:40.189242 ops/training.py:65 2019-01-16 10:54:40.189173: step 8880, loss = 0.60241 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:54:41.149497 ops/training.py:65 2019-01-16 10:54:41.149425: step 8881, loss = 0.74448 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:54:42.112979 ops/training.py:65 2019-01-16 10:54:42.112929: step 8882, loss = 0.61239 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:54:43.074924 ops/training.py:65 2019-01-16 10:54:43.074873: step 8883, loss = 0.65699 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:54:44.037404 ops/training.py:65 2019-01-16 10:54:44.037343: step 8884, loss = 0.66507 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:54:45.000232 ops/training.py:65 2019-01-16 10:54:45.000161: step 8885, loss = 0.58116 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:54:45.962354 ops/training.py:65 2019-01-16 10:54:45.962283: step 8886, loss = 0.69935 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:54:46.922729 ops/training.py:65 2019-01-16 10:54:46.922669: step 8887, loss = 0.58999 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:54:47.884600 ops/training.py:65 2019-01-16 10:54:47.884550: step 8888, loss = 0.61156 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:54:48.847106 ops/training.py:65 2019-01-16 10:54:48.847061: step 8889, loss = 0.72079 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:54:49.808852 ops/training.py:65 2019-01-16 10:54:49.808803: step 8890, loss = 0.68964 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:54:50.769754 ops/training.py:65 2019-01-16 10:54:50.769698: step 8891, loss = 0.65115 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:54:51.730577 ops/training.py:65 2019-01-16 10:54:51.730526: step 8892, loss = 0.60740 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:54:52.691701 ops/training.py:65 2019-01-16 10:54:52.691650: step 8893, loss = 0.66959 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:54:53.651973 ops/training.py:65 2019-01-16 10:54:53.651921: step 8894, loss = 0.70554 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:54:54.612698 ops/training.py:65 2019-01-16 10:54:54.612651: step 8895, loss = 0.70150 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:54:55.573451 ops/training.py:65 2019-01-16 10:54:55.573402: step 8896, loss = 0.69880 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:54:56.533714 ops/training.py:65 2019-01-16 10:54:56.533641: step 8897, loss = 0.78380 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:54:57.495608 ops/training.py:65 2019-01-16 10:54:57.495540: step 8898, loss = 0.64453 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:54:58.457648 ops/training.py:65 2019-01-16 10:54:58.457582: step 8899, loss = 0.66150 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:54:59.418978 ops/training.py:65 2019-01-16 10:54:59.418905: step 8900, loss = 0.57127 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:55:00.381137 ops/training.py:65 2019-01-16 10:55:00.381067: step 8901, loss = 0.72910 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:55:01.341023 ops/training.py:65 2019-01-16 10:55:01.340970: step 8902, loss = 0.66066 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:55:02.302277 ops/training.py:65 2019-01-16 10:55:02.302214: step 8903, loss = 0.65304 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:55:03.264891 ops/training.py:65 2019-01-16 10:55:03.264840: step 8904, loss = 0.65210 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:55:04.227488 ops/training.py:65 2019-01-16 10:55:04.227433: step 8905, loss = 0.53021 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 10:55:05.187474 ops/training.py:65 2019-01-16 10:55:05.187424: step 8906, loss = 0.67372 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:55:06.149818 ops/training.py:65 2019-01-16 10:55:06.149753: step 8907, loss = 0.62488 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:55:07.114273 ops/training.py:65 2019-01-16 10:55:07.114225: step 8908, loss = 0.67904 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:55:08.077207 ops/training.py:65 2019-01-16 10:55:08.077160: step 8909, loss = 0.76564 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:55:09.039724 ops/training.py:65 2019-01-16 10:55:09.039674: step 8910, loss = 0.58740 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:55:10.003118 ops/training.py:65 2019-01-16 10:55:10.003061: step 8911, loss = 0.72632 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:55:10.966474 ops/training.py:65 2019-01-16 10:55:10.966424: step 8912, loss = 0.68147 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:55:11.929069 ops/training.py:65 2019-01-16 10:55:11.929007: step 8913, loss = 0.72358 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:55:12.890439 ops/training.py:65 2019-01-16 10:55:12.890367: step 8914, loss = 0.70560 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:55:13.850892 ops/training.py:65 2019-01-16 10:55:13.850819: step 8915, loss = 0.65519 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:55:14.811684 ops/training.py:65 2019-01-16 10:55:14.811631: step 8916, loss = 0.62230 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:55:15.777276 ops/training.py:65 2019-01-16 10:55:15.777227: step 8917, loss = 0.67325 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:55:16.740014 ops/training.py:65 2019-01-16 10:55:16.739950: step 8918, loss = 0.65088 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:55:17.703095 ops/training.py:65 2019-01-16 10:55:17.703045: step 8919, loss = 0.67513 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:55:18.663900 ops/training.py:65 2019-01-16 10:55:18.663839: step 8920, loss = 0.63832 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:55:19.625066 ops/training.py:65 2019-01-16 10:55:19.625000: step 8921, loss = 0.74702 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 10:55:20.587924 ops/training.py:65 2019-01-16 10:55:20.587857: step 8922, loss = 0.62093 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:55:21.552267 ops/training.py:65 2019-01-16 10:55:21.552199: step 8923, loss = 0.62439 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:55:22.513015 ops/training.py:65 2019-01-16 10:55:22.512948: step 8924, loss = 0.64067 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:55:23.476367 ops/training.py:65 2019-01-16 10:55:23.476299: step 8925, loss = 0.68502 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:55:24.440405 ops/training.py:65 2019-01-16 10:55:24.440359: step 8926, loss = 0.67751 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:55:25.402584 ops/training.py:65 2019-01-16 10:55:25.402533: step 8927, loss = 0.61548 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:55:26.365447 ops/training.py:65 2019-01-16 10:55:26.365396: step 8928, loss = 0.64888 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:55:27.328205 ops/training.py:65 2019-01-16 10:55:27.328158: step 8929, loss = 0.68720 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:55:28.290505 ops/training.py:65 2019-01-16 10:55:28.290457: step 8930, loss = 0.68817 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:55:29.252123 ops/training.py:65 2019-01-16 10:55:29.252061: step 8931, loss = 0.71387 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:55:30.216449 ops/training.py:65 2019-01-16 10:55:30.216405: step 8932, loss = 0.63076 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:55:31.180575 ops/training.py:65 2019-01-16 10:55:31.180511: step 8933, loss = 0.59239 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:55:32.144759 ops/training.py:65 2019-01-16 10:55:32.144696: step 8934, loss = 0.61915 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:55:33.107565 ops/training.py:65 2019-01-16 10:55:33.107512: step 8935, loss = 0.65341 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:55:34.069204 ops/training.py:65 2019-01-16 10:55:34.069153: step 8936, loss = 0.69444 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:55:35.033488 ops/training.py:65 2019-01-16 10:55:35.033427: step 8937, loss = 0.64158 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:55:35.996036 ops/training.py:65 2019-01-16 10:55:35.995963: step 8938, loss = 0.70148 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:55:36.958905 ops/training.py:65 2019-01-16 10:55:36.958839: step 8939, loss = 0.70715 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:55:37.919327 ops/training.py:65 2019-01-16 10:55:37.919257: step 8940, loss = 0.56376 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:55:38.882098 ops/training.py:65 2019-01-16 10:55:38.882037: step 8941, loss = 0.70649 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:55:39.843204 ops/training.py:65 2019-01-16 10:55:39.843153: step 8942, loss = 0.65256 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:55:40.803559 ops/training.py:65 2019-01-16 10:55:40.803493: step 8943, loss = 0.69865 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:55:41.764679 ops/training.py:65 2019-01-16 10:55:41.764624: step 8944, loss = 0.67735 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:55:42.725070 ops/training.py:65 2019-01-16 10:55:42.724996: step 8945, loss = 0.72029 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:55:43.686817 ops/training.py:65 2019-01-16 10:55:43.686768: step 8946, loss = 0.61316 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:55:44.647231 ops/training.py:65 2019-01-16 10:55:44.647180: step 8947, loss = 0.64998 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:55:45.607907 ops/training.py:65 2019-01-16 10:55:45.607855: step 8948, loss = 0.68742 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:55:46.569926 ops/training.py:65 2019-01-16 10:55:46.569874: step 8949, loss = 0.68547 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:55:47.531413 ops/training.py:65 2019-01-16 10:55:47.531356: step 8950, loss = 0.68092 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:55:48.493463 ops/training.py:65 2019-01-16 10:55:48.493414: step 8951, loss = 0.63996 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:55:49.454291 ops/training.py:65 2019-01-16 10:55:49.454245: step 8952, loss = 0.53265 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 10:55:50.418218 ops/training.py:65 2019-01-16 10:55:50.418170: step 8953, loss = 0.62848 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:55:51.380048 ops/training.py:65 2019-01-16 10:55:51.379982: step 8954, loss = 0.68516 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:55:52.341134 ops/training.py:65 2019-01-16 10:55:52.341063: step 8955, loss = 0.63734 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:55:53.305392 ops/training.py:65 2019-01-16 10:55:53.305347: step 8956, loss = 0.62520 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:55:54.268764 ops/training.py:65 2019-01-16 10:55:54.268714: step 8957, loss = 0.67677 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:55:55.232933 ops/training.py:65 2019-01-16 10:55:55.232877: step 8958, loss = 0.60998 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:55:56.193714 ops/training.py:65 2019-01-16 10:55:56.193666: step 8959, loss = 0.63309 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:55:57.158214 ops/training.py:65 2019-01-16 10:55:57.158160: step 8960, loss = 0.61344 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:55:58.122718 ops/training.py:65 2019-01-16 10:55:58.122665: step 8961, loss = 0.68978 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:55:59.084911 ops/training.py:65 2019-01-16 10:55:59.084859: step 8962, loss = 0.63929 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:56:00.049312 ops/training.py:65 2019-01-16 10:56:00.049240: step 8963, loss = 0.75015 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:56:01.012853 ops/training.py:65 2019-01-16 10:56:01.012792: step 8964, loss = 0.67503 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:56:01.975636 ops/training.py:65 2019-01-16 10:56:01.975590: step 8965, loss = 0.63343 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:56:02.938340 ops/training.py:65 2019-01-16 10:56:02.938287: step 8966, loss = 0.71972 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:56:03.901533 ops/training.py:65 2019-01-16 10:56:03.901483: step 8967, loss = 0.66819 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:56:04.865516 ops/training.py:65 2019-01-16 10:56:04.865461: step 8968, loss = 0.66956 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:56:05.829453 ops/training.py:65 2019-01-16 10:56:05.829403: step 8969, loss = 0.63722 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:56:06.792797 ops/training.py:65 2019-01-16 10:56:06.792745: step 8970, loss = 0.70321 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:56:07.755082 ops/training.py:65 2019-01-16 10:56:07.755009: step 8971, loss = 0.67742 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:56:08.717035 ops/training.py:65 2019-01-16 10:56:08.716988: step 8972, loss = 0.67007 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:56:09.678905 ops/training.py:65 2019-01-16 10:56:09.678853: step 8973, loss = 0.71096 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:56:10.640531 ops/training.py:65 2019-01-16 10:56:10.640476: step 8974, loss = 0.63751 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:56:11.606720 ops/training.py:65 2019-01-16 10:56:11.606676: step 8975, loss = 0.72331 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:56:12.567845 ops/training.py:65 2019-01-16 10:56:12.567775: step 8976, loss = 0.62463 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:56:13.531652 ops/training.py:65 2019-01-16 10:56:13.531590: step 8977, loss = 0.58885 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:56:14.493171 ops/training.py:65 2019-01-16 10:56:14.493109: step 8978, loss = 0.56458 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:56:15.457297 ops/training.py:65 2019-01-16 10:56:15.457227: step 8979, loss = 0.73811 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:56:16.420225 ops/training.py:65 2019-01-16 10:56:16.420151: step 8980, loss = 0.68811 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:56:17.381902 ops/training.py:65 2019-01-16 10:56:17.381848: step 8981, loss = 0.58191 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:56:18.344052 ops/training.py:65 2019-01-16 10:56:18.344005: step 8982, loss = 0.66920 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:56:19.308514 ops/training.py:65 2019-01-16 10:56:19.308457: step 8983, loss = 0.68111 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:56:20.271216 ops/training.py:65 2019-01-16 10:56:20.271146: step 8984, loss = 0.66726 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:56:21.234131 ops/training.py:65 2019-01-16 10:56:21.234086: step 8985, loss = 0.55950 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 10:56:22.194302 ops/training.py:65 2019-01-16 10:56:22.194235: step 8986, loss = 0.54927 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:56:23.159104 ops/training.py:65 2019-01-16 10:56:23.159033: step 8987, loss = 0.64316 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:56:24.121533 ops/training.py:65 2019-01-16 10:56:24.121466: step 8988, loss = 0.66570 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:56:25.084917 ops/training.py:65 2019-01-16 10:56:25.084867: step 8989, loss = 0.69210 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:56:26.047918 ops/training.py:65 2019-01-16 10:56:26.047871: step 8990, loss = 0.66855 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:56:27.010813 ops/training.py:65 2019-01-16 10:56:27.010764: step 8991, loss = 0.63238 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:56:27.973305 ops/training.py:65 2019-01-16 10:56:27.973258: step 8992, loss = 0.56812 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 10:56:28.934898 ops/training.py:65 2019-01-16 10:56:28.934848: step 8993, loss = 0.61115 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:56:29.895912 ops/training.py:65 2019-01-16 10:56:29.895846: step 8994, loss = 0.66991 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:56:30.856889 ops/training.py:65 2019-01-16 10:56:30.856823: step 8995, loss = 0.67581 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:56:31.818495 ops/training.py:65 2019-01-16 10:56:31.818431: step 8996, loss = 0.72017 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:56:32.779664 ops/training.py:65 2019-01-16 10:56:32.779610: step 8997, loss = 0.63887 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:56:33.741160 ops/training.py:65 2019-01-16 10:56:33.741115: step 8998, loss = 0.76437 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:56:34.702032 ops/training.py:65 2019-01-16 10:56:34.701984: step 8999, loss = 0.68971 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:56:35.663788 ops/training.py:65 2019-01-16 10:56:35.663732: step 9000, loss = 0.69669 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:56:36.625424 ops/training.py:65 2019-01-16 10:56:36.625361: step 9001, loss = 0.64137 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:56:37.590535 ops/training.py:65 2019-01-16 10:56:37.590475: step 9002, loss = 0.65136 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:56:38.554680 ops/training.py:65 2019-01-16 10:56:38.554628: step 9003, loss = 0.64467 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:56:39.516854 ops/training.py:65 2019-01-16 10:56:39.516796: step 9004, loss = 0.71771 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:56:40.481024 ops/training.py:65 2019-01-16 10:56:40.480974: step 9005, loss = 0.58611 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:56:41.442848 ops/training.py:65 2019-01-16 10:56:41.442791: step 9006, loss = 0.60655 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:56:42.405313 ops/training.py:65 2019-01-16 10:56:42.405241: step 9007, loss = 0.63337 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:56:43.371262 ops/training.py:65 2019-01-16 10:56:43.371195: step 9008, loss = 0.66876 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:56:44.334498 ops/training.py:65 2019-01-16 10:56:44.334449: step 9009, loss = 0.65813 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:56:45.297313 ops/training.py:65 2019-01-16 10:56:45.297257: step 9010, loss = 0.67645 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:56:46.260775 ops/training.py:65 2019-01-16 10:56:46.260714: step 9011, loss = 0.56385 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 10:56:47.225545 ops/training.py:65 2019-01-16 10:56:47.225481: step 9012, loss = 0.70331 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:56:48.188295 ops/training.py:65 2019-01-16 10:56:48.188231: step 9013, loss = 0.68570 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:56:49.151142 ops/training.py:65 2019-01-16 10:56:49.151071: step 9014, loss = 0.70557 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:56:50.114137 ops/training.py:65 2019-01-16 10:56:50.114064: step 9015, loss = 0.60392 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 10:56:51.076565 ops/training.py:65 2019-01-16 10:56:51.076495: step 9016, loss = 0.59051 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:56:52.039903 ops/training.py:65 2019-01-16 10:56:52.039855: step 9017, loss = 0.68203 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:56:53.003835 ops/training.py:65 2019-01-16 10:56:53.003788: step 9018, loss = 0.60583 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:56:53.966224 ops/training.py:65 2019-01-16 10:56:53.966174: step 9019, loss = 0.62284 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:56:54.928275 ops/training.py:65 2019-01-16 10:56:54.928222: step 9020, loss = 0.61701 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:56:55.890598 ops/training.py:65 2019-01-16 10:56:55.890530: step 9021, loss = 0.64027 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:56:56.852100 ops/training.py:65 2019-01-16 10:56:56.852033: step 9022, loss = 0.68945 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:56:57.813827 ops/training.py:65 2019-01-16 10:56:57.813751: step 9023, loss = 0.58559 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:56:58.774625 ops/training.py:65 2019-01-16 10:56:58.774574: step 9024, loss = 0.84808 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 10:56:59.734637 ops/training.py:65 2019-01-16 10:56:59.734569: step 9025, loss = 0.66641 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:57:00.697015 ops/training.py:65 2019-01-16 10:57:00.696968: step 9026, loss = 0.67051 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:57:01.660438 ops/training.py:65 2019-01-16 10:57:01.660369: step 9027, loss = 0.58079 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:57:02.621976 ops/training.py:65 2019-01-16 10:57:02.621914: step 9028, loss = 0.71933 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:57:03.584090 ops/training.py:65 2019-01-16 10:57:03.584039: step 9029, loss = 0.62568 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:57:04.544963 ops/training.py:65 2019-01-16 10:57:04.544907: step 9030, loss = 0.63305 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:57:05.507710 ops/training.py:65 2019-01-16 10:57:05.507649: step 9031, loss = 0.68672 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:57:06.470027 ops/training.py:65 2019-01-16 10:57:06.469957: step 9032, loss = 0.68777 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:57:07.432945 ops/training.py:65 2019-01-16 10:57:07.432872: step 9033, loss = 0.76005 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:57:08.395300 ops/training.py:65 2019-01-16 10:57:08.395237: step 9034, loss = 0.57724 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:57:09.356959 ops/training.py:65 2019-01-16 10:57:09.356895: step 9035, loss = 0.64166 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:57:10.317119 ops/training.py:65 2019-01-16 10:57:10.317048: step 9036, loss = 0.61667 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:57:11.278671 ops/training.py:65 2019-01-16 10:57:11.278608: step 9037, loss = 0.71812 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:57:12.242033 ops/training.py:65 2019-01-16 10:57:12.241972: step 9038, loss = 0.77276 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:57:13.205094 ops/training.py:65 2019-01-16 10:57:13.205029: step 9039, loss = 0.73553 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:57:14.168243 ops/training.py:65 2019-01-16 10:57:14.168172: step 9040, loss = 0.69799 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:57:15.131730 ops/training.py:65 2019-01-16 10:57:15.131666: step 9041, loss = 0.70234 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:57:16.094209 ops/training.py:65 2019-01-16 10:57:16.094140: step 9042, loss = 0.67319 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:57:17.055595 ops/training.py:65 2019-01-16 10:57:17.055546: step 9043, loss = 0.57616 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:57:18.017265 ops/training.py:65 2019-01-16 10:57:18.017213: step 9044, loss = 0.63973 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:57:18.977941 ops/training.py:65 2019-01-16 10:57:18.977893: step 9045, loss = 0.61729 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:57:19.938745 ops/training.py:65 2019-01-16 10:57:19.938696: step 9046, loss = 0.62822 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:57:20.900313 ops/training.py:65 2019-01-16 10:57:20.900261: step 9047, loss = 0.73377 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:57:21.861847 ops/training.py:65 2019-01-16 10:57:21.861801: step 9048, loss = 0.60044 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:57:22.824294 ops/training.py:65 2019-01-16 10:57:22.824235: step 9049, loss = 0.57468 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 10:57:23.786256 ops/training.py:65 2019-01-16 10:57:23.786181: step 9050, loss = 0.63389 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:57:24.751015 ops/training.py:65 2019-01-16 10:57:24.750950: step 9051, loss = 0.57419 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:57:25.713234 ops/training.py:65 2019-01-16 10:57:25.713168: step 9052, loss = 0.56602 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:57:26.675546 ops/training.py:65 2019-01-16 10:57:26.675474: step 9053, loss = 0.67855 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:57:27.638928 ops/training.py:65 2019-01-16 10:57:27.638846: step 9054, loss = 0.71466 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:57:28.600940 ops/training.py:65 2019-01-16 10:57:28.600873: step 9055, loss = 0.66737 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:57:29.562754 ops/training.py:65 2019-01-16 10:57:29.562688: step 9056, loss = 0.59829 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:57:30.525691 ops/training.py:65 2019-01-16 10:57:30.525646: step 9057, loss = 0.62912 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:57:31.487276 ops/training.py:65 2019-01-16 10:57:31.487230: step 9058, loss = 0.64511 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:57:32.451145 ops/training.py:65 2019-01-16 10:57:32.451086: step 9059, loss = 0.59331 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:57:33.414858 ops/training.py:65 2019-01-16 10:57:33.414791: step 9060, loss = 0.61391 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:57:34.375967 ops/training.py:65 2019-01-16 10:57:34.375923: step 9061, loss = 0.64417 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:57:35.339716 ops/training.py:65 2019-01-16 10:57:35.339642: step 9062, loss = 0.67428 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:57:36.303159 ops/training.py:65 2019-01-16 10:57:36.303109: step 9063, loss = 0.64279 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:57:37.266075 ops/training.py:65 2019-01-16 10:57:37.266015: step 9064, loss = 0.55141 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 10:57:38.228117 ops/training.py:65 2019-01-16 10:57:38.228064: step 9065, loss = 0.61835 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:57:39.191880 ops/training.py:65 2019-01-16 10:57:39.191828: step 9066, loss = 0.60274 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:57:40.153638 ops/training.py:65 2019-01-16 10:57:40.153581: step 9067, loss = 0.63218 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:57:41.116785 ops/training.py:65 2019-01-16 10:57:41.116715: step 9068, loss = 0.60540 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:57:42.078023 ops/training.py:65 2019-01-16 10:57:42.077968: step 9069, loss = 0.60858 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:57:43.040745 ops/training.py:65 2019-01-16 10:57:43.040690: step 9070, loss = 0.68734 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:57:44.004408 ops/training.py:65 2019-01-16 10:57:44.004358: step 9071, loss = 0.68185 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:57:44.968989 ops/training.py:65 2019-01-16 10:57:44.968925: step 9072, loss = 0.66546 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:57:45.932763 ops/training.py:65 2019-01-16 10:57:45.932699: step 9073, loss = 0.58475 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:57:46.894785 ops/training.py:65 2019-01-16 10:57:46.894718: step 9074, loss = 0.71286 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:57:47.857198 ops/training.py:65 2019-01-16 10:57:47.857131: step 9075, loss = 0.64795 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:57:48.819111 ops/training.py:65 2019-01-16 10:57:48.819050: step 9076, loss = 0.61785 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:57:49.781731 ops/training.py:65 2019-01-16 10:57:49.781657: step 9077, loss = 0.54184 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 10:57:50.744271 ops/training.py:65 2019-01-16 10:57:50.744205: step 9078, loss = 0.63341 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:57:51.706747 ops/training.py:65 2019-01-16 10:57:51.706678: step 9079, loss = 0.66063 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:57:52.670299 ops/training.py:65 2019-01-16 10:57:52.670245: step 9080, loss = 0.69292 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:57:53.634247 ops/training.py:65 2019-01-16 10:57:53.634178: step 9081, loss = 0.55963 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:57:54.597578 ops/training.py:65 2019-01-16 10:57:54.597512: step 9082, loss = 0.69024 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:57:55.561483 ops/training.py:65 2019-01-16 10:57:55.561427: step 9083, loss = 0.56524 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:57:56.524211 ops/training.py:65 2019-01-16 10:57:56.524140: step 9084, loss = 0.53363 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 10:57:57.484927 ops/training.py:65 2019-01-16 10:57:57.484879: step 9085, loss = 0.69463 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:57:58.447120 ops/training.py:65 2019-01-16 10:57:58.447068: step 9086, loss = 0.69430 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:57:59.411698 ops/training.py:65 2019-01-16 10:57:59.411648: step 9087, loss = 0.67319 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:58:00.375789 ops/training.py:65 2019-01-16 10:58:00.375718: step 9088, loss = 0.63103 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:58:01.337833 ops/training.py:65 2019-01-16 10:58:01.337780: step 9089, loss = 0.63934 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:58:02.301216 ops/training.py:65 2019-01-16 10:58:02.301161: step 9090, loss = 0.63859 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:58:03.263758 ops/training.py:65 2019-01-16 10:58:03.263693: step 9091, loss = 0.51608 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:58:04.225133 ops/training.py:65 2019-01-16 10:58:04.225082: step 9092, loss = 0.55258 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:58:05.188297 ops/training.py:65 2019-01-16 10:58:05.188248: step 9093, loss = 0.62730 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:58:06.150286 ops/training.py:65 2019-01-16 10:58:06.150244: step 9094, loss = 0.72411 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:58:07.111926 ops/training.py:65 2019-01-16 10:58:07.111869: step 9095, loss = 0.68768 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:58:08.072796 ops/training.py:65 2019-01-16 10:58:08.072744: step 9096, loss = 0.65784 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:58:09.033461 ops/training.py:65 2019-01-16 10:58:09.033407: step 9097, loss = 0.80008 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:58:09.993574 ops/training.py:65 2019-01-16 10:58:09.993526: step 9098, loss = 0.69027 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:58:10.955363 ops/training.py:65 2019-01-16 10:58:10.955306: step 9099, loss = 0.62420 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:58:11.919560 ops/training.py:65 2019-01-16 10:58:11.919511: step 9100, loss = 0.66674 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:58:12.883844 ops/training.py:65 2019-01-16 10:58:12.883788: step 9101, loss = 0.61924 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:58:13.847209 ops/training.py:65 2019-01-16 10:58:13.847158: step 9102, loss = 0.53339 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 10:58:14.809325 ops/training.py:65 2019-01-16 10:58:14.809267: step 9103, loss = 0.60880 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:58:15.774541 ops/training.py:65 2019-01-16 10:58:15.774495: step 9104, loss = 0.62431 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:58:16.736405 ops/training.py:65 2019-01-16 10:58:16.736353: step 9105, loss = 0.66491 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:58:17.700120 ops/training.py:65 2019-01-16 10:58:17.700054: step 9106, loss = 0.66469 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:58:18.661541 ops/training.py:65 2019-01-16 10:58:18.661486: step 9107, loss = 0.65476 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:58:19.624635 ops/training.py:65 2019-01-16 10:58:19.624572: step 9108, loss = 0.54582 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:58:20.585479 ops/training.py:65 2019-01-16 10:58:20.585428: step 9109, loss = 0.54661 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:58:21.550048 ops/training.py:65 2019-01-16 10:58:21.549995: step 9110, loss = 0.69512 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:58:22.512585 ops/training.py:65 2019-01-16 10:58:22.512535: step 9111, loss = 0.65585 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:58:23.474397 ops/training.py:65 2019-01-16 10:58:23.474343: step 9112, loss = 0.53914 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 10:58:24.435438 ops/training.py:65 2019-01-16 10:58:24.435380: step 9113, loss = 0.73948 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:58:25.396707 ops/training.py:65 2019-01-16 10:58:25.396654: step 9114, loss = 0.78174 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 10:58:26.360186 ops/training.py:65 2019-01-16 10:58:26.360126: step 9115, loss = 0.60017 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:58:27.323471 ops/training.py:65 2019-01-16 10:58:27.323398: step 9116, loss = 0.70184 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:58:28.284642 ops/training.py:65 2019-01-16 10:58:28.284573: step 9117, loss = 0.62483 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:58:29.245111 ops/training.py:65 2019-01-16 10:58:29.245046: step 9118, loss = 0.64993 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:58:30.208197 ops/training.py:65 2019-01-16 10:58:30.208140: step 9119, loss = 0.56975 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 10:58:31.169252 ops/training.py:65 2019-01-16 10:58:31.169191: step 9120, loss = 0.70503 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:58:32.129443 ops/training.py:65 2019-01-16 10:58:32.129374: step 9121, loss = 0.59119 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:58:33.089958 ops/training.py:65 2019-01-16 10:58:33.089906: step 9122, loss = 0.71044 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:58:34.052492 ops/training.py:65 2019-01-16 10:58:34.052430: step 9123, loss = 0.68748 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:58:35.012793 ops/training.py:65 2019-01-16 10:58:35.012742: step 9124, loss = 0.69951 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:58:35.975851 ops/training.py:65 2019-01-16 10:58:35.975798: step 9125, loss = 0.65338 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:58:36.937533 ops/training.py:65 2019-01-16 10:58:36.937472: step 9126, loss = 0.61235 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:58:37.898633 ops/training.py:65 2019-01-16 10:58:37.898560: step 9127, loss = 0.70308 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:58:38.860081 ops/training.py:65 2019-01-16 10:58:38.860014: step 9128, loss = 0.62351 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:58:39.821697 ops/training.py:65 2019-01-16 10:58:39.821622: step 9129, loss = 0.68711 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:58:40.783079 ops/training.py:65 2019-01-16 10:58:40.783009: step 9130, loss = 0.70350 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:58:41.747801 ops/training.py:65 2019-01-16 10:58:41.747750: step 9131, loss = 0.63653 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:58:42.709308 ops/training.py:65 2019-01-16 10:58:42.709245: step 9132, loss = 0.70510 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:58:43.669796 ops/training.py:65 2019-01-16 10:58:43.669736: step 9133, loss = 0.64033 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:58:44.632457 ops/training.py:65 2019-01-16 10:58:44.632405: step 9134, loss = 0.79471 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:58:45.594114 ops/training.py:65 2019-01-16 10:58:45.594064: step 9135, loss = 0.67536 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:58:46.557416 ops/training.py:65 2019-01-16 10:58:46.557361: step 9136, loss = 0.68565 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:58:47.519520 ops/training.py:65 2019-01-16 10:58:47.519455: step 9137, loss = 0.69048 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:58:48.481227 ops/training.py:65 2019-01-16 10:58:48.481178: step 9138, loss = 0.63208 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:58:49.445511 ops/training.py:65 2019-01-16 10:58:49.445461: step 9139, loss = 0.69839 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:58:50.407810 ops/training.py:65 2019-01-16 10:58:50.407758: step 9140, loss = 0.58007 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:58:51.370060 ops/training.py:65 2019-01-16 10:58:51.369999: step 9141, loss = 0.59778 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:58:52.332365 ops/training.py:65 2019-01-16 10:58:52.332303: step 9142, loss = 0.60009 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:58:53.292835 ops/training.py:65 2019-01-16 10:58:53.292773: step 9143, loss = 0.68362 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:58:54.253646 ops/training.py:65 2019-01-16 10:58:54.253595: step 9144, loss = 0.67698 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:58:55.217378 ops/training.py:65 2019-01-16 10:58:55.217327: step 9145, loss = 0.60436 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:58:56.179174 ops/training.py:65 2019-01-16 10:58:56.179118: step 9146, loss = 0.61115 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:58:57.138697 ops/training.py:65 2019-01-16 10:58:57.138628: step 9147, loss = 0.59264 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:58:58.101211 ops/training.py:65 2019-01-16 10:58:58.101160: step 9148, loss = 0.70835 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:58:59.064804 ops/training.py:65 2019-01-16 10:58:59.064749: step 9149, loss = 0.71549 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:59:00.026329 ops/training.py:65 2019-01-16 10:59:00.026281: step 9150, loss = 0.66382 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:59:00.990178 ops/training.py:65 2019-01-16 10:59:00.990125: step 9151, loss = 0.73162 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:59:01.953889 ops/training.py:65 2019-01-16 10:59:01.953838: step 9152, loss = 0.60658 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:59:02.915769 ops/training.py:65 2019-01-16 10:59:02.915710: step 9153, loss = 0.65001 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:59:03.877227 ops/training.py:65 2019-01-16 10:59:03.877180: step 9154, loss = 0.74958 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:59:04.838230 ops/training.py:65 2019-01-16 10:59:04.838182: step 9155, loss = 0.60314 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:59:05.798841 ops/training.py:65 2019-01-16 10:59:05.798768: step 9156, loss = 0.62315 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:59:06.759858 ops/training.py:65 2019-01-16 10:59:06.759808: step 9157, loss = 0.69823 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:59:07.720421 ops/training.py:65 2019-01-16 10:59:07.720350: step 9158, loss = 0.77134 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:59:08.681217 ops/training.py:65 2019-01-16 10:59:08.681158: step 9159, loss = 0.60975 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:59:09.646813 ops/training.py:65 2019-01-16 10:59:09.646766: step 9160, loss = 0.65991 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:59:10.609454 ops/training.py:65 2019-01-16 10:59:10.609389: step 9161, loss = 0.59381 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:59:11.573608 ops/training.py:65 2019-01-16 10:59:11.573536: step 9162, loss = 0.59133 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:59:12.538224 ops/training.py:65 2019-01-16 10:59:12.538151: step 9163, loss = 0.71646 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:59:13.501311 ops/training.py:65 2019-01-16 10:59:13.501258: step 9164, loss = 0.73457 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:59:14.463371 ops/training.py:65 2019-01-16 10:59:14.463318: step 9165, loss = 0.66581 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:59:15.424785 ops/training.py:65 2019-01-16 10:59:15.424723: step 9166, loss = 0.69409 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:59:16.389295 ops/training.py:65 2019-01-16 10:59:16.389245: step 9167, loss = 0.61743 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:59:17.351903 ops/training.py:65 2019-01-16 10:59:17.351854: step 9168, loss = 0.56838 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:59:18.313732 ops/training.py:65 2019-01-16 10:59:18.313683: step 9169, loss = 0.62535 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:59:19.274820 ops/training.py:65 2019-01-16 10:59:19.274756: step 9170, loss = 0.54963 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:59:20.237414 ops/training.py:65 2019-01-16 10:59:20.237342: step 9171, loss = 0.65171 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:59:21.199330 ops/training.py:65 2019-01-16 10:59:21.199271: step 9172, loss = 0.64578 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:59:22.162770 ops/training.py:65 2019-01-16 10:59:22.162719: step 9173, loss = 0.58633 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:59:23.126692 ops/training.py:65 2019-01-16 10:59:23.126644: step 9174, loss = 0.56907 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:59:24.087896 ops/training.py:65 2019-01-16 10:59:24.087844: step 9175, loss = 0.61547 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:59:25.048593 ops/training.py:65 2019-01-16 10:59:25.048527: step 9176, loss = 0.68363 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:59:26.009462 ops/training.py:65 2019-01-16 10:59:26.009410: step 9177, loss = 0.72489 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:59:26.971183 ops/training.py:65 2019-01-16 10:59:26.971134: step 9178, loss = 0.62254 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:59:27.932278 ops/training.py:65 2019-01-16 10:59:27.932221: step 9179, loss = 0.58297 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:59:28.893985 ops/training.py:65 2019-01-16 10:59:28.893916: step 9180, loss = 0.69231 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:59:29.854699 ops/training.py:65 2019-01-16 10:59:29.854636: step 9181, loss = 0.60621 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:59:30.816383 ops/training.py:65 2019-01-16 10:59:30.816311: step 9182, loss = 0.58908 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:59:31.778132 ops/training.py:65 2019-01-16 10:59:31.778064: step 9183, loss = 0.56839 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:59:32.738851 ops/training.py:65 2019-01-16 10:59:32.738790: step 9184, loss = 0.69451 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:59:33.699421 ops/training.py:65 2019-01-16 10:59:33.699367: step 9185, loss = 0.60678 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:59:34.659096 ops/training.py:65 2019-01-16 10:59:34.659038: step 9186, loss = 0.60175 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:59:35.621205 ops/training.py:65 2019-01-16 10:59:35.621154: step 9187, loss = 0.64979 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:59:36.582643 ops/training.py:65 2019-01-16 10:59:36.582585: step 9188, loss = 0.53671 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:59:37.548693 ops/training.py:65 2019-01-16 10:59:37.548627: step 9189, loss = 0.69067 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 10:59:38.511116 ops/training.py:65 2019-01-16 10:59:38.511066: step 9190, loss = 0.61279 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:59:39.474219 ops/training.py:65 2019-01-16 10:59:39.474169: step 9191, loss = 0.62157 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:59:40.435114 ops/training.py:65 2019-01-16 10:59:40.435041: step 9192, loss = 0.60704 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:59:41.396558 ops/training.py:65 2019-01-16 10:59:41.396500: step 9193, loss = 0.63218 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:59:42.361388 ops/training.py:65 2019-01-16 10:59:42.361319: step 9194, loss = 0.67260 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:59:43.325865 ops/training.py:65 2019-01-16 10:59:43.325799: step 9195, loss = 0.70798 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:59:44.288570 ops/training.py:65 2019-01-16 10:59:44.288518: step 9196, loss = 0.74007 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 10:59:45.252985 ops/training.py:65 2019-01-16 10:59:45.252937: step 9197, loss = 0.63382 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:59:46.216458 ops/training.py:65 2019-01-16 10:59:46.216407: step 9198, loss = 0.58551 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:59:47.179800 ops/training.py:65 2019-01-16 10:59:47.179750: step 9199, loss = 0.80978 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:59:48.141138 ops/training.py:65 2019-01-16 10:59:48.141088: step 9200, loss = 0.58894 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:59:49.103322 ops/training.py:65 2019-01-16 10:59:49.103266: step 9201, loss = 0.63176 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 10:59:50.064012 ops/training.py:65 2019-01-16 10:59:50.063937: step 9202, loss = 0.64805 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:59:51.028038 ops/training.py:65 2019-01-16 10:59:51.027989: step 9203, loss = 0.67355 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 10:59:51.991760 ops/training.py:65 2019-01-16 10:59:51.991696: step 9204, loss = 0.63352 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:59:52.954418 ops/training.py:65 2019-01-16 10:59:52.954346: step 9205, loss = 0.58560 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 10:59:53.915806 ops/training.py:65 2019-01-16 10:59:53.915748: step 9206, loss = 0.60114 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:59:54.879138 ops/training.py:65 2019-01-16 10:59:54.879074: step 9207, loss = 0.69474 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 10:59:55.841166 ops/training.py:65 2019-01-16 10:59:55.841099: step 9208, loss = 0.60357 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 10:59:56.802657 ops/training.py:65 2019-01-16 10:59:56.802591: step 9209, loss = 0.63552 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 10:59:57.764052 ops/training.py:65 2019-01-16 10:59:57.763985: step 9210, loss = 0.56521 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 10:59:58.725869 ops/training.py:65 2019-01-16 10:59:58.725798: step 9211, loss = 0.56736 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 10:59:59.686095 ops/training.py:65 2019-01-16 10:59:59.686027: step 9212, loss = 0.58063 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:00:00.644440 ops/training.py:65 2019-01-16 11:00:00.644398: step 9213, loss = 0.51630 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:00:01.603774 ops/training.py:65 2019-01-16 11:00:01.603712: step 9214, loss = 0.53585 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:00:02.564919 ops/training.py:65 2019-01-16 11:00:02.564849: step 9215, loss = 0.51843 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:00:03.526897 ops/training.py:65 2019-01-16 11:00:03.526827: step 9216, loss = 0.63036 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:00:04.486838 ops/training.py:65 2019-01-16 11:00:04.486786: step 9217, loss = 0.63466 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:00:05.449015 ops/training.py:65 2019-01-16 11:00:05.448937: step 9218, loss = 0.64194 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:00:06.408832 ops/training.py:65 2019-01-16 11:00:06.408759: step 9219, loss = 0.52694 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:00:07.374395 ops/training.py:65 2019-01-16 11:00:07.374328: step 9220, loss = 0.58219 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:00:08.335481 ops/training.py:65 2019-01-16 11:00:08.335411: step 9221, loss = 0.71362 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:00:09.300667 ops/training.py:65 2019-01-16 11:00:09.300600: step 9222, loss = 0.68099 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:00:10.262001 ops/training.py:65 2019-01-16 11:00:10.261940: step 9223, loss = 0.68827 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:00:11.223562 ops/training.py:65 2019-01-16 11:00:11.223495: step 9224, loss = 0.55272 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:00:12.183484 ops/training.py:65 2019-01-16 11:00:12.183415: step 9225, loss = 0.61958 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:00:13.144892 ops/training.py:65 2019-01-16 11:00:13.144834: step 9226, loss = 0.68273 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:00:14.108923 ops/training.py:65 2019-01-16 11:00:14.108870: step 9227, loss = 0.68201 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:00:15.072082 ops/training.py:65 2019-01-16 11:00:15.072027: step 9228, loss = 0.79171 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:00:16.033795 ops/training.py:65 2019-01-16 11:00:16.033745: step 9229, loss = 0.72941 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:00:16.994425 ops/training.py:65 2019-01-16 11:00:16.994370: step 9230, loss = 0.71035 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 11:00:17.955259 ops/training.py:65 2019-01-16 11:00:17.955194: step 9231, loss = 0.67889 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:00:18.916485 ops/training.py:65 2019-01-16 11:00:18.916421: step 9232, loss = 0.71642 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:00:19.876546 ops/training.py:65 2019-01-16 11:00:19.876501: step 9233, loss = 0.63469 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:00:20.839028 ops/training.py:65 2019-01-16 11:00:20.838979: step 9234, loss = 0.58070 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:00:21.799278 ops/training.py:65 2019-01-16 11:00:21.799228: step 9235, loss = 0.73861 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:00:22.761301 ops/training.py:65 2019-01-16 11:00:22.761227: step 9236, loss = 0.71719 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:00:23.721494 ops/training.py:65 2019-01-16 11:00:23.721424: step 9237, loss = 0.67689 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:00:24.680469 ops/training.py:65 2019-01-16 11:00:24.680382: step 9238, loss = 0.59986 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:00:25.638504 ops/training.py:65 2019-01-16 11:00:25.638421: step 9239, loss = 0.63210 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:00:26.600255 ops/training.py:65 2019-01-16 11:00:26.600212: step 9240, loss = 0.63125 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:00:27.563551 ops/training.py:65 2019-01-16 11:00:27.563488: step 9241, loss = 0.63544 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:00:28.526343 ops/training.py:65 2019-01-16 11:00:28.526286: step 9242, loss = 0.63757 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:00:29.486786 ops/training.py:65 2019-01-16 11:00:29.486748: step 9243, loss = 0.68915 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:00:30.448946 ops/training.py:65 2019-01-16 11:00:30.448862: step 9244, loss = 0.57893 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:00:31.414966 ops/training.py:65 2019-01-16 11:00:31.414897: step 9245, loss = 0.60710 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:00:32.377414 ops/training.py:65 2019-01-16 11:00:32.377345: step 9246, loss = 0.66108 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:00:33.339457 ops/training.py:65 2019-01-16 11:00:33.339380: step 9247, loss = 0.68309 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:00:34.302168 ops/training.py:65 2019-01-16 11:00:34.302111: step 9248, loss = 0.60988 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:00:35.264177 ops/training.py:65 2019-01-16 11:00:35.264112: step 9249, loss = 0.51419 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:00:36.226364 ops/training.py:65 2019-01-16 11:00:36.226299: step 9250, loss = 0.62899 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:00:37.187603 ops/training.py:65 2019-01-16 11:00:37.187545: step 9251, loss = 0.59110 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:00:38.148781 ops/training.py:65 2019-01-16 11:00:38.148723: step 9252, loss = 0.66188 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:00:39.109799 ops/training.py:65 2019-01-16 11:00:39.109749: step 9253, loss = 0.75368 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:00:40.071271 ops/training.py:65 2019-01-16 11:00:40.071207: step 9254, loss = 0.68321 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:00:41.032029 ops/training.py:65 2019-01-16 11:00:41.031970: step 9255, loss = 0.70071 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 11:00:41.992926 ops/training.py:65 2019-01-16 11:00:41.992864: step 9256, loss = 0.61889 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:00:42.954063 ops/training.py:65 2019-01-16 11:00:42.954018: step 9257, loss = 0.55013 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:00:43.914887 ops/training.py:65 2019-01-16 11:00:43.914828: step 9258, loss = 0.67227 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:00:44.875896 ops/training.py:65 2019-01-16 11:00:44.875838: step 9259, loss = 0.73219 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:00:45.836323 ops/training.py:65 2019-01-16 11:00:45.836258: step 9260, loss = 0.65878 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:00:46.802506 ops/training.py:65 2019-01-16 11:00:46.802448: step 9261, loss = 0.70481 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:00:47.766676 ops/training.py:65 2019-01-16 11:00:47.766617: step 9262, loss = 0.64391 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:00:48.726452 ops/training.py:65 2019-01-16 11:00:48.726401: step 9263, loss = 0.71641 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:00:49.690815 ops/training.py:65 2019-01-16 11:00:49.690768: step 9264, loss = 0.70262 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:00:50.654732 ops/training.py:65 2019-01-16 11:00:50.654665: step 9265, loss = 0.64506 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:00:51.615055 ops/training.py:65 2019-01-16 11:00:51.614977: step 9266, loss = 0.60888 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:00:52.579720 ops/training.py:65 2019-01-16 11:00:52.579670: step 9267, loss = 0.85043 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 11:00:53.543689 ops/training.py:65 2019-01-16 11:00:53.543644: step 9268, loss = 0.58576 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:00:54.506584 ops/training.py:65 2019-01-16 11:00:54.506525: step 9269, loss = 0.72846 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:00:55.467881 ops/training.py:65 2019-01-16 11:00:55.467822: step 9270, loss = 0.66911 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:00:56.429077 ops/training.py:65 2019-01-16 11:00:56.429002: step 9271, loss = 0.65432 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:00:57.391586 ops/training.py:65 2019-01-16 11:00:57.391514: step 9272, loss = 0.60921 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:00:58.357006 ops/training.py:65 2019-01-16 11:00:58.356937: step 9273, loss = 0.56347 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:00:59.322705 ops/training.py:65 2019-01-16 11:00:59.322642: step 9274, loss = 0.55495 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:01:00.287946 ops/training.py:65 2019-01-16 11:01:00.287885: step 9275, loss = 0.61218 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:01:01.248808 ops/training.py:65 2019-01-16 11:01:01.248757: step 9276, loss = 0.68891 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:01:02.212352 ops/training.py:65 2019-01-16 11:01:02.212292: step 9277, loss = 0.66895 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 11:01:03.174418 ops/training.py:65 2019-01-16 11:01:03.174353: step 9278, loss = 0.59316 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:01:04.134663 ops/training.py:65 2019-01-16 11:01:04.134598: step 9279, loss = 0.68851 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:01:05.099216 ops/training.py:65 2019-01-16 11:01:05.099158: step 9280, loss = 0.63862 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:01:06.061727 ops/training.py:65 2019-01-16 11:01:06.061673: step 9281, loss = 0.69627 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:01:07.022024 ops/training.py:65 2019-01-16 11:01:07.021950: step 9282, loss = 0.71305 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:01:07.985780 ops/training.py:65 2019-01-16 11:01:07.985723: step 9283, loss = 0.68521 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:01:08.947972 ops/training.py:65 2019-01-16 11:01:08.947916: step 9284, loss = 0.59542 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:01:09.911394 ops/training.py:65 2019-01-16 11:01:09.911342: step 9285, loss = 0.57594 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:01:10.872362 ops/training.py:65 2019-01-16 11:01:10.872302: step 9286, loss = 0.61444 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:01:11.837444 ops/training.py:65 2019-01-16 11:01:11.837373: step 9287, loss = 0.65642 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:01:12.797733 ops/training.py:65 2019-01-16 11:01:12.797659: step 9288, loss = 0.55172 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:01:13.762284 ops/training.py:65 2019-01-16 11:01:13.762212: step 9289, loss = 0.66963 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:01:14.723527 ops/training.py:65 2019-01-16 11:01:14.723475: step 9290, loss = 0.60947 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:01:15.685521 ops/training.py:65 2019-01-16 11:01:15.685471: step 9291, loss = 0.58540 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:01:16.646818 ops/training.py:65 2019-01-16 11:01:16.646771: step 9292, loss = 0.63537 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:01:17.608087 ops/training.py:65 2019-01-16 11:01:17.608048: step 9293, loss = 0.65315 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:01:18.568968 ops/training.py:65 2019-01-16 11:01:18.568926: step 9294, loss = 0.62696 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:01:19.529687 ops/training.py:65 2019-01-16 11:01:19.529629: step 9295, loss = 0.58985 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:01:20.490827 ops/training.py:65 2019-01-16 11:01:20.490791: step 9296, loss = 0.65047 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:01:21.451276 ops/training.py:65 2019-01-16 11:01:21.451238: step 9297, loss = 0.68599 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:01:22.412057 ops/training.py:65 2019-01-16 11:01:22.412011: step 9298, loss = 0.53414 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:01:23.373317 ops/training.py:65 2019-01-16 11:01:23.373262: step 9299, loss = 0.69868 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:01:24.337719 ops/training.py:65 2019-01-16 11:01:24.337662: step 9300, loss = 0.59394 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:01:25.300179 ops/training.py:65 2019-01-16 11:01:25.300141: step 9301, loss = 0.67278 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:01:26.262851 ops/training.py:65 2019-01-16 11:01:26.262813: step 9302, loss = 0.68605 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:01:27.225045 ops/training.py:65 2019-01-16 11:01:27.225007: step 9303, loss = 0.66078 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:01:28.188881 ops/training.py:65 2019-01-16 11:01:28.188826: step 9304, loss = 0.65650 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:01:29.151102 ops/training.py:65 2019-01-16 11:01:29.151047: step 9305, loss = 0.90042 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.28125
I0832 2019-01-16 11:01:30.113910 ops/training.py:65 2019-01-16 11:01:30.113866: step 9306, loss = 0.59630 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:01:31.079391 ops/training.py:65 2019-01-16 11:01:31.079332: step 9307, loss = 0.83846 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 11:01:32.041464 ops/training.py:65 2019-01-16 11:01:32.041405: step 9308, loss = 0.61536 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:01:33.002105 ops/training.py:65 2019-01-16 11:01:33.002048: step 9309, loss = 0.63274 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:01:33.966621 ops/training.py:65 2019-01-16 11:01:33.966546: step 9310, loss = 0.64252 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:01:34.927392 ops/training.py:65 2019-01-16 11:01:34.927338: step 9311, loss = 0.70947 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:01:35.889757 ops/training.py:65 2019-01-16 11:01:35.889681: step 9312, loss = 0.66173 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:01:36.853836 ops/training.py:65 2019-01-16 11:01:36.853787: step 9313, loss = 0.58233 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:01:37.817516 ops/training.py:65 2019-01-16 11:01:37.817465: step 9314, loss = 0.67991 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:01:38.779288 ops/training.py:65 2019-01-16 11:01:38.779233: step 9315, loss = 0.59625 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:01:39.740717 ops/training.py:65 2019-01-16 11:01:39.740670: step 9316, loss = 0.63582 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:01:40.700812 ops/training.py:65 2019-01-16 11:01:40.700743: step 9317, loss = 0.55092 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:01:41.661578 ops/training.py:65 2019-01-16 11:01:41.661522: step 9318, loss = 0.67490 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:01:42.625907 ops/training.py:65 2019-01-16 11:01:42.625844: step 9319, loss = 0.62635 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:01:43.589624 ops/training.py:65 2019-01-16 11:01:43.589557: step 9320, loss = 0.57791 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:01:44.552839 ops/training.py:65 2019-01-16 11:01:44.552790: step 9321, loss = 0.53517 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:01:45.512622 ops/training.py:65 2019-01-16 11:01:45.512572: step 9322, loss = 0.60086 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:01:46.476260 ops/training.py:65 2019-01-16 11:01:46.476189: step 9323, loss = 0.61021 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:01:47.437381 ops/training.py:65 2019-01-16 11:01:47.437304: step 9324, loss = 0.73696 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:01:48.396575 ops/training.py:65 2019-01-16 11:01:48.396513: step 9325, loss = 0.58946 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:01:49.358857 ops/training.py:65 2019-01-16 11:01:49.358796: step 9326, loss = 0.72655 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:01:50.322952 ops/training.py:65 2019-01-16 11:01:50.322893: step 9327, loss = 0.62629 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:01:51.286564 ops/training.py:65 2019-01-16 11:01:51.286499: step 9328, loss = 0.60553 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:01:52.247344 ops/training.py:65 2019-01-16 11:01:52.247303: step 9329, loss = 0.67485 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:01:53.208819 ops/training.py:65 2019-01-16 11:01:53.208759: step 9330, loss = 0.76056 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:01:54.169627 ops/training.py:65 2019-01-16 11:01:54.169584: step 9331, loss = 0.55802 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:01:55.133962 ops/training.py:65 2019-01-16 11:01:55.133919: step 9332, loss = 0.69729 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:01:56.094137 ops/training.py:65 2019-01-16 11:01:56.094081: step 9333, loss = 0.59337 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:01:57.055927 ops/training.py:65 2019-01-16 11:01:57.055857: step 9334, loss = 0.74487 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:01:58.016131 ops/training.py:65 2019-01-16 11:01:58.016075: step 9335, loss = 0.54297 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:01:58.976156 ops/training.py:65 2019-01-16 11:01:58.976106: step 9336, loss = 0.67497 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:01:59.935682 ops/training.py:65 2019-01-16 11:01:59.935613: step 9337, loss = 0.63335 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:02:00.898189 ops/training.py:65 2019-01-16 11:02:00.898127: step 9338, loss = 0.71134 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:02:01.858811 ops/training.py:65 2019-01-16 11:02:01.858746: step 9339, loss = 0.66448 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:02:02.817452 ops/training.py:65 2019-01-16 11:02:02.817383: step 9340, loss = 0.52547 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:02:03.779526 ops/training.py:65 2019-01-16 11:02:03.779471: step 9341, loss = 0.74846 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:02:04.742430 ops/training.py:65 2019-01-16 11:02:04.742376: step 9342, loss = 0.66532 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:02:05.703472 ops/training.py:65 2019-01-16 11:02:05.703415: step 9343, loss = 0.60666 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:02:06.663653 ops/training.py:65 2019-01-16 11:02:06.663599: step 9344, loss = 0.64042 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:02:07.624379 ops/training.py:65 2019-01-16 11:02:07.624338: step 9345, loss = 0.64100 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:02:08.586304 ops/training.py:65 2019-01-16 11:02:08.586260: step 9346, loss = 0.73699 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:02:09.547083 ops/training.py:65 2019-01-16 11:02:09.547012: step 9347, loss = 0.66870 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:02:10.507689 ops/training.py:65 2019-01-16 11:02:10.507616: step 9348, loss = 0.75246 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:02:11.467930 ops/training.py:65 2019-01-16 11:02:11.467861: step 9349, loss = 0.59368 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:02:12.430091 ops/training.py:65 2019-01-16 11:02:12.430026: step 9350, loss = 0.68085 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:02:13.391966 ops/training.py:65 2019-01-16 11:02:13.391895: step 9351, loss = 0.67212 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:02:14.355954 ops/training.py:65 2019-01-16 11:02:14.355905: step 9352, loss = 0.62336 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:02:15.319331 ops/training.py:65 2019-01-16 11:02:15.319258: step 9353, loss = 0.71232 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:02:16.282626 ops/training.py:65 2019-01-16 11:02:16.282552: step 9354, loss = 0.71009 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:02:17.244103 ops/training.py:65 2019-01-16 11:02:17.244045: step 9355, loss = 0.63263 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:02:18.206104 ops/training.py:65 2019-01-16 11:02:18.206061: step 9356, loss = 0.58042 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:02:19.166561 ops/training.py:65 2019-01-16 11:02:19.166513: step 9357, loss = 0.56303 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:02:20.126931 ops/training.py:65 2019-01-16 11:02:20.126875: step 9358, loss = 0.63356 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:02:21.088739 ops/training.py:65 2019-01-16 11:02:21.088669: step 9359, loss = 0.60083 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:02:22.049357 ops/training.py:65 2019-01-16 11:02:22.049288: step 9360, loss = 0.60796 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:02:23.010965 ops/training.py:65 2019-01-16 11:02:23.010898: step 9361, loss = 0.60770 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:02:23.971564 ops/training.py:65 2019-01-16 11:02:23.971506: step 9362, loss = 0.67432 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:02:24.933294 ops/training.py:65 2019-01-16 11:02:24.933241: step 9363, loss = 0.60641 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:02:25.895049 ops/training.py:65 2019-01-16 11:02:25.894994: step 9364, loss = 0.57296 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:02:26.859142 ops/training.py:65 2019-01-16 11:02:26.859083: step 9365, loss = 0.71408 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:02:27.820711 ops/training.py:65 2019-01-16 11:02:27.820641: step 9366, loss = 0.73183 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:02:28.783572 ops/training.py:65 2019-01-16 11:02:28.783508: step 9367, loss = 0.65776 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:02:29.747221 ops/training.py:65 2019-01-16 11:02:29.747154: step 9368, loss = 0.57394 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:02:30.709424 ops/training.py:65 2019-01-16 11:02:30.709353: step 9369, loss = 0.59330 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:02:31.670913 ops/training.py:65 2019-01-16 11:02:31.670839: step 9370, loss = 0.59028 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:02:32.635694 ops/training.py:65 2019-01-16 11:02:32.635644: step 9371, loss = 0.59318 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:02:33.597653 ops/training.py:65 2019-01-16 11:02:33.597606: step 9372, loss = 0.64898 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:02:34.559223 ops/training.py:65 2019-01-16 11:02:34.559167: step 9373, loss = 0.56313 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:02:35.520473 ops/training.py:65 2019-01-16 11:02:35.520405: step 9374, loss = 0.58267 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:02:36.483953 ops/training.py:65 2019-01-16 11:02:36.483901: step 9375, loss = 0.65414 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:02:37.446731 ops/training.py:65 2019-01-16 11:02:37.446675: step 9376, loss = 0.60698 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:02:38.409326 ops/training.py:65 2019-01-16 11:02:38.409263: step 9377, loss = 0.62138 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:02:39.371781 ops/training.py:65 2019-01-16 11:02:39.371728: step 9378, loss = 0.69225 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:02:40.334240 ops/training.py:65 2019-01-16 11:02:40.334190: step 9379, loss = 0.57467 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:02:41.295487 ops/training.py:65 2019-01-16 11:02:41.295423: step 9380, loss = 0.63116 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:02:42.258495 ops/training.py:65 2019-01-16 11:02:42.258430: step 9381, loss = 0.60033 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:02:43.219149 ops/training.py:65 2019-01-16 11:02:43.219083: step 9382, loss = 0.60056 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:02:44.182937 ops/training.py:65 2019-01-16 11:02:44.182868: step 9383, loss = 0.67654 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:02:45.147320 ops/training.py:65 2019-01-16 11:02:45.147269: step 9384, loss = 0.64160 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:02:46.109016 ops/training.py:65 2019-01-16 11:02:46.108944: step 9385, loss = 0.72053 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:02:47.072034 ops/training.py:65 2019-01-16 11:02:47.071963: step 9386, loss = 0.68941 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:02:48.035620 ops/training.py:65 2019-01-16 11:02:48.035550: step 9387, loss = 0.50924 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:02:48.997616 ops/training.py:65 2019-01-16 11:02:48.997541: step 9388, loss = 0.61430 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:02:49.961301 ops/training.py:65 2019-01-16 11:02:49.961258: step 9389, loss = 0.59048 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:02:50.923786 ops/training.py:65 2019-01-16 11:02:50.923715: step 9390, loss = 0.62731 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:02:51.885577 ops/training.py:65 2019-01-16 11:02:51.885527: step 9391, loss = 0.69628 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:02:52.845713 ops/training.py:65 2019-01-16 11:02:52.845664: step 9392, loss = 0.72082 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:02:53.805903 ops/training.py:65 2019-01-16 11:02:53.805858: step 9393, loss = 0.66248 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:02:54.766351 ops/training.py:65 2019-01-16 11:02:54.766301: step 9394, loss = 0.68574 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:02:55.728238 ops/training.py:65 2019-01-16 11:02:55.728194: step 9395, loss = 0.66095 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:02:56.692430 ops/training.py:65 2019-01-16 11:02:56.692378: step 9396, loss = 0.65392 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:02:57.654497 ops/training.py:65 2019-01-16 11:02:57.654427: step 9397, loss = 0.60845 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:02:58.617131 ops/training.py:65 2019-01-16 11:02:58.617080: step 9398, loss = 0.69550 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:02:59.581458 ops/training.py:65 2019-01-16 11:02:59.581393: step 9399, loss = 0.59382 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:03:00.544040 ops/training.py:65 2019-01-16 11:03:00.543977: step 9400, loss = 0.61768 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:03:01.504538 ops/training.py:65 2019-01-16 11:03:01.504487: step 9401, loss = 0.65150 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:03:02.464503 ops/training.py:65 2019-01-16 11:03:02.464451: step 9402, loss = 0.69785 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:03:03.424753 ops/training.py:65 2019-01-16 11:03:03.424687: step 9403, loss = 0.68902 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:03:04.384526 ops/training.py:65 2019-01-16 11:03:04.384461: step 9404, loss = 0.69921 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:03:05.346846 ops/training.py:65 2019-01-16 11:03:05.346789: step 9405, loss = 0.66256 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:03:06.310246 ops/training.py:65 2019-01-16 11:03:06.310187: step 9406, loss = 0.59549 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:03:07.273469 ops/training.py:65 2019-01-16 11:03:07.273399: step 9407, loss = 0.71255 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:03:08.236947 ops/training.py:65 2019-01-16 11:03:08.236881: step 9408, loss = 0.62745 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:03:09.199850 ops/training.py:65 2019-01-16 11:03:09.199799: step 9409, loss = 0.54405 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:03:10.161785 ops/training.py:65 2019-01-16 11:03:10.161721: step 9410, loss = 0.73052 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:03:11.124793 ops/training.py:65 2019-01-16 11:03:11.124728: step 9411, loss = 0.68362 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:03:12.088931 ops/training.py:65 2019-01-16 11:03:12.088864: step 9412, loss = 0.69577 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:03:13.052362 ops/training.py:65 2019-01-16 11:03:13.052295: step 9413, loss = 0.66563 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:03:14.012944 ops/training.py:65 2019-01-16 11:03:14.012869: step 9414, loss = 0.61274 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:03:14.973059 ops/training.py:65 2019-01-16 11:03:14.972990: step 9415, loss = 0.70788 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:03:15.934248 ops/training.py:65 2019-01-16 11:03:15.934177: step 9416, loss = 0.54208 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:03:16.895716 ops/training.py:65 2019-01-16 11:03:16.895645: step 9417, loss = 0.55802 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:03:17.859559 ops/training.py:65 2019-01-16 11:03:17.859508: step 9418, loss = 0.67401 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:03:18.822732 ops/training.py:65 2019-01-16 11:03:18.822655: step 9419, loss = 0.61410 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:03:19.787233 ops/training.py:65 2019-01-16 11:03:19.787166: step 9420, loss = 0.65997 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:03:20.752462 ops/training.py:65 2019-01-16 11:03:20.752393: step 9421, loss = 0.64133 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:03:21.714032 ops/training.py:65 2019-01-16 11:03:21.713956: step 9422, loss = 0.76747 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 11:03:22.675119 ops/training.py:65 2019-01-16 11:03:22.675043: step 9423, loss = 0.68991 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:03:23.635982 ops/training.py:65 2019-01-16 11:03:23.635913: step 9424, loss = 0.53909 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:03:24.596081 ops/training.py:65 2019-01-16 11:03:24.596031: step 9425, loss = 0.70835 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:03:25.556609 ops/training.py:65 2019-01-16 11:03:25.556538: step 9426, loss = 0.65440 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:03:26.517486 ops/training.py:65 2019-01-16 11:03:26.517406: step 9427, loss = 0.58423 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:03:27.478441 ops/training.py:65 2019-01-16 11:03:27.478374: step 9428, loss = 0.70755 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:03:28.439900 ops/training.py:65 2019-01-16 11:03:28.439834: step 9429, loss = 0.71274 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:03:29.400763 ops/training.py:65 2019-01-16 11:03:29.400697: step 9430, loss = 0.64392 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:03:30.361971 ops/training.py:65 2019-01-16 11:03:30.361905: step 9431, loss = 0.67492 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:03:31.324140 ops/training.py:65 2019-01-16 11:03:31.324064: step 9432, loss = 0.62988 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:03:32.288462 ops/training.py:65 2019-01-16 11:03:32.288397: step 9433, loss = 0.64136 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:03:33.251894 ops/training.py:65 2019-01-16 11:03:33.251826: step 9434, loss = 0.63439 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:03:34.214031 ops/training.py:65 2019-01-16 11:03:34.213954: step 9435, loss = 0.52314 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:03:35.175650 ops/training.py:65 2019-01-16 11:03:35.175591: step 9436, loss = 0.68211 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:03:36.137124 ops/training.py:65 2019-01-16 11:03:36.137052: step 9437, loss = 0.64587 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:03:37.101297 ops/training.py:65 2019-01-16 11:03:37.101255: step 9438, loss = 0.63441 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:03:38.062277 ops/training.py:65 2019-01-16 11:03:38.062209: step 9439, loss = 0.61882 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:03:39.022606 ops/training.py:65 2019-01-16 11:03:39.022566: step 9440, loss = 0.58450 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:03:39.982224 ops/training.py:65 2019-01-16 11:03:39.982172: step 9441, loss = 0.52585 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:03:40.944878 ops/training.py:65 2019-01-16 11:03:40.944822: step 9442, loss = 0.63424 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:03:41.908530 ops/training.py:65 2019-01-16 11:03:41.908466: step 9443, loss = 0.66068 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:03:42.872494 ops/training.py:65 2019-01-16 11:03:42.872417: step 9444, loss = 0.54124 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:03:43.833954 ops/training.py:65 2019-01-16 11:03:43.833878: step 9445, loss = 0.52814 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:03:44.795687 ops/training.py:65 2019-01-16 11:03:44.795617: step 9446, loss = 0.63293 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:03:45.756097 ops/training.py:65 2019-01-16 11:03:45.756052: step 9447, loss = 0.59927 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:03:46.717875 ops/training.py:65 2019-01-16 11:03:46.717830: step 9448, loss = 0.67961 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:03:47.682591 ops/training.py:65 2019-01-16 11:03:47.682516: step 9449, loss = 0.66190 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:03:48.646927 ops/training.py:65 2019-01-16 11:03:48.646861: step 9450, loss = 0.64012 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:03:49.607914 ops/training.py:65 2019-01-16 11:03:49.607843: step 9451, loss = 0.61782 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:03:50.568649 ops/training.py:65 2019-01-16 11:03:50.568605: step 9452, loss = 0.63595 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:03:51.525984 ops/training.py:65 2019-01-16 11:03:51.525936: step 9453, loss = 0.59789 (33.5 examples/sec; 0.956 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:03:52.485385 ops/training.py:65 2019-01-16 11:03:52.485341: step 9454, loss = 0.59870 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:03:53.443140 ops/training.py:65 2019-01-16 11:03:53.443090: step 9455, loss = 0.61439 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:03:54.403908 ops/training.py:65 2019-01-16 11:03:54.403862: step 9456, loss = 0.58879 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:03:55.363180 ops/training.py:65 2019-01-16 11:03:55.363132: step 9457, loss = 0.68365 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:03:56.321805 ops/training.py:65 2019-01-16 11:03:56.321754: step 9458, loss = 0.53740 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:03:57.280460 ops/training.py:65 2019-01-16 11:03:57.280412: step 9459, loss = 0.55256 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:03:58.238395 ops/training.py:65 2019-01-16 11:03:58.238343: step 9460, loss = 0.57464 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:03:59.198462 ops/training.py:65 2019-01-16 11:03:59.198414: step 9461, loss = 0.60982 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:04:00.157533 ops/training.py:65 2019-01-16 11:04:00.157484: step 9462, loss = 0.67208 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:04:01.116154 ops/training.py:65 2019-01-16 11:04:01.116112: step 9463, loss = 0.65335 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:04:02.078223 ops/training.py:65 2019-01-16 11:04:02.078176: step 9464, loss = 0.73153 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:04:03.043247 ops/training.py:65 2019-01-16 11:04:03.043183: step 9465, loss = 0.61449 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:04:04.006888 ops/training.py:65 2019-01-16 11:04:04.006815: step 9466, loss = 0.75262 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:04:04.967399 ops/training.py:65 2019-01-16 11:04:04.967345: step 9467, loss = 0.64410 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:04:05.928833 ops/training.py:65 2019-01-16 11:04:05.928776: step 9468, loss = 0.66970 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:04:06.890075 ops/training.py:65 2019-01-16 11:04:06.890008: step 9469, loss = 0.64688 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:04:07.851287 ops/training.py:65 2019-01-16 11:04:07.851211: step 9470, loss = 0.67864 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:04:08.814734 ops/training.py:65 2019-01-16 11:04:08.814671: step 9471, loss = 0.60993 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:04:09.775785 ops/training.py:65 2019-01-16 11:04:09.775711: step 9472, loss = 0.67656 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:04:10.736376 ops/training.py:65 2019-01-16 11:04:10.736307: step 9473, loss = 0.55793 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:04:11.700165 ops/training.py:65 2019-01-16 11:04:11.700116: step 9474, loss = 0.72863 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:04:12.663632 ops/training.py:65 2019-01-16 11:04:12.663556: step 9475, loss = 0.70340 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:04:13.628709 ops/training.py:65 2019-01-16 11:04:13.628642: step 9476, loss = 0.67008 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:04:14.592022 ops/training.py:65 2019-01-16 11:04:14.591956: step 9477, loss = 0.58143 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:04:15.553037 ops/training.py:65 2019-01-16 11:04:15.552969: step 9478, loss = 0.58557 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:04:16.513302 ops/training.py:65 2019-01-16 11:04:16.513251: step 9479, loss = 0.54057 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:04:17.475091 ops/training.py:65 2019-01-16 11:04:17.475019: step 9480, loss = 0.67777 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:04:18.437017 ops/training.py:65 2019-01-16 11:04:18.436964: step 9481, loss = 0.68012 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:04:19.395070 ops/training.py:65 2019-01-16 11:04:19.395020: step 9482, loss = 0.62633 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:04:20.354924 ops/training.py:65 2019-01-16 11:04:20.354873: step 9483, loss = 0.69078 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:04:21.317800 ops/training.py:65 2019-01-16 11:04:21.317753: step 9484, loss = 0.54666 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:04:22.279688 ops/training.py:65 2019-01-16 11:04:22.279613: step 9485, loss = 0.62580 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:04:23.242346 ops/training.py:65 2019-01-16 11:04:23.242303: step 9486, loss = 0.56871 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:04:24.203889 ops/training.py:65 2019-01-16 11:04:24.203816: step 9487, loss = 0.61442 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:04:25.168516 ops/training.py:65 2019-01-16 11:04:25.168454: step 9488, loss = 0.63223 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:04:26.131018 ops/training.py:65 2019-01-16 11:04:26.130947: step 9489, loss = 0.57892 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:04:27.091847 ops/training.py:65 2019-01-16 11:04:27.091800: step 9490, loss = 0.64130 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:04:28.053098 ops/training.py:65 2019-01-16 11:04:28.053052: step 9491, loss = 0.71535 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:04:29.017026 ops/training.py:65 2019-01-16 11:04:29.016959: step 9492, loss = 0.60302 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:04:29.977644 ops/training.py:65 2019-01-16 11:04:29.977579: step 9493, loss = 0.57302 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:04:30.937786 ops/training.py:65 2019-01-16 11:04:30.937735: step 9494, loss = 0.62602 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:04:31.900527 ops/training.py:65 2019-01-16 11:04:31.900439: step 9495, loss = 0.57873 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:04:32.862417 ops/training.py:65 2019-01-16 11:04:32.862340: step 9496, loss = 0.65252 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:04:33.824155 ops/training.py:65 2019-01-16 11:04:33.824104: step 9497, loss = 0.61101 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:04:34.783677 ops/training.py:65 2019-01-16 11:04:34.783619: step 9498, loss = 0.65276 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:04:35.748220 ops/training.py:65 2019-01-16 11:04:35.748161: step 9499, loss = 0.63597 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:04:36.711862 ops/training.py:65 2019-01-16 11:04:36.711809: step 9500, loss = 0.59059 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:04:37.672643 ops/training.py:65 2019-01-16 11:04:37.672570: step 9501, loss = 0.63976 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:04:38.633626 ops/training.py:65 2019-01-16 11:04:38.633560: step 9502, loss = 0.52588 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:04:39.595446 ops/training.py:65 2019-01-16 11:04:39.595378: step 9503, loss = 0.65670 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:04:40.556463 ops/training.py:65 2019-01-16 11:04:40.556397: step 9504, loss = 0.60244 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:04:41.516650 ops/training.py:65 2019-01-16 11:04:41.516579: step 9505, loss = 0.60834 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:04:42.479687 ops/training.py:65 2019-01-16 11:04:42.479614: step 9506, loss = 0.59496 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:04:43.441033 ops/training.py:65 2019-01-16 11:04:43.440968: step 9507, loss = 0.55089 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:04:44.402108 ops/training.py:65 2019-01-16 11:04:44.402059: step 9508, loss = 0.56651 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:04:45.362578 ops/training.py:65 2019-01-16 11:04:45.362529: step 9509, loss = 0.70484 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:04:46.324505 ops/training.py:65 2019-01-16 11:04:46.324462: step 9510, loss = 0.71171 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:04:47.289120 ops/training.py:65 2019-01-16 11:04:47.289056: step 9511, loss = 0.88463 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 11:04:48.252750 ops/training.py:65 2019-01-16 11:04:48.252685: step 9512, loss = 0.65161 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:04:49.213784 ops/training.py:65 2019-01-16 11:04:49.213717: step 9513, loss = 0.66628 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:04:50.177757 ops/training.py:65 2019-01-16 11:04:50.177681: step 9514, loss = 0.66932 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:04:51.138985 ops/training.py:65 2019-01-16 11:04:51.138938: step 9515, loss = 0.58071 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:04:52.098982 ops/training.py:65 2019-01-16 11:04:52.098943: step 9516, loss = 0.76565 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:04:53.058196 ops/training.py:65 2019-01-16 11:04:53.058151: step 9517, loss = 0.65217 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:04:54.018946 ops/training.py:65 2019-01-16 11:04:54.018893: step 9518, loss = 0.71828 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:04:54.982054 ops/training.py:65 2019-01-16 11:04:54.982007: step 9519, loss = 0.52403 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:04:55.946887 ops/training.py:65 2019-01-16 11:04:55.946822: step 9520, loss = 0.67140 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:04:56.910502 ops/training.py:65 2019-01-16 11:04:56.910435: step 9521, loss = 0.54225 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:04:57.872296 ops/training.py:65 2019-01-16 11:04:57.872221: step 9522, loss = 0.57870 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:04:58.833929 ops/training.py:65 2019-01-16 11:04:58.833861: step 9523, loss = 0.70786 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:04:59.798725 ops/training.py:65 2019-01-16 11:04:59.798659: step 9524, loss = 0.58085 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:05:00.763469 ops/training.py:65 2019-01-16 11:05:00.763399: step 9525, loss = 0.65067 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:05:01.724072 ops/training.py:65 2019-01-16 11:05:01.724015: step 9526, loss = 0.56769 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:05:02.684520 ops/training.py:65 2019-01-16 11:05:02.684450: step 9527, loss = 0.59714 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:05:03.644739 ops/training.py:65 2019-01-16 11:05:03.644675: step 9528, loss = 0.57913 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:05:04.607094 ops/training.py:65 2019-01-16 11:05:04.607020: step 9529, loss = 0.57255 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:05:05.568660 ops/training.py:65 2019-01-16 11:05:05.568605: step 9530, loss = 0.60040 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:05:06.532184 ops/training.py:65 2019-01-16 11:05:06.532113: step 9531, loss = 0.68580 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:05:07.494133 ops/training.py:65 2019-01-16 11:05:07.494062: step 9532, loss = 0.50917 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:05:08.455615 ops/training.py:65 2019-01-16 11:05:08.455562: step 9533, loss = 0.72292 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 11:05:09.414707 ops/training.py:65 2019-01-16 11:05:09.414659: step 9534, loss = 0.72469 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 11:05:10.376833 ops/training.py:65 2019-01-16 11:05:10.376782: step 9535, loss = 0.67778 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:05:11.339330 ops/training.py:65 2019-01-16 11:05:11.339256: step 9536, loss = 0.84871 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 11:05:12.303352 ops/training.py:65 2019-01-16 11:05:12.303297: step 9537, loss = 0.63818 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:05:13.265817 ops/training.py:65 2019-01-16 11:05:13.265748: step 9538, loss = 0.64605 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:05:14.227991 ops/training.py:65 2019-01-16 11:05:14.227939: step 9539, loss = 0.65905 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:05:15.188860 ops/training.py:65 2019-01-16 11:05:15.188791: step 9540, loss = 0.72440 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:05:16.149179 ops/training.py:65 2019-01-16 11:05:16.149127: step 9541, loss = 0.64779 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:05:17.109762 ops/training.py:65 2019-01-16 11:05:17.109695: step 9542, loss = 0.66985 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:05:18.069931 ops/training.py:65 2019-01-16 11:05:18.069864: step 9543, loss = 0.69588 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:05:19.034721 ops/training.py:65 2019-01-16 11:05:19.034673: step 9544, loss = 0.70653 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:05:19.997725 ops/training.py:65 2019-01-16 11:05:19.997661: step 9545, loss = 0.63442 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:05:20.959477 ops/training.py:65 2019-01-16 11:05:20.959404: step 9546, loss = 0.53670 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:05:21.920910 ops/training.py:65 2019-01-16 11:05:21.920861: step 9547, loss = 0.58088 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:05:22.880590 ops/training.py:65 2019-01-16 11:05:22.880547: step 9548, loss = 0.61948 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:05:23.840927 ops/training.py:65 2019-01-16 11:05:23.840878: step 9549, loss = 0.57738 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:05:24.799962 ops/training.py:65 2019-01-16 11:05:24.799917: step 9550, loss = 0.62938 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:05:25.758908 ops/training.py:65 2019-01-16 11:05:25.758862: step 9551, loss = 0.65647 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:05:26.720010 ops/training.py:65 2019-01-16 11:05:26.719962: step 9552, loss = 0.74866 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 11:05:27.683544 ops/training.py:65 2019-01-16 11:05:27.683478: step 9553, loss = 0.64557 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:05:28.646681 ops/training.py:65 2019-01-16 11:05:28.646617: step 9554, loss = 0.54805 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:05:29.606334 ops/training.py:65 2019-01-16 11:05:29.606269: step 9555, loss = 0.72307 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:05:30.567253 ops/training.py:65 2019-01-16 11:05:30.567186: step 9556, loss = 0.71116 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:05:31.527310 ops/training.py:65 2019-01-16 11:05:31.527237: step 9557, loss = 0.63856 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:05:32.487897 ops/training.py:65 2019-01-16 11:05:32.487833: step 9558, loss = 0.61874 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:05:33.448441 ops/training.py:65 2019-01-16 11:05:33.448375: step 9559, loss = 0.64000 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:05:34.410922 ops/training.py:65 2019-01-16 11:05:34.410854: step 9560, loss = 0.67069 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:05:35.373853 ops/training.py:65 2019-01-16 11:05:35.373795: step 9561, loss = 0.71808 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:05:36.335519 ops/training.py:65 2019-01-16 11:05:36.335467: step 9562, loss = 0.69803 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:05:37.297807 ops/training.py:65 2019-01-16 11:05:37.297758: step 9563, loss = 0.64075 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:05:38.261460 ops/training.py:65 2019-01-16 11:05:38.261391: step 9564, loss = 0.65751 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:05:39.224388 ops/training.py:65 2019-01-16 11:05:39.224323: step 9565, loss = 0.65961 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:05:40.185006 ops/training.py:65 2019-01-16 11:05:40.184949: step 9566, loss = 0.61591 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:05:41.146567 ops/training.py:65 2019-01-16 11:05:41.146515: step 9567, loss = 0.61389 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:05:42.107208 ops/training.py:65 2019-01-16 11:05:42.107142: step 9568, loss = 0.62902 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:05:43.068876 ops/training.py:65 2019-01-16 11:05:43.068807: step 9569, loss = 0.74255 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 11:05:44.030480 ops/training.py:65 2019-01-16 11:05:44.030404: step 9570, loss = 0.65788 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:05:44.991526 ops/training.py:65 2019-01-16 11:05:44.991451: step 9571, loss = 0.55829 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:05:45.955962 ops/training.py:65 2019-01-16 11:05:45.955899: step 9572, loss = 0.61169 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:05:46.920083 ops/training.py:65 2019-01-16 11:05:46.920016: step 9573, loss = 0.65154 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:05:47.883848 ops/training.py:65 2019-01-16 11:05:47.883774: step 9574, loss = 0.69426 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:05:48.844435 ops/training.py:65 2019-01-16 11:05:48.844360: step 9575, loss = 0.57878 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:05:49.808762 ops/training.py:65 2019-01-16 11:05:49.808699: step 9576, loss = 0.72181 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:05:50.774908 ops/training.py:65 2019-01-16 11:05:50.774840: step 9577, loss = 0.60390 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:05:51.736826 ops/training.py:65 2019-01-16 11:05:51.736757: step 9578, loss = 0.64592 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:05:52.697612 ops/training.py:65 2019-01-16 11:05:52.697556: step 9579, loss = 0.58248 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:05:53.660539 ops/training.py:65 2019-01-16 11:05:53.660490: step 9580, loss = 0.73465 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:05:54.624580 ops/training.py:65 2019-01-16 11:05:54.624516: step 9581, loss = 0.61727 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:05:55.587592 ops/training.py:65 2019-01-16 11:05:55.587528: step 9582, loss = 0.72882 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:05:56.548873 ops/training.py:65 2019-01-16 11:05:56.548817: step 9583, loss = 0.70424 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:05:57.509578 ops/training.py:65 2019-01-16 11:05:57.509501: step 9584, loss = 0.75111 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:05:58.470294 ops/training.py:65 2019-01-16 11:05:58.470248: step 9585, loss = 0.54074 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:05:59.431687 ops/training.py:65 2019-01-16 11:05:59.431644: step 9586, loss = 0.63844 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:06:00.396716 ops/training.py:65 2019-01-16 11:06:00.396640: step 9587, loss = 0.73386 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:06:01.358963 ops/training.py:65 2019-01-16 11:06:01.358904: step 9588, loss = 0.58555 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:06:02.321072 ops/training.py:65 2019-01-16 11:06:02.321024: step 9589, loss = 0.57216 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:06:03.280450 ops/training.py:65 2019-01-16 11:06:03.280405: step 9590, loss = 0.74410 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:06:04.240214 ops/training.py:65 2019-01-16 11:06:04.240168: step 9591, loss = 0.65820 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:06:05.202784 ops/training.py:65 2019-01-16 11:06:05.202732: step 9592, loss = 0.71744 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:06:06.165669 ops/training.py:65 2019-01-16 11:06:06.165598: step 9593, loss = 0.65516 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:06:07.130892 ops/training.py:65 2019-01-16 11:06:07.130828: step 9594, loss = 0.70112 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:06:08.094006 ops/training.py:65 2019-01-16 11:06:08.093936: step 9595, loss = 0.69592 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:06:09.056324 ops/training.py:65 2019-01-16 11:06:09.056269: step 9596, loss = 0.54590 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:06:10.016427 ops/training.py:65 2019-01-16 11:06:10.016380: step 9597, loss = 0.67029 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:06:10.975049 ops/training.py:65 2019-01-16 11:06:10.975001: step 9598, loss = 0.58108 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:06:11.934377 ops/training.py:65 2019-01-16 11:06:11.934327: step 9599, loss = 0.59140 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:06:12.896072 ops/training.py:65 2019-01-16 11:06:12.896027: step 9600, loss = 0.69973 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:06:13.859598 ops/training.py:65 2019-01-16 11:06:13.859533: step 9601, loss = 0.58224 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:06:14.822992 ops/training.py:65 2019-01-16 11:06:14.822923: step 9602, loss = 0.61484 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:06:15.784483 ops/training.py:65 2019-01-16 11:06:15.784417: step 9603, loss = 0.56548 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:06:16.746008 ops/training.py:65 2019-01-16 11:06:16.745937: step 9604, loss = 0.61521 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:06:17.706958 ops/training.py:65 2019-01-16 11:06:17.706893: step 9605, loss = 0.62727 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:06:18.668839 ops/training.py:65 2019-01-16 11:06:18.668769: step 9606, loss = 0.58048 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:06:19.631435 ops/training.py:65 2019-01-16 11:06:19.631377: step 9607, loss = 0.66421 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:06:20.596993 ops/training.py:65 2019-01-16 11:06:20.596924: step 9608, loss = 0.68190 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:06:21.557827 ops/training.py:65 2019-01-16 11:06:21.557757: step 9609, loss = 0.61168 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:06:22.521251 ops/training.py:65 2019-01-16 11:06:22.521176: step 9610, loss = 0.70324 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:06:23.485185 ops/training.py:65 2019-01-16 11:06:23.485117: step 9611, loss = 0.61090 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:06:24.447030 ops/training.py:65 2019-01-16 11:06:24.446980: step 9612, loss = 0.63222 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:06:25.407351 ops/training.py:65 2019-01-16 11:06:25.407306: step 9613, loss = 0.67985 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:06:26.366272 ops/training.py:65 2019-01-16 11:06:26.366223: step 9614, loss = 0.65333 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:06:27.325028 ops/training.py:65 2019-01-16 11:06:27.324981: step 9615, loss = 0.60087 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:06:28.287196 ops/training.py:65 2019-01-16 11:06:28.287151: step 9616, loss = 0.64117 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:06:29.249819 ops/training.py:65 2019-01-16 11:06:29.249755: step 9617, loss = 0.72838 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:06:30.214485 ops/training.py:65 2019-01-16 11:06:30.214439: step 9618, loss = 0.71069 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:06:31.178226 ops/training.py:65 2019-01-16 11:06:31.178146: step 9619, loss = 0.66906 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:06:32.138412 ops/training.py:65 2019-01-16 11:06:32.138355: step 9620, loss = 0.80610 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:06:33.098907 ops/training.py:65 2019-01-16 11:06:33.098862: step 9621, loss = 0.62488 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:06:34.057403 ops/training.py:65 2019-01-16 11:06:34.057344: step 9622, loss = 0.68931 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:06:35.017901 ops/training.py:65 2019-01-16 11:06:35.017851: step 9623, loss = 0.64509 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:06:35.980977 ops/training.py:65 2019-01-16 11:06:35.980914: step 9624, loss = 0.65163 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:06:36.941806 ops/training.py:65 2019-01-16 11:06:36.941736: step 9625, loss = 0.60300 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:06:37.906002 ops/training.py:65 2019-01-16 11:06:37.905931: step 9626, loss = 0.64658 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:06:38.869151 ops/training.py:65 2019-01-16 11:06:38.869085: step 9627, loss = 0.69520 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:06:39.831374 ops/training.py:65 2019-01-16 11:06:39.831290: step 9628, loss = 0.64294 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:06:40.793044 ops/training.py:65 2019-01-16 11:06:40.792978: step 9629, loss = 0.60616 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:06:41.752901 ops/training.py:65 2019-01-16 11:06:41.752852: step 9630, loss = 0.63265 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:06:42.715936 ops/training.py:65 2019-01-16 11:06:42.715880: step 9631, loss = 0.63900 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:06:43.676754 ops/training.py:65 2019-01-16 11:06:43.676678: step 9632, loss = 0.66473 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:06:44.642490 ops/training.py:65 2019-01-16 11:06:44.642438: step 9633, loss = 0.67295 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:06:45.606332 ops/training.py:65 2019-01-16 11:06:45.606266: step 9634, loss = 0.63351 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:06:46.568834 ops/training.py:65 2019-01-16 11:06:46.568756: step 9635, loss = 0.64814 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:06:47.531613 ops/training.py:65 2019-01-16 11:06:47.531539: step 9636, loss = 0.54587 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:06:48.493711 ops/training.py:65 2019-01-16 11:06:48.493647: step 9637, loss = 0.62559 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:06:49.456507 ops/training.py:65 2019-01-16 11:06:49.456466: step 9638, loss = 0.55070 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:06:50.419803 ops/training.py:65 2019-01-16 11:06:50.419733: step 9639, loss = 0.71125 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:06:51.380617 ops/training.py:65 2019-01-16 11:06:51.380567: step 9640, loss = 0.59656 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:06:52.340997 ops/training.py:65 2019-01-16 11:06:52.340932: step 9641, loss = 0.63153 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:06:53.301574 ops/training.py:65 2019-01-16 11:06:53.301503: step 9642, loss = 0.62167 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:06:54.262670 ops/training.py:65 2019-01-16 11:06:54.262604: step 9643, loss = 0.60385 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:06:55.226791 ops/training.py:65 2019-01-16 11:06:55.226718: step 9644, loss = 0.62841 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:06:56.188831 ops/training.py:65 2019-01-16 11:06:56.188773: step 9645, loss = 0.68958 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:06:57.152921 ops/training.py:65 2019-01-16 11:06:57.152859: step 9646, loss = 0.56783 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:06:58.116466 ops/training.py:65 2019-01-16 11:06:58.116401: step 9647, loss = 0.61558 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:06:59.079799 ops/training.py:65 2019-01-16 11:06:59.079723: step 9648, loss = 0.63870 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:07:00.040735 ops/training.py:65 2019-01-16 11:07:00.040667: step 9649, loss = 0.68839 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:07:01.000368 ops/training.py:65 2019-01-16 11:07:01.000302: step 9650, loss = 0.51664 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:07:01.962309 ops/training.py:65 2019-01-16 11:07:01.962257: step 9651, loss = 0.58710 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:07:02.924318 ops/training.py:65 2019-01-16 11:07:02.924250: step 9652, loss = 0.57122 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:07:03.884704 ops/training.py:65 2019-01-16 11:07:03.884639: step 9653, loss = 0.63232 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:07:04.845766 ops/training.py:65 2019-01-16 11:07:04.845699: step 9654, loss = 0.69565 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:07:05.809122 ops/training.py:65 2019-01-16 11:07:05.809049: step 9655, loss = 0.85746 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 11:07:06.772865 ops/training.py:65 2019-01-16 11:07:06.772800: step 9656, loss = 0.71094 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:07:07.735949 ops/training.py:65 2019-01-16 11:07:07.735876: step 9657, loss = 0.53907 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:07:08.696905 ops/training.py:65 2019-01-16 11:07:08.696840: step 9658, loss = 0.56228 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:07:09.656925 ops/training.py:65 2019-01-16 11:07:09.656858: step 9659, loss = 0.59194 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:07:10.616667 ops/training.py:65 2019-01-16 11:07:10.616603: step 9660, loss = 0.65341 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:07:11.578104 ops/training.py:65 2019-01-16 11:07:11.578031: step 9661, loss = 0.71092 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:07:12.538714 ops/training.py:65 2019-01-16 11:07:12.538647: step 9662, loss = 0.68986 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:07:13.499811 ops/training.py:65 2019-01-16 11:07:13.499744: step 9663, loss = 0.76109 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:07:14.461404 ops/training.py:65 2019-01-16 11:07:14.461338: step 9664, loss = 0.62766 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:07:15.421617 ops/training.py:65 2019-01-16 11:07:15.421547: step 9665, loss = 0.68430 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:07:16.382154 ops/training.py:65 2019-01-16 11:07:16.382101: step 9666, loss = 0.58043 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:07:17.344863 ops/training.py:65 2019-01-16 11:07:17.344814: step 9667, loss = 0.64950 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:07:18.309839 ops/training.py:65 2019-01-16 11:07:18.309776: step 9668, loss = 0.56308 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:07:19.272847 ops/training.py:65 2019-01-16 11:07:19.272780: step 9669, loss = 0.61005 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:07:20.233303 ops/training.py:65 2019-01-16 11:07:20.233253: step 9670, loss = 0.56313 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:07:21.193301 ops/training.py:65 2019-01-16 11:07:21.193222: step 9671, loss = 0.55186 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:07:22.154359 ops/training.py:65 2019-01-16 11:07:22.154295: step 9672, loss = 0.63594 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:07:23.116485 ops/training.py:65 2019-01-16 11:07:23.116416: step 9673, loss = 0.56088 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:07:24.077862 ops/training.py:65 2019-01-16 11:07:24.077788: step 9674, loss = 0.67884 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:07:25.038917 ops/training.py:65 2019-01-16 11:07:25.038871: step 9675, loss = 0.56400 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:07:26.001360 ops/training.py:65 2019-01-16 11:07:26.001311: step 9676, loss = 0.65477 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:07:26.964449 ops/training.py:65 2019-01-16 11:07:26.964387: step 9677, loss = 0.67425 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:07:27.927191 ops/training.py:65 2019-01-16 11:07:27.927124: step 9678, loss = 0.54502 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:07:28.887282 ops/training.py:65 2019-01-16 11:07:28.887214: step 9679, loss = 0.64477 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:07:29.848037 ops/training.py:65 2019-01-16 11:07:29.847975: step 9680, loss = 0.60688 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:07:30.808495 ops/training.py:65 2019-01-16 11:07:30.808431: step 9681, loss = 0.72910 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:07:31.768989 ops/training.py:65 2019-01-16 11:07:31.768924: step 9682, loss = 0.54144 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:07:32.729207 ops/training.py:65 2019-01-16 11:07:32.729138: step 9683, loss = 0.62484 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:07:33.689661 ops/training.py:65 2019-01-16 11:07:33.689598: step 9684, loss = 0.67168 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:07:34.651335 ops/training.py:65 2019-01-16 11:07:34.651271: step 9685, loss = 0.60103 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:07:35.611865 ops/training.py:65 2019-01-16 11:07:35.611815: step 9686, loss = 0.65733 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:07:36.573100 ops/training.py:65 2019-01-16 11:07:36.573040: step 9687, loss = 0.55119 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:07:37.535417 ops/training.py:65 2019-01-16 11:07:37.535354: step 9688, loss = 0.63982 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:07:38.496643 ops/training.py:65 2019-01-16 11:07:38.496579: step 9689, loss = 0.66294 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:07:39.457148 ops/training.py:65 2019-01-16 11:07:39.457086: step 9690, loss = 0.54693 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:07:40.417559 ops/training.py:65 2019-01-16 11:07:40.417509: step 9691, loss = 0.59476 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:07:41.377752 ops/training.py:65 2019-01-16 11:07:41.377686: step 9692, loss = 0.69516 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:07:42.338133 ops/training.py:65 2019-01-16 11:07:42.338066: step 9693, loss = 0.58444 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:07:43.298706 ops/training.py:65 2019-01-16 11:07:43.298641: step 9694, loss = 0.74678 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:07:44.259849 ops/training.py:65 2019-01-16 11:07:44.259783: step 9695, loss = 0.62492 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:07:45.220865 ops/training.py:65 2019-01-16 11:07:45.220795: step 9696, loss = 0.57554 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:07:46.180935 ops/training.py:65 2019-01-16 11:07:46.180869: step 9697, loss = 0.71364 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:07:47.141673 ops/training.py:65 2019-01-16 11:07:47.141610: step 9698, loss = 0.67469 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:07:48.101376 ops/training.py:65 2019-01-16 11:07:48.101310: step 9699, loss = 0.63549 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:07:49.062983 ops/training.py:65 2019-01-16 11:07:49.062929: step 9700, loss = 0.61063 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:07:50.025517 ops/training.py:65 2019-01-16 11:07:50.025469: step 9701, loss = 0.57132 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:07:50.990163 ops/training.py:65 2019-01-16 11:07:50.990110: step 9702, loss = 0.70232 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:07:51.953549 ops/training.py:65 2019-01-16 11:07:51.953483: step 9703, loss = 0.67167 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:07:52.914518 ops/training.py:65 2019-01-16 11:07:52.914448: step 9704, loss = 0.64205 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:07:53.875683 ops/training.py:65 2019-01-16 11:07:53.875619: step 9705, loss = 0.70772 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:07:54.836155 ops/training.py:65 2019-01-16 11:07:54.836091: step 9706, loss = 0.58208 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:07:55.796610 ops/training.py:65 2019-01-16 11:07:55.796546: step 9707, loss = 0.66217 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:07:56.758188 ops/training.py:65 2019-01-16 11:07:56.758124: step 9708, loss = 0.63682 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:07:57.720331 ops/training.py:65 2019-01-16 11:07:57.720261: step 9709, loss = 0.69295 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:07:58.682702 ops/training.py:65 2019-01-16 11:07:58.682637: step 9710, loss = 0.57079 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:07:59.642959 ops/training.py:65 2019-01-16 11:07:59.642893: step 9711, loss = 0.66961 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:08:00.604032 ops/training.py:65 2019-01-16 11:08:00.603967: step 9712, loss = 0.61024 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:08:01.564275 ops/training.py:65 2019-01-16 11:08:01.564223: step 9713, loss = 0.71445 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:08:02.525943 ops/training.py:65 2019-01-16 11:08:02.525879: step 9714, loss = 0.68795 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:08:03.487047 ops/training.py:65 2019-01-16 11:08:03.486981: step 9715, loss = 0.69955 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:08:04.447575 ops/training.py:65 2019-01-16 11:08:04.447508: step 9716, loss = 0.56440 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:08:05.408007 ops/training.py:65 2019-01-16 11:08:05.407958: step 9717, loss = 0.63422 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:08:06.368285 ops/training.py:65 2019-01-16 11:08:06.368230: step 9718, loss = 0.62980 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:08:07.329047 ops/training.py:65 2019-01-16 11:08:07.328980: step 9719, loss = 0.68676 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:08:08.289801 ops/training.py:65 2019-01-16 11:08:08.289735: step 9720, loss = 0.68348 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:08:09.254384 ops/training.py:65 2019-01-16 11:08:09.254336: step 9721, loss = 0.55347 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 11:08:10.218253 ops/training.py:65 2019-01-16 11:08:10.218183: step 9722, loss = 0.60158 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:08:11.181183 ops/training.py:65 2019-01-16 11:08:11.181116: step 9723, loss = 0.62910 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:08:12.142558 ops/training.py:65 2019-01-16 11:08:12.142492: step 9724, loss = 0.61245 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:08:13.102373 ops/training.py:65 2019-01-16 11:08:13.102307: step 9725, loss = 0.62342 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:08:14.062246 ops/training.py:65 2019-01-16 11:08:14.062191: step 9726, loss = 0.64574 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:08:15.021230 ops/training.py:65 2019-01-16 11:08:15.021183: step 9727, loss = 0.54577 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:08:15.978713 ops/training.py:65 2019-01-16 11:08:15.978667: step 9728, loss = 0.70318 (33.5 examples/sec; 0.957 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:08:16.940944 ops/training.py:65 2019-01-16 11:08:16.940893: step 9729, loss = 0.57815 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:08:17.905184 ops/training.py:65 2019-01-16 11:08:17.905114: step 9730, loss = 0.55220 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:08:18.867615 ops/training.py:65 2019-01-16 11:08:18.867553: step 9731, loss = 0.69898 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:08:19.827741 ops/training.py:65 2019-01-16 11:08:19.827675: step 9732, loss = 0.66601 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:08:20.788494 ops/training.py:65 2019-01-16 11:08:20.788443: step 9733, loss = 0.60819 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:08:21.748543 ops/training.py:65 2019-01-16 11:08:21.748484: step 9734, loss = 0.53002 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:08:22.709069 ops/training.py:65 2019-01-16 11:08:22.709004: step 9735, loss = 0.56874 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:08:23.669310 ops/training.py:65 2019-01-16 11:08:23.669243: step 9736, loss = 0.65112 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:08:24.630553 ops/training.py:65 2019-01-16 11:08:24.630482: step 9737, loss = 0.69155 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:08:25.592377 ops/training.py:65 2019-01-16 11:08:25.592305: step 9738, loss = 0.59038 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:08:26.552750 ops/training.py:65 2019-01-16 11:08:26.552677: step 9739, loss = 0.70878 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:08:27.513309 ops/training.py:65 2019-01-16 11:08:27.513261: step 9740, loss = 0.67219 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:08:28.474959 ops/training.py:65 2019-01-16 11:08:28.474912: step 9741, loss = 0.77242 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:08:29.438657 ops/training.py:65 2019-01-16 11:08:29.438586: step 9742, loss = 0.61439 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:08:30.400393 ops/training.py:65 2019-01-16 11:08:30.400334: step 9743, loss = 0.66762 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:08:31.364528 ops/training.py:65 2019-01-16 11:08:31.364480: step 9744, loss = 0.58292 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:08:32.325840 ops/training.py:65 2019-01-16 11:08:32.325773: step 9745, loss = 0.61126 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:08:33.287284 ops/training.py:65 2019-01-16 11:08:33.287230: step 9746, loss = 0.61555 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:08:34.245385 ops/training.py:65 2019-01-16 11:08:34.245330: step 9747, loss = 0.67740 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:08:35.208373 ops/training.py:65 2019-01-16 11:08:35.208325: step 9748, loss = 0.71000 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:08:36.171440 ops/training.py:65 2019-01-16 11:08:36.171380: step 9749, loss = 0.72657 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:08:37.131333 ops/training.py:65 2019-01-16 11:08:37.131269: step 9750, loss = 0.52008 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:08:38.091375 ops/training.py:65 2019-01-16 11:08:38.091310: step 9751, loss = 0.60901 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:08:39.052453 ops/training.py:65 2019-01-16 11:08:39.052385: step 9752, loss = 0.65534 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:08:40.012509 ops/training.py:65 2019-01-16 11:08:40.012438: step 9753, loss = 0.62464 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:08:40.973802 ops/training.py:65 2019-01-16 11:08:40.973730: step 9754, loss = 0.62010 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:08:41.934456 ops/training.py:65 2019-01-16 11:08:41.934376: step 9755, loss = 0.72433 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:08:42.894479 ops/training.py:65 2019-01-16 11:08:42.894424: step 9756, loss = 0.64738 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:08:43.852962 ops/training.py:65 2019-01-16 11:08:43.852910: step 9757, loss = 0.59338 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:08:44.811942 ops/training.py:65 2019-01-16 11:08:44.811896: step 9758, loss = 0.56866 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:08:45.770039 ops/training.py:65 2019-01-16 11:08:45.769993: step 9759, loss = 0.51175 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:08:46.732103 ops/training.py:65 2019-01-16 11:08:46.732058: step 9760, loss = 0.57557 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:08:47.694046 ops/training.py:65 2019-01-16 11:08:47.693976: step 9761, loss = 0.62609 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:08:48.655003 ops/training.py:65 2019-01-16 11:08:48.654960: step 9762, loss = 0.63139 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:08:49.617133 ops/training.py:65 2019-01-16 11:08:49.617077: step 9763, loss = 0.59683 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:08:50.582207 ops/training.py:65 2019-01-16 11:08:50.582154: step 9764, loss = 0.58335 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:08:51.544650 ops/training.py:65 2019-01-16 11:08:51.544578: step 9765, loss = 0.64468 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:08:52.505920 ops/training.py:65 2019-01-16 11:08:52.505853: step 9766, loss = 0.63702 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:08:53.467990 ops/training.py:65 2019-01-16 11:08:53.467939: step 9767, loss = 0.64286 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:08:54.426855 ops/training.py:65 2019-01-16 11:08:54.426812: step 9768, loss = 0.71784 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:08:55.389207 ops/training.py:65 2019-01-16 11:08:55.389154: step 9769, loss = 0.62649 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:08:56.352823 ops/training.py:65 2019-01-16 11:08:56.352757: step 9770, loss = 0.66421 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:08:57.314813 ops/training.py:65 2019-01-16 11:08:57.314750: step 9771, loss = 0.60801 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:08:58.274857 ops/training.py:65 2019-01-16 11:08:58.274784: step 9772, loss = 0.64348 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:08:59.235532 ops/training.py:65 2019-01-16 11:08:59.235489: step 9773, loss = 0.65615 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:09:00.193588 ops/training.py:65 2019-01-16 11:09:00.193539: step 9774, loss = 0.63581 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:09:01.151472 ops/training.py:65 2019-01-16 11:09:01.151428: step 9775, loss = 0.58118 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:09:02.108942 ops/training.py:65 2019-01-16 11:09:02.108901: step 9776, loss = 0.55936 (33.5 examples/sec; 0.957 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:09:03.066720 ops/training.py:65 2019-01-16 11:09:03.066674: step 9777, loss = 0.67131 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:09:04.028754 ops/training.py:65 2019-01-16 11:09:04.028704: step 9778, loss = 0.72386 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 11:09:04.989870 ops/training.py:65 2019-01-16 11:09:04.989814: step 9779, loss = 0.64233 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:09:05.952342 ops/training.py:65 2019-01-16 11:09:05.952275: step 9780, loss = 0.60393 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:09:06.918156 ops/training.py:65 2019-01-16 11:09:06.918094: step 9781, loss = 0.54494 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:09:07.883854 ops/training.py:65 2019-01-16 11:09:07.883782: step 9782, loss = 0.63577 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:09:08.847160 ops/training.py:65 2019-01-16 11:09:08.847098: step 9783, loss = 0.56583 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:09:09.807546 ops/training.py:65 2019-01-16 11:09:09.807481: step 9784, loss = 0.60912 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:09:10.768759 ops/training.py:65 2019-01-16 11:09:10.768693: step 9785, loss = 0.76136 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:09:11.729269 ops/training.py:65 2019-01-16 11:09:11.729208: step 9786, loss = 0.60008 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:09:12.689203 ops/training.py:65 2019-01-16 11:09:12.689129: step 9787, loss = 0.55104 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:09:13.649274 ops/training.py:65 2019-01-16 11:09:13.649224: step 9788, loss = 0.67113 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:09:14.607441 ops/training.py:65 2019-01-16 11:09:14.607394: step 9789, loss = 0.65740 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:09:15.565910 ops/training.py:65 2019-01-16 11:09:15.565862: step 9790, loss = 0.64044 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:09:16.528086 ops/training.py:65 2019-01-16 11:09:16.528037: step 9791, loss = 0.51965 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:09:17.491909 ops/training.py:65 2019-01-16 11:09:17.491843: step 9792, loss = 0.61955 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:09:18.454398 ops/training.py:65 2019-01-16 11:09:18.454335: step 9793, loss = 0.54428 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:09:19.414817 ops/training.py:65 2019-01-16 11:09:19.414752: step 9794, loss = 0.58327 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:09:20.375373 ops/training.py:65 2019-01-16 11:09:20.375321: step 9795, loss = 0.66102 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:09:21.336415 ops/training.py:65 2019-01-16 11:09:21.336349: step 9796, loss = 0.59031 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:09:22.296797 ops/training.py:65 2019-01-16 11:09:22.296733: step 9797, loss = 0.71125 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:09:23.256708 ops/training.py:65 2019-01-16 11:09:23.256640: step 9798, loss = 0.83087 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 11:09:24.217770 ops/training.py:65 2019-01-16 11:09:24.217699: step 9799, loss = 0.77133 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 11:09:25.178180 ops/training.py:65 2019-01-16 11:09:25.178109: step 9800, loss = 0.63286 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:09:26.140554 ops/training.py:65 2019-01-16 11:09:26.140480: step 9801, loss = 0.57935 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:09:27.103403 ops/training.py:65 2019-01-16 11:09:27.103339: step 9802, loss = 0.55398 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:09:28.067192 ops/training.py:65 2019-01-16 11:09:28.067125: step 9803, loss = 0.65702 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:09:29.030407 ops/training.py:65 2019-01-16 11:09:29.030318: step 9804, loss = 0.63418 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:09:29.990969 ops/training.py:65 2019-01-16 11:09:29.990894: step 9805, loss = 0.58642 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:09:30.951237 ops/training.py:65 2019-01-16 11:09:30.951155: step 9806, loss = 0.65301 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:09:31.913316 ops/training.py:65 2019-01-16 11:09:31.913235: step 9807, loss = 0.67555 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:09:32.875627 ops/training.py:65 2019-01-16 11:09:32.875557: step 9808, loss = 0.57529 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:09:33.836854 ops/training.py:65 2019-01-16 11:09:33.836784: step 9809, loss = 0.57548 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:09:34.798290 ops/training.py:65 2019-01-16 11:09:34.798227: step 9810, loss = 0.59745 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:09:35.758628 ops/training.py:65 2019-01-16 11:09:35.758566: step 9811, loss = 0.66027 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:09:36.719678 ops/training.py:65 2019-01-16 11:09:36.719609: step 9812, loss = 0.54351 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:09:37.680291 ops/training.py:65 2019-01-16 11:09:37.680240: step 9813, loss = 0.64254 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:09:38.642702 ops/training.py:65 2019-01-16 11:09:38.642653: step 9814, loss = 0.66929 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:09:39.606336 ops/training.py:65 2019-01-16 11:09:39.606272: step 9815, loss = 0.60391 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:09:40.569396 ops/training.py:65 2019-01-16 11:09:40.569343: step 9816, loss = 0.72944 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:09:41.530506 ops/training.py:65 2019-01-16 11:09:41.530434: step 9817, loss = 0.52464 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:09:42.491262 ops/training.py:65 2019-01-16 11:09:42.491195: step 9818, loss = 0.57640 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:09:43.452742 ops/training.py:65 2019-01-16 11:09:43.452679: step 9819, loss = 0.50730 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:09:44.413958 ops/training.py:65 2019-01-16 11:09:44.413893: step 9820, loss = 0.57019 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:09:45.374986 ops/training.py:65 2019-01-16 11:09:45.374922: step 9821, loss = 0.65647 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:09:46.335633 ops/training.py:65 2019-01-16 11:09:46.335569: step 9822, loss = 0.57797 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:09:47.297475 ops/training.py:65 2019-01-16 11:09:47.297408: step 9823, loss = 0.51986 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:09:48.260011 ops/training.py:65 2019-01-16 11:09:48.259935: step 9824, loss = 0.62110 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:09:49.221201 ops/training.py:65 2019-01-16 11:09:49.221134: step 9825, loss = 0.64486 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:09:50.182425 ops/training.py:65 2019-01-16 11:09:50.182352: step 9826, loss = 0.62624 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:09:51.147809 ops/training.py:65 2019-01-16 11:09:51.147746: step 9827, loss = 0.58237 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:09:52.111956 ops/training.py:65 2019-01-16 11:09:52.111890: step 9828, loss = 0.57839 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:09:53.075548 ops/training.py:65 2019-01-16 11:09:53.075482: step 9829, loss = 0.69695 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:09:54.036999 ops/training.py:65 2019-01-16 11:09:54.036928: step 9830, loss = 0.69242 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:09:54.996889 ops/training.py:65 2019-01-16 11:09:54.996823: step 9831, loss = 0.56995 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:09:55.958715 ops/training.py:65 2019-01-16 11:09:55.958647: step 9832, loss = 0.69274 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:09:56.921044 ops/training.py:65 2019-01-16 11:09:56.920980: step 9833, loss = 0.54374 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:09:57.882640 ops/training.py:65 2019-01-16 11:09:57.882569: step 9834, loss = 0.67575 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:09:58.844096 ops/training.py:65 2019-01-16 11:09:58.844032: step 9835, loss = 0.63738 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:09:59.805737 ops/training.py:65 2019-01-16 11:09:59.805665: step 9836, loss = 0.54400 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:10:00.766420 ops/training.py:65 2019-01-16 11:10:00.766369: step 9837, loss = 0.63110 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:10:01.729806 ops/training.py:65 2019-01-16 11:10:01.729759: step 9838, loss = 0.58419 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:10:02.695130 ops/training.py:65 2019-01-16 11:10:02.695067: step 9839, loss = 0.58328 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:10:03.659196 ops/training.py:65 2019-01-16 11:10:03.659128: step 9840, loss = 0.63926 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:10:04.621226 ops/training.py:65 2019-01-16 11:10:04.621143: step 9841, loss = 0.54047 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:10:05.583202 ops/training.py:65 2019-01-16 11:10:05.583146: step 9842, loss = 0.68130 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:10:06.544454 ops/training.py:65 2019-01-16 11:10:06.544393: step 9843, loss = 0.56144 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:10:07.505596 ops/training.py:65 2019-01-16 11:10:07.505519: step 9844, loss = 0.67577 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:10:08.470165 ops/training.py:65 2019-01-16 11:10:08.470115: step 9845, loss = 0.76674 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:10:09.433608 ops/training.py:65 2019-01-16 11:10:09.433543: step 9846, loss = 0.74149 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 11:10:10.395830 ops/training.py:65 2019-01-16 11:10:10.395756: step 9847, loss = 0.60877 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:10:11.357665 ops/training.py:65 2019-01-16 11:10:11.357595: step 9848, loss = 0.66269 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:10:12.319038 ops/training.py:65 2019-01-16 11:10:12.318955: step 9849, loss = 0.75341 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 11:10:13.279849 ops/training.py:65 2019-01-16 11:10:13.279780: step 9850, loss = 0.61774 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:10:14.239849 ops/training.py:65 2019-01-16 11:10:14.239763: step 9851, loss = 0.44475 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:10:15.200066 ops/training.py:65 2019-01-16 11:10:15.199994: step 9852, loss = 0.57832 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:10:16.160235 ops/training.py:65 2019-01-16 11:10:16.160166: step 9853, loss = 0.67279 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:10:17.120623 ops/training.py:65 2019-01-16 11:10:17.120556: step 9854, loss = 0.60172 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:10:18.082511 ops/training.py:65 2019-01-16 11:10:18.082422: step 9855, loss = 0.50988 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:10:19.043509 ops/training.py:65 2019-01-16 11:10:19.043432: step 9856, loss = 0.74687 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:10:20.007715 ops/training.py:65 2019-01-16 11:10:20.007649: step 9857, loss = 0.65192 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:10:20.971114 ops/training.py:65 2019-01-16 11:10:20.971058: step 9858, loss = 0.64290 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:10:21.931358 ops/training.py:65 2019-01-16 11:10:21.931291: step 9859, loss = 0.64461 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:10:22.891997 ops/training.py:65 2019-01-16 11:10:22.891927: step 9860, loss = 0.51540 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:10:23.852529 ops/training.py:65 2019-01-16 11:10:23.852460: step 9861, loss = 0.64148 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:10:24.813309 ops/training.py:65 2019-01-16 11:10:24.813240: step 9862, loss = 0.52917 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:10:25.773903 ops/training.py:65 2019-01-16 11:10:25.773834: step 9863, loss = 0.50783 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:10:26.735008 ops/training.py:65 2019-01-16 11:10:26.734938: step 9864, loss = 0.67164 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:10:27.696040 ops/training.py:65 2019-01-16 11:10:27.695967: step 9865, loss = 0.60263 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:10:28.657965 ops/training.py:65 2019-01-16 11:10:28.657897: step 9866, loss = 0.61546 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:10:29.619398 ops/training.py:65 2019-01-16 11:10:29.619321: step 9867, loss = 0.62657 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:10:30.581668 ops/training.py:65 2019-01-16 11:10:30.581599: step 9868, loss = 0.67083 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:10:31.545111 ops/training.py:65 2019-01-16 11:10:31.545063: step 9869, loss = 0.72040 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:10:32.510136 ops/training.py:65 2019-01-16 11:10:32.510068: step 9870, loss = 0.76284 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.3125
I0832 2019-01-16 11:10:33.473150 ops/training.py:65 2019-01-16 11:10:33.473080: step 9871, loss = 0.67222 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:10:34.433142 ops/training.py:65 2019-01-16 11:10:34.433076: step 9872, loss = 0.58357 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:10:35.392918 ops/training.py:65 2019-01-16 11:10:35.392865: step 9873, loss = 0.64952 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:10:36.353862 ops/training.py:65 2019-01-16 11:10:36.353806: step 9874, loss = 0.67188 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:10:37.315590 ops/training.py:65 2019-01-16 11:10:37.315530: step 9875, loss = 0.57003 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:10:38.276319 ops/training.py:65 2019-01-16 11:10:38.276233: step 9876, loss = 0.63471 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:10:39.237735 ops/training.py:65 2019-01-16 11:10:39.237665: step 9877, loss = 0.57529 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:10:40.202972 ops/training.py:65 2019-01-16 11:10:40.202899: step 9878, loss = 0.55653 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:10:41.166876 ops/training.py:65 2019-01-16 11:10:41.166808: step 9879, loss = 0.64520 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:10:42.128079 ops/training.py:65 2019-01-16 11:10:42.128013: step 9880, loss = 0.60216 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:10:43.089336 ops/training.py:65 2019-01-16 11:10:43.089267: step 9881, loss = 0.53786 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:10:44.049968 ops/training.py:65 2019-01-16 11:10:44.049893: step 9882, loss = 0.58824 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:10:45.011476 ops/training.py:65 2019-01-16 11:10:45.011407: step 9883, loss = 0.72615 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:10:45.972539 ops/training.py:65 2019-01-16 11:10:45.972471: step 9884, loss = 0.66199 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:10:46.933389 ops/training.py:65 2019-01-16 11:10:46.933321: step 9885, loss = 0.51464 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:10:47.895109 ops/training.py:65 2019-01-16 11:10:47.895031: step 9886, loss = 0.68491 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:10:48.856106 ops/training.py:65 2019-01-16 11:10:48.856040: step 9887, loss = 0.71976 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:10:49.817001 ops/training.py:65 2019-01-16 11:10:49.816937: step 9888, loss = 0.73639 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:10:50.777630 ops/training.py:65 2019-01-16 11:10:50.777578: step 9889, loss = 0.51208 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:10:51.738009 ops/training.py:65 2019-01-16 11:10:51.737938: step 9890, loss = 0.76050 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:10:52.702566 ops/training.py:65 2019-01-16 11:10:52.702491: step 9891, loss = 0.62892 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:10:53.666623 ops/training.py:65 2019-01-16 11:10:53.666556: step 9892, loss = 0.69384 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:10:54.626788 ops/training.py:65 2019-01-16 11:10:54.626716: step 9893, loss = 0.72260 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:10:55.590706 ops/training.py:65 2019-01-16 11:10:55.590658: step 9894, loss = 0.65525 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:10:56.556078 ops/training.py:65 2019-01-16 11:10:56.556008: step 9895, loss = 0.63034 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:10:57.519820 ops/training.py:65 2019-01-16 11:10:57.519750: step 9896, loss = 0.64384 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:10:58.481894 ops/training.py:65 2019-01-16 11:10:58.481824: step 9897, loss = 0.66990 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:10:59.442069 ops/training.py:65 2019-01-16 11:10:59.441999: step 9898, loss = 0.71368 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:11:00.402768 ops/training.py:65 2019-01-16 11:11:00.402691: step 9899, loss = 0.68421 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:11:01.362632 ops/training.py:65 2019-01-16 11:11:01.362563: step 9900, loss = 0.70142 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:11:02.323957 ops/training.py:65 2019-01-16 11:11:02.323879: step 9901, loss = 0.79659 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 11:11:03.288659 ops/training.py:65 2019-01-16 11:11:03.288592: step 9902, loss = 0.62929 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:11:04.253776 ops/training.py:65 2019-01-16 11:11:04.253707: step 9903, loss = 0.66693 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:11:05.214994 ops/training.py:65 2019-01-16 11:11:05.214936: step 9904, loss = 0.70221 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:11:06.177393 ops/training.py:65 2019-01-16 11:11:06.177316: step 9905, loss = 0.52851 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:11:07.142763 ops/training.py:65 2019-01-16 11:11:07.142697: step 9906, loss = 0.63952 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:11:08.108097 ops/training.py:65 2019-01-16 11:11:08.108030: step 9907, loss = 0.70148 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:11:09.071211 ops/training.py:65 2019-01-16 11:11:09.071139: step 9908, loss = 0.68921 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:11:10.032457 ops/training.py:65 2019-01-16 11:11:10.032389: step 9909, loss = 0.61158 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:11:10.994654 ops/training.py:65 2019-01-16 11:11:10.994584: step 9910, loss = 0.58514 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:11:11.957526 ops/training.py:65 2019-01-16 11:11:11.957455: step 9911, loss = 0.58900 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:11:12.918754 ops/training.py:65 2019-01-16 11:11:12.918674: step 9912, loss = 0.64780 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:11:13.880639 ops/training.py:65 2019-01-16 11:11:13.880579: step 9913, loss = 0.64845 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:11:14.840430 ops/training.py:65 2019-01-16 11:11:14.840378: step 9914, loss = 0.69670 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:11:15.800104 ops/training.py:65 2019-01-16 11:11:15.800055: step 9915, loss = 0.66988 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:11:16.758377 ops/training.py:65 2019-01-16 11:11:16.758333: step 9916, loss = 0.59963 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:11:17.717250 ops/training.py:65 2019-01-16 11:11:17.717204: step 9917, loss = 0.62499 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:11:18.679836 ops/training.py:65 2019-01-16 11:11:18.679787: step 9918, loss = 0.57539 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:11:19.642727 ops/training.py:65 2019-01-16 11:11:19.642661: step 9919, loss = 0.56894 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:11:20.605304 ops/training.py:65 2019-01-16 11:11:20.605255: step 9920, loss = 0.63312 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:11:21.565635 ops/training.py:65 2019-01-16 11:11:21.565562: step 9921, loss = 0.56822 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:11:22.529808 ops/training.py:65 2019-01-16 11:11:22.529757: step 9922, loss = 0.69484 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:11:23.493083 ops/training.py:65 2019-01-16 11:11:23.493017: step 9923, loss = 0.64047 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:11:24.455339 ops/training.py:65 2019-01-16 11:11:24.455273: step 9924, loss = 0.64831 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:11:25.415968 ops/training.py:65 2019-01-16 11:11:25.415894: step 9925, loss = 0.63525 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:11:26.376243 ops/training.py:65 2019-01-16 11:11:26.376175: step 9926, loss = 0.62060 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:11:27.336318 ops/training.py:65 2019-01-16 11:11:27.336254: step 9927, loss = 0.60280 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:11:28.296429 ops/training.py:65 2019-01-16 11:11:28.296360: step 9928, loss = 0.64986 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:11:29.256826 ops/training.py:65 2019-01-16 11:11:29.256760: step 9929, loss = 0.65380 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:11:30.217778 ops/training.py:65 2019-01-16 11:11:30.217712: step 9930, loss = 0.67285 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:11:31.178491 ops/training.py:65 2019-01-16 11:11:31.178425: step 9931, loss = 0.59681 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:11:32.140411 ops/training.py:65 2019-01-16 11:11:32.140343: step 9932, loss = 0.65907 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:11:33.101236 ops/training.py:65 2019-01-16 11:11:33.101168: step 9933, loss = 0.63382 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:11:34.063435 ops/training.py:65 2019-01-16 11:11:34.063343: step 9934, loss = 0.53237 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:11:35.025154 ops/training.py:65 2019-01-16 11:11:35.025081: step 9935, loss = 0.51715 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:11:35.987371 ops/training.py:65 2019-01-16 11:11:35.987311: step 9936, loss = 0.59911 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:11:36.948610 ops/training.py:65 2019-01-16 11:11:36.948544: step 9937, loss = 0.66679 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:11:37.909344 ops/training.py:65 2019-01-16 11:11:37.909296: step 9938, loss = 0.59647 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:11:38.867518 ops/training.py:65 2019-01-16 11:11:38.867472: step 9939, loss = 0.56732 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:11:39.826987 ops/training.py:65 2019-01-16 11:11:39.826937: step 9940, loss = 0.60548 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:11:40.785788 ops/training.py:65 2019-01-16 11:11:40.785742: step 9941, loss = 0.52886 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:11:41.744733 ops/training.py:65 2019-01-16 11:11:41.744687: step 9942, loss = 0.61045 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:11:42.706988 ops/training.py:65 2019-01-16 11:11:42.706943: step 9943, loss = 0.71887 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:11:43.670008 ops/training.py:65 2019-01-16 11:11:43.669936: step 9944, loss = 0.64016 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:11:44.633413 ops/training.py:65 2019-01-16 11:11:44.633342: step 9945, loss = 0.66558 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:11:45.594153 ops/training.py:65 2019-01-16 11:11:45.594086: step 9946, loss = 0.59394 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:11:46.554633 ops/training.py:65 2019-01-16 11:11:46.554586: step 9947, loss = 0.53275 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:11:47.518079 ops/training.py:65 2019-01-16 11:11:47.518031: step 9948, loss = 0.57692 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:11:48.483315 ops/training.py:65 2019-01-16 11:11:48.483251: step 9949, loss = 0.64021 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:11:49.447135 ops/training.py:65 2019-01-16 11:11:49.447071: step 9950, loss = 0.60839 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:11:50.408437 ops/training.py:65 2019-01-16 11:11:50.408384: step 9951, loss = 0.74262 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:11:51.369771 ops/training.py:65 2019-01-16 11:11:51.369702: step 9952, loss = 0.67920 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:11:52.329525 ops/training.py:65 2019-01-16 11:11:52.329460: step 9953, loss = 0.68265 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:11:53.290868 ops/training.py:65 2019-01-16 11:11:53.290798: step 9954, loss = 0.48953 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:11:54.253546 ops/training.py:65 2019-01-16 11:11:54.253477: step 9955, loss = 0.53270 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:11:55.219107 ops/training.py:65 2019-01-16 11:11:55.219056: step 9956, loss = 0.63502 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:11:56.183315 ops/training.py:65 2019-01-16 11:11:56.183243: step 9957, loss = 0.62950 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:11:57.145479 ops/training.py:65 2019-01-16 11:11:57.145424: step 9958, loss = 0.59654 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:11:58.111105 ops/training.py:65 2019-01-16 11:11:58.111056: step 9959, loss = 0.62163 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:11:59.075159 ops/training.py:65 2019-01-16 11:11:59.075069: step 9960, loss = 0.75730 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:12:00.037539 ops/training.py:65 2019-01-16 11:12:00.037473: step 9961, loss = 0.62391 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:12:00.999021 ops/training.py:65 2019-01-16 11:12:00.998950: step 9962, loss = 0.67466 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:12:01.963234 ops/training.py:65 2019-01-16 11:12:01.963188: step 9963, loss = 0.61507 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:12:02.927709 ops/training.py:65 2019-01-16 11:12:02.927637: step 9964, loss = 0.71054 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:12:03.888513 ops/training.py:65 2019-01-16 11:12:03.888462: step 9965, loss = 0.54153 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:12:04.849916 ops/training.py:65 2019-01-16 11:12:04.849832: step 9966, loss = 0.55105 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:12:05.810771 ops/training.py:65 2019-01-16 11:12:05.810709: step 9967, loss = 0.79550 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:12:06.774943 ops/training.py:65 2019-01-16 11:12:06.774883: step 9968, loss = 0.73222 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:12:07.738907 ops/training.py:65 2019-01-16 11:12:07.738840: step 9969, loss = 0.63594 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:12:08.701435 ops/training.py:65 2019-01-16 11:12:08.701379: step 9970, loss = 0.62860 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:12:09.662940 ops/training.py:65 2019-01-16 11:12:09.662889: step 9971, loss = 0.61606 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:12:10.623410 ops/training.py:65 2019-01-16 11:12:10.623361: step 9972, loss = 0.69750 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:12:11.583007 ops/training.py:65 2019-01-16 11:12:11.582964: step 9973, loss = 0.63749 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:12:12.542656 ops/training.py:65 2019-01-16 11:12:12.542612: step 9974, loss = 0.54829 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:12:13.506209 ops/training.py:65 2019-01-16 11:12:13.506168: step 9975, loss = 0.66144 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:12:14.472522 ops/training.py:65 2019-01-16 11:12:14.472470: step 9976, loss = 0.73093 (33.1 examples/sec; 0.965 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:12:15.435617 ops/training.py:65 2019-01-16 11:12:15.435566: step 9977, loss = 0.66522 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:12:16.396993 ops/training.py:65 2019-01-16 11:12:16.396902: step 9978, loss = 0.72057 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:12:17.357229 ops/training.py:65 2019-01-16 11:12:17.357160: step 9979, loss = 0.68864 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:12:18.321353 ops/training.py:65 2019-01-16 11:12:18.321313: step 9980, loss = 0.65850 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:12:19.285108 ops/training.py:65 2019-01-16 11:12:19.285048: step 9981, loss = 0.65924 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:12:20.246354 ops/training.py:65 2019-01-16 11:12:20.246278: step 9982, loss = 0.63922 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:12:21.209021 ops/training.py:65 2019-01-16 11:12:21.208975: step 9983, loss = 0.63279 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:12:22.168229 ops/training.py:65 2019-01-16 11:12:22.168183: step 9984, loss = 0.70562 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:12:23.127931 ops/training.py:65 2019-01-16 11:12:23.127886: step 9985, loss = 0.66870 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:12:24.089900 ops/training.py:65 2019-01-16 11:12:24.089852: step 9986, loss = 0.61419 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:12:25.053431 ops/training.py:65 2019-01-16 11:12:25.053368: step 9987, loss = 0.63365 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:12:26.016205 ops/training.py:65 2019-01-16 11:12:26.016141: step 9988, loss = 0.69307 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:12:26.976616 ops/training.py:65 2019-01-16 11:12:26.976555: step 9989, loss = 0.53500 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:12:27.938174 ops/training.py:65 2019-01-16 11:12:27.938100: step 9990, loss = 0.65052 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:12:28.898667 ops/training.py:65 2019-01-16 11:12:28.898597: step 9991, loss = 0.59452 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:12:29.859464 ops/training.py:65 2019-01-16 11:12:29.859401: step 9992, loss = 0.63458 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:12:30.820053 ops/training.py:65 2019-01-16 11:12:30.819987: step 9993, loss = 0.68056 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:12:31.780743 ops/training.py:65 2019-01-16 11:12:31.780672: step 9994, loss = 0.63227 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:12:32.741600 ops/training.py:65 2019-01-16 11:12:32.741523: step 9995, loss = 0.64755 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:12:33.703003 ops/training.py:65 2019-01-16 11:12:33.702949: step 9996, loss = 0.64243 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:12:34.661669 ops/training.py:65 2019-01-16 11:12:34.661621: step 9997, loss = 0.59523 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:12:35.621906 ops/training.py:65 2019-01-16 11:12:35.621854: step 9998, loss = 0.67045 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:12:36.585114 ops/training.py:65 2019-01-16 11:12:36.585045: step 9999, loss = 0.60912 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:17:15.963055 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I0832 2019-01-16 11:17:15.963905 ops/training.py:41 2019-01-16 11:17:15.963857: step 10000, loss = 0.64 (0.1 examples/sec; 278.413 sec/batch) | Training accuracy = 0.5625 | Validation accuracy = 0.6376 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_08_07_39_512188
I0832 2019-01-16 11:17:16.926126 ops/training.py:65 2019-01-16 11:17:16.926054: step 10001, loss = 0.62148 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:17:17.888183 ops/training.py:65 2019-01-16 11:17:17.888106: step 10002, loss = 0.57905 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:17:18.852653 ops/training.py:65 2019-01-16 11:17:18.852607: step 10003, loss = 0.60001 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:17:19.815883 ops/training.py:65 2019-01-16 11:17:19.815810: step 10004, loss = 0.63545 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:17:20.780020 ops/training.py:65 2019-01-16 11:17:20.779934: step 10005, loss = 0.49923 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:17:21.740403 ops/training.py:65 2019-01-16 11:17:21.740334: step 10006, loss = 0.52235 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 11:17:22.700817 ops/training.py:65 2019-01-16 11:17:22.700740: step 10007, loss = 0.65585 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:17:23.662366 ops/training.py:65 2019-01-16 11:17:23.662295: step 10008, loss = 0.59332 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:17:24.623991 ops/training.py:65 2019-01-16 11:17:24.623918: step 10009, loss = 0.66859 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:17:25.584843 ops/training.py:65 2019-01-16 11:17:25.584753: step 10010, loss = 0.55377 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:17:26.545279 ops/training.py:65 2019-01-16 11:17:26.545186: step 10011, loss = 0.69601 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:17:27.506305 ops/training.py:65 2019-01-16 11:17:27.506236: step 10012, loss = 0.67242 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:17:28.466761 ops/training.py:65 2019-01-16 11:17:28.466694: step 10013, loss = 0.68788 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:17:29.427795 ops/training.py:65 2019-01-16 11:17:29.427725: step 10014, loss = 0.66857 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:17:30.387892 ops/training.py:65 2019-01-16 11:17:30.387829: step 10015, loss = 0.51326 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:17:31.349747 ops/training.py:65 2019-01-16 11:17:31.349671: step 10016, loss = 0.52414 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:17:32.310646 ops/training.py:65 2019-01-16 11:17:32.310583: step 10017, loss = 0.59208 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:17:33.269317 ops/training.py:65 2019-01-16 11:17:33.269269: step 10018, loss = 0.63187 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:17:34.232098 ops/training.py:65 2019-01-16 11:17:34.232048: step 10019, loss = 0.62416 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:17:35.195686 ops/training.py:65 2019-01-16 11:17:35.195609: step 10020, loss = 0.65424 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:17:36.158998 ops/training.py:65 2019-01-16 11:17:36.158944: step 10021, loss = 0.56544 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:17:37.121269 ops/training.py:65 2019-01-16 11:17:37.121185: step 10022, loss = 0.55722 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:17:38.084355 ops/training.py:65 2019-01-16 11:17:38.084306: step 10023, loss = 0.59936 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:17:39.043985 ops/training.py:65 2019-01-16 11:17:39.043941: step 10024, loss = 0.63189 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:17:40.006396 ops/training.py:65 2019-01-16 11:17:40.006345: step 10025, loss = 0.66683 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:17:40.970679 ops/training.py:65 2019-01-16 11:17:40.970622: step 10026, loss = 0.68118 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:17:41.932362 ops/training.py:65 2019-01-16 11:17:41.932270: step 10027, loss = 0.53780 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:17:42.893845 ops/training.py:65 2019-01-16 11:17:42.893772: step 10028, loss = 0.72822 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:17:43.853975 ops/training.py:65 2019-01-16 11:17:43.853920: step 10029, loss = 0.57098 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:17:44.813492 ops/training.py:65 2019-01-16 11:17:44.813447: step 10030, loss = 0.66519 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:17:45.776505 ops/training.py:65 2019-01-16 11:17:45.776448: step 10031, loss = 0.68914 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:17:46.739931 ops/training.py:65 2019-01-16 11:17:46.739867: step 10032, loss = 0.60162 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:17:47.702324 ops/training.py:65 2019-01-16 11:17:47.702246: step 10033, loss = 0.61992 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:17:48.663495 ops/training.py:65 2019-01-16 11:17:48.663429: step 10034, loss = 0.69295 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:17:49.623913 ops/training.py:65 2019-01-16 11:17:49.623840: step 10035, loss = 0.64222 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:17:50.584917 ops/training.py:65 2019-01-16 11:17:50.584843: step 10036, loss = 0.60765 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:17:51.546653 ops/training.py:65 2019-01-16 11:17:51.546575: step 10037, loss = 0.63884 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:17:52.507584 ops/training.py:65 2019-01-16 11:17:52.507516: step 10038, loss = 0.59033 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:17:53.467970 ops/training.py:65 2019-01-16 11:17:53.467904: step 10039, loss = 0.62291 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:17:54.429111 ops/training.py:65 2019-01-16 11:17:54.429043: step 10040, loss = 0.53383 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:17:55.389045 ops/training.py:65 2019-01-16 11:17:55.388972: step 10041, loss = 0.68653 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:17:56.350106 ops/training.py:65 2019-01-16 11:17:56.350039: step 10042, loss = 0.60512 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:17:57.312000 ops/training.py:65 2019-01-16 11:17:57.311934: step 10043, loss = 0.71871 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:17:58.273596 ops/training.py:65 2019-01-16 11:17:58.273542: step 10044, loss = 0.70440 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:17:59.236425 ops/training.py:65 2019-01-16 11:17:59.236361: step 10045, loss = 0.65731 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:18:00.198142 ops/training.py:65 2019-01-16 11:18:00.198070: step 10046, loss = 0.59449 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:18:01.159672 ops/training.py:65 2019-01-16 11:18:01.159600: step 10047, loss = 0.73128 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:18:02.120497 ops/training.py:65 2019-01-16 11:18:02.120451: step 10048, loss = 0.69557 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:18:03.078298 ops/training.py:65 2019-01-16 11:18:03.078256: step 10049, loss = 0.50630 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:18:04.036016 ops/training.py:65 2019-01-16 11:18:04.035961: step 10050, loss = 0.67475 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:18:04.996789 ops/training.py:65 2019-01-16 11:18:04.996744: step 10051, loss = 0.67729 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:18:05.960061 ops/training.py:65 2019-01-16 11:18:05.960012: step 10052, loss = 0.64849 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:18:06.924571 ops/training.py:65 2019-01-16 11:18:06.924513: step 10053, loss = 0.78011 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:18:07.888711 ops/training.py:65 2019-01-16 11:18:07.888638: step 10054, loss = 0.71623 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:18:08.850930 ops/training.py:65 2019-01-16 11:18:08.850859: step 10055, loss = 0.57996 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:18:09.813128 ops/training.py:65 2019-01-16 11:18:09.813054: step 10056, loss = 0.63563 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:18:10.775551 ops/training.py:65 2019-01-16 11:18:10.775478: step 10057, loss = 0.55850 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:18:11.737581 ops/training.py:65 2019-01-16 11:18:11.737510: step 10058, loss = 0.59425 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:18:12.698832 ops/training.py:65 2019-01-16 11:18:12.698754: step 10059, loss = 0.65935 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:18:13.658987 ops/training.py:65 2019-01-16 11:18:13.658921: step 10060, loss = 0.63036 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:18:14.618882 ops/training.py:65 2019-01-16 11:18:14.618817: step 10061, loss = 0.57700 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:18:15.579760 ops/training.py:65 2019-01-16 11:18:15.579691: step 10062, loss = 0.60466 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:18:16.541230 ops/training.py:65 2019-01-16 11:18:16.541157: step 10063, loss = 0.59841 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:18:17.501949 ops/training.py:65 2019-01-16 11:18:17.501869: step 10064, loss = 0.59062 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:18:18.463523 ops/training.py:65 2019-01-16 11:18:18.463448: step 10065, loss = 0.66017 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:18:19.425828 ops/training.py:65 2019-01-16 11:18:19.425759: step 10066, loss = 0.61908 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:18:20.386318 ops/training.py:65 2019-01-16 11:18:20.386251: step 10067, loss = 0.58283 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:18:21.346959 ops/training.py:65 2019-01-16 11:18:21.346906: step 10068, loss = 0.67931 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:18:22.306895 ops/training.py:65 2019-01-16 11:18:22.306843: step 10069, loss = 0.66488 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:18:23.265970 ops/training.py:65 2019-01-16 11:18:23.265923: step 10070, loss = 0.57455 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:18:24.227819 ops/training.py:65 2019-01-16 11:18:24.227773: step 10071, loss = 0.60334 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:18:25.192235 ops/training.py:65 2019-01-16 11:18:25.192164: step 10072, loss = 0.77361 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 11:18:26.154060 ops/training.py:65 2019-01-16 11:18:26.153991: step 10073, loss = 0.65904 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:18:27.118172 ops/training.py:65 2019-01-16 11:18:27.118094: step 10074, loss = 0.68036 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:18:28.083146 ops/training.py:65 2019-01-16 11:18:28.083094: step 10075, loss = 0.62661 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:18:29.045921 ops/training.py:65 2019-01-16 11:18:29.045852: step 10076, loss = 0.62069 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:18:30.007191 ops/training.py:65 2019-01-16 11:18:30.007123: step 10077, loss = 0.74903 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:18:30.968203 ops/training.py:65 2019-01-16 11:18:30.968133: step 10078, loss = 0.64855 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:18:31.929290 ops/training.py:65 2019-01-16 11:18:31.929221: step 10079, loss = 0.71330 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:18:32.890801 ops/training.py:65 2019-01-16 11:18:32.890733: step 10080, loss = 0.60972 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:18:33.853541 ops/training.py:65 2019-01-16 11:18:33.853471: step 10081, loss = 0.65212 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:18:34.816471 ops/training.py:65 2019-01-16 11:18:34.816426: step 10082, loss = 0.64698 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:18:35.780131 ops/training.py:65 2019-01-16 11:18:35.780077: step 10083, loss = 0.59018 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:18:36.742316 ops/training.py:65 2019-01-16 11:18:36.742258: step 10084, loss = 0.61394 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:18:37.704096 ops/training.py:65 2019-01-16 11:18:37.704025: step 10085, loss = 0.63398 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:18:38.667715 ops/training.py:65 2019-01-16 11:18:38.667672: step 10086, loss = 0.58076 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:18:39.631162 ops/training.py:65 2019-01-16 11:18:39.631096: step 10087, loss = 0.61968 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:18:40.593360 ops/training.py:65 2019-01-16 11:18:40.593292: step 10088, loss = 0.47332 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:18:41.555214 ops/training.py:65 2019-01-16 11:18:41.555162: step 10089, loss = 0.67000 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:18:42.514956 ops/training.py:65 2019-01-16 11:18:42.514906: step 10090, loss = 0.56403 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:18:43.477486 ops/training.py:65 2019-01-16 11:18:43.477421: step 10091, loss = 0.59183 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:18:44.440837 ops/training.py:65 2019-01-16 11:18:44.440771: step 10092, loss = 0.75515 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:18:45.401617 ops/training.py:65 2019-01-16 11:18:45.401547: step 10093, loss = 0.61568 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:18:46.363484 ops/training.py:65 2019-01-16 11:18:46.363430: step 10094, loss = 0.58182 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:18:47.321662 ops/training.py:65 2019-01-16 11:18:47.321615: step 10095, loss = 0.64887 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:18:48.285234 ops/training.py:65 2019-01-16 11:18:48.285189: step 10096, loss = 0.53800 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:18:49.246192 ops/training.py:65 2019-01-16 11:18:49.246130: step 10097, loss = 0.71553 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:18:50.206562 ops/training.py:65 2019-01-16 11:18:50.206516: step 10098, loss = 0.63157 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:18:51.169609 ops/training.py:65 2019-01-16 11:18:51.169580: step 10099, loss = 0.66027 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:18:52.134434 ops/training.py:65 2019-01-16 11:18:52.134363: step 10100, loss = 0.62772 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:18:53.096988 ops/training.py:65 2019-01-16 11:18:53.096918: step 10101, loss = 0.58518 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:18:54.058983 ops/training.py:65 2019-01-16 11:18:54.058930: step 10102, loss = 0.66228 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:18:55.019707 ops/training.py:65 2019-01-16 11:18:55.019635: step 10103, loss = 0.64755 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:18:55.981493 ops/training.py:65 2019-01-16 11:18:55.981422: step 10104, loss = 0.54530 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:18:56.941756 ops/training.py:65 2019-01-16 11:18:56.941710: step 10105, loss = 0.64108 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:18:57.901354 ops/training.py:65 2019-01-16 11:18:57.901306: step 10106, loss = 0.63381 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:18:58.859365 ops/training.py:65 2019-01-16 11:18:58.859321: step 10107, loss = 0.54295 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:18:59.817945 ops/training.py:65 2019-01-16 11:18:59.817899: step 10108, loss = 0.54879 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:19:00.779756 ops/training.py:65 2019-01-16 11:19:00.779717: step 10109, loss = 0.65856 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:19:01.743502 ops/training.py:65 2019-01-16 11:19:01.743446: step 10110, loss = 0.59501 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:19:02.705936 ops/training.py:65 2019-01-16 11:19:02.705865: step 10111, loss = 0.50585 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:19:03.666695 ops/training.py:65 2019-01-16 11:19:03.666624: step 10112, loss = 0.66696 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:19:04.627803 ops/training.py:65 2019-01-16 11:19:04.627729: step 10113, loss = 0.55463 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:19:05.590642 ops/training.py:65 2019-01-16 11:19:05.590586: step 10114, loss = 0.65728 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:19:06.554065 ops/training.py:65 2019-01-16 11:19:06.554010: step 10115, loss = 0.62294 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:19:07.516063 ops/training.py:65 2019-01-16 11:19:07.515987: step 10116, loss = 0.64593 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:19:08.477430 ops/training.py:65 2019-01-16 11:19:08.477367: step 10117, loss = 0.60472 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:19:09.439002 ops/training.py:65 2019-01-16 11:19:09.438933: step 10118, loss = 0.67869 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:19:10.401195 ops/training.py:65 2019-01-16 11:19:10.401124: step 10119, loss = 0.63538 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:19:11.365262 ops/training.py:65 2019-01-16 11:19:11.365219: step 10120, loss = 0.58581 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:19:12.327354 ops/training.py:65 2019-01-16 11:19:12.327283: step 10121, loss = 0.68947 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:19:13.291311 ops/training.py:65 2019-01-16 11:19:13.291245: step 10122, loss = 0.48498 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 11:19:14.255201 ops/training.py:65 2019-01-16 11:19:14.255135: step 10123, loss = 0.49149 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:19:15.218320 ops/training.py:65 2019-01-16 11:19:15.218243: step 10124, loss = 0.78370 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:19:16.179496 ops/training.py:65 2019-01-16 11:19:16.179422: step 10125, loss = 0.65542 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:19:17.143642 ops/training.py:65 2019-01-16 11:19:17.143595: step 10126, loss = 0.58863 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:19:18.107135 ops/training.py:65 2019-01-16 11:19:18.107066: step 10127, loss = 0.83026 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 11:19:19.067932 ops/training.py:65 2019-01-16 11:19:19.067859: step 10128, loss = 0.68588 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:19:20.028499 ops/training.py:65 2019-01-16 11:19:20.028444: step 10129, loss = 0.63913 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:19:20.991561 ops/training.py:65 2019-01-16 11:19:20.991518: step 10130, loss = 0.52356 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:19:21.955221 ops/training.py:65 2019-01-16 11:19:21.955152: step 10131, loss = 0.59616 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:19:22.917083 ops/training.py:65 2019-01-16 11:19:22.917013: step 10132, loss = 0.53683 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:19:23.878049 ops/training.py:65 2019-01-16 11:19:23.877990: step 10133, loss = 0.63930 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:19:24.839810 ops/training.py:65 2019-01-16 11:19:24.839741: step 10134, loss = 0.54032 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:19:25.802046 ops/training.py:65 2019-01-16 11:19:25.801999: step 10135, loss = 0.60602 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:19:26.762543 ops/training.py:65 2019-01-16 11:19:26.762482: step 10136, loss = 0.64301 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:19:27.722660 ops/training.py:65 2019-01-16 11:19:27.722587: step 10137, loss = 0.65520 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:19:28.682184 ops/training.py:65 2019-01-16 11:19:28.682137: step 10138, loss = 0.68784 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:19:29.640084 ops/training.py:65 2019-01-16 11:19:29.640035: step 10139, loss = 0.67534 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:19:30.603720 ops/training.py:65 2019-01-16 11:19:30.603661: step 10140, loss = 0.60548 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:19:31.563654 ops/training.py:65 2019-01-16 11:19:31.563603: step 10141, loss = 0.62662 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:19:32.528199 ops/training.py:65 2019-01-16 11:19:32.528109: step 10142, loss = 0.60477 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:19:33.491517 ops/training.py:65 2019-01-16 11:19:33.491449: step 10143, loss = 0.61144 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:19:34.453980 ops/training.py:65 2019-01-16 11:19:34.453910: step 10144, loss = 0.60543 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:19:35.414351 ops/training.py:65 2019-01-16 11:19:35.414278: step 10145, loss = 0.62931 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:19:36.374203 ops/training.py:65 2019-01-16 11:19:36.374149: step 10146, loss = 0.63132 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:19:37.333903 ops/training.py:65 2019-01-16 11:19:37.333832: step 10147, loss = 0.67830 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:19:38.297735 ops/training.py:65 2019-01-16 11:19:38.297685: step 10148, loss = 0.68469 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:19:39.259678 ops/training.py:65 2019-01-16 11:19:39.259613: step 10149, loss = 0.58753 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:19:40.224448 ops/training.py:65 2019-01-16 11:19:40.224375: step 10150, loss = 0.68843 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:19:41.187677 ops/training.py:65 2019-01-16 11:19:41.187619: step 10151, loss = 0.56234 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:19:42.150476 ops/training.py:65 2019-01-16 11:19:42.150401: step 10152, loss = 0.60488 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:19:43.111337 ops/training.py:65 2019-01-16 11:19:43.111267: step 10153, loss = 0.69444 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:19:44.075056 ops/training.py:65 2019-01-16 11:19:44.074979: step 10154, loss = 0.53131 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 11:19:45.038470 ops/training.py:65 2019-01-16 11:19:45.038392: step 10155, loss = 0.63685 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:19:46.001145 ops/training.py:65 2019-01-16 11:19:46.001068: step 10156, loss = 0.68776 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:19:46.961098 ops/training.py:65 2019-01-16 11:19:46.961043: step 10157, loss = 0.64546 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:19:47.920899 ops/training.py:65 2019-01-16 11:19:47.920848: step 10158, loss = 0.74320 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:19:48.883560 ops/training.py:65 2019-01-16 11:19:48.883501: step 10159, loss = 0.65666 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:19:49.847724 ops/training.py:65 2019-01-16 11:19:49.847650: step 10160, loss = 0.57570 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:19:50.811117 ops/training.py:65 2019-01-16 11:19:50.811047: step 10161, loss = 0.70551 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:19:51.772415 ops/training.py:65 2019-01-16 11:19:51.772343: step 10162, loss = 0.67921 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:19:52.733322 ops/training.py:65 2019-01-16 11:19:52.733246: step 10163, loss = 0.70539 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:19:53.693566 ops/training.py:65 2019-01-16 11:19:53.693518: step 10164, loss = 0.66728 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:19:54.657187 ops/training.py:65 2019-01-16 11:19:54.657128: step 10165, loss = 0.60791 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:19:55.621618 ops/training.py:65 2019-01-16 11:19:55.621548: step 10166, loss = 0.56739 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:19:56.583967 ops/training.py:65 2019-01-16 11:19:56.583892: step 10167, loss = 0.79305 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:19:57.544756 ops/training.py:65 2019-01-16 11:19:57.544706: step 10168, loss = 0.67430 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:19:58.503949 ops/training.py:65 2019-01-16 11:19:58.503897: step 10169, loss = 0.62990 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:19:59.462990 ops/training.py:65 2019-01-16 11:19:59.462943: step 10170, loss = 0.59491 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:20:00.425454 ops/training.py:65 2019-01-16 11:20:00.425393: step 10171, loss = 0.56450 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:20:01.388575 ops/training.py:65 2019-01-16 11:20:01.388498: step 10172, loss = 0.54658 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:20:02.353197 ops/training.py:65 2019-01-16 11:20:02.353123: step 10173, loss = 0.74313 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 11:20:03.314430 ops/training.py:65 2019-01-16 11:20:03.314355: step 10174, loss = 0.62279 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:20:04.277848 ops/training.py:65 2019-01-16 11:20:04.277778: step 10175, loss = 0.65948 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:20:05.240896 ops/training.py:65 2019-01-16 11:20:05.240818: step 10176, loss = 0.75585 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 11:20:06.201840 ops/training.py:65 2019-01-16 11:20:06.201784: step 10177, loss = 0.70532 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 11:20:07.163097 ops/training.py:65 2019-01-16 11:20:07.163022: step 10178, loss = 0.69570 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:20:08.123601 ops/training.py:65 2019-01-16 11:20:08.123546: step 10179, loss = 0.56254 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:20:09.082482 ops/training.py:65 2019-01-16 11:20:09.082429: step 10180, loss = 0.61413 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:20:10.041484 ops/training.py:65 2019-01-16 11:20:10.041434: step 10181, loss = 0.60314 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:20:11.000511 ops/training.py:65 2019-01-16 11:20:11.000461: step 10182, loss = 0.59591 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:20:11.959697 ops/training.py:65 2019-01-16 11:20:11.959644: step 10183, loss = 0.61173 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:20:12.918076 ops/training.py:65 2019-01-16 11:20:12.918026: step 10184, loss = 0.56365 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:20:13.876414 ops/training.py:65 2019-01-16 11:20:13.876361: step 10185, loss = 0.65633 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:20:14.835221 ops/training.py:65 2019-01-16 11:20:14.835160: step 10186, loss = 0.64435 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:20:15.794436 ops/training.py:65 2019-01-16 11:20:15.794381: step 10187, loss = 0.68965 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:20:16.753546 ops/training.py:65 2019-01-16 11:20:16.753499: step 10188, loss = 0.70892 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:20:17.712786 ops/training.py:65 2019-01-16 11:20:17.712740: step 10189, loss = 0.65843 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:20:18.676495 ops/training.py:65 2019-01-16 11:20:18.676435: step 10190, loss = 0.66565 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:20:19.640363 ops/training.py:65 2019-01-16 11:20:19.640288: step 10191, loss = 0.59026 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:20:20.603259 ops/training.py:65 2019-01-16 11:20:20.603181: step 10192, loss = 0.67546 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:20:21.564527 ops/training.py:65 2019-01-16 11:20:21.564447: step 10193, loss = 0.62096 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:20:22.526631 ops/training.py:65 2019-01-16 11:20:22.526556: step 10194, loss = 0.62817 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:20:23.487452 ops/training.py:65 2019-01-16 11:20:23.487387: step 10195, loss = 0.50986 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:20:24.448424 ops/training.py:65 2019-01-16 11:20:24.448360: step 10196, loss = 0.65006 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:20:25.413055 ops/training.py:65 2019-01-16 11:20:25.412979: step 10197, loss = 0.63584 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:20:26.377218 ops/training.py:65 2019-01-16 11:20:26.377140: step 10198, loss = 0.60051 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:20:27.339072 ops/training.py:65 2019-01-16 11:20:27.338994: step 10199, loss = 0.63587 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:20:28.298705 ops/training.py:65 2019-01-16 11:20:28.298630: step 10200, loss = 0.54459 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:20:29.260145 ops/training.py:65 2019-01-16 11:20:29.260083: step 10201, loss = 0.64007 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:20:30.218767 ops/training.py:65 2019-01-16 11:20:30.218720: step 10202, loss = 0.62504 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:20:31.177531 ops/training.py:65 2019-01-16 11:20:31.177485: step 10203, loss = 0.62174 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:20:32.135792 ops/training.py:65 2019-01-16 11:20:32.135748: step 10204, loss = 0.51162 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:20:33.094017 ops/training.py:65 2019-01-16 11:20:33.093967: step 10205, loss = 0.69361 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:20:34.052710 ops/training.py:65 2019-01-16 11:20:34.052656: step 10206, loss = 0.77555 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:20:35.011657 ops/training.py:65 2019-01-16 11:20:35.011607: step 10207, loss = 0.57081 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:20:35.970207 ops/training.py:65 2019-01-16 11:20:35.970142: step 10208, loss = 0.57721 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:20:36.930285 ops/training.py:65 2019-01-16 11:20:36.930215: step 10209, loss = 0.59916 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:20:37.890870 ops/training.py:65 2019-01-16 11:20:37.890797: step 10210, loss = 0.60500 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:20:38.850786 ops/training.py:65 2019-01-16 11:20:38.850725: step 10211, loss = 0.67877 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:20:39.810239 ops/training.py:65 2019-01-16 11:20:39.810184: step 10212, loss = 0.62108 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:20:40.769071 ops/training.py:65 2019-01-16 11:20:40.769020: step 10213, loss = 0.65638 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:20:41.727747 ops/training.py:65 2019-01-16 11:20:41.727701: step 10214, loss = 0.69482 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:20:42.690388 ops/training.py:65 2019-01-16 11:20:42.690327: step 10215, loss = 0.64276 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:20:43.653124 ops/training.py:65 2019-01-16 11:20:43.653049: step 10216, loss = 0.54589 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:20:44.613924 ops/training.py:65 2019-01-16 11:20:44.613857: step 10217, loss = 0.72629 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:20:45.576482 ops/training.py:65 2019-01-16 11:20:45.576425: step 10218, loss = 0.62135 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:20:46.539582 ops/training.py:65 2019-01-16 11:20:46.539505: step 10219, loss = 0.62558 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:20:47.501848 ops/training.py:65 2019-01-16 11:20:47.501771: step 10220, loss = 0.54498 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:20:48.461809 ops/training.py:65 2019-01-16 11:20:48.461755: step 10221, loss = 0.57952 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:20:49.421537 ops/training.py:65 2019-01-16 11:20:49.421489: step 10222, loss = 0.61352 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:20:50.384693 ops/training.py:65 2019-01-16 11:20:50.384632: step 10223, loss = 0.73146 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 11:20:51.348240 ops/training.py:65 2019-01-16 11:20:51.348167: step 10224, loss = 0.66164 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:20:52.308708 ops/training.py:65 2019-01-16 11:20:52.308634: step 10225, loss = 0.57705 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:20:53.270315 ops/training.py:65 2019-01-16 11:20:53.270256: step 10226, loss = 0.73632 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:20:54.231885 ops/training.py:65 2019-01-16 11:20:54.231814: step 10227, loss = 0.61108 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:20:55.191876 ops/training.py:65 2019-01-16 11:20:55.191810: step 10228, loss = 0.65294 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:20:56.153252 ops/training.py:65 2019-01-16 11:20:56.153190: step 10229, loss = 0.61379 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:20:57.113009 ops/training.py:65 2019-01-16 11:20:57.112960: step 10230, loss = 0.73961 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:20:58.071317 ops/training.py:65 2019-01-16 11:20:58.071273: step 10231, loss = 0.62855 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:20:59.029840 ops/training.py:65 2019-01-16 11:20:59.029792: step 10232, loss = 0.55082 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:20:59.989357 ops/training.py:65 2019-01-16 11:20:59.989308: step 10233, loss = 0.66521 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:21:00.948107 ops/training.py:65 2019-01-16 11:21:00.948058: step 10234, loss = 0.56136 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:21:01.906539 ops/training.py:65 2019-01-16 11:21:01.906498: step 10235, loss = 0.63005 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:21:02.865794 ops/training.py:65 2019-01-16 11:21:02.865746: step 10236, loss = 0.69620 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:21:03.823825 ops/training.py:65 2019-01-16 11:21:03.823777: step 10237, loss = 0.60933 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:21:04.786063 ops/training.py:65 2019-01-16 11:21:04.786005: step 10238, loss = 0.62796 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:21:05.749033 ops/training.py:65 2019-01-16 11:21:05.748977: step 10239, loss = 0.66567 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:21:06.711966 ops/training.py:65 2019-01-16 11:21:06.711910: step 10240, loss = 0.62810 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:21:07.673194 ops/training.py:65 2019-01-16 11:21:07.673121: step 10241, loss = 0.53532 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:21:08.634048 ops/training.py:65 2019-01-16 11:21:08.633988: step 10242, loss = 0.52519 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:21:09.593226 ops/training.py:65 2019-01-16 11:21:09.593175: step 10243, loss = 0.60321 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:21:10.552389 ops/training.py:65 2019-01-16 11:21:10.552339: step 10244, loss = 0.74630 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 11:21:11.511641 ops/training.py:65 2019-01-16 11:21:11.511590: step 10245, loss = 0.58050 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:21:12.469927 ops/training.py:65 2019-01-16 11:21:12.469880: step 10246, loss = 0.61948 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:21:13.427577 ops/training.py:65 2019-01-16 11:21:13.427527: step 10247, loss = 0.67119 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:21:14.386971 ops/training.py:65 2019-01-16 11:21:14.386922: step 10248, loss = 0.66777 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:21:15.349104 ops/training.py:65 2019-01-16 11:21:15.349046: step 10249, loss = 0.65537 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:21:16.314079 ops/training.py:65 2019-01-16 11:21:16.314011: step 10250, loss = 0.56639 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:21:17.276684 ops/training.py:65 2019-01-16 11:21:17.276633: step 10251, loss = 0.64535 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:21:18.241241 ops/training.py:65 2019-01-16 11:21:18.241185: step 10252, loss = 0.56837 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:21:19.204232 ops/training.py:65 2019-01-16 11:21:19.204172: step 10253, loss = 0.64491 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:21:20.166512 ops/training.py:65 2019-01-16 11:21:20.166461: step 10254, loss = 0.59950 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:21:21.129144 ops/training.py:65 2019-01-16 11:21:21.129092: step 10255, loss = 0.54619 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:21:22.095336 ops/training.py:65 2019-01-16 11:21:22.095284: step 10256, loss = 0.49836 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:21:23.058512 ops/training.py:65 2019-01-16 11:21:23.058448: step 10257, loss = 0.64100 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:21:24.020406 ops/training.py:65 2019-01-16 11:21:24.020338: step 10258, loss = 0.53690 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:21:24.982911 ops/training.py:65 2019-01-16 11:21:24.982839: step 10259, loss = 0.54243 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:21:25.947473 ops/training.py:65 2019-01-16 11:21:25.947410: step 10260, loss = 0.54447 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:21:26.911215 ops/training.py:65 2019-01-16 11:21:26.911154: step 10261, loss = 0.61997 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:21:27.875045 ops/training.py:65 2019-01-16 11:21:27.874976: step 10262, loss = 0.54304 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:21:28.836792 ops/training.py:65 2019-01-16 11:21:28.836729: step 10263, loss = 0.62908 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:21:29.797680 ops/training.py:65 2019-01-16 11:21:29.797618: step 10264, loss = 0.63674 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:21:30.759005 ops/training.py:65 2019-01-16 11:21:30.758941: step 10265, loss = 0.65875 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:21:31.720078 ops/training.py:65 2019-01-16 11:21:31.720013: step 10266, loss = 0.59804 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:21:32.681907 ops/training.py:65 2019-01-16 11:21:32.681839: step 10267, loss = 0.72029 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:21:33.643561 ops/training.py:65 2019-01-16 11:21:33.643511: step 10268, loss = 0.71571 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:21:34.605458 ops/training.py:65 2019-01-16 11:21:34.605405: step 10269, loss = 0.74450 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:21:35.565530 ops/training.py:65 2019-01-16 11:21:35.565478: step 10270, loss = 0.71140 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:21:36.525851 ops/training.py:65 2019-01-16 11:21:36.525798: step 10271, loss = 0.78602 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:21:37.485964 ops/training.py:65 2019-01-16 11:21:37.485915: step 10272, loss = 0.71645 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:21:38.450102 ops/training.py:65 2019-01-16 11:21:38.450041: step 10273, loss = 0.66013 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:21:39.414862 ops/training.py:65 2019-01-16 11:21:39.414803: step 10274, loss = 0.65086 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:21:40.378082 ops/training.py:65 2019-01-16 11:21:40.378011: step 10275, loss = 0.59954 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:21:41.338908 ops/training.py:65 2019-01-16 11:21:41.338858: step 10276, loss = 0.57634 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:21:42.299618 ops/training.py:65 2019-01-16 11:21:42.299552: step 10277, loss = 0.62026 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:21:43.261150 ops/training.py:65 2019-01-16 11:21:43.261089: step 10278, loss = 0.68569 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:21:44.223066 ops/training.py:65 2019-01-16 11:21:44.223006: step 10279, loss = 0.55875 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:21:45.183816 ops/training.py:65 2019-01-16 11:21:45.183746: step 10280, loss = 0.60953 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:21:46.145095 ops/training.py:65 2019-01-16 11:21:46.145034: step 10281, loss = 0.57950 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:21:47.124817 ops/training.py:65 2019-01-16 11:21:47.124752: step 10282, loss = 0.56869 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:21:48.086611 ops/training.py:65 2019-01-16 11:21:48.086544: step 10283, loss = 0.64332 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:21:49.048675 ops/training.py:65 2019-01-16 11:21:49.048624: step 10284, loss = 0.57484 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:21:50.009231 ops/training.py:65 2019-01-16 11:21:50.009163: step 10285, loss = 0.68350 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:21:50.971994 ops/training.py:65 2019-01-16 11:21:50.971930: step 10286, loss = 0.61425 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:21:51.935494 ops/training.py:65 2019-01-16 11:21:51.935430: step 10287, loss = 0.56478 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:21:52.900737 ops/training.py:65 2019-01-16 11:21:52.900686: step 10288, loss = 0.67823 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:21:53.863967 ops/training.py:65 2019-01-16 11:21:53.863904: step 10289, loss = 0.68773 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:21:54.825774 ops/training.py:65 2019-01-16 11:21:54.825710: step 10290, loss = 0.54415 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:21:55.786332 ops/training.py:65 2019-01-16 11:21:55.786271: step 10291, loss = 0.57520 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:21:56.747626 ops/training.py:65 2019-01-16 11:21:56.747568: step 10292, loss = 0.61429 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:21:57.708894 ops/training.py:65 2019-01-16 11:21:57.708824: step 10293, loss = 0.56226 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:21:58.668929 ops/training.py:65 2019-01-16 11:21:58.668852: step 10294, loss = 0.58670 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:21:59.629784 ops/training.py:65 2019-01-16 11:21:59.629719: step 10295, loss = 0.63225 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:22:00.591111 ops/training.py:65 2019-01-16 11:22:00.591045: step 10296, loss = 0.67226 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:22:01.553104 ops/training.py:65 2019-01-16 11:22:01.553045: step 10297, loss = 0.51830 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:22:02.514270 ops/training.py:65 2019-01-16 11:22:02.514221: step 10298, loss = 0.65224 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:22:03.474265 ops/training.py:65 2019-01-16 11:22:03.474217: step 10299, loss = 0.69121 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:22:04.433365 ops/training.py:65 2019-01-16 11:22:04.433318: step 10300, loss = 0.58310 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:22:05.395389 ops/training.py:65 2019-01-16 11:22:05.395344: step 10301, loss = 0.58943 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:22:06.359344 ops/training.py:65 2019-01-16 11:22:06.359291: step 10302, loss = 0.63639 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:22:07.321786 ops/training.py:65 2019-01-16 11:22:07.321734: step 10303, loss = 0.53451 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:22:08.282001 ops/training.py:65 2019-01-16 11:22:08.281947: step 10304, loss = 0.61458 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:22:09.242998 ops/training.py:65 2019-01-16 11:22:09.242948: step 10305, loss = 0.62717 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:22:10.207276 ops/training.py:65 2019-01-16 11:22:10.207223: step 10306, loss = 0.59819 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:22:11.171414 ops/training.py:65 2019-01-16 11:22:11.171363: step 10307, loss = 0.59890 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:22:12.134231 ops/training.py:65 2019-01-16 11:22:12.134173: step 10308, loss = 0.48778 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:22:13.095258 ops/training.py:65 2019-01-16 11:22:13.095209: step 10309, loss = 0.59341 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:22:14.056620 ops/training.py:65 2019-01-16 11:22:14.056548: step 10310, loss = 0.66297 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:22:15.016752 ops/training.py:65 2019-01-16 11:22:15.016684: step 10311, loss = 0.70759 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:22:15.978592 ops/training.py:65 2019-01-16 11:22:15.978528: step 10312, loss = 0.61495 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:22:16.939484 ops/training.py:65 2019-01-16 11:22:16.939420: step 10313, loss = 0.55952 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:22:17.900996 ops/training.py:65 2019-01-16 11:22:17.900924: step 10314, loss = 0.48685 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:22:18.860764 ops/training.py:65 2019-01-16 11:22:18.860717: step 10315, loss = 0.61339 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:22:19.820095 ops/training.py:65 2019-01-16 11:22:19.820049: step 10316, loss = 0.56966 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:22:20.778438 ops/training.py:65 2019-01-16 11:22:20.778391: step 10317, loss = 0.62433 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:22:21.741179 ops/training.py:65 2019-01-16 11:22:21.741133: step 10318, loss = 0.63196 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:22:22.705351 ops/training.py:65 2019-01-16 11:22:22.705297: step 10319, loss = 0.55690 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:22:23.668761 ops/training.py:65 2019-01-16 11:22:23.668691: step 10320, loss = 0.67158 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:22:24.629267 ops/training.py:65 2019-01-16 11:22:24.629220: step 10321, loss = 0.57515 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:22:25.587093 ops/training.py:65 2019-01-16 11:22:25.587048: step 10322, loss = 0.62785 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:22:26.544466 ops/training.py:65 2019-01-16 11:22:26.544421: step 10323, loss = 0.68409 (33.5 examples/sec; 0.956 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:22:27.502147 ops/training.py:65 2019-01-16 11:22:27.502100: step 10324, loss = 0.53789 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:22:28.464595 ops/training.py:65 2019-01-16 11:22:28.464544: step 10325, loss = 0.64032 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:22:29.427433 ops/training.py:65 2019-01-16 11:22:29.427369: step 10326, loss = 0.61328 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:22:30.389258 ops/training.py:65 2019-01-16 11:22:30.389180: step 10327, loss = 0.68605 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:22:31.349582 ops/training.py:65 2019-01-16 11:22:31.349507: step 10328, loss = 0.56410 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:22:32.313892 ops/training.py:65 2019-01-16 11:22:32.313842: step 10329, loss = 0.60157 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:22:33.276399 ops/training.py:65 2019-01-16 11:22:33.276354: step 10330, loss = 0.64176 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:22:34.239988 ops/training.py:65 2019-01-16 11:22:34.239917: step 10331, loss = 0.65335 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:22:35.204319 ops/training.py:65 2019-01-16 11:22:35.204263: step 10332, loss = 0.53061 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:22:36.165360 ops/training.py:65 2019-01-16 11:22:36.165306: step 10333, loss = 0.56279 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:22:37.127107 ops/training.py:65 2019-01-16 11:22:37.127048: step 10334, loss = 0.65365 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:22:38.088432 ops/training.py:65 2019-01-16 11:22:38.088381: step 10335, loss = 0.60416 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:22:39.048355 ops/training.py:65 2019-01-16 11:22:39.048289: step 10336, loss = 0.66597 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:22:40.010366 ops/training.py:65 2019-01-16 11:22:40.010302: step 10337, loss = 0.62021 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:22:40.972078 ops/training.py:65 2019-01-16 11:22:40.972014: step 10338, loss = 0.59139 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:22:41.932717 ops/training.py:65 2019-01-16 11:22:41.932644: step 10339, loss = 0.65615 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:22:42.894648 ops/training.py:65 2019-01-16 11:22:42.894573: step 10340, loss = 0.70684 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:22:43.856688 ops/training.py:65 2019-01-16 11:22:43.856623: step 10341, loss = 0.73761 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:22:44.818119 ops/training.py:65 2019-01-16 11:22:44.818053: step 10342, loss = 0.55743 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:22:45.778680 ops/training.py:65 2019-01-16 11:22:45.778610: step 10343, loss = 0.61669 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:22:46.741710 ops/training.py:65 2019-01-16 11:22:46.741644: step 10344, loss = 0.70626 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:22:47.703569 ops/training.py:65 2019-01-16 11:22:47.703504: step 10345, loss = 0.57877 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:22:48.665671 ops/training.py:65 2019-01-16 11:22:48.665602: step 10346, loss = 0.54206 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:22:49.630350 ops/training.py:65 2019-01-16 11:22:49.630303: step 10347, loss = 0.62265 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:22:50.593332 ops/training.py:65 2019-01-16 11:22:50.593278: step 10348, loss = 0.62838 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:22:51.553843 ops/training.py:65 2019-01-16 11:22:51.553801: step 10349, loss = 0.66227 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:22:52.513335 ops/training.py:65 2019-01-16 11:22:52.513288: step 10350, loss = 0.56221 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:22:53.471079 ops/training.py:65 2019-01-16 11:22:53.471033: step 10351, loss = 0.58019 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:22:54.430426 ops/training.py:65 2019-01-16 11:22:54.430378: step 10352, loss = 0.52854 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:22:55.387832 ops/training.py:65 2019-01-16 11:22:55.387781: step 10353, loss = 0.65413 (33.5 examples/sec; 0.956 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:22:56.346433 ops/training.py:65 2019-01-16 11:22:56.346388: step 10354, loss = 0.51286 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:22:57.306526 ops/training.py:65 2019-01-16 11:22:57.306479: step 10355, loss = 0.54842 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:22:58.265879 ops/training.py:65 2019-01-16 11:22:58.265834: step 10356, loss = 0.66243 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:22:59.229283 ops/training.py:65 2019-01-16 11:22:59.229235: step 10357, loss = 0.64449 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:23:00.192762 ops/training.py:65 2019-01-16 11:23:00.192687: step 10358, loss = 0.66820 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:23:01.153489 ops/training.py:65 2019-01-16 11:23:01.153419: step 10359, loss = 0.73078 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:23:02.113932 ops/training.py:65 2019-01-16 11:23:02.113886: step 10360, loss = 0.54600 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:23:03.074112 ops/training.py:65 2019-01-16 11:23:03.074065: step 10361, loss = 0.66997 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:23:04.032414 ops/training.py:65 2019-01-16 11:23:04.032368: step 10362, loss = 0.56860 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:23:04.994087 ops/training.py:65 2019-01-16 11:23:04.994037: step 10363, loss = 0.56603 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:23:05.957432 ops/training.py:65 2019-01-16 11:23:05.957381: step 10364, loss = 0.63661 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:23:06.920650 ops/training.py:65 2019-01-16 11:23:06.920589: step 10365, loss = 0.59785 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:23:07.882825 ops/training.py:65 2019-01-16 11:23:07.882755: step 10366, loss = 0.51342 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:23:08.847574 ops/training.py:65 2019-01-16 11:23:08.847527: step 10367, loss = 0.59416 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:23:09.811313 ops/training.py:65 2019-01-16 11:23:09.811248: step 10368, loss = 0.61456 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:23:10.771718 ops/training.py:65 2019-01-16 11:23:10.771665: step 10369, loss = 0.46819 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:23:11.732485 ops/training.py:65 2019-01-16 11:23:11.732425: step 10370, loss = 0.72940 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:23:12.694804 ops/training.py:65 2019-01-16 11:23:12.694759: step 10371, loss = 0.49117 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:23:13.656165 ops/training.py:65 2019-01-16 11:23:13.656115: step 10372, loss = 0.80201 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 11:23:14.620173 ops/training.py:65 2019-01-16 11:23:14.620127: step 10373, loss = 0.67381 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:23:15.583360 ops/training.py:65 2019-01-16 11:23:15.583308: step 10374, loss = 0.65395 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:23:16.546736 ops/training.py:65 2019-01-16 11:23:16.546667: step 10375, loss = 0.61715 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:23:17.507771 ops/training.py:65 2019-01-16 11:23:17.507705: step 10376, loss = 0.62501 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:23:18.471914 ops/training.py:65 2019-01-16 11:23:18.471852: step 10377, loss = 0.55398 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:23:19.432354 ops/training.py:65 2019-01-16 11:23:19.432283: step 10378, loss = 0.55832 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:23:20.393672 ops/training.py:65 2019-01-16 11:23:20.393598: step 10379, loss = 0.58074 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:23:21.355973 ops/training.py:65 2019-01-16 11:23:21.355897: step 10380, loss = 0.63606 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:23:22.319160 ops/training.py:65 2019-01-16 11:23:22.319114: step 10381, loss = 0.57303 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:23:23.282121 ops/training.py:65 2019-01-16 11:23:23.282048: step 10382, loss = 0.75524 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:23:24.244335 ops/training.py:65 2019-01-16 11:23:24.244292: step 10383, loss = 0.63477 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:23:25.208158 ops/training.py:65 2019-01-16 11:23:25.208116: step 10384, loss = 0.61037 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:23:26.171504 ops/training.py:65 2019-01-16 11:23:26.171440: step 10385, loss = 0.64735 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:23:27.134521 ops/training.py:65 2019-01-16 11:23:27.134451: step 10386, loss = 0.66760 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:23:28.096092 ops/training.py:65 2019-01-16 11:23:28.096022: step 10387, loss = 0.61550 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:23:29.056215 ops/training.py:65 2019-01-16 11:23:29.056169: step 10388, loss = 0.51624 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:23:30.014157 ops/training.py:65 2019-01-16 11:23:30.014114: step 10389, loss = 0.61254 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:23:30.973252 ops/training.py:65 2019-01-16 11:23:30.973205: step 10390, loss = 0.60957 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:23:31.932343 ops/training.py:65 2019-01-16 11:23:31.932292: step 10391, loss = 0.53022 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:23:32.892572 ops/training.py:65 2019-01-16 11:23:32.892523: step 10392, loss = 0.63406 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:23:33.851167 ops/training.py:65 2019-01-16 11:23:33.851117: step 10393, loss = 0.64459 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:23:34.813340 ops/training.py:65 2019-01-16 11:23:34.813289: step 10394, loss = 0.65934 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:23:35.776693 ops/training.py:65 2019-01-16 11:23:35.776624: step 10395, loss = 0.62267 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:23:36.739292 ops/training.py:65 2019-01-16 11:23:36.739236: step 10396, loss = 0.68877 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:23:37.700796 ops/training.py:65 2019-01-16 11:23:37.700724: step 10397, loss = 0.57383 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:23:38.663365 ops/training.py:65 2019-01-16 11:23:38.663298: step 10398, loss = 0.60178 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:23:39.624619 ops/training.py:65 2019-01-16 11:23:39.624570: step 10399, loss = 0.53546 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:23:40.588189 ops/training.py:65 2019-01-16 11:23:40.588135: step 10400, loss = 0.54667 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:23:41.552377 ops/training.py:65 2019-01-16 11:23:41.552324: step 10401, loss = 0.72391 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:23:42.514831 ops/training.py:65 2019-01-16 11:23:42.514769: step 10402, loss = 0.64602 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:23:43.475864 ops/training.py:65 2019-01-16 11:23:43.475796: step 10403, loss = 0.58649 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:23:44.436258 ops/training.py:65 2019-01-16 11:23:44.436177: step 10404, loss = 0.58358 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:23:45.397859 ops/training.py:65 2019-01-16 11:23:45.397785: step 10405, loss = 0.59326 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:23:46.359299 ops/training.py:65 2019-01-16 11:23:46.359247: step 10406, loss = 0.60538 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:23:47.319983 ops/training.py:65 2019-01-16 11:23:47.319920: step 10407, loss = 0.63260 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:23:48.281753 ops/training.py:65 2019-01-16 11:23:48.281695: step 10408, loss = 0.69498 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:23:49.243529 ops/training.py:65 2019-01-16 11:23:49.243470: step 10409, loss = 0.50590 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:23:50.207283 ops/training.py:65 2019-01-16 11:23:50.207236: step 10410, loss = 0.53557 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:23:51.171108 ops/training.py:65 2019-01-16 11:23:51.171044: step 10411, loss = 0.55244 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:23:52.132331 ops/training.py:65 2019-01-16 11:23:52.132266: step 10412, loss = 0.61112 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:23:53.093610 ops/training.py:65 2019-01-16 11:23:53.093539: step 10413, loss = 0.66893 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:23:54.054975 ops/training.py:65 2019-01-16 11:23:54.054904: step 10414, loss = 0.58696 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:23:55.016699 ops/training.py:65 2019-01-16 11:23:55.016610: step 10415, loss = 0.64647 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:23:55.980877 ops/training.py:65 2019-01-16 11:23:55.980813: step 10416, loss = 0.58457 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:23:56.945595 ops/training.py:65 2019-01-16 11:23:56.945514: step 10417, loss = 0.79148 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:23:57.908008 ops/training.py:65 2019-01-16 11:23:57.907937: step 10418, loss = 0.73062 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:23:58.873246 ops/training.py:65 2019-01-16 11:23:58.873183: step 10419, loss = 0.55915 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:23:59.836711 ops/training.py:65 2019-01-16 11:23:59.836656: step 10420, loss = 0.56821 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:24:00.799269 ops/training.py:65 2019-01-16 11:24:00.799205: step 10421, loss = 0.60358 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:24:01.759960 ops/training.py:65 2019-01-16 11:24:01.759908: step 10422, loss = 0.61653 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:24:02.722119 ops/training.py:65 2019-01-16 11:24:02.722043: step 10423, loss = 0.56566 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:24:03.685197 ops/training.py:65 2019-01-16 11:24:03.685130: step 10424, loss = 0.57635 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:24:04.647205 ops/training.py:65 2019-01-16 11:24:04.647137: step 10425, loss = 0.46387 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:24:05.607479 ops/training.py:65 2019-01-16 11:24:05.607415: step 10426, loss = 0.55100 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:24:06.571339 ops/training.py:65 2019-01-16 11:24:06.571290: step 10427, loss = 0.59950 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:24:07.535092 ops/training.py:65 2019-01-16 11:24:07.535040: step 10428, loss = 0.49991 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:24:08.499420 ops/training.py:65 2019-01-16 11:24:08.499363: step 10429, loss = 0.66276 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:24:09.460086 ops/training.py:65 2019-01-16 11:24:09.460022: step 10430, loss = 0.58444 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:24:10.423411 ops/training.py:65 2019-01-16 11:24:10.423342: step 10431, loss = 0.67621 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:24:11.384900 ops/training.py:65 2019-01-16 11:24:11.384829: step 10432, loss = 0.47995 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:24:12.346339 ops/training.py:65 2019-01-16 11:24:12.346269: step 10433, loss = 0.58242 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:24:13.306125 ops/training.py:65 2019-01-16 11:24:13.306074: step 10434, loss = 0.54397 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:24:14.265608 ops/training.py:65 2019-01-16 11:24:14.265565: step 10435, loss = 0.52069 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:24:15.224436 ops/training.py:65 2019-01-16 11:24:15.224387: step 10436, loss = 0.73869 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:24:16.183440 ops/training.py:65 2019-01-16 11:24:16.183394: step 10437, loss = 0.61485 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:24:17.142730 ops/training.py:65 2019-01-16 11:24:17.142686: step 10438, loss = 0.65678 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:24:18.105130 ops/training.py:65 2019-01-16 11:24:18.105087: step 10439, loss = 0.60389 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:24:19.068432 ops/training.py:65 2019-01-16 11:24:19.068367: step 10440, loss = 0.55831 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:24:20.032083 ops/training.py:65 2019-01-16 11:24:20.032019: step 10441, loss = 0.65986 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:24:20.994030 ops/training.py:65 2019-01-16 11:24:20.993963: step 10442, loss = 0.66722 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:24:21.954651 ops/training.py:65 2019-01-16 11:24:21.954601: step 10443, loss = 0.67878 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:24:22.913827 ops/training.py:65 2019-01-16 11:24:22.913780: step 10444, loss = 0.52673 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:24:23.872615 ops/training.py:65 2019-01-16 11:24:23.872564: step 10445, loss = 0.51226 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:24:24.832051 ops/training.py:65 2019-01-16 11:24:24.832003: step 10446, loss = 0.68503 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:24:25.794516 ops/training.py:65 2019-01-16 11:24:25.794466: step 10447, loss = 0.55865 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:24:26.757403 ops/training.py:65 2019-01-16 11:24:26.757341: step 10448, loss = 0.65691 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:24:27.720086 ops/training.py:65 2019-01-16 11:24:27.720013: step 10449, loss = 0.67031 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:24:28.680655 ops/training.py:65 2019-01-16 11:24:28.680594: step 10450, loss = 0.67613 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:24:29.641762 ops/training.py:65 2019-01-16 11:24:29.641692: step 10451, loss = 0.64658 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:24:30.603598 ops/training.py:65 2019-01-16 11:24:30.603556: step 10452, loss = 0.66408 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:24:31.561838 ops/training.py:65 2019-01-16 11:24:31.561793: step 10453, loss = 0.63398 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:24:32.520297 ops/training.py:65 2019-01-16 11:24:32.520249: step 10454, loss = 0.57332 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:24:33.483592 ops/training.py:65 2019-01-16 11:24:33.483539: step 10455, loss = 0.66890 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:24:34.446700 ops/training.py:65 2019-01-16 11:24:34.446634: step 10456, loss = 0.55739 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:24:35.409448 ops/training.py:65 2019-01-16 11:24:35.409375: step 10457, loss = 0.62255 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:24:36.373478 ops/training.py:65 2019-01-16 11:24:36.373428: step 10458, loss = 0.66604 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:24:37.336711 ops/training.py:65 2019-01-16 11:24:37.336661: step 10459, loss = 0.59970 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:24:38.298644 ops/training.py:65 2019-01-16 11:24:38.298587: step 10460, loss = 0.66241 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:24:39.259073 ops/training.py:65 2019-01-16 11:24:39.259012: step 10461, loss = 0.63356 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:24:40.221077 ops/training.py:65 2019-01-16 11:24:40.221027: step 10462, loss = 0.72053 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:24:41.181179 ops/training.py:65 2019-01-16 11:24:41.181109: step 10463, loss = 0.57352 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:24:42.145590 ops/training.py:65 2019-01-16 11:24:42.145525: step 10464, loss = 0.70907 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:24:43.109356 ops/training.py:65 2019-01-16 11:24:43.109304: step 10465, loss = 0.53585 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:24:44.073948 ops/training.py:65 2019-01-16 11:24:44.073877: step 10466, loss = 0.63384 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:24:45.035081 ops/training.py:65 2019-01-16 11:24:45.035016: step 10467, loss = 0.53077 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:24:45.998180 ops/training.py:65 2019-01-16 11:24:45.998107: step 10468, loss = 0.68378 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:24:46.959218 ops/training.py:65 2019-01-16 11:24:46.959170: step 10469, loss = 0.72867 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:24:47.921845 ops/training.py:65 2019-01-16 11:24:47.921794: step 10470, loss = 0.69238 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:24:48.891284 ops/training.py:65 2019-01-16 11:24:48.891220: step 10471, loss = 0.68327 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:24:49.852948 ops/training.py:65 2019-01-16 11:24:49.852874: step 10472, loss = 0.57930 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:24:50.818480 ops/training.py:65 2019-01-16 11:24:50.818431: step 10473, loss = 0.80026 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:24:51.782023 ops/training.py:65 2019-01-16 11:24:51.781972: step 10474, loss = 0.55451 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:24:52.743563 ops/training.py:65 2019-01-16 11:24:52.743511: step 10475, loss = 0.68634 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:24:53.706212 ops/training.py:65 2019-01-16 11:24:53.706152: step 10476, loss = 0.58893 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:24:54.668088 ops/training.py:65 2019-01-16 11:24:54.668032: step 10477, loss = 0.55239 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:24:55.628991 ops/training.py:65 2019-01-16 11:24:55.628941: step 10478, loss = 0.62875 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:24:56.590545 ops/training.py:65 2019-01-16 11:24:56.590495: step 10479, loss = 0.65530 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:24:57.552224 ops/training.py:65 2019-01-16 11:24:57.552159: step 10480, loss = 0.58161 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:24:58.514292 ops/training.py:65 2019-01-16 11:24:58.514230: step 10481, loss = 0.63402 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:24:59.476803 ops/training.py:65 2019-01-16 11:24:59.476743: step 10482, loss = 0.57983 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:25:00.439222 ops/training.py:65 2019-01-16 11:25:00.439150: step 10483, loss = 0.59635 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:25:01.402900 ops/training.py:65 2019-01-16 11:25:01.402840: step 10484, loss = 0.58850 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:25:02.366071 ops/training.py:65 2019-01-16 11:25:02.366001: step 10485, loss = 0.58153 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:25:03.328114 ops/training.py:65 2019-01-16 11:25:03.328045: step 10486, loss = 0.57195 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:25:04.289627 ops/training.py:65 2019-01-16 11:25:04.289567: step 10487, loss = 0.64467 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:25:05.249938 ops/training.py:65 2019-01-16 11:25:05.249866: step 10488, loss = 0.64116 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:25:06.210367 ops/training.py:65 2019-01-16 11:25:06.210311: step 10489, loss = 0.54319 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:25:07.172145 ops/training.py:65 2019-01-16 11:25:07.172082: step 10490, loss = 0.67903 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:25:08.137195 ops/training.py:65 2019-01-16 11:25:08.137130: step 10491, loss = 0.54913 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:25:09.099130 ops/training.py:65 2019-01-16 11:25:09.099073: step 10492, loss = 0.51866 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:25:10.058999 ops/training.py:65 2019-01-16 11:25:10.058925: step 10493, loss = 0.48384 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:25:11.018613 ops/training.py:65 2019-01-16 11:25:11.018570: step 10494, loss = 0.67702 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:25:11.980902 ops/training.py:65 2019-01-16 11:25:11.980858: step 10495, loss = 0.56643 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:25:12.946248 ops/training.py:65 2019-01-16 11:25:12.946178: step 10496, loss = 0.52980 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:25:13.908591 ops/training.py:65 2019-01-16 11:25:13.908524: step 10497, loss = 0.66927 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:25:14.869352 ops/training.py:65 2019-01-16 11:25:14.869290: step 10498, loss = 0.59153 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:25:15.831590 ops/training.py:65 2019-01-16 11:25:15.831526: step 10499, loss = 0.49754 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:25:16.793265 ops/training.py:65 2019-01-16 11:25:16.793199: step 10500, loss = 0.65018 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:25:17.754406 ops/training.py:65 2019-01-16 11:25:17.754337: step 10501, loss = 0.59413 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:25:18.715129 ops/training.py:65 2019-01-16 11:25:18.715068: step 10502, loss = 0.56301 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:25:19.676224 ops/training.py:65 2019-01-16 11:25:19.676160: step 10503, loss = 0.55087 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:25:20.638220 ops/training.py:65 2019-01-16 11:25:20.638156: step 10504, loss = 0.61935 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:25:21.598317 ops/training.py:65 2019-01-16 11:25:21.598248: step 10505, loss = 0.57351 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:25:22.560638 ops/training.py:65 2019-01-16 11:25:22.560572: step 10506, loss = 0.68468 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:25:23.522821 ops/training.py:65 2019-01-16 11:25:23.522753: step 10507, loss = 0.56250 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:25:24.483707 ops/training.py:65 2019-01-16 11:25:24.483643: step 10508, loss = 0.65616 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:25:25.444664 ops/training.py:65 2019-01-16 11:25:25.444615: step 10509, loss = 0.65814 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:25:26.404577 ops/training.py:65 2019-01-16 11:25:26.404527: step 10510, loss = 0.63985 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:25:27.366188 ops/training.py:65 2019-01-16 11:25:27.366132: step 10511, loss = 0.56406 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:25:28.328396 ops/training.py:65 2019-01-16 11:25:28.328324: step 10512, loss = 0.49063 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:25:29.291946 ops/training.py:65 2019-01-16 11:25:29.291895: step 10513, loss = 0.69301 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:25:30.253748 ops/training.py:65 2019-01-16 11:25:30.253684: step 10514, loss = 0.48440 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 11:25:31.215910 ops/training.py:65 2019-01-16 11:25:31.215837: step 10515, loss = 0.59845 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:25:32.178832 ops/training.py:65 2019-01-16 11:25:32.178775: step 10516, loss = 0.57381 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:25:33.138756 ops/training.py:65 2019-01-16 11:25:33.138708: step 10517, loss = 0.58807 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:25:34.101892 ops/training.py:65 2019-01-16 11:25:34.101840: step 10518, loss = 0.53120 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:25:35.064159 ops/training.py:65 2019-01-16 11:25:35.064103: step 10519, loss = 0.79430 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:25:36.027192 ops/training.py:65 2019-01-16 11:25:36.027133: step 10520, loss = 0.56833 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:25:36.989873 ops/training.py:65 2019-01-16 11:25:36.989818: step 10521, loss = 0.60775 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:25:37.954119 ops/training.py:65 2019-01-16 11:25:37.954062: step 10522, loss = 0.63026 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:25:38.919307 ops/training.py:65 2019-01-16 11:25:38.919243: step 10523, loss = 0.57172 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:25:39.883706 ops/training.py:65 2019-01-16 11:25:39.883644: step 10524, loss = 0.52160 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:25:40.845134 ops/training.py:65 2019-01-16 11:25:40.845071: step 10525, loss = 0.60051 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:25:41.805676 ops/training.py:65 2019-01-16 11:25:41.805610: step 10526, loss = 0.70962 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:25:42.767382 ops/training.py:65 2019-01-16 11:25:42.767306: step 10527, loss = 0.60126 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:25:43.729778 ops/training.py:65 2019-01-16 11:25:43.729711: step 10528, loss = 0.57467 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:25:44.691574 ops/training.py:65 2019-01-16 11:25:44.691522: step 10529, loss = 0.44160 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 11:25:45.652931 ops/training.py:65 2019-01-16 11:25:45.652863: step 10530, loss = 0.56076 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:25:46.612940 ops/training.py:65 2019-01-16 11:25:46.612864: step 10531, loss = 0.57155 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:25:47.575598 ops/training.py:65 2019-01-16 11:25:47.575531: step 10532, loss = 0.57221 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:25:48.536997 ops/training.py:65 2019-01-16 11:25:48.536929: step 10533, loss = 0.65383 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:25:49.498430 ops/training.py:65 2019-01-16 11:25:49.498381: step 10534, loss = 0.43570 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:25:50.457405 ops/training.py:65 2019-01-16 11:25:50.457357: step 10535, loss = 0.59918 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:25:51.419400 ops/training.py:65 2019-01-16 11:25:51.419344: step 10536, loss = 0.66364 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:25:52.382795 ops/training.py:65 2019-01-16 11:25:52.382733: step 10537, loss = 0.69082 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:25:53.345941 ops/training.py:65 2019-01-16 11:25:53.345876: step 10538, loss = 0.55277 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:25:54.308312 ops/training.py:65 2019-01-16 11:25:54.308227: step 10539, loss = 0.52686 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:25:55.270419 ops/training.py:65 2019-01-16 11:25:55.270372: step 10540, loss = 0.56572 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:25:56.230694 ops/training.py:65 2019-01-16 11:25:56.230643: step 10541, loss = 0.60175 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:25:57.190491 ops/training.py:65 2019-01-16 11:25:57.190444: step 10542, loss = 0.60894 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:25:58.150488 ops/training.py:65 2019-01-16 11:25:58.150443: step 10543, loss = 0.70167 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:25:59.112835 ops/training.py:65 2019-01-16 11:25:59.112794: step 10544, loss = 0.57660 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:26:00.076670 ops/training.py:65 2019-01-16 11:26:00.076606: step 10545, loss = 0.56680 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:26:01.039550 ops/training.py:65 2019-01-16 11:26:01.039486: step 10546, loss = 0.61950 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:26:02.001515 ops/training.py:65 2019-01-16 11:26:02.001450: step 10547, loss = 0.48239 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:26:02.962572 ops/training.py:65 2019-01-16 11:26:02.962527: step 10548, loss = 0.67156 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:26:03.920484 ops/training.py:65 2019-01-16 11:26:03.920441: step 10549, loss = 0.70057 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:26:04.879714 ops/training.py:65 2019-01-16 11:26:04.879669: step 10550, loss = 0.55327 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:26:05.843134 ops/training.py:65 2019-01-16 11:26:05.843089: step 10551, loss = 0.68690 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:26:06.806849 ops/training.py:65 2019-01-16 11:26:06.806795: step 10552, loss = 0.73896 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:26:07.770501 ops/training.py:65 2019-01-16 11:26:07.770444: step 10553, loss = 0.51295 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:26:08.732871 ops/training.py:65 2019-01-16 11:26:08.732809: step 10554, loss = 0.61703 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:26:09.693931 ops/training.py:65 2019-01-16 11:26:09.693871: step 10555, loss = 0.69487 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:26:10.655828 ops/training.py:65 2019-01-16 11:26:10.655779: step 10556, loss = 0.68577 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:26:11.616970 ops/training.py:65 2019-01-16 11:26:11.616913: step 10557, loss = 0.58271 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:26:12.577787 ops/training.py:65 2019-01-16 11:26:12.577736: step 10558, loss = 0.57091 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:26:13.538798 ops/training.py:65 2019-01-16 11:26:13.538747: step 10559, loss = 0.61961 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:26:14.500437 ops/training.py:65 2019-01-16 11:26:14.500369: step 10560, loss = 0.67676 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:26:15.461725 ops/training.py:65 2019-01-16 11:26:15.461661: step 10561, loss = 0.51291 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:26:16.423254 ops/training.py:65 2019-01-16 11:26:16.423185: step 10562, loss = 0.51349 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:26:17.384174 ops/training.py:65 2019-01-16 11:26:17.384118: step 10563, loss = 0.60155 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:26:18.344398 ops/training.py:65 2019-01-16 11:26:18.344335: step 10564, loss = 0.69665 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:26:19.306611 ops/training.py:65 2019-01-16 11:26:19.306551: step 10565, loss = 0.58534 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:26:20.275896 ops/training.py:65 2019-01-16 11:26:20.275813: step 10566, loss = 0.52585 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:26:21.241621 ops/training.py:65 2019-01-16 11:26:21.241554: step 10567, loss = 0.59287 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:26:22.203799 ops/training.py:65 2019-01-16 11:26:22.203731: step 10568, loss = 0.74992 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:26:23.168293 ops/training.py:65 2019-01-16 11:26:23.168247: step 10569, loss = 0.60726 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:26:24.131105 ops/training.py:65 2019-01-16 11:26:24.131040: step 10570, loss = 0.44596 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:26:25.096376 ops/training.py:65 2019-01-16 11:26:25.096314: step 10571, loss = 0.75908 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:26:26.059324 ops/training.py:65 2019-01-16 11:26:26.059243: step 10572, loss = 0.62532 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:26:27.019338 ops/training.py:65 2019-01-16 11:26:27.019272: step 10573, loss = 0.63779 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:26:27.983902 ops/training.py:65 2019-01-16 11:26:27.983855: step 10574, loss = 0.58829 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:26:28.946983 ops/training.py:65 2019-01-16 11:26:28.946931: step 10575, loss = 0.48109 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:26:29.907417 ops/training.py:65 2019-01-16 11:26:29.907352: step 10576, loss = 0.70667 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:26:30.869141 ops/training.py:65 2019-01-16 11:26:30.869075: step 10577, loss = 0.47185 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:26:31.830694 ops/training.py:65 2019-01-16 11:26:31.830644: step 10578, loss = 0.71904 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:26:32.790230 ops/training.py:65 2019-01-16 11:26:32.790183: step 10579, loss = 0.65559 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:26:33.748491 ops/training.py:65 2019-01-16 11:26:33.748447: step 10580, loss = 0.58761 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:26:34.706394 ops/training.py:65 2019-01-16 11:26:34.706346: step 10581, loss = 0.73994 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:26:35.668032 ops/training.py:65 2019-01-16 11:26:35.667990: step 10582, loss = 0.62272 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:26:36.631133 ops/training.py:65 2019-01-16 11:26:36.631081: step 10583, loss = 0.65648 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:26:37.591346 ops/training.py:65 2019-01-16 11:26:37.591281: step 10584, loss = 0.53434 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:26:38.556581 ops/training.py:65 2019-01-16 11:26:38.556530: step 10585, loss = 0.50592 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:26:39.519670 ops/training.py:65 2019-01-16 11:26:39.519601: step 10586, loss = 0.71034 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:26:40.480157 ops/training.py:65 2019-01-16 11:26:40.480107: step 10587, loss = 0.50302 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:26:41.437999 ops/training.py:65 2019-01-16 11:26:41.437945: step 10588, loss = 0.74654 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:26:42.395656 ops/training.py:65 2019-01-16 11:26:42.395608: step 10589, loss = 0.63684 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:26:43.358624 ops/training.py:65 2019-01-16 11:26:43.358585: step 10590, loss = 0.69685 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:26:44.322496 ops/training.py:65 2019-01-16 11:26:44.322432: step 10591, loss = 0.66463 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:26:45.284728 ops/training.py:65 2019-01-16 11:26:45.284653: step 10592, loss = 0.55983 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:26:46.245359 ops/training.py:65 2019-01-16 11:26:46.245308: step 10593, loss = 0.71114 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:26:47.205730 ops/training.py:65 2019-01-16 11:26:47.205655: step 10594, loss = 0.58138 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:26:48.167048 ops/training.py:65 2019-01-16 11:26:48.167001: step 10595, loss = 0.73056 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:26:49.124654 ops/training.py:65 2019-01-16 11:26:49.124612: step 10596, loss = 0.66052 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:26:50.082232 ops/training.py:65 2019-01-16 11:26:50.082186: step 10597, loss = 0.62341 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:26:51.045217 ops/training.py:65 2019-01-16 11:26:51.045178: step 10598, loss = 0.65648 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:26:52.008741 ops/training.py:65 2019-01-16 11:26:52.008692: step 10599, loss = 0.59283 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:26:52.971793 ops/training.py:65 2019-01-16 11:26:52.971745: step 10600, loss = 0.64067 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:26:53.934087 ops/training.py:65 2019-01-16 11:26:53.934039: step 10601, loss = 0.59232 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:26:54.895847 ops/training.py:65 2019-01-16 11:26:54.895777: step 10602, loss = 0.57166 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:26:55.856369 ops/training.py:65 2019-01-16 11:26:55.856300: step 10603, loss = 0.63263 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:26:56.817074 ops/training.py:65 2019-01-16 11:26:56.817008: step 10604, loss = 0.65062 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:26:57.780941 ops/training.py:65 2019-01-16 11:26:57.780889: step 10605, loss = 0.63158 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:26:58.744644 ops/training.py:65 2019-01-16 11:26:58.744583: step 10606, loss = 0.61245 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:26:59.708332 ops/training.py:65 2019-01-16 11:26:59.708267: step 10607, loss = 0.58355 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:27:00.669387 ops/training.py:65 2019-01-16 11:27:00.669325: step 10608, loss = 0.64617 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:27:01.629395 ops/training.py:65 2019-01-16 11:27:01.629341: step 10609, loss = 0.59358 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:27:02.591511 ops/training.py:65 2019-01-16 11:27:02.591441: step 10610, loss = 0.54212 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:27:03.554623 ops/training.py:65 2019-01-16 11:27:03.554569: step 10611, loss = 0.58607 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:27:04.518121 ops/training.py:65 2019-01-16 11:27:04.518058: step 10612, loss = 0.64744 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:27:05.480046 ops/training.py:65 2019-01-16 11:27:05.479906: step 10613, loss = 0.65412 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:27:06.441382 ops/training.py:65 2019-01-16 11:27:06.441329: step 10614, loss = 0.56942 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:27:07.403933 ops/training.py:65 2019-01-16 11:27:07.403863: step 10615, loss = 0.64922 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:27:08.365204 ops/training.py:65 2019-01-16 11:27:08.365156: step 10616, loss = 0.56115 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:27:09.326522 ops/training.py:65 2019-01-16 11:27:09.326477: step 10617, loss = 0.57808 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:27:10.288995 ops/training.py:65 2019-01-16 11:27:10.288939: step 10618, loss = 0.63814 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:27:11.253712 ops/training.py:65 2019-01-16 11:27:11.253651: step 10619, loss = 0.48304 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:27:12.216782 ops/training.py:65 2019-01-16 11:27:12.216700: step 10620, loss = 0.53311 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:27:13.177014 ops/training.py:65 2019-01-16 11:27:13.176951: step 10621, loss = 0.50531 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 11:27:14.138555 ops/training.py:65 2019-01-16 11:27:14.138487: step 10622, loss = 0.55396 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:27:15.098878 ops/training.py:65 2019-01-16 11:27:15.098807: step 10623, loss = 0.63962 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:27:16.058961 ops/training.py:65 2019-01-16 11:27:16.058913: step 10624, loss = 0.57198 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:27:17.016879 ops/training.py:65 2019-01-16 11:27:17.016833: step 10625, loss = 0.66762 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:27:17.978237 ops/training.py:65 2019-01-16 11:27:17.978192: step 10626, loss = 0.57486 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:27:18.942016 ops/training.py:65 2019-01-16 11:27:18.941955: step 10627, loss = 0.52845 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:27:19.904387 ops/training.py:65 2019-01-16 11:27:19.904322: step 10628, loss = 0.60563 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:27:20.865376 ops/training.py:65 2019-01-16 11:27:20.865321: step 10629, loss = 0.54823 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:27:21.825256 ops/training.py:65 2019-01-16 11:27:21.825207: step 10630, loss = 0.56014 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:27:22.786749 ops/training.py:65 2019-01-16 11:27:22.786691: step 10631, loss = 0.68448 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:27:23.749287 ops/training.py:65 2019-01-16 11:27:23.749229: step 10632, loss = 0.59391 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:27:24.710026 ops/training.py:65 2019-01-16 11:27:24.709962: step 10633, loss = 0.68894 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:27:25.671278 ops/training.py:65 2019-01-16 11:27:25.671213: step 10634, loss = 0.57172 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:27:26.632128 ops/training.py:65 2019-01-16 11:27:26.632061: step 10635, loss = 0.60473 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:27:27.592614 ops/training.py:65 2019-01-16 11:27:27.592549: step 10636, loss = 0.67397 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:27:28.554444 ops/training.py:65 2019-01-16 11:27:28.554385: step 10637, loss = 0.57711 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:27:29.516322 ops/training.py:65 2019-01-16 11:27:29.516257: step 10638, loss = 0.65285 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:27:30.477638 ops/training.py:65 2019-01-16 11:27:30.477573: step 10639, loss = 0.60748 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:27:31.438142 ops/training.py:65 2019-01-16 11:27:31.438073: step 10640, loss = 0.64179 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:27:32.398799 ops/training.py:65 2019-01-16 11:27:32.398740: step 10641, loss = 0.78290 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 11:27:33.359987 ops/training.py:65 2019-01-16 11:27:33.359917: step 10642, loss = 0.68776 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:27:34.321800 ops/training.py:65 2019-01-16 11:27:34.321735: step 10643, loss = 0.56950 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:27:35.282482 ops/training.py:65 2019-01-16 11:27:35.282430: step 10644, loss = 0.53024 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:27:36.241118 ops/training.py:65 2019-01-16 11:27:36.241069: step 10645, loss = 0.72404 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:27:37.201392 ops/training.py:65 2019-01-16 11:27:37.201329: step 10646, loss = 0.71278 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:27:38.161084 ops/training.py:65 2019-01-16 11:27:38.161034: step 10647, loss = 0.60811 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:27:39.120016 ops/training.py:65 2019-01-16 11:27:39.119967: step 10648, loss = 0.54949 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:27:40.080125 ops/training.py:65 2019-01-16 11:27:40.080081: step 10649, loss = 0.68086 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:27:41.038932 ops/training.py:65 2019-01-16 11:27:41.038886: step 10650, loss = 0.62053 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:27:41.998248 ops/training.py:65 2019-01-16 11:27:41.998195: step 10651, loss = 0.64900 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:27:42.960729 ops/training.py:65 2019-01-16 11:27:42.960679: step 10652, loss = 0.58425 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:27:43.922533 ops/training.py:65 2019-01-16 11:27:43.922474: step 10653, loss = 0.49524 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:27:44.883801 ops/training.py:65 2019-01-16 11:27:44.883738: step 10654, loss = 0.66723 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:27:45.848073 ops/training.py:65 2019-01-16 11:27:45.848029: step 10655, loss = 0.53845 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:27:46.810942 ops/training.py:65 2019-01-16 11:27:46.810872: step 10656, loss = 0.46456 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:27:47.774949 ops/training.py:65 2019-01-16 11:27:47.774887: step 10657, loss = 0.62489 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:27:48.735567 ops/training.py:65 2019-01-16 11:27:48.735520: step 10658, loss = 0.57590 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:27:49.693691 ops/training.py:65 2019-01-16 11:27:49.693643: step 10659, loss = 0.66517 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:27:50.658352 ops/training.py:65 2019-01-16 11:27:50.658312: step 10660, loss = 0.44475 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:27:51.621756 ops/training.py:65 2019-01-16 11:27:51.621729: step 10661, loss = 0.61089 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:27:52.582838 ops/training.py:65 2019-01-16 11:27:52.582811: step 10662, loss = 0.59671 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:27:53.542778 ops/training.py:65 2019-01-16 11:27:53.542719: step 10663, loss = 0.69997 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:27:54.502192 ops/training.py:65 2019-01-16 11:27:54.502150: step 10664, loss = 0.58531 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:27:55.464835 ops/training.py:65 2019-01-16 11:27:55.464805: step 10665, loss = 0.55848 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:27:56.428630 ops/training.py:65 2019-01-16 11:27:56.428603: step 10666, loss = 0.61881 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:27:57.389577 ops/training.py:65 2019-01-16 11:27:57.389548: step 10667, loss = 0.69817 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:27:58.354182 ops/training.py:65 2019-01-16 11:27:58.354154: step 10668, loss = 0.61385 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:27:59.317452 ops/training.py:65 2019-01-16 11:27:59.317426: step 10669, loss = 0.71708 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:28:00.278171 ops/training.py:65 2019-01-16 11:28:00.278143: step 10670, loss = 0.56224 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:28:01.236949 ops/training.py:65 2019-01-16 11:28:01.236881: step 10671, loss = 0.67430 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:28:02.196763 ops/training.py:65 2019-01-16 11:28:02.196713: step 10672, loss = 0.53721 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:28:03.158748 ops/training.py:65 2019-01-16 11:28:03.158698: step 10673, loss = 0.53498 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:28:04.123344 ops/training.py:65 2019-01-16 11:28:04.123277: step 10674, loss = 0.50898 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:28:05.084124 ops/training.py:65 2019-01-16 11:28:05.084051: step 10675, loss = 0.69823 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:28:06.045191 ops/training.py:65 2019-01-16 11:28:06.045122: step 10676, loss = 0.65048 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:28:07.006377 ops/training.py:65 2019-01-16 11:28:07.006323: step 10677, loss = 0.62624 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:28:07.967452 ops/training.py:65 2019-01-16 11:28:07.967381: step 10678, loss = 0.63132 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:28:08.930141 ops/training.py:65 2019-01-16 11:28:08.930072: step 10679, loss = 0.75019 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:28:09.893898 ops/training.py:65 2019-01-16 11:28:09.893841: step 10680, loss = 0.60313 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:28:10.857090 ops/training.py:65 2019-01-16 11:28:10.857041: step 10681, loss = 0.59546 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:28:11.818296 ops/training.py:65 2019-01-16 11:28:11.818243: step 10682, loss = 0.64140 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:28:12.780106 ops/training.py:65 2019-01-16 11:28:12.780052: step 10683, loss = 0.60702 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:28:13.742955 ops/training.py:65 2019-01-16 11:28:13.742889: step 10684, loss = 0.62393 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:28:14.704938 ops/training.py:65 2019-01-16 11:28:14.704886: step 10685, loss = 0.65820 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:28:15.667137 ops/training.py:65 2019-01-16 11:28:15.667065: step 10686, loss = 0.60171 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:28:16.628940 ops/training.py:65 2019-01-16 11:28:16.628866: step 10687, loss = 0.58454 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:28:17.590261 ops/training.py:65 2019-01-16 11:28:17.590192: step 10688, loss = 0.63278 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:28:18.551350 ops/training.py:65 2019-01-16 11:28:18.551306: step 10689, loss = 0.58014 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:28:19.514570 ops/training.py:65 2019-01-16 11:28:19.514511: step 10690, loss = 0.69034 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:28:20.477816 ops/training.py:65 2019-01-16 11:28:20.477744: step 10691, loss = 0.54612 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:28:21.441281 ops/training.py:65 2019-01-16 11:28:21.441206: step 10692, loss = 0.57642 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:28:22.402023 ops/training.py:65 2019-01-16 11:28:22.401954: step 10693, loss = 0.67771 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:28:23.363625 ops/training.py:65 2019-01-16 11:28:23.363554: step 10694, loss = 0.68232 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:28:24.324952 ops/training.py:65 2019-01-16 11:28:24.324895: step 10695, loss = 0.61756 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:28:25.285493 ops/training.py:65 2019-01-16 11:28:25.285426: step 10696, loss = 0.66082 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:28:26.245191 ops/training.py:65 2019-01-16 11:28:26.245123: step 10697, loss = 0.65268 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:28:27.206004 ops/training.py:65 2019-01-16 11:28:27.205939: step 10698, loss = 0.67424 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:28:28.166830 ops/training.py:65 2019-01-16 11:28:28.166760: step 10699, loss = 0.54502 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:28:29.127858 ops/training.py:65 2019-01-16 11:28:29.127799: step 10700, loss = 0.58434 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:28:30.089141 ops/training.py:65 2019-01-16 11:28:30.089086: step 10701, loss = 0.72430 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:28:31.050262 ops/training.py:65 2019-01-16 11:28:31.050196: step 10702, loss = 0.52901 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:28:32.011117 ops/training.py:65 2019-01-16 11:28:32.011048: step 10703, loss = 0.69088 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:28:32.972366 ops/training.py:65 2019-01-16 11:28:32.972298: step 10704, loss = 0.69696 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:28:33.933046 ops/training.py:65 2019-01-16 11:28:33.932982: step 10705, loss = 0.73733 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:28:34.896398 ops/training.py:65 2019-01-16 11:28:34.896330: step 10706, loss = 0.62334 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:28:35.858945 ops/training.py:65 2019-01-16 11:28:35.858900: step 10707, loss = 0.57493 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:28:36.818068 ops/training.py:65 2019-01-16 11:28:36.818019: step 10708, loss = 0.63074 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:28:37.783849 ops/training.py:65 2019-01-16 11:28:37.783796: step 10709, loss = 0.66812 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:28:38.748532 ops/training.py:65 2019-01-16 11:28:38.748478: step 10710, loss = 0.63882 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:28:39.709645 ops/training.py:65 2019-01-16 11:28:39.709577: step 10711, loss = 0.60705 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:28:40.670533 ops/training.py:65 2019-01-16 11:28:40.670474: step 10712, loss = 0.64733 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:28:41.635182 ops/training.py:65 2019-01-16 11:28:41.635137: step 10713, loss = 0.60652 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:28:42.597894 ops/training.py:65 2019-01-16 11:28:42.597863: step 10714, loss = 0.58743 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:28:43.559221 ops/training.py:65 2019-01-16 11:28:43.559182: step 10715, loss = 0.64382 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:28:44.520166 ops/training.py:65 2019-01-16 11:28:44.520132: step 10716, loss = 0.60675 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:28:45.480615 ops/training.py:65 2019-01-16 11:28:45.480574: step 10717, loss = 0.54752 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:28:46.441577 ops/training.py:65 2019-01-16 11:28:46.441548: step 10718, loss = 0.64876 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:28:47.402350 ops/training.py:65 2019-01-16 11:28:47.402317: step 10719, loss = 0.56779 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:28:48.363896 ops/training.py:65 2019-01-16 11:28:48.363869: step 10720, loss = 0.61348 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:28:49.324237 ops/training.py:65 2019-01-16 11:28:49.324208: step 10721, loss = 0.59313 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:28:50.284704 ops/training.py:65 2019-01-16 11:28:50.284677: step 10722, loss = 0.63468 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:28:51.244710 ops/training.py:65 2019-01-16 11:28:51.244666: step 10723, loss = 0.60586 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:28:52.205400 ops/training.py:65 2019-01-16 11:28:52.205368: step 10724, loss = 0.60086 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:28:53.165880 ops/training.py:65 2019-01-16 11:28:53.165851: step 10725, loss = 0.66227 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:28:54.127674 ops/training.py:65 2019-01-16 11:28:54.127631: step 10726, loss = 0.65500 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:28:55.089604 ops/training.py:65 2019-01-16 11:28:55.089555: step 10727, loss = 0.61258 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:28:56.050719 ops/training.py:65 2019-01-16 11:28:56.050659: step 10728, loss = 0.52132 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:28:57.012190 ops/training.py:65 2019-01-16 11:28:57.012139: step 10729, loss = 0.65979 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:28:57.974674 ops/training.py:65 2019-01-16 11:28:57.974628: step 10730, loss = 0.53398 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:28:58.936851 ops/training.py:65 2019-01-16 11:28:58.936794: step 10731, loss = 0.58244 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:28:59.902103 ops/training.py:65 2019-01-16 11:28:59.902040: step 10732, loss = 0.65062 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:29:00.866610 ops/training.py:65 2019-01-16 11:29:00.866546: step 10733, loss = 0.61056 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:29:01.830155 ops/training.py:65 2019-01-16 11:29:01.830089: step 10734, loss = 0.63151 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:29:02.790971 ops/training.py:65 2019-01-16 11:29:02.790903: step 10735, loss = 0.52811 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:29:03.752675 ops/training.py:65 2019-01-16 11:29:03.752611: step 10736, loss = 0.69020 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:29:04.715234 ops/training.py:65 2019-01-16 11:29:04.715170: step 10737, loss = 0.62642 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:29:05.676756 ops/training.py:65 2019-01-16 11:29:05.676695: step 10738, loss = 0.83833 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 11:29:06.640466 ops/training.py:65 2019-01-16 11:29:06.640412: step 10739, loss = 0.60969 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:29:07.604296 ops/training.py:65 2019-01-16 11:29:07.604228: step 10740, loss = 0.58909 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:29:08.567292 ops/training.py:65 2019-01-16 11:29:08.567235: step 10741, loss = 0.63703 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:29:09.528622 ops/training.py:65 2019-01-16 11:29:09.528558: step 10742, loss = 0.61964 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:29:10.489904 ops/training.py:65 2019-01-16 11:29:10.489852: step 10743, loss = 0.81449 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 11:29:11.450770 ops/training.py:65 2019-01-16 11:29:11.450700: step 10744, loss = 0.59015 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:29:12.415399 ops/training.py:65 2019-01-16 11:29:12.415341: step 10745, loss = 0.53058 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:29:13.376034 ops/training.py:65 2019-01-16 11:29:13.375964: step 10746, loss = 0.71707 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:29:14.340009 ops/training.py:65 2019-01-16 11:29:14.339940: step 10747, loss = 0.62487 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:29:15.303640 ops/training.py:65 2019-01-16 11:29:15.303570: step 10748, loss = 0.55302 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:29:16.268348 ops/training.py:65 2019-01-16 11:29:16.268278: step 10749, loss = 0.75923 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:29:17.228896 ops/training.py:65 2019-01-16 11:29:17.228835: step 10750, loss = 0.69156 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:29:18.189684 ops/training.py:65 2019-01-16 11:29:18.189618: step 10751, loss = 0.73381 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:29:19.151881 ops/training.py:65 2019-01-16 11:29:19.151822: step 10752, loss = 0.65255 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:29:20.111800 ops/training.py:65 2019-01-16 11:29:20.111735: step 10753, loss = 0.59130 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:29:21.082875 ops/training.py:65 2019-01-16 11:29:21.082811: step 10754, loss = 0.70233 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:29:22.057245 ops/training.py:65 2019-01-16 11:29:22.057158: step 10755, loss = 0.61925 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:29:23.020928 ops/training.py:65 2019-01-16 11:29:23.020856: step 10756, loss = 0.47769 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 11:29:23.982816 ops/training.py:65 2019-01-16 11:29:23.982767: step 10757, loss = 0.69072 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:29:24.944798 ops/training.py:65 2019-01-16 11:29:24.944751: step 10758, loss = 0.59189 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:29:25.906044 ops/training.py:65 2019-01-16 11:29:25.905995: step 10759, loss = 0.73040 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:29:26.866997 ops/training.py:65 2019-01-16 11:29:26.866905: step 10760, loss = 0.70115 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:29:27.831506 ops/training.py:65 2019-01-16 11:29:27.831441: step 10761, loss = 0.53746 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:29:28.796462 ops/training.py:65 2019-01-16 11:29:28.796389: step 10762, loss = 0.67728 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:29:29.760753 ops/training.py:65 2019-01-16 11:29:29.760678: step 10763, loss = 0.57510 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:29:30.724018 ops/training.py:65 2019-01-16 11:29:30.723950: step 10764, loss = 0.55149 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:29:31.685546 ops/training.py:65 2019-01-16 11:29:31.685479: step 10765, loss = 0.62966 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:29:32.647010 ops/training.py:65 2019-01-16 11:29:32.646958: step 10766, loss = 0.59388 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:29:33.609592 ops/training.py:65 2019-01-16 11:29:33.609544: step 10767, loss = 0.59457 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:29:34.574570 ops/training.py:65 2019-01-16 11:29:34.574520: step 10768, loss = 0.48921 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:29:35.538147 ops/training.py:65 2019-01-16 11:29:35.538083: step 10769, loss = 0.60293 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:29:36.502217 ops/training.py:65 2019-01-16 11:29:36.502161: step 10770, loss = 0.62636 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:29:37.463718 ops/training.py:65 2019-01-16 11:29:37.463650: step 10771, loss = 0.54500 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:29:38.425780 ops/training.py:65 2019-01-16 11:29:38.425710: step 10772, loss = 0.67213 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:29:39.387031 ops/training.py:65 2019-01-16 11:29:39.386963: step 10773, loss = 0.60792 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:29:40.349618 ops/training.py:65 2019-01-16 11:29:40.349560: step 10774, loss = 0.56609 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:29:41.311245 ops/training.py:65 2019-01-16 11:29:41.311196: step 10775, loss = 0.53065 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:29:42.271877 ops/training.py:65 2019-01-16 11:29:42.271819: step 10776, loss = 0.50606 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:29:43.232809 ops/training.py:65 2019-01-16 11:29:43.232742: step 10777, loss = 0.66752 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:29:44.193679 ops/training.py:65 2019-01-16 11:29:44.193613: step 10778, loss = 0.65230 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:29:45.155350 ops/training.py:65 2019-01-16 11:29:45.155280: step 10779, loss = 0.63676 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:29:46.116696 ops/training.py:65 2019-01-16 11:29:46.116610: step 10780, loss = 0.57865 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:29:47.078861 ops/training.py:65 2019-01-16 11:29:47.078775: step 10781, loss = 0.62247 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:29:48.040683 ops/training.py:65 2019-01-16 11:29:48.040630: step 10782, loss = 0.56371 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:29:49.001646 ops/training.py:65 2019-01-16 11:29:49.001575: step 10783, loss = 0.62993 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:29:49.962950 ops/training.py:65 2019-01-16 11:29:49.962883: step 10784, loss = 0.56663 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:29:50.925230 ops/training.py:65 2019-01-16 11:29:50.925154: step 10785, loss = 0.58600 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:29:51.886773 ops/training.py:65 2019-01-16 11:29:51.886702: step 10786, loss = 0.55520 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:29:52.848542 ops/training.py:65 2019-01-16 11:29:52.848468: step 10787, loss = 0.63363 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:29:53.809576 ops/training.py:65 2019-01-16 11:29:53.809503: step 10788, loss = 0.69382 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:29:54.774053 ops/training.py:65 2019-01-16 11:29:54.773984: step 10789, loss = 0.64124 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:29:55.738572 ops/training.py:65 2019-01-16 11:29:55.738501: step 10790, loss = 0.69270 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:29:56.701577 ops/training.py:65 2019-01-16 11:29:56.701508: step 10791, loss = 0.61612 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:29:57.661611 ops/training.py:65 2019-01-16 11:29:57.661559: step 10792, loss = 0.48844 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:29:58.622801 ops/training.py:65 2019-01-16 11:29:58.622744: step 10793, loss = 0.64835 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:29:59.583837 ops/training.py:65 2019-01-16 11:29:59.583779: step 10794, loss = 0.62391 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:30:00.544262 ops/training.py:65 2019-01-16 11:30:00.544199: step 10795, loss = 0.49762 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:30:01.504914 ops/training.py:65 2019-01-16 11:30:01.504862: step 10796, loss = 0.58799 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:30:02.465559 ops/training.py:65 2019-01-16 11:30:02.465499: step 10797, loss = 0.85353 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.34375
I0832 2019-01-16 11:30:03.426629 ops/training.py:65 2019-01-16 11:30:03.426560: step 10798, loss = 0.68342 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:30:04.387922 ops/training.py:65 2019-01-16 11:30:04.387873: step 10799, loss = 0.47271 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:30:05.348835 ops/training.py:65 2019-01-16 11:30:05.348775: step 10800, loss = 0.48581 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:30:06.310141 ops/training.py:65 2019-01-16 11:30:06.310087: step 10801, loss = 0.57021 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:30:07.271289 ops/training.py:65 2019-01-16 11:30:07.271220: step 10802, loss = 0.61226 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:30:08.232803 ops/training.py:65 2019-01-16 11:30:08.232729: step 10803, loss = 0.64408 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:30:09.194951 ops/training.py:65 2019-01-16 11:30:09.194889: step 10804, loss = 0.53706 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:30:10.156351 ops/training.py:65 2019-01-16 11:30:10.156283: step 10805, loss = 0.64738 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:30:11.117279 ops/training.py:65 2019-01-16 11:30:11.117230: step 10806, loss = 0.58070 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:30:12.079002 ops/training.py:65 2019-01-16 11:30:12.078931: step 10807, loss = 0.61420 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:30:13.039690 ops/training.py:65 2019-01-16 11:30:13.039641: step 10808, loss = 0.60830 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:30:14.001223 ops/training.py:65 2019-01-16 11:30:14.001173: step 10809, loss = 0.55222 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:30:14.963512 ops/training.py:65 2019-01-16 11:30:14.963463: step 10810, loss = 0.50635 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:30:15.925737 ops/training.py:65 2019-01-16 11:30:15.925685: step 10811, loss = 0.70863 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:30:16.887058 ops/training.py:65 2019-01-16 11:30:16.887010: step 10812, loss = 0.63052 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:30:17.848410 ops/training.py:65 2019-01-16 11:30:17.848353: step 10813, loss = 0.65474 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:30:18.809523 ops/training.py:65 2019-01-16 11:30:18.809458: step 10814, loss = 0.74340 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:30:19.770443 ops/training.py:65 2019-01-16 11:30:19.770394: step 10815, loss = 0.54107 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:30:20.732164 ops/training.py:65 2019-01-16 11:30:20.732097: step 10816, loss = 0.59442 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:30:21.692274 ops/training.py:65 2019-01-16 11:30:21.692215: step 10817, loss = 0.55732 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:30:22.653637 ops/training.py:65 2019-01-16 11:30:22.653569: step 10818, loss = 0.65264 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:30:23.615457 ops/training.py:65 2019-01-16 11:30:23.615391: step 10819, loss = 0.55705 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:30:24.577251 ops/training.py:65 2019-01-16 11:30:24.577195: step 10820, loss = 0.58315 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:30:25.539233 ops/training.py:65 2019-01-16 11:30:25.539168: step 10821, loss = 0.60598 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:30:26.501091 ops/training.py:65 2019-01-16 11:30:26.501025: step 10822, loss = 0.62118 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:30:27.462239 ops/training.py:65 2019-01-16 11:30:27.462171: step 10823, loss = 0.56765 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:30:28.423978 ops/training.py:65 2019-01-16 11:30:28.423923: step 10824, loss = 0.57543 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:30:29.387857 ops/training.py:65 2019-01-16 11:30:29.387789: step 10825, loss = 0.59092 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:30:30.350291 ops/training.py:65 2019-01-16 11:30:30.350219: step 10826, loss = 0.62244 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:30:31.315630 ops/training.py:65 2019-01-16 11:30:31.315561: step 10827, loss = 0.54506 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:30:32.279937 ops/training.py:65 2019-01-16 11:30:32.279869: step 10828, loss = 0.55623 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:30:33.243891 ops/training.py:65 2019-01-16 11:30:33.243843: step 10829, loss = 0.68860 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:30:34.206673 ops/training.py:65 2019-01-16 11:30:34.206625: step 10830, loss = 0.61384 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:30:35.168369 ops/training.py:65 2019-01-16 11:30:35.168317: step 10831, loss = 0.52921 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:30:36.130404 ops/training.py:65 2019-01-16 11:30:36.130340: step 10832, loss = 0.61562 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:30:37.091435 ops/training.py:65 2019-01-16 11:30:37.091370: step 10833, loss = 0.57265 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:30:38.054759 ops/training.py:65 2019-01-16 11:30:38.054709: step 10834, loss = 0.61100 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:30:39.018017 ops/training.py:65 2019-01-16 11:30:39.017958: step 10835, loss = 0.56795 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:30:39.981661 ops/training.py:65 2019-01-16 11:30:39.981617: step 10836, loss = 0.56634 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:30:40.945191 ops/training.py:65 2019-01-16 11:30:40.945145: step 10837, loss = 0.63830 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:30:41.906204 ops/training.py:65 2019-01-16 11:30:41.906157: step 10838, loss = 0.71726 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:30:42.868007 ops/training.py:65 2019-01-16 11:30:42.867938: step 10839, loss = 0.62984 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:30:43.831423 ops/training.py:65 2019-01-16 11:30:43.831361: step 10840, loss = 0.62307 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:30:44.792359 ops/training.py:65 2019-01-16 11:30:44.792286: step 10841, loss = 0.65341 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:30:45.753082 ops/training.py:65 2019-01-16 11:30:45.753011: step 10842, loss = 0.58582 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:30:46.714593 ops/training.py:65 2019-01-16 11:30:46.714525: step 10843, loss = 0.61946 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:30:47.676787 ops/training.py:65 2019-01-16 11:30:47.676710: step 10844, loss = 0.52970 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:30:48.639172 ops/training.py:65 2019-01-16 11:30:48.639111: step 10845, loss = 0.59137 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:30:49.599390 ops/training.py:65 2019-01-16 11:30:49.599326: step 10846, loss = 0.53969 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:30:50.563309 ops/training.py:65 2019-01-16 11:30:50.563241: step 10847, loss = 0.51805 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:30:51.525772 ops/training.py:65 2019-01-16 11:30:51.525701: step 10848, loss = 0.48137 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:30:52.487955 ops/training.py:65 2019-01-16 11:30:52.487892: step 10849, loss = 0.53488 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:30:53.452210 ops/training.py:65 2019-01-16 11:30:53.452142: step 10850, loss = 0.71919 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:30:54.413153 ops/training.py:65 2019-01-16 11:30:54.413097: step 10851, loss = 0.60661 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:30:55.375424 ops/training.py:65 2019-01-16 11:30:55.375354: step 10852, loss = 0.56684 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:30:56.338533 ops/training.py:65 2019-01-16 11:30:56.338467: step 10853, loss = 0.58153 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:30:57.300722 ops/training.py:65 2019-01-16 11:30:57.300666: step 10854, loss = 0.71406 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:30:58.262443 ops/training.py:65 2019-01-16 11:30:58.262382: step 10855, loss = 0.67143 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:30:59.224005 ops/training.py:65 2019-01-16 11:30:59.223949: step 10856, loss = 0.71402 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:31:00.185128 ops/training.py:65 2019-01-16 11:31:00.185075: step 10857, loss = 0.53741 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:31:01.146502 ops/training.py:65 2019-01-16 11:31:01.146445: step 10858, loss = 0.58525 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:31:02.107889 ops/training.py:65 2019-01-16 11:31:02.107824: step 10859, loss = 0.62753 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:31:03.068960 ops/training.py:65 2019-01-16 11:31:03.068900: step 10860, loss = 0.58944 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:31:04.030257 ops/training.py:65 2019-01-16 11:31:04.030192: step 10861, loss = 0.66982 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:31:04.992033 ops/training.py:65 2019-01-16 11:31:04.991979: step 10862, loss = 0.68537 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:31:05.953241 ops/training.py:65 2019-01-16 11:31:05.953172: step 10863, loss = 0.58772 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:31:06.914603 ops/training.py:65 2019-01-16 11:31:06.914529: step 10864, loss = 0.58810 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:31:07.876403 ops/training.py:65 2019-01-16 11:31:07.876333: step 10865, loss = 0.51517 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:31:08.838510 ops/training.py:65 2019-01-16 11:31:08.838436: step 10866, loss = 0.48865 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:31:09.800386 ops/training.py:65 2019-01-16 11:31:09.800313: step 10867, loss = 0.68041 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:31:10.761235 ops/training.py:65 2019-01-16 11:31:10.761162: step 10868, loss = 0.54482 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:31:11.726380 ops/training.py:65 2019-01-16 11:31:11.726309: step 10869, loss = 0.51468 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:31:12.688238 ops/training.py:65 2019-01-16 11:31:12.688161: step 10870, loss = 0.56658 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:31:13.652146 ops/training.py:65 2019-01-16 11:31:13.652071: step 10871, loss = 0.70514 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:31:14.613426 ops/training.py:65 2019-01-16 11:31:14.613355: step 10872, loss = 0.59386 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:31:15.576704 ops/training.py:65 2019-01-16 11:31:15.576639: step 10873, loss = 0.56400 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:31:16.541909 ops/training.py:65 2019-01-16 11:31:16.541851: step 10874, loss = 0.57732 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:31:17.504416 ops/training.py:65 2019-01-16 11:31:17.504344: step 10875, loss = 0.65993 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:31:18.466702 ops/training.py:65 2019-01-16 11:31:18.466641: step 10876, loss = 0.67488 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:31:19.429306 ops/training.py:65 2019-01-16 11:31:19.429244: step 10877, loss = 0.57595 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:31:20.392291 ops/training.py:65 2019-01-16 11:31:20.392223: step 10878, loss = 0.45773 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:31:21.354277 ops/training.py:65 2019-01-16 11:31:21.354222: step 10879, loss = 0.56491 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:31:22.315168 ops/training.py:65 2019-01-16 11:31:22.315107: step 10880, loss = 0.47268 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:31:23.275563 ops/training.py:65 2019-01-16 11:31:23.275499: step 10881, loss = 0.60147 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:31:24.237314 ops/training.py:65 2019-01-16 11:31:24.237240: step 10882, loss = 0.69942 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:31:25.199985 ops/training.py:65 2019-01-16 11:31:25.199906: step 10883, loss = 0.53157 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:31:26.160784 ops/training.py:65 2019-01-16 11:31:26.160713: step 10884, loss = 0.43033 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:31:27.125341 ops/training.py:65 2019-01-16 11:31:27.125298: step 10885, loss = 0.46216 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:31:28.087808 ops/training.py:65 2019-01-16 11:31:28.087735: step 10886, loss = 0.65770 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:31:29.049608 ops/training.py:65 2019-01-16 11:31:29.049535: step 10887, loss = 0.58887 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:31:30.011659 ops/training.py:65 2019-01-16 11:31:30.011581: step 10888, loss = 0.51372 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:31:30.973080 ops/training.py:65 2019-01-16 11:31:30.973001: step 10889, loss = 0.63992 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:31:31.935944 ops/training.py:65 2019-01-16 11:31:31.935874: step 10890, loss = 0.53340 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:31:32.899656 ops/training.py:65 2019-01-16 11:31:32.899584: step 10891, loss = 0.58635 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:31:33.862622 ops/training.py:65 2019-01-16 11:31:33.862555: step 10892, loss = 0.61527 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:31:34.823420 ops/training.py:65 2019-01-16 11:31:34.823353: step 10893, loss = 0.58309 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:31:35.784692 ops/training.py:65 2019-01-16 11:31:35.784628: step 10894, loss = 0.57370 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:31:36.746496 ops/training.py:65 2019-01-16 11:31:36.746433: step 10895, loss = 0.63062 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:31:37.708003 ops/training.py:65 2019-01-16 11:31:37.707935: step 10896, loss = 0.53645 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:31:38.671124 ops/training.py:65 2019-01-16 11:31:38.671059: step 10897, loss = 0.55321 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:31:39.634217 ops/training.py:65 2019-01-16 11:31:39.634144: step 10898, loss = 0.70913 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:31:40.594667 ops/training.py:65 2019-01-16 11:31:40.594600: step 10899, loss = 0.56518 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:31:41.558338 ops/training.py:65 2019-01-16 11:31:41.558284: step 10900, loss = 0.52339 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:31:42.521958 ops/training.py:65 2019-01-16 11:31:42.521885: step 10901, loss = 0.58246 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:31:43.485332 ops/training.py:65 2019-01-16 11:31:43.485255: step 10902, loss = 0.65098 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:31:44.446802 ops/training.py:65 2019-01-16 11:31:44.446732: step 10903, loss = 0.43787 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:31:45.407869 ops/training.py:65 2019-01-16 11:31:45.407797: step 10904, loss = 0.71236 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:31:46.368764 ops/training.py:65 2019-01-16 11:31:46.368693: step 10905, loss = 0.69763 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:31:47.329637 ops/training.py:65 2019-01-16 11:31:47.329569: step 10906, loss = 0.71155 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 11:31:48.290088 ops/training.py:65 2019-01-16 11:31:48.290014: step 10907, loss = 0.59105 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:31:49.250837 ops/training.py:65 2019-01-16 11:31:49.250770: step 10908, loss = 0.52648 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:31:50.212177 ops/training.py:65 2019-01-16 11:31:50.212106: step 10909, loss = 0.64115 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:31:51.174883 ops/training.py:65 2019-01-16 11:31:51.174810: step 10910, loss = 0.61616 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:31:52.135858 ops/training.py:65 2019-01-16 11:31:52.135789: step 10911, loss = 0.59840 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:31:53.096778 ops/training.py:65 2019-01-16 11:31:53.096711: step 10912, loss = 0.59900 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:31:54.056896 ops/training.py:65 2019-01-16 11:31:54.056828: step 10913, loss = 0.48237 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:31:55.022143 ops/training.py:65 2019-01-16 11:31:55.022070: step 10914, loss = 0.63226 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:31:55.985363 ops/training.py:65 2019-01-16 11:31:55.985292: step 10915, loss = 0.52257 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:31:56.951136 ops/training.py:65 2019-01-16 11:31:56.951063: step 10916, loss = 0.51750 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:31:57.914311 ops/training.py:65 2019-01-16 11:31:57.914235: step 10917, loss = 0.72906 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:31:58.877510 ops/training.py:65 2019-01-16 11:31:58.877430: step 10918, loss = 0.58039 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:31:59.839933 ops/training.py:65 2019-01-16 11:31:59.839841: step 10919, loss = 0.61789 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:32:00.803508 ops/training.py:65 2019-01-16 11:32:00.803439: step 10920, loss = 0.63676 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:32:01.763508 ops/training.py:65 2019-01-16 11:32:01.763437: step 10921, loss = 0.62856 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:32:02.727628 ops/training.py:65 2019-01-16 11:32:02.727558: step 10922, loss = 0.57757 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:32:03.691034 ops/training.py:65 2019-01-16 11:32:03.690957: step 10923, loss = 0.52503 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:32:04.653998 ops/training.py:65 2019-01-16 11:32:04.653926: step 10924, loss = 0.56199 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:32:05.614346 ops/training.py:65 2019-01-16 11:32:05.614275: step 10925, loss = 0.48174 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:32:06.577545 ops/training.py:65 2019-01-16 11:32:06.577483: step 10926, loss = 0.77761 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:32:07.542071 ops/training.py:65 2019-01-16 11:32:07.541999: step 10927, loss = 0.70455 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:32:08.504557 ops/training.py:65 2019-01-16 11:32:08.504485: step 10928, loss = 0.55150 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:32:09.465404 ops/training.py:65 2019-01-16 11:32:09.465333: step 10929, loss = 0.63624 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:32:10.426353 ops/training.py:65 2019-01-16 11:32:10.426279: step 10930, loss = 0.58917 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:32:11.387290 ops/training.py:65 2019-01-16 11:32:11.387216: step 10931, loss = 0.51512 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:32:12.348426 ops/training.py:65 2019-01-16 11:32:12.348351: step 10932, loss = 0.63908 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:32:13.309267 ops/training.py:65 2019-01-16 11:32:13.309197: step 10933, loss = 0.61440 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:32:14.270316 ops/training.py:65 2019-01-16 11:32:14.270243: step 10934, loss = 0.51429 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:32:15.230152 ops/training.py:65 2019-01-16 11:32:15.230081: step 10935, loss = 0.68304 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:32:16.192776 ops/training.py:65 2019-01-16 11:32:16.192704: step 10936, loss = 0.50707 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:32:17.154053 ops/training.py:65 2019-01-16 11:32:17.153983: step 10937, loss = 0.66291 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:32:18.117067 ops/training.py:65 2019-01-16 11:32:18.116996: step 10938, loss = 0.60749 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:32:19.078122 ops/training.py:65 2019-01-16 11:32:19.078057: step 10939, loss = 0.70688 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:32:20.038750 ops/training.py:65 2019-01-16 11:32:20.038682: step 10940, loss = 0.51361 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:32:20.999106 ops/training.py:65 2019-01-16 11:32:20.999037: step 10941, loss = 0.60642 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:32:21.963265 ops/training.py:65 2019-01-16 11:32:21.963194: step 10942, loss = 0.58125 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:32:22.927547 ops/training.py:65 2019-01-16 11:32:22.927481: step 10943, loss = 0.64816 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:32:23.891472 ops/training.py:65 2019-01-16 11:32:23.891402: step 10944, loss = 0.59926 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:32:24.852333 ops/training.py:65 2019-01-16 11:32:24.852264: step 10945, loss = 0.60657 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:32:25.814145 ops/training.py:65 2019-01-16 11:32:25.814075: step 10946, loss = 0.58520 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:32:26.775327 ops/training.py:65 2019-01-16 11:32:26.775256: step 10947, loss = 0.63556 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:32:27.735484 ops/training.py:65 2019-01-16 11:32:27.735418: step 10948, loss = 0.71088 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:32:28.698914 ops/training.py:65 2019-01-16 11:32:28.698845: step 10949, loss = 0.65433 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:32:29.660613 ops/training.py:65 2019-01-16 11:32:29.660545: step 10950, loss = 0.57984 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:32:30.625299 ops/training.py:65 2019-01-16 11:32:30.625229: step 10951, loss = 0.56630 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:32:31.588672 ops/training.py:65 2019-01-16 11:32:31.588603: step 10952, loss = 0.58254 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:32:32.551170 ops/training.py:65 2019-01-16 11:32:32.551101: step 10953, loss = 0.64554 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:32:33.512793 ops/training.py:65 2019-01-16 11:32:33.512722: step 10954, loss = 0.72523 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:32:34.474584 ops/training.py:65 2019-01-16 11:32:34.474513: step 10955, loss = 0.59436 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:32:35.435074 ops/training.py:65 2019-01-16 11:32:35.435003: step 10956, loss = 0.59665 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:32:36.395796 ops/training.py:65 2019-01-16 11:32:36.395734: step 10957, loss = 0.67155 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:32:37.356690 ops/training.py:65 2019-01-16 11:32:37.356616: step 10958, loss = 0.77153 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:32:38.317824 ops/training.py:65 2019-01-16 11:32:38.317750: step 10959, loss = 0.63460 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:32:39.279062 ops/training.py:65 2019-01-16 11:32:39.278989: step 10960, loss = 0.49890 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:32:40.239151 ops/training.py:65 2019-01-16 11:32:40.239084: step 10961, loss = 0.57605 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:32:41.202566 ops/training.py:65 2019-01-16 11:32:41.202495: step 10962, loss = 0.60694 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:32:42.166112 ops/training.py:65 2019-01-16 11:32:42.166042: step 10963, loss = 0.68309 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:32:43.129220 ops/training.py:65 2019-01-16 11:32:43.129145: step 10964, loss = 0.55939 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:32:44.122136 ops/training.py:65 2019-01-16 11:32:44.122065: step 10965, loss = 0.68703 (32.3 examples/sec; 0.992 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:32:45.080270 ops/training.py:65 2019-01-16 11:32:45.080200: step 10966, loss = 0.62356 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:32:46.043514 ops/training.py:65 2019-01-16 11:32:46.043438: step 10967, loss = 0.60497 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:32:47.005316 ops/training.py:65 2019-01-16 11:32:47.005246: step 10968, loss = 0.55628 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:32:47.964206 ops/training.py:65 2019-01-16 11:32:47.964131: step 10969, loss = 0.64372 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:32:48.922533 ops/training.py:65 2019-01-16 11:32:48.922458: step 10970, loss = 0.56211 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:32:49.884894 ops/training.py:65 2019-01-16 11:32:49.884821: step 10971, loss = 0.58966 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:32:50.845806 ops/training.py:65 2019-01-16 11:32:50.845738: step 10972, loss = 0.53906 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:32:51.808857 ops/training.py:65 2019-01-16 11:32:51.808783: step 10973, loss = 0.71015 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:32:52.772728 ops/training.py:65 2019-01-16 11:32:52.772648: step 10974, loss = 0.47173 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:32:53.734152 ops/training.py:65 2019-01-16 11:32:53.734076: step 10975, loss = 0.73167 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:32:54.697959 ops/training.py:65 2019-01-16 11:32:54.697883: step 10976, loss = 0.64545 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:32:55.661750 ops/training.py:65 2019-01-16 11:32:55.661685: step 10977, loss = 0.59480 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:32:56.624419 ops/training.py:65 2019-01-16 11:32:56.624363: step 10978, loss = 0.64215 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:32:57.585917 ops/training.py:65 2019-01-16 11:32:57.585844: step 10979, loss = 0.61781 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:32:58.546836 ops/training.py:65 2019-01-16 11:32:58.546775: step 10980, loss = 0.62151 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:32:59.506374 ops/training.py:65 2019-01-16 11:32:59.506302: step 10981, loss = 0.60364 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:33:00.466496 ops/training.py:65 2019-01-16 11:33:00.466425: step 10982, loss = 0.56982 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:33:01.425477 ops/training.py:65 2019-01-16 11:33:01.425404: step 10983, loss = 0.68580 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:33:02.389453 ops/training.py:65 2019-01-16 11:33:02.389378: step 10984, loss = 0.57539 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:33:03.353855 ops/training.py:65 2019-01-16 11:33:03.353783: step 10985, loss = 0.61049 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:33:04.316691 ops/training.py:65 2019-01-16 11:33:04.316615: step 10986, loss = 0.72477 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:33:05.275793 ops/training.py:65 2019-01-16 11:33:05.275722: step 10987, loss = 0.64045 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:33:06.235388 ops/training.py:65 2019-01-16 11:33:06.235316: step 10988, loss = 0.55752 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:33:07.198551 ops/training.py:65 2019-01-16 11:33:07.198487: step 10989, loss = 0.72559 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:33:08.162992 ops/training.py:65 2019-01-16 11:33:08.162921: step 10990, loss = 0.58501 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:33:09.123856 ops/training.py:65 2019-01-16 11:33:09.123786: step 10991, loss = 0.53830 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:33:10.085246 ops/training.py:65 2019-01-16 11:33:10.085171: step 10992, loss = 0.61986 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:33:11.047782 ops/training.py:65 2019-01-16 11:33:11.047705: step 10993, loss = 0.56520 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:33:12.011648 ops/training.py:65 2019-01-16 11:33:12.011576: step 10994, loss = 0.65666 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:33:12.972797 ops/training.py:65 2019-01-16 11:33:12.972727: step 10995, loss = 0.68276 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:33:13.932882 ops/training.py:65 2019-01-16 11:33:13.932807: step 10996, loss = 0.57604 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:33:14.895739 ops/training.py:65 2019-01-16 11:33:14.895668: step 10997, loss = 0.79021 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:33:15.856636 ops/training.py:65 2019-01-16 11:33:15.856560: step 10998, loss = 0.66915 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:33:16.820502 ops/training.py:65 2019-01-16 11:33:16.820428: step 10999, loss = 0.53846 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:33:17.780570 ops/training.py:65 2019-01-16 11:33:17.780503: step 11000, loss = 0.67567 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:33:18.744226 ops/training.py:65 2019-01-16 11:33:18.744156: step 11001, loss = 0.63341 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:33:19.704867 ops/training.py:65 2019-01-16 11:33:19.704797: step 11002, loss = 0.61668 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:33:20.667669 ops/training.py:65 2019-01-16 11:33:20.667598: step 11003, loss = 0.56915 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:33:21.627896 ops/training.py:65 2019-01-16 11:33:21.627827: step 11004, loss = 0.62047 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:33:22.586242 ops/training.py:65 2019-01-16 11:33:22.586171: step 11005, loss = 0.65053 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:33:23.549763 ops/training.py:65 2019-01-16 11:33:23.549692: step 11006, loss = 0.61697 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:33:24.512058 ops/training.py:65 2019-01-16 11:33:24.511985: step 11007, loss = 0.63709 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:33:25.474353 ops/training.py:65 2019-01-16 11:33:25.474282: step 11008, loss = 0.67467 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:33:26.436145 ops/training.py:65 2019-01-16 11:33:26.436068: step 11009, loss = 0.52112 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:33:27.396128 ops/training.py:65 2019-01-16 11:33:27.396055: step 11010, loss = 0.56685 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:33:28.356689 ops/training.py:65 2019-01-16 11:33:28.356610: step 11011, loss = 0.53169 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:33:29.320908 ops/training.py:65 2019-01-16 11:33:29.320836: step 11012, loss = 0.67274 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:33:30.283940 ops/training.py:65 2019-01-16 11:33:30.283873: step 11013, loss = 0.60819 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:33:31.247636 ops/training.py:65 2019-01-16 11:33:31.247560: step 11014, loss = 0.53584 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:33:32.210099 ops/training.py:65 2019-01-16 11:33:32.210024: step 11015, loss = 0.53000 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:33:33.172385 ops/training.py:65 2019-01-16 11:33:33.172313: step 11016, loss = 0.53838 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:33:34.136023 ops/training.py:65 2019-01-16 11:33:34.135952: step 11017, loss = 0.57138 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:33:35.097613 ops/training.py:65 2019-01-16 11:33:35.097541: step 11018, loss = 0.65201 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:33:36.058592 ops/training.py:65 2019-01-16 11:33:36.058521: step 11019, loss = 0.69161 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:33:37.018148 ops/training.py:65 2019-01-16 11:33:37.018082: step 11020, loss = 0.67832 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:33:37.981655 ops/training.py:65 2019-01-16 11:33:37.981583: step 11021, loss = 0.55584 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:33:38.944172 ops/training.py:65 2019-01-16 11:33:38.944100: step 11022, loss = 0.67571 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:33:39.906783 ops/training.py:65 2019-01-16 11:33:39.906714: step 11023, loss = 0.61537 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:33:40.869600 ops/training.py:65 2019-01-16 11:33:40.869528: step 11024, loss = 0.60858 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:33:41.830020 ops/training.py:65 2019-01-16 11:33:41.829943: step 11025, loss = 0.67255 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:33:42.788740 ops/training.py:65 2019-01-16 11:33:42.788672: step 11026, loss = 0.63668 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:33:43.747166 ops/training.py:65 2019-01-16 11:33:43.747092: step 11027, loss = 0.50630 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:33:44.710981 ops/training.py:65 2019-01-16 11:33:44.710907: step 11028, loss = 0.55137 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:33:45.672383 ops/training.py:65 2019-01-16 11:33:45.672307: step 11029, loss = 0.50116 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:33:46.630836 ops/training.py:65 2019-01-16 11:33:46.630762: step 11030, loss = 0.56138 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:33:47.594941 ops/training.py:65 2019-01-16 11:33:47.594867: step 11031, loss = 0.54801 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:33:48.557983 ops/training.py:65 2019-01-16 11:33:48.557920: step 11032, loss = 0.46991 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:33:49.521447 ops/training.py:65 2019-01-16 11:33:49.521379: step 11033, loss = 0.61699 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:33:50.484551 ops/training.py:65 2019-01-16 11:33:50.484479: step 11034, loss = 0.57114 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:33:51.445593 ops/training.py:65 2019-01-16 11:33:51.445517: step 11035, loss = 0.59552 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:33:52.406604 ops/training.py:65 2019-01-16 11:33:52.406526: step 11036, loss = 0.56721 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:33:53.366262 ops/training.py:65 2019-01-16 11:33:53.366190: step 11037, loss = 0.67593 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:33:54.325744 ops/training.py:65 2019-01-16 11:33:54.325671: step 11038, loss = 0.58452 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:33:55.290962 ops/training.py:65 2019-01-16 11:33:55.290892: step 11039, loss = 0.58259 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:33:56.254231 ops/training.py:65 2019-01-16 11:33:56.254159: step 11040, loss = 0.58801 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:33:57.216914 ops/training.py:65 2019-01-16 11:33:57.216844: step 11041, loss = 0.57973 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:33:58.179243 ops/training.py:65 2019-01-16 11:33:58.179139: step 11042, loss = 0.56978 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:33:59.141106 ops/training.py:65 2019-01-16 11:33:59.141030: step 11043, loss = 0.54912 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:34:00.102412 ops/training.py:65 2019-01-16 11:34:00.102335: step 11044, loss = 0.63363 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:34:01.063712 ops/training.py:65 2019-01-16 11:34:01.063639: step 11045, loss = 0.51210 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:34:02.025603 ops/training.py:65 2019-01-16 11:34:02.025532: step 11046, loss = 0.67064 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:34:02.985603 ops/training.py:65 2019-01-16 11:34:02.985521: step 11047, loss = 0.61136 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:34:03.946691 ops/training.py:65 2019-01-16 11:34:03.946613: step 11048, loss = 0.62511 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:34:04.904780 ops/training.py:65 2019-01-16 11:34:04.904711: step 11049, loss = 0.44404 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:34:05.863857 ops/training.py:65 2019-01-16 11:34:05.863786: step 11050, loss = 0.56367 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:34:06.822570 ops/training.py:65 2019-01-16 11:34:06.822500: step 11051, loss = 0.58622 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:34:07.786353 ops/training.py:65 2019-01-16 11:34:07.786285: step 11052, loss = 0.72136 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:34:08.747768 ops/training.py:65 2019-01-16 11:34:08.747696: step 11053, loss = 0.53733 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:34:09.706982 ops/training.py:65 2019-01-16 11:34:09.706911: step 11054, loss = 0.58635 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:34:10.666715 ops/training.py:65 2019-01-16 11:34:10.666645: step 11055, loss = 0.65756 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:34:11.629553 ops/training.py:65 2019-01-16 11:34:11.629502: step 11056, loss = 0.52162 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:34:12.593103 ops/training.py:65 2019-01-16 11:34:12.593028: step 11057, loss = 0.65882 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:34:13.556289 ops/training.py:65 2019-01-16 11:34:13.556218: step 11058, loss = 0.65803 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:34:14.519472 ops/training.py:65 2019-01-16 11:34:14.519398: step 11059, loss = 0.53828 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:34:15.480831 ops/training.py:65 2019-01-16 11:34:15.480753: step 11060, loss = 0.62620 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:34:16.443200 ops/training.py:65 2019-01-16 11:34:16.443124: step 11061, loss = 0.49945 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:34:17.405795 ops/training.py:65 2019-01-16 11:34:17.405720: step 11062, loss = 0.62792 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:34:18.367446 ops/training.py:65 2019-01-16 11:34:18.367373: step 11063, loss = 0.64756 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:34:19.329503 ops/training.py:65 2019-01-16 11:34:19.329427: step 11064, loss = 0.71921 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:34:20.291908 ops/training.py:65 2019-01-16 11:34:20.291835: step 11065, loss = 0.63037 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:34:21.253494 ops/training.py:65 2019-01-16 11:34:21.253422: step 11066, loss = 0.56045 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:34:22.216400 ops/training.py:65 2019-01-16 11:34:22.216327: step 11067, loss = 0.70980 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:34:23.179177 ops/training.py:65 2019-01-16 11:34:23.179104: step 11068, loss = 0.76076 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:34:24.140820 ops/training.py:65 2019-01-16 11:34:24.140752: step 11069, loss = 0.56407 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:34:25.102902 ops/training.py:65 2019-01-16 11:34:25.102830: step 11070, loss = 0.60585 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:34:26.064413 ops/training.py:65 2019-01-16 11:34:26.064342: step 11071, loss = 0.64743 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:34:27.024568 ops/training.py:65 2019-01-16 11:34:27.024495: step 11072, loss = 0.67728 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:34:27.984321 ops/training.py:65 2019-01-16 11:34:27.984248: step 11073, loss = 0.62934 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:34:28.947701 ops/training.py:65 2019-01-16 11:34:28.947628: step 11074, loss = 0.57190 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:34:29.910565 ops/training.py:65 2019-01-16 11:34:29.910488: step 11075, loss = 0.71168 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:34:30.874118 ops/training.py:65 2019-01-16 11:34:30.874047: step 11076, loss = 0.48724 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:34:31.836330 ops/training.py:65 2019-01-16 11:34:31.836260: step 11077, loss = 0.52836 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:34:32.798243 ops/training.py:65 2019-01-16 11:34:32.798175: step 11078, loss = 0.55346 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:34:33.759763 ops/training.py:65 2019-01-16 11:34:33.759688: step 11079, loss = 0.57539 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:34:34.721478 ops/training.py:65 2019-01-16 11:34:34.721403: step 11080, loss = 0.65114 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:34:35.683600 ops/training.py:65 2019-01-16 11:34:35.683521: step 11081, loss = 0.64797 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:34:36.645242 ops/training.py:65 2019-01-16 11:34:36.645186: step 11082, loss = 0.56372 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:34:37.607388 ops/training.py:65 2019-01-16 11:34:37.607317: step 11083, loss = 0.63508 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:34:38.566971 ops/training.py:65 2019-01-16 11:34:38.566907: step 11084, loss = 0.64903 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:34:39.530427 ops/training.py:65 2019-01-16 11:34:39.530356: step 11085, loss = 0.55900 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:34:40.494628 ops/training.py:65 2019-01-16 11:34:40.494553: step 11086, loss = 0.51525 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:34:41.457535 ops/training.py:65 2019-01-16 11:34:41.457453: step 11087, loss = 0.72813 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:34:42.418401 ops/training.py:65 2019-01-16 11:34:42.418326: step 11088, loss = 0.49439 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:34:43.381962 ops/training.py:65 2019-01-16 11:34:43.381888: step 11089, loss = 0.55701 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:34:44.344871 ops/training.py:65 2019-01-16 11:34:44.344800: step 11090, loss = 0.65641 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:34:45.308319 ops/training.py:65 2019-01-16 11:34:45.308250: step 11091, loss = 0.62675 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:34:46.270260 ops/training.py:65 2019-01-16 11:34:46.270182: step 11092, loss = 0.65786 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:34:47.232117 ops/training.py:65 2019-01-16 11:34:47.232042: step 11093, loss = 0.47469 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:34:48.193128 ops/training.py:65 2019-01-16 11:34:48.193056: step 11094, loss = 0.51516 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:34:49.155430 ops/training.py:65 2019-01-16 11:34:49.155360: step 11095, loss = 0.58386 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:34:50.118533 ops/training.py:65 2019-01-16 11:34:50.118458: step 11096, loss = 0.57474 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:34:51.080851 ops/training.py:65 2019-01-16 11:34:51.080775: step 11097, loss = 0.53335 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:34:52.041295 ops/training.py:65 2019-01-16 11:34:52.041217: step 11098, loss = 0.75616 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:34:53.001412 ops/training.py:65 2019-01-16 11:34:53.001337: step 11099, loss = 0.50556 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:34:53.965096 ops/training.py:65 2019-01-16 11:34:53.965023: step 11100, loss = 0.65606 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:34:54.925641 ops/training.py:65 2019-01-16 11:34:54.925568: step 11101, loss = 0.67756 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:34:55.888518 ops/training.py:65 2019-01-16 11:34:55.888445: step 11102, loss = 0.46007 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:34:56.849876 ops/training.py:65 2019-01-16 11:34:56.849804: step 11103, loss = 0.38164 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 11:34:57.809561 ops/training.py:65 2019-01-16 11:34:57.809477: step 11104, loss = 0.65462 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:34:58.769232 ops/training.py:65 2019-01-16 11:34:58.769157: step 11105, loss = 0.75744 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:34:59.727892 ops/training.py:65 2019-01-16 11:34:59.727819: step 11106, loss = 0.61817 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:35:00.686923 ops/training.py:65 2019-01-16 11:35:00.686847: step 11107, loss = 0.70850 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:35:01.645063 ops/training.py:65 2019-01-16 11:35:01.645013: step 11108, loss = 0.64018 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:35:02.603000 ops/training.py:65 2019-01-16 11:35:02.602928: step 11109, loss = 0.54429 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:35:03.568973 ops/training.py:65 2019-01-16 11:35:03.568896: step 11110, loss = 0.53134 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:35:04.532165 ops/training.py:65 2019-01-16 11:35:04.532092: step 11111, loss = 0.52085 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:35:05.495282 ops/training.py:65 2019-01-16 11:35:05.495209: step 11112, loss = 0.63779 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:35:06.458829 ops/training.py:65 2019-01-16 11:35:06.458774: step 11113, loss = 0.57858 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:35:07.420922 ops/training.py:65 2019-01-16 11:35:07.420845: step 11114, loss = 0.63807 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:35:08.383156 ops/training.py:65 2019-01-16 11:35:08.383090: step 11115, loss = 0.57991 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:35:09.345292 ops/training.py:65 2019-01-16 11:35:09.345223: step 11116, loss = 0.60045 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:35:10.307793 ops/training.py:65 2019-01-16 11:35:10.307726: step 11117, loss = 0.81927 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:35:11.270952 ops/training.py:65 2019-01-16 11:35:11.270870: step 11118, loss = 0.52807 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:35:12.232305 ops/training.py:65 2019-01-16 11:35:12.232228: step 11119, loss = 0.60462 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:35:13.192090 ops/training.py:65 2019-01-16 11:35:13.192017: step 11120, loss = 0.66742 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:35:14.151478 ops/training.py:65 2019-01-16 11:35:14.151427: step 11121, loss = 0.54506 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:35:15.110996 ops/training.py:65 2019-01-16 11:35:15.110929: step 11122, loss = 0.67191 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:35:16.070191 ops/training.py:65 2019-01-16 11:35:16.070124: step 11123, loss = 0.58588 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:35:17.029657 ops/training.py:65 2019-01-16 11:35:17.029591: step 11124, loss = 0.65254 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:35:17.993411 ops/training.py:65 2019-01-16 11:35:17.993351: step 11125, loss = 0.64714 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:35:18.956506 ops/training.py:65 2019-01-16 11:35:18.956443: step 11126, loss = 0.63466 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:35:19.919623 ops/training.py:65 2019-01-16 11:35:19.919552: step 11127, loss = 0.59791 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:35:20.880256 ops/training.py:65 2019-01-16 11:35:20.880189: step 11128, loss = 0.57370 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:35:21.840931 ops/training.py:65 2019-01-16 11:35:21.840866: step 11129, loss = 0.51274 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:35:22.799013 ops/training.py:65 2019-01-16 11:35:22.798935: step 11130, loss = 0.66639 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:35:23.757259 ops/training.py:65 2019-01-16 11:35:23.757184: step 11131, loss = 0.47815 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:35:24.714739 ops/training.py:65 2019-01-16 11:35:24.714678: step 11132, loss = 0.51882 (33.5 examples/sec; 0.956 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:35:25.677418 ops/training.py:65 2019-01-16 11:35:25.677342: step 11133, loss = 0.50992 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:35:26.641343 ops/training.py:65 2019-01-16 11:35:26.641265: step 11134, loss = 0.59065 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:35:27.602353 ops/training.py:65 2019-01-16 11:35:27.602280: step 11135, loss = 0.54433 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:35:28.563038 ops/training.py:65 2019-01-16 11:35:28.562976: step 11136, loss = 0.73326 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:35:29.522523 ops/training.py:65 2019-01-16 11:35:29.522449: step 11137, loss = 0.62584 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:35:30.481738 ops/training.py:65 2019-01-16 11:35:30.481666: step 11138, loss = 0.64383 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:35:31.439206 ops/training.py:65 2019-01-16 11:35:31.439138: step 11139, loss = 0.61297 (33.5 examples/sec; 0.956 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:35:32.401824 ops/training.py:65 2019-01-16 11:35:32.401752: step 11140, loss = 0.61539 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:35:33.364831 ops/training.py:65 2019-01-16 11:35:33.364760: step 11141, loss = 0.55157 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:35:34.327124 ops/training.py:65 2019-01-16 11:35:34.327050: step 11142, loss = 0.55806 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:35:35.289082 ops/training.py:65 2019-01-16 11:35:35.289006: step 11143, loss = 0.54093 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:35:36.252041 ops/training.py:65 2019-01-16 11:35:36.251961: step 11144, loss = 0.73905 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:35:37.214793 ops/training.py:65 2019-01-16 11:35:37.214720: step 11145, loss = 0.60357 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:35:38.177751 ops/training.py:65 2019-01-16 11:35:38.177693: step 11146, loss = 0.53981 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:35:39.141066 ops/training.py:65 2019-01-16 11:35:39.141009: step 11147, loss = 0.56597 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:35:40.104330 ops/training.py:65 2019-01-16 11:35:40.104269: step 11148, loss = 0.57142 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:35:41.064469 ops/training.py:65 2019-01-16 11:35:41.064408: step 11149, loss = 0.72845 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:35:42.027977 ops/training.py:65 2019-01-16 11:35:42.027931: step 11150, loss = 0.51679 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:35:42.989472 ops/training.py:65 2019-01-16 11:35:42.989406: step 11151, loss = 0.69825 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:35:43.952609 ops/training.py:65 2019-01-16 11:35:43.952545: step 11152, loss = 0.60343 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:35:44.916106 ops/training.py:65 2019-01-16 11:35:44.916042: step 11153, loss = 0.50078 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:35:45.878950 ops/training.py:65 2019-01-16 11:35:45.878885: step 11154, loss = 0.60832 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:35:46.839583 ops/training.py:65 2019-01-16 11:35:46.839521: step 11155, loss = 0.69618 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:35:47.802760 ops/training.py:65 2019-01-16 11:35:47.802699: step 11156, loss = 0.64185 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:35:48.767019 ops/training.py:65 2019-01-16 11:35:48.766967: step 11157, loss = 0.47599 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:35:49.729183 ops/training.py:65 2019-01-16 11:35:49.729114: step 11158, loss = 0.60756 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:35:50.689314 ops/training.py:65 2019-01-16 11:35:50.689260: step 11159, loss = 0.62906 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:35:51.651008 ops/training.py:65 2019-01-16 11:35:51.650949: step 11160, loss = 0.58700 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:35:52.612243 ops/training.py:65 2019-01-16 11:35:52.612182: step 11161, loss = 0.52484 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:35:53.571592 ops/training.py:65 2019-01-16 11:35:53.571531: step 11162, loss = 0.62453 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:35:54.534066 ops/training.py:65 2019-01-16 11:35:54.533977: step 11163, loss = 0.55901 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:35:55.497962 ops/training.py:65 2019-01-16 11:35:55.497915: step 11164, loss = 0.44671 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:35:56.460450 ops/training.py:65 2019-01-16 11:35:56.460386: step 11165, loss = 0.55442 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:35:57.422059 ops/training.py:65 2019-01-16 11:35:57.421992: step 11166, loss = 0.63415 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:35:58.384436 ops/training.py:65 2019-01-16 11:35:58.384370: step 11167, loss = 0.52258 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:35:59.345175 ops/training.py:65 2019-01-16 11:35:59.345112: step 11168, loss = 0.57705 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:36:00.307103 ops/training.py:65 2019-01-16 11:36:00.307037: step 11169, loss = 0.53638 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:36:01.269487 ops/training.py:65 2019-01-16 11:36:01.269431: step 11170, loss = 0.49984 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:36:02.230114 ops/training.py:65 2019-01-16 11:36:02.230059: step 11171, loss = 0.48730 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:36:03.191556 ops/training.py:65 2019-01-16 11:36:03.191496: step 11172, loss = 0.66064 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:36:04.154068 ops/training.py:65 2019-01-16 11:36:04.154004: step 11173, loss = 0.54693 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:36:05.116671 ops/training.py:65 2019-01-16 11:36:05.116604: step 11174, loss = 0.35524 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:36:06.079901 ops/training.py:65 2019-01-16 11:36:06.079829: step 11175, loss = 0.51592 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:36:07.043259 ops/training.py:65 2019-01-16 11:36:07.043208: step 11176, loss = 0.51152 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:36:08.005455 ops/training.py:65 2019-01-16 11:36:08.005394: step 11177, loss = 0.74835 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:36:08.967156 ops/training.py:65 2019-01-16 11:36:08.967092: step 11178, loss = 0.44071 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:36:09.928542 ops/training.py:65 2019-01-16 11:36:09.928466: step 11179, loss = 0.55655 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:36:10.887747 ops/training.py:65 2019-01-16 11:36:10.887692: step 11180, loss = 0.62324 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:36:11.852686 ops/training.py:65 2019-01-16 11:36:11.852632: step 11181, loss = 0.58780 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:36:12.813919 ops/training.py:65 2019-01-16 11:36:12.813851: step 11182, loss = 0.57676 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:36:13.773374 ops/training.py:65 2019-01-16 11:36:13.773299: step 11183, loss = 0.57940 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:36:14.737648 ops/training.py:65 2019-01-16 11:36:14.737591: step 11184, loss = 0.60625 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:36:15.702510 ops/training.py:65 2019-01-16 11:36:15.702448: step 11185, loss = 0.65633 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:36:16.665973 ops/training.py:65 2019-01-16 11:36:16.665915: step 11186, loss = 0.60449 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:36:17.628613 ops/training.py:65 2019-01-16 11:36:17.628550: step 11187, loss = 0.80110 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:36:18.590538 ops/training.py:65 2019-01-16 11:36:18.590478: step 11188, loss = 0.60371 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:36:19.551328 ops/training.py:65 2019-01-16 11:36:19.551263: step 11189, loss = 0.65399 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:36:20.511247 ops/training.py:65 2019-01-16 11:36:20.511178: step 11190, loss = 0.81849 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:36:21.475553 ops/training.py:65 2019-01-16 11:36:21.475497: step 11191, loss = 0.58338 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:36:22.437433 ops/training.py:65 2019-01-16 11:36:22.437372: step 11192, loss = 0.64546 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:36:23.396569 ops/training.py:65 2019-01-16 11:36:23.396503: step 11193, loss = 0.62861 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:36:24.357109 ops/training.py:65 2019-01-16 11:36:24.357052: step 11194, loss = 0.56609 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:36:25.316845 ops/training.py:65 2019-01-16 11:36:25.316794: step 11195, loss = 0.62978 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:36:26.276974 ops/training.py:65 2019-01-16 11:36:26.276912: step 11196, loss = 0.52867 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:36:27.240604 ops/training.py:65 2019-01-16 11:36:27.240542: step 11197, loss = 0.61373 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:36:28.204490 ops/training.py:65 2019-01-16 11:36:28.204428: step 11198, loss = 0.51145 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:36:29.168379 ops/training.py:65 2019-01-16 11:36:29.168325: step 11199, loss = 0.59284 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:36:30.132091 ops/training.py:65 2019-01-16 11:36:30.132031: step 11200, loss = 0.57594 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:36:31.096557 ops/training.py:65 2019-01-16 11:36:31.096494: step 11201, loss = 0.60719 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:36:32.060710 ops/training.py:65 2019-01-16 11:36:32.060645: step 11202, loss = 0.51630 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:36:33.023677 ops/training.py:65 2019-01-16 11:36:33.023616: step 11203, loss = 0.52218 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:36:33.987885 ops/training.py:65 2019-01-16 11:36:33.987823: step 11204, loss = 0.56100 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:36:34.952099 ops/training.py:65 2019-01-16 11:36:34.952035: step 11205, loss = 0.59400 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:36:35.915820 ops/training.py:65 2019-01-16 11:36:35.915752: step 11206, loss = 0.53283 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:36:36.876354 ops/training.py:65 2019-01-16 11:36:36.876299: step 11207, loss = 0.61441 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:36:37.836176 ops/training.py:65 2019-01-16 11:36:37.836117: step 11208, loss = 0.59109 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:36:38.797538 ops/training.py:65 2019-01-16 11:36:38.797474: step 11209, loss = 0.55990 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:36:39.761160 ops/training.py:65 2019-01-16 11:36:39.761098: step 11210, loss = 0.59276 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:36:40.724139 ops/training.py:65 2019-01-16 11:36:40.724078: step 11211, loss = 0.63050 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:36:41.686422 ops/training.py:65 2019-01-16 11:36:41.686359: step 11212, loss = 0.60533 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:36:42.648827 ops/training.py:65 2019-01-16 11:36:42.648759: step 11213, loss = 0.62536 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:36:43.611966 ops/training.py:65 2019-01-16 11:36:43.611890: step 11214, loss = 0.62353 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:36:44.571546 ops/training.py:65 2019-01-16 11:36:44.571475: step 11215, loss = 0.51285 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:36:45.535460 ops/training.py:65 2019-01-16 11:36:45.535386: step 11216, loss = 0.58777 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:36:46.498733 ops/training.py:65 2019-01-16 11:36:46.498656: step 11217, loss = 0.70210 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:36:47.462283 ops/training.py:65 2019-01-16 11:36:47.462204: step 11218, loss = 0.66045 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:36:48.424492 ops/training.py:65 2019-01-16 11:36:48.424418: step 11219, loss = 0.54434 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 11:36:49.384740 ops/training.py:65 2019-01-16 11:36:49.384683: step 11220, loss = 0.59007 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:36:50.350021 ops/training.py:65 2019-01-16 11:36:50.349945: step 11221, loss = 0.64875 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:36:51.312192 ops/training.py:65 2019-01-16 11:36:51.312121: step 11222, loss = 0.65002 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:36:52.271445 ops/training.py:65 2019-01-16 11:36:52.271385: step 11223, loss = 0.65480 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:36:53.235689 ops/training.py:65 2019-01-16 11:36:53.235619: step 11224, loss = 0.50265 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:36:54.199522 ops/training.py:65 2019-01-16 11:36:54.199456: step 11225, loss = 0.64950 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:36:55.160762 ops/training.py:65 2019-01-16 11:36:55.160706: step 11226, loss = 0.66241 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:36:56.119921 ops/training.py:65 2019-01-16 11:36:56.119856: step 11227, loss = 0.69811 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:36:57.083666 ops/training.py:65 2019-01-16 11:36:57.083605: step 11228, loss = 0.49769 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:36:58.046702 ops/training.py:65 2019-01-16 11:36:58.046636: step 11229, loss = 0.59280 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:36:59.008953 ops/training.py:65 2019-01-16 11:36:59.008897: step 11230, loss = 0.77519 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:36:59.971487 ops/training.py:65 2019-01-16 11:36:59.971431: step 11231, loss = 0.67082 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:37:00.932045 ops/training.py:65 2019-01-16 11:37:00.931984: step 11232, loss = 0.62418 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:37:01.896231 ops/training.py:65 2019-01-16 11:37:01.896159: step 11233, loss = 0.60246 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:37:02.856640 ops/training.py:65 2019-01-16 11:37:02.856590: step 11234, loss = 0.63534 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:37:03.816316 ops/training.py:65 2019-01-16 11:37:03.816253: step 11235, loss = 0.62665 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:37:04.776720 ops/training.py:65 2019-01-16 11:37:04.776668: step 11236, loss = 0.61389 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:37:05.736610 ops/training.py:65 2019-01-16 11:37:05.736541: step 11237, loss = 0.52892 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:37:06.699391 ops/training.py:65 2019-01-16 11:37:06.699335: step 11238, loss = 0.61941 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:37:07.663264 ops/training.py:65 2019-01-16 11:37:07.663198: step 11239, loss = 0.69541 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:37:08.625647 ops/training.py:65 2019-01-16 11:37:08.625595: step 11240, loss = 0.63337 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:37:09.586677 ops/training.py:65 2019-01-16 11:37:09.586610: step 11241, loss = 0.60804 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:37:10.551029 ops/training.py:65 2019-01-16 11:37:10.550966: step 11242, loss = 0.61541 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:37:11.514960 ops/training.py:65 2019-01-16 11:37:11.514889: step 11243, loss = 0.66079 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:37:12.477551 ops/training.py:65 2019-01-16 11:37:12.477483: step 11244, loss = 0.67407 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:37:13.440522 ops/training.py:65 2019-01-16 11:37:13.440455: step 11245, loss = 0.64402 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:37:14.402788 ops/training.py:65 2019-01-16 11:37:14.402722: step 11246, loss = 0.93882 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.375
I0832 2019-01-16 11:37:15.364814 ops/training.py:65 2019-01-16 11:37:15.364746: step 11247, loss = 0.71270 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:37:16.326760 ops/training.py:65 2019-01-16 11:37:16.326689: step 11248, loss = 0.76917 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:37:17.290907 ops/training.py:65 2019-01-16 11:37:17.290835: step 11249, loss = 0.74020 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:37:18.254979 ops/training.py:65 2019-01-16 11:37:18.254915: step 11250, loss = 0.69880 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:37:19.217819 ops/training.py:65 2019-01-16 11:37:19.217750: step 11251, loss = 0.84497 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:37:20.180240 ops/training.py:65 2019-01-16 11:37:20.180175: step 11252, loss = 0.65256 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:37:21.142709 ops/training.py:65 2019-01-16 11:37:21.142640: step 11253, loss = 0.70687 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:37:22.104616 ops/training.py:65 2019-01-16 11:37:22.104555: step 11254, loss = 0.51919 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:37:23.066918 ops/training.py:65 2019-01-16 11:37:23.066842: step 11255, loss = 0.65329 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:37:24.029134 ops/training.py:65 2019-01-16 11:37:24.029057: step 11256, loss = 0.67325 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:37:24.991434 ops/training.py:65 2019-01-16 11:37:24.991355: step 11257, loss = 0.59083 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:37:25.954519 ops/training.py:65 2019-01-16 11:37:25.954460: step 11258, loss = 0.46634 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:37:26.915449 ops/training.py:65 2019-01-16 11:37:26.915395: step 11259, loss = 0.57052 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:37:27.880223 ops/training.py:65 2019-01-16 11:37:27.880146: step 11260, loss = 0.58152 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:37:28.843677 ops/training.py:65 2019-01-16 11:37:28.843623: step 11261, loss = 0.51714 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:37:29.805079 ops/training.py:65 2019-01-16 11:37:29.805010: step 11262, loss = 0.70934 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:37:30.766478 ops/training.py:65 2019-01-16 11:37:30.766401: step 11263, loss = 0.58046 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:37:31.727150 ops/training.py:65 2019-01-16 11:37:31.727077: step 11264, loss = 0.47586 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:37:32.686287 ops/training.py:65 2019-01-16 11:37:32.686234: step 11265, loss = 0.55512 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:37:33.646963 ops/training.py:65 2019-01-16 11:37:33.646905: step 11266, loss = 0.59029 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:37:34.607680 ops/training.py:65 2019-01-16 11:37:34.607604: step 11267, loss = 0.65082 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:37:35.567294 ops/training.py:65 2019-01-16 11:37:35.567216: step 11268, loss = 0.62678 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:37:36.526386 ops/training.py:65 2019-01-16 11:37:36.526313: step 11269, loss = 0.60422 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:37:37.485198 ops/training.py:65 2019-01-16 11:37:37.485129: step 11270, loss = 0.66244 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:37:38.443521 ops/training.py:65 2019-01-16 11:37:38.443460: step 11271, loss = 0.49319 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:37:39.402552 ops/training.py:65 2019-01-16 11:37:39.402486: step 11272, loss = 0.61357 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:37:40.361201 ops/training.py:65 2019-01-16 11:37:40.361145: step 11273, loss = 0.59925 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:37:41.320699 ops/training.py:65 2019-01-16 11:37:41.320648: step 11274, loss = 0.73965 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:37:42.279290 ops/training.py:65 2019-01-16 11:37:42.279221: step 11275, loss = 0.62722 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:37:43.238962 ops/training.py:65 2019-01-16 11:37:43.238906: step 11276, loss = 0.48047 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:37:44.202426 ops/training.py:65 2019-01-16 11:37:44.202368: step 11277, loss = 0.50081 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:37:45.165943 ops/training.py:65 2019-01-16 11:37:45.165883: step 11278, loss = 0.58295 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:37:46.127002 ops/training.py:65 2019-01-16 11:37:46.126940: step 11279, loss = 0.53582 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:37:47.086032 ops/training.py:65 2019-01-16 11:37:47.085971: step 11280, loss = 0.64592 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:37:48.045248 ops/training.py:65 2019-01-16 11:37:48.045192: step 11281, loss = 0.69574 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:37:49.004036 ops/training.py:65 2019-01-16 11:37:49.003980: step 11282, loss = 0.59318 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:37:49.968880 ops/training.py:65 2019-01-16 11:37:49.968822: step 11283, loss = 0.56407 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:37:50.932387 ops/training.py:65 2019-01-16 11:37:50.932331: step 11284, loss = 0.57983 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:37:51.894990 ops/training.py:65 2019-01-16 11:37:51.894934: step 11285, loss = 0.58545 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:37:52.856353 ops/training.py:65 2019-01-16 11:37:52.856296: step 11286, loss = 0.62881 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:37:53.818431 ops/training.py:65 2019-01-16 11:37:53.818367: step 11287, loss = 0.61588 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:37:54.779755 ops/training.py:65 2019-01-16 11:37:54.779689: step 11288, loss = 0.51578 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:37:55.744306 ops/training.py:65 2019-01-16 11:37:55.744249: step 11289, loss = 0.76835 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:37:56.708509 ops/training.py:65 2019-01-16 11:37:56.708454: step 11290, loss = 0.58638 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:37:57.670073 ops/training.py:65 2019-01-16 11:37:57.670012: step 11291, loss = 0.53931 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:37:58.630601 ops/training.py:65 2019-01-16 11:37:58.630546: step 11292, loss = 0.63819 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:37:59.590263 ops/training.py:65 2019-01-16 11:37:59.590206: step 11293, loss = 0.73721 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:38:00.554269 ops/training.py:65 2019-01-16 11:38:00.554216: step 11294, loss = 0.60544 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:38:01.517581 ops/training.py:65 2019-01-16 11:38:01.517509: step 11295, loss = 0.62234 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:38:02.481560 ops/training.py:65 2019-01-16 11:38:02.481483: step 11296, loss = 0.63132 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:38:03.441882 ops/training.py:65 2019-01-16 11:38:03.441825: step 11297, loss = 0.53848 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:38:04.405874 ops/training.py:65 2019-01-16 11:38:04.405821: step 11298, loss = 0.50253 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:38:05.369637 ops/training.py:65 2019-01-16 11:38:05.369559: step 11299, loss = 0.56840 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:38:06.330891 ops/training.py:65 2019-01-16 11:38:06.330825: step 11300, loss = 0.58372 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:38:07.290627 ops/training.py:65 2019-01-16 11:38:07.290552: step 11301, loss = 0.63917 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:38:08.251366 ops/training.py:65 2019-01-16 11:38:08.251289: step 11302, loss = 0.64117 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:38:09.212482 ops/training.py:65 2019-01-16 11:38:09.212407: step 11303, loss = 0.61116 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:38:10.176663 ops/training.py:65 2019-01-16 11:38:10.176608: step 11304, loss = 0.64256 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:38:11.140638 ops/training.py:65 2019-01-16 11:38:11.140579: step 11305, loss = 0.56717 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:38:12.104460 ops/training.py:65 2019-01-16 11:38:12.104406: step 11306, loss = 0.55091 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:38:13.067243 ops/training.py:65 2019-01-16 11:38:13.067180: step 11307, loss = 0.56521 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:38:14.030091 ops/training.py:65 2019-01-16 11:38:14.030034: step 11308, loss = 0.61349 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:38:14.992919 ops/training.py:65 2019-01-16 11:38:14.992861: step 11309, loss = 0.59987 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:38:15.956067 ops/training.py:65 2019-01-16 11:38:15.956007: step 11310, loss = 0.53533 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:38:16.920942 ops/training.py:65 2019-01-16 11:38:16.920883: step 11311, loss = 0.61571 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:38:17.883555 ops/training.py:65 2019-01-16 11:38:17.883496: step 11312, loss = 0.60874 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:38:18.843287 ops/training.py:65 2019-01-16 11:38:18.843226: step 11313, loss = 0.67097 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:38:19.804047 ops/training.py:65 2019-01-16 11:38:19.803986: step 11314, loss = 0.63331 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:38:20.762562 ops/training.py:65 2019-01-16 11:38:20.762500: step 11315, loss = 0.61135 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:38:21.722363 ops/training.py:65 2019-01-16 11:38:21.722305: step 11316, loss = 0.65938 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:38:22.681779 ops/training.py:65 2019-01-16 11:38:22.681718: step 11317, loss = 0.58399 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:38:23.640503 ops/training.py:65 2019-01-16 11:38:23.640455: step 11318, loss = 0.59776 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:38:24.600288 ops/training.py:65 2019-01-16 11:38:24.600229: step 11319, loss = 0.59540 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:38:25.562951 ops/training.py:65 2019-01-16 11:38:25.562895: step 11320, loss = 0.64725 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:38:26.525126 ops/training.py:65 2019-01-16 11:38:26.525069: step 11321, loss = 0.64445 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:38:27.484197 ops/training.py:65 2019-01-16 11:38:27.484133: step 11322, loss = 0.53593 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:38:28.444421 ops/training.py:65 2019-01-16 11:38:28.444359: step 11323, loss = 0.71364 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:38:29.403457 ops/training.py:65 2019-01-16 11:38:29.403401: step 11324, loss = 0.58024 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:38:30.361936 ops/training.py:65 2019-01-16 11:38:30.361875: step 11325, loss = 0.77454 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:38:31.321753 ops/training.py:65 2019-01-16 11:38:31.321690: step 11326, loss = 0.65738 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:38:32.281076 ops/training.py:65 2019-01-16 11:38:32.281023: step 11327, loss = 0.48866 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:38:33.240520 ops/training.py:65 2019-01-16 11:38:33.240463: step 11328, loss = 0.60755 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:38:34.199811 ops/training.py:65 2019-01-16 11:38:34.199752: step 11329, loss = 0.61734 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:38:35.163095 ops/training.py:65 2019-01-16 11:38:35.163024: step 11330, loss = 0.67904 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:38:36.126791 ops/training.py:65 2019-01-16 11:38:36.126731: step 11331, loss = 0.56768 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:38:37.087356 ops/training.py:65 2019-01-16 11:38:37.087289: step 11332, loss = 0.59089 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:38:38.051436 ops/training.py:65 2019-01-16 11:38:38.051374: step 11333, loss = 0.57342 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:38:39.015533 ops/training.py:65 2019-01-16 11:38:39.015476: step 11334, loss = 0.50019 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:38:39.978200 ops/training.py:65 2019-01-16 11:38:39.978146: step 11335, loss = 0.75707 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 11:38:40.941262 ops/training.py:65 2019-01-16 11:38:40.941201: step 11336, loss = 0.61191 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:38:41.900914 ops/training.py:65 2019-01-16 11:38:41.900849: step 11337, loss = 0.74846 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 11:38:42.864739 ops/training.py:65 2019-01-16 11:38:42.864668: step 11338, loss = 0.54667 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:38:43.827536 ops/training.py:65 2019-01-16 11:38:43.827479: step 11339, loss = 0.72088 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:38:44.788611 ops/training.py:65 2019-01-16 11:38:44.788549: step 11340, loss = 0.56227 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:38:45.748755 ops/training.py:65 2019-01-16 11:38:45.748694: step 11341, loss = 0.64386 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:38:46.711872 ops/training.py:65 2019-01-16 11:38:46.711811: step 11342, loss = 0.52696 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:38:47.675554 ops/training.py:65 2019-01-16 11:38:47.675496: step 11343, loss = 0.66545 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:38:48.637548 ops/training.py:65 2019-01-16 11:38:48.637495: step 11344, loss = 0.64656 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:38:49.599875 ops/training.py:65 2019-01-16 11:38:49.599810: step 11345, loss = 0.56248 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:38:50.561365 ops/training.py:65 2019-01-16 11:38:50.561307: step 11346, loss = 0.65656 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:38:51.523631 ops/training.py:65 2019-01-16 11:38:51.523575: step 11347, loss = 0.47694 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:38:52.485182 ops/training.py:65 2019-01-16 11:38:52.485129: step 11348, loss = 0.54177 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:38:53.446580 ops/training.py:65 2019-01-16 11:38:53.446506: step 11349, loss = 0.60537 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:38:54.407866 ops/training.py:65 2019-01-16 11:38:54.407794: step 11350, loss = 0.54365 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:38:55.367903 ops/training.py:65 2019-01-16 11:38:55.367828: step 11351, loss = 0.57079 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:38:56.328750 ops/training.py:65 2019-01-16 11:38:56.328689: step 11352, loss = 0.60130 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:38:57.287964 ops/training.py:65 2019-01-16 11:38:57.287902: step 11353, loss = 0.59543 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:38:58.248755 ops/training.py:65 2019-01-16 11:38:58.248696: step 11354, loss = 0.65212 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:38:59.213390 ops/training.py:65 2019-01-16 11:38:59.213342: step 11355, loss = 0.65845 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:39:00.176350 ops/training.py:65 2019-01-16 11:39:00.176288: step 11356, loss = 0.60262 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:39:01.135901 ops/training.py:65 2019-01-16 11:39:01.135833: step 11357, loss = 0.58947 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:39:02.095483 ops/training.py:65 2019-01-16 11:39:02.095416: step 11358, loss = 0.56238 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:39:03.059145 ops/training.py:65 2019-01-16 11:39:03.059091: step 11359, loss = 0.49854 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:39:04.022186 ops/training.py:65 2019-01-16 11:39:04.022134: step 11360, loss = 0.47979 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:39:04.985345 ops/training.py:65 2019-01-16 11:39:04.985285: step 11361, loss = 0.66175 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:39:05.947482 ops/training.py:65 2019-01-16 11:39:05.947413: step 11362, loss = 0.59159 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:39:06.908229 ops/training.py:65 2019-01-16 11:39:06.908168: step 11363, loss = 0.51417 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:39:07.868735 ops/training.py:65 2019-01-16 11:39:07.868671: step 11364, loss = 0.64829 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:39:08.828483 ops/training.py:65 2019-01-16 11:39:08.828421: step 11365, loss = 0.54029 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:39:09.787324 ops/training.py:65 2019-01-16 11:39:09.787249: step 11366, loss = 0.58835 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:39:10.747413 ops/training.py:65 2019-01-16 11:39:10.747354: step 11367, loss = 0.66713 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:39:11.707208 ops/training.py:65 2019-01-16 11:39:11.707152: step 11368, loss = 0.55590 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:39:12.667177 ops/training.py:65 2019-01-16 11:39:12.667118: step 11369, loss = 0.54279 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:39:13.627325 ops/training.py:65 2019-01-16 11:39:13.627262: step 11370, loss = 0.61973 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:39:14.587462 ops/training.py:65 2019-01-16 11:39:14.587405: step 11371, loss = 0.64538 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:39:15.547538 ops/training.py:65 2019-01-16 11:39:15.547478: step 11372, loss = 0.59005 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:39:16.506645 ops/training.py:65 2019-01-16 11:39:16.506580: step 11373, loss = 0.62833 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:39:17.466324 ops/training.py:65 2019-01-16 11:39:17.466275: step 11374, loss = 0.69015 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:39:18.430825 ops/training.py:65 2019-01-16 11:39:18.430763: step 11375, loss = 0.55106 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:39:19.395462 ops/training.py:65 2019-01-16 11:39:19.395394: step 11376, loss = 0.64351 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:39:20.358646 ops/training.py:65 2019-01-16 11:39:20.358580: step 11377, loss = 0.58777 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:39:21.321332 ops/training.py:65 2019-01-16 11:39:21.321266: step 11378, loss = 0.56603 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:39:22.284680 ops/training.py:65 2019-01-16 11:39:22.284619: step 11379, loss = 0.58144 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:39:23.245140 ops/training.py:65 2019-01-16 11:39:23.245078: step 11380, loss = 0.68399 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:39:24.205469 ops/training.py:65 2019-01-16 11:39:24.205406: step 11381, loss = 0.65474 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:39:25.165183 ops/training.py:65 2019-01-16 11:39:25.165119: step 11382, loss = 0.69128 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:39:26.125792 ops/training.py:65 2019-01-16 11:39:26.125722: step 11383, loss = 0.68793 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:39:27.084764 ops/training.py:65 2019-01-16 11:39:27.084697: step 11384, loss = 0.65072 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:39:28.044908 ops/training.py:65 2019-01-16 11:39:28.044844: step 11385, loss = 0.61916 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:39:29.009506 ops/training.py:65 2019-01-16 11:39:29.009449: step 11386, loss = 0.57524 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:39:29.972433 ops/training.py:65 2019-01-16 11:39:29.972378: step 11387, loss = 0.48531 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:39:30.932400 ops/training.py:65 2019-01-16 11:39:30.932331: step 11388, loss = 0.64596 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:39:31.896687 ops/training.py:65 2019-01-16 11:39:31.896628: step 11389, loss = 0.68742 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:39:32.860306 ops/training.py:65 2019-01-16 11:39:32.860247: step 11390, loss = 0.56347 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:39:33.821620 ops/training.py:65 2019-01-16 11:39:33.821549: step 11391, loss = 0.54938 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:39:34.785460 ops/training.py:65 2019-01-16 11:39:34.785397: step 11392, loss = 0.58477 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:39:35.749200 ops/training.py:65 2019-01-16 11:39:35.749132: step 11393, loss = 0.56625 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:39:36.712348 ops/training.py:65 2019-01-16 11:39:36.712289: step 11394, loss = 0.54948 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:39:37.675378 ops/training.py:65 2019-01-16 11:39:37.675317: step 11395, loss = 0.58492 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:39:38.636814 ops/training.py:65 2019-01-16 11:39:38.636756: step 11396, loss = 0.65416 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:39:39.600206 ops/training.py:65 2019-01-16 11:39:39.600134: step 11397, loss = 0.73571 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:39:40.564043 ops/training.py:65 2019-01-16 11:39:40.563986: step 11398, loss = 0.61819 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:39:41.527411 ops/training.py:65 2019-01-16 11:39:41.527355: step 11399, loss = 0.61676 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:39:42.490892 ops/training.py:65 2019-01-16 11:39:42.490835: step 11400, loss = 0.62060 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:39:43.452959 ops/training.py:65 2019-01-16 11:39:43.452881: step 11401, loss = 0.61426 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:39:44.413364 ops/training.py:65 2019-01-16 11:39:44.413306: step 11402, loss = 0.69995 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:39:45.374284 ops/training.py:65 2019-01-16 11:39:45.374225: step 11403, loss = 0.69263 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:39:46.333639 ops/training.py:65 2019-01-16 11:39:46.333572: step 11404, loss = 0.56822 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:39:47.293389 ops/training.py:65 2019-01-16 11:39:47.293328: step 11405, loss = 0.69929 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:39:48.255671 ops/training.py:65 2019-01-16 11:39:48.255618: step 11406, loss = 0.64041 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:39:49.218265 ops/training.py:65 2019-01-16 11:39:49.218207: step 11407, loss = 0.51339 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:39:50.180288 ops/training.py:65 2019-01-16 11:39:50.180225: step 11408, loss = 0.65137 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:39:51.140015 ops/training.py:65 2019-01-16 11:39:51.139947: step 11409, loss = 0.47735 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:39:52.101286 ops/training.py:65 2019-01-16 11:39:52.101226: step 11410, loss = 0.53882 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:39:53.065025 ops/training.py:65 2019-01-16 11:39:53.064967: step 11411, loss = 0.58725 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:39:54.028227 ops/training.py:65 2019-01-16 11:39:54.028169: step 11412, loss = 0.65705 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:39:54.991281 ops/training.py:65 2019-01-16 11:39:54.991230: step 11413, loss = 0.62197 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:39:55.952800 ops/training.py:65 2019-01-16 11:39:55.952741: step 11414, loss = 0.65057 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:39:56.914090 ops/training.py:65 2019-01-16 11:39:56.914030: step 11415, loss = 0.60498 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:39:57.875024 ops/training.py:65 2019-01-16 11:39:57.874962: step 11416, loss = 0.54055 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:39:58.836576 ops/training.py:65 2019-01-16 11:39:58.836524: step 11417, loss = 0.61045 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:39:59.799394 ops/training.py:65 2019-01-16 11:39:59.799333: step 11418, loss = 0.51598 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:40:00.760195 ops/training.py:65 2019-01-16 11:40:00.760137: step 11419, loss = 0.63466 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:40:01.721239 ops/training.py:65 2019-01-16 11:40:01.721183: step 11420, loss = 0.59176 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:40:02.682148 ops/training.py:65 2019-01-16 11:40:02.682066: step 11421, loss = 0.60775 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:40:03.643980 ops/training.py:65 2019-01-16 11:40:03.643897: step 11422, loss = 0.63477 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:40:04.607987 ops/training.py:65 2019-01-16 11:40:04.607905: step 11423, loss = 0.59153 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:40:05.570446 ops/training.py:65 2019-01-16 11:40:05.570361: step 11424, loss = 0.53934 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:40:06.532966 ops/training.py:65 2019-01-16 11:40:06.532865: step 11425, loss = 0.60950 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:40:07.497419 ops/training.py:65 2019-01-16 11:40:07.497356: step 11426, loss = 0.57435 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:40:08.461152 ops/training.py:65 2019-01-16 11:40:08.461090: step 11427, loss = 0.62625 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:40:09.422818 ops/training.py:65 2019-01-16 11:40:09.422759: step 11428, loss = 0.69139 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:40:10.386745 ops/training.py:65 2019-01-16 11:40:10.386686: step 11429, loss = 0.55547 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:40:11.348206 ops/training.py:65 2019-01-16 11:40:11.348144: step 11430, loss = 0.65246 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:40:12.311545 ops/training.py:65 2019-01-16 11:40:12.311489: step 11431, loss = 0.60920 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:40:13.274157 ops/training.py:65 2019-01-16 11:40:13.274099: step 11432, loss = 0.60951 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:40:14.236650 ops/training.py:65 2019-01-16 11:40:14.236568: step 11433, loss = 0.66989 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:40:15.198026 ops/training.py:65 2019-01-16 11:40:15.197968: step 11434, loss = 0.60476 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:40:16.159691 ops/training.py:65 2019-01-16 11:40:16.159630: step 11435, loss = 0.55950 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:40:17.119754 ops/training.py:65 2019-01-16 11:40:17.119693: step 11436, loss = 0.63291 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:40:18.080239 ops/training.py:65 2019-01-16 11:40:18.080166: step 11437, loss = 0.73363 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:40:19.040001 ops/training.py:65 2019-01-16 11:40:19.039929: step 11438, loss = 0.51790 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:40:19.999930 ops/training.py:65 2019-01-16 11:40:19.999870: step 11439, loss = 0.41952 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 11:40:20.959373 ops/training.py:65 2019-01-16 11:40:20.959314: step 11440, loss = 0.59533 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:40:21.918941 ops/training.py:65 2019-01-16 11:40:21.918886: step 11441, loss = 0.54242 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:40:22.878292 ops/training.py:65 2019-01-16 11:40:22.878237: step 11442, loss = 0.62678 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:40:23.837474 ops/training.py:65 2019-01-16 11:40:23.837417: step 11443, loss = 0.54381 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:40:24.796901 ops/training.py:65 2019-01-16 11:40:24.796843: step 11444, loss = 0.54753 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:40:25.760703 ops/training.py:65 2019-01-16 11:40:25.760628: step 11445, loss = 0.69819 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:40:26.724303 ops/training.py:65 2019-01-16 11:40:26.724228: step 11446, loss = 0.60049 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:40:27.688044 ops/training.py:65 2019-01-16 11:40:27.687967: step 11447, loss = 0.58742 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:40:28.648128 ops/training.py:65 2019-01-16 11:40:28.648069: step 11448, loss = 0.54255 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:40:29.608418 ops/training.py:65 2019-01-16 11:40:29.608343: step 11449, loss = 0.58886 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:40:30.571708 ops/training.py:65 2019-01-16 11:40:30.571631: step 11450, loss = 0.58239 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:40:31.535291 ops/training.py:65 2019-01-16 11:40:31.535231: step 11451, loss = 0.52538 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:40:32.497688 ops/training.py:65 2019-01-16 11:40:32.497624: step 11452, loss = 0.60589 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:40:33.459872 ops/training.py:65 2019-01-16 11:40:33.459803: step 11453, loss = 0.68903 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:40:34.420443 ops/training.py:65 2019-01-16 11:40:34.420362: step 11454, loss = 0.63413 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:40:35.380052 ops/training.py:65 2019-01-16 11:40:35.379994: step 11455, loss = 0.57390 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:40:36.344903 ops/training.py:65 2019-01-16 11:40:36.344853: step 11456, loss = 0.61884 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:40:37.305688 ops/training.py:65 2019-01-16 11:40:37.305593: step 11457, loss = 0.51915 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:40:38.264859 ops/training.py:65 2019-01-16 11:40:38.264794: step 11458, loss = 0.52603 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:40:39.229296 ops/training.py:65 2019-01-16 11:40:39.229235: step 11459, loss = 0.65708 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:40:40.191647 ops/training.py:65 2019-01-16 11:40:40.191594: step 11460, loss = 0.59447 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:40:41.151978 ops/training.py:65 2019-01-16 11:40:41.151925: step 11461, loss = 0.54174 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:40:42.111830 ops/training.py:65 2019-01-16 11:40:42.111766: step 11462, loss = 0.52608 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:40:43.075341 ops/training.py:65 2019-01-16 11:40:43.075262: step 11463, loss = 0.52175 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:40:44.039708 ops/training.py:65 2019-01-16 11:40:44.039653: step 11464, loss = 0.71758 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:40:45.002133 ops/training.py:65 2019-01-16 11:40:45.002075: step 11465, loss = 0.60326 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:40:45.964749 ops/training.py:65 2019-01-16 11:40:45.964691: step 11466, loss = 0.60733 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:40:46.925767 ops/training.py:65 2019-01-16 11:40:46.925709: step 11467, loss = 0.66184 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:40:47.890012 ops/training.py:65 2019-01-16 11:40:47.889952: step 11468, loss = 0.62866 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:40:48.853588 ops/training.py:65 2019-01-16 11:40:48.853530: step 11469, loss = 0.50898 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:40:49.815081 ops/training.py:65 2019-01-16 11:40:49.815025: step 11470, loss = 0.49240 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:40:50.774315 ops/training.py:65 2019-01-16 11:40:50.774248: step 11471, loss = 0.54489 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:40:51.735424 ops/training.py:65 2019-01-16 11:40:51.735369: step 11472, loss = 0.51181 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:40:52.693993 ops/training.py:65 2019-01-16 11:40:52.693932: step 11473, loss = 0.57758 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:40:53.654090 ops/training.py:65 2019-01-16 11:40:53.654027: step 11474, loss = 0.52951 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:40:54.612944 ops/training.py:65 2019-01-16 11:40:54.612880: step 11475, loss = 0.74294 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:40:55.572430 ops/training.py:65 2019-01-16 11:40:55.572363: step 11476, loss = 0.59518 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:40:56.531699 ops/training.py:65 2019-01-16 11:40:56.531644: step 11477, loss = 0.60669 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:40:57.490141 ops/training.py:65 2019-01-16 11:40:57.490082: step 11478, loss = 0.66815 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:40:58.452313 ops/training.py:65 2019-01-16 11:40:58.452252: step 11479, loss = 0.77680 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 11:40:59.415267 ops/training.py:65 2019-01-16 11:40:59.415191: step 11480, loss = 0.49660 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:41:00.376320 ops/training.py:65 2019-01-16 11:41:00.376244: step 11481, loss = 0.58173 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:41:01.337003 ops/training.py:65 2019-01-16 11:41:01.336944: step 11482, loss = 0.67765 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:41:02.296272 ops/training.py:65 2019-01-16 11:41:02.296218: step 11483, loss = 0.61352 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:41:03.259944 ops/training.py:65 2019-01-16 11:41:03.259886: step 11484, loss = 0.56756 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:41:04.222858 ops/training.py:65 2019-01-16 11:41:04.222800: step 11485, loss = 0.69214 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:41:05.183663 ops/training.py:65 2019-01-16 11:41:05.183606: step 11486, loss = 0.58889 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:41:06.143508 ops/training.py:65 2019-01-16 11:41:06.143451: step 11487, loss = 0.62039 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:41:07.101771 ops/training.py:65 2019-01-16 11:41:07.101704: step 11488, loss = 0.61708 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:41:08.065910 ops/training.py:65 2019-01-16 11:41:08.065827: step 11489, loss = 0.61061 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:41:09.030935 ops/training.py:65 2019-01-16 11:41:09.030869: step 11490, loss = 0.61428 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:41:09.993543 ops/training.py:65 2019-01-16 11:41:09.993475: step 11491, loss = 0.53864 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:41:10.955321 ops/training.py:65 2019-01-16 11:41:10.955267: step 11492, loss = 0.64005 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:41:11.918047 ops/training.py:65 2019-01-16 11:41:11.917967: step 11493, loss = 0.58035 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:41:12.880885 ops/training.py:65 2019-01-16 11:41:12.880809: step 11494, loss = 0.56392 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:41:13.841701 ops/training.py:65 2019-01-16 11:41:13.841620: step 11495, loss = 0.63715 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:41:14.801272 ops/training.py:65 2019-01-16 11:41:14.801215: step 11496, loss = 0.57931 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:41:15.764958 ops/training.py:65 2019-01-16 11:41:15.764897: step 11497, loss = 0.60628 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:41:16.727767 ops/training.py:65 2019-01-16 11:41:16.727706: step 11498, loss = 0.72920 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:41:17.688041 ops/training.py:65 2019-01-16 11:41:17.687992: step 11499, loss = 0.47816 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:41:18.646973 ops/training.py:65 2019-01-16 11:41:18.646922: step 11500, loss = 0.56163 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:41:19.606010 ops/training.py:65 2019-01-16 11:41:19.605933: step 11501, loss = 0.60823 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:41:20.570043 ops/training.py:65 2019-01-16 11:41:20.569955: step 11502, loss = 0.58213 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:41:21.533593 ops/training.py:65 2019-01-16 11:41:21.533542: step 11503, loss = 0.55830 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:41:22.495126 ops/training.py:65 2019-01-16 11:41:22.495072: step 11504, loss = 0.55979 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:41:23.456370 ops/training.py:65 2019-01-16 11:41:23.456310: step 11505, loss = 0.59143 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:41:24.416941 ops/training.py:65 2019-01-16 11:41:24.416883: step 11506, loss = 0.60456 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:41:25.379997 ops/training.py:65 2019-01-16 11:41:25.379935: step 11507, loss = 0.66605 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:41:26.343377 ops/training.py:65 2019-01-16 11:41:26.343302: step 11508, loss = 0.68675 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:41:27.305058 ops/training.py:65 2019-01-16 11:41:27.304985: step 11509, loss = 0.57997 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:41:28.268093 ops/training.py:65 2019-01-16 11:41:28.268017: step 11510, loss = 0.60961 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:41:29.231491 ops/training.py:65 2019-01-16 11:41:29.231417: step 11511, loss = 0.44699 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:41:30.193099 ops/training.py:65 2019-01-16 11:41:30.193039: step 11512, loss = 0.52910 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:41:31.157236 ops/training.py:65 2019-01-16 11:41:31.157176: step 11513, loss = 0.81836 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:41:32.120434 ops/training.py:65 2019-01-16 11:41:32.120382: step 11514, loss = 0.51783 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:41:33.082319 ops/training.py:65 2019-01-16 11:41:33.082245: step 11515, loss = 0.61632 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:41:34.042407 ops/training.py:65 2019-01-16 11:41:34.042350: step 11516, loss = 0.60857 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:41:35.006702 ops/training.py:65 2019-01-16 11:41:35.006628: step 11517, loss = 0.82440 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:41:35.968185 ops/training.py:65 2019-01-16 11:41:35.968111: step 11518, loss = 0.49713 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:41:36.928232 ops/training.py:65 2019-01-16 11:41:36.928174: step 11519, loss = 0.54526 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:41:37.889754 ops/training.py:65 2019-01-16 11:41:37.889679: step 11520, loss = 0.68252 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:41:38.849082 ops/training.py:65 2019-01-16 11:41:38.849023: step 11521, loss = 0.59383 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:41:39.807945 ops/training.py:65 2019-01-16 11:41:39.807885: step 11522, loss = 0.68254 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:41:40.771212 ops/training.py:65 2019-01-16 11:41:40.771138: step 11523, loss = 0.61023 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:41:41.734307 ops/training.py:65 2019-01-16 11:41:41.734231: step 11524, loss = 0.65028 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:41:42.697063 ops/training.py:65 2019-01-16 11:41:42.696984: step 11525, loss = 0.63657 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:41:43.659592 ops/training.py:65 2019-01-16 11:41:43.659510: step 11526, loss = 0.57748 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:41:44.622547 ops/training.py:65 2019-01-16 11:41:44.622495: step 11527, loss = 0.57250 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:41:45.582978 ops/training.py:65 2019-01-16 11:41:45.582897: step 11528, loss = 0.60915 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:41:46.543577 ops/training.py:65 2019-01-16 11:41:46.543500: step 11529, loss = 0.56771 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:41:47.502696 ops/training.py:65 2019-01-16 11:41:47.502641: step 11530, loss = 0.62213 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:41:48.466854 ops/training.py:65 2019-01-16 11:41:48.466799: step 11531, loss = 0.53697 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:41:49.430126 ops/training.py:65 2019-01-16 11:41:49.430051: step 11532, loss = 0.75376 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:41:50.393941 ops/training.py:65 2019-01-16 11:41:50.393883: step 11533, loss = 0.68406 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:41:51.355632 ops/training.py:65 2019-01-16 11:41:51.355580: step 11534, loss = 0.58268 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:41:52.317400 ops/training.py:65 2019-01-16 11:41:52.317347: step 11535, loss = 0.59627 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:41:53.277589 ops/training.py:65 2019-01-16 11:41:53.277528: step 11536, loss = 0.65902 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:41:54.238582 ops/training.py:65 2019-01-16 11:41:54.238510: step 11537, loss = 0.64446 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:41:55.202413 ops/training.py:65 2019-01-16 11:41:55.202336: step 11538, loss = 0.62875 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:41:56.164973 ops/training.py:65 2019-01-16 11:41:56.164896: step 11539, loss = 0.68380 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:41:57.127560 ops/training.py:65 2019-01-16 11:41:57.127481: step 11540, loss = 0.62851 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:41:58.088760 ops/training.py:65 2019-01-16 11:41:58.088680: step 11541, loss = 0.65467 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:41:59.052418 ops/training.py:65 2019-01-16 11:41:59.052345: step 11542, loss = 0.59021 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:42:00.013601 ops/training.py:65 2019-01-16 11:42:00.013546: step 11543, loss = 0.57623 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:42:00.973092 ops/training.py:65 2019-01-16 11:42:00.973034: step 11544, loss = 0.62103 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:42:01.932002 ops/training.py:65 2019-01-16 11:42:01.931946: step 11545, loss = 0.61359 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:42:02.895321 ops/training.py:65 2019-01-16 11:42:02.895262: step 11546, loss = 0.60962 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:42:03.859597 ops/training.py:65 2019-01-16 11:42:03.859522: step 11547, loss = 0.55161 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:42:04.823073 ops/training.py:65 2019-01-16 11:42:04.822995: step 11548, loss = 0.69363 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:42:05.785933 ops/training.py:65 2019-01-16 11:42:05.785859: step 11549, loss = 0.55974 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:42:06.746898 ops/training.py:65 2019-01-16 11:42:06.746824: step 11550, loss = 0.55315 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:42:07.707311 ops/training.py:65 2019-01-16 11:42:07.707235: step 11551, loss = 0.59279 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:42:08.666901 ops/training.py:65 2019-01-16 11:42:08.666836: step 11552, loss = 0.75113 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:42:09.631039 ops/training.py:65 2019-01-16 11:42:09.630963: step 11553, loss = 0.59286 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:42:10.591957 ops/training.py:65 2019-01-16 11:42:10.591881: step 11554, loss = 0.50574 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:42:11.557407 ops/training.py:65 2019-01-16 11:42:11.557348: step 11555, loss = 0.60877 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:42:12.520518 ops/training.py:65 2019-01-16 11:42:12.520460: step 11556, loss = 0.64380 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:42:13.481197 ops/training.py:65 2019-01-16 11:42:13.481137: step 11557, loss = 0.64650 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:42:14.445141 ops/training.py:65 2019-01-16 11:42:14.445088: step 11558, loss = 0.65461 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:42:15.406942 ops/training.py:65 2019-01-16 11:42:15.406886: step 11559, loss = 0.46639 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:42:16.371019 ops/training.py:65 2019-01-16 11:42:16.370962: step 11560, loss = 0.55635 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:42:17.334770 ops/training.py:65 2019-01-16 11:42:17.334693: step 11561, loss = 0.52200 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:42:18.297732 ops/training.py:65 2019-01-16 11:42:18.297654: step 11562, loss = 0.56988 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:42:19.259060 ops/training.py:65 2019-01-16 11:42:19.258981: step 11563, loss = 0.67770 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:42:20.219495 ops/training.py:65 2019-01-16 11:42:20.219443: step 11564, loss = 0.54334 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:42:21.179403 ops/training.py:65 2019-01-16 11:42:21.179323: step 11565, loss = 0.61466 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:42:22.138716 ops/training.py:65 2019-01-16 11:42:22.138661: step 11566, loss = 0.55892 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:42:23.097704 ops/training.py:65 2019-01-16 11:42:23.097644: step 11567, loss = 0.56936 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:42:24.061620 ops/training.py:65 2019-01-16 11:42:24.061562: step 11568, loss = 0.55637 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:42:25.024774 ops/training.py:65 2019-01-16 11:42:25.024696: step 11569, loss = 0.54445 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:42:25.983697 ops/training.py:65 2019-01-16 11:42:25.983643: step 11570, loss = 0.57331 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:42:26.941925 ops/training.py:65 2019-01-16 11:42:26.941855: step 11571, loss = 0.88686 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:42:27.899578 ops/training.py:65 2019-01-16 11:42:27.899510: step 11572, loss = 0.72324 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:42:28.857316 ops/training.py:65 2019-01-16 11:42:28.857263: step 11573, loss = 0.66561 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:42:29.815963 ops/training.py:65 2019-01-16 11:42:29.815894: step 11574, loss = 0.48706 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:42:30.779548 ops/training.py:65 2019-01-16 11:42:30.779498: step 11575, loss = 0.62544 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:42:31.743645 ops/training.py:65 2019-01-16 11:42:31.743570: step 11576, loss = 0.40941 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 11:42:32.707184 ops/training.py:65 2019-01-16 11:42:32.707103: step 11577, loss = 0.56797 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:42:33.669632 ops/training.py:65 2019-01-16 11:42:33.669575: step 11578, loss = 0.54028 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:42:34.630563 ops/training.py:65 2019-01-16 11:42:34.630489: step 11579, loss = 0.51381 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:42:35.591721 ops/training.py:65 2019-01-16 11:42:35.591642: step 11580, loss = 0.45808 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:42:36.551831 ops/training.py:65 2019-01-16 11:42:36.551758: step 11581, loss = 0.45745 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:42:37.510243 ops/training.py:65 2019-01-16 11:42:37.510168: step 11582, loss = 0.49051 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:42:38.470037 ops/training.py:65 2019-01-16 11:42:38.469952: step 11583, loss = 0.55294 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:42:39.428140 ops/training.py:65 2019-01-16 11:42:39.428068: step 11584, loss = 0.49803 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:42:40.390826 ops/training.py:65 2019-01-16 11:42:40.390756: step 11585, loss = 0.48150 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:42:41.354317 ops/training.py:65 2019-01-16 11:42:41.354241: step 11586, loss = 0.53510 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:42:42.317755 ops/training.py:65 2019-01-16 11:42:42.317673: step 11587, loss = 0.64757 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:42:43.279698 ops/training.py:65 2019-01-16 11:42:43.279621: step 11588, loss = 0.75054 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:42:44.242825 ops/training.py:65 2019-01-16 11:42:44.242740: step 11589, loss = 0.62111 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:42:45.203665 ops/training.py:65 2019-01-16 11:42:45.203608: step 11590, loss = 0.54721 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:42:46.166494 ops/training.py:65 2019-01-16 11:42:46.166437: step 11591, loss = 0.48230 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:42:47.129441 ops/training.py:65 2019-01-16 11:42:47.129382: step 11592, loss = 0.65977 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:42:48.092531 ops/training.py:65 2019-01-16 11:42:48.092467: step 11593, loss = 0.44494 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:42:49.054892 ops/training.py:65 2019-01-16 11:42:49.054840: step 11594, loss = 0.64969 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:42:50.016578 ops/training.py:65 2019-01-16 11:42:50.016518: step 11595, loss = 0.63863 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:42:50.979019 ops/training.py:65 2019-01-16 11:42:50.978961: step 11596, loss = 0.55450 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:42:51.943362 ops/training.py:65 2019-01-16 11:42:51.943285: step 11597, loss = 0.56093 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:42:52.907201 ops/training.py:65 2019-01-16 11:42:52.907145: step 11598, loss = 0.65062 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:42:53.869942 ops/training.py:65 2019-01-16 11:42:53.869883: step 11599, loss = 0.54914 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:42:54.832434 ops/training.py:65 2019-01-16 11:42:54.832358: step 11600, loss = 0.62190 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:42:55.795856 ops/training.py:65 2019-01-16 11:42:55.795805: step 11601, loss = 0.56227 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:42:56.759768 ops/training.py:65 2019-01-16 11:42:56.759715: step 11602, loss = 0.60251 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:42:57.722554 ops/training.py:65 2019-01-16 11:42:57.722493: step 11603, loss = 0.59871 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:42:58.683791 ops/training.py:65 2019-01-16 11:42:58.683738: step 11604, loss = 0.54761 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:42:59.644254 ops/training.py:65 2019-01-16 11:42:59.644178: step 11605, loss = 0.59761 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:43:00.609195 ops/training.py:65 2019-01-16 11:43:00.609117: step 11606, loss = 0.61321 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:43:01.572902 ops/training.py:65 2019-01-16 11:43:01.572834: step 11607, loss = 0.57872 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:43:02.536171 ops/training.py:65 2019-01-16 11:43:02.536091: step 11608, loss = 0.53218 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:43:03.499563 ops/training.py:65 2019-01-16 11:43:03.499510: step 11609, loss = 0.61500 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:43:04.461980 ops/training.py:65 2019-01-16 11:43:04.461922: step 11610, loss = 0.53130 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:43:05.423631 ops/training.py:65 2019-01-16 11:43:05.423581: step 11611, loss = 0.52001 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:43:06.385592 ops/training.py:65 2019-01-16 11:43:06.385532: step 11612, loss = 0.56738 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:43:07.347224 ops/training.py:65 2019-01-16 11:43:07.347168: step 11613, loss = 0.61099 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:43:08.309196 ops/training.py:65 2019-01-16 11:43:08.309139: step 11614, loss = 0.59812 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:43:09.271563 ops/training.py:65 2019-01-16 11:43:09.271511: step 11615, loss = 0.53460 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:43:10.233785 ops/training.py:65 2019-01-16 11:43:10.233708: step 11616, loss = 0.69951 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:43:11.195658 ops/training.py:65 2019-01-16 11:43:11.195584: step 11617, loss = 0.55676 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:43:12.158350 ops/training.py:65 2019-01-16 11:43:12.158273: step 11618, loss = 0.54929 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:43:13.118072 ops/training.py:65 2019-01-16 11:43:13.118019: step 11619, loss = 0.55659 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:43:14.078001 ops/training.py:65 2019-01-16 11:43:14.077943: step 11620, loss = 0.60209 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:43:15.041498 ops/training.py:65 2019-01-16 11:43:15.041446: step 11621, loss = 0.67395 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:43:16.005187 ops/training.py:65 2019-01-16 11:43:16.005130: step 11622, loss = 0.50383 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:43:16.968914 ops/training.py:65 2019-01-16 11:43:16.968859: step 11623, loss = 0.59530 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:43:17.931139 ops/training.py:65 2019-01-16 11:43:17.931083: step 11624, loss = 0.61913 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:43:18.894113 ops/training.py:65 2019-01-16 11:43:18.894061: step 11625, loss = 0.58246 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:43:19.857479 ops/training.py:65 2019-01-16 11:43:19.857425: step 11626, loss = 0.61850 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:43:20.819702 ops/training.py:65 2019-01-16 11:43:20.819648: step 11627, loss = 0.51255 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:43:21.781442 ops/training.py:65 2019-01-16 11:43:21.781396: step 11628, loss = 0.64594 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:43:22.743659 ops/training.py:65 2019-01-16 11:43:22.743610: step 11629, loss = 0.50871 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:43:23.706016 ops/training.py:65 2019-01-16 11:43:23.705941: step 11630, loss = 0.51872 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:43:24.669121 ops/training.py:65 2019-01-16 11:43:24.669049: step 11631, loss = 0.65407 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:43:25.631911 ops/training.py:65 2019-01-16 11:43:25.631841: step 11632, loss = 0.48447 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:43:26.594980 ops/training.py:65 2019-01-16 11:43:26.594909: step 11633, loss = 0.62737 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:43:27.557573 ops/training.py:65 2019-01-16 11:43:27.557498: step 11634, loss = 0.50699 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:43:28.519723 ops/training.py:65 2019-01-16 11:43:28.519648: step 11635, loss = 0.71796 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:43:29.483305 ops/training.py:65 2019-01-16 11:43:29.483235: step 11636, loss = 0.56244 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:43:30.443384 ops/training.py:65 2019-01-16 11:43:30.443313: step 11637, loss = 0.56498 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:43:31.407032 ops/training.py:65 2019-01-16 11:43:31.406979: step 11638, loss = 0.49609 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:43:32.371393 ops/training.py:65 2019-01-16 11:43:32.371337: step 11639, loss = 0.53834 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:43:33.334983 ops/training.py:65 2019-01-16 11:43:33.334932: step 11640, loss = 0.51161 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:43:34.297098 ops/training.py:65 2019-01-16 11:43:34.297043: step 11641, loss = 0.58000 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:43:35.260218 ops/training.py:65 2019-01-16 11:43:35.260169: step 11642, loss = 0.50028 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:43:36.223587 ops/training.py:65 2019-01-16 11:43:36.223513: step 11643, loss = 0.47611 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:43:37.186085 ops/training.py:65 2019-01-16 11:43:37.186014: step 11644, loss = 0.60511 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:43:38.148235 ops/training.py:65 2019-01-16 11:43:38.148157: step 11645, loss = 0.58441 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:43:39.111602 ops/training.py:65 2019-01-16 11:43:39.111544: step 11646, loss = 0.52392 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:43:40.074143 ops/training.py:65 2019-01-16 11:43:40.074084: step 11647, loss = 0.67167 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:43:41.036391 ops/training.py:65 2019-01-16 11:43:41.036342: step 11648, loss = 0.47467 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:43:41.996967 ops/training.py:65 2019-01-16 11:43:41.996904: step 11649, loss = 0.67704 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:43:42.957907 ops/training.py:65 2019-01-16 11:43:42.957834: step 11650, loss = 0.48112 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:43:43.923107 ops/training.py:65 2019-01-16 11:43:43.923031: step 11651, loss = 0.54296 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:43:44.886504 ops/training.py:65 2019-01-16 11:43:44.886430: step 11652, loss = 0.67694 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:43:45.850319 ops/training.py:65 2019-01-16 11:43:45.850242: step 11653, loss = 0.50454 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:43:46.813368 ops/training.py:65 2019-01-16 11:43:46.813297: step 11654, loss = 0.71119 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:43:47.772348 ops/training.py:65 2019-01-16 11:43:47.772278: step 11655, loss = 0.47312 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:43:48.734274 ops/training.py:65 2019-01-16 11:43:48.734214: step 11656, loss = 0.61453 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:43:49.696888 ops/training.py:65 2019-01-16 11:43:49.696816: step 11657, loss = 0.60975 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:43:50.662541 ops/training.py:65 2019-01-16 11:43:50.662484: step 11658, loss = 0.54305 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:43:51.629967 ops/training.py:65 2019-01-16 11:43:51.629893: step 11659, loss = 0.71633 (33.1 examples/sec; 0.966 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:43:52.592579 ops/training.py:65 2019-01-16 11:43:52.592531: step 11660, loss = 0.50545 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:43:53.559847 ops/training.py:65 2019-01-16 11:43:53.559774: step 11661, loss = 0.84277 (33.1 examples/sec; 0.966 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:43:54.522309 ops/training.py:65 2019-01-16 11:43:54.522244: step 11662, loss = 0.69147 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:43:55.484487 ops/training.py:65 2019-01-16 11:43:55.484439: step 11663, loss = 0.64598 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:43:56.445939 ops/training.py:65 2019-01-16 11:43:56.445890: step 11664, loss = 0.62012 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:43:57.407750 ops/training.py:65 2019-01-16 11:43:57.407699: step 11665, loss = 0.70383 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:43:58.369534 ops/training.py:65 2019-01-16 11:43:58.369481: step 11666, loss = 0.72217 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:43:59.331027 ops/training.py:65 2019-01-16 11:43:59.330981: step 11667, loss = 0.62214 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:44:00.293597 ops/training.py:65 2019-01-16 11:44:00.293545: step 11668, loss = 0.53447 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:44:01.255764 ops/training.py:65 2019-01-16 11:44:01.255711: step 11669, loss = 0.58374 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:44:02.218066 ops/training.py:65 2019-01-16 11:44:02.218011: step 11670, loss = 0.70696 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:44:03.180197 ops/training.py:65 2019-01-16 11:44:03.180148: step 11671, loss = 0.52835 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:44:04.142127 ops/training.py:65 2019-01-16 11:44:04.142078: step 11672, loss = 0.51528 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:44:05.103857 ops/training.py:65 2019-01-16 11:44:05.103807: step 11673, loss = 0.52155 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:44:06.064733 ops/training.py:65 2019-01-16 11:44:06.064687: step 11674, loss = 0.51965 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:44:07.026010 ops/training.py:65 2019-01-16 11:44:07.025961: step 11675, loss = 0.51540 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:44:07.989259 ops/training.py:65 2019-01-16 11:44:07.989191: step 11676, loss = 0.70094 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:44:08.950566 ops/training.py:65 2019-01-16 11:44:08.950505: step 11677, loss = 0.69667 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:44:09.912200 ops/training.py:65 2019-01-16 11:44:09.912145: step 11678, loss = 0.56858 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:44:10.874363 ops/training.py:65 2019-01-16 11:44:10.874294: step 11679, loss = 0.63620 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:44:11.837399 ops/training.py:65 2019-01-16 11:44:11.837327: step 11680, loss = 0.66562 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:44:12.797819 ops/training.py:65 2019-01-16 11:44:12.797744: step 11681, loss = 0.60609 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:44:13.761822 ops/training.py:65 2019-01-16 11:44:13.761770: step 11682, loss = 0.54443 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:44:14.725674 ops/training.py:65 2019-01-16 11:44:14.725607: step 11683, loss = 0.57495 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:44:15.688982 ops/training.py:65 2019-01-16 11:44:15.688927: step 11684, loss = 0.51339 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:44:16.651346 ops/training.py:65 2019-01-16 11:44:16.651296: step 11685, loss = 0.58994 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:44:17.613377 ops/training.py:65 2019-01-16 11:44:17.613321: step 11686, loss = 0.50324 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:44:18.575707 ops/training.py:65 2019-01-16 11:44:18.575633: step 11687, loss = 0.51742 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:44:19.537933 ops/training.py:65 2019-01-16 11:44:19.537878: step 11688, loss = 0.44122 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:44:20.500465 ops/training.py:65 2019-01-16 11:44:20.500413: step 11689, loss = 0.57863 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:44:21.463589 ops/training.py:65 2019-01-16 11:44:21.463526: step 11690, loss = 0.45873 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:44:22.426552 ops/training.py:65 2019-01-16 11:44:22.426504: step 11691, loss = 0.60599 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:44:23.389654 ops/training.py:65 2019-01-16 11:44:23.389582: step 11692, loss = 0.45775 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:44:24.352313 ops/training.py:65 2019-01-16 11:44:24.352247: step 11693, loss = 0.52735 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:44:25.316475 ops/training.py:65 2019-01-16 11:44:25.316425: step 11694, loss = 0.50858 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:44:26.278724 ops/training.py:65 2019-01-16 11:44:26.278645: step 11695, loss = 0.83684 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:44:27.241351 ops/training.py:65 2019-01-16 11:44:27.241278: step 11696, loss = 0.54727 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:44:28.203918 ops/training.py:65 2019-01-16 11:44:28.203859: step 11697, loss = 0.42581 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:44:29.166127 ops/training.py:65 2019-01-16 11:44:29.166088: step 11698, loss = 0.59850 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:44:30.128162 ops/training.py:65 2019-01-16 11:44:30.128102: step 11699, loss = 0.60187 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:44:31.090494 ops/training.py:65 2019-01-16 11:44:31.090434: step 11700, loss = 0.58647 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:44:32.053178 ops/training.py:65 2019-01-16 11:44:32.053124: step 11701, loss = 0.53037 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:44:33.015668 ops/training.py:65 2019-01-16 11:44:33.015617: step 11702, loss = 0.58626 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:44:33.979307 ops/training.py:65 2019-01-16 11:44:33.979254: step 11703, loss = 0.64199 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:44:34.940812 ops/training.py:65 2019-01-16 11:44:34.940742: step 11704, loss = 0.70127 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:44:35.903049 ops/training.py:65 2019-01-16 11:44:35.902998: step 11705, loss = 0.66458 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:44:36.864919 ops/training.py:65 2019-01-16 11:44:36.864864: step 11706, loss = 0.70940 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:44:37.826767 ops/training.py:65 2019-01-16 11:44:37.826699: step 11707, loss = 0.62396 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:44:38.789265 ops/training.py:65 2019-01-16 11:44:38.789201: step 11708, loss = 0.54725 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:44:39.752232 ops/training.py:65 2019-01-16 11:44:39.752171: step 11709, loss = 0.48779 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:44:40.714586 ops/training.py:65 2019-01-16 11:44:40.714516: step 11710, loss = 0.40721 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:44:41.677340 ops/training.py:65 2019-01-16 11:44:41.677269: step 11711, loss = 0.65121 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:44:42.639837 ops/training.py:65 2019-01-16 11:44:42.639763: step 11712, loss = 0.63581 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:44:43.602385 ops/training.py:65 2019-01-16 11:44:43.602327: step 11713, loss = 0.75341 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:44:44.565176 ops/training.py:65 2019-01-16 11:44:44.565122: step 11714, loss = 0.54275 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:44:45.526822 ops/training.py:65 2019-01-16 11:44:45.526770: step 11715, loss = 0.66745 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:44:46.487588 ops/training.py:65 2019-01-16 11:44:46.487535: step 11716, loss = 0.50466 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:44:47.449551 ops/training.py:65 2019-01-16 11:44:47.449480: step 11717, loss = 0.59239 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:44:48.411886 ops/training.py:65 2019-01-16 11:44:48.411835: step 11718, loss = 0.61137 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:44:49.374103 ops/training.py:65 2019-01-16 11:44:49.374052: step 11719, loss = 0.62275 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:44:50.335903 ops/training.py:65 2019-01-16 11:44:50.335860: step 11720, loss = 0.58628 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:44:51.298995 ops/training.py:65 2019-01-16 11:44:51.298923: step 11721, loss = 0.60129 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:44:52.261820 ops/training.py:65 2019-01-16 11:44:52.261769: step 11722, loss = 0.68956 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:44:53.223263 ops/training.py:65 2019-01-16 11:44:53.223209: step 11723, loss = 0.53760 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:44:54.184910 ops/training.py:65 2019-01-16 11:44:54.184855: step 11724, loss = 0.60090 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:44:55.146225 ops/training.py:65 2019-01-16 11:44:55.146172: step 11725, loss = 0.53115 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:44:56.106530 ops/training.py:65 2019-01-16 11:44:56.106474: step 11726, loss = 0.58559 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:44:57.071188 ops/training.py:65 2019-01-16 11:44:57.071136: step 11727, loss = 0.54737 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:44:58.035510 ops/training.py:65 2019-01-16 11:44:58.035456: step 11728, loss = 0.62191 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:44:58.995922 ops/training.py:65 2019-01-16 11:44:58.995869: step 11729, loss = 0.59612 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:44:59.960715 ops/training.py:65 2019-01-16 11:44:59.960643: step 11730, loss = 0.57210 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:45:00.925005 ops/training.py:65 2019-01-16 11:45:00.924938: step 11731, loss = 0.55911 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:45:01.887738 ops/training.py:65 2019-01-16 11:45:01.887674: step 11732, loss = 0.42956 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 11:45:02.848406 ops/training.py:65 2019-01-16 11:45:02.848345: step 11733, loss = 0.63600 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:45:03.809017 ops/training.py:65 2019-01-16 11:45:03.808962: step 11734, loss = 0.45559 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:45:04.771556 ops/training.py:65 2019-01-16 11:45:04.771496: step 11735, loss = 0.63106 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:45:05.733158 ops/training.py:65 2019-01-16 11:45:05.733065: step 11736, loss = 0.63897 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:45:06.696721 ops/training.py:65 2019-01-16 11:45:06.696661: step 11737, loss = 0.68811 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:45:07.658625 ops/training.py:65 2019-01-16 11:45:07.658560: step 11738, loss = 0.51957 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:45:08.620829 ops/training.py:65 2019-01-16 11:45:08.620776: step 11739, loss = 0.54527 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:45:09.583611 ops/training.py:65 2019-01-16 11:45:09.583557: step 11740, loss = 0.57085 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:45:10.545147 ops/training.py:65 2019-01-16 11:45:10.545101: step 11741, loss = 0.59101 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:45:11.506642 ops/training.py:65 2019-01-16 11:45:11.506586: step 11742, loss = 0.63203 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:45:12.468633 ops/training.py:65 2019-01-16 11:45:12.468579: step 11743, loss = 0.56497 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:45:13.429443 ops/training.py:65 2019-01-16 11:45:13.429389: step 11744, loss = 0.68009 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:45:14.389638 ops/training.py:65 2019-01-16 11:45:14.389600: step 11745, loss = 0.59152 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:45:15.351747 ops/training.py:65 2019-01-16 11:45:15.351693: step 11746, loss = 0.61413 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:45:16.314135 ops/training.py:65 2019-01-16 11:45:16.314082: step 11747, loss = 0.50640 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:45:17.274663 ops/training.py:65 2019-01-16 11:45:17.274611: step 11748, loss = 0.55882 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:45:18.239286 ops/training.py:65 2019-01-16 11:45:18.239233: step 11749, loss = 0.54683 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:45:19.201693 ops/training.py:65 2019-01-16 11:45:19.201640: step 11750, loss = 0.77034 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:45:20.164786 ops/training.py:65 2019-01-16 11:45:20.164733: step 11751, loss = 0.65054 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:45:21.124826 ops/training.py:65 2019-01-16 11:45:21.124774: step 11752, loss = 0.49452 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:45:22.088537 ops/training.py:65 2019-01-16 11:45:22.088497: step 11753, loss = 0.59103 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:45:23.052224 ops/training.py:65 2019-01-16 11:45:23.052180: step 11754, loss = 0.58651 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:45:24.016080 ops/training.py:65 2019-01-16 11:45:24.016040: step 11755, loss = 0.61444 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:45:24.977842 ops/training.py:65 2019-01-16 11:45:24.977802: step 11756, loss = 0.64433 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:45:25.939689 ops/training.py:65 2019-01-16 11:45:25.939646: step 11757, loss = 0.53780 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:45:26.902191 ops/training.py:65 2019-01-16 11:45:26.902153: step 11758, loss = 0.73443 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:45:27.863803 ops/training.py:65 2019-01-16 11:45:27.863762: step 11759, loss = 0.64925 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:45:28.827019 ops/training.py:65 2019-01-16 11:45:28.826981: step 11760, loss = 0.55832 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:45:29.789399 ops/training.py:65 2019-01-16 11:45:29.789360: step 11761, loss = 0.50275 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:45:30.751063 ops/training.py:65 2019-01-16 11:45:30.751018: step 11762, loss = 0.71631 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:45:31.715343 ops/training.py:65 2019-01-16 11:45:31.715287: step 11763, loss = 0.49166 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:45:32.679023 ops/training.py:65 2019-01-16 11:45:32.678968: step 11764, loss = 0.48737 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:45:33.641257 ops/training.py:65 2019-01-16 11:45:33.641208: step 11765, loss = 0.50433 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:45:34.603932 ops/training.py:65 2019-01-16 11:45:34.603869: step 11766, loss = 0.72562 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:45:35.568350 ops/training.py:65 2019-01-16 11:45:35.568295: step 11767, loss = 0.66676 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:45:36.529500 ops/training.py:65 2019-01-16 11:45:36.529456: step 11768, loss = 0.54513 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:45:37.493831 ops/training.py:65 2019-01-16 11:45:37.493772: step 11769, loss = 0.55493 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:45:38.457962 ops/training.py:65 2019-01-16 11:45:38.457901: step 11770, loss = 0.66367 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:45:39.420349 ops/training.py:65 2019-01-16 11:45:39.420289: step 11771, loss = 0.55825 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:45:40.384038 ops/training.py:65 2019-01-16 11:45:40.383998: step 11772, loss = 0.63247 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:45:41.348306 ops/training.py:65 2019-01-16 11:45:41.348256: step 11773, loss = 0.68135 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:45:42.311101 ops/training.py:65 2019-01-16 11:45:42.311047: step 11774, loss = 0.56277 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:45:43.274056 ops/training.py:65 2019-01-16 11:45:43.274002: step 11775, loss = 0.49061 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:45:44.235148 ops/training.py:65 2019-01-16 11:45:44.235092: step 11776, loss = 0.44125 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:45:45.196855 ops/training.py:65 2019-01-16 11:45:45.196798: step 11777, loss = 0.67591 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:45:46.158125 ops/training.py:65 2019-01-16 11:45:46.158085: step 11778, loss = 0.48043 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:45:47.119812 ops/training.py:65 2019-01-16 11:45:47.119758: step 11779, loss = 0.65291 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:45:48.082095 ops/training.py:65 2019-01-16 11:45:48.082041: step 11780, loss = 0.62152 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:45:49.043474 ops/training.py:65 2019-01-16 11:45:49.043420: step 11781, loss = 0.60891 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:45:50.004605 ops/training.py:65 2019-01-16 11:45:50.004549: step 11782, loss = 0.63983 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:45:50.966053 ops/training.py:65 2019-01-16 11:45:50.966013: step 11783, loss = 0.65391 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:45:51.928555 ops/training.py:65 2019-01-16 11:45:51.928506: step 11784, loss = 0.55580 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:45:52.890644 ops/training.py:65 2019-01-16 11:45:52.890604: step 11785, loss = 0.63333 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:45:53.852031 ops/training.py:65 2019-01-16 11:45:53.851977: step 11786, loss = 0.49278 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:45:54.813351 ops/training.py:65 2019-01-16 11:45:54.813297: step 11787, loss = 0.66922 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:45:55.774484 ops/training.py:65 2019-01-16 11:45:55.774434: step 11788, loss = 0.71498 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:45:56.736444 ops/training.py:65 2019-01-16 11:45:56.736392: step 11789, loss = 0.61110 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:45:57.698168 ops/training.py:65 2019-01-16 11:45:57.698114: step 11790, loss = 0.62008 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:45:58.662077 ops/training.py:65 2019-01-16 11:45:58.662028: step 11791, loss = 0.50375 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:45:59.624655 ops/training.py:65 2019-01-16 11:45:59.624603: step 11792, loss = 0.64347 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:46:00.586891 ops/training.py:65 2019-01-16 11:46:00.586842: step 11793, loss = 0.71449 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:46:01.550389 ops/training.py:65 2019-01-16 11:46:01.550341: step 11794, loss = 0.49959 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:46:02.511674 ops/training.py:65 2019-01-16 11:46:02.511630: step 11795, loss = 0.71668 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:46:03.472442 ops/training.py:65 2019-01-16 11:46:03.472383: step 11796, loss = 0.67317 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:46:04.434482 ops/training.py:65 2019-01-16 11:46:04.434429: step 11797, loss = 0.54957 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:46:05.396184 ops/training.py:65 2019-01-16 11:46:05.396134: step 11798, loss = 0.53940 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:46:06.358712 ops/training.py:65 2019-01-16 11:46:06.358666: step 11799, loss = 0.66892 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:46:07.320050 ops/training.py:65 2019-01-16 11:46:07.319992: step 11800, loss = 0.55984 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:46:08.282229 ops/training.py:65 2019-01-16 11:46:08.282175: step 11801, loss = 0.53232 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:46:09.243363 ops/training.py:65 2019-01-16 11:46:09.243311: step 11802, loss = 0.61666 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:46:10.204412 ops/training.py:65 2019-01-16 11:46:10.204361: step 11803, loss = 0.70774 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:46:11.165723 ops/training.py:65 2019-01-16 11:46:11.165671: step 11804, loss = 0.50451 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:46:12.127186 ops/training.py:65 2019-01-16 11:46:12.127133: step 11805, loss = 0.61032 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:46:13.088082 ops/training.py:65 2019-01-16 11:46:13.088029: step 11806, loss = 0.52728 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:46:14.050568 ops/training.py:65 2019-01-16 11:46:14.050514: step 11807, loss = 0.52892 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:46:15.011355 ops/training.py:65 2019-01-16 11:46:15.011305: step 11808, loss = 0.56091 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:46:15.972279 ops/training.py:65 2019-01-16 11:46:15.972218: step 11809, loss = 0.60041 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:46:16.932833 ops/training.py:65 2019-01-16 11:46:16.932776: step 11810, loss = 0.54194 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:46:17.893961 ops/training.py:65 2019-01-16 11:46:17.893904: step 11811, loss = 0.54131 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:46:18.856192 ops/training.py:65 2019-01-16 11:46:18.856136: step 11812, loss = 0.65097 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:46:19.818274 ops/training.py:65 2019-01-16 11:46:19.818216: step 11813, loss = 0.48935 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:46:20.779441 ops/training.py:65 2019-01-16 11:46:20.779387: step 11814, loss = 0.53822 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:46:21.740369 ops/training.py:65 2019-01-16 11:46:21.740330: step 11815, loss = 0.51943 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:46:22.702843 ops/training.py:65 2019-01-16 11:46:22.702795: step 11816, loss = 0.49951 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:46:23.665590 ops/training.py:65 2019-01-16 11:46:23.665546: step 11817, loss = 0.63788 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:46:24.627646 ops/training.py:65 2019-01-16 11:46:24.627584: step 11818, loss = 0.59240 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:46:25.588979 ops/training.py:65 2019-01-16 11:46:25.588938: step 11819, loss = 0.65620 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:46:26.550285 ops/training.py:65 2019-01-16 11:46:26.550225: step 11820, loss = 0.59593 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:46:27.512548 ops/training.py:65 2019-01-16 11:46:27.512492: step 11821, loss = 0.58334 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:46:28.474094 ops/training.py:65 2019-01-16 11:46:28.474037: step 11822, loss = 0.48331 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:46:29.435784 ops/training.py:65 2019-01-16 11:46:29.435743: step 11823, loss = 0.50649 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:46:30.398390 ops/training.py:65 2019-01-16 11:46:30.398346: step 11824, loss = 0.54013 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:46:31.360145 ops/training.py:65 2019-01-16 11:46:31.360097: step 11825, loss = 0.66703 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:46:32.320985 ops/training.py:65 2019-01-16 11:46:32.320945: step 11826, loss = 0.71285 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:46:33.283700 ops/training.py:65 2019-01-16 11:46:33.283636: step 11827, loss = 0.53492 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:46:34.247427 ops/training.py:65 2019-01-16 11:46:34.247367: step 11828, loss = 0.50727 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:46:35.209442 ops/training.py:65 2019-01-16 11:46:35.209384: step 11829, loss = 0.63757 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:46:36.170886 ops/training.py:65 2019-01-16 11:46:36.170839: step 11830, loss = 0.64725 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:46:37.132074 ops/training.py:65 2019-01-16 11:46:37.132014: step 11831, loss = 0.60707 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:46:38.093779 ops/training.py:65 2019-01-16 11:46:38.093722: step 11832, loss = 0.60509 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:46:39.055761 ops/training.py:65 2019-01-16 11:46:39.055706: step 11833, loss = 0.58889 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:46:40.019249 ops/training.py:65 2019-01-16 11:46:40.019176: step 11834, loss = 0.67257 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:46:40.981523 ops/training.py:65 2019-01-16 11:46:40.981472: step 11835, loss = 0.66364 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:46:41.942683 ops/training.py:65 2019-01-16 11:46:41.942616: step 11836, loss = 0.56857 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:46:42.904595 ops/training.py:65 2019-01-16 11:46:42.904507: step 11837, loss = 0.54250 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:46:43.866431 ops/training.py:65 2019-01-16 11:46:43.866369: step 11838, loss = 0.70210 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:46:44.828061 ops/training.py:65 2019-01-16 11:46:44.828012: step 11839, loss = 0.49736 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:46:45.789835 ops/training.py:65 2019-01-16 11:46:45.789774: step 11840, loss = 0.55503 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:46:46.750801 ops/training.py:65 2019-01-16 11:46:46.750744: step 11841, loss = 0.46264 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:46:47.711684 ops/training.py:65 2019-01-16 11:46:47.711622: step 11842, loss = 0.52559 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:46:48.673214 ops/training.py:65 2019-01-16 11:46:48.673165: step 11843, loss = 0.56649 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:46:49.635483 ops/training.py:65 2019-01-16 11:46:49.635419: step 11844, loss = 0.52883 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:46:50.596043 ops/training.py:65 2019-01-16 11:46:50.595969: step 11845, loss = 0.64621 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:46:51.557720 ops/training.py:65 2019-01-16 11:46:51.557655: step 11846, loss = 0.58651 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:46:52.516442 ops/training.py:65 2019-01-16 11:46:52.516390: step 11847, loss = 0.63496 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:46:53.480261 ops/training.py:65 2019-01-16 11:46:53.480204: step 11848, loss = 0.47744 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:46:54.441832 ops/training.py:65 2019-01-16 11:46:54.441779: step 11849, loss = 0.61410 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:46:55.405047 ops/training.py:65 2019-01-16 11:46:55.405000: step 11850, loss = 0.59613 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:46:56.368041 ops/training.py:65 2019-01-16 11:46:56.367988: step 11851, loss = 0.55525 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:46:57.329324 ops/training.py:65 2019-01-16 11:46:57.329272: step 11852, loss = 0.57412 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:46:58.290158 ops/training.py:65 2019-01-16 11:46:58.290105: step 11853, loss = 0.53377 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:46:59.250555 ops/training.py:65 2019-01-16 11:46:59.250509: step 11854, loss = 0.55537 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:47:00.210298 ops/training.py:65 2019-01-16 11:47:00.210246: step 11855, loss = 0.59580 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:47:01.169695 ops/training.py:65 2019-01-16 11:47:01.169642: step 11856, loss = 0.66963 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:47:02.127955 ops/training.py:65 2019-01-16 11:47:02.127888: step 11857, loss = 0.50918 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:47:03.090668 ops/training.py:65 2019-01-16 11:47:03.090625: step 11858, loss = 0.54001 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:47:04.053900 ops/training.py:65 2019-01-16 11:47:04.053827: step 11859, loss = 0.48923 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:47:05.015620 ops/training.py:65 2019-01-16 11:47:05.015572: step 11860, loss = 0.61163 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:47:05.976757 ops/training.py:65 2019-01-16 11:47:05.976687: step 11861, loss = 0.51851 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:47:06.938481 ops/training.py:65 2019-01-16 11:47:06.938431: step 11862, loss = 0.54741 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:47:07.900399 ops/training.py:65 2019-01-16 11:47:07.900334: step 11863, loss = 0.65087 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:47:08.861632 ops/training.py:65 2019-01-16 11:47:08.861572: step 11864, loss = 0.61113 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:47:09.822807 ops/training.py:65 2019-01-16 11:47:09.822750: step 11865, loss = 0.55292 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:47:10.784071 ops/training.py:65 2019-01-16 11:47:10.784006: step 11866, loss = 0.54582 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:47:11.742940 ops/training.py:65 2019-01-16 11:47:11.742874: step 11867, loss = 0.64167 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:47:12.702429 ops/training.py:65 2019-01-16 11:47:12.702358: step 11868, loss = 0.68224 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:47:13.660860 ops/training.py:65 2019-01-16 11:47:13.660791: step 11869, loss = 0.51759 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:47:14.619816 ops/training.py:65 2019-01-16 11:47:14.619751: step 11870, loss = 0.55740 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:47:15.583364 ops/training.py:65 2019-01-16 11:47:15.583297: step 11871, loss = 0.60646 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:47:16.544686 ops/training.py:65 2019-01-16 11:47:16.544631: step 11872, loss = 0.48596 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:47:17.502540 ops/training.py:65 2019-01-16 11:47:17.502471: step 11873, loss = 0.60559 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:47:18.465692 ops/training.py:65 2019-01-16 11:47:18.465635: step 11874, loss = 0.63454 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:47:19.428605 ops/training.py:65 2019-01-16 11:47:19.428547: step 11875, loss = 0.56666 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:47:20.389978 ops/training.py:65 2019-01-16 11:47:20.389914: step 11876, loss = 0.53508 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:47:21.350920 ops/training.py:65 2019-01-16 11:47:21.350867: step 11877, loss = 0.53002 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:47:22.310679 ops/training.py:65 2019-01-16 11:47:22.310623: step 11878, loss = 0.55521 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:47:23.270770 ops/training.py:65 2019-01-16 11:47:23.270716: step 11879, loss = 0.58953 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:47:24.231463 ops/training.py:65 2019-01-16 11:47:24.231406: step 11880, loss = 0.59995 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:47:25.193059 ops/training.py:65 2019-01-16 11:47:25.193003: step 11881, loss = 0.68534 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:47:26.154777 ops/training.py:65 2019-01-16 11:47:26.154727: step 11882, loss = 0.75769 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:47:27.115926 ops/training.py:65 2019-01-16 11:47:27.115858: step 11883, loss = 0.68471 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:47:28.076339 ops/training.py:65 2019-01-16 11:47:28.076277: step 11884, loss = 0.64300 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:47:29.037252 ops/training.py:65 2019-01-16 11:47:29.037190: step 11885, loss = 0.59834 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:47:29.999475 ops/training.py:65 2019-01-16 11:47:29.999410: step 11886, loss = 0.58862 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:47:30.959569 ops/training.py:65 2019-01-16 11:47:30.959512: step 11887, loss = 0.44054 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:47:31.921280 ops/training.py:65 2019-01-16 11:47:31.921220: step 11888, loss = 0.52942 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:47:32.883244 ops/training.py:65 2019-01-16 11:47:32.883185: step 11889, loss = 0.57750 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:47:33.842875 ops/training.py:65 2019-01-16 11:47:33.842828: step 11890, loss = 0.45455 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:47:34.807279 ops/training.py:65 2019-01-16 11:47:34.807227: step 11891, loss = 0.55383 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:47:35.769399 ops/training.py:65 2019-01-16 11:47:35.769348: step 11892, loss = 0.42008 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:47:36.733009 ops/training.py:65 2019-01-16 11:47:36.732974: step 11893, loss = 0.69320 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:47:37.695621 ops/training.py:65 2019-01-16 11:47:37.695566: step 11894, loss = 0.56615 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:47:38.657594 ops/training.py:65 2019-01-16 11:47:38.657543: step 11895, loss = 0.59389 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:47:39.619472 ops/training.py:65 2019-01-16 11:47:39.619422: step 11896, loss = 0.48343 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:47:40.581847 ops/training.py:65 2019-01-16 11:47:40.581809: step 11897, loss = 0.58582 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:47:41.544820 ops/training.py:65 2019-01-16 11:47:41.544774: step 11898, loss = 0.61971 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:47:42.509496 ops/training.py:65 2019-01-16 11:47:42.509447: step 11899, loss = 0.54442 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:47:43.473650 ops/training.py:65 2019-01-16 11:47:43.473601: step 11900, loss = 0.68619 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:47:44.435470 ops/training.py:65 2019-01-16 11:47:44.435421: step 11901, loss = 0.49351 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:47:45.397629 ops/training.py:65 2019-01-16 11:47:45.397580: step 11902, loss = 0.59155 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:47:46.360109 ops/training.py:65 2019-01-16 11:47:46.360057: step 11903, loss = 0.59335 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:47:47.323831 ops/training.py:65 2019-01-16 11:47:47.323774: step 11904, loss = 0.55212 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:47:48.286483 ops/training.py:65 2019-01-16 11:47:48.286420: step 11905, loss = 0.61738 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:47:49.248732 ops/training.py:65 2019-01-16 11:47:49.248678: step 11906, loss = 0.54625 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:47:50.210750 ops/training.py:65 2019-01-16 11:47:50.210695: step 11907, loss = 0.68491 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:47:51.172982 ops/training.py:65 2019-01-16 11:47:51.172916: step 11908, loss = 0.57993 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:47:52.134874 ops/training.py:65 2019-01-16 11:47:52.134830: step 11909, loss = 0.64587 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:47:53.095287 ops/training.py:65 2019-01-16 11:47:53.095235: step 11910, loss = 0.55921 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:47:54.054981 ops/training.py:65 2019-01-16 11:47:54.054914: step 11911, loss = 0.54002 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:47:55.015137 ops/training.py:65 2019-01-16 11:47:55.015085: step 11912, loss = 0.65932 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:47:55.978623 ops/training.py:65 2019-01-16 11:47:55.978588: step 11913, loss = 0.62006 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:47:56.939745 ops/training.py:65 2019-01-16 11:47:56.939691: step 11914, loss = 0.52542 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:47:57.898340 ops/training.py:65 2019-01-16 11:47:57.898293: step 11915, loss = 0.48327 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:47:58.856577 ops/training.py:65 2019-01-16 11:47:58.856537: step 11916, loss = 0.43738 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 11:47:59.814903 ops/training.py:65 2019-01-16 11:47:59.814867: step 11917, loss = 0.67298 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:48:00.778589 ops/training.py:65 2019-01-16 11:48:00.778540: step 11918, loss = 0.40820 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:48:01.740710 ops/training.py:65 2019-01-16 11:48:01.740674: step 11919, loss = 0.61405 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:48:02.704038 ops/training.py:65 2019-01-16 11:48:02.703971: step 11920, loss = 0.53071 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:48:03.668830 ops/training.py:65 2019-01-16 11:48:03.668776: step 11921, loss = 0.49093 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:48:04.630221 ops/training.py:65 2019-01-16 11:48:04.630172: step 11922, loss = 0.69309 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:48:05.591108 ops/training.py:65 2019-01-16 11:48:05.591038: step 11923, loss = 0.60920 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:48:06.551185 ops/training.py:65 2019-01-16 11:48:06.551118: step 11924, loss = 0.51225 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:48:07.513526 ops/training.py:65 2019-01-16 11:48:07.513452: step 11925, loss = 0.68761 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:48:08.476581 ops/training.py:65 2019-01-16 11:48:08.476505: step 11926, loss = 0.55565 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:48:09.438237 ops/training.py:65 2019-01-16 11:48:09.438177: step 11927, loss = 0.44016 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:48:10.398122 ops/training.py:65 2019-01-16 11:48:10.398065: step 11928, loss = 0.59570 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:48:11.358288 ops/training.py:65 2019-01-16 11:48:11.358218: step 11929, loss = 0.49444 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:48:12.318090 ops/training.py:65 2019-01-16 11:48:12.318027: step 11930, loss = 0.54360 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:48:13.278378 ops/training.py:65 2019-01-16 11:48:13.278325: step 11931, loss = 0.62295 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:48:14.237684 ops/training.py:65 2019-01-16 11:48:14.237602: step 11932, loss = 0.65901 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:48:15.202018 ops/training.py:65 2019-01-16 11:48:15.201968: step 11933, loss = 0.53663 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:48:16.164267 ops/training.py:65 2019-01-16 11:48:16.164191: step 11934, loss = 0.67043 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:48:17.123359 ops/training.py:65 2019-01-16 11:48:17.123291: step 11935, loss = 0.60476 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:48:18.086601 ops/training.py:65 2019-01-16 11:48:18.086542: step 11936, loss = 0.57520 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:48:19.049111 ops/training.py:65 2019-01-16 11:48:19.049060: step 11937, loss = 0.51878 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:48:20.008795 ops/training.py:65 2019-01-16 11:48:20.008751: step 11938, loss = 0.39840 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 11:48:20.967869 ops/training.py:65 2019-01-16 11:48:20.967791: step 11939, loss = 0.55226 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:48:21.928753 ops/training.py:65 2019-01-16 11:48:21.928710: step 11940, loss = 0.68249 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:48:22.888239 ops/training.py:65 2019-01-16 11:48:22.888202: step 11941, loss = 0.57338 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:48:23.850506 ops/training.py:65 2019-01-16 11:48:23.850445: step 11942, loss = 0.54699 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:48:24.813771 ops/training.py:65 2019-01-16 11:48:24.813712: step 11943, loss = 0.48285 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:48:25.775431 ops/training.py:65 2019-01-16 11:48:25.775390: step 11944, loss = 0.51821 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:48:26.736448 ops/training.py:65 2019-01-16 11:48:26.736400: step 11945, loss = 0.57799 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:48:27.698459 ops/training.py:65 2019-01-16 11:48:27.698406: step 11946, loss = 0.68092 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:48:28.658933 ops/training.py:65 2019-01-16 11:48:28.658893: step 11947, loss = 0.70585 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:48:29.619643 ops/training.py:65 2019-01-16 11:48:29.619588: step 11948, loss = 0.47841 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:48:30.581223 ops/training.py:65 2019-01-16 11:48:30.581153: step 11949, loss = 0.49412 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:48:31.540655 ops/training.py:65 2019-01-16 11:48:31.540618: step 11950, loss = 0.48645 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:48:32.499313 ops/training.py:65 2019-01-16 11:48:32.499230: step 11951, loss = 0.52937 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:48:33.459067 ops/training.py:65 2019-01-16 11:48:33.459003: step 11952, loss = 0.56178 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:48:34.418756 ops/training.py:65 2019-01-16 11:48:34.418702: step 11953, loss = 0.72375 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:48:35.381779 ops/training.py:65 2019-01-16 11:48:35.381739: step 11954, loss = 0.61314 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:48:36.344247 ops/training.py:65 2019-01-16 11:48:36.344206: step 11955, loss = 0.57505 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:48:37.307013 ops/training.py:65 2019-01-16 11:48:37.306963: step 11956, loss = 0.59550 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:48:38.268653 ops/training.py:65 2019-01-16 11:48:38.268621: step 11957, loss = 0.62412 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:48:39.230004 ops/training.py:65 2019-01-16 11:48:39.229975: step 11958, loss = 0.69395 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:48:40.193465 ops/training.py:65 2019-01-16 11:48:40.193432: step 11959, loss = 0.74867 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:48:41.156033 ops/training.py:65 2019-01-16 11:48:41.155999: step 11960, loss = 0.55433 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:48:42.116915 ops/training.py:65 2019-01-16 11:48:42.116875: step 11961, loss = 0.49543 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:48:43.080064 ops/training.py:65 2019-01-16 11:48:43.080031: step 11962, loss = 0.49817 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:48:44.042866 ops/training.py:65 2019-01-16 11:48:44.042834: step 11963, loss = 0.60056 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:48:45.002636 ops/training.py:65 2019-01-16 11:48:45.002601: step 11964, loss = 0.57997 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:48:45.967297 ops/training.py:65 2019-01-16 11:48:45.967265: step 11965, loss = 0.63620 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:48:46.927703 ops/training.py:65 2019-01-16 11:48:46.927651: step 11966, loss = 0.49159 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:48:47.885687 ops/training.py:65 2019-01-16 11:48:47.885617: step 11967, loss = 0.63269 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:48:48.844036 ops/training.py:65 2019-01-16 11:48:48.843976: step 11968, loss = 0.50943 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:48:49.804843 ops/training.py:65 2019-01-16 11:48:49.804798: step 11969, loss = 0.58937 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:48:50.766693 ops/training.py:65 2019-01-16 11:48:50.766649: step 11970, loss = 0.60536 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:48:51.729902 ops/training.py:65 2019-01-16 11:48:51.729865: step 11971, loss = 0.51815 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:48:52.692400 ops/training.py:65 2019-01-16 11:48:52.692367: step 11972, loss = 0.58220 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:48:53.652889 ops/training.py:65 2019-01-16 11:48:53.652856: step 11973, loss = 0.54544 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:48:54.614968 ops/training.py:65 2019-01-16 11:48:54.614940: step 11974, loss = 0.53610 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:48:55.576164 ops/training.py:65 2019-01-16 11:48:55.576112: step 11975, loss = 0.46059 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:48:56.537110 ops/training.py:65 2019-01-16 11:48:56.537074: step 11976, loss = 0.49413 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:48:57.497989 ops/training.py:65 2019-01-16 11:48:57.497943: step 11977, loss = 0.78326 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:48:58.459610 ops/training.py:65 2019-01-16 11:48:58.459579: step 11978, loss = 0.52910 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:48:59.419223 ops/training.py:65 2019-01-16 11:48:59.419155: step 11979, loss = 0.50557 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:49:00.383037 ops/training.py:65 2019-01-16 11:49:00.382990: step 11980, loss = 0.68779 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:49:01.346695 ops/training.py:65 2019-01-16 11:49:01.346633: step 11981, loss = 0.55977 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:49:02.309160 ops/training.py:65 2019-01-16 11:49:02.309112: step 11982, loss = 0.48642 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:49:03.268662 ops/training.py:65 2019-01-16 11:49:03.268614: step 11983, loss = 0.48292 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:49:04.233980 ops/training.py:65 2019-01-16 11:49:04.233907: step 11984, loss = 0.47644 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 11:49:05.237983 ops/training.py:65 2019-01-16 11:49:05.237932: step 11985, loss = 0.62069 (31.9 examples/sec; 1.002 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:49:06.200295 ops/training.py:65 2019-01-16 11:49:06.200233: step 11986, loss = 0.51163 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:49:07.159892 ops/training.py:65 2019-01-16 11:49:07.159832: step 11987, loss = 0.73416 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:49:08.123391 ops/training.py:65 2019-01-16 11:49:08.123335: step 11988, loss = 0.62807 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:49:09.085586 ops/training.py:65 2019-01-16 11:49:09.085521: step 11989, loss = 0.54368 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:49:10.047955 ops/training.py:65 2019-01-16 11:49:10.047900: step 11990, loss = 0.58256 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:49:11.014581 ops/training.py:65 2019-01-16 11:49:11.014527: step 11991, loss = 0.53135 (33.1 examples/sec; 0.966 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:49:11.975005 ops/training.py:65 2019-01-16 11:49:11.974953: step 11992, loss = 0.54876 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:49:12.935440 ops/training.py:65 2019-01-16 11:49:12.935391: step 11993, loss = 0.64905 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:49:13.897366 ops/training.py:65 2019-01-16 11:49:13.897314: step 11994, loss = 0.53211 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:49:14.859014 ops/training.py:65 2019-01-16 11:49:14.858962: step 11995, loss = 0.64434 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:49:15.819717 ops/training.py:65 2019-01-16 11:49:15.819660: step 11996, loss = 0.53794 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:49:16.780015 ops/training.py:65 2019-01-16 11:49:16.779962: step 11997, loss = 0.64208 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:49:17.742642 ops/training.py:65 2019-01-16 11:49:17.742591: step 11998, loss = 0.70232 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:49:18.702924 ops/training.py:65 2019-01-16 11:49:18.702870: step 11999, loss = 0.58372 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:53:58.010589 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I0832 2019-01-16 11:53:58.011433 ops/training.py:41 2019-01-16 11:53:58.011381: step 12000, loss = 0.50 (0.1 examples/sec; 278.342 sec/batch) | Training accuracy = 0.84375 | Validation accuracy = 0.6556 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_08_07_39_512188
I0832 2019-01-16 11:53:58.976566 ops/training.py:65 2019-01-16 11:53:58.976520: step 12001, loss = 0.61559 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:53:59.938682 ops/training.py:65 2019-01-16 11:53:59.938632: step 12002, loss = 0.49684 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:54:00.903703 ops/training.py:65 2019-01-16 11:54:00.903653: step 12003, loss = 0.53250 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:54:01.867201 ops/training.py:65 2019-01-16 11:54:01.867148: step 12004, loss = 0.49397 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:54:02.831293 ops/training.py:65 2019-01-16 11:54:02.831247: step 12005, loss = 0.50071 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:54:03.792728 ops/training.py:65 2019-01-16 11:54:03.792673: step 12006, loss = 0.55068 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:54:04.758119 ops/training.py:65 2019-01-16 11:54:04.758047: step 12007, loss = 0.59366 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:54:05.720054 ops/training.py:65 2019-01-16 11:54:05.719999: step 12008, loss = 0.53944 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:54:06.684288 ops/training.py:65 2019-01-16 11:54:06.684241: step 12009, loss = 0.59864 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:54:07.648212 ops/training.py:65 2019-01-16 11:54:07.648153: step 12010, loss = 0.58287 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:54:08.610721 ops/training.py:65 2019-01-16 11:54:08.610657: step 12011, loss = 0.62474 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:54:09.573142 ops/training.py:65 2019-01-16 11:54:09.573083: step 12012, loss = 0.58006 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:54:10.534802 ops/training.py:65 2019-01-16 11:54:10.534745: step 12013, loss = 0.65601 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:54:11.496553 ops/training.py:65 2019-01-16 11:54:11.496498: step 12014, loss = 0.66379 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:54:12.459035 ops/training.py:65 2019-01-16 11:54:12.458995: step 12015, loss = 0.67435 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:54:13.422304 ops/training.py:65 2019-01-16 11:54:13.422249: step 12016, loss = 0.58556 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:54:14.385757 ops/training.py:65 2019-01-16 11:54:14.385702: step 12017, loss = 0.51818 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:54:15.348471 ops/training.py:65 2019-01-16 11:54:15.348420: step 12018, loss = 0.50344 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:54:16.310736 ops/training.py:65 2019-01-16 11:54:16.310693: step 12019, loss = 0.51166 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:54:17.272511 ops/training.py:65 2019-01-16 11:54:17.272460: step 12020, loss = 0.56477 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:54:18.235162 ops/training.py:65 2019-01-16 11:54:18.235106: step 12021, loss = 0.57695 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:54:19.198946 ops/training.py:65 2019-01-16 11:54:19.198891: step 12022, loss = 0.58583 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:54:20.161922 ops/training.py:65 2019-01-16 11:54:20.161865: step 12023, loss = 0.51135 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:54:21.124900 ops/training.py:65 2019-01-16 11:54:21.124843: step 12024, loss = 0.63726 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:54:22.086406 ops/training.py:65 2019-01-16 11:54:22.086360: step 12025, loss = 0.50988 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:54:23.048298 ops/training.py:65 2019-01-16 11:54:23.048242: step 12026, loss = 0.64856 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:54:24.010682 ops/training.py:65 2019-01-16 11:54:24.010628: step 12027, loss = 0.61941 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:54:24.973690 ops/training.py:65 2019-01-16 11:54:24.973635: step 12028, loss = 0.67196 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:54:25.936696 ops/training.py:65 2019-01-16 11:54:25.936640: step 12029, loss = 0.60811 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:54:26.901050 ops/training.py:65 2019-01-16 11:54:26.900993: step 12030, loss = 0.44446 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:54:27.863312 ops/training.py:65 2019-01-16 11:54:27.863262: step 12031, loss = 0.62791 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:54:28.826204 ops/training.py:65 2019-01-16 11:54:28.826150: step 12032, loss = 0.55242 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:54:29.788783 ops/training.py:65 2019-01-16 11:54:29.788728: step 12033, loss = 0.62891 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:54:30.751134 ops/training.py:65 2019-01-16 11:54:30.751079: step 12034, loss = 0.54589 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:54:31.714242 ops/training.py:65 2019-01-16 11:54:31.714189: step 12035, loss = 0.46459 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 11:54:32.677790 ops/training.py:65 2019-01-16 11:54:32.677749: step 12036, loss = 0.66647 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:54:33.640795 ops/training.py:65 2019-01-16 11:54:33.640737: step 12037, loss = 0.57118 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:54:34.603815 ops/training.py:65 2019-01-16 11:54:34.603742: step 12038, loss = 0.58961 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:54:35.565300 ops/training.py:65 2019-01-16 11:54:35.565233: step 12039, loss = 0.58079 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:54:36.526195 ops/training.py:65 2019-01-16 11:54:36.526139: step 12040, loss = 0.68566 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:54:37.488042 ops/training.py:65 2019-01-16 11:54:37.487969: step 12041, loss = 0.56574 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:54:38.449127 ops/training.py:65 2019-01-16 11:54:38.449056: step 12042, loss = 0.52860 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:54:39.410629 ops/training.py:65 2019-01-16 11:54:39.410555: step 12043, loss = 0.65452 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:54:40.371234 ops/training.py:65 2019-01-16 11:54:40.371166: step 12044, loss = 0.55334 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:54:41.331337 ops/training.py:65 2019-01-16 11:54:41.331251: step 12045, loss = 0.62130 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:54:42.289760 ops/training.py:65 2019-01-16 11:54:42.289694: step 12046, loss = 0.59861 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:54:43.248034 ops/training.py:65 2019-01-16 11:54:43.247978: step 12047, loss = 0.57497 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:54:44.207116 ops/training.py:65 2019-01-16 11:54:44.207061: step 12048, loss = 0.52833 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:54:45.167532 ops/training.py:65 2019-01-16 11:54:45.167466: step 12049, loss = 0.53534 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:54:46.126799 ops/training.py:65 2019-01-16 11:54:46.126730: step 12050, loss = 0.53050 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:54:47.085049 ops/training.py:65 2019-01-16 11:54:47.085004: step 12051, loss = 0.48000 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:54:48.042749 ops/training.py:65 2019-01-16 11:54:48.042686: step 12052, loss = 0.51798 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:54:49.000919 ops/training.py:65 2019-01-16 11:54:49.000856: step 12053, loss = 0.63579 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:54:49.958805 ops/training.py:65 2019-01-16 11:54:49.958740: step 12054, loss = 0.59876 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:54:50.922960 ops/training.py:65 2019-01-16 11:54:50.922917: step 12055, loss = 0.49070 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:54:51.886431 ops/training.py:65 2019-01-16 11:54:51.886386: step 12056, loss = 0.57315 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:54:52.847147 ops/training.py:65 2019-01-16 11:54:52.847080: step 12057, loss = 0.57153 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:54:53.810653 ops/training.py:65 2019-01-16 11:54:53.810578: step 12058, loss = 0.53997 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:54:54.773380 ops/training.py:65 2019-01-16 11:54:54.773307: step 12059, loss = 0.46148 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:54:55.735836 ops/training.py:65 2019-01-16 11:54:55.735771: step 12060, loss = 0.59128 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:54:56.698504 ops/training.py:65 2019-01-16 11:54:56.698459: step 12061, loss = 0.59190 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:54:57.659365 ops/training.py:65 2019-01-16 11:54:57.659321: step 12062, loss = 0.58385 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:54:58.619582 ops/training.py:65 2019-01-16 11:54:58.619520: step 12063, loss = 0.46933 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:54:59.584270 ops/training.py:65 2019-01-16 11:54:59.584226: step 12064, loss = 0.54560 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:55:00.545927 ops/training.py:65 2019-01-16 11:55:00.545874: step 12065, loss = 0.56704 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:55:01.506321 ops/training.py:65 2019-01-16 11:55:01.506267: step 12066, loss = 0.58151 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:55:02.466926 ops/training.py:65 2019-01-16 11:55:02.466873: step 12067, loss = 0.49673 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:55:03.427105 ops/training.py:65 2019-01-16 11:55:03.427040: step 12068, loss = 0.52022 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:55:04.386069 ops/training.py:65 2019-01-16 11:55:04.386017: step 12069, loss = 0.57165 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:55:05.345573 ops/training.py:65 2019-01-16 11:55:05.345509: step 12070, loss = 0.64490 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:55:06.304448 ops/training.py:65 2019-01-16 11:55:06.304385: step 12071, loss = 0.51801 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:55:07.267956 ops/training.py:65 2019-01-16 11:55:07.267872: step 12072, loss = 0.65936 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:55:08.232071 ops/training.py:65 2019-01-16 11:55:08.232011: step 12073, loss = 0.59809 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:55:09.193556 ops/training.py:65 2019-01-16 11:55:09.193503: step 12074, loss = 0.61512 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:55:10.153978 ops/training.py:65 2019-01-16 11:55:10.153927: step 12075, loss = 0.67794 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:55:11.115091 ops/training.py:65 2019-01-16 11:55:11.115046: step 12076, loss = 0.66610 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:55:12.075601 ops/training.py:65 2019-01-16 11:55:12.075550: step 12077, loss = 0.61566 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:55:13.035997 ops/training.py:65 2019-01-16 11:55:13.035953: step 12078, loss = 0.42729 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:55:13.997382 ops/training.py:65 2019-01-16 11:55:13.997331: step 12079, loss = 0.52870 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:55:14.958803 ops/training.py:65 2019-01-16 11:55:14.958754: step 12080, loss = 0.53425 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:55:15.919748 ops/training.py:65 2019-01-16 11:55:15.919699: step 12081, loss = 0.55711 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:55:16.882518 ops/training.py:65 2019-01-16 11:55:16.882479: step 12082, loss = 0.54157 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:55:17.845884 ops/training.py:65 2019-01-16 11:55:17.845837: step 12083, loss = 0.50565 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:55:18.808841 ops/training.py:65 2019-01-16 11:55:18.808794: step 12084, loss = 0.63439 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:55:19.770692 ops/training.py:65 2019-01-16 11:55:19.770645: step 12085, loss = 0.50015 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:55:20.731444 ops/training.py:65 2019-01-16 11:55:20.731390: step 12086, loss = 0.60297 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:55:21.692374 ops/training.py:65 2019-01-16 11:55:21.692323: step 12087, loss = 0.58225 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:55:22.656529 ops/training.py:65 2019-01-16 11:55:22.656478: step 12088, loss = 0.53679 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:55:23.619992 ops/training.py:65 2019-01-16 11:55:23.619914: step 12089, loss = 0.64910 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:55:24.583121 ops/training.py:65 2019-01-16 11:55:24.583053: step 12090, loss = 0.56063 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:55:25.543666 ops/training.py:65 2019-01-16 11:55:25.543625: step 12091, loss = 0.59392 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:55:26.503541 ops/training.py:65 2019-01-16 11:55:26.503486: step 12092, loss = 0.63906 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:55:27.464494 ops/training.py:65 2019-01-16 11:55:27.464428: step 12093, loss = 0.59205 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:55:28.426764 ops/training.py:65 2019-01-16 11:55:28.426721: step 12094, loss = 0.53573 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:55:29.387788 ops/training.py:65 2019-01-16 11:55:29.387747: step 12095, loss = 0.75182 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:55:30.349017 ops/training.py:65 2019-01-16 11:55:30.348934: step 12096, loss = 0.55561 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:55:31.311003 ops/training.py:65 2019-01-16 11:55:31.310932: step 12097, loss = 0.57834 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:55:32.273138 ops/training.py:65 2019-01-16 11:55:32.273091: step 12098, loss = 0.54572 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:55:33.234946 ops/training.py:65 2019-01-16 11:55:33.234904: step 12099, loss = 0.78498 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:55:34.196129 ops/training.py:65 2019-01-16 11:55:34.196080: step 12100, loss = 0.54468 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:55:35.157132 ops/training.py:65 2019-01-16 11:55:35.157085: step 12101, loss = 0.72384 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:55:36.116939 ops/training.py:65 2019-01-16 11:55:36.116892: step 12102, loss = 0.56416 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:55:37.075613 ops/training.py:65 2019-01-16 11:55:37.075567: step 12103, loss = 0.64013 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:55:38.038543 ops/training.py:65 2019-01-16 11:55:38.038496: step 12104, loss = 0.50138 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:55:39.003229 ops/training.py:65 2019-01-16 11:55:39.003182: step 12105, loss = 0.52000 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:55:39.966242 ops/training.py:65 2019-01-16 11:55:39.966188: step 12106, loss = 0.59393 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:55:40.927855 ops/training.py:65 2019-01-16 11:55:40.927809: step 12107, loss = 0.36198 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 11:55:41.889693 ops/training.py:65 2019-01-16 11:55:41.889647: step 12108, loss = 0.66259 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:55:42.850927 ops/training.py:65 2019-01-16 11:55:42.850874: step 12109, loss = 0.59111 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:55:43.812049 ops/training.py:65 2019-01-16 11:55:43.811979: step 12110, loss = 0.67907 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:55:44.773706 ops/training.py:65 2019-01-16 11:55:44.773658: step 12111, loss = 0.55391 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:55:45.735757 ops/training.py:65 2019-01-16 11:55:45.735711: step 12112, loss = 0.51038 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:55:46.696654 ops/training.py:65 2019-01-16 11:55:46.696589: step 12113, loss = 0.57771 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:55:47.660000 ops/training.py:65 2019-01-16 11:55:47.659938: step 12114, loss = 0.58615 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:55:48.621644 ops/training.py:65 2019-01-16 11:55:48.621585: step 12115, loss = 0.54762 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:55:49.583388 ops/training.py:65 2019-01-16 11:55:49.583319: step 12116, loss = 0.49926 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:55:50.545185 ops/training.py:65 2019-01-16 11:55:50.545115: step 12117, loss = 0.45944 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:55:51.506483 ops/training.py:65 2019-01-16 11:55:51.506411: step 12118, loss = 0.63430 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:55:52.469861 ops/training.py:65 2019-01-16 11:55:52.469814: step 12119, loss = 0.62577 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:55:53.431811 ops/training.py:65 2019-01-16 11:55:53.431742: step 12120, loss = 0.44103 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 11:55:54.393267 ops/training.py:65 2019-01-16 11:55:54.393203: step 12121, loss = 0.62830 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:55:55.354092 ops/training.py:65 2019-01-16 11:55:55.354022: step 12122, loss = 0.54020 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:55:56.316345 ops/training.py:65 2019-01-16 11:55:56.316301: step 12123, loss = 0.55482 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:55:57.276559 ops/training.py:65 2019-01-16 11:55:57.276518: step 12124, loss = 0.55740 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:55:58.238477 ops/training.py:65 2019-01-16 11:55:58.238424: step 12125, loss = 0.56187 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:55:59.198623 ops/training.py:65 2019-01-16 11:55:59.198555: step 12126, loss = 0.62175 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:56:00.160373 ops/training.py:65 2019-01-16 11:56:00.160326: step 12127, loss = 0.57778 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:56:01.121550 ops/training.py:65 2019-01-16 11:56:01.121501: step 12128, loss = 0.56826 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:56:02.081889 ops/training.py:65 2019-01-16 11:56:02.081847: step 12129, loss = 0.70999 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:56:03.042481 ops/training.py:65 2019-01-16 11:56:03.042427: step 12130, loss = 0.55261 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:56:04.002504 ops/training.py:65 2019-01-16 11:56:04.002459: step 12131, loss = 0.68887 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:56:04.965757 ops/training.py:65 2019-01-16 11:56:04.965710: step 12132, loss = 0.52651 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:56:05.929014 ops/training.py:65 2019-01-16 11:56:05.928969: step 12133, loss = 0.59575 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:56:06.891662 ops/training.py:65 2019-01-16 11:56:06.891592: step 12134, loss = 0.65827 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:56:07.852559 ops/training.py:65 2019-01-16 11:56:07.852494: step 12135, loss = 0.59502 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:56:08.813694 ops/training.py:65 2019-01-16 11:56:08.813636: step 12136, loss = 0.59383 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:56:09.775022 ops/training.py:65 2019-01-16 11:56:09.774971: step 12137, loss = 0.47925 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:56:10.736759 ops/training.py:65 2019-01-16 11:56:10.736702: step 12138, loss = 0.59881 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:56:11.698791 ops/training.py:65 2019-01-16 11:56:11.698728: step 12139, loss = 0.53815 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:56:12.659953 ops/training.py:65 2019-01-16 11:56:12.659890: step 12140, loss = 0.55850 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:56:13.621400 ops/training.py:65 2019-01-16 11:56:13.621343: step 12141, loss = 0.54314 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:56:14.582689 ops/training.py:65 2019-01-16 11:56:14.582631: step 12142, loss = 0.54055 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:56:15.544032 ops/training.py:65 2019-01-16 11:56:15.543972: step 12143, loss = 0.54251 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:56:16.505543 ops/training.py:65 2019-01-16 11:56:16.505476: step 12144, loss = 0.56666 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:56:17.466517 ops/training.py:65 2019-01-16 11:56:17.466462: step 12145, loss = 0.57966 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:56:18.427780 ops/training.py:65 2019-01-16 11:56:18.427726: step 12146, loss = 0.70049 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:56:19.389418 ops/training.py:65 2019-01-16 11:56:19.389373: step 12147, loss = 0.58930 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:56:20.350804 ops/training.py:65 2019-01-16 11:56:20.350757: step 12148, loss = 0.56627 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:56:21.312965 ops/training.py:65 2019-01-16 11:56:21.312919: step 12149, loss = 0.63739 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:56:22.274136 ops/training.py:65 2019-01-16 11:56:22.274085: step 12150, loss = 0.56858 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:56:23.235709 ops/training.py:65 2019-01-16 11:56:23.235639: step 12151, loss = 0.52855 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:56:24.197576 ops/training.py:65 2019-01-16 11:56:24.197510: step 12152, loss = 0.54684 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:56:25.160022 ops/training.py:65 2019-01-16 11:56:25.159949: step 12153, loss = 0.52444 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:56:26.121181 ops/training.py:65 2019-01-16 11:56:26.121116: step 12154, loss = 0.57649 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:56:27.085004 ops/training.py:65 2019-01-16 11:56:27.084942: step 12155, loss = 0.55128 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:56:28.046285 ops/training.py:65 2019-01-16 11:56:28.046232: step 12156, loss = 0.73448 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:56:29.010876 ops/training.py:65 2019-01-16 11:56:29.010807: step 12157, loss = 0.55008 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:56:29.973341 ops/training.py:65 2019-01-16 11:56:29.973287: step 12158, loss = 0.59446 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:56:30.935524 ops/training.py:65 2019-01-16 11:56:30.935464: step 12159, loss = 0.63064 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:56:31.895784 ops/training.py:65 2019-01-16 11:56:31.895739: step 12160, loss = 0.51647 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:56:32.856122 ops/training.py:65 2019-01-16 11:56:32.856051: step 12161, loss = 0.62472 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:56:33.817410 ops/training.py:65 2019-01-16 11:56:33.817363: step 12162, loss = 0.71709 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:56:34.778588 ops/training.py:65 2019-01-16 11:56:34.778539: step 12163, loss = 0.53729 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:56:35.739409 ops/training.py:65 2019-01-16 11:56:35.739362: step 12164, loss = 0.59142 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:56:36.699494 ops/training.py:65 2019-01-16 11:56:36.699433: step 12165, loss = 0.46709 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:56:37.662434 ops/training.py:65 2019-01-16 11:56:37.662380: step 12166, loss = 0.56020 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:56:38.625962 ops/training.py:65 2019-01-16 11:56:38.625875: step 12167, loss = 0.59761 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:56:39.589052 ops/training.py:65 2019-01-16 11:56:39.589002: step 12168, loss = 0.53778 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:56:40.548584 ops/training.py:65 2019-01-16 11:56:40.548524: step 12169, loss = 0.46107 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:56:41.511351 ops/training.py:65 2019-01-16 11:56:41.511299: step 12170, loss = 0.62878 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:56:42.475914 ops/training.py:65 2019-01-16 11:56:42.475868: step 12171, loss = 0.52699 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:56:43.438862 ops/training.py:65 2019-01-16 11:56:43.438818: step 12172, loss = 0.75777 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:56:44.400653 ops/training.py:65 2019-01-16 11:56:44.400604: step 12173, loss = 0.61147 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:56:45.361925 ops/training.py:65 2019-01-16 11:56:45.361877: step 12174, loss = 0.58591 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:56:46.323066 ops/training.py:65 2019-01-16 11:56:46.322998: step 12175, loss = 0.53297 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:56:47.284536 ops/training.py:65 2019-01-16 11:56:47.284485: step 12176, loss = 0.59436 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:56:48.246588 ops/training.py:65 2019-01-16 11:56:48.246514: step 12177, loss = 0.58965 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:56:49.209787 ops/training.py:65 2019-01-16 11:56:49.209740: step 12178, loss = 0.58574 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:56:50.173362 ops/training.py:65 2019-01-16 11:56:50.173316: step 12179, loss = 0.56304 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:56:51.134246 ops/training.py:65 2019-01-16 11:56:51.134201: step 12180, loss = 0.58665 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:56:52.095251 ops/training.py:65 2019-01-16 11:56:52.095201: step 12181, loss = 0.45960 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:56:53.058585 ops/training.py:65 2019-01-16 11:56:53.058540: step 12182, loss = 0.65092 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:56:54.026516 ops/training.py:65 2019-01-16 11:56:54.026472: step 12183, loss = 0.59015 (33.1 examples/sec; 0.967 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:56:54.988498 ops/training.py:65 2019-01-16 11:56:54.988448: step 12184, loss = 0.56143 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:56:55.950042 ops/training.py:65 2019-01-16 11:56:55.949998: step 12185, loss = 0.49825 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:56:56.910684 ops/training.py:65 2019-01-16 11:56:56.910631: step 12186, loss = 0.62759 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:56:57.875246 ops/training.py:65 2019-01-16 11:56:57.875195: step 12187, loss = 0.53673 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:56:58.837222 ops/training.py:65 2019-01-16 11:56:58.837141: step 12188, loss = 0.54661 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:56:59.798135 ops/training.py:65 2019-01-16 11:56:59.798070: step 12189, loss = 0.53404 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:57:00.759564 ops/training.py:65 2019-01-16 11:57:00.759496: step 12190, loss = 0.59113 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:57:01.722152 ops/training.py:65 2019-01-16 11:57:01.722093: step 12191, loss = 0.56637 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:57:02.681273 ops/training.py:65 2019-01-16 11:57:02.681220: step 12192, loss = 0.54345 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:57:03.642300 ops/training.py:65 2019-01-16 11:57:03.642256: step 12193, loss = 0.51123 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:57:04.603643 ops/training.py:65 2019-01-16 11:57:04.603577: step 12194, loss = 0.70113 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 11:57:05.563540 ops/training.py:65 2019-01-16 11:57:05.563489: step 12195, loss = 0.72147 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:57:06.524314 ops/training.py:65 2019-01-16 11:57:06.524258: step 12196, loss = 0.67805 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:57:07.487318 ops/training.py:65 2019-01-16 11:57:07.487262: step 12197, loss = 0.51501 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:57:08.450145 ops/training.py:65 2019-01-16 11:57:08.450096: step 12198, loss = 0.56307 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:57:09.410873 ops/training.py:65 2019-01-16 11:57:09.410806: step 12199, loss = 0.73853 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:57:10.371305 ops/training.py:65 2019-01-16 11:57:10.371235: step 12200, loss = 0.52748 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:57:11.336155 ops/training.py:65 2019-01-16 11:57:11.336110: step 12201, loss = 0.56707 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:57:12.297975 ops/training.py:65 2019-01-16 11:57:12.297925: step 12202, loss = 0.58422 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:57:13.258676 ops/training.py:65 2019-01-16 11:57:13.258625: step 12203, loss = 0.50396 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:57:14.219429 ops/training.py:65 2019-01-16 11:57:14.219379: step 12204, loss = 0.35187 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 11:57:15.181719 ops/training.py:65 2019-01-16 11:57:15.181674: step 12205, loss = 0.53329 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:57:16.144027 ops/training.py:65 2019-01-16 11:57:16.143984: step 12206, loss = 0.50626 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:57:17.105724 ops/training.py:65 2019-01-16 11:57:17.105683: step 12207, loss = 0.50583 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:57:18.067640 ops/training.py:65 2019-01-16 11:57:18.067596: step 12208, loss = 0.53684 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:57:19.028638 ops/training.py:65 2019-01-16 11:57:19.028582: step 12209, loss = 0.60236 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:57:19.989715 ops/training.py:65 2019-01-16 11:57:19.989655: step 12210, loss = 0.53774 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:57:20.950648 ops/training.py:65 2019-01-16 11:57:20.950577: step 12211, loss = 0.55231 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:57:21.912182 ops/training.py:65 2019-01-16 11:57:21.912118: step 12212, loss = 0.49017 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:57:22.874591 ops/training.py:65 2019-01-16 11:57:22.874542: step 12213, loss = 0.54595 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:57:23.837528 ops/training.py:65 2019-01-16 11:57:23.837484: step 12214, loss = 0.60777 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:57:24.797460 ops/training.py:65 2019-01-16 11:57:24.797409: step 12215, loss = 0.44924 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:57:25.759566 ops/training.py:65 2019-01-16 11:57:25.759516: step 12216, loss = 0.48374 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:57:26.722272 ops/training.py:65 2019-01-16 11:57:26.722203: step 12217, loss = 0.59380 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:57:27.684426 ops/training.py:65 2019-01-16 11:57:27.684355: step 12218, loss = 0.53280 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:57:28.644577 ops/training.py:65 2019-01-16 11:57:28.644511: step 12219, loss = 0.55687 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:57:29.607470 ops/training.py:65 2019-01-16 11:57:29.607420: step 12220, loss = 0.62012 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:57:30.570067 ops/training.py:65 2019-01-16 11:57:30.569999: step 12221, loss = 0.57516 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:57:31.531192 ops/training.py:65 2019-01-16 11:57:31.531122: step 12222, loss = 0.63989 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:57:32.492294 ops/training.py:65 2019-01-16 11:57:32.492233: step 12223, loss = 0.52103 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:57:33.453398 ops/training.py:65 2019-01-16 11:57:33.453332: step 12224, loss = 0.44372 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:57:34.414413 ops/training.py:65 2019-01-16 11:57:34.414362: step 12225, loss = 0.50145 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:57:35.374972 ops/training.py:65 2019-01-16 11:57:35.374921: step 12226, loss = 0.62035 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:57:36.336043 ops/training.py:65 2019-01-16 11:57:36.335982: step 12227, loss = 0.65727 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:57:37.296930 ops/training.py:65 2019-01-16 11:57:37.296862: step 12228, loss = 0.54821 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:57:38.257592 ops/training.py:65 2019-01-16 11:57:38.257525: step 12229, loss = 0.52212 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:57:39.218476 ops/training.py:65 2019-01-16 11:57:39.218413: step 12230, loss = 0.59497 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:57:40.179683 ops/training.py:65 2019-01-16 11:57:40.179614: step 12231, loss = 0.39093 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:57:41.143360 ops/training.py:65 2019-01-16 11:57:41.143292: step 12232, loss = 0.53330 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:57:42.105004 ops/training.py:65 2019-01-16 11:57:42.104957: step 12233, loss = 0.57674 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:57:43.066885 ops/training.py:65 2019-01-16 11:57:43.066834: step 12234, loss = 0.51434 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:57:44.028629 ops/training.py:65 2019-01-16 11:57:44.028567: step 12235, loss = 0.49363 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:57:44.989912 ops/training.py:65 2019-01-16 11:57:44.989843: step 12236, loss = 0.46497 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:57:45.951133 ops/training.py:65 2019-01-16 11:57:45.951064: step 12237, loss = 0.60028 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:57:46.912239 ops/training.py:65 2019-01-16 11:57:46.912171: step 12238, loss = 0.43206 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:57:47.872851 ops/training.py:65 2019-01-16 11:57:47.872795: step 12239, loss = 0.58779 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:57:48.832626 ops/training.py:65 2019-01-16 11:57:48.832577: step 12240, loss = 0.53903 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:57:49.796986 ops/training.py:65 2019-01-16 11:57:49.796937: step 12241, loss = 0.46304 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:57:50.759006 ops/training.py:65 2019-01-16 11:57:50.758934: step 12242, loss = 0.68007 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:57:51.721595 ops/training.py:65 2019-01-16 11:57:51.721527: step 12243, loss = 0.50428 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:57:52.683042 ops/training.py:65 2019-01-16 11:57:52.682985: step 12244, loss = 0.47737 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:57:53.643714 ops/training.py:65 2019-01-16 11:57:53.643647: step 12245, loss = 0.56655 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:57:54.605001 ops/training.py:65 2019-01-16 11:57:54.604930: step 12246, loss = 0.39389 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:57:55.566917 ops/training.py:65 2019-01-16 11:57:55.566847: step 12247, loss = 0.44875 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:57:56.528535 ops/training.py:65 2019-01-16 11:57:56.528474: step 12248, loss = 0.50973 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:57:57.489944 ops/training.py:65 2019-01-16 11:57:57.489875: step 12249, loss = 0.51221 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:57:58.450363 ops/training.py:65 2019-01-16 11:57:58.450313: step 12250, loss = 0.58825 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:57:59.411954 ops/training.py:65 2019-01-16 11:57:59.411873: step 12251, loss = 0.53411 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:58:00.373263 ops/training.py:65 2019-01-16 11:58:00.373217: step 12252, loss = 0.61733 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:58:01.334839 ops/training.py:65 2019-01-16 11:58:01.334791: step 12253, loss = 0.48820 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:58:02.296485 ops/training.py:65 2019-01-16 11:58:02.296436: step 12254, loss = 0.53103 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:58:03.258378 ops/training.py:65 2019-01-16 11:58:03.258325: step 12255, loss = 0.59372 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:58:04.219592 ops/training.py:65 2019-01-16 11:58:04.219545: step 12256, loss = 0.63829 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:58:05.180690 ops/training.py:65 2019-01-16 11:58:05.180642: step 12257, loss = 0.49379 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:58:06.141756 ops/training.py:65 2019-01-16 11:58:06.141709: step 12258, loss = 0.47194 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:58:07.102634 ops/training.py:65 2019-01-16 11:58:07.102567: step 12259, loss = 0.67199 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:58:08.063811 ops/training.py:65 2019-01-16 11:58:08.063754: step 12260, loss = 0.58828 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:58:09.024397 ops/training.py:65 2019-01-16 11:58:09.024331: step 12261, loss = 0.59987 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:58:09.988859 ops/training.py:65 2019-01-16 11:58:09.988793: step 12262, loss = 0.53375 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:58:10.951690 ops/training.py:65 2019-01-16 11:58:10.951635: step 12263, loss = 0.63445 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:58:11.912697 ops/training.py:65 2019-01-16 11:58:11.912615: step 12264, loss = 0.56930 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:58:12.873383 ops/training.py:65 2019-01-16 11:58:12.873318: step 12265, loss = 0.65610 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:58:13.833905 ops/training.py:65 2019-01-16 11:58:13.833838: step 12266, loss = 0.55558 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:58:14.797324 ops/training.py:65 2019-01-16 11:58:14.797275: step 12267, loss = 0.69363 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:58:15.759722 ops/training.py:65 2019-01-16 11:58:15.759674: step 12268, loss = 0.52418 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:58:16.721940 ops/training.py:65 2019-01-16 11:58:16.721890: step 12269, loss = 0.53219 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:58:17.687059 ops/training.py:65 2019-01-16 11:58:17.687012: step 12270, loss = 0.52854 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:58:18.648924 ops/training.py:65 2019-01-16 11:58:18.648859: step 12271, loss = 0.60152 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:58:19.613350 ops/training.py:65 2019-01-16 11:58:19.613305: step 12272, loss = 0.54160 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:58:20.576822 ops/training.py:65 2019-01-16 11:58:20.576769: step 12273, loss = 0.50484 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:58:21.539772 ops/training.py:65 2019-01-16 11:58:21.539718: step 12274, loss = 0.55668 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:58:22.503717 ops/training.py:65 2019-01-16 11:58:22.503665: step 12275, loss = 0.51526 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:58:23.466801 ops/training.py:65 2019-01-16 11:58:23.466752: step 12276, loss = 0.49306 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:58:24.429578 ops/training.py:65 2019-01-16 11:58:24.429520: step 12277, loss = 0.67820 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:58:25.395219 ops/training.py:65 2019-01-16 11:58:25.395166: step 12278, loss = 0.51733 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:58:26.356400 ops/training.py:65 2019-01-16 11:58:26.356354: step 12279, loss = 0.52069 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:58:27.322069 ops/training.py:65 2019-01-16 11:58:27.322018: step 12280, loss = 0.53500 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:58:28.284101 ops/training.py:65 2019-01-16 11:58:28.284054: step 12281, loss = 0.46495 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:58:29.245374 ops/training.py:65 2019-01-16 11:58:29.245325: step 12282, loss = 0.59420 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:58:30.206012 ops/training.py:65 2019-01-16 11:58:30.205966: step 12283, loss = 0.60449 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:58:31.166922 ops/training.py:65 2019-01-16 11:58:31.166873: step 12284, loss = 0.66729 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:58:32.128780 ops/training.py:65 2019-01-16 11:58:32.128731: step 12285, loss = 0.53723 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:58:33.090654 ops/training.py:65 2019-01-16 11:58:33.090584: step 12286, loss = 0.60324 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:58:34.051959 ops/training.py:65 2019-01-16 11:58:34.051913: step 12287, loss = 0.54137 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:58:35.013357 ops/training.py:65 2019-01-16 11:58:35.013308: step 12288, loss = 0.49027 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:58:35.974840 ops/training.py:65 2019-01-16 11:58:35.974792: step 12289, loss = 0.52298 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:58:36.936319 ops/training.py:65 2019-01-16 11:58:36.936269: step 12290, loss = 0.48440 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:58:37.897679 ops/training.py:65 2019-01-16 11:58:37.897628: step 12291, loss = 0.47186 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:58:38.858739 ops/training.py:65 2019-01-16 11:58:38.858683: step 12292, loss = 0.48609 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 11:58:39.820777 ops/training.py:65 2019-01-16 11:58:39.820706: step 12293, loss = 0.49277 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:58:40.781855 ops/training.py:65 2019-01-16 11:58:40.781786: step 12294, loss = 0.52968 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:58:41.742330 ops/training.py:65 2019-01-16 11:58:41.742277: step 12295, loss = 0.52151 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:58:42.703832 ops/training.py:65 2019-01-16 11:58:42.703759: step 12296, loss = 0.60421 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:58:43.664613 ops/training.py:65 2019-01-16 11:58:43.664558: step 12297, loss = 0.66992 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:58:44.626346 ops/training.py:65 2019-01-16 11:58:44.626293: step 12298, loss = 0.57153 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:58:45.588782 ops/training.py:65 2019-01-16 11:58:45.588735: step 12299, loss = 0.66922 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:58:46.550881 ops/training.py:65 2019-01-16 11:58:46.550835: step 12300, loss = 0.48718 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:58:47.511939 ops/training.py:65 2019-01-16 11:58:47.511889: step 12301, loss = 0.63995 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:58:48.472640 ops/training.py:65 2019-01-16 11:58:48.472587: step 12302, loss = 0.63211 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:58:49.433963 ops/training.py:65 2019-01-16 11:58:49.433910: step 12303, loss = 0.60632 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:58:50.395087 ops/training.py:65 2019-01-16 11:58:50.395014: step 12304, loss = 0.54654 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:58:51.360875 ops/training.py:65 2019-01-16 11:58:51.360810: step 12305, loss = 0.69674 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:58:52.322883 ops/training.py:65 2019-01-16 11:58:52.322833: step 12306, loss = 0.74198 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:58:53.284649 ops/training.py:65 2019-01-16 11:58:53.284589: step 12307, loss = 0.55934 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:58:54.249574 ops/training.py:65 2019-01-16 11:58:54.249504: step 12308, loss = 0.60580 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:58:55.210774 ops/training.py:65 2019-01-16 11:58:55.210704: step 12309, loss = 0.66493 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:58:56.174546 ops/training.py:65 2019-01-16 11:58:56.174478: step 12310, loss = 0.45132 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:58:57.138011 ops/training.py:65 2019-01-16 11:58:57.137967: step 12311, loss = 0.69212 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:58:58.101552 ops/training.py:65 2019-01-16 11:58:58.101503: step 12312, loss = 0.61868 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:58:59.063144 ops/training.py:65 2019-01-16 11:58:59.063095: step 12313, loss = 0.68625 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:59:00.025933 ops/training.py:65 2019-01-16 11:59:00.025879: step 12314, loss = 0.65585 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:59:00.989173 ops/training.py:65 2019-01-16 11:59:00.989125: step 12315, loss = 0.49864 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:59:01.950658 ops/training.py:65 2019-01-16 11:59:01.950608: step 12316, loss = 0.61927 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:59:02.913211 ops/training.py:65 2019-01-16 11:59:02.913160: step 12317, loss = 0.53129 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:59:03.874255 ops/training.py:65 2019-01-16 11:59:03.874207: step 12318, loss = 0.59725 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:59:04.835489 ops/training.py:65 2019-01-16 11:59:04.835441: step 12319, loss = 0.51895 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:59:05.796652 ops/training.py:65 2019-01-16 11:59:05.796602: step 12320, loss = 0.55142 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:59:06.758198 ops/training.py:65 2019-01-16 11:59:06.758146: step 12321, loss = 0.52920 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:59:07.721438 ops/training.py:65 2019-01-16 11:59:07.721389: step 12322, loss = 0.55047 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:59:08.684502 ops/training.py:65 2019-01-16 11:59:08.684439: step 12323, loss = 0.48798 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:59:09.645516 ops/training.py:65 2019-01-16 11:59:09.645455: step 12324, loss = 0.47630 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:59:10.606890 ops/training.py:65 2019-01-16 11:59:10.606818: step 12325, loss = 0.59946 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:59:11.569257 ops/training.py:65 2019-01-16 11:59:11.569185: step 12326, loss = 0.67752 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:59:12.531481 ops/training.py:65 2019-01-16 11:59:12.531418: step 12327, loss = 0.52436 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:59:13.493087 ops/training.py:65 2019-01-16 11:59:13.493030: step 12328, loss = 0.56156 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:59:14.455046 ops/training.py:65 2019-01-16 11:59:14.454990: step 12329, loss = 0.44264 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:59:15.418523 ops/training.py:65 2019-01-16 11:59:15.418474: step 12330, loss = 0.52274 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:59:16.382125 ops/training.py:65 2019-01-16 11:59:16.382078: step 12331, loss = 0.67402 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:59:17.344020 ops/training.py:65 2019-01-16 11:59:17.343970: step 12332, loss = 0.59044 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:59:18.305151 ops/training.py:65 2019-01-16 11:59:18.305101: step 12333, loss = 0.54738 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:59:19.265842 ops/training.py:65 2019-01-16 11:59:19.265793: step 12334, loss = 0.65579 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:59:20.227050 ops/training.py:65 2019-01-16 11:59:20.226999: step 12335, loss = 0.63697 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:59:21.187937 ops/training.py:65 2019-01-16 11:59:21.187888: step 12336, loss = 0.55912 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:59:22.149728 ops/training.py:65 2019-01-16 11:59:22.149673: step 12337, loss = 0.47701 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:59:23.113593 ops/training.py:65 2019-01-16 11:59:23.113546: step 12338, loss = 0.57470 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:59:24.077727 ops/training.py:65 2019-01-16 11:59:24.077678: step 12339, loss = 0.58076 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:59:25.040110 ops/training.py:65 2019-01-16 11:59:25.040054: step 12340, loss = 0.48590 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:59:26.002283 ops/training.py:65 2019-01-16 11:59:26.002230: step 12341, loss = 0.79496 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 11:59:26.964244 ops/training.py:65 2019-01-16 11:59:26.964196: step 12342, loss = 0.48449 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:59:27.925916 ops/training.py:65 2019-01-16 11:59:27.925870: step 12343, loss = 0.52523 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:59:28.887656 ops/training.py:65 2019-01-16 11:59:28.887607: step 12344, loss = 0.41994 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:59:29.848532 ops/training.py:65 2019-01-16 11:59:29.848488: step 12345, loss = 0.56819 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:59:30.809328 ops/training.py:65 2019-01-16 11:59:30.809278: step 12346, loss = 0.47087 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:59:31.771105 ops/training.py:65 2019-01-16 11:59:31.771054: step 12347, loss = 0.51805 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:59:32.733487 ops/training.py:65 2019-01-16 11:59:32.733433: step 12348, loss = 0.47664 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:59:33.697220 ops/training.py:65 2019-01-16 11:59:33.697176: step 12349, loss = 0.50853 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 11:59:34.661094 ops/training.py:65 2019-01-16 11:59:34.661043: step 12350, loss = 0.66420 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:59:35.624336 ops/training.py:65 2019-01-16 11:59:35.624288: step 12351, loss = 0.39960 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 11:59:36.586986 ops/training.py:65 2019-01-16 11:59:36.586930: step 12352, loss = 0.75584 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:59:37.549820 ops/training.py:65 2019-01-16 11:59:37.549775: step 12353, loss = 0.55391 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:59:38.512791 ops/training.py:65 2019-01-16 11:59:38.512722: step 12354, loss = 0.47920 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:59:39.477990 ops/training.py:65 2019-01-16 11:59:39.477935: step 12355, loss = 0.69865 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 11:59:40.442450 ops/training.py:65 2019-01-16 11:59:40.442397: step 12356, loss = 0.54005 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:59:41.404484 ops/training.py:65 2019-01-16 11:59:41.404436: step 12357, loss = 0.58593 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:59:42.368620 ops/training.py:65 2019-01-16 11:59:42.368571: step 12358, loss = 0.52782 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:59:43.330144 ops/training.py:65 2019-01-16 11:59:43.330090: step 12359, loss = 0.72519 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 11:59:44.294952 ops/training.py:65 2019-01-16 11:59:44.294894: step 12360, loss = 0.54056 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:59:45.258768 ops/training.py:65 2019-01-16 11:59:45.258722: step 12361, loss = 0.61599 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:59:46.222035 ops/training.py:65 2019-01-16 11:59:46.221987: step 12362, loss = 0.54478 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:59:47.183311 ops/training.py:65 2019-01-16 11:59:47.183258: step 12363, loss = 0.63018 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:59:48.144023 ops/training.py:65 2019-01-16 11:59:48.143967: step 12364, loss = 0.65075 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:59:49.108319 ops/training.py:65 2019-01-16 11:59:49.108270: step 12365, loss = 0.55047 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:59:50.071359 ops/training.py:65 2019-01-16 11:59:50.071309: step 12366, loss = 0.67242 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:59:51.034895 ops/training.py:65 2019-01-16 11:59:51.034844: step 12367, loss = 0.57875 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:59:51.996728 ops/training.py:65 2019-01-16 11:59:51.996676: step 12368, loss = 0.54894 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 11:59:52.957715 ops/training.py:65 2019-01-16 11:59:52.957667: step 12369, loss = 0.57384 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 11:59:53.919368 ops/training.py:65 2019-01-16 11:59:53.919317: step 12370, loss = 0.54223 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 11:59:54.881208 ops/training.py:65 2019-01-16 11:59:54.881159: step 12371, loss = 0.64562 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 11:59:55.842551 ops/training.py:65 2019-01-16 11:59:55.842506: step 12372, loss = 0.54280 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 11:59:56.804174 ops/training.py:65 2019-01-16 11:59:56.804128: step 12373, loss = 0.63844 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:59:57.766508 ops/training.py:65 2019-01-16 11:59:57.766459: step 12374, loss = 0.62708 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 11:59:58.728571 ops/training.py:65 2019-01-16 11:59:58.728522: step 12375, loss = 0.63132 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 11:59:59.690607 ops/training.py:65 2019-01-16 11:59:59.690555: step 12376, loss = 0.55187 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:00:00.652160 ops/training.py:65 2019-01-16 12:00:00.652109: step 12377, loss = 0.55012 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:00:01.615606 ops/training.py:65 2019-01-16 12:00:01.615555: step 12378, loss = 0.81214 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 12:00:02.578574 ops/training.py:65 2019-01-16 12:00:02.578519: step 12379, loss = 0.51233 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:00:03.541948 ops/training.py:65 2019-01-16 12:00:03.541900: step 12380, loss = 0.59822 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:00:04.503222 ops/training.py:65 2019-01-16 12:00:04.503171: step 12381, loss = 0.58508 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:00:05.464336 ops/training.py:65 2019-01-16 12:00:05.464284: step 12382, loss = 0.56392 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:00:06.425211 ops/training.py:65 2019-01-16 12:00:06.425158: step 12383, loss = 0.44245 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:00:07.385741 ops/training.py:65 2019-01-16 12:00:07.385671: step 12384, loss = 0.72996 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:00:08.349923 ops/training.py:65 2019-01-16 12:00:08.349867: step 12385, loss = 0.59512 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:00:09.311909 ops/training.py:65 2019-01-16 12:00:09.311844: step 12386, loss = 0.48964 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:00:10.273729 ops/training.py:65 2019-01-16 12:00:10.273655: step 12387, loss = 0.55534 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:00:11.235648 ops/training.py:65 2019-01-16 12:00:11.235598: step 12388, loss = 0.56543 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:00:12.196807 ops/training.py:65 2019-01-16 12:00:12.196759: step 12389, loss = 0.48590 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:00:13.160814 ops/training.py:65 2019-01-16 12:00:13.160753: step 12390, loss = 0.54258 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:00:14.124816 ops/training.py:65 2019-01-16 12:00:14.124766: step 12391, loss = 0.52146 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:00:15.087759 ops/training.py:65 2019-01-16 12:00:15.087711: step 12392, loss = 0.55807 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:00:16.049576 ops/training.py:65 2019-01-16 12:00:16.049527: step 12393, loss = 0.57844 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:00:17.011205 ops/training.py:65 2019-01-16 12:00:17.011154: step 12394, loss = 0.61990 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:00:17.974169 ops/training.py:65 2019-01-16 12:00:17.974116: step 12395, loss = 0.59375 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:00:18.935695 ops/training.py:65 2019-01-16 12:00:18.935647: step 12396, loss = 0.59088 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:00:19.897606 ops/training.py:65 2019-01-16 12:00:19.897557: step 12397, loss = 0.65598 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:00:20.858827 ops/training.py:65 2019-01-16 12:00:20.858763: step 12398, loss = 0.47226 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:00:21.823359 ops/training.py:65 2019-01-16 12:00:21.823315: step 12399, loss = 0.60263 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:00:22.787472 ops/training.py:65 2019-01-16 12:00:22.787424: step 12400, loss = 0.56606 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:00:23.751127 ops/training.py:65 2019-01-16 12:00:23.751075: step 12401, loss = 0.51652 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:00:24.712350 ops/training.py:65 2019-01-16 12:00:24.712299: step 12402, loss = 0.66022 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:00:25.673404 ops/training.py:65 2019-01-16 12:00:25.673359: step 12403, loss = 0.58945 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:00:26.635220 ops/training.py:65 2019-01-16 12:00:26.635171: step 12404, loss = 0.57529 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:00:27.596601 ops/training.py:65 2019-01-16 12:00:27.596555: step 12405, loss = 0.56701 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:00:28.558095 ops/training.py:65 2019-01-16 12:00:28.558041: step 12406, loss = 0.56686 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:00:29.520009 ops/training.py:65 2019-01-16 12:00:29.519932: step 12407, loss = 0.51451 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:00:30.481963 ops/training.py:65 2019-01-16 12:00:30.481890: step 12408, loss = 0.50954 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:00:31.444011 ops/training.py:65 2019-01-16 12:00:31.443962: step 12409, loss = 0.61905 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:00:32.405178 ops/training.py:65 2019-01-16 12:00:32.405123: step 12410, loss = 0.55492 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:00:33.366248 ops/training.py:65 2019-01-16 12:00:33.366178: step 12411, loss = 0.58487 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:00:34.328075 ops/training.py:65 2019-01-16 12:00:34.328001: step 12412, loss = 0.65574 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:00:35.292183 ops/training.py:65 2019-01-16 12:00:35.292110: step 12413, loss = 0.54914 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:00:36.255691 ops/training.py:65 2019-01-16 12:00:36.255621: step 12414, loss = 0.76484 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 12:00:37.219786 ops/training.py:65 2019-01-16 12:00:37.219715: step 12415, loss = 0.63525 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:00:38.184090 ops/training.py:65 2019-01-16 12:00:38.184039: step 12416, loss = 0.44756 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:00:39.146491 ops/training.py:65 2019-01-16 12:00:39.146425: step 12417, loss = 0.48406 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:00:40.108553 ops/training.py:65 2019-01-16 12:00:40.108484: step 12418, loss = 0.54900 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:00:41.073216 ops/training.py:65 2019-01-16 12:00:41.073147: step 12419, loss = 0.64588 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:00:42.036679 ops/training.py:65 2019-01-16 12:00:42.036613: step 12420, loss = 0.53135 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:00:42.998277 ops/training.py:65 2019-01-16 12:00:42.998210: step 12421, loss = 0.50319 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:00:43.962593 ops/training.py:65 2019-01-16 12:00:43.962535: step 12422, loss = 0.51271 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:00:44.923816 ops/training.py:65 2019-01-16 12:00:44.923750: step 12423, loss = 0.56524 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:00:45.885002 ops/training.py:65 2019-01-16 12:00:45.884934: step 12424, loss = 0.60655 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:00:46.846046 ops/training.py:65 2019-01-16 12:00:46.845994: step 12425, loss = 0.51190 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:00:47.807156 ops/training.py:65 2019-01-16 12:00:47.807097: step 12426, loss = 0.51483 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:00:48.768508 ops/training.py:65 2019-01-16 12:00:48.768448: step 12427, loss = 0.59961 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:00:49.730141 ops/training.py:65 2019-01-16 12:00:49.730074: step 12428, loss = 0.52543 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:00:50.691925 ops/training.py:65 2019-01-16 12:00:50.691855: step 12429, loss = 0.72473 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:00:51.653435 ops/training.py:65 2019-01-16 12:00:51.653368: step 12430, loss = 0.51234 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:00:52.615841 ops/training.py:65 2019-01-16 12:00:52.615771: step 12431, loss = 0.79693 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 12:00:53.577750 ops/training.py:65 2019-01-16 12:00:53.577683: step 12432, loss = 0.59113 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:00:54.541690 ops/training.py:65 2019-01-16 12:00:54.541623: step 12433, loss = 0.57997 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:00:55.506258 ops/training.py:65 2019-01-16 12:00:55.506190: step 12434, loss = 0.56083 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:00:56.469817 ops/training.py:65 2019-01-16 12:00:56.469747: step 12435, loss = 0.54691 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:00:57.432053 ops/training.py:65 2019-01-16 12:00:57.432005: step 12436, loss = 0.47237 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:00:58.393388 ops/training.py:65 2019-01-16 12:00:58.393317: step 12437, loss = 0.57854 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:00:59.357559 ops/training.py:65 2019-01-16 12:00:59.357489: step 12438, loss = 0.56359 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:01:00.321953 ops/training.py:65 2019-01-16 12:01:00.321882: step 12439, loss = 0.50900 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:01:01.285546 ops/training.py:65 2019-01-16 12:01:01.285497: step 12440, loss = 0.44114 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:01:02.246444 ops/training.py:65 2019-01-16 12:01:02.246390: step 12441, loss = 0.60187 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:01:03.208202 ops/training.py:65 2019-01-16 12:01:03.208139: step 12442, loss = 0.47645 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:01:04.169958 ops/training.py:65 2019-01-16 12:01:04.169883: step 12443, loss = 0.63805 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:01:05.131022 ops/training.py:65 2019-01-16 12:01:05.130951: step 12444, loss = 0.57268 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:01:06.092588 ops/training.py:65 2019-01-16 12:01:06.092521: step 12445, loss = 0.56923 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:01:07.053884 ops/training.py:65 2019-01-16 12:01:07.053813: step 12446, loss = 0.62279 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:01:08.014999 ops/training.py:65 2019-01-16 12:01:08.014946: step 12447, loss = 0.62525 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:01:08.976255 ops/training.py:65 2019-01-16 12:01:08.976194: step 12448, loss = 0.55985 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:01:09.938087 ops/training.py:65 2019-01-16 12:01:09.938018: step 12449, loss = 0.60380 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:01:10.899610 ops/training.py:65 2019-01-16 12:01:10.899541: step 12450, loss = 0.46322 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:01:11.861020 ops/training.py:65 2019-01-16 12:01:11.860955: step 12451, loss = 0.59615 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:01:12.823685 ops/training.py:65 2019-01-16 12:01:12.823617: step 12452, loss = 0.41266 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:01:13.788080 ops/training.py:65 2019-01-16 12:01:13.788008: step 12453, loss = 0.62573 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:01:14.751516 ops/training.py:65 2019-01-16 12:01:14.751445: step 12454, loss = 0.69279 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:01:15.713682 ops/training.py:65 2019-01-16 12:01:15.713610: step 12455, loss = 0.58334 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:01:16.675076 ops/training.py:65 2019-01-16 12:01:16.675010: step 12456, loss = 0.50076 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:01:17.640792 ops/training.py:65 2019-01-16 12:01:17.640735: step 12457, loss = 0.46176 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:01:18.602439 ops/training.py:65 2019-01-16 12:01:18.602372: step 12458, loss = 0.48795 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:01:19.566780 ops/training.py:65 2019-01-16 12:01:19.566712: step 12459, loss = 0.49978 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:01:20.530298 ops/training.py:65 2019-01-16 12:01:20.530228: step 12460, loss = 0.65827 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:01:21.492559 ops/training.py:65 2019-01-16 12:01:21.492490: step 12461, loss = 0.60345 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:01:22.452626 ops/training.py:65 2019-01-16 12:01:22.452560: step 12462, loss = 0.47044 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:01:23.416286 ops/training.py:65 2019-01-16 12:01:23.416219: step 12463, loss = 0.68903 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:01:24.378240 ops/training.py:65 2019-01-16 12:01:24.378156: step 12464, loss = 0.59206 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:01:25.339136 ops/training.py:65 2019-01-16 12:01:25.339070: step 12465, loss = 0.63299 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:01:26.302023 ops/training.py:65 2019-01-16 12:01:26.301954: step 12466, loss = 0.71782 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:01:27.263991 ops/training.py:65 2019-01-16 12:01:27.263940: step 12467, loss = 0.54783 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:01:28.226472 ops/training.py:65 2019-01-16 12:01:28.226405: step 12468, loss = 0.58136 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:01:29.189548 ops/training.py:65 2019-01-16 12:01:29.189486: step 12469, loss = 0.62732 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:01:30.151099 ops/training.py:65 2019-01-16 12:01:30.151046: step 12470, loss = 0.49958 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:01:31.110981 ops/training.py:65 2019-01-16 12:01:31.110925: step 12471, loss = 0.56934 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:01:32.075351 ops/training.py:65 2019-01-16 12:01:32.075287: step 12472, loss = 0.56450 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:01:33.037409 ops/training.py:65 2019-01-16 12:01:33.037340: step 12473, loss = 0.49891 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:01:33.998994 ops/training.py:65 2019-01-16 12:01:33.998926: step 12474, loss = 0.60708 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:01:34.959129 ops/training.py:65 2019-01-16 12:01:34.959064: step 12475, loss = 0.64686 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:01:35.919417 ops/training.py:65 2019-01-16 12:01:35.919353: step 12476, loss = 0.63666 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:01:36.884823 ops/training.py:65 2019-01-16 12:01:36.884758: step 12477, loss = 0.56617 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:01:37.850123 ops/training.py:65 2019-01-16 12:01:37.850057: step 12478, loss = 0.63622 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:01:38.813456 ops/training.py:65 2019-01-16 12:01:38.813392: step 12479, loss = 0.47179 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:01:39.775784 ops/training.py:65 2019-01-16 12:01:39.775714: step 12480, loss = 0.54169 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:01:40.738809 ops/training.py:65 2019-01-16 12:01:40.738738: step 12481, loss = 0.59657 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:01:41.703363 ops/training.py:65 2019-01-16 12:01:41.703294: step 12482, loss = 0.60299 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:01:42.667374 ops/training.py:65 2019-01-16 12:01:42.667323: step 12483, loss = 0.71193 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:01:43.630975 ops/training.py:65 2019-01-16 12:01:43.630906: step 12484, loss = 0.70786 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 12:01:44.592981 ops/training.py:65 2019-01-16 12:01:44.592929: step 12485, loss = 0.60914 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:01:45.554716 ops/training.py:65 2019-01-16 12:01:45.554652: step 12486, loss = 0.64619 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:01:46.516453 ops/training.py:65 2019-01-16 12:01:46.516399: step 12487, loss = 0.50088 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:01:47.478038 ops/training.py:65 2019-01-16 12:01:47.477970: step 12488, loss = 0.57945 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:01:48.439509 ops/training.py:65 2019-01-16 12:01:48.439441: step 12489, loss = 0.54034 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:01:49.400734 ops/training.py:65 2019-01-16 12:01:49.400669: step 12490, loss = 0.59854 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:01:50.362116 ops/training.py:65 2019-01-16 12:01:50.362053: step 12491, loss = 0.73886 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:01:51.324231 ops/training.py:65 2019-01-16 12:01:51.324146: step 12492, loss = 0.47956 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:01:52.287480 ops/training.py:65 2019-01-16 12:01:52.287411: step 12493, loss = 0.51967 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:01:53.249295 ops/training.py:65 2019-01-16 12:01:53.249230: step 12494, loss = 0.59073 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:01:54.209840 ops/training.py:65 2019-01-16 12:01:54.209776: step 12495, loss = 0.49744 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:01:55.174826 ops/training.py:65 2019-01-16 12:01:55.174759: step 12496, loss = 0.51343 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:01:56.140129 ops/training.py:65 2019-01-16 12:01:56.140064: step 12497, loss = 0.58314 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:01:57.104404 ops/training.py:65 2019-01-16 12:01:57.104334: step 12498, loss = 0.52934 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:01:58.066691 ops/training.py:65 2019-01-16 12:01:58.066621: step 12499, loss = 0.34366 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:01:59.028219 ops/training.py:65 2019-01-16 12:01:59.028158: step 12500, loss = 0.60707 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:01:59.990450 ops/training.py:65 2019-01-16 12:01:59.990382: step 12501, loss = 0.54420 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:02:00.952519 ops/training.py:65 2019-01-16 12:02:00.952451: step 12502, loss = 0.60087 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:02:01.914476 ops/training.py:65 2019-01-16 12:02:01.914422: step 12503, loss = 0.52941 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:02:02.875769 ops/training.py:65 2019-01-16 12:02:02.875711: step 12504, loss = 0.51811 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:02:03.836463 ops/training.py:65 2019-01-16 12:02:03.836408: step 12505, loss = 0.56840 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:02:04.797696 ops/training.py:65 2019-01-16 12:02:04.797628: step 12506, loss = 0.46187 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:02:05.759209 ops/training.py:65 2019-01-16 12:02:05.759146: step 12507, loss = 0.52421 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:02:06.723391 ops/training.py:65 2019-01-16 12:02:06.723342: step 12508, loss = 0.63455 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:02:07.685825 ops/training.py:65 2019-01-16 12:02:07.685759: step 12509, loss = 0.54867 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:02:08.647473 ops/training.py:65 2019-01-16 12:02:08.647417: step 12510, loss = 0.49403 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:02:09.611108 ops/training.py:65 2019-01-16 12:02:09.611048: step 12511, loss = 0.45324 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:02:10.575451 ops/training.py:65 2019-01-16 12:02:10.575384: step 12512, loss = 0.39967 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:02:11.539221 ops/training.py:65 2019-01-16 12:02:11.539155: step 12513, loss = 0.51881 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:02:12.502419 ops/training.py:65 2019-01-16 12:02:12.502354: step 12514, loss = 0.54884 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:02:13.466996 ops/training.py:65 2019-01-16 12:02:13.466928: step 12515, loss = 0.48645 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:02:14.431213 ops/training.py:65 2019-01-16 12:02:14.431147: step 12516, loss = 0.49515 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:02:15.394821 ops/training.py:65 2019-01-16 12:02:15.394753: step 12517, loss = 0.62146 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:02:16.356663 ops/training.py:65 2019-01-16 12:02:16.356614: step 12518, loss = 0.67195 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:02:17.318196 ops/training.py:65 2019-01-16 12:02:17.318129: step 12519, loss = 0.50638 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:02:18.280575 ops/training.py:65 2019-01-16 12:02:18.280506: step 12520, loss = 0.59055 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:02:19.241706 ops/training.py:65 2019-01-16 12:02:19.241644: step 12521, loss = 0.55483 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:02:20.203519 ops/training.py:65 2019-01-16 12:02:20.203450: step 12522, loss = 0.55669 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:02:21.164447 ops/training.py:65 2019-01-16 12:02:21.164383: step 12523, loss = 0.52284 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:02:22.124897 ops/training.py:65 2019-01-16 12:02:22.124832: step 12524, loss = 0.46212 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:02:23.086980 ops/training.py:65 2019-01-16 12:02:23.086917: step 12525, loss = 0.67475 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:02:24.051279 ops/training.py:65 2019-01-16 12:02:24.051212: step 12526, loss = 0.56073 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:02:25.011674 ops/training.py:65 2019-01-16 12:02:25.011609: step 12527, loss = 0.45196 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:02:25.975030 ops/training.py:65 2019-01-16 12:02:25.974965: step 12528, loss = 0.49357 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:02:26.936218 ops/training.py:65 2019-01-16 12:02:26.936154: step 12529, loss = 0.68456 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:02:27.900588 ops/training.py:65 2019-01-16 12:02:27.900523: step 12530, loss = 0.59151 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:02:28.864064 ops/training.py:65 2019-01-16 12:02:28.863997: step 12531, loss = 0.79092 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 12:02:29.825921 ops/training.py:65 2019-01-16 12:02:29.825855: step 12532, loss = 0.54268 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:02:30.789659 ops/training.py:65 2019-01-16 12:02:30.789594: step 12533, loss = 0.44768 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:02:31.752239 ops/training.py:65 2019-01-16 12:02:31.752190: step 12534, loss = 0.46952 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:02:32.714628 ops/training.py:65 2019-01-16 12:02:32.714564: step 12535, loss = 0.61947 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:02:33.676642 ops/training.py:65 2019-01-16 12:02:33.676574: step 12536, loss = 0.54450 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:02:34.637116 ops/training.py:65 2019-01-16 12:02:34.637051: step 12537, loss = 0.48240 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:02:35.598686 ops/training.py:65 2019-01-16 12:02:35.598619: step 12538, loss = 0.51903 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:02:36.561318 ops/training.py:65 2019-01-16 12:02:36.561244: step 12539, loss = 0.54608 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:02:37.522582 ops/training.py:65 2019-01-16 12:02:37.522515: step 12540, loss = 0.49591 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:02:38.483226 ops/training.py:65 2019-01-16 12:02:38.483174: step 12541, loss = 0.68447 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:02:39.447625 ops/training.py:65 2019-01-16 12:02:39.447561: step 12542, loss = 0.60024 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:02:40.409077 ops/training.py:65 2019-01-16 12:02:40.409013: step 12543, loss = 0.56289 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:02:41.370097 ops/training.py:65 2019-01-16 12:02:41.370030: step 12544, loss = 0.60612 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:02:42.331526 ops/training.py:65 2019-01-16 12:02:42.331466: step 12545, loss = 0.71244 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:02:43.293793 ops/training.py:65 2019-01-16 12:02:43.293724: step 12546, loss = 0.59739 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:02:44.255142 ops/training.py:65 2019-01-16 12:02:44.255073: step 12547, loss = 0.58702 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:02:45.216700 ops/training.py:65 2019-01-16 12:02:45.216631: step 12548, loss = 0.53818 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:02:46.180780 ops/training.py:65 2019-01-16 12:02:46.180712: step 12549, loss = 0.59532 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:02:47.144190 ops/training.py:65 2019-01-16 12:02:47.144139: step 12550, loss = 0.43029 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:02:48.105729 ops/training.py:65 2019-01-16 12:02:48.105657: step 12551, loss = 0.60902 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:02:49.070960 ops/training.py:65 2019-01-16 12:02:49.070887: step 12552, loss = 0.49863 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:02:50.033313 ops/training.py:65 2019-01-16 12:02:50.033242: step 12553, loss = 0.52149 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:02:50.996179 ops/training.py:65 2019-01-16 12:02:50.996109: step 12554, loss = 0.65243 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:02:51.959942 ops/training.py:65 2019-01-16 12:02:51.959888: step 12555, loss = 0.55901 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:02:52.921896 ops/training.py:65 2019-01-16 12:02:52.921831: step 12556, loss = 0.63045 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 12:02:53.884422 ops/training.py:65 2019-01-16 12:02:53.884352: step 12557, loss = 0.53226 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:02:54.845418 ops/training.py:65 2019-01-16 12:02:54.845347: step 12558, loss = 0.40976 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:02:55.807107 ops/training.py:65 2019-01-16 12:02:55.807037: step 12559, loss = 0.53491 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:02:56.768266 ops/training.py:65 2019-01-16 12:02:56.768203: step 12560, loss = 0.44757 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:02:57.729809 ops/training.py:65 2019-01-16 12:02:57.729742: step 12561, loss = 0.52088 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:02:58.691594 ops/training.py:65 2019-01-16 12:02:58.691526: step 12562, loss = 0.61568 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:02:59.652686 ops/training.py:65 2019-01-16 12:02:59.652616: step 12563, loss = 0.68963 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:03:00.616918 ops/training.py:65 2019-01-16 12:03:00.616862: step 12564, loss = 0.66746 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:03:01.580182 ops/training.py:65 2019-01-16 12:03:01.580132: step 12565, loss = 0.45797 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:03:02.542519 ops/training.py:65 2019-01-16 12:03:02.542460: step 12566, loss = 0.44438 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:03:03.504218 ops/training.py:65 2019-01-16 12:03:03.504150: step 12567, loss = 0.55701 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:03:04.465164 ops/training.py:65 2019-01-16 12:03:04.465098: step 12568, loss = 0.49680 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:03:05.426769 ops/training.py:65 2019-01-16 12:03:05.426707: step 12569, loss = 0.57569 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:03:06.387623 ops/training.py:65 2019-01-16 12:03:06.387572: step 12570, loss = 0.49020 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:03:07.349143 ops/training.py:65 2019-01-16 12:03:07.349076: step 12571, loss = 0.52458 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:03:08.310852 ops/training.py:65 2019-01-16 12:03:08.310801: step 12572, loss = 0.66285 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:03:09.273070 ops/training.py:65 2019-01-16 12:03:09.273002: step 12573, loss = 0.53868 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:03:10.233814 ops/training.py:65 2019-01-16 12:03:10.233744: step 12574, loss = 0.64363 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:03:11.196365 ops/training.py:65 2019-01-16 12:03:11.196308: step 12575, loss = 0.66243 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 12:03:12.160313 ops/training.py:65 2019-01-16 12:03:12.160246: step 12576, loss = 0.48575 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:03:13.124400 ops/training.py:65 2019-01-16 12:03:13.124331: step 12577, loss = 0.48088 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:03:14.086081 ops/training.py:65 2019-01-16 12:03:14.086013: step 12578, loss = 0.50225 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:03:15.049101 ops/training.py:65 2019-01-16 12:03:15.049035: step 12579, loss = 0.60412 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:03:16.013806 ops/training.py:65 2019-01-16 12:03:16.013735: step 12580, loss = 0.57228 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:03:16.977616 ops/training.py:65 2019-01-16 12:03:16.977563: step 12581, loss = 0.65493 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:03:17.939434 ops/training.py:65 2019-01-16 12:03:17.939365: step 12582, loss = 0.64440 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:03:18.902118 ops/training.py:65 2019-01-16 12:03:18.902053: step 12583, loss = 0.55052 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:03:19.866833 ops/training.py:65 2019-01-16 12:03:19.866779: step 12584, loss = 0.51750 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:03:20.830357 ops/training.py:65 2019-01-16 12:03:20.830289: step 12585, loss = 0.44265 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:03:21.794971 ops/training.py:65 2019-01-16 12:03:21.794922: step 12586, loss = 0.45101 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:03:22.757707 ops/training.py:65 2019-01-16 12:03:22.757639: step 12587, loss = 0.50609 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:03:23.720465 ops/training.py:65 2019-01-16 12:03:23.720396: step 12588, loss = 0.65362 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:03:24.683070 ops/training.py:65 2019-01-16 12:03:24.682998: step 12589, loss = 0.57586 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:03:25.647538 ops/training.py:65 2019-01-16 12:03:25.647481: step 12590, loss = 0.47455 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:03:26.610139 ops/training.py:65 2019-01-16 12:03:26.610075: step 12591, loss = 0.58175 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:03:27.574791 ops/training.py:65 2019-01-16 12:03:27.574724: step 12592, loss = 0.49527 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:03:28.537985 ops/training.py:65 2019-01-16 12:03:28.537924: step 12593, loss = 0.54771 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:03:29.502248 ops/training.py:65 2019-01-16 12:03:29.502180: step 12594, loss = 0.52283 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:03:30.464762 ops/training.py:65 2019-01-16 12:03:30.464692: step 12595, loss = 0.63584 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:03:31.428994 ops/training.py:65 2019-01-16 12:03:31.428949: step 12596, loss = 0.46042 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:03:32.390442 ops/training.py:65 2019-01-16 12:03:32.390372: step 12597, loss = 0.41461 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:03:33.354339 ops/training.py:65 2019-01-16 12:03:33.354269: step 12598, loss = 0.62332 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:03:34.318824 ops/training.py:65 2019-01-16 12:03:34.318753: step 12599, loss = 0.57179 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:03:35.282143 ops/training.py:65 2019-01-16 12:03:35.282075: step 12600, loss = 0.61133 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:03:36.244575 ops/training.py:65 2019-01-16 12:03:36.244485: step 12601, loss = 0.71350 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 12:03:37.209749 ops/training.py:65 2019-01-16 12:03:37.209665: step 12602, loss = 0.55680 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:03:38.171071 ops/training.py:65 2019-01-16 12:03:38.171014: step 12603, loss = 0.46283 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:03:39.135037 ops/training.py:65 2019-01-16 12:03:39.134966: step 12604, loss = 0.57576 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:03:40.098774 ops/training.py:65 2019-01-16 12:03:40.098705: step 12605, loss = 0.59998 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:03:41.061181 ops/training.py:65 2019-01-16 12:03:41.061108: step 12606, loss = 0.61486 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:03:42.022742 ops/training.py:65 2019-01-16 12:03:42.022677: step 12607, loss = 0.47833 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:03:42.987864 ops/training.py:65 2019-01-16 12:03:42.987795: step 12608, loss = 0.47468 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:03:43.951432 ops/training.py:65 2019-01-16 12:03:43.951376: step 12609, loss = 0.54600 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:03:44.914721 ops/training.py:65 2019-01-16 12:03:44.914655: step 12610, loss = 0.48068 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:03:45.880363 ops/training.py:65 2019-01-16 12:03:45.880296: step 12611, loss = 0.57055 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:03:46.844437 ops/training.py:65 2019-01-16 12:03:46.844384: step 12612, loss = 0.59310 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:03:47.807012 ops/training.py:65 2019-01-16 12:03:47.806946: step 12613, loss = 0.58230 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:03:48.769568 ops/training.py:65 2019-01-16 12:03:48.769507: step 12614, loss = 0.43073 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:03:49.734083 ops/training.py:65 2019-01-16 12:03:49.734016: step 12615, loss = 0.57476 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:03:50.697580 ops/training.py:65 2019-01-16 12:03:50.697506: step 12616, loss = 0.68594 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:03:51.660654 ops/training.py:65 2019-01-16 12:03:51.660591: step 12617, loss = 0.51889 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:03:52.624301 ops/training.py:65 2019-01-16 12:03:52.624235: step 12618, loss = 0.67027 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:03:53.587719 ops/training.py:65 2019-01-16 12:03:53.587653: step 12619, loss = 0.45587 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:03:54.549642 ops/training.py:65 2019-01-16 12:03:54.549559: step 12620, loss = 0.62707 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:03:55.512544 ops/training.py:65 2019-01-16 12:03:55.512470: step 12621, loss = 0.46222 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:03:56.477862 ops/training.py:65 2019-01-16 12:03:56.477792: step 12622, loss = 0.54003 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:03:57.441439 ops/training.py:65 2019-01-16 12:03:57.441373: step 12623, loss = 0.44973 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:03:58.404390 ops/training.py:65 2019-01-16 12:03:58.404324: step 12624, loss = 0.57589 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:03:59.366909 ops/training.py:65 2019-01-16 12:03:59.366842: step 12625, loss = 0.70672 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:04:00.330336 ops/training.py:65 2019-01-16 12:04:00.330269: step 12626, loss = 0.58500 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:04:01.294868 ops/training.py:65 2019-01-16 12:04:01.294774: step 12627, loss = 0.54264 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:04:02.257466 ops/training.py:65 2019-01-16 12:04:02.257408: step 12628, loss = 0.48148 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:04:03.220701 ops/training.py:65 2019-01-16 12:04:03.220638: step 12629, loss = 0.49523 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:04:04.183449 ops/training.py:65 2019-01-16 12:04:04.183380: step 12630, loss = 0.60300 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:04:05.145718 ops/training.py:65 2019-01-16 12:04:05.145650: step 12631, loss = 0.50571 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:04:06.108443 ops/training.py:65 2019-01-16 12:04:06.108374: step 12632, loss = 0.60028 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:04:07.071144 ops/training.py:65 2019-01-16 12:04:07.071076: step 12633, loss = 0.50839 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:04:08.033026 ops/training.py:65 2019-01-16 12:04:08.032963: step 12634, loss = 0.43285 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:04:08.997920 ops/training.py:65 2019-01-16 12:04:08.997851: step 12635, loss = 0.61469 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:04:09.959214 ops/training.py:65 2019-01-16 12:04:09.959163: step 12636, loss = 0.58427 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:04:10.923881 ops/training.py:65 2019-01-16 12:04:10.923822: step 12637, loss = 0.53139 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:04:11.888377 ops/training.py:65 2019-01-16 12:04:11.888330: step 12638, loss = 0.61295 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:04:12.851300 ops/training.py:65 2019-01-16 12:04:12.851243: step 12639, loss = 0.41426 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:04:13.815555 ops/training.py:65 2019-01-16 12:04:13.815482: step 12640, loss = 0.63586 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 12:04:14.778679 ops/training.py:65 2019-01-16 12:04:14.778628: step 12641, loss = 0.61518 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:04:15.741336 ops/training.py:65 2019-01-16 12:04:15.741289: step 12642, loss = 0.45447 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:04:16.703028 ops/training.py:65 2019-01-16 12:04:16.702978: step 12643, loss = 0.56532 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:04:17.665194 ops/training.py:65 2019-01-16 12:04:17.665140: step 12644, loss = 0.50433 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:04:18.626255 ops/training.py:65 2019-01-16 12:04:18.626203: step 12645, loss = 0.62091 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:04:19.589704 ops/training.py:65 2019-01-16 12:04:19.589655: step 12646, loss = 0.56543 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:04:20.551671 ops/training.py:65 2019-01-16 12:04:20.551620: step 12647, loss = 0.61040 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:04:21.517087 ops/training.py:65 2019-01-16 12:04:21.517040: step 12648, loss = 0.51320 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:04:22.481303 ops/training.py:65 2019-01-16 12:04:22.481248: step 12649, loss = 0.58529 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:04:23.443739 ops/training.py:65 2019-01-16 12:04:23.443691: step 12650, loss = 0.51988 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:04:24.405957 ops/training.py:65 2019-01-16 12:04:24.405905: step 12651, loss = 0.59758 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:04:25.368227 ops/training.py:65 2019-01-16 12:04:25.368178: step 12652, loss = 0.47594 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:04:26.328764 ops/training.py:65 2019-01-16 12:04:26.328711: step 12653, loss = 0.55086 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:04:27.290020 ops/training.py:65 2019-01-16 12:04:27.289964: step 12654, loss = 0.46288 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:04:28.252676 ops/training.py:65 2019-01-16 12:04:28.252618: step 12655, loss = 0.55535 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:04:29.213983 ops/training.py:65 2019-01-16 12:04:29.213920: step 12656, loss = 0.60704 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:04:30.173901 ops/training.py:65 2019-01-16 12:04:30.173852: step 12657, loss = 0.40849 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:04:31.133132 ops/training.py:65 2019-01-16 12:04:31.133069: step 12658, loss = 0.54875 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:04:32.093997 ops/training.py:65 2019-01-16 12:04:32.093932: step 12659, loss = 0.51649 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:04:33.057188 ops/training.py:65 2019-01-16 12:04:33.057133: step 12660, loss = 0.51565 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:04:34.021408 ops/training.py:65 2019-01-16 12:04:34.021328: step 12661, loss = 0.51435 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:04:34.983688 ops/training.py:65 2019-01-16 12:04:34.983638: step 12662, loss = 0.57063 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:04:35.945466 ops/training.py:65 2019-01-16 12:04:35.945414: step 12663, loss = 0.57640 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:04:36.909241 ops/training.py:65 2019-01-16 12:04:36.909188: step 12664, loss = 0.57210 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:04:37.873517 ops/training.py:65 2019-01-16 12:04:37.873466: step 12665, loss = 0.53031 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:04:38.837309 ops/training.py:65 2019-01-16 12:04:38.837264: step 12666, loss = 0.53744 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:04:39.802908 ops/training.py:65 2019-01-16 12:04:39.802847: step 12667, loss = 0.46360 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:04:40.766702 ops/training.py:65 2019-01-16 12:04:40.766640: step 12668, loss = 0.53675 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:04:41.730127 ops/training.py:65 2019-01-16 12:04:41.730068: step 12669, loss = 0.71261 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 12:04:42.692508 ops/training.py:65 2019-01-16 12:04:42.692450: step 12670, loss = 0.38370 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:04:43.654510 ops/training.py:65 2019-01-16 12:04:43.654449: step 12671, loss = 0.49726 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:04:44.615838 ops/training.py:65 2019-01-16 12:04:44.615776: step 12672, loss = 0.47053 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:04:45.581061 ops/training.py:65 2019-01-16 12:04:45.581003: step 12673, loss = 0.45975 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:04:46.545316 ops/training.py:65 2019-01-16 12:04:46.545258: step 12674, loss = 0.59914 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:04:47.508934 ops/training.py:65 2019-01-16 12:04:47.508871: step 12675, loss = 0.67544 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:04:48.470926 ops/training.py:65 2019-01-16 12:04:48.470862: step 12676, loss = 0.50450 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:04:49.431983 ops/training.py:65 2019-01-16 12:04:49.431911: step 12677, loss = 0.59268 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:04:50.393888 ops/training.py:65 2019-01-16 12:04:50.393843: step 12678, loss = 0.48245 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:04:51.357973 ops/training.py:65 2019-01-16 12:04:51.357933: step 12679, loss = 0.42223 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:04:52.321655 ops/training.py:65 2019-01-16 12:04:52.321599: step 12680, loss = 0.65629 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:04:53.285095 ops/training.py:65 2019-01-16 12:04:53.285044: step 12681, loss = 0.70648 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:04:54.246619 ops/training.py:65 2019-01-16 12:04:54.246546: step 12682, loss = 0.51709 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:04:55.208591 ops/training.py:65 2019-01-16 12:04:55.208530: step 12683, loss = 0.55062 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:04:56.169989 ops/training.py:65 2019-01-16 12:04:56.169915: step 12684, loss = 0.48972 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:04:57.133074 ops/training.py:65 2019-01-16 12:04:57.133021: step 12685, loss = 0.41727 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:04:58.097520 ops/training.py:65 2019-01-16 12:04:58.097470: step 12686, loss = 0.42668 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:04:59.059779 ops/training.py:65 2019-01-16 12:04:59.059726: step 12687, loss = 0.58635 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:05:00.022867 ops/training.py:65 2019-01-16 12:05:00.022797: step 12688, loss = 0.61061 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:05:00.985211 ops/training.py:65 2019-01-16 12:05:00.985166: step 12689, loss = 0.50581 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:05:01.945904 ops/training.py:65 2019-01-16 12:05:01.945844: step 12690, loss = 0.60577 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:05:02.906517 ops/training.py:65 2019-01-16 12:05:02.906455: step 12691, loss = 0.57090 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:05:03.867274 ops/training.py:65 2019-01-16 12:05:03.867184: step 12692, loss = 0.58161 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:05:04.832408 ops/training.py:65 2019-01-16 12:05:04.832362: step 12693, loss = 0.43491 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:05:05.795935 ops/training.py:65 2019-01-16 12:05:05.795884: step 12694, loss = 0.63372 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:05:06.759603 ops/training.py:65 2019-01-16 12:05:06.759560: step 12695, loss = 0.39738 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:05:07.721455 ops/training.py:65 2019-01-16 12:05:07.721398: step 12696, loss = 0.54016 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:05:08.684883 ops/training.py:65 2019-01-16 12:05:08.684836: step 12697, loss = 0.59454 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:05:09.647165 ops/training.py:65 2019-01-16 12:05:09.647106: step 12698, loss = 0.57890 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:05:10.609913 ops/training.py:65 2019-01-16 12:05:10.609850: step 12699, loss = 0.52500 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:05:11.574812 ops/training.py:65 2019-01-16 12:05:11.574755: step 12700, loss = 0.56981 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:05:12.539880 ops/training.py:65 2019-01-16 12:05:12.539824: step 12701, loss = 0.54051 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:05:13.503407 ops/training.py:65 2019-01-16 12:05:13.503328: step 12702, loss = 0.57388 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:05:14.464715 ops/training.py:65 2019-01-16 12:05:14.464654: step 12703, loss = 0.43527 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:05:15.426214 ops/training.py:65 2019-01-16 12:05:15.426155: step 12704, loss = 0.57182 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:05:16.388166 ops/training.py:65 2019-01-16 12:05:16.388107: step 12705, loss = 0.72883 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:05:17.352838 ops/training.py:65 2019-01-16 12:05:17.352781: step 12706, loss = 0.59010 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:05:18.315323 ops/training.py:65 2019-01-16 12:05:18.315258: step 12707, loss = 0.60428 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:05:19.276769 ops/training.py:65 2019-01-16 12:05:19.276721: step 12708, loss = 0.45722 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:05:20.237558 ops/training.py:65 2019-01-16 12:05:20.237487: step 12709, loss = 0.57273 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:05:21.198691 ops/training.py:65 2019-01-16 12:05:21.198611: step 12710, loss = 0.55520 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:05:22.162206 ops/training.py:65 2019-01-16 12:05:22.162153: step 12711, loss = 0.70263 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:05:23.126354 ops/training.py:65 2019-01-16 12:05:23.126284: step 12712, loss = 0.48822 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:05:24.088192 ops/training.py:65 2019-01-16 12:05:24.088121: step 12713, loss = 0.48992 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:05:25.051605 ops/training.py:65 2019-01-16 12:05:25.051532: step 12714, loss = 0.70714 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:05:26.015631 ops/training.py:65 2019-01-16 12:05:26.015568: step 12715, loss = 0.58848 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:05:26.978378 ops/training.py:65 2019-01-16 12:05:26.978327: step 12716, loss = 0.52709 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:05:27.941769 ops/training.py:65 2019-01-16 12:05:27.941720: step 12717, loss = 0.59148 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:05:28.903735 ops/training.py:65 2019-01-16 12:05:28.903686: step 12718, loss = 0.49455 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:05:29.865057 ops/training.py:65 2019-01-16 12:05:29.865000: step 12719, loss = 0.59849 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:05:30.825643 ops/training.py:65 2019-01-16 12:05:30.825570: step 12720, loss = 0.49451 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:05:31.787525 ops/training.py:65 2019-01-16 12:05:31.787460: step 12721, loss = 0.66623 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:05:32.749038 ops/training.py:65 2019-01-16 12:05:32.748970: step 12722, loss = 0.49939 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:05:33.708481 ops/training.py:65 2019-01-16 12:05:33.708416: step 12723, loss = 0.59287 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:05:34.667629 ops/training.py:65 2019-01-16 12:05:34.667565: step 12724, loss = 0.63681 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:05:35.628039 ops/training.py:65 2019-01-16 12:05:35.627973: step 12725, loss = 0.51232 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:05:36.588351 ops/training.py:65 2019-01-16 12:05:36.588303: step 12726, loss = 0.64755 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:05:37.549444 ops/training.py:65 2019-01-16 12:05:37.549378: step 12727, loss = 0.53865 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:05:38.510183 ops/training.py:65 2019-01-16 12:05:38.510115: step 12728, loss = 0.47167 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:05:39.475650 ops/training.py:65 2019-01-16 12:05:39.475599: step 12729, loss = 0.46405 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:05:40.437822 ops/training.py:65 2019-01-16 12:05:40.437768: step 12730, loss = 0.73479 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:05:41.399034 ops/training.py:65 2019-01-16 12:05:41.398981: step 12731, loss = 0.53382 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:05:42.360529 ops/training.py:65 2019-01-16 12:05:42.360472: step 12732, loss = 0.52517 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:05:43.326074 ops/training.py:65 2019-01-16 12:05:43.326004: step 12733, loss = 0.73596 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:05:44.289908 ops/training.py:65 2019-01-16 12:05:44.289839: step 12734, loss = 0.55800 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:05:45.252406 ops/training.py:65 2019-01-16 12:05:45.252353: step 12735, loss = 0.44549 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:05:46.214925 ops/training.py:65 2019-01-16 12:05:46.214857: step 12736, loss = 0.54016 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:05:47.176496 ops/training.py:65 2019-01-16 12:05:47.176440: step 12737, loss = 0.59053 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:05:48.138139 ops/training.py:65 2019-01-16 12:05:48.138070: step 12738, loss = 0.67240 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:05:49.100891 ops/training.py:65 2019-01-16 12:05:49.100848: step 12739, loss = 0.40981 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:05:50.065026 ops/training.py:65 2019-01-16 12:05:50.064974: step 12740, loss = 0.68634 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:05:51.030209 ops/training.py:65 2019-01-16 12:05:51.030160: step 12741, loss = 0.77979 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:05:51.992552 ops/training.py:65 2019-01-16 12:05:51.992496: step 12742, loss = 0.54533 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:05:52.953928 ops/training.py:65 2019-01-16 12:05:52.953880: step 12743, loss = 0.63985 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:05:53.915613 ops/training.py:65 2019-01-16 12:05:53.915552: step 12744, loss = 0.46460 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:05:54.880431 ops/training.py:65 2019-01-16 12:05:54.880363: step 12745, loss = 0.72109 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 12:05:55.843091 ops/training.py:65 2019-01-16 12:05:55.843024: step 12746, loss = 0.71039 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:05:56.808771 ops/training.py:65 2019-01-16 12:05:56.808723: step 12747, loss = 0.43436 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:05:57.772903 ops/training.py:65 2019-01-16 12:05:57.772853: step 12748, loss = 0.67043 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:05:58.736647 ops/training.py:65 2019-01-16 12:05:58.736599: step 12749, loss = 0.53804 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:05:59.698097 ops/training.py:65 2019-01-16 12:05:59.698038: step 12750, loss = 0.47297 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:06:00.658816 ops/training.py:65 2019-01-16 12:06:00.658747: step 12751, loss = 0.60412 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:06:01.619851 ops/training.py:65 2019-01-16 12:06:01.619797: step 12752, loss = 0.49616 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:06:02.581179 ops/training.py:65 2019-01-16 12:06:02.581127: step 12753, loss = 0.54154 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:06:03.542251 ops/training.py:65 2019-01-16 12:06:03.542199: step 12754, loss = 0.52030 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:06:04.503582 ops/training.py:65 2019-01-16 12:06:04.503536: step 12755, loss = 0.56212 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:06:05.467312 ops/training.py:65 2019-01-16 12:06:05.467259: step 12756, loss = 0.63021 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:06:06.429773 ops/training.py:65 2019-01-16 12:06:06.429729: step 12757, loss = 0.66879 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:06:07.393183 ops/training.py:65 2019-01-16 12:06:07.393123: step 12758, loss = 0.45205 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:06:08.354478 ops/training.py:65 2019-01-16 12:06:08.354423: step 12759, loss = 0.50165 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:06:09.318738 ops/training.py:65 2019-01-16 12:06:09.318670: step 12760, loss = 0.45460 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:06:10.281572 ops/training.py:65 2019-01-16 12:06:10.281519: step 12761, loss = 0.51944 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:06:11.244530 ops/training.py:65 2019-01-16 12:06:11.244475: step 12762, loss = 0.67923 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:06:12.208512 ops/training.py:65 2019-01-16 12:06:12.208463: step 12763, loss = 0.57510 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:06:13.171384 ops/training.py:65 2019-01-16 12:06:13.171333: step 12764, loss = 0.44667 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:06:14.133778 ops/training.py:65 2019-01-16 12:06:14.133728: step 12765, loss = 0.44544 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:06:15.093759 ops/training.py:65 2019-01-16 12:06:15.093704: step 12766, loss = 0.46679 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:06:16.058764 ops/training.py:65 2019-01-16 12:06:16.058716: step 12767, loss = 0.62579 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:06:17.023646 ops/training.py:65 2019-01-16 12:06:17.023600: step 12768, loss = 0.58690 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:06:17.985649 ops/training.py:65 2019-01-16 12:06:17.985598: step 12769, loss = 0.67334 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:06:18.948684 ops/training.py:65 2019-01-16 12:06:18.948623: step 12770, loss = 0.47166 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:06:19.911867 ops/training.py:65 2019-01-16 12:06:19.911813: step 12771, loss = 0.42810 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:06:20.874984 ops/training.py:65 2019-01-16 12:06:20.874915: step 12772, loss = 0.55492 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:06:21.836458 ops/training.py:65 2019-01-16 12:06:21.836390: step 12773, loss = 0.70700 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.40625
I0832 2019-01-16 12:06:22.800375 ops/training.py:65 2019-01-16 12:06:22.800310: step 12774, loss = 0.51431 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:06:23.762339 ops/training.py:65 2019-01-16 12:06:23.762274: step 12775, loss = 0.42348 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:06:24.724089 ops/training.py:65 2019-01-16 12:06:24.724039: step 12776, loss = 0.58872 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:06:25.684668 ops/training.py:65 2019-01-16 12:06:25.684616: step 12777, loss = 0.67887 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:06:26.646022 ops/training.py:65 2019-01-16 12:06:26.645975: step 12778, loss = 0.46394 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:06:27.608009 ops/training.py:65 2019-01-16 12:06:27.607960: step 12779, loss = 0.57422 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:06:28.569212 ops/training.py:65 2019-01-16 12:06:28.569158: step 12780, loss = 0.70910 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:06:29.531043 ops/training.py:65 2019-01-16 12:06:29.530990: step 12781, loss = 0.70155 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:06:30.492666 ops/training.py:65 2019-01-16 12:06:30.492600: step 12782, loss = 0.57899 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:06:31.455232 ops/training.py:65 2019-01-16 12:06:31.455178: step 12783, loss = 0.47954 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:06:32.416738 ops/training.py:65 2019-01-16 12:06:32.416671: step 12784, loss = 0.61545 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:06:33.381972 ops/training.py:65 2019-01-16 12:06:33.381906: step 12785, loss = 0.65476 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:06:34.345586 ops/training.py:65 2019-01-16 12:06:34.345515: step 12786, loss = 0.68990 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 12:06:35.310734 ops/training.py:65 2019-01-16 12:06:35.310663: step 12787, loss = 0.52887 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:06:36.275884 ops/training.py:65 2019-01-16 12:06:36.275831: step 12788, loss = 0.53366 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:06:37.236277 ops/training.py:65 2019-01-16 12:06:37.236231: step 12789, loss = 0.64098 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:06:38.198477 ops/training.py:65 2019-01-16 12:06:38.198428: step 12790, loss = 0.55606 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:06:39.160196 ops/training.py:65 2019-01-16 12:06:39.160127: step 12791, loss = 0.45146 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:06:40.121030 ops/training.py:65 2019-01-16 12:06:40.120975: step 12792, loss = 0.61542 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:06:41.082150 ops/training.py:65 2019-01-16 12:06:41.082097: step 12793, loss = 0.57750 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:06:42.046217 ops/training.py:65 2019-01-16 12:06:42.046167: step 12794, loss = 0.51098 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:06:43.008670 ops/training.py:65 2019-01-16 12:06:43.008616: step 12795, loss = 0.45750 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:06:43.971183 ops/training.py:65 2019-01-16 12:06:43.971095: step 12796, loss = 0.43370 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:06:44.934047 ops/training.py:65 2019-01-16 12:06:44.933976: step 12797, loss = 0.49003 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:06:45.898129 ops/training.py:65 2019-01-16 12:06:45.898077: step 12798, loss = 0.52417 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:06:46.862412 ops/training.py:65 2019-01-16 12:06:46.862367: step 12799, loss = 0.47453 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:06:47.826237 ops/training.py:65 2019-01-16 12:06:47.826187: step 12800, loss = 0.37715 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:06:48.787850 ops/training.py:65 2019-01-16 12:06:48.787798: step 12801, loss = 0.49977 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:06:49.749489 ops/training.py:65 2019-01-16 12:06:49.749439: step 12802, loss = 0.61848 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:06:50.710617 ops/training.py:65 2019-01-16 12:06:50.710567: step 12803, loss = 0.35912 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:06:51.671936 ops/training.py:65 2019-01-16 12:06:51.671888: step 12804, loss = 0.55289 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:06:52.633163 ops/training.py:65 2019-01-16 12:06:52.633108: step 12805, loss = 0.57684 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:06:53.595276 ops/training.py:65 2019-01-16 12:06:53.595229: step 12806, loss = 0.46715 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:06:54.556206 ops/training.py:65 2019-01-16 12:06:54.556157: step 12807, loss = 0.50345 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:06:55.517938 ops/training.py:65 2019-01-16 12:06:55.517889: step 12808, loss = 0.55047 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:06:56.478234 ops/training.py:65 2019-01-16 12:06:56.478186: step 12809, loss = 0.65355 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:06:57.439948 ops/training.py:65 2019-01-16 12:06:57.439900: step 12810, loss = 0.49608 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:06:58.401671 ops/training.py:65 2019-01-16 12:06:58.401619: step 12811, loss = 0.61575 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:06:59.363308 ops/training.py:65 2019-01-16 12:06:59.363243: step 12812, loss = 0.50318 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:07:00.324320 ops/training.py:65 2019-01-16 12:07:00.324263: step 12813, loss = 0.59625 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:07:01.285670 ops/training.py:65 2019-01-16 12:07:01.285607: step 12814, loss = 0.51739 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:07:02.246238 ops/training.py:65 2019-01-16 12:07:02.246192: step 12815, loss = 0.52148 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:07:03.206890 ops/training.py:65 2019-01-16 12:07:03.206811: step 12816, loss = 0.77081 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:07:04.167841 ops/training.py:65 2019-01-16 12:07:04.167779: step 12817, loss = 0.47167 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:07:05.130628 ops/training.py:65 2019-01-16 12:07:05.130567: step 12818, loss = 0.40347 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:07:06.092168 ops/training.py:65 2019-01-16 12:07:06.092084: step 12819, loss = 0.63856 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:07:07.052225 ops/training.py:65 2019-01-16 12:07:07.052169: step 12820, loss = 0.56571 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:07:08.014304 ops/training.py:65 2019-01-16 12:07:08.014262: step 12821, loss = 0.41151 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:07:08.977303 ops/training.py:65 2019-01-16 12:07:08.977239: step 12822, loss = 0.48301 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:07:09.939581 ops/training.py:65 2019-01-16 12:07:09.939526: step 12823, loss = 0.52075 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:07:10.900461 ops/training.py:65 2019-01-16 12:07:10.900396: step 12824, loss = 0.59067 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:07:11.861697 ops/training.py:65 2019-01-16 12:07:11.861648: step 12825, loss = 0.56967 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:07:12.821929 ops/training.py:65 2019-01-16 12:07:12.821870: step 12826, loss = 0.65971 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:07:13.786559 ops/training.py:65 2019-01-16 12:07:13.786507: step 12827, loss = 0.53746 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:07:14.747256 ops/training.py:65 2019-01-16 12:07:14.747200: step 12828, loss = 0.53362 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:07:15.708862 ops/training.py:65 2019-01-16 12:07:15.708797: step 12829, loss = 0.53176 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:07:16.670921 ops/training.py:65 2019-01-16 12:07:16.670868: step 12830, loss = 0.52089 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:07:17.632860 ops/training.py:65 2019-01-16 12:07:17.632807: step 12831, loss = 0.57365 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:07:18.594168 ops/training.py:65 2019-01-16 12:07:18.594113: step 12832, loss = 0.48379 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:07:19.556121 ops/training.py:65 2019-01-16 12:07:19.556074: step 12833, loss = 0.49662 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:07:20.520845 ops/training.py:65 2019-01-16 12:07:20.520795: step 12834, loss = 0.35009 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:07:21.485041 ops/training.py:65 2019-01-16 12:07:21.484990: step 12835, loss = 0.61014 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:07:22.448127 ops/training.py:65 2019-01-16 12:07:22.448063: step 12836, loss = 0.60680 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:07:23.409772 ops/training.py:65 2019-01-16 12:07:23.409703: step 12837, loss = 0.47204 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:07:24.372677 ops/training.py:65 2019-01-16 12:07:24.372608: step 12838, loss = 0.55151 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:07:25.336070 ops/training.py:65 2019-01-16 12:07:25.336017: step 12839, loss = 0.55456 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:07:26.297075 ops/training.py:65 2019-01-16 12:07:26.297000: step 12840, loss = 0.65461 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:07:27.258294 ops/training.py:65 2019-01-16 12:07:27.258238: step 12841, loss = 0.67829 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:07:28.219754 ops/training.py:65 2019-01-16 12:07:28.219692: step 12842, loss = 0.44676 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:07:29.180486 ops/training.py:65 2019-01-16 12:07:29.180422: step 12843, loss = 0.51224 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:07:30.141957 ops/training.py:65 2019-01-16 12:07:30.141887: step 12844, loss = 0.54336 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:07:31.106207 ops/training.py:65 2019-01-16 12:07:31.106155: step 12845, loss = 0.57860 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:07:32.069096 ops/training.py:65 2019-01-16 12:07:32.069022: step 12846, loss = 0.36171 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:07:33.031219 ops/training.py:65 2019-01-16 12:07:33.031164: step 12847, loss = 0.46998 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:07:33.996385 ops/training.py:65 2019-01-16 12:07:33.996327: step 12848, loss = 0.55429 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:07:34.959069 ops/training.py:65 2019-01-16 12:07:34.958999: step 12849, loss = 0.54934 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:07:35.921552 ops/training.py:65 2019-01-16 12:07:35.921481: step 12850, loss = 0.55650 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:07:36.883399 ops/training.py:65 2019-01-16 12:07:36.883346: step 12851, loss = 0.57334 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:07:37.843785 ops/training.py:65 2019-01-16 12:07:37.843716: step 12852, loss = 0.55997 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:07:38.806352 ops/training.py:65 2019-01-16 12:07:38.806286: step 12853, loss = 0.49650 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:07:39.772086 ops/training.py:65 2019-01-16 12:07:39.772035: step 12854, loss = 0.62403 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 12:07:40.736448 ops/training.py:65 2019-01-16 12:07:40.736397: step 12855, loss = 0.51605 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:07:41.699521 ops/training.py:65 2019-01-16 12:07:41.699474: step 12856, loss = 0.45821 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:07:42.661352 ops/training.py:65 2019-01-16 12:07:42.661289: step 12857, loss = 0.57447 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:07:43.622476 ops/training.py:65 2019-01-16 12:07:43.622425: step 12858, loss = 0.63121 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:07:44.584266 ops/training.py:65 2019-01-16 12:07:44.584194: step 12859, loss = 0.56918 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:07:45.546141 ops/training.py:65 2019-01-16 12:07:45.546075: step 12860, loss = 0.58423 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:07:46.507990 ops/training.py:65 2019-01-16 12:07:46.507924: step 12861, loss = 0.57513 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:07:47.468858 ops/training.py:65 2019-01-16 12:07:47.468786: step 12862, loss = 0.53456 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:07:48.429632 ops/training.py:65 2019-01-16 12:07:48.429564: step 12863, loss = 0.59356 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:07:49.393858 ops/training.py:65 2019-01-16 12:07:49.393794: step 12864, loss = 0.50288 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:07:50.355760 ops/training.py:65 2019-01-16 12:07:50.355694: step 12865, loss = 0.44690 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:07:51.320407 ops/training.py:65 2019-01-16 12:07:51.320336: step 12866, loss = 0.61938 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:07:52.281511 ops/training.py:65 2019-01-16 12:07:52.281444: step 12867, loss = 0.49030 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:07:53.243500 ops/training.py:65 2019-01-16 12:07:53.243455: step 12868, loss = 0.48812 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:07:54.204378 ops/training.py:65 2019-01-16 12:07:54.204330: step 12869, loss = 0.54288 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:07:55.166343 ops/training.py:65 2019-01-16 12:07:55.166294: step 12870, loss = 0.50268 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:07:56.127512 ops/training.py:65 2019-01-16 12:07:56.127460: step 12871, loss = 0.63000 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:07:57.088679 ops/training.py:65 2019-01-16 12:07:57.088630: step 12872, loss = 0.59017 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:07:58.051432 ops/training.py:65 2019-01-16 12:07:58.051383: step 12873, loss = 0.41562 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:07:59.013704 ops/training.py:65 2019-01-16 12:07:59.013655: step 12874, loss = 0.49679 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:07:59.976155 ops/training.py:65 2019-01-16 12:07:59.976101: step 12875, loss = 0.54220 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:08:00.937740 ops/training.py:65 2019-01-16 12:08:00.937692: step 12876, loss = 0.60717 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:08:01.899442 ops/training.py:65 2019-01-16 12:08:01.899398: step 12877, loss = 0.46319 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:08:02.860610 ops/training.py:65 2019-01-16 12:08:02.860559: step 12878, loss = 0.61044 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:08:03.822134 ops/training.py:65 2019-01-16 12:08:03.822080: step 12879, loss = 0.49560 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:08:04.784601 ops/training.py:65 2019-01-16 12:08:04.784543: step 12880, loss = 0.43754 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:08:05.746489 ops/training.py:65 2019-01-16 12:08:05.746418: step 12881, loss = 0.49960 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:08:06.708305 ops/training.py:65 2019-01-16 12:08:06.708250: step 12882, loss = 0.51480 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:08:07.670183 ops/training.py:65 2019-01-16 12:08:07.670110: step 12883, loss = 0.67596 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:08:08.631267 ops/training.py:65 2019-01-16 12:08:08.631195: step 12884, loss = 0.57840 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:08:09.592140 ops/training.py:65 2019-01-16 12:08:09.592086: step 12885, loss = 0.55906 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:08:10.553398 ops/training.py:65 2019-01-16 12:08:10.553342: step 12886, loss = 0.62049 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:08:11.516171 ops/training.py:65 2019-01-16 12:08:11.516115: step 12887, loss = 0.56246 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:08:12.479582 ops/training.py:65 2019-01-16 12:08:12.479533: step 12888, loss = 0.69220 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:08:13.442382 ops/training.py:65 2019-01-16 12:08:13.442326: step 12889, loss = 0.53892 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:08:14.406590 ops/training.py:65 2019-01-16 12:08:14.406537: step 12890, loss = 0.51830 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:08:15.369954 ops/training.py:65 2019-01-16 12:08:15.369878: step 12891, loss = 0.60039 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:08:16.333801 ops/training.py:65 2019-01-16 12:08:16.333751: step 12892, loss = 0.66106 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:08:17.296908 ops/training.py:65 2019-01-16 12:08:17.296858: step 12893, loss = 0.45098 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:08:18.259043 ops/training.py:65 2019-01-16 12:08:18.258994: step 12894, loss = 0.54415 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:08:19.221003 ops/training.py:65 2019-01-16 12:08:19.220955: step 12895, loss = 0.51359 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:08:20.183189 ops/training.py:65 2019-01-16 12:08:20.183120: step 12896, loss = 0.67035 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:08:21.144761 ops/training.py:65 2019-01-16 12:08:21.144694: step 12897, loss = 0.57040 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:08:22.105659 ops/training.py:65 2019-01-16 12:08:22.105605: step 12898, loss = 0.60738 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:08:23.066819 ops/training.py:65 2019-01-16 12:08:23.066748: step 12899, loss = 0.54419 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:08:24.028150 ops/training.py:65 2019-01-16 12:08:24.028102: step 12900, loss = 0.44688 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:08:24.989328 ops/training.py:65 2019-01-16 12:08:24.989238: step 12901, loss = 0.49801 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:08:25.950635 ops/training.py:65 2019-01-16 12:08:25.950570: step 12902, loss = 0.50885 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:08:26.909323 ops/training.py:65 2019-01-16 12:08:26.909273: step 12903, loss = 0.53342 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:08:27.872272 ops/training.py:65 2019-01-16 12:08:27.872226: step 12904, loss = 0.39423 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:08:28.835702 ops/training.py:65 2019-01-16 12:08:28.835653: step 12905, loss = 0.53606 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:08:29.798872 ops/training.py:65 2019-01-16 12:08:29.798819: step 12906, loss = 0.59454 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 12:08:30.760612 ops/training.py:65 2019-01-16 12:08:30.760560: step 12907, loss = 0.49616 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:08:31.722825 ops/training.py:65 2019-01-16 12:08:31.722779: step 12908, loss = 0.47825 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:08:32.684306 ops/training.py:65 2019-01-16 12:08:32.684240: step 12909, loss = 0.73246 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:08:33.646412 ops/training.py:65 2019-01-16 12:08:33.646345: step 12910, loss = 0.52333 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:08:34.608356 ops/training.py:65 2019-01-16 12:08:34.608310: step 12911, loss = 0.59146 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:08:35.578086 ops/training.py:65 2019-01-16 12:08:35.578016: step 12912, loss = 0.42691 (33.0 examples/sec; 0.969 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:08:36.542644 ops/training.py:65 2019-01-16 12:08:36.542592: step 12913, loss = 0.55000 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:08:37.506694 ops/training.py:65 2019-01-16 12:08:37.506641: step 12914, loss = 0.56999 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:08:38.467357 ops/training.py:65 2019-01-16 12:08:38.467292: step 12915, loss = 0.57758 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:08:39.429889 ops/training.py:65 2019-01-16 12:08:39.429823: step 12916, loss = 0.54842 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:08:40.391665 ops/training.py:65 2019-01-16 12:08:40.391611: step 12917, loss = 0.55643 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:08:41.352275 ops/training.py:65 2019-01-16 12:08:41.352220: step 12918, loss = 0.55586 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:08:42.315831 ops/training.py:65 2019-01-16 12:08:42.315781: step 12919, loss = 0.57358 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:08:43.278031 ops/training.py:65 2019-01-16 12:08:43.277979: step 12920, loss = 0.42173 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:08:44.240086 ops/training.py:65 2019-01-16 12:08:44.240034: step 12921, loss = 0.58327 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:08:45.201089 ops/training.py:65 2019-01-16 12:08:45.201038: step 12922, loss = 0.68135 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:08:46.162719 ops/training.py:65 2019-01-16 12:08:46.162672: step 12923, loss = 0.59668 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:08:47.123979 ops/training.py:65 2019-01-16 12:08:47.123931: step 12924, loss = 0.57085 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:08:48.085806 ops/training.py:65 2019-01-16 12:08:48.085754: step 12925, loss = 0.49177 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:08:49.047862 ops/training.py:65 2019-01-16 12:08:49.047813: step 12926, loss = 0.60257 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:08:50.010016 ops/training.py:65 2019-01-16 12:08:50.009960: step 12927, loss = 0.57882 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:08:50.970972 ops/training.py:65 2019-01-16 12:08:50.970914: step 12928, loss = 0.58719 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:08:51.933258 ops/training.py:65 2019-01-16 12:08:51.933197: step 12929, loss = 0.52578 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:08:52.894963 ops/training.py:65 2019-01-16 12:08:52.894896: step 12930, loss = 0.53846 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:08:53.856146 ops/training.py:65 2019-01-16 12:08:53.856098: step 12931, loss = 0.49808 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:08:54.817054 ops/training.py:65 2019-01-16 12:08:54.817002: step 12932, loss = 0.59993 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:08:55.779021 ops/training.py:65 2019-01-16 12:08:55.778951: step 12933, loss = 0.61478 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:08:56.740014 ops/training.py:65 2019-01-16 12:08:56.739937: step 12934, loss = 0.56515 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:08:57.701285 ops/training.py:65 2019-01-16 12:08:57.701236: step 12935, loss = 0.57912 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:08:58.662984 ops/training.py:65 2019-01-16 12:08:58.662929: step 12936, loss = 0.37691 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:08:59.623442 ops/training.py:65 2019-01-16 12:08:59.623387: step 12937, loss = 0.45030 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:09:00.587923 ops/training.py:65 2019-01-16 12:09:00.587871: step 12938, loss = 0.65403 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:09:01.551272 ops/training.py:65 2019-01-16 12:09:01.551223: step 12939, loss = 0.67422 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:09:02.514707 ops/training.py:65 2019-01-16 12:09:02.514656: step 12940, loss = 0.83722 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 12:09:03.476887 ops/training.py:65 2019-01-16 12:09:03.476835: step 12941, loss = 0.61855 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:09:04.438320 ops/training.py:65 2019-01-16 12:09:04.438269: step 12942, loss = 0.51457 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:09:05.399458 ops/training.py:65 2019-01-16 12:09:05.399408: step 12943, loss = 0.52435 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:09:06.362800 ops/training.py:65 2019-01-16 12:09:06.362725: step 12944, loss = 0.71790 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 12:09:07.327575 ops/training.py:65 2019-01-16 12:09:07.327508: step 12945, loss = 0.54292 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:09:08.292784 ops/training.py:65 2019-01-16 12:09:08.292740: step 12946, loss = 0.52388 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:09:09.255302 ops/training.py:65 2019-01-16 12:09:09.255238: step 12947, loss = 0.52121 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:09:10.217320 ops/training.py:65 2019-01-16 12:09:10.217271: step 12948, loss = 0.55308 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:09:11.177990 ops/training.py:65 2019-01-16 12:09:11.177935: step 12949, loss = 0.49967 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:09:12.139922 ops/training.py:65 2019-01-16 12:09:12.139865: step 12950, loss = 0.58917 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:09:13.104292 ops/training.py:65 2019-01-16 12:09:13.104221: step 12951, loss = 0.56774 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:09:14.068362 ops/training.py:65 2019-01-16 12:09:14.068297: step 12952, loss = 0.41391 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:09:15.030573 ops/training.py:65 2019-01-16 12:09:15.030522: step 12953, loss = 0.44551 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:09:15.993037 ops/training.py:65 2019-01-16 12:09:15.992990: step 12954, loss = 0.58355 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:09:16.953133 ops/training.py:65 2019-01-16 12:09:16.953087: step 12955, loss = 0.45561 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:09:17.914027 ops/training.py:65 2019-01-16 12:09:17.913973: step 12956, loss = 0.54592 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:09:18.875441 ops/training.py:65 2019-01-16 12:09:18.875389: step 12957, loss = 0.55325 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:09:19.836655 ops/training.py:65 2019-01-16 12:09:19.836607: step 12958, loss = 0.58848 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:09:20.798036 ops/training.py:65 2019-01-16 12:09:20.797986: step 12959, loss = 0.58991 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:09:21.758513 ops/training.py:65 2019-01-16 12:09:21.758466: step 12960, loss = 0.59900 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:09:22.723449 ops/training.py:65 2019-01-16 12:09:22.723393: step 12961, loss = 0.45810 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:09:23.687821 ops/training.py:65 2019-01-16 12:09:23.687773: step 12962, loss = 0.60197 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:09:24.650949 ops/training.py:65 2019-01-16 12:09:24.650896: step 12963, loss = 0.55437 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:09:25.611938 ops/training.py:65 2019-01-16 12:09:25.611871: step 12964, loss = 0.55342 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:09:26.574097 ops/training.py:65 2019-01-16 12:09:26.574028: step 12965, loss = 0.49566 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:09:27.536006 ops/training.py:65 2019-01-16 12:09:27.535942: step 12966, loss = 0.60375 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:09:28.497273 ops/training.py:65 2019-01-16 12:09:28.497210: step 12967, loss = 0.49855 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:09:29.458060 ops/training.py:65 2019-01-16 12:09:29.457993: step 12968, loss = 0.54855 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:09:30.418296 ops/training.py:65 2019-01-16 12:09:30.418227: step 12969, loss = 0.40174 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:09:31.380507 ops/training.py:65 2019-01-16 12:09:31.380441: step 12970, loss = 0.44003 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:09:32.342041 ops/training.py:65 2019-01-16 12:09:32.341990: step 12971, loss = 0.52071 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:09:33.303404 ops/training.py:65 2019-01-16 12:09:33.303348: step 12972, loss = 0.41528 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:09:34.268535 ops/training.py:65 2019-01-16 12:09:34.268476: step 12973, loss = 0.50958 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:09:35.229682 ops/training.py:65 2019-01-16 12:09:35.229625: step 12974, loss = 0.48087 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:09:36.190336 ops/training.py:65 2019-01-16 12:09:36.190278: step 12975, loss = 0.53432 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:09:37.150427 ops/training.py:65 2019-01-16 12:09:37.150383: step 12976, loss = 0.61651 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:09:38.111174 ops/training.py:65 2019-01-16 12:09:38.111117: step 12977, loss = 0.49395 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:09:39.071955 ops/training.py:65 2019-01-16 12:09:39.071907: step 12978, loss = 0.58823 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:09:40.034211 ops/training.py:65 2019-01-16 12:09:40.034139: step 12979, loss = 0.51025 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:09:40.995509 ops/training.py:65 2019-01-16 12:09:40.995436: step 12980, loss = 0.48622 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:09:41.957346 ops/training.py:65 2019-01-16 12:09:41.957271: step 12981, loss = 0.62143 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:09:42.918866 ops/training.py:65 2019-01-16 12:09:42.918813: step 12982, loss = 0.52596 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:09:43.882500 ops/training.py:65 2019-01-16 12:09:43.882441: step 12983, loss = 0.60096 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:09:44.845117 ops/training.py:65 2019-01-16 12:09:44.845065: step 12984, loss = 0.54772 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:09:45.807903 ops/training.py:65 2019-01-16 12:09:45.807851: step 12985, loss = 0.56666 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:09:46.768485 ops/training.py:65 2019-01-16 12:09:46.768443: step 12986, loss = 0.59400 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:09:47.734525 ops/training.py:65 2019-01-16 12:09:47.734476: step 12987, loss = 0.52282 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:09:48.697559 ops/training.py:65 2019-01-16 12:09:48.697502: step 12988, loss = 0.61972 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:09:49.662000 ops/training.py:65 2019-01-16 12:09:49.661953: step 12989, loss = 0.62350 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:09:50.625771 ops/training.py:65 2019-01-16 12:09:50.625723: step 12990, loss = 0.53205 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:09:51.589560 ops/training.py:65 2019-01-16 12:09:51.589507: step 12991, loss = 0.62155 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:09:52.554905 ops/training.py:65 2019-01-16 12:09:52.554859: step 12992, loss = 0.54548 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:09:53.518584 ops/training.py:65 2019-01-16 12:09:53.518536: step 12993, loss = 0.56072 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:09:54.480116 ops/training.py:65 2019-01-16 12:09:54.480064: step 12994, loss = 0.43243 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:09:55.443686 ops/training.py:65 2019-01-16 12:09:55.443636: step 12995, loss = 0.50626 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:09:56.406984 ops/training.py:65 2019-01-16 12:09:56.406931: step 12996, loss = 0.58536 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:09:57.369705 ops/training.py:65 2019-01-16 12:09:57.369638: step 12997, loss = 0.46624 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:09:58.332118 ops/training.py:65 2019-01-16 12:09:58.332051: step 12998, loss = 0.50288 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:09:59.294938 ops/training.py:65 2019-01-16 12:09:59.294883: step 12999, loss = 0.53576 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:10:00.257322 ops/training.py:65 2019-01-16 12:10:00.257269: step 13000, loss = 0.51239 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:10:01.220407 ops/training.py:65 2019-01-16 12:10:01.220359: step 13001, loss = 0.57374 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:10:02.185201 ops/training.py:65 2019-01-16 12:10:02.185153: step 13002, loss = 0.63836 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:10:03.149536 ops/training.py:65 2019-01-16 12:10:03.149483: step 13003, loss = 0.61499 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:10:04.111618 ops/training.py:65 2019-01-16 12:10:04.111557: step 13004, loss = 0.54787 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:10:05.072435 ops/training.py:65 2019-01-16 12:10:05.072377: step 13005, loss = 0.53746 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:10:06.035799 ops/training.py:65 2019-01-16 12:10:06.035746: step 13006, loss = 0.53924 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:10:06.997318 ops/training.py:65 2019-01-16 12:10:06.997258: step 13007, loss = 0.45969 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:10:07.958723 ops/training.py:65 2019-01-16 12:10:07.958666: step 13008, loss = 0.44248 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:10:08.923588 ops/training.py:65 2019-01-16 12:10:08.923521: step 13009, loss = 0.50924 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:10:09.886469 ops/training.py:65 2019-01-16 12:10:09.886417: step 13010, loss = 0.45580 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:10:10.849602 ops/training.py:65 2019-01-16 12:10:10.849549: step 13011, loss = 0.49394 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:10:11.810977 ops/training.py:65 2019-01-16 12:10:11.810922: step 13012, loss = 0.46588 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:10:12.772355 ops/training.py:65 2019-01-16 12:10:12.772302: step 13013, loss = 0.52044 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:10:13.734325 ops/training.py:65 2019-01-16 12:10:13.734273: step 13014, loss = 0.54251 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:10:14.696177 ops/training.py:65 2019-01-16 12:10:14.696123: step 13015, loss = 0.47181 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:10:15.657457 ops/training.py:65 2019-01-16 12:10:15.657404: step 13016, loss = 0.72873 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:10:16.619169 ops/training.py:65 2019-01-16 12:10:16.619118: step 13017, loss = 0.49352 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:10:17.580891 ops/training.py:65 2019-01-16 12:10:17.580842: step 13018, loss = 0.59929 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:10:18.543413 ops/training.py:65 2019-01-16 12:10:18.543353: step 13019, loss = 0.52414 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:10:19.505183 ops/training.py:65 2019-01-16 12:10:19.505136: step 13020, loss = 0.51065 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:10:20.466444 ops/training.py:65 2019-01-16 12:10:20.466394: step 13021, loss = 0.53260 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:10:21.430983 ops/training.py:65 2019-01-16 12:10:21.430931: step 13022, loss = 0.60261 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:10:22.394801 ops/training.py:65 2019-01-16 12:10:22.394751: step 13023, loss = 0.72142 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:10:23.358531 ops/training.py:65 2019-01-16 12:10:23.358463: step 13024, loss = 0.45799 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:10:24.320321 ops/training.py:65 2019-01-16 12:10:24.320252: step 13025, loss = 0.45914 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:10:25.282329 ops/training.py:65 2019-01-16 12:10:25.282257: step 13026, loss = 0.56860 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:10:26.245879 ops/training.py:65 2019-01-16 12:10:26.245810: step 13027, loss = 0.48834 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:10:27.209620 ops/training.py:65 2019-01-16 12:10:27.209575: step 13028, loss = 0.43522 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:10:28.172201 ops/training.py:65 2019-01-16 12:10:28.172150: step 13029, loss = 0.45319 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:10:29.132908 ops/training.py:65 2019-01-16 12:10:29.132859: step 13030, loss = 0.53557 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:10:30.094921 ops/training.py:65 2019-01-16 12:10:30.094864: step 13031, loss = 0.74353 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 12:10:31.056629 ops/training.py:65 2019-01-16 12:10:31.056561: step 13032, loss = 0.43990 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:10:32.017431 ops/training.py:65 2019-01-16 12:10:32.017362: step 13033, loss = 0.43784 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:10:32.979408 ops/training.py:65 2019-01-16 12:10:32.979335: step 13034, loss = 0.56701 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:10:33.940789 ops/training.py:65 2019-01-16 12:10:33.940732: step 13035, loss = 0.46501 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:10:34.902162 ops/training.py:65 2019-01-16 12:10:34.902098: step 13036, loss = 0.63914 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:10:35.863676 ops/training.py:65 2019-01-16 12:10:35.863605: step 13037, loss = 0.57890 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:10:36.824582 ops/training.py:65 2019-01-16 12:10:36.824527: step 13038, loss = 0.59147 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:10:37.787555 ops/training.py:65 2019-01-16 12:10:37.787483: step 13039, loss = 0.44727 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:10:38.749170 ops/training.py:65 2019-01-16 12:10:38.749109: step 13040, loss = 0.39669 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:10:39.709779 ops/training.py:65 2019-01-16 12:10:39.709727: step 13041, loss = 0.59263 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:10:40.672262 ops/training.py:65 2019-01-16 12:10:40.672207: step 13042, loss = 0.49517 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:10:41.634427 ops/training.py:65 2019-01-16 12:10:41.634374: step 13043, loss = 0.55490 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:10:42.595522 ops/training.py:65 2019-01-16 12:10:42.595474: step 13044, loss = 0.41466 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:10:43.559384 ops/training.py:65 2019-01-16 12:10:43.559335: step 13045, loss = 0.64869 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:10:44.522000 ops/training.py:65 2019-01-16 12:10:44.521951: step 13046, loss = 0.55508 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:10:45.486045 ops/training.py:65 2019-01-16 12:10:45.485994: step 13047, loss = 0.50080 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:10:46.448632 ops/training.py:65 2019-01-16 12:10:46.448583: step 13048, loss = 0.56348 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:10:47.410272 ops/training.py:65 2019-01-16 12:10:47.410222: step 13049, loss = 0.47019 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:10:48.370818 ops/training.py:65 2019-01-16 12:10:48.370764: step 13050, loss = 0.56251 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:10:49.331721 ops/training.py:65 2019-01-16 12:10:49.331650: step 13051, loss = 0.52730 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:10:50.293572 ops/training.py:65 2019-01-16 12:10:50.293502: step 13052, loss = 0.50725 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:10:51.254655 ops/training.py:65 2019-01-16 12:10:51.254586: step 13053, loss = 0.51408 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:10:52.215180 ops/training.py:65 2019-01-16 12:10:52.215129: step 13054, loss = 0.48646 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:10:53.175775 ops/training.py:65 2019-01-16 12:10:53.175711: step 13055, loss = 0.58479 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:10:54.136667 ops/training.py:65 2019-01-16 12:10:54.136619: step 13056, loss = 0.53280 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:10:55.098709 ops/training.py:65 2019-01-16 12:10:55.098660: step 13057, loss = 0.45764 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:10:56.059414 ops/training.py:65 2019-01-16 12:10:56.059361: step 13058, loss = 0.52263 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:10:57.020749 ops/training.py:65 2019-01-16 12:10:57.020692: step 13059, loss = 0.59122 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:10:57.982882 ops/training.py:65 2019-01-16 12:10:57.982814: step 13060, loss = 0.49963 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:10:58.944472 ops/training.py:65 2019-01-16 12:10:58.944416: step 13061, loss = 0.60349 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:10:59.909798 ops/training.py:65 2019-01-16 12:10:59.909729: step 13062, loss = 0.61744 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:11:00.872758 ops/training.py:65 2019-01-16 12:11:00.872690: step 13063, loss = 0.53550 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:11:01.835184 ops/training.py:65 2019-01-16 12:11:01.835132: step 13064, loss = 0.52094 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:11:02.796986 ops/training.py:65 2019-01-16 12:11:02.796915: step 13065, loss = 0.58511 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:11:03.758013 ops/training.py:65 2019-01-16 12:11:03.757947: step 13066, loss = 0.54864 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:11:04.718587 ops/training.py:65 2019-01-16 12:11:04.718535: step 13067, loss = 0.59194 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:11:05.678713 ops/training.py:65 2019-01-16 12:11:05.678663: step 13068, loss = 0.52477 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:11:06.639674 ops/training.py:65 2019-01-16 12:11:06.639625: step 13069, loss = 0.40302 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:11:07.600445 ops/training.py:65 2019-01-16 12:11:07.600390: step 13070, loss = 0.49669 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:11:08.562979 ops/training.py:65 2019-01-16 12:11:08.562934: step 13071, loss = 0.54917 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:11:09.527446 ops/training.py:65 2019-01-16 12:11:09.527378: step 13072, loss = 0.55292 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:11:10.489759 ops/training.py:65 2019-01-16 12:11:10.489704: step 13073, loss = 0.59322 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:11:11.452538 ops/training.py:65 2019-01-16 12:11:11.452466: step 13074, loss = 0.48648 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:11:12.416685 ops/training.py:65 2019-01-16 12:11:12.416615: step 13075, loss = 0.44873 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:11:13.379418 ops/training.py:65 2019-01-16 12:11:13.379352: step 13076, loss = 0.50983 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:11:14.341048 ops/training.py:65 2019-01-16 12:11:14.340994: step 13077, loss = 0.37331 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:11:15.301913 ops/training.py:65 2019-01-16 12:11:15.301842: step 13078, loss = 0.51684 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:11:16.262181 ops/training.py:65 2019-01-16 12:11:16.262134: step 13079, loss = 0.54186 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:11:17.224203 ops/training.py:65 2019-01-16 12:11:17.224156: step 13080, loss = 0.57269 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:11:18.184708 ops/training.py:65 2019-01-16 12:11:18.184653: step 13081, loss = 0.47774 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:11:19.146069 ops/training.py:65 2019-01-16 12:11:19.146017: step 13082, loss = 0.54306 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:11:20.106732 ops/training.py:65 2019-01-16 12:11:20.106662: step 13083, loss = 0.47580 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:11:21.066530 ops/training.py:65 2019-01-16 12:11:21.066469: step 13084, loss = 0.44298 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:11:22.028086 ops/training.py:65 2019-01-16 12:11:22.028040: step 13085, loss = 0.49396 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:11:22.987936 ops/training.py:65 2019-01-16 12:11:22.987879: step 13086, loss = 0.40771 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:11:23.946718 ops/training.py:65 2019-01-16 12:11:23.946652: step 13087, loss = 0.64682 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:11:24.907962 ops/training.py:65 2019-01-16 12:11:24.907875: step 13088, loss = 0.59715 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:11:25.869532 ops/training.py:65 2019-01-16 12:11:25.869482: step 13089, loss = 0.51933 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:11:26.830905 ops/training.py:65 2019-01-16 12:11:26.830853: step 13090, loss = 0.62158 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:11:27.791549 ops/training.py:65 2019-01-16 12:11:27.791499: step 13091, loss = 0.51621 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:11:28.756109 ops/training.py:65 2019-01-16 12:11:28.756059: step 13092, loss = 0.46811 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:11:29.717631 ops/training.py:65 2019-01-16 12:11:29.717580: step 13093, loss = 0.47858 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:11:30.679177 ops/training.py:65 2019-01-16 12:11:30.679127: step 13094, loss = 0.50279 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:11:31.640162 ops/training.py:65 2019-01-16 12:11:31.640115: step 13095, loss = 0.54199 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:11:32.600850 ops/training.py:65 2019-01-16 12:11:32.600797: step 13096, loss = 0.48513 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:11:33.561700 ops/training.py:65 2019-01-16 12:11:33.561648: step 13097, loss = 0.65457 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 12:11:34.524158 ops/training.py:65 2019-01-16 12:11:34.524095: step 13098, loss = 0.45655 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:11:35.488185 ops/training.py:65 2019-01-16 12:11:35.488116: step 13099, loss = 0.38110 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:11:36.451640 ops/training.py:65 2019-01-16 12:11:36.451571: step 13100, loss = 0.65330 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:11:37.414996 ops/training.py:65 2019-01-16 12:11:37.414950: step 13101, loss = 0.40572 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:11:38.376468 ops/training.py:65 2019-01-16 12:11:38.376416: step 13102, loss = 0.58920 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:11:39.337870 ops/training.py:65 2019-01-16 12:11:39.337803: step 13103, loss = 0.43393 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:11:40.299540 ops/training.py:65 2019-01-16 12:11:40.299473: step 13104, loss = 0.51645 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:11:41.259983 ops/training.py:65 2019-01-16 12:11:41.259910: step 13105, loss = 0.58957 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:11:42.221327 ops/training.py:65 2019-01-16 12:11:42.221272: step 13106, loss = 0.46377 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:11:43.184357 ops/training.py:65 2019-01-16 12:11:43.184289: step 13107, loss = 0.67254 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:11:44.146556 ops/training.py:65 2019-01-16 12:11:44.146497: step 13108, loss = 0.42009 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:11:45.107937 ops/training.py:65 2019-01-16 12:11:45.107866: step 13109, loss = 0.53616 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:11:46.070134 ops/training.py:65 2019-01-16 12:11:46.070082: step 13110, loss = 0.39393 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:11:47.031640 ops/training.py:65 2019-01-16 12:11:47.031595: step 13111, loss = 0.50208 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:11:47.993232 ops/training.py:65 2019-01-16 12:11:47.993180: step 13112, loss = 0.67189 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:11:48.955063 ops/training.py:65 2019-01-16 12:11:48.955003: step 13113, loss = 0.62012 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:11:49.918894 ops/training.py:65 2019-01-16 12:11:49.918837: step 13114, loss = 0.65966 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:11:50.882024 ops/training.py:65 2019-01-16 12:11:50.881962: step 13115, loss = 0.46241 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:11:51.846026 ops/training.py:65 2019-01-16 12:11:51.845977: step 13116, loss = 0.62651 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:11:52.807516 ops/training.py:65 2019-01-16 12:11:52.807461: step 13117, loss = 0.51975 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:11:53.769236 ops/training.py:65 2019-01-16 12:11:53.769177: step 13118, loss = 0.66277 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:11:54.732355 ops/training.py:65 2019-01-16 12:11:54.732291: step 13119, loss = 0.48980 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:11:55.694632 ops/training.py:65 2019-01-16 12:11:55.694580: step 13120, loss = 0.44572 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:11:56.656858 ops/training.py:65 2019-01-16 12:11:56.656806: step 13121, loss = 0.51838 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:11:57.619198 ops/training.py:65 2019-01-16 12:11:57.619152: step 13122, loss = 0.54956 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:11:58.581903 ops/training.py:65 2019-01-16 12:11:58.581850: step 13123, loss = 0.58773 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:11:59.545911 ops/training.py:65 2019-01-16 12:11:59.545856: step 13124, loss = 0.45854 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:12:00.510106 ops/training.py:65 2019-01-16 12:12:00.510052: step 13125, loss = 0.58198 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:12:01.473050 ops/training.py:65 2019-01-16 12:12:01.473004: step 13126, loss = 0.39232 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:12:02.434403 ops/training.py:65 2019-01-16 12:12:02.434355: step 13127, loss = 0.42990 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:12:03.396096 ops/training.py:65 2019-01-16 12:12:03.396030: step 13128, loss = 0.51837 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:12:04.357930 ops/training.py:65 2019-01-16 12:12:04.357877: step 13129, loss = 0.44313 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:12:05.319259 ops/training.py:65 2019-01-16 12:12:05.319201: step 13130, loss = 0.60544 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:12:06.281180 ops/training.py:65 2019-01-16 12:12:06.281127: step 13131, loss = 0.52142 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:12:07.241961 ops/training.py:65 2019-01-16 12:12:07.241917: step 13132, loss = 0.49184 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:12:08.202929 ops/training.py:65 2019-01-16 12:12:08.202877: step 13133, loss = 0.43970 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:12:09.164414 ops/training.py:65 2019-01-16 12:12:09.164369: step 13134, loss = 0.60126 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:12:10.125556 ops/training.py:65 2019-01-16 12:12:10.125497: step 13135, loss = 0.57091 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:12:11.086534 ops/training.py:65 2019-01-16 12:12:11.086472: step 13136, loss = 0.53267 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:12:12.047810 ops/training.py:65 2019-01-16 12:12:12.047748: step 13137, loss = 0.57300 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:12:13.009538 ops/training.py:65 2019-01-16 12:12:13.009479: step 13138, loss = 0.59557 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:12:13.970623 ops/training.py:65 2019-01-16 12:12:13.970562: step 13139, loss = 0.53201 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:12:14.931915 ops/training.py:65 2019-01-16 12:12:14.931850: step 13140, loss = 0.50568 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:12:15.893941 ops/training.py:65 2019-01-16 12:12:15.893873: step 13141, loss = 0.49321 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:12:16.855268 ops/training.py:65 2019-01-16 12:12:16.855220: step 13142, loss = 0.58584 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:12:17.817074 ops/training.py:65 2019-01-16 12:12:17.817024: step 13143, loss = 0.58777 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:12:18.778705 ops/training.py:65 2019-01-16 12:12:18.778652: step 13144, loss = 0.72498 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:12:19.743938 ops/training.py:65 2019-01-16 12:12:19.743884: step 13145, loss = 0.40968 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:12:20.707308 ops/training.py:65 2019-01-16 12:12:20.707255: step 13146, loss = 0.62742 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:12:21.670876 ops/training.py:65 2019-01-16 12:12:21.670807: step 13147, loss = 0.47723 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:12:22.632831 ops/training.py:65 2019-01-16 12:12:22.632765: step 13148, loss = 0.54871 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:12:23.594537 ops/training.py:65 2019-01-16 12:12:23.594483: step 13149, loss = 0.58566 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:12:24.555398 ops/training.py:65 2019-01-16 12:12:24.555347: step 13150, loss = 0.56986 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:12:25.516155 ops/training.py:65 2019-01-16 12:12:25.516099: step 13151, loss = 0.61327 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:12:26.477198 ops/training.py:65 2019-01-16 12:12:26.477123: step 13152, loss = 0.59396 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:12:27.438665 ops/training.py:65 2019-01-16 12:12:27.438617: step 13153, loss = 0.62286 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:12:28.399617 ops/training.py:65 2019-01-16 12:12:28.399567: step 13154, loss = 0.51861 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:12:29.360489 ops/training.py:65 2019-01-16 12:12:29.360437: step 13155, loss = 0.64405 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 12:12:30.322098 ops/training.py:65 2019-01-16 12:12:30.322045: step 13156, loss = 0.52918 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:12:31.283225 ops/training.py:65 2019-01-16 12:12:31.283178: step 13157, loss = 0.45328 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:12:32.247823 ops/training.py:65 2019-01-16 12:12:32.247774: step 13158, loss = 0.47522 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:12:33.211265 ops/training.py:65 2019-01-16 12:12:33.211213: step 13159, loss = 0.53479 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:12:34.174599 ops/training.py:65 2019-01-16 12:12:34.174550: step 13160, loss = 0.48921 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:12:35.135771 ops/training.py:65 2019-01-16 12:12:35.135723: step 13161, loss = 0.48946 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:12:36.098294 ops/training.py:65 2019-01-16 12:12:36.098236: step 13162, loss = 0.54160 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:12:37.060602 ops/training.py:65 2019-01-16 12:12:37.060550: step 13163, loss = 0.60447 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:12:38.022880 ops/training.py:65 2019-01-16 12:12:38.022809: step 13164, loss = 0.61696 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 12:12:38.984616 ops/training.py:65 2019-01-16 12:12:38.984563: step 13165, loss = 0.44947 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:12:39.949410 ops/training.py:65 2019-01-16 12:12:39.949338: step 13166, loss = 0.59145 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:12:40.911548 ops/training.py:65 2019-01-16 12:12:40.911494: step 13167, loss = 0.51834 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:12:41.875426 ops/training.py:65 2019-01-16 12:12:41.875378: step 13168, loss = 0.58234 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:12:42.839658 ops/training.py:65 2019-01-16 12:12:42.839587: step 13169, loss = 0.50851 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:12:43.802224 ops/training.py:65 2019-01-16 12:12:43.802161: step 13170, loss = 0.50325 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:12:44.764279 ops/training.py:65 2019-01-16 12:12:44.764226: step 13171, loss = 0.56701 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:12:45.728375 ops/training.py:65 2019-01-16 12:12:45.728320: step 13172, loss = 0.50076 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:12:46.691414 ops/training.py:65 2019-01-16 12:12:46.691368: step 13173, loss = 0.54473 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:12:47.654030 ops/training.py:65 2019-01-16 12:12:47.653983: step 13174, loss = 0.53448 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:12:48.615523 ops/training.py:65 2019-01-16 12:12:48.615461: step 13175, loss = 0.52863 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:12:49.577252 ops/training.py:65 2019-01-16 12:12:49.577188: step 13176, loss = 0.63151 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:12:50.538838 ops/training.py:65 2019-01-16 12:12:50.538779: step 13177, loss = 0.45522 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:12:51.499189 ops/training.py:65 2019-01-16 12:12:51.499145: step 13178, loss = 0.53127 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:12:52.458605 ops/training.py:65 2019-01-16 12:12:52.458556: step 13179, loss = 0.50581 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:12:53.417789 ops/training.py:65 2019-01-16 12:12:53.417736: step 13180, loss = 0.62940 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:12:54.380779 ops/training.py:65 2019-01-16 12:12:54.380715: step 13181, loss = 0.53026 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:12:55.344117 ops/training.py:65 2019-01-16 12:12:55.344056: step 13182, loss = 0.68458 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:12:56.307212 ops/training.py:65 2019-01-16 12:12:56.307147: step 13183, loss = 0.61868 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:12:57.269074 ops/training.py:65 2019-01-16 12:12:57.269014: step 13184, loss = 0.65995 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:12:58.231526 ops/training.py:65 2019-01-16 12:12:58.231467: step 13185, loss = 0.56900 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:12:59.193766 ops/training.py:65 2019-01-16 12:12:59.193707: step 13186, loss = 0.50458 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:13:00.155134 ops/training.py:65 2019-01-16 12:13:00.155076: step 13187, loss = 0.43733 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:13:01.115811 ops/training.py:65 2019-01-16 12:13:01.115753: step 13188, loss = 0.62716 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:13:02.077821 ops/training.py:65 2019-01-16 12:13:02.077764: step 13189, loss = 0.53461 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:13:03.039823 ops/training.py:65 2019-01-16 12:13:03.039756: step 13190, loss = 0.52148 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:13:04.001474 ops/training.py:65 2019-01-16 12:13:04.001424: step 13191, loss = 0.50220 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:13:04.962499 ops/training.py:65 2019-01-16 12:13:04.962453: step 13192, loss = 0.57050 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:13:05.923369 ops/training.py:65 2019-01-16 12:13:05.923319: step 13193, loss = 0.58909 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:13:06.885677 ops/training.py:65 2019-01-16 12:13:06.885633: step 13194, loss = 0.52953 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:13:07.847753 ops/training.py:65 2019-01-16 12:13:07.847698: step 13195, loss = 0.58142 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:13:08.808964 ops/training.py:65 2019-01-16 12:13:08.808916: step 13196, loss = 0.62948 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:13:09.769553 ops/training.py:65 2019-01-16 12:13:09.769485: step 13197, loss = 0.55994 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:13:10.730212 ops/training.py:65 2019-01-16 12:13:10.730145: step 13198, loss = 0.44033 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:13:11.691812 ops/training.py:65 2019-01-16 12:13:11.691753: step 13199, loss = 0.50029 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:13:12.656295 ops/training.py:65 2019-01-16 12:13:12.656247: step 13200, loss = 0.54674 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:13:13.619867 ops/training.py:65 2019-01-16 12:13:13.619819: step 13201, loss = 0.39281 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:13:14.583407 ops/training.py:65 2019-01-16 12:13:14.583354: step 13202, loss = 0.57798 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:13:15.545172 ops/training.py:65 2019-01-16 12:13:15.545110: step 13203, loss = 0.50562 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:13:16.506189 ops/training.py:65 2019-01-16 12:13:16.506122: step 13204, loss = 0.75990 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:13:17.467848 ops/training.py:65 2019-01-16 12:13:17.467778: step 13205, loss = 0.55078 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:13:18.429018 ops/training.py:65 2019-01-16 12:13:18.428949: step 13206, loss = 0.54752 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:13:19.391739 ops/training.py:65 2019-01-16 12:13:19.391686: step 13207, loss = 0.70138 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:13:20.353727 ops/training.py:65 2019-01-16 12:13:20.353678: step 13208, loss = 0.80646 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:13:21.316319 ops/training.py:65 2019-01-16 12:13:21.316249: step 13209, loss = 0.37308 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:13:22.278238 ops/training.py:65 2019-01-16 12:13:22.278181: step 13210, loss = 0.54143 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:13:23.240318 ops/training.py:65 2019-01-16 12:13:23.240265: step 13211, loss = 0.72197 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:13:24.202517 ops/training.py:65 2019-01-16 12:13:24.202465: step 13212, loss = 0.56298 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:13:25.166984 ops/training.py:65 2019-01-16 12:13:25.166934: step 13213, loss = 0.39012 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:13:26.130675 ops/training.py:65 2019-01-16 12:13:26.130623: step 13214, loss = 0.51236 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:13:27.091668 ops/training.py:65 2019-01-16 12:13:27.091611: step 13215, loss = 0.66267 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:13:28.052794 ops/training.py:65 2019-01-16 12:13:28.052744: step 13216, loss = 0.76582 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:13:29.013921 ops/training.py:65 2019-01-16 12:13:29.013860: step 13217, loss = 0.50714 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:13:29.975049 ops/training.py:65 2019-01-16 12:13:29.974982: step 13218, loss = 0.46470 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:13:30.935589 ops/training.py:65 2019-01-16 12:13:30.935525: step 13219, loss = 0.50413 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:13:31.895962 ops/training.py:65 2019-01-16 12:13:31.895918: step 13220, loss = 0.55541 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:13:32.859919 ops/training.py:65 2019-01-16 12:13:32.859861: step 13221, loss = 0.48935 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:13:33.823032 ops/training.py:65 2019-01-16 12:13:33.822972: step 13222, loss = 0.59184 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:13:34.786133 ops/training.py:65 2019-01-16 12:13:34.786053: step 13223, loss = 0.50451 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:13:35.747403 ops/training.py:65 2019-01-16 12:13:35.747354: step 13224, loss = 0.62906 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:13:36.708817 ops/training.py:65 2019-01-16 12:13:36.708768: step 13225, loss = 0.64304 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:13:37.670115 ops/training.py:65 2019-01-16 12:13:37.670060: step 13226, loss = 0.49923 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:13:38.631600 ops/training.py:65 2019-01-16 12:13:38.631547: step 13227, loss = 0.47484 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:13:39.592411 ops/training.py:65 2019-01-16 12:13:39.592342: step 13228, loss = 0.51807 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:13:40.557571 ops/training.py:65 2019-01-16 12:13:40.557518: step 13229, loss = 0.46527 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:13:41.521220 ops/training.py:65 2019-01-16 12:13:41.521149: step 13230, loss = 0.43676 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:13:42.485224 ops/training.py:65 2019-01-16 12:13:42.485156: step 13231, loss = 0.66462 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:13:43.447779 ops/training.py:65 2019-01-16 12:13:43.447712: step 13232, loss = 0.41755 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:13:44.409393 ops/training.py:65 2019-01-16 12:13:44.409339: step 13233, loss = 0.54573 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:13:45.370202 ops/training.py:65 2019-01-16 12:13:45.370139: step 13234, loss = 0.42090 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:13:46.334215 ops/training.py:65 2019-01-16 12:13:46.334152: step 13235, loss = 0.75773 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 12:13:47.297456 ops/training.py:65 2019-01-16 12:13:47.297398: step 13236, loss = 0.52216 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:13:48.260003 ops/training.py:65 2019-01-16 12:13:48.259923: step 13237, loss = 0.53283 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:13:49.221261 ops/training.py:65 2019-01-16 12:13:49.221192: step 13238, loss = 0.76352 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:13:50.181752 ops/training.py:65 2019-01-16 12:13:50.181704: step 13239, loss = 0.55260 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:13:51.145455 ops/training.py:65 2019-01-16 12:13:51.145408: step 13240, loss = 0.52462 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:13:52.108514 ops/training.py:65 2019-01-16 12:13:52.108469: step 13241, loss = 0.54734 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:13:53.072831 ops/training.py:65 2019-01-16 12:13:53.072780: step 13242, loss = 0.64641 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:13:54.034566 ops/training.py:65 2019-01-16 12:13:54.034518: step 13243, loss = 0.49014 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:13:54.997074 ops/training.py:65 2019-01-16 12:13:54.997024: step 13244, loss = 0.52374 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:13:55.958421 ops/training.py:65 2019-01-16 12:13:55.958371: step 13245, loss = 0.52868 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:13:56.920565 ops/training.py:65 2019-01-16 12:13:56.920512: step 13246, loss = 0.68002 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:13:57.881250 ops/training.py:65 2019-01-16 12:13:57.881199: step 13247, loss = 0.59860 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:13:58.846058 ops/training.py:65 2019-01-16 12:13:58.846010: step 13248, loss = 0.42977 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:13:59.809493 ops/training.py:65 2019-01-16 12:13:59.809439: step 13249, loss = 0.54550 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:14:00.772459 ops/training.py:65 2019-01-16 12:14:00.772406: step 13250, loss = 0.59316 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:14:01.734731 ops/training.py:65 2019-01-16 12:14:01.734667: step 13251, loss = 0.47699 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:14:02.696745 ops/training.py:65 2019-01-16 12:14:02.696677: step 13252, loss = 0.58659 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:14:03.658450 ops/training.py:65 2019-01-16 12:14:03.658384: step 13253, loss = 0.47464 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:14:04.619685 ops/training.py:65 2019-01-16 12:14:04.619615: step 13254, loss = 0.54388 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:14:05.580722 ops/training.py:65 2019-01-16 12:14:05.580658: step 13255, loss = 0.56863 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:14:06.541472 ops/training.py:65 2019-01-16 12:14:06.541423: step 13256, loss = 0.53086 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:14:07.504031 ops/training.py:65 2019-01-16 12:14:07.503983: step 13257, loss = 0.36659 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:14:08.465953 ops/training.py:65 2019-01-16 12:14:08.465902: step 13258, loss = 0.59077 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:14:09.427612 ops/training.py:65 2019-01-16 12:14:09.427542: step 13259, loss = 0.54876 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:14:10.388503 ops/training.py:65 2019-01-16 12:14:10.388446: step 13260, loss = 0.63852 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:14:11.351026 ops/training.py:65 2019-01-16 12:14:11.350974: step 13261, loss = 0.42746 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:14:12.313365 ops/training.py:65 2019-01-16 12:14:12.313314: step 13262, loss = 0.53792 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:14:13.275760 ops/training.py:65 2019-01-16 12:14:13.275711: step 13263, loss = 0.48737 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:14:14.237167 ops/training.py:65 2019-01-16 12:14:14.237118: step 13264, loss = 0.49604 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:14:15.198480 ops/training.py:65 2019-01-16 12:14:15.198429: step 13265, loss = 0.48572 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:14:16.160918 ops/training.py:65 2019-01-16 12:14:16.160871: step 13266, loss = 0.49331 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:14:17.122367 ops/training.py:65 2019-01-16 12:14:17.122296: step 13267, loss = 0.44272 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:14:18.083944 ops/training.py:65 2019-01-16 12:14:18.083870: step 13268, loss = 0.45352 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:14:19.049047 ops/training.py:65 2019-01-16 12:14:19.048999: step 13269, loss = 0.45420 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:14:20.013292 ops/training.py:65 2019-01-16 12:14:20.013245: step 13270, loss = 0.47880 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:14:20.977650 ops/training.py:65 2019-01-16 12:14:20.977582: step 13271, loss = 0.52769 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:14:21.940560 ops/training.py:65 2019-01-16 12:14:21.940507: step 13272, loss = 0.46235 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:14:22.902388 ops/training.py:65 2019-01-16 12:14:22.902315: step 13273, loss = 0.69283 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:14:23.863977 ops/training.py:65 2019-01-16 12:14:23.863929: step 13274, loss = 0.43639 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:14:24.826606 ops/training.py:65 2019-01-16 12:14:24.826557: step 13275, loss = 0.55278 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:14:25.789232 ops/training.py:65 2019-01-16 12:14:25.789181: step 13276, loss = 0.46641 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:14:26.751422 ops/training.py:65 2019-01-16 12:14:26.751368: step 13277, loss = 0.35472 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:14:27.712647 ops/training.py:65 2019-01-16 12:14:27.712599: step 13278, loss = 0.45452 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:14:28.674075 ops/training.py:65 2019-01-16 12:14:28.674022: step 13279, loss = 0.48563 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:14:29.635418 ops/training.py:65 2019-01-16 12:14:29.635368: step 13280, loss = 0.51002 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:14:30.596778 ops/training.py:65 2019-01-16 12:14:30.596726: step 13281, loss = 0.52415 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:14:31.557534 ops/training.py:65 2019-01-16 12:14:31.557482: step 13282, loss = 0.53894 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:14:32.518253 ops/training.py:65 2019-01-16 12:14:32.518199: step 13283, loss = 0.49323 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:14:33.480533 ops/training.py:65 2019-01-16 12:14:33.480480: step 13284, loss = 0.58405 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:14:34.442677 ops/training.py:65 2019-01-16 12:14:34.442623: step 13285, loss = 0.46823 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:14:35.406320 ops/training.py:65 2019-01-16 12:14:35.406268: step 13286, loss = 0.51712 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:14:36.369853 ops/training.py:65 2019-01-16 12:14:36.369801: step 13287, loss = 0.47526 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:14:37.332363 ops/training.py:65 2019-01-16 12:14:37.332311: step 13288, loss = 0.61271 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:14:38.298020 ops/training.py:65 2019-01-16 12:14:38.297948: step 13289, loss = 0.43976 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:14:39.261633 ops/training.py:65 2019-01-16 12:14:39.261577: step 13290, loss = 0.76247 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:14:40.224733 ops/training.py:65 2019-01-16 12:14:40.224678: step 13291, loss = 0.47864 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:14:41.188835 ops/training.py:65 2019-01-16 12:14:41.188776: step 13292, loss = 0.61280 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:14:42.150596 ops/training.py:65 2019-01-16 12:14:42.150526: step 13293, loss = 0.61618 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:14:43.111905 ops/training.py:65 2019-01-16 12:14:43.111846: step 13294, loss = 0.44018 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:14:44.074034 ops/training.py:65 2019-01-16 12:14:44.073983: step 13295, loss = 0.37629 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:14:45.036213 ops/training.py:65 2019-01-16 12:14:45.036159: step 13296, loss = 0.50763 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:14:45.997406 ops/training.py:65 2019-01-16 12:14:45.997351: step 13297, loss = 0.55580 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:14:46.959188 ops/training.py:65 2019-01-16 12:14:46.959135: step 13298, loss = 0.50052 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:14:47.920565 ops/training.py:65 2019-01-16 12:14:47.920510: step 13299, loss = 0.48911 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:14:48.882111 ops/training.py:65 2019-01-16 12:14:48.882059: step 13300, loss = 0.54398 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:14:49.843193 ops/training.py:65 2019-01-16 12:14:49.843122: step 13301, loss = 0.49892 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:14:50.807705 ops/training.py:65 2019-01-16 12:14:50.807656: step 13302, loss = 0.57447 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:14:51.768963 ops/training.py:65 2019-01-16 12:14:51.768908: step 13303, loss = 0.58551 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:14:52.729498 ops/training.py:65 2019-01-16 12:14:52.729426: step 13304, loss = 0.57208 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:14:53.691313 ops/training.py:65 2019-01-16 12:14:53.691270: step 13305, loss = 0.57480 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:14:54.652719 ops/training.py:65 2019-01-16 12:14:54.652653: step 13306, loss = 0.61800 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:14:55.614389 ops/training.py:65 2019-01-16 12:14:55.614340: step 13307, loss = 0.46515 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:14:56.580375 ops/training.py:65 2019-01-16 12:14:56.580327: step 13308, loss = 0.84559 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:14:57.544204 ops/training.py:65 2019-01-16 12:14:57.544156: step 13309, loss = 0.58370 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:14:58.507252 ops/training.py:65 2019-01-16 12:14:58.507199: step 13310, loss = 0.59985 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:14:59.469420 ops/training.py:65 2019-01-16 12:14:59.469366: step 13311, loss = 0.62967 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:15:00.433193 ops/training.py:65 2019-01-16 12:15:00.433139: step 13312, loss = 0.62340 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:15:01.395480 ops/training.py:65 2019-01-16 12:15:01.395431: step 13313, loss = 0.49394 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:15:02.361695 ops/training.py:65 2019-01-16 12:15:02.361649: step 13314, loss = 0.65581 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:15:03.325457 ops/training.py:65 2019-01-16 12:15:03.325404: step 13315, loss = 0.63358 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:15:04.288036 ops/training.py:65 2019-01-16 12:15:04.287986: step 13316, loss = 0.68351 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:15:05.249703 ops/training.py:65 2019-01-16 12:15:05.249633: step 13317, loss = 0.63119 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:15:06.211359 ops/training.py:65 2019-01-16 12:15:06.211289: step 13318, loss = 0.55294 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:15:07.172470 ops/training.py:65 2019-01-16 12:15:07.172417: step 13319, loss = 0.62935 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:15:08.133599 ops/training.py:65 2019-01-16 12:15:08.133534: step 13320, loss = 0.61396 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:15:09.095329 ops/training.py:65 2019-01-16 12:15:09.095284: step 13321, loss = 0.54773 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:15:10.057431 ops/training.py:65 2019-01-16 12:15:10.057371: step 13322, loss = 0.48448 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:15:11.019114 ops/training.py:65 2019-01-16 12:15:11.019051: step 13323, loss = 0.49854 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:15:11.981044 ops/training.py:65 2019-01-16 12:15:11.980986: step 13324, loss = 0.52834 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:15:12.943623 ops/training.py:65 2019-01-16 12:15:12.943569: step 13325, loss = 0.68181 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:15:13.906036 ops/training.py:65 2019-01-16 12:15:13.905975: step 13326, loss = 0.46385 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:15:14.867875 ops/training.py:65 2019-01-16 12:15:14.867817: step 13327, loss = 0.49383 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:15:15.830412 ops/training.py:65 2019-01-16 12:15:15.830351: step 13328, loss = 0.57436 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:15:16.794436 ops/training.py:65 2019-01-16 12:15:16.794379: step 13329, loss = 0.52119 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:15:17.759711 ops/training.py:65 2019-01-16 12:15:17.759664: step 13330, loss = 0.59967 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:15:18.724555 ops/training.py:65 2019-01-16 12:15:18.724497: step 13331, loss = 0.65742 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:15:19.689118 ops/training.py:65 2019-01-16 12:15:19.689061: step 13332, loss = 0.49594 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:15:20.654024 ops/training.py:65 2019-01-16 12:15:20.653963: step 13333, loss = 0.52269 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:15:21.615975 ops/training.py:65 2019-01-16 12:15:21.615909: step 13334, loss = 0.64747 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:15:22.577598 ops/training.py:65 2019-01-16 12:15:22.577542: step 13335, loss = 0.41158 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:15:23.540283 ops/training.py:65 2019-01-16 12:15:23.540223: step 13336, loss = 0.61763 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:15:24.503732 ops/training.py:65 2019-01-16 12:15:24.503673: step 13337, loss = 0.52802 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:15:25.465662 ops/training.py:65 2019-01-16 12:15:25.465608: step 13338, loss = 0.46378 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:15:26.430361 ops/training.py:65 2019-01-16 12:15:26.430301: step 13339, loss = 0.62901 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:15:27.394425 ops/training.py:65 2019-01-16 12:15:27.394368: step 13340, loss = 0.58829 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:15:28.358163 ops/training.py:65 2019-01-16 12:15:28.358112: step 13341, loss = 0.46463 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:15:29.319955 ops/training.py:65 2019-01-16 12:15:29.319900: step 13342, loss = 0.49055 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:15:30.282286 ops/training.py:65 2019-01-16 12:15:30.282217: step 13343, loss = 0.43469 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:15:31.243714 ops/training.py:65 2019-01-16 12:15:31.243641: step 13344, loss = 0.49187 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:15:32.204001 ops/training.py:65 2019-01-16 12:15:32.203944: step 13345, loss = 0.53205 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:15:33.168499 ops/training.py:65 2019-01-16 12:15:33.168439: step 13346, loss = 0.50631 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:15:34.132055 ops/training.py:65 2019-01-16 12:15:34.131994: step 13347, loss = 0.50125 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:15:35.095016 ops/training.py:65 2019-01-16 12:15:35.094956: step 13348, loss = 0.50455 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:15:36.057862 ops/training.py:65 2019-01-16 12:15:36.057810: step 13349, loss = 0.52584 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:15:37.022261 ops/training.py:65 2019-01-16 12:15:37.022220: step 13350, loss = 0.48791 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:15:37.987816 ops/training.py:65 2019-01-16 12:15:37.987761: step 13351, loss = 0.52297 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:15:38.950821 ops/training.py:65 2019-01-16 12:15:38.950778: step 13352, loss = 0.54460 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:15:39.913761 ops/training.py:65 2019-01-16 12:15:39.913699: step 13353, loss = 0.41979 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:15:40.878042 ops/training.py:65 2019-01-16 12:15:40.877972: step 13354, loss = 0.43681 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:15:41.839774 ops/training.py:65 2019-01-16 12:15:41.839715: step 13355, loss = 0.54651 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:15:42.801838 ops/training.py:65 2019-01-16 12:15:42.801772: step 13356, loss = 0.54490 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:15:43.764164 ops/training.py:65 2019-01-16 12:15:43.764095: step 13357, loss = 0.60009 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:15:44.728268 ops/training.py:65 2019-01-16 12:15:44.728217: step 13358, loss = 0.58818 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:15:45.690531 ops/training.py:65 2019-01-16 12:15:45.690480: step 13359, loss = 0.42542 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:15:46.652174 ops/training.py:65 2019-01-16 12:15:46.652124: step 13360, loss = 0.63721 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:15:47.613001 ops/training.py:65 2019-01-16 12:15:47.612955: step 13361, loss = 0.50043 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:15:48.573955 ops/training.py:65 2019-01-16 12:15:48.573900: step 13362, loss = 0.48545 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:15:49.534650 ops/training.py:65 2019-01-16 12:15:49.534604: step 13363, loss = 0.60979 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:15:50.496131 ops/training.py:65 2019-01-16 12:15:50.496072: step 13364, loss = 0.40438 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:15:51.458571 ops/training.py:65 2019-01-16 12:15:51.458507: step 13365, loss = 0.46141 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:15:52.420307 ops/training.py:65 2019-01-16 12:15:52.420262: step 13366, loss = 0.40642 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:15:53.382970 ops/training.py:65 2019-01-16 12:15:53.382908: step 13367, loss = 0.63262 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:15:54.347883 ops/training.py:65 2019-01-16 12:15:54.347833: step 13368, loss = 0.47954 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:15:55.309964 ops/training.py:65 2019-01-16 12:15:55.309908: step 13369, loss = 0.42408 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:15:56.274025 ops/training.py:65 2019-01-16 12:15:56.273966: step 13370, loss = 0.59682 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:15:57.237189 ops/training.py:65 2019-01-16 12:15:57.237142: step 13371, loss = 0.51399 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:15:58.200321 ops/training.py:65 2019-01-16 12:15:58.200269: step 13372, loss = 0.49974 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:15:59.163367 ops/training.py:65 2019-01-16 12:15:59.163310: step 13373, loss = 0.46479 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:16:00.126265 ops/training.py:65 2019-01-16 12:16:00.126210: step 13374, loss = 0.48650 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:16:01.088867 ops/training.py:65 2019-01-16 12:16:01.088817: step 13375, loss = 0.52064 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:16:02.051329 ops/training.py:65 2019-01-16 12:16:02.051276: step 13376, loss = 0.46668 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:16:03.016467 ops/training.py:65 2019-01-16 12:16:03.016407: step 13377, loss = 0.66446 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:16:03.981445 ops/training.py:65 2019-01-16 12:16:03.981377: step 13378, loss = 0.51986 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:16:04.945694 ops/training.py:65 2019-01-16 12:16:04.945645: step 13379, loss = 0.69056 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:16:05.907962 ops/training.py:65 2019-01-16 12:16:05.907910: step 13380, loss = 0.46944 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:16:06.870620 ops/training.py:65 2019-01-16 12:16:06.870567: step 13381, loss = 0.41487 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:16:07.832987 ops/training.py:65 2019-01-16 12:16:07.832931: step 13382, loss = 0.49480 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:16:08.795459 ops/training.py:65 2019-01-16 12:16:08.795403: step 13383, loss = 0.47750 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:16:09.758810 ops/training.py:65 2019-01-16 12:16:09.758739: step 13384, loss = 0.47782 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:16:10.721356 ops/training.py:65 2019-01-16 12:16:10.721302: step 13385, loss = 0.54915 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:16:11.686517 ops/training.py:65 2019-01-16 12:16:11.686466: step 13386, loss = 0.55107 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:16:12.650039 ops/training.py:65 2019-01-16 12:16:12.649988: step 13387, loss = 0.51502 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:16:13.613403 ops/training.py:65 2019-01-16 12:16:13.613345: step 13388, loss = 0.54089 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:16:14.574776 ops/training.py:65 2019-01-16 12:16:14.574712: step 13389, loss = 0.54179 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:16:15.538302 ops/training.py:65 2019-01-16 12:16:15.538235: step 13390, loss = 0.49282 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:16:16.498500 ops/training.py:65 2019-01-16 12:16:16.498429: step 13391, loss = 0.46539 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:16:17.459328 ops/training.py:65 2019-01-16 12:16:17.459267: step 13392, loss = 0.57274 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:16:18.420629 ops/training.py:65 2019-01-16 12:16:18.420566: step 13393, loss = 0.43848 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:16:19.383818 ops/training.py:65 2019-01-16 12:16:19.383751: step 13394, loss = 0.54300 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:16:20.346406 ops/training.py:65 2019-01-16 12:16:20.346361: step 13395, loss = 0.56822 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:16:21.309060 ops/training.py:65 2019-01-16 12:16:21.309008: step 13396, loss = 0.45175 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:16:22.270823 ops/training.py:65 2019-01-16 12:16:22.270766: step 13397, loss = 0.52101 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:16:23.232490 ops/training.py:65 2019-01-16 12:16:23.232439: step 13398, loss = 0.52968 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:16:24.196393 ops/training.py:65 2019-01-16 12:16:24.196336: step 13399, loss = 0.56549 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:16:25.158108 ops/training.py:65 2019-01-16 12:16:25.158048: step 13400, loss = 0.54021 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:16:26.121089 ops/training.py:65 2019-01-16 12:16:26.121028: step 13401, loss = 0.53556 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:16:27.085104 ops/training.py:65 2019-01-16 12:16:27.085047: step 13402, loss = 0.57122 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:16:28.048815 ops/training.py:65 2019-01-16 12:16:28.048756: step 13403, loss = 0.52001 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:16:29.012981 ops/training.py:65 2019-01-16 12:16:29.012913: step 13404, loss = 0.35007 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:16:29.975048 ops/training.py:65 2019-01-16 12:16:29.974999: step 13405, loss = 0.43364 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:16:30.936977 ops/training.py:65 2019-01-16 12:16:30.936925: step 13406, loss = 0.47630 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:16:31.901404 ops/training.py:65 2019-01-16 12:16:31.901343: step 13407, loss = 0.49937 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:16:32.863454 ops/training.py:65 2019-01-16 12:16:32.863393: step 13408, loss = 0.39498 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:16:33.824655 ops/training.py:65 2019-01-16 12:16:33.824594: step 13409, loss = 0.45970 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:16:34.788180 ops/training.py:65 2019-01-16 12:16:34.788121: step 13410, loss = 0.60260 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:16:35.751198 ops/training.py:65 2019-01-16 12:16:35.751141: step 13411, loss = 0.62275 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:16:36.714842 ops/training.py:65 2019-01-16 12:16:36.714780: step 13412, loss = 0.38518 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:16:37.677491 ops/training.py:65 2019-01-16 12:16:37.677444: step 13413, loss = 0.56907 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:16:38.639682 ops/training.py:65 2019-01-16 12:16:38.639626: step 13414, loss = 0.37552 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:16:39.602593 ops/training.py:65 2019-01-16 12:16:39.602540: step 13415, loss = 0.47211 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:16:40.565252 ops/training.py:65 2019-01-16 12:16:40.565191: step 13416, loss = 0.51208 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:16:41.528021 ops/training.py:65 2019-01-16 12:16:41.527959: step 13417, loss = 0.45899 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:16:42.491417 ops/training.py:65 2019-01-16 12:16:42.491360: step 13418, loss = 0.54521 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:16:43.452895 ops/training.py:65 2019-01-16 12:16:43.452834: step 13419, loss = 0.46011 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:16:44.415166 ops/training.py:65 2019-01-16 12:16:44.415101: step 13420, loss = 0.47872 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:16:45.377148 ops/training.py:65 2019-01-16 12:16:45.377092: step 13421, loss = 0.58563 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:16:46.338314 ops/training.py:65 2019-01-16 12:16:46.338270: step 13422, loss = 0.52352 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:16:47.299952 ops/training.py:65 2019-01-16 12:16:47.299882: step 13423, loss = 0.47162 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:16:48.262745 ops/training.py:65 2019-01-16 12:16:48.262687: step 13424, loss = 0.45047 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:16:49.224615 ops/training.py:65 2019-01-16 12:16:49.224561: step 13425, loss = 0.69904 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:16:50.186155 ops/training.py:65 2019-01-16 12:16:50.186102: step 13426, loss = 0.57796 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:16:51.146423 ops/training.py:65 2019-01-16 12:16:51.146352: step 13427, loss = 0.47880 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:16:52.110418 ops/training.py:65 2019-01-16 12:16:52.110356: step 13428, loss = 0.46087 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:16:53.074844 ops/training.py:65 2019-01-16 12:16:53.074777: step 13429, loss = 0.46819 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:16:54.039169 ops/training.py:65 2019-01-16 12:16:54.039116: step 13430, loss = 0.49158 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:16:55.002238 ops/training.py:65 2019-01-16 12:16:55.002180: step 13431, loss = 0.50625 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:16:55.963651 ops/training.py:65 2019-01-16 12:16:55.963589: step 13432, loss = 0.53964 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:16:56.925855 ops/training.py:65 2019-01-16 12:16:56.925789: step 13433, loss = 0.51256 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:16:57.888339 ops/training.py:65 2019-01-16 12:16:57.888286: step 13434, loss = 0.49564 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:16:58.849351 ops/training.py:65 2019-01-16 12:16:58.849305: step 13435, loss = 0.44135 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:16:59.809698 ops/training.py:65 2019-01-16 12:16:59.809634: step 13436, loss = 0.47348 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:17:00.770002 ops/training.py:65 2019-01-16 12:17:00.769940: step 13437, loss = 0.54296 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:17:01.732796 ops/training.py:65 2019-01-16 12:17:01.732745: step 13438, loss = 0.62843 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:17:02.696042 ops/training.py:65 2019-01-16 12:17:02.695979: step 13439, loss = 0.52849 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:17:03.658525 ops/training.py:65 2019-01-16 12:17:03.658479: step 13440, loss = 0.46553 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:17:04.621755 ops/training.py:65 2019-01-16 12:17:04.621708: step 13441, loss = 0.54828 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:17:05.582823 ops/training.py:65 2019-01-16 12:17:05.582762: step 13442, loss = 0.41077 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:17:06.545041 ops/training.py:65 2019-01-16 12:17:06.544979: step 13443, loss = 0.49428 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:17:07.506262 ops/training.py:65 2019-01-16 12:17:07.506203: step 13444, loss = 0.57493 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:17:08.467306 ops/training.py:65 2019-01-16 12:17:08.467245: step 13445, loss = 0.56755 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:17:09.428407 ops/training.py:65 2019-01-16 12:17:09.428360: step 13446, loss = 0.51409 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:17:10.390383 ops/training.py:65 2019-01-16 12:17:10.390317: step 13447, loss = 0.58310 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:17:11.351932 ops/training.py:65 2019-01-16 12:17:11.351866: step 13448, loss = 0.50941 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:17:12.315742 ops/training.py:65 2019-01-16 12:17:12.315684: step 13449, loss = 0.61014 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:17:13.279051 ops/training.py:65 2019-01-16 12:17:13.278991: step 13450, loss = 0.47173 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:17:14.240156 ops/training.py:65 2019-01-16 12:17:14.240093: step 13451, loss = 0.40217 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:17:15.204120 ops/training.py:65 2019-01-16 12:17:15.204059: step 13452, loss = 0.46145 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:17:16.168436 ops/training.py:65 2019-01-16 12:17:16.168376: step 13453, loss = 0.61144 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:17:17.131358 ops/training.py:65 2019-01-16 12:17:17.131307: step 13454, loss = 0.49918 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:17:18.092242 ops/training.py:65 2019-01-16 12:17:18.092171: step 13455, loss = 0.41885 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:17:19.053563 ops/training.py:65 2019-01-16 12:17:19.053503: step 13456, loss = 0.53140 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:17:20.015468 ops/training.py:65 2019-01-16 12:17:20.015404: step 13457, loss = 0.58742 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:17:20.977730 ops/training.py:65 2019-01-16 12:17:20.977669: step 13458, loss = 0.58388 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:17:21.941734 ops/training.py:65 2019-01-16 12:17:21.941676: step 13459, loss = 0.55114 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:17:22.906331 ops/training.py:65 2019-01-16 12:17:22.906272: step 13460, loss = 0.63176 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:17:23.869160 ops/training.py:65 2019-01-16 12:17:23.869100: step 13461, loss = 0.69878 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:17:24.831051 ops/training.py:65 2019-01-16 12:17:24.830991: step 13462, loss = 0.47876 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:17:25.795443 ops/training.py:65 2019-01-16 12:17:25.795383: step 13463, loss = 0.40602 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:17:26.759378 ops/training.py:65 2019-01-16 12:17:26.759315: step 13464, loss = 0.66133 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:17:27.724158 ops/training.py:65 2019-01-16 12:17:27.724101: step 13465, loss = 0.43814 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:17:28.685675 ops/training.py:65 2019-01-16 12:17:28.685616: step 13466, loss = 0.54820 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:17:29.646392 ops/training.py:65 2019-01-16 12:17:29.646322: step 13467, loss = 0.46489 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:17:30.607899 ops/training.py:65 2019-01-16 12:17:30.607831: step 13468, loss = 0.50038 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:17:31.569013 ops/training.py:65 2019-01-16 12:17:31.568944: step 13469, loss = 0.56985 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:17:32.534088 ops/training.py:65 2019-01-16 12:17:32.534017: step 13470, loss = 0.53164 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:17:33.498235 ops/training.py:65 2019-01-16 12:17:33.498179: step 13471, loss = 0.46898 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:17:34.461602 ops/training.py:65 2019-01-16 12:17:34.461553: step 13472, loss = 0.62094 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:17:35.424342 ops/training.py:65 2019-01-16 12:17:35.424291: step 13473, loss = 0.68479 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:17:36.385726 ops/training.py:65 2019-01-16 12:17:36.385677: step 13474, loss = 0.58613 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:17:37.346355 ops/training.py:65 2019-01-16 12:17:37.346305: step 13475, loss = 0.65079 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:17:38.307433 ops/training.py:65 2019-01-16 12:17:38.307383: step 13476, loss = 0.46986 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:17:39.268652 ops/training.py:65 2019-01-16 12:17:39.268601: step 13477, loss = 0.49298 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:17:40.230354 ops/training.py:65 2019-01-16 12:17:40.230298: step 13478, loss = 0.67660 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:17:41.194064 ops/training.py:65 2019-01-16 12:17:41.194012: step 13479, loss = 0.54546 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:17:42.157030 ops/training.py:65 2019-01-16 12:17:42.156983: step 13480, loss = 0.68217 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:17:43.120390 ops/training.py:65 2019-01-16 12:17:43.120340: step 13481, loss = 0.61386 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:17:44.081914 ops/training.py:65 2019-01-16 12:17:44.081864: step 13482, loss = 0.55078 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:17:45.044818 ops/training.py:65 2019-01-16 12:17:45.044761: step 13483, loss = 0.47768 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:17:46.006526 ops/training.py:65 2019-01-16 12:17:46.006475: step 13484, loss = 0.59942 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:17:46.968630 ops/training.py:65 2019-01-16 12:17:46.968563: step 13485, loss = 0.48224 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:17:47.933306 ops/training.py:65 2019-01-16 12:17:47.933233: step 13486, loss = 0.58002 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:17:48.895962 ops/training.py:65 2019-01-16 12:17:48.895901: step 13487, loss = 0.68619 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:17:49.857192 ops/training.py:65 2019-01-16 12:17:49.857136: step 13488, loss = 0.48869 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:17:50.818812 ops/training.py:65 2019-01-16 12:17:50.818745: step 13489, loss = 0.49198 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:17:51.779673 ops/training.py:65 2019-01-16 12:17:51.779599: step 13490, loss = 0.42531 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:17:52.742065 ops/training.py:65 2019-01-16 12:17:52.742002: step 13491, loss = 0.50502 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:17:53.703554 ops/training.py:65 2019-01-16 12:17:53.703483: step 13492, loss = 0.61518 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:17:54.664416 ops/training.py:65 2019-01-16 12:17:54.664352: step 13493, loss = 0.62215 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:17:55.625480 ops/training.py:65 2019-01-16 12:17:55.625430: step 13494, loss = 0.40952 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:17:56.586004 ops/training.py:65 2019-01-16 12:17:56.585952: step 13495, loss = 0.59855 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:17:57.546520 ops/training.py:65 2019-01-16 12:17:57.546471: step 13496, loss = 0.48711 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:17:58.508834 ops/training.py:65 2019-01-16 12:17:58.508781: step 13497, loss = 0.51818 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:17:59.470167 ops/training.py:65 2019-01-16 12:17:59.470101: step 13498, loss = 0.38056 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:18:00.431771 ops/training.py:65 2019-01-16 12:18:00.431698: step 13499, loss = 0.57856 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:18:01.392947 ops/training.py:65 2019-01-16 12:18:01.392895: step 13500, loss = 0.47669 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:18:02.354758 ops/training.py:65 2019-01-16 12:18:02.354705: step 13501, loss = 0.54625 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:18:03.316203 ops/training.py:65 2019-01-16 12:18:03.316150: step 13502, loss = 0.45946 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:18:04.277549 ops/training.py:65 2019-01-16 12:18:04.277493: step 13503, loss = 0.65927 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:18:05.238097 ops/training.py:65 2019-01-16 12:18:05.238036: step 13504, loss = 0.56069 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:18:06.197296 ops/training.py:65 2019-01-16 12:18:06.197249: step 13505, loss = 0.53247 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:18:07.157521 ops/training.py:65 2019-01-16 12:18:07.157461: step 13506, loss = 0.54648 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:18:08.119899 ops/training.py:65 2019-01-16 12:18:08.119848: step 13507, loss = 0.43570 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:18:09.083117 ops/training.py:65 2019-01-16 12:18:09.083067: step 13508, loss = 0.54122 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:18:10.045400 ops/training.py:65 2019-01-16 12:18:10.045334: step 13509, loss = 0.55691 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:18:11.005449 ops/training.py:65 2019-01-16 12:18:11.005378: step 13510, loss = 0.65159 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:18:11.967453 ops/training.py:65 2019-01-16 12:18:11.967406: step 13511, loss = 0.73667 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 12:18:12.928168 ops/training.py:65 2019-01-16 12:18:12.928117: step 13512, loss = 0.67665 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:18:13.888896 ops/training.py:65 2019-01-16 12:18:13.888841: step 13513, loss = 0.63143 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:18:14.849480 ops/training.py:65 2019-01-16 12:18:14.849422: step 13514, loss = 0.52087 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:18:15.810779 ops/training.py:65 2019-01-16 12:18:15.810734: step 13515, loss = 0.48758 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:18:16.771924 ops/training.py:65 2019-01-16 12:18:16.771871: step 13516, loss = 0.46854 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:18:17.735616 ops/training.py:65 2019-01-16 12:18:17.735565: step 13517, loss = 0.50509 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:18:18.699268 ops/training.py:65 2019-01-16 12:18:18.699216: step 13518, loss = 0.50205 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:18:19.663041 ops/training.py:65 2019-01-16 12:18:19.662991: step 13519, loss = 0.44346 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:18:20.624182 ops/training.py:65 2019-01-16 12:18:20.624128: step 13520, loss = 0.47294 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:18:21.585324 ops/training.py:65 2019-01-16 12:18:21.585276: step 13521, loss = 0.57540 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:18:22.546040 ops/training.py:65 2019-01-16 12:18:22.545974: step 13522, loss = 0.65318 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:18:23.506844 ops/training.py:65 2019-01-16 12:18:23.506795: step 13523, loss = 0.51064 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:18:24.471820 ops/training.py:65 2019-01-16 12:18:24.471768: step 13524, loss = 0.48355 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:18:25.434838 ops/training.py:65 2019-01-16 12:18:25.434781: step 13525, loss = 0.47034 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:18:26.398006 ops/training.py:65 2019-01-16 12:18:26.397941: step 13526, loss = 0.57433 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:18:27.359671 ops/training.py:65 2019-01-16 12:18:27.359623: step 13527, loss = 0.55096 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:18:28.320970 ops/training.py:65 2019-01-16 12:18:28.320921: step 13528, loss = 0.53443 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:18:29.282919 ops/training.py:65 2019-01-16 12:18:29.282871: step 13529, loss = 0.63944 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:18:30.243251 ops/training.py:65 2019-01-16 12:18:30.243183: step 13530, loss = 0.51597 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:18:31.206881 ops/training.py:65 2019-01-16 12:18:31.206826: step 13531, loss = 0.49897 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:18:32.170296 ops/training.py:65 2019-01-16 12:18:32.170225: step 13532, loss = 0.49096 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:18:33.132552 ops/training.py:65 2019-01-16 12:18:33.132479: step 13533, loss = 0.40845 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:18:34.095204 ops/training.py:65 2019-01-16 12:18:34.095150: step 13534, loss = 0.53976 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:18:35.057076 ops/training.py:65 2019-01-16 12:18:35.057025: step 13535, loss = 0.56874 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:18:36.017637 ops/training.py:65 2019-01-16 12:18:36.017586: step 13536, loss = 0.56011 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:18:36.978101 ops/training.py:65 2019-01-16 12:18:36.978051: step 13537, loss = 0.57970 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:18:37.939476 ops/training.py:65 2019-01-16 12:18:37.939425: step 13538, loss = 0.77137 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:18:38.900173 ops/training.py:65 2019-01-16 12:18:38.900121: step 13539, loss = 0.46363 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:18:39.861856 ops/training.py:65 2019-01-16 12:18:39.861790: step 13540, loss = 0.46025 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:18:40.823595 ops/training.py:65 2019-01-16 12:18:40.823527: step 13541, loss = 0.66498 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:18:41.784119 ops/training.py:65 2019-01-16 12:18:41.784049: step 13542, loss = 0.45403 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:18:42.743886 ops/training.py:65 2019-01-16 12:18:42.743805: step 13543, loss = 0.62683 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:18:43.703968 ops/training.py:65 2019-01-16 12:18:43.703898: step 13544, loss = 0.41205 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:18:44.664973 ops/training.py:65 2019-01-16 12:18:44.664910: step 13545, loss = 0.59795 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:18:45.625667 ops/training.py:65 2019-01-16 12:18:45.625601: step 13546, loss = 0.46998 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:18:46.585262 ops/training.py:65 2019-01-16 12:18:46.585198: step 13547, loss = 0.58489 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:18:47.545793 ops/training.py:65 2019-01-16 12:18:47.545727: step 13548, loss = 0.65590 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:18:48.507190 ops/training.py:65 2019-01-16 12:18:48.507139: step 13549, loss = 0.62671 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:18:49.469728 ops/training.py:65 2019-01-16 12:18:49.469688: step 13550, loss = 0.64092 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:18:50.434268 ops/training.py:65 2019-01-16 12:18:50.434211: step 13551, loss = 0.60165 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:18:51.397137 ops/training.py:65 2019-01-16 12:18:51.397082: step 13552, loss = 0.48055 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:18:52.362505 ops/training.py:65 2019-01-16 12:18:52.362432: step 13553, loss = 0.47281 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:18:53.325466 ops/training.py:65 2019-01-16 12:18:53.325401: step 13554, loss = 0.47767 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:18:54.288190 ops/training.py:65 2019-01-16 12:18:54.288122: step 13555, loss = 0.60721 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:18:55.249754 ops/training.py:65 2019-01-16 12:18:55.249684: step 13556, loss = 0.73491 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:18:56.211287 ops/training.py:65 2019-01-16 12:18:56.211215: step 13557, loss = 0.66908 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:18:57.175634 ops/training.py:65 2019-01-16 12:18:57.175586: step 13558, loss = 0.46968 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:18:58.137974 ops/training.py:65 2019-01-16 12:18:58.137924: step 13559, loss = 0.47794 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:18:59.100474 ops/training.py:65 2019-01-16 12:18:59.100421: step 13560, loss = 0.47337 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:19:00.064576 ops/training.py:65 2019-01-16 12:19:00.064505: step 13561, loss = 0.55511 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:19:01.027381 ops/training.py:65 2019-01-16 12:19:01.027332: step 13562, loss = 0.49249 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:19:01.989386 ops/training.py:65 2019-01-16 12:19:01.989332: step 13563, loss = 0.73323 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:19:02.954196 ops/training.py:65 2019-01-16 12:19:02.954128: step 13564, loss = 0.58324 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:19:03.917318 ops/training.py:65 2019-01-16 12:19:03.917248: step 13565, loss = 0.53771 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:19:04.879428 ops/training.py:65 2019-01-16 12:19:04.879378: step 13566, loss = 0.44657 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:19:05.840864 ops/training.py:65 2019-01-16 12:19:05.840812: step 13567, loss = 0.55555 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:19:06.803145 ops/training.py:65 2019-01-16 12:19:06.803092: step 13568, loss = 0.65182 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:19:07.765458 ops/training.py:65 2019-01-16 12:19:07.765407: step 13569, loss = 0.56174 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:19:08.726309 ops/training.py:65 2019-01-16 12:19:08.726249: step 13570, loss = 0.59126 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:19:09.687389 ops/training.py:65 2019-01-16 12:19:09.687322: step 13571, loss = 0.50070 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:19:10.649056 ops/training.py:65 2019-01-16 12:19:10.649008: step 13572, loss = 0.54288 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:19:11.612285 ops/training.py:65 2019-01-16 12:19:11.612220: step 13573, loss = 0.52239 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:19:12.574769 ops/training.py:65 2019-01-16 12:19:12.574708: step 13574, loss = 0.51263 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:19:13.536302 ops/training.py:65 2019-01-16 12:19:13.536215: step 13575, loss = 0.55217 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:19:14.497462 ops/training.py:65 2019-01-16 12:19:14.497385: step 13576, loss = 0.62599 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:19:15.458982 ops/training.py:65 2019-01-16 12:19:15.458927: step 13577, loss = 0.70975 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:19:16.421027 ops/training.py:65 2019-01-16 12:19:16.420979: step 13578, loss = 0.55971 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:19:17.383537 ops/training.py:65 2019-01-16 12:19:17.383482: step 13579, loss = 0.64576 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:19:18.349132 ops/training.py:65 2019-01-16 12:19:18.349075: step 13580, loss = 0.46922 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:19:19.313172 ops/training.py:65 2019-01-16 12:19:19.313107: step 13581, loss = 0.34264 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:19:20.277265 ops/training.py:65 2019-01-16 12:19:20.277210: step 13582, loss = 0.50454 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:19:21.237638 ops/training.py:65 2019-01-16 12:19:21.237588: step 13583, loss = 0.60363 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:19:22.197813 ops/training.py:65 2019-01-16 12:19:22.197742: step 13584, loss = 0.45489 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:19:23.157706 ops/training.py:65 2019-01-16 12:19:23.157655: step 13585, loss = 0.63370 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:19:24.121816 ops/training.py:65 2019-01-16 12:19:24.121768: step 13586, loss = 0.51264 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:19:25.085430 ops/training.py:65 2019-01-16 12:19:25.085358: step 13587, loss = 0.47078 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:19:26.048794 ops/training.py:65 2019-01-16 12:19:26.048722: step 13588, loss = 0.46333 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:19:27.010219 ops/training.py:65 2019-01-16 12:19:27.010174: step 13589, loss = 0.54916 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:19:27.972137 ops/training.py:65 2019-01-16 12:19:27.972089: step 13590, loss = 0.37882 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:19:28.934259 ops/training.py:65 2019-01-16 12:19:28.934210: step 13591, loss = 0.49108 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:19:29.896436 ops/training.py:65 2019-01-16 12:19:29.896383: step 13592, loss = 0.36289 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:19:30.859117 ops/training.py:65 2019-01-16 12:19:30.859068: step 13593, loss = 0.48274 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:19:31.821592 ops/training.py:65 2019-01-16 12:19:31.821540: step 13594, loss = 0.51060 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:19:32.783832 ops/training.py:65 2019-01-16 12:19:32.783781: step 13595, loss = 0.44724 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:19:33.745379 ops/training.py:65 2019-01-16 12:19:33.745326: step 13596, loss = 0.55374 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:19:34.707411 ops/training.py:65 2019-01-16 12:19:34.707362: step 13597, loss = 0.50918 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:19:35.669506 ops/training.py:65 2019-01-16 12:19:35.669455: step 13598, loss = 0.41543 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:19:36.629871 ops/training.py:65 2019-01-16 12:19:36.629816: step 13599, loss = 0.64248 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:19:37.594781 ops/training.py:65 2019-01-16 12:19:37.594726: step 13600, loss = 0.39778 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:19:38.556671 ops/training.py:65 2019-01-16 12:19:38.556621: step 13601, loss = 0.62645 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:19:39.522087 ops/training.py:65 2019-01-16 12:19:39.522036: step 13602, loss = 0.59608 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:19:40.484901 ops/training.py:65 2019-01-16 12:19:40.484835: step 13603, loss = 0.42592 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:19:41.449328 ops/training.py:65 2019-01-16 12:19:41.449266: step 13604, loss = 0.54219 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:19:42.412470 ops/training.py:65 2019-01-16 12:19:42.412413: step 13605, loss = 0.46962 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:19:43.375894 ops/training.py:65 2019-01-16 12:19:43.375825: step 13606, loss = 0.55831 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:19:44.339488 ops/training.py:65 2019-01-16 12:19:44.339436: step 13607, loss = 0.45056 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:19:45.302831 ops/training.py:65 2019-01-16 12:19:45.302760: step 13608, loss = 0.50552 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:19:46.265099 ops/training.py:65 2019-01-16 12:19:46.265049: step 13609, loss = 0.56662 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:19:47.231213 ops/training.py:65 2019-01-16 12:19:47.231159: step 13610, loss = 0.53685 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:19:48.195559 ops/training.py:65 2019-01-16 12:19:48.195508: step 13611, loss = 0.48200 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:19:49.158710 ops/training.py:65 2019-01-16 12:19:49.158656: step 13612, loss = 0.57799 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:19:50.121292 ops/training.py:65 2019-01-16 12:19:50.121240: step 13613, loss = 0.57953 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:19:51.085951 ops/training.py:65 2019-01-16 12:19:51.085898: step 13614, loss = 0.48074 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:19:52.049042 ops/training.py:65 2019-01-16 12:19:52.048991: step 13615, loss = 0.45810 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:19:53.011834 ops/training.py:65 2019-01-16 12:19:53.011788: step 13616, loss = 0.46013 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:19:53.974619 ops/training.py:65 2019-01-16 12:19:53.974567: step 13617, loss = 0.44667 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:19:54.936335 ops/training.py:65 2019-01-16 12:19:54.936282: step 13618, loss = 0.50516 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:19:55.898037 ops/training.py:65 2019-01-16 12:19:55.897965: step 13619, loss = 0.48024 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:19:56.859313 ops/training.py:65 2019-01-16 12:19:56.859250: step 13620, loss = 0.51412 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:19:57.820700 ops/training.py:65 2019-01-16 12:19:57.820630: step 13621, loss = 0.43401 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:19:58.786153 ops/training.py:65 2019-01-16 12:19:58.786102: step 13622, loss = 0.54294 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:19:59.750528 ops/training.py:65 2019-01-16 12:19:59.750475: step 13623, loss = 0.40026 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:20:00.713779 ops/training.py:65 2019-01-16 12:20:00.713733: step 13624, loss = 0.41050 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:20:01.674797 ops/training.py:65 2019-01-16 12:20:01.674745: step 13625, loss = 0.54775 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:20:02.636577 ops/training.py:65 2019-01-16 12:20:02.636505: step 13626, loss = 0.57714 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:20:03.597586 ops/training.py:65 2019-01-16 12:20:03.597512: step 13627, loss = 0.54022 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:20:04.562434 ops/training.py:65 2019-01-16 12:20:04.562382: step 13628, loss = 0.41614 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:20:05.524644 ops/training.py:65 2019-01-16 12:20:05.524589: step 13629, loss = 0.50441 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:20:06.489552 ops/training.py:65 2019-01-16 12:20:06.489505: step 13630, loss = 0.48523 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:20:07.454859 ops/training.py:65 2019-01-16 12:20:07.454806: step 13631, loss = 0.50822 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:20:08.418425 ops/training.py:65 2019-01-16 12:20:08.418331: step 13632, loss = 0.47856 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:20:09.379979 ops/training.py:65 2019-01-16 12:20:09.379905: step 13633, loss = 0.36906 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:20:10.342246 ops/training.py:65 2019-01-16 12:20:10.342165: step 13634, loss = 0.45006 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:20:11.303734 ops/training.py:65 2019-01-16 12:20:11.303676: step 13635, loss = 0.34723 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:20:12.265561 ops/training.py:65 2019-01-16 12:20:12.265508: step 13636, loss = 0.44508 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:20:13.225933 ops/training.py:65 2019-01-16 12:20:13.225875: step 13637, loss = 0.52406 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:20:14.189126 ops/training.py:65 2019-01-16 12:20:14.189075: step 13638, loss = 0.49260 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:20:15.151592 ops/training.py:65 2019-01-16 12:20:15.151541: step 13639, loss = 0.47499 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:20:16.115387 ops/training.py:65 2019-01-16 12:20:16.115333: step 13640, loss = 0.39781 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:20:17.076518 ops/training.py:65 2019-01-16 12:20:17.076450: step 13641, loss = 0.50579 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:20:18.039175 ops/training.py:65 2019-01-16 12:20:18.039101: step 13642, loss = 0.53594 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:20:19.000255 ops/training.py:65 2019-01-16 12:20:19.000172: step 13643, loss = 0.44313 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:20:19.963637 ops/training.py:65 2019-01-16 12:20:19.963589: step 13644, loss = 0.39666 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:20:20.924690 ops/training.py:65 2019-01-16 12:20:20.924628: step 13645, loss = 0.64795 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:20:21.885066 ops/training.py:65 2019-01-16 12:20:21.885005: step 13646, loss = 0.43020 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:20:22.849888 ops/training.py:65 2019-01-16 12:20:22.849835: step 13647, loss = 0.40545 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:20:23.814262 ops/training.py:65 2019-01-16 12:20:23.814215: step 13648, loss = 0.35911 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:20:24.775987 ops/training.py:65 2019-01-16 12:20:24.775932: step 13649, loss = 0.52207 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:20:25.737067 ops/training.py:65 2019-01-16 12:20:25.737010: step 13650, loss = 0.45660 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:20:26.701781 ops/training.py:65 2019-01-16 12:20:26.701729: step 13651, loss = 0.48918 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:20:27.665852 ops/training.py:65 2019-01-16 12:20:27.665781: step 13652, loss = 0.62955 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:20:28.629362 ops/training.py:65 2019-01-16 12:20:28.629311: step 13653, loss = 0.40450 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:20:29.591006 ops/training.py:65 2019-01-16 12:20:29.590954: step 13654, loss = 0.48860 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:20:30.552438 ops/training.py:65 2019-01-16 12:20:30.552391: step 13655, loss = 0.60076 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:20:31.513979 ops/training.py:65 2019-01-16 12:20:31.513929: step 13656, loss = 0.37729 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:20:32.475523 ops/training.py:65 2019-01-16 12:20:32.475468: step 13657, loss = 0.35150 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:20:33.438777 ops/training.py:65 2019-01-16 12:20:33.438719: step 13658, loss = 0.51667 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:20:34.402015 ops/training.py:65 2019-01-16 12:20:34.401968: step 13659, loss = 0.55156 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:20:35.366021 ops/training.py:65 2019-01-16 12:20:35.365973: step 13660, loss = 0.47173 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:20:36.329028 ops/training.py:65 2019-01-16 12:20:36.328985: step 13661, loss = 0.43452 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:20:37.290983 ops/training.py:65 2019-01-16 12:20:37.290927: step 13662, loss = 0.55047 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:20:38.256033 ops/training.py:65 2019-01-16 12:20:38.255985: step 13663, loss = 0.57421 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:20:39.217919 ops/training.py:65 2019-01-16 12:20:39.217864: step 13664, loss = 0.46962 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:20:40.180221 ops/training.py:65 2019-01-16 12:20:40.180151: step 13665, loss = 0.43775 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:20:41.144460 ops/training.py:65 2019-01-16 12:20:41.144374: step 13666, loss = 0.51131 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:20:42.107476 ops/training.py:65 2019-01-16 12:20:42.107390: step 13667, loss = 0.46891 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:20:43.070690 ops/training.py:65 2019-01-16 12:20:43.070624: step 13668, loss = 0.59953 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:20:44.032038 ops/training.py:65 2019-01-16 12:20:44.031968: step 13669, loss = 0.51813 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:20:44.994143 ops/training.py:65 2019-01-16 12:20:44.994088: step 13670, loss = 0.62660 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:20:45.955320 ops/training.py:65 2019-01-16 12:20:45.955248: step 13671, loss = 0.65209 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:20:46.916212 ops/training.py:65 2019-01-16 12:20:46.916143: step 13672, loss = 0.54713 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:20:47.877519 ops/training.py:65 2019-01-16 12:20:47.877467: step 13673, loss = 0.62096 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:20:48.838275 ops/training.py:65 2019-01-16 12:20:48.838224: step 13674, loss = 0.65264 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:20:49.800232 ops/training.py:65 2019-01-16 12:20:49.800183: step 13675, loss = 0.55590 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:20:50.761629 ops/training.py:65 2019-01-16 12:20:50.761575: step 13676, loss = 0.39945 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:20:51.723334 ops/training.py:65 2019-01-16 12:20:51.723264: step 13677, loss = 0.48681 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:20:52.687887 ops/training.py:65 2019-01-16 12:20:52.687817: step 13678, loss = 0.53633 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:20:53.652035 ops/training.py:65 2019-01-16 12:20:53.651984: step 13679, loss = 0.65215 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:20:54.614315 ops/training.py:65 2019-01-16 12:20:54.614265: step 13680, loss = 0.46642 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:20:55.577199 ops/training.py:65 2019-01-16 12:20:55.577143: step 13681, loss = 0.45110 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:20:56.539871 ops/training.py:65 2019-01-16 12:20:56.539815: step 13682, loss = 0.36601 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:20:57.501634 ops/training.py:65 2019-01-16 12:20:57.501563: step 13683, loss = 0.48712 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:20:58.465736 ops/training.py:65 2019-01-16 12:20:58.465670: step 13684, loss = 0.53624 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:20:59.427831 ops/training.py:65 2019-01-16 12:20:59.427774: step 13685, loss = 0.58071 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:21:00.388538 ops/training.py:65 2019-01-16 12:21:00.388483: step 13686, loss = 0.48868 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:21:01.349014 ops/training.py:65 2019-01-16 12:21:01.348967: step 13687, loss = 0.44258 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:21:02.309810 ops/training.py:65 2019-01-16 12:21:02.309755: step 13688, loss = 0.56243 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:21:03.273874 ops/training.py:65 2019-01-16 12:21:03.273823: step 13689, loss = 0.64609 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:21:04.235632 ops/training.py:65 2019-01-16 12:21:04.235586: step 13690, loss = 0.56703 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:21:05.198111 ops/training.py:65 2019-01-16 12:21:05.198058: step 13691, loss = 0.39015 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:21:06.161393 ops/training.py:65 2019-01-16 12:21:06.161318: step 13692, loss = 0.43528 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:21:07.123512 ops/training.py:65 2019-01-16 12:21:07.123446: step 13693, loss = 0.51009 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:21:08.087929 ops/training.py:65 2019-01-16 12:21:08.087884: step 13694, loss = 0.44503 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:21:09.052069 ops/training.py:65 2019-01-16 12:21:09.052017: step 13695, loss = 0.65950 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:21:10.014388 ops/training.py:65 2019-01-16 12:21:10.014318: step 13696, loss = 0.67082 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:21:10.978736 ops/training.py:65 2019-01-16 12:21:10.978669: step 13697, loss = 0.48141 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:21:11.942815 ops/training.py:65 2019-01-16 12:21:11.942767: step 13698, loss = 0.54049 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:21:12.905962 ops/training.py:65 2019-01-16 12:21:12.905892: step 13699, loss = 0.65280 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:21:13.869574 ops/training.py:65 2019-01-16 12:21:13.869508: step 13700, loss = 0.56034 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:21:14.833091 ops/training.py:65 2019-01-16 12:21:14.833038: step 13701, loss = 0.57239 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:21:15.796533 ops/training.py:65 2019-01-16 12:21:15.796460: step 13702, loss = 0.34644 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:21:16.758737 ops/training.py:65 2019-01-16 12:21:16.758680: step 13703, loss = 0.49453 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:21:17.719638 ops/training.py:65 2019-01-16 12:21:17.719570: step 13704, loss = 0.58108 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:21:18.682535 ops/training.py:65 2019-01-16 12:21:18.682477: step 13705, loss = 0.54406 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:21:19.645864 ops/training.py:65 2019-01-16 12:21:19.645816: step 13706, loss = 0.62732 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:21:20.610375 ops/training.py:65 2019-01-16 12:21:20.610323: step 13707, loss = 0.39317 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:21:21.574681 ops/training.py:65 2019-01-16 12:21:21.574635: step 13708, loss = 0.52027 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:21:22.536247 ops/training.py:65 2019-01-16 12:21:22.536191: step 13709, loss = 0.40237 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:21:23.500234 ops/training.py:65 2019-01-16 12:21:23.500186: step 13710, loss = 0.57399 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:21:24.464295 ops/training.py:65 2019-01-16 12:21:24.464244: step 13711, loss = 0.53608 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:21:25.427189 ops/training.py:65 2019-01-16 12:21:25.427139: step 13712, loss = 0.35888 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:21:26.389377 ops/training.py:65 2019-01-16 12:21:26.389316: step 13713, loss = 0.44891 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:21:27.352177 ops/training.py:65 2019-01-16 12:21:27.352126: step 13714, loss = 0.62868 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:21:28.315687 ops/training.py:65 2019-01-16 12:21:28.315636: step 13715, loss = 0.51236 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:21:29.280013 ops/training.py:65 2019-01-16 12:21:29.279949: step 13716, loss = 0.41891 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:21:30.243129 ops/training.py:65 2019-01-16 12:21:30.243068: step 13717, loss = 0.58353 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:21:31.207904 ops/training.py:65 2019-01-16 12:21:31.207857: step 13718, loss = 0.77019 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:21:32.169478 ops/training.py:65 2019-01-16 12:21:32.169423: step 13719, loss = 0.53551 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:21:33.134593 ops/training.py:65 2019-01-16 12:21:33.134541: step 13720, loss = 0.46934 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:21:34.099298 ops/training.py:65 2019-01-16 12:21:34.099228: step 13721, loss = 0.41366 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:21:35.061606 ops/training.py:65 2019-01-16 12:21:35.061538: step 13722, loss = 0.63757 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:21:36.024937 ops/training.py:65 2019-01-16 12:21:36.024867: step 13723, loss = 0.63572 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:21:36.987634 ops/training.py:65 2019-01-16 12:21:36.987583: step 13724, loss = 0.46286 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:21:37.950247 ops/training.py:65 2019-01-16 12:21:37.950200: step 13725, loss = 0.53320 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:21:38.911864 ops/training.py:65 2019-01-16 12:21:38.911781: step 13726, loss = 0.46509 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:21:39.873447 ops/training.py:65 2019-01-16 12:21:39.873378: step 13727, loss = 0.48707 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:21:40.836178 ops/training.py:65 2019-01-16 12:21:40.836123: step 13728, loss = 0.56301 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:21:41.798545 ops/training.py:65 2019-01-16 12:21:41.798498: step 13729, loss = 0.59469 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:21:42.759497 ops/training.py:65 2019-01-16 12:21:42.759445: step 13730, loss = 0.62067 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:21:43.720766 ops/training.py:65 2019-01-16 12:21:43.720713: step 13731, loss = 0.46992 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:21:44.682908 ops/training.py:65 2019-01-16 12:21:44.682856: step 13732, loss = 0.54962 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:21:45.647077 ops/training.py:65 2019-01-16 12:21:45.647025: step 13733, loss = 0.56503 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:21:46.608013 ops/training.py:65 2019-01-16 12:21:46.607957: step 13734, loss = 0.44620 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:21:47.568981 ops/training.py:65 2019-01-16 12:21:47.568928: step 13735, loss = 0.44215 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:21:48.531548 ops/training.py:65 2019-01-16 12:21:48.531485: step 13736, loss = 0.44862 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:21:49.492463 ops/training.py:65 2019-01-16 12:21:49.492402: step 13737, loss = 0.55659 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:21:50.455745 ops/training.py:65 2019-01-16 12:21:50.455693: step 13738, loss = 0.45497 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:21:51.419965 ops/training.py:65 2019-01-16 12:21:51.419910: step 13739, loss = 0.51006 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:21:52.382926 ops/training.py:65 2019-01-16 12:21:52.382854: step 13740, loss = 0.54784 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:21:53.345340 ops/training.py:65 2019-01-16 12:21:53.345293: step 13741, loss = 0.46440 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:21:54.308072 ops/training.py:65 2019-01-16 12:21:54.308020: step 13742, loss = 0.37053 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:21:55.272554 ops/training.py:65 2019-01-16 12:21:55.272508: step 13743, loss = 0.56591 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:21:56.233879 ops/training.py:65 2019-01-16 12:21:56.233805: step 13744, loss = 0.40930 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:21:57.194399 ops/training.py:65 2019-01-16 12:21:57.194338: step 13745, loss = 0.40575 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:21:58.158837 ops/training.py:65 2019-01-16 12:21:58.158787: step 13746, loss = 0.67702 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:21:59.121979 ops/training.py:65 2019-01-16 12:21:59.121913: step 13747, loss = 0.43060 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:22:00.083960 ops/training.py:65 2019-01-16 12:22:00.083895: step 13748, loss = 0.43571 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:22:01.044653 ops/training.py:65 2019-01-16 12:22:01.044582: step 13749, loss = 0.58790 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:22:02.005316 ops/training.py:65 2019-01-16 12:22:02.005250: step 13750, loss = 0.40810 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:22:02.969151 ops/training.py:65 2019-01-16 12:22:02.969086: step 13751, loss = 0.59477 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:22:03.933164 ops/training.py:65 2019-01-16 12:22:03.933101: step 13752, loss = 0.54760 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:22:04.895605 ops/training.py:65 2019-01-16 12:22:04.895548: step 13753, loss = 0.52507 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:22:05.856635 ops/training.py:65 2019-01-16 12:22:05.856576: step 13754, loss = 0.38597 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:22:06.820747 ops/training.py:65 2019-01-16 12:22:06.820689: step 13755, loss = 0.49989 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:22:07.784505 ops/training.py:65 2019-01-16 12:22:07.784452: step 13756, loss = 0.54995 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:22:08.747539 ops/training.py:65 2019-01-16 12:22:08.747472: step 13757, loss = 0.55269 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:22:09.710144 ops/training.py:65 2019-01-16 12:22:09.710079: step 13758, loss = 0.40499 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:22:10.672365 ops/training.py:65 2019-01-16 12:22:10.672295: step 13759, loss = 0.52814 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:22:11.633402 ops/training.py:65 2019-01-16 12:22:11.633328: step 13760, loss = 0.42807 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:22:12.594301 ops/training.py:65 2019-01-16 12:22:12.594231: step 13761, loss = 0.55016 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:22:13.556965 ops/training.py:65 2019-01-16 12:22:13.556900: step 13762, loss = 0.45955 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:22:14.518617 ops/training.py:65 2019-01-16 12:22:14.518544: step 13763, loss = 0.43058 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:22:15.480340 ops/training.py:65 2019-01-16 12:22:15.480260: step 13764, loss = 0.61278 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:22:16.443070 ops/training.py:65 2019-01-16 12:22:16.443016: step 13765, loss = 0.52698 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:22:17.404830 ops/training.py:65 2019-01-16 12:22:17.404761: step 13766, loss = 0.56971 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:22:18.366309 ops/training.py:65 2019-01-16 12:22:18.366238: step 13767, loss = 0.49278 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:22:19.327637 ops/training.py:65 2019-01-16 12:22:19.327591: step 13768, loss = 0.40606 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:22:20.288279 ops/training.py:65 2019-01-16 12:22:20.288225: step 13769, loss = 0.40843 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:22:21.249061 ops/training.py:65 2019-01-16 12:22:21.248972: step 13770, loss = 0.60439 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:22:22.209448 ops/training.py:65 2019-01-16 12:22:22.209377: step 13771, loss = 0.60585 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:22:23.170426 ops/training.py:65 2019-01-16 12:22:23.170381: step 13772, loss = 0.44932 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:22:24.131697 ops/training.py:65 2019-01-16 12:22:24.131647: step 13773, loss = 0.48912 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:22:25.092344 ops/training.py:65 2019-01-16 12:22:25.092295: step 13774, loss = 0.45662 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:22:26.052635 ops/training.py:65 2019-01-16 12:22:26.052585: step 13775, loss = 0.49594 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:22:27.014619 ops/training.py:65 2019-01-16 12:22:27.014571: step 13776, loss = 0.47055 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:22:27.976847 ops/training.py:65 2019-01-16 12:22:27.976796: step 13777, loss = 0.41435 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:22:28.938003 ops/training.py:65 2019-01-16 12:22:28.937954: step 13778, loss = 0.58216 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:22:29.897957 ops/training.py:65 2019-01-16 12:22:29.897902: step 13779, loss = 0.56073 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:22:30.861961 ops/training.py:65 2019-01-16 12:22:30.861915: step 13780, loss = 0.57820 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:22:31.825727 ops/training.py:65 2019-01-16 12:22:31.825675: step 13781, loss = 0.47821 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:22:32.790339 ops/training.py:65 2019-01-16 12:22:32.790289: step 13782, loss = 0.45394 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:22:33.751688 ops/training.py:65 2019-01-16 12:22:33.751636: step 13783, loss = 0.49878 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:22:34.715069 ops/training.py:65 2019-01-16 12:22:34.715021: step 13784, loss = 0.52147 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:22:35.677239 ops/training.py:65 2019-01-16 12:22:35.677185: step 13785, loss = 0.47995 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:22:36.641030 ops/training.py:65 2019-01-16 12:22:36.640982: step 13786, loss = 0.57304 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:22:37.604361 ops/training.py:65 2019-01-16 12:22:37.604300: step 13787, loss = 0.50648 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:22:38.567009 ops/training.py:65 2019-01-16 12:22:38.566960: step 13788, loss = 0.82168 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 12:22:39.528574 ops/training.py:65 2019-01-16 12:22:39.528526: step 13789, loss = 0.55594 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:22:40.489834 ops/training.py:65 2019-01-16 12:22:40.489761: step 13790, loss = 0.55897 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:22:41.450460 ops/training.py:65 2019-01-16 12:22:41.450391: step 13791, loss = 0.60414 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:22:42.412246 ops/training.py:65 2019-01-16 12:22:42.412194: step 13792, loss = 0.49869 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:22:43.375607 ops/training.py:65 2019-01-16 12:22:43.375557: step 13793, loss = 0.46291 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:22:44.339709 ops/training.py:65 2019-01-16 12:22:44.339660: step 13794, loss = 0.41108 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:22:45.302899 ops/training.py:65 2019-01-16 12:22:45.302842: step 13795, loss = 0.67535 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.4375
I0832 2019-01-16 12:22:46.264404 ops/training.py:65 2019-01-16 12:22:46.264352: step 13796, loss = 0.56451 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:22:47.224858 ops/training.py:65 2019-01-16 12:22:47.224802: step 13797, loss = 0.39451 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:22:48.187422 ops/training.py:65 2019-01-16 12:22:48.187373: step 13798, loss = 0.44052 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:22:49.148104 ops/training.py:65 2019-01-16 12:22:49.148058: step 13799, loss = 0.59877 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:22:50.109556 ops/training.py:65 2019-01-16 12:22:50.109504: step 13800, loss = 0.57844 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:22:51.069721 ops/training.py:65 2019-01-16 12:22:51.069652: step 13801, loss = 0.37874 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:22:52.033258 ops/training.py:65 2019-01-16 12:22:52.033201: step 13802, loss = 0.46942 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:22:52.997239 ops/training.py:65 2019-01-16 12:22:52.997192: step 13803, loss = 0.59488 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:22:53.961140 ops/training.py:65 2019-01-16 12:22:53.961091: step 13804, loss = 0.55723 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:22:54.922847 ops/training.py:65 2019-01-16 12:22:54.922795: step 13805, loss = 0.58898 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:22:55.885814 ops/training.py:65 2019-01-16 12:22:55.885757: step 13806, loss = 0.56396 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:22:56.850175 ops/training.py:65 2019-01-16 12:22:56.850105: step 13807, loss = 0.44481 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:22:57.812564 ops/training.py:65 2019-01-16 12:22:57.812495: step 13808, loss = 0.48297 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:22:58.777324 ops/training.py:65 2019-01-16 12:22:58.777273: step 13809, loss = 0.64753 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:22:59.742470 ops/training.py:65 2019-01-16 12:22:59.742415: step 13810, loss = 0.48653 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:23:00.706802 ops/training.py:65 2019-01-16 12:23:00.706732: step 13811, loss = 0.44269 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:23:01.667718 ops/training.py:65 2019-01-16 12:23:01.667627: step 13812, loss = 0.68494 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:23:02.630586 ops/training.py:65 2019-01-16 12:23:02.630537: step 13813, loss = 0.79464 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:23:03.592321 ops/training.py:65 2019-01-16 12:23:03.592269: step 13814, loss = 0.43661 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:23:04.553329 ops/training.py:65 2019-01-16 12:23:04.553281: step 13815, loss = 0.47244 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:23:05.517571 ops/training.py:65 2019-01-16 12:23:05.517520: step 13816, loss = 0.47646 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:23:06.480586 ops/training.py:65 2019-01-16 12:23:06.480541: step 13817, loss = 0.55785 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:23:07.443876 ops/training.py:65 2019-01-16 12:23:07.443824: step 13818, loss = 0.34261 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:23:08.405675 ops/training.py:65 2019-01-16 12:23:08.405625: step 13819, loss = 0.54124 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:23:09.366400 ops/training.py:65 2019-01-16 12:23:09.366347: step 13820, loss = 0.59627 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:23:10.327330 ops/training.py:65 2019-01-16 12:23:10.327262: step 13821, loss = 0.50317 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:23:11.288789 ops/training.py:65 2019-01-16 12:23:11.288733: step 13822, loss = 0.52457 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:23:12.250993 ops/training.py:65 2019-01-16 12:23:12.250945: step 13823, loss = 0.38977 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:23:13.213140 ops/training.py:65 2019-01-16 12:23:13.213092: step 13824, loss = 0.62717 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:23:14.175966 ops/training.py:65 2019-01-16 12:23:14.175913: step 13825, loss = 0.56474 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:23:15.137331 ops/training.py:65 2019-01-16 12:23:15.137281: step 13826, loss = 0.54098 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:23:16.099315 ops/training.py:65 2019-01-16 12:23:16.099264: step 13827, loss = 0.62683 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:23:17.061569 ops/training.py:65 2019-01-16 12:23:17.061519: step 13828, loss = 0.52603 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:23:18.023709 ops/training.py:65 2019-01-16 12:23:18.023655: step 13829, loss = 0.52286 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:23:18.985820 ops/training.py:65 2019-01-16 12:23:18.985767: step 13830, loss = 0.45662 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:23:19.946913 ops/training.py:65 2019-01-16 12:23:19.946863: step 13831, loss = 0.48380 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:23:20.907542 ops/training.py:65 2019-01-16 12:23:20.907490: step 13832, loss = 0.49377 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:23:21.869483 ops/training.py:65 2019-01-16 12:23:21.869434: step 13833, loss = 0.42040 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:23:22.831820 ops/training.py:65 2019-01-16 12:23:22.831761: step 13834, loss = 0.58241 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:23:23.793905 ops/training.py:65 2019-01-16 12:23:23.793836: step 13835, loss = 0.54820 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:23:24.755822 ops/training.py:65 2019-01-16 12:23:24.755755: step 13836, loss = 0.46816 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:23:25.716392 ops/training.py:65 2019-01-16 12:23:25.716328: step 13837, loss = 0.48133 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:23:26.681844 ops/training.py:65 2019-01-16 12:23:26.681797: step 13838, loss = 0.48182 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:23:27.646447 ops/training.py:65 2019-01-16 12:23:27.646379: step 13839, loss = 0.62198 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:23:28.610241 ops/training.py:65 2019-01-16 12:23:28.610179: step 13840, loss = 0.47856 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:23:29.571784 ops/training.py:65 2019-01-16 12:23:29.571718: step 13841, loss = 0.55988 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:23:30.532712 ops/training.py:65 2019-01-16 12:23:30.532647: step 13842, loss = 0.50351 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:23:31.494735 ops/training.py:65 2019-01-16 12:23:31.494686: step 13843, loss = 0.44085 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:23:32.456894 ops/training.py:65 2019-01-16 12:23:32.456819: step 13844, loss = 0.45038 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:23:33.418556 ops/training.py:65 2019-01-16 12:23:33.418485: step 13845, loss = 0.34779 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:23:34.379324 ops/training.py:65 2019-01-16 12:23:34.379270: step 13846, loss = 0.32423 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:23:35.342934 ops/training.py:65 2019-01-16 12:23:35.342888: step 13847, loss = 0.47230 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:23:36.306578 ops/training.py:65 2019-01-16 12:23:36.306530: step 13848, loss = 0.64049 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:23:37.269565 ops/training.py:65 2019-01-16 12:23:37.269517: step 13849, loss = 0.53178 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:23:38.230416 ops/training.py:65 2019-01-16 12:23:38.230370: step 13850, loss = 0.48357 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:23:39.192291 ops/training.py:65 2019-01-16 12:23:39.192225: step 13851, loss = 0.40662 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:23:40.155412 ops/training.py:65 2019-01-16 12:23:40.155359: step 13852, loss = 0.37801 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:23:41.117264 ops/training.py:65 2019-01-16 12:23:41.117211: step 13853, loss = 0.49239 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:23:42.079789 ops/training.py:65 2019-01-16 12:23:42.079738: step 13854, loss = 0.38403 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:23:43.040755 ops/training.py:65 2019-01-16 12:23:43.040706: step 13855, loss = 0.44373 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:23:44.002844 ops/training.py:65 2019-01-16 12:23:44.002791: step 13856, loss = 0.45646 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:23:44.965849 ops/training.py:65 2019-01-16 12:23:44.965797: step 13857, loss = 0.39437 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:23:45.926039 ops/training.py:65 2019-01-16 12:23:45.925988: step 13858, loss = 0.41177 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:23:46.888591 ops/training.py:65 2019-01-16 12:23:46.888538: step 13859, loss = 0.42196 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:23:47.853489 ops/training.py:65 2019-01-16 12:23:47.853437: step 13860, loss = 0.49699 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:23:48.817593 ops/training.py:65 2019-01-16 12:23:48.817540: step 13861, loss = 0.47778 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:23:49.780610 ops/training.py:65 2019-01-16 12:23:49.780536: step 13862, loss = 0.55087 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:23:50.743130 ops/training.py:65 2019-01-16 12:23:50.743058: step 13863, loss = 0.55721 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:23:51.705697 ops/training.py:65 2019-01-16 12:23:51.705633: step 13864, loss = 0.62577 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:23:52.668385 ops/training.py:65 2019-01-16 12:23:52.668312: step 13865, loss = 0.35988 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:23:53.633864 ops/training.py:65 2019-01-16 12:23:53.633793: step 13866, loss = 0.40919 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:23:54.595384 ops/training.py:65 2019-01-16 12:23:54.595309: step 13867, loss = 0.53784 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:23:55.556366 ops/training.py:65 2019-01-16 12:23:55.556293: step 13868, loss = 0.52896 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:23:56.517299 ops/training.py:65 2019-01-16 12:23:56.517207: step 13869, loss = 0.51808 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:23:57.477242 ops/training.py:65 2019-01-16 12:23:57.477196: step 13870, loss = 0.41604 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:23:58.438006 ops/training.py:65 2019-01-16 12:23:58.437956: step 13871, loss = 0.58599 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:23:59.401032 ops/training.py:65 2019-01-16 12:23:59.400984: step 13872, loss = 0.62307 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:24:00.364212 ops/training.py:65 2019-01-16 12:24:00.364163: step 13873, loss = 0.42071 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:24:01.326046 ops/training.py:65 2019-01-16 12:24:01.325996: step 13874, loss = 0.54588 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:24:02.287488 ops/training.py:65 2019-01-16 12:24:02.287441: step 13875, loss = 0.37333 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 12:24:03.249359 ops/training.py:65 2019-01-16 12:24:03.249308: step 13876, loss = 0.47163 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:24:04.212335 ops/training.py:65 2019-01-16 12:24:04.212287: step 13877, loss = 0.58968 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:24:05.173008 ops/training.py:65 2019-01-16 12:24:05.172959: step 13878, loss = 0.46218 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:24:06.133679 ops/training.py:65 2019-01-16 12:24:06.133629: step 13879, loss = 0.53038 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:24:07.095401 ops/training.py:65 2019-01-16 12:24:07.095354: step 13880, loss = 0.49038 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:24:08.056110 ops/training.py:65 2019-01-16 12:24:08.056065: step 13881, loss = 0.58176 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:24:09.018188 ops/training.py:65 2019-01-16 12:24:09.018139: step 13882, loss = 0.54872 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:24:09.979429 ops/training.py:65 2019-01-16 12:24:09.979374: step 13883, loss = 0.47854 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:24:10.940291 ops/training.py:65 2019-01-16 12:24:10.940230: step 13884, loss = 0.58817 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:24:11.905419 ops/training.py:65 2019-01-16 12:24:11.905371: step 13885, loss = 0.55622 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:24:12.869569 ops/training.py:65 2019-01-16 12:24:12.869521: step 13886, loss = 0.51214 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:24:13.835130 ops/training.py:65 2019-01-16 12:24:13.835077: step 13887, loss = 0.44121 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:24:14.797219 ops/training.py:65 2019-01-16 12:24:14.797160: step 13888, loss = 0.39733 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:24:15.759211 ops/training.py:65 2019-01-16 12:24:15.759163: step 13889, loss = 0.43554 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:24:16.721321 ops/training.py:65 2019-01-16 12:24:16.721274: step 13890, loss = 0.71199 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:24:17.683343 ops/training.py:65 2019-01-16 12:24:17.683271: step 13891, loss = 0.62768 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:24:18.645328 ops/training.py:65 2019-01-16 12:24:18.645255: step 13892, loss = 0.41798 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:24:19.606314 ops/training.py:65 2019-01-16 12:24:19.606265: step 13893, loss = 0.44144 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:24:20.567601 ops/training.py:65 2019-01-16 12:24:20.567545: step 13894, loss = 0.41320 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:24:21.529885 ops/training.py:65 2019-01-16 12:24:21.529836: step 13895, loss = 0.57223 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:24:22.493580 ops/training.py:65 2019-01-16 12:24:22.493513: step 13896, loss = 0.63541 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:24:23.457328 ops/training.py:65 2019-01-16 12:24:23.457282: step 13897, loss = 0.42898 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:24:24.420827 ops/training.py:65 2019-01-16 12:24:24.420770: step 13898, loss = 0.55350 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:24:25.382585 ops/training.py:65 2019-01-16 12:24:25.382515: step 13899, loss = 0.37620 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:24:26.344372 ops/training.py:65 2019-01-16 12:24:26.344300: step 13900, loss = 0.51733 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:24:27.306143 ops/training.py:65 2019-01-16 12:24:27.306094: step 13901, loss = 0.43932 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:24:28.268374 ops/training.py:65 2019-01-16 12:24:28.268324: step 13902, loss = 0.51929 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:24:29.229711 ops/training.py:65 2019-01-16 12:24:29.229662: step 13903, loss = 0.57150 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:24:30.191596 ops/training.py:65 2019-01-16 12:24:30.191550: step 13904, loss = 0.61626 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:24:31.154133 ops/training.py:65 2019-01-16 12:24:31.154065: step 13905, loss = 0.48158 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:24:32.116384 ops/training.py:65 2019-01-16 12:24:32.116323: step 13906, loss = 0.53546 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:24:33.077100 ops/training.py:65 2019-01-16 12:24:33.077049: step 13907, loss = 0.70952 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:24:34.038492 ops/training.py:65 2019-01-16 12:24:34.038446: step 13908, loss = 0.41307 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:24:34.999551 ops/training.py:65 2019-01-16 12:24:34.999503: step 13909, loss = 0.51606 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:24:35.960950 ops/training.py:65 2019-01-16 12:24:35.960900: step 13910, loss = 0.50128 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:24:36.921985 ops/training.py:65 2019-01-16 12:24:36.921927: step 13911, loss = 0.51019 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:24:37.883754 ops/training.py:65 2019-01-16 12:24:37.883705: step 13912, loss = 0.55635 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:24:38.845530 ops/training.py:65 2019-01-16 12:24:38.845482: step 13913, loss = 0.52339 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:24:39.808379 ops/training.py:65 2019-01-16 12:24:39.808313: step 13914, loss = 0.74531 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:24:40.772795 ops/training.py:65 2019-01-16 12:24:40.772728: step 13915, loss = 0.56381 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:24:41.735528 ops/training.py:65 2019-01-16 12:24:41.735483: step 13916, loss = 0.50703 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:24:42.698397 ops/training.py:65 2019-01-16 12:24:42.698335: step 13917, loss = 0.47196 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:24:43.662267 ops/training.py:65 2019-01-16 12:24:43.662214: step 13918, loss = 0.53909 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:24:44.625365 ops/training.py:65 2019-01-16 12:24:44.625309: step 13919, loss = 0.60505 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:24:45.586778 ops/training.py:65 2019-01-16 12:24:45.586730: step 13920, loss = 0.57404 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:24:46.550522 ops/training.py:65 2019-01-16 12:24:46.550470: step 13921, loss = 0.49809 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:24:47.513080 ops/training.py:65 2019-01-16 12:24:47.513017: step 13922, loss = 0.50318 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:24:48.475591 ops/training.py:65 2019-01-16 12:24:48.475529: step 13923, loss = 0.53373 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:24:49.436189 ops/training.py:65 2019-01-16 12:24:49.436115: step 13924, loss = 0.44600 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:24:50.400442 ops/training.py:65 2019-01-16 12:24:50.400389: step 13925, loss = 0.38637 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:24:51.365799 ops/training.py:65 2019-01-16 12:24:51.365740: step 13926, loss = 0.49534 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:24:52.328858 ops/training.py:65 2019-01-16 12:24:52.328784: step 13927, loss = 0.47748 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:24:53.291515 ops/training.py:65 2019-01-16 12:24:53.291448: step 13928, loss = 0.46316 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:24:54.253799 ops/training.py:65 2019-01-16 12:24:54.253730: step 13929, loss = 0.50536 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:24:55.218104 ops/training.py:65 2019-01-16 12:24:55.218016: step 13930, loss = 0.51784 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:24:56.182284 ops/training.py:65 2019-01-16 12:24:56.182238: step 13931, loss = 0.48511 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:24:57.145689 ops/training.py:65 2019-01-16 12:24:57.145641: step 13932, loss = 0.47768 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:24:58.106738 ops/training.py:65 2019-01-16 12:24:58.106682: step 13933, loss = 0.60347 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:24:59.068494 ops/training.py:65 2019-01-16 12:24:59.068428: step 13934, loss = 0.41639 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:25:00.029524 ops/training.py:65 2019-01-16 12:25:00.029478: step 13935, loss = 0.57329 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:25:00.993147 ops/training.py:65 2019-01-16 12:25:00.993086: step 13936, loss = 0.55715 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:25:01.956795 ops/training.py:65 2019-01-16 12:25:01.956742: step 13937, loss = 0.42792 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:25:02.919436 ops/training.py:65 2019-01-16 12:25:02.919381: step 13938, loss = 0.39376 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:25:03.881241 ops/training.py:65 2019-01-16 12:25:03.881173: step 13939, loss = 0.42074 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:25:04.842596 ops/training.py:65 2019-01-16 12:25:04.842531: step 13940, loss = 0.45541 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:25:05.803465 ops/training.py:65 2019-01-16 12:25:05.803399: step 13941, loss = 0.58464 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:25:06.764288 ops/training.py:65 2019-01-16 12:25:06.764213: step 13942, loss = 0.45811 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:25:07.725850 ops/training.py:65 2019-01-16 12:25:07.725777: step 13943, loss = 0.54020 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:25:08.688318 ops/training.py:65 2019-01-16 12:25:08.688247: step 13944, loss = 0.58499 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:25:09.649448 ops/training.py:65 2019-01-16 12:25:09.649384: step 13945, loss = 0.52487 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:25:10.613833 ops/training.py:65 2019-01-16 12:25:10.613770: step 13946, loss = 0.64988 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:25:11.577486 ops/training.py:65 2019-01-16 12:25:11.577423: step 13947, loss = 0.60129 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:25:12.540118 ops/training.py:65 2019-01-16 12:25:12.540067: step 13948, loss = 0.58140 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:25:13.502046 ops/training.py:65 2019-01-16 12:25:13.501993: step 13949, loss = 0.43445 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:25:14.463571 ops/training.py:65 2019-01-16 12:25:14.463515: step 13950, loss = 0.52317 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:25:15.425706 ops/training.py:65 2019-01-16 12:25:15.425642: step 13951, loss = 0.48843 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:25:16.390266 ops/training.py:65 2019-01-16 12:25:16.390218: step 13952, loss = 0.57084 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:25:17.354295 ops/training.py:65 2019-01-16 12:25:17.354247: step 13953, loss = 0.46681 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:25:18.317957 ops/training.py:65 2019-01-16 12:25:18.317906: step 13954, loss = 0.47404 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:25:19.280078 ops/training.py:65 2019-01-16 12:25:19.280031: step 13955, loss = 0.53608 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:25:20.241288 ops/training.py:65 2019-01-16 12:25:20.241216: step 13956, loss = 0.44457 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:25:21.202424 ops/training.py:65 2019-01-16 12:25:21.202336: step 13957, loss = 0.48923 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:25:22.164534 ops/training.py:65 2019-01-16 12:25:22.164443: step 13958, loss = 0.45400 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:25:23.126918 ops/training.py:65 2019-01-16 12:25:23.126871: step 13959, loss = 0.48698 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:25:24.088658 ops/training.py:65 2019-01-16 12:25:24.088602: step 13960, loss = 0.43243 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:25:25.049422 ops/training.py:65 2019-01-16 12:25:25.049364: step 13961, loss = 0.46935 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:25:26.010855 ops/training.py:65 2019-01-16 12:25:26.010793: step 13962, loss = 0.44303 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:25:26.972176 ops/training.py:65 2019-01-16 12:25:26.972109: step 13963, loss = 0.55771 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:25:27.933551 ops/training.py:65 2019-01-16 12:25:27.933490: step 13964, loss = 0.48113 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:25:28.893919 ops/training.py:65 2019-01-16 12:25:28.893857: step 13965, loss = 0.42680 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:25:29.854465 ops/training.py:65 2019-01-16 12:25:29.854396: step 13966, loss = 0.34923 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:25:30.815791 ops/training.py:65 2019-01-16 12:25:30.815722: step 13967, loss = 0.45104 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:25:31.777316 ops/training.py:65 2019-01-16 12:25:31.777261: step 13968, loss = 0.50964 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:25:32.739655 ops/training.py:65 2019-01-16 12:25:32.739600: step 13969, loss = 0.45110 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:25:33.703139 ops/training.py:65 2019-01-16 12:25:33.703084: step 13970, loss = 0.47426 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:25:34.665078 ops/training.py:65 2019-01-16 12:25:34.665027: step 13971, loss = 0.40887 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:25:35.630203 ops/training.py:65 2019-01-16 12:25:35.630151: step 13972, loss = 0.52920 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:25:36.594651 ops/training.py:65 2019-01-16 12:25:36.594598: step 13973, loss = 0.64479 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:25:37.558412 ops/training.py:65 2019-01-16 12:25:37.558363: step 13974, loss = 0.48241 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:25:38.520231 ops/training.py:65 2019-01-16 12:25:38.520181: step 13975, loss = 0.70096 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:25:39.481621 ops/training.py:65 2019-01-16 12:25:39.481566: step 13976, loss = 0.51804 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:25:40.446145 ops/training.py:65 2019-01-16 12:25:40.446098: step 13977, loss = 0.38102 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:25:41.409859 ops/training.py:65 2019-01-16 12:25:41.409791: step 13978, loss = 0.52099 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:25:42.373174 ops/training.py:65 2019-01-16 12:25:42.373110: step 13979, loss = 0.50489 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:25:43.335064 ops/training.py:65 2019-01-16 12:25:43.335012: step 13980, loss = 0.61989 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:25:44.297430 ops/training.py:65 2019-01-16 12:25:44.297361: step 13981, loss = 0.46606 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:25:45.259842 ops/training.py:65 2019-01-16 12:25:45.259792: step 13982, loss = 0.52081 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:25:46.221466 ops/training.py:65 2019-01-16 12:25:46.221415: step 13983, loss = 0.63149 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:25:47.183613 ops/training.py:65 2019-01-16 12:25:47.183563: step 13984, loss = 0.50134 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:25:48.144428 ops/training.py:65 2019-01-16 12:25:48.144374: step 13985, loss = 0.54954 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:25:49.105971 ops/training.py:65 2019-01-16 12:25:49.105923: step 13986, loss = 0.54957 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:25:50.068149 ops/training.py:65 2019-01-16 12:25:50.068095: step 13987, loss = 0.48029 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:25:51.032844 ops/training.py:65 2019-01-16 12:25:51.032794: step 13988, loss = 0.50682 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:25:51.996031 ops/training.py:65 2019-01-16 12:25:51.995977: step 13989, loss = 0.34909 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:25:52.959727 ops/training.py:65 2019-01-16 12:25:52.959668: step 13990, loss = 0.37389 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:25:53.920601 ops/training.py:65 2019-01-16 12:25:53.920530: step 13991, loss = 0.62570 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:25:54.881840 ops/training.py:65 2019-01-16 12:25:54.881788: step 13992, loss = 0.49290 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:25:55.842549 ops/training.py:65 2019-01-16 12:25:55.842481: step 13993, loss = 0.43294 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:25:56.806294 ops/training.py:65 2019-01-16 12:25:56.806244: step 13994, loss = 0.49557 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:25:57.769522 ops/training.py:65 2019-01-16 12:25:57.769471: step 13995, loss = 0.44397 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:25:58.731954 ops/training.py:65 2019-01-16 12:25:58.731900: step 13996, loss = 0.55180 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:25:59.692924 ops/training.py:65 2019-01-16 12:25:59.692871: step 13997, loss = 0.65103 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:26:00.653694 ops/training.py:65 2019-01-16 12:26:00.653648: step 13998, loss = 0.59484 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:26:01.615227 ops/training.py:65 2019-01-16 12:26:01.615172: step 13999, loss = 0.36324 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:30:40.858570 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I0832 2019-01-16 12:30:40.859388 ops/training.py:41 2019-01-16 12:30:40.859342: step 14000, loss = 0.45 (0.1 examples/sec; 278.281 sec/batch) | Training accuracy = 0.78125 | Validation accuracy = 0.6631 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_08_07_39_512188
I0832 2019-01-16 12:30:41.820984 ops/training.py:65 2019-01-16 12:30:41.820918: step 14001, loss = 0.55217 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:30:42.782981 ops/training.py:65 2019-01-16 12:30:42.782908: step 14002, loss = 0.46223 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:30:43.744308 ops/training.py:65 2019-01-16 12:30:43.744241: step 14003, loss = 0.50762 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:30:44.705226 ops/training.py:65 2019-01-16 12:30:44.705130: step 14004, loss = 0.47465 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:30:45.666243 ops/training.py:65 2019-01-16 12:30:45.666148: step 14005, loss = 0.46221 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:30:46.628411 ops/training.py:65 2019-01-16 12:30:46.628342: step 14006, loss = 0.75623 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 12:30:47.593814 ops/training.py:65 2019-01-16 12:30:47.593763: step 14007, loss = 0.48876 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:30:48.558064 ops/training.py:65 2019-01-16 12:30:48.558009: step 14008, loss = 0.57626 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:30:49.521475 ops/training.py:65 2019-01-16 12:30:49.521404: step 14009, loss = 0.66299 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:30:50.482775 ops/training.py:65 2019-01-16 12:30:50.482704: step 14010, loss = 0.59301 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:30:51.445504 ops/training.py:65 2019-01-16 12:30:51.445432: step 14011, loss = 0.47586 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:30:52.406665 ops/training.py:65 2019-01-16 12:30:52.406595: step 14012, loss = 0.60192 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:30:53.368305 ops/training.py:65 2019-01-16 12:30:53.368234: step 14013, loss = 0.62199 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:30:54.329411 ops/training.py:65 2019-01-16 12:30:54.329341: step 14014, loss = 0.59588 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:30:55.290538 ops/training.py:65 2019-01-16 12:30:55.290463: step 14015, loss = 0.73449 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:30:56.251957 ops/training.py:65 2019-01-16 12:30:56.251885: step 14016, loss = 0.50855 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:30:57.214436 ops/training.py:65 2019-01-16 12:30:57.214360: step 14017, loss = 0.65530 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:30:58.175210 ops/training.py:65 2019-01-16 12:30:58.175147: step 14018, loss = 0.48146 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:30:59.136155 ops/training.py:65 2019-01-16 12:30:59.136081: step 14019, loss = 0.46788 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:31:00.097782 ops/training.py:65 2019-01-16 12:31:00.097711: step 14020, loss = 0.52389 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:31:01.059118 ops/training.py:65 2019-01-16 12:31:01.059045: step 14021, loss = 0.55436 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:31:02.020851 ops/training.py:65 2019-01-16 12:31:02.020798: step 14022, loss = 0.50257 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:31:02.982136 ops/training.py:65 2019-01-16 12:31:02.982069: step 14023, loss = 0.47922 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:31:03.945653 ops/training.py:65 2019-01-16 12:31:03.945611: step 14024, loss = 0.60790 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:31:04.908955 ops/training.py:65 2019-01-16 12:31:04.908885: step 14025, loss = 0.47116 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:31:05.872125 ops/training.py:65 2019-01-16 12:31:05.872064: step 14026, loss = 0.61396 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:31:06.833503 ops/training.py:65 2019-01-16 12:31:06.833435: step 14027, loss = 0.55536 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:31:07.796001 ops/training.py:65 2019-01-16 12:31:07.795931: step 14028, loss = 0.47130 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:31:08.758412 ops/training.py:65 2019-01-16 12:31:08.758345: step 14029, loss = 0.56694 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:31:09.719421 ops/training.py:65 2019-01-16 12:31:09.719366: step 14030, loss = 0.39149 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:31:10.681198 ops/training.py:65 2019-01-16 12:31:10.681131: step 14031, loss = 0.54109 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:31:11.644081 ops/training.py:65 2019-01-16 12:31:11.644012: step 14032, loss = 0.62556 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:31:12.607135 ops/training.py:65 2019-01-16 12:31:12.607071: step 14033, loss = 0.59779 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:31:13.570312 ops/training.py:65 2019-01-16 12:31:13.570244: step 14034, loss = 0.44631 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:31:14.535716 ops/training.py:65 2019-01-16 12:31:14.535649: step 14035, loss = 0.59808 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:31:15.500861 ops/training.py:65 2019-01-16 12:31:15.500790: step 14036, loss = 0.43739 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:31:16.464692 ops/training.py:65 2019-01-16 12:31:16.464621: step 14037, loss = 0.56325 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:31:17.426388 ops/training.py:65 2019-01-16 12:31:17.426336: step 14038, loss = 0.60065 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:31:18.388268 ops/training.py:65 2019-01-16 12:31:18.388198: step 14039, loss = 0.49889 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:31:19.349420 ops/training.py:65 2019-01-16 12:31:19.349370: step 14040, loss = 0.53769 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:31:20.310557 ops/training.py:65 2019-01-16 12:31:20.310486: step 14041, loss = 0.60503 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:31:21.272156 ops/training.py:65 2019-01-16 12:31:21.272084: step 14042, loss = 0.52496 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:31:22.233449 ops/training.py:65 2019-01-16 12:31:22.233383: step 14043, loss = 0.36703 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:31:23.196340 ops/training.py:65 2019-01-16 12:31:23.196269: step 14044, loss = 0.53303 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:31:24.158842 ops/training.py:65 2019-01-16 12:31:24.158775: step 14045, loss = 0.38189 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:31:25.121448 ops/training.py:65 2019-01-16 12:31:25.121383: step 14046, loss = 0.59286 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:31:26.085860 ops/training.py:65 2019-01-16 12:31:26.085792: step 14047, loss = 0.45551 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:31:27.050078 ops/training.py:65 2019-01-16 12:31:27.050011: step 14048, loss = 0.46906 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:31:28.014110 ops/training.py:65 2019-01-16 12:31:28.014040: step 14049, loss = 0.48896 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:31:28.975769 ops/training.py:65 2019-01-16 12:31:28.975713: step 14050, loss = 0.50334 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:31:29.940756 ops/training.py:65 2019-01-16 12:31:29.940692: step 14051, loss = 0.51288 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:31:30.903342 ops/training.py:65 2019-01-16 12:31:30.903276: step 14052, loss = 0.68813 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:31:31.868286 ops/training.py:65 2019-01-16 12:31:31.868218: step 14053, loss = 0.65339 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 12:31:32.833570 ops/training.py:65 2019-01-16 12:31:32.833502: step 14054, loss = 0.43085 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:31:33.795855 ops/training.py:65 2019-01-16 12:31:33.795787: step 14055, loss = 0.52549 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:31:34.760207 ops/training.py:65 2019-01-16 12:31:34.760153: step 14056, loss = 0.48597 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:31:35.724440 ops/training.py:65 2019-01-16 12:31:35.724370: step 14057, loss = 0.45158 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:31:36.688316 ops/training.py:65 2019-01-16 12:31:36.688249: step 14058, loss = 0.42815 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:31:37.652416 ops/training.py:65 2019-01-16 12:31:37.652345: step 14059, loss = 0.55092 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:31:38.615717 ops/training.py:65 2019-01-16 12:31:38.615652: step 14060, loss = 0.58664 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:31:39.577039 ops/training.py:65 2019-01-16 12:31:39.576974: step 14061, loss = 0.49549 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:31:40.538576 ops/training.py:65 2019-01-16 12:31:40.538520: step 14062, loss = 0.52048 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:31:41.500287 ops/training.py:65 2019-01-16 12:31:41.500218: step 14063, loss = 0.59991 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:31:42.463057 ops/training.py:65 2019-01-16 12:31:42.462991: step 14064, loss = 0.49889 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:31:43.423792 ops/training.py:65 2019-01-16 12:31:43.423720: step 14065, loss = 0.56212 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:31:44.387383 ops/training.py:65 2019-01-16 12:31:44.387318: step 14066, loss = 0.65358 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 12:31:45.350286 ops/training.py:65 2019-01-16 12:31:45.350232: step 14067, loss = 0.60407 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:31:46.314137 ops/training.py:65 2019-01-16 12:31:46.314068: step 14068, loss = 0.51434 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:31:47.276913 ops/training.py:65 2019-01-16 12:31:47.276859: step 14069, loss = 0.60120 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:31:48.238601 ops/training.py:65 2019-01-16 12:31:48.238524: step 14070, loss = 0.58822 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:31:49.202666 ops/training.py:65 2019-01-16 12:31:49.202614: step 14071, loss = 0.59166 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:31:50.164886 ops/training.py:65 2019-01-16 12:31:50.164814: step 14072, loss = 0.52488 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:31:51.129813 ops/training.py:65 2019-01-16 12:31:51.129745: step 14073, loss = 0.63402 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:31:52.092695 ops/training.py:65 2019-01-16 12:31:52.092630: step 14074, loss = 0.40894 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:31:53.054146 ops/training.py:65 2019-01-16 12:31:53.054072: step 14075, loss = 0.68245 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:31:54.015564 ops/training.py:65 2019-01-16 12:31:54.015490: step 14076, loss = 0.39089 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:31:54.975875 ops/training.py:65 2019-01-16 12:31:54.975822: step 14077, loss = 0.50892 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:31:55.937216 ops/training.py:65 2019-01-16 12:31:55.937159: step 14078, loss = 0.61936 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:31:56.897642 ops/training.py:65 2019-01-16 12:31:56.897586: step 14079, loss = 0.54401 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:31:57.858657 ops/training.py:65 2019-01-16 12:31:57.858596: step 14080, loss = 0.47568 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:31:58.820362 ops/training.py:65 2019-01-16 12:31:58.820303: step 14081, loss = 0.40111 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:31:59.780870 ops/training.py:65 2019-01-16 12:31:59.780819: step 14082, loss = 0.55585 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:32:00.744735 ops/training.py:65 2019-01-16 12:32:00.744666: step 14083, loss = 0.44995 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:32:01.708879 ops/training.py:65 2019-01-16 12:32:01.708795: step 14084, loss = 0.38848 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:32:02.673129 ops/training.py:65 2019-01-16 12:32:02.673078: step 14085, loss = 0.44429 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:32:03.636006 ops/training.py:65 2019-01-16 12:32:03.635940: step 14086, loss = 0.44927 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:32:04.598001 ops/training.py:65 2019-01-16 12:32:04.597950: step 14087, loss = 0.51067 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:32:05.560063 ops/training.py:65 2019-01-16 12:32:05.559995: step 14088, loss = 0.47436 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:32:06.521407 ops/training.py:65 2019-01-16 12:32:06.521340: step 14089, loss = 0.45837 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:32:07.483832 ops/training.py:65 2019-01-16 12:32:07.483761: step 14090, loss = 0.44654 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:32:08.445796 ops/training.py:65 2019-01-16 12:32:08.445733: step 14091, loss = 0.49181 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:32:09.408281 ops/training.py:65 2019-01-16 12:32:09.408218: step 14092, loss = 0.50004 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:32:10.372279 ops/training.py:65 2019-01-16 12:32:10.372222: step 14093, loss = 0.46923 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:32:11.335692 ops/training.py:65 2019-01-16 12:32:11.335626: step 14094, loss = 0.54043 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:32:12.299388 ops/training.py:65 2019-01-16 12:32:12.299320: step 14095, loss = 0.61111 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:32:13.262473 ops/training.py:65 2019-01-16 12:32:13.262412: step 14096, loss = 0.54096 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:32:14.227197 ops/training.py:65 2019-01-16 12:32:14.227128: step 14097, loss = 0.35585 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:32:15.191942 ops/training.py:65 2019-01-16 12:32:15.191874: step 14098, loss = 0.43853 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:32:16.153802 ops/training.py:65 2019-01-16 12:32:16.153731: step 14099, loss = 0.48288 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:32:17.114858 ops/training.py:65 2019-01-16 12:32:17.114788: step 14100, loss = 0.52418 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:32:18.078891 ops/training.py:65 2019-01-16 12:32:18.078834: step 14101, loss = 0.41942 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:32:19.042436 ops/training.py:65 2019-01-16 12:32:19.042386: step 14102, loss = 0.61001 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:32:20.005407 ops/training.py:65 2019-01-16 12:32:20.005358: step 14103, loss = 0.40648 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:32:20.968011 ops/training.py:65 2019-01-16 12:32:20.967943: step 14104, loss = 0.48686 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:32:21.931133 ops/training.py:65 2019-01-16 12:32:21.931063: step 14105, loss = 0.40576 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:32:22.899582 ops/training.py:65 2019-01-16 12:32:22.899528: step 14106, loss = 0.44829 (33.1 examples/sec; 0.967 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:32:23.863207 ops/training.py:65 2019-01-16 12:32:23.863115: step 14107, loss = 0.40918 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:32:24.826078 ops/training.py:65 2019-01-16 12:32:24.826007: step 14108, loss = 0.48771 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:32:25.787147 ops/training.py:65 2019-01-16 12:32:25.787093: step 14109, loss = 0.49278 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:32:26.748977 ops/training.py:65 2019-01-16 12:32:26.748923: step 14110, loss = 0.50816 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:32:27.712554 ops/training.py:65 2019-01-16 12:32:27.712482: step 14111, loss = 0.48343 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:32:28.675745 ops/training.py:65 2019-01-16 12:32:28.675673: step 14112, loss = 0.44843 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:32:29.636859 ops/training.py:65 2019-01-16 12:32:29.636790: step 14113, loss = 0.63643 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:32:30.597625 ops/training.py:65 2019-01-16 12:32:30.597560: step 14114, loss = 0.47637 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:32:31.562713 ops/training.py:65 2019-01-16 12:32:31.562643: step 14115, loss = 0.47608 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:32:32.526732 ops/training.py:65 2019-01-16 12:32:32.526663: step 14116, loss = 0.65920 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:32:33.489411 ops/training.py:65 2019-01-16 12:32:33.489344: step 14117, loss = 0.51161 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:32:34.450567 ops/training.py:65 2019-01-16 12:32:34.450515: step 14118, loss = 0.46164 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:32:35.412297 ops/training.py:65 2019-01-16 12:32:35.412235: step 14119, loss = 0.42133 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:32:36.377526 ops/training.py:65 2019-01-16 12:32:36.377462: step 14120, loss = 0.64067 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:32:37.338063 ops/training.py:65 2019-01-16 12:32:37.337998: step 14121, loss = 0.48749 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:32:38.303918 ops/training.py:65 2019-01-16 12:32:38.303856: step 14122, loss = 0.49977 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:32:39.267973 ops/training.py:65 2019-01-16 12:32:39.267903: step 14123, loss = 0.44511 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:32:40.229758 ops/training.py:65 2019-01-16 12:32:40.229705: step 14124, loss = 0.55716 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:32:41.191942 ops/training.py:65 2019-01-16 12:32:41.191869: step 14125, loss = 0.54154 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:32:42.153227 ops/training.py:65 2019-01-16 12:32:42.153153: step 14126, loss = 0.52865 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:32:43.118328 ops/training.py:65 2019-01-16 12:32:43.118255: step 14127, loss = 0.55396 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:32:44.081341 ops/training.py:65 2019-01-16 12:32:44.081270: step 14128, loss = 0.38903 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:32:45.046359 ops/training.py:65 2019-01-16 12:32:45.046288: step 14129, loss = 0.37425 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:32:46.009564 ops/training.py:65 2019-01-16 12:32:46.009487: step 14130, loss = 0.42798 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:32:46.970889 ops/training.py:65 2019-01-16 12:32:46.970818: step 14131, loss = 0.51951 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:32:47.936088 ops/training.py:65 2019-01-16 12:32:47.936022: step 14132, loss = 0.45838 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:32:48.897661 ops/training.py:65 2019-01-16 12:32:48.897600: step 14133, loss = 0.52049 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:32:49.858625 ops/training.py:65 2019-01-16 12:32:49.858556: step 14134, loss = 0.54051 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:32:50.822511 ops/training.py:65 2019-01-16 12:32:50.822467: step 14135, loss = 0.56964 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:32:51.785778 ops/training.py:65 2019-01-16 12:32:51.785707: step 14136, loss = 0.55327 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:32:52.749226 ops/training.py:65 2019-01-16 12:32:52.749172: step 14137, loss = 0.35719 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:32:53.712701 ops/training.py:65 2019-01-16 12:32:53.712637: step 14138, loss = 0.76438 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:32:54.674502 ops/training.py:65 2019-01-16 12:32:54.674413: step 14139, loss = 0.54156 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:32:55.636943 ops/training.py:65 2019-01-16 12:32:55.636870: step 14140, loss = 0.70151 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.46875
I0832 2019-01-16 12:32:56.599445 ops/training.py:65 2019-01-16 12:32:56.599359: step 14141, loss = 0.50986 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:32:57.562175 ops/training.py:65 2019-01-16 12:32:57.562105: step 14142, loss = 0.56116 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:32:58.527458 ops/training.py:65 2019-01-16 12:32:58.527370: step 14143, loss = 0.50228 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:32:59.490941 ops/training.py:65 2019-01-16 12:32:59.490874: step 14144, loss = 0.54508 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:33:00.456154 ops/training.py:65 2019-01-16 12:33:00.456087: step 14145, loss = 0.48983 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:33:01.420365 ops/training.py:65 2019-01-16 12:33:01.420304: step 14146, loss = 0.40782 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:33:02.383935 ops/training.py:65 2019-01-16 12:33:02.383876: step 14147, loss = 0.50991 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:33:03.347478 ops/training.py:65 2019-01-16 12:33:03.347409: step 14148, loss = 0.41207 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:33:04.312248 ops/training.py:65 2019-01-16 12:33:04.312196: step 14149, loss = 0.60327 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:33:05.275929 ops/training.py:65 2019-01-16 12:33:05.275860: step 14150, loss = 0.52581 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:33:06.240066 ops/training.py:65 2019-01-16 12:33:06.239996: step 14151, loss = 0.53123 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:33:07.201644 ops/training.py:65 2019-01-16 12:33:07.201574: step 14152, loss = 0.55360 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:33:08.163655 ops/training.py:65 2019-01-16 12:33:08.163604: step 14153, loss = 0.40864 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:33:09.126201 ops/training.py:65 2019-01-16 12:33:09.126116: step 14154, loss = 0.51029 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:33:10.090125 ops/training.py:65 2019-01-16 12:33:10.090048: step 14155, loss = 0.50901 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:33:11.054295 ops/training.py:65 2019-01-16 12:33:11.054235: step 14156, loss = 0.43771 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:33:12.019004 ops/training.py:65 2019-01-16 12:33:12.018950: step 14157, loss = 0.47794 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:33:12.981391 ops/training.py:65 2019-01-16 12:33:12.981343: step 14158, loss = 0.42961 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:33:13.943454 ops/training.py:65 2019-01-16 12:33:13.943404: step 14159, loss = 0.53089 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:33:14.906747 ops/training.py:65 2019-01-16 12:33:14.906694: step 14160, loss = 0.50880 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:33:15.869601 ops/training.py:65 2019-01-16 12:33:15.869548: step 14161, loss = 0.60777 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:33:16.833571 ops/training.py:65 2019-01-16 12:33:16.833523: step 14162, loss = 0.40754 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:33:17.796548 ops/training.py:65 2019-01-16 12:33:17.796494: step 14163, loss = 0.53242 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:33:18.761504 ops/training.py:65 2019-01-16 12:33:18.761456: step 14164, loss = 0.54432 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:33:19.724938 ops/training.py:65 2019-01-16 12:33:19.724883: step 14165, loss = 0.40874 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:33:20.688543 ops/training.py:65 2019-01-16 12:33:20.688485: step 14166, loss = 0.51176 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:33:21.651224 ops/training.py:65 2019-01-16 12:33:21.651163: step 14167, loss = 0.51149 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:33:22.613513 ops/training.py:65 2019-01-16 12:33:22.613451: step 14168, loss = 0.48545 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:33:23.577956 ops/training.py:65 2019-01-16 12:33:23.577914: step 14169, loss = 0.40344 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:33:24.539883 ops/training.py:65 2019-01-16 12:33:24.539834: step 14170, loss = 0.42084 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:33:25.500568 ops/training.py:65 2019-01-16 12:33:25.500500: step 14171, loss = 0.48293 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:33:26.462603 ops/training.py:65 2019-01-16 12:33:26.462532: step 14172, loss = 0.37118 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:33:27.426688 ops/training.py:65 2019-01-16 12:33:27.426636: step 14173, loss = 0.36692 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:33:28.390036 ops/training.py:65 2019-01-16 12:33:28.389981: step 14174, loss = 0.43119 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:33:29.353297 ops/training.py:65 2019-01-16 12:33:29.353242: step 14175, loss = 0.44988 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:33:30.315519 ops/training.py:65 2019-01-16 12:33:30.315448: step 14176, loss = 0.36482 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:33:31.281145 ops/training.py:65 2019-01-16 12:33:31.281088: step 14177, loss = 0.39551 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:33:32.243746 ops/training.py:65 2019-01-16 12:33:32.243691: step 14178, loss = 0.55627 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:33:33.206502 ops/training.py:65 2019-01-16 12:33:33.206444: step 14179, loss = 0.38314 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:33:34.168335 ops/training.py:65 2019-01-16 12:33:34.168276: step 14180, loss = 0.42433 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:33:35.130800 ops/training.py:65 2019-01-16 12:33:35.130721: step 14181, loss = 0.44710 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:33:36.093344 ops/training.py:65 2019-01-16 12:33:36.093300: step 14182, loss = 0.50630 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:33:37.057812 ops/training.py:65 2019-01-16 12:33:37.057755: step 14183, loss = 0.34726 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:33:38.020097 ops/training.py:65 2019-01-16 12:33:38.020039: step 14184, loss = 0.45403 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:33:38.981307 ops/training.py:65 2019-01-16 12:33:38.981248: step 14185, loss = 0.49475 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:33:39.942693 ops/training.py:65 2019-01-16 12:33:39.942648: step 14186, loss = 0.55598 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:33:40.905450 ops/training.py:65 2019-01-16 12:33:40.905409: step 14187, loss = 0.45678 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:33:41.867786 ops/training.py:65 2019-01-16 12:33:41.867745: step 14188, loss = 0.48863 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:33:42.827760 ops/training.py:65 2019-01-16 12:33:42.827702: step 14189, loss = 0.29868 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:33:43.791054 ops/training.py:65 2019-01-16 12:33:43.790983: step 14190, loss = 0.55927 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:33:44.754438 ops/training.py:65 2019-01-16 12:33:44.754382: step 14191, loss = 0.43404 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:33:45.716617 ops/training.py:65 2019-01-16 12:33:45.716567: step 14192, loss = 0.62259 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:33:46.677167 ops/training.py:65 2019-01-16 12:33:46.677103: step 14193, loss = 0.58384 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:33:47.638937 ops/training.py:65 2019-01-16 12:33:47.638880: step 14194, loss = 0.37278 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:33:48.599946 ops/training.py:65 2019-01-16 12:33:48.599891: step 14195, loss = 0.49231 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:33:49.561364 ops/training.py:65 2019-01-16 12:33:49.561307: step 14196, loss = 0.45151 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:33:50.521943 ops/training.py:65 2019-01-16 12:33:50.521886: step 14197, loss = 0.46159 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:33:51.483434 ops/training.py:65 2019-01-16 12:33:51.483375: step 14198, loss = 0.45078 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:33:52.443985 ops/training.py:65 2019-01-16 12:33:52.443924: step 14199, loss = 0.50039 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:33:53.405980 ops/training.py:65 2019-01-16 12:33:53.405921: step 14200, loss = 0.38737 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:33:54.369136 ops/training.py:65 2019-01-16 12:33:54.369080: step 14201, loss = 0.37840 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:33:55.333396 ops/training.py:65 2019-01-16 12:33:55.333340: step 14202, loss = 0.46370 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:33:56.296509 ops/training.py:65 2019-01-16 12:33:56.296452: step 14203, loss = 0.49985 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:33:57.258180 ops/training.py:65 2019-01-16 12:33:57.258120: step 14204, loss = 0.41859 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:33:58.219905 ops/training.py:65 2019-01-16 12:33:58.219842: step 14205, loss = 0.41061 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:33:59.182993 ops/training.py:65 2019-01-16 12:33:59.182940: step 14206, loss = 0.35327 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:34:00.146074 ops/training.py:65 2019-01-16 12:34:00.146016: step 14207, loss = 0.56602 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:34:01.109943 ops/training.py:65 2019-01-16 12:34:01.109880: step 14208, loss = 0.47483 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:34:02.072899 ops/training.py:65 2019-01-16 12:34:02.072850: step 14209, loss = 0.49169 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:34:03.033881 ops/training.py:65 2019-01-16 12:34:03.033829: step 14210, loss = 0.38827 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:34:03.995354 ops/training.py:65 2019-01-16 12:34:03.995293: step 14211, loss = 0.55394 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:34:04.956478 ops/training.py:65 2019-01-16 12:34:04.956422: step 14212, loss = 0.55420 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:34:05.918104 ops/training.py:65 2019-01-16 12:34:05.918057: step 14213, loss = 0.50718 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:34:06.880467 ops/training.py:65 2019-01-16 12:34:06.880409: step 14214, loss = 0.55019 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:34:07.843255 ops/training.py:65 2019-01-16 12:34:07.843192: step 14215, loss = 0.37388 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:34:08.805399 ops/training.py:65 2019-01-16 12:34:08.805342: step 14216, loss = 0.41687 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:34:09.768523 ops/training.py:65 2019-01-16 12:34:09.768463: step 14217, loss = 0.49133 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:34:10.731786 ops/training.py:65 2019-01-16 12:34:10.731731: step 14218, loss = 0.54751 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:34:11.694577 ops/training.py:65 2019-01-16 12:34:11.694515: step 14219, loss = 0.65225 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:34:12.656663 ops/training.py:65 2019-01-16 12:34:12.656599: step 14220, loss = 0.56985 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:34:13.620484 ops/training.py:65 2019-01-16 12:34:13.620435: step 14221, loss = 0.39466 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:34:14.582012 ops/training.py:65 2019-01-16 12:34:14.581948: step 14222, loss = 0.44279 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:34:15.544777 ops/training.py:65 2019-01-16 12:34:15.544725: step 14223, loss = 0.40724 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:34:16.505285 ops/training.py:65 2019-01-16 12:34:16.505237: step 14224, loss = 0.57598 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:34:17.467092 ops/training.py:65 2019-01-16 12:34:17.467040: step 14225, loss = 0.44167 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:34:18.428956 ops/training.py:65 2019-01-16 12:34:18.428896: step 14226, loss = 0.53101 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:34:19.391197 ops/training.py:65 2019-01-16 12:34:19.391144: step 14227, loss = 0.34693 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:34:20.354761 ops/training.py:65 2019-01-16 12:34:20.354709: step 14228, loss = 0.67749 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:34:21.319160 ops/training.py:65 2019-01-16 12:34:21.319100: step 14229, loss = 0.53437 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:34:22.280800 ops/training.py:65 2019-01-16 12:34:22.280742: step 14230, loss = 0.36823 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:34:23.242261 ops/training.py:65 2019-01-16 12:34:23.242205: step 14231, loss = 0.51893 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:34:24.207202 ops/training.py:65 2019-01-16 12:34:24.207144: step 14232, loss = 0.51782 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:34:25.171112 ops/training.py:65 2019-01-16 12:34:25.171051: step 14233, loss = 0.44851 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:34:26.134742 ops/training.py:65 2019-01-16 12:34:26.134671: step 14234, loss = 0.47122 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:34:27.100783 ops/training.py:65 2019-01-16 12:34:27.100710: step 14235, loss = 0.47270 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:34:28.065636 ops/training.py:65 2019-01-16 12:34:28.065577: step 14236, loss = 0.67780 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:34:29.027183 ops/training.py:65 2019-01-16 12:34:29.027125: step 14237, loss = 0.70843 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:34:29.988739 ops/training.py:65 2019-01-16 12:34:29.988684: step 14238, loss = 0.61530 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:34:30.950546 ops/training.py:65 2019-01-16 12:34:30.950503: step 14239, loss = 0.43161 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:34:31.912076 ops/training.py:65 2019-01-16 12:34:31.912015: step 14240, loss = 0.49392 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:34:32.874732 ops/training.py:65 2019-01-16 12:34:32.874674: step 14241, loss = 0.48310 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:34:33.837246 ops/training.py:65 2019-01-16 12:34:33.837184: step 14242, loss = 0.35875 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:34:34.798977 ops/training.py:65 2019-01-16 12:34:34.798910: step 14243, loss = 0.61459 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:34:35.761028 ops/training.py:65 2019-01-16 12:34:35.760957: step 14244, loss = 0.59540 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:34:36.724391 ops/training.py:65 2019-01-16 12:34:36.724332: step 14245, loss = 0.49124 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:34:37.687332 ops/training.py:65 2019-01-16 12:34:37.687261: step 14246, loss = 0.46730 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:34:38.650437 ops/training.py:65 2019-01-16 12:34:38.650369: step 14247, loss = 0.55509 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:34:39.609765 ops/training.py:65 2019-01-16 12:34:39.609714: step 14248, loss = 0.57946 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:34:40.571059 ops/training.py:65 2019-01-16 12:34:40.570989: step 14249, loss = 0.57251 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:34:41.532446 ops/training.py:65 2019-01-16 12:34:41.532391: step 14250, loss = 0.39866 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:34:42.497948 ops/training.py:65 2019-01-16 12:34:42.497891: step 14251, loss = 0.67462 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:34:43.462185 ops/training.py:65 2019-01-16 12:34:43.462117: step 14252, loss = 0.63567 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:34:44.425593 ops/training.py:65 2019-01-16 12:34:44.425526: step 14253, loss = 0.87294 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5
I0832 2019-01-16 12:34:45.387179 ops/training.py:65 2019-01-16 12:34:45.387126: step 14254, loss = 0.58200 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:34:46.347995 ops/training.py:65 2019-01-16 12:34:46.347945: step 14255, loss = 0.51964 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:34:47.308807 ops/training.py:65 2019-01-16 12:34:47.308755: step 14256, loss = 0.47169 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:34:48.273465 ops/training.py:65 2019-01-16 12:34:48.273421: step 14257, loss = 0.56740 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:34:49.235288 ops/training.py:65 2019-01-16 12:34:49.235230: step 14258, loss = 0.44911 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:34:50.196140 ops/training.py:65 2019-01-16 12:34:50.196094: step 14259, loss = 0.49535 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:34:51.156728 ops/training.py:65 2019-01-16 12:34:51.156676: step 14260, loss = 0.40063 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:34:52.121076 ops/training.py:65 2019-01-16 12:34:52.121031: step 14261, loss = 0.56087 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:34:53.083056 ops/training.py:65 2019-01-16 12:34:53.083002: step 14262, loss = 0.56647 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:34:54.048047 ops/training.py:65 2019-01-16 12:34:54.048001: step 14263, loss = 0.40386 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:34:55.009743 ops/training.py:65 2019-01-16 12:34:55.009688: step 14264, loss = 0.46909 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:34:55.971876 ops/training.py:65 2019-01-16 12:34:55.971813: step 14265, loss = 0.41905 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:34:56.934607 ops/training.py:65 2019-01-16 12:34:56.934550: step 14266, loss = 0.58001 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:34:57.897139 ops/training.py:65 2019-01-16 12:34:57.897081: step 14267, loss = 0.52559 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:34:58.858653 ops/training.py:65 2019-01-16 12:34:58.858589: step 14268, loss = 0.50339 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:34:59.821271 ops/training.py:65 2019-01-16 12:34:59.821223: step 14269, loss = 0.54428 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:35:00.784116 ops/training.py:65 2019-01-16 12:35:00.784057: step 14270, loss = 0.60405 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:35:01.745718 ops/training.py:65 2019-01-16 12:35:01.745671: step 14271, loss = 0.46624 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:35:02.707852 ops/training.py:65 2019-01-16 12:35:02.707782: step 14272, loss = 0.52722 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:35:03.668975 ops/training.py:65 2019-01-16 12:35:03.668912: step 14273, loss = 0.60048 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:35:04.630980 ops/training.py:65 2019-01-16 12:35:04.630926: step 14274, loss = 0.50995 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:35:05.591436 ops/training.py:65 2019-01-16 12:35:05.591387: step 14275, loss = 0.52235 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:35:06.551898 ops/training.py:65 2019-01-16 12:35:06.551846: step 14276, loss = 0.57008 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:35:07.513577 ops/training.py:65 2019-01-16 12:35:07.513523: step 14277, loss = 0.57985 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:35:08.474752 ops/training.py:65 2019-01-16 12:35:08.474687: step 14278, loss = 0.49839 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:35:09.435968 ops/training.py:65 2019-01-16 12:35:09.435920: step 14279, loss = 0.53205 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:35:10.396216 ops/training.py:65 2019-01-16 12:35:10.396149: step 14280, loss = 0.52508 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:35:11.357821 ops/training.py:65 2019-01-16 12:35:11.357768: step 14281, loss = 0.52079 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:35:12.319556 ops/training.py:65 2019-01-16 12:35:12.319504: step 14282, loss = 0.48580 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:35:13.281457 ops/training.py:65 2019-01-16 12:35:13.281407: step 14283, loss = 0.50591 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:35:14.243492 ops/training.py:65 2019-01-16 12:35:14.243441: step 14284, loss = 0.43831 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:35:15.205475 ops/training.py:65 2019-01-16 12:35:15.205415: step 14285, loss = 0.49521 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:35:16.166577 ops/training.py:65 2019-01-16 12:35:16.166501: step 14286, loss = 0.50208 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:35:17.127547 ops/training.py:65 2019-01-16 12:35:17.127479: step 14287, loss = 0.50007 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:35:18.088039 ops/training.py:65 2019-01-16 12:35:18.087969: step 14288, loss = 0.55525 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:35:19.047523 ops/training.py:65 2019-01-16 12:35:19.047450: step 14289, loss = 0.57387 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:35:20.007242 ops/training.py:65 2019-01-16 12:35:20.007190: step 14290, loss = 0.45950 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:35:20.969887 ops/training.py:65 2019-01-16 12:35:20.969838: step 14291, loss = 0.55159 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:35:21.931228 ops/training.py:65 2019-01-16 12:35:21.931174: step 14292, loss = 0.46023 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:35:22.892797 ops/training.py:65 2019-01-16 12:35:22.892745: step 14293, loss = 0.46846 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:35:23.854881 ops/training.py:65 2019-01-16 12:35:23.854825: step 14294, loss = 0.57102 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:35:24.816972 ops/training.py:65 2019-01-16 12:35:24.816921: step 14295, loss = 0.53392 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:35:25.777875 ops/training.py:65 2019-01-16 12:35:25.777819: step 14296, loss = 0.54092 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:35:26.742676 ops/training.py:65 2019-01-16 12:35:26.742626: step 14297, loss = 0.64663 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:35:27.706601 ops/training.py:65 2019-01-16 12:35:27.706553: step 14298, loss = 0.48864 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:35:28.669250 ops/training.py:65 2019-01-16 12:35:28.669201: step 14299, loss = 0.34794 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:35:29.630347 ops/training.py:65 2019-01-16 12:35:29.630294: step 14300, loss = 0.36621 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:35:30.591499 ops/training.py:65 2019-01-16 12:35:30.591432: step 14301, loss = 0.34304 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:35:31.552935 ops/training.py:65 2019-01-16 12:35:31.552863: step 14302, loss = 0.38153 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:35:32.513536 ops/training.py:65 2019-01-16 12:35:32.513470: step 14303, loss = 0.40280 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:35:33.475351 ops/training.py:65 2019-01-16 12:35:33.475298: step 14304, loss = 0.39332 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:35:34.439856 ops/training.py:65 2019-01-16 12:35:34.439789: step 14305, loss = 0.46789 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:35:35.403688 ops/training.py:65 2019-01-16 12:35:35.403614: step 14306, loss = 0.52719 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:35:36.366565 ops/training.py:65 2019-01-16 12:35:36.366475: step 14307, loss = 0.53813 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:35:37.327831 ops/training.py:65 2019-01-16 12:35:37.327784: step 14308, loss = 0.40542 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:35:38.292567 ops/training.py:65 2019-01-16 12:35:38.292515: step 14309, loss = 0.51719 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:35:39.255598 ops/training.py:65 2019-01-16 12:35:39.255550: step 14310, loss = 0.59529 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:35:40.219334 ops/training.py:65 2019-01-16 12:35:40.219287: step 14311, loss = 0.56301 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:35:41.181918 ops/training.py:65 2019-01-16 12:35:41.181844: step 14312, loss = 0.54994 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:35:42.143087 ops/training.py:65 2019-01-16 12:35:42.143034: step 14313, loss = 0.33779 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:35:43.104157 ops/training.py:65 2019-01-16 12:35:43.104106: step 14314, loss = 0.55966 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:35:44.067259 ops/training.py:65 2019-01-16 12:35:44.067210: step 14315, loss = 0.47816 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:35:45.028797 ops/training.py:65 2019-01-16 12:35:45.028745: step 14316, loss = 0.45740 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:35:45.989615 ops/training.py:65 2019-01-16 12:35:45.989564: step 14317, loss = 0.46644 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:35:46.950516 ops/training.py:65 2019-01-16 12:35:46.950465: step 14318, loss = 0.47561 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:35:47.913436 ops/training.py:65 2019-01-16 12:35:47.913383: step 14319, loss = 0.47213 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:35:48.875601 ops/training.py:65 2019-01-16 12:35:48.875546: step 14320, loss = 0.55984 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:35:49.838774 ops/training.py:65 2019-01-16 12:35:49.838717: step 14321, loss = 0.49154 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:35:50.803587 ops/training.py:65 2019-01-16 12:35:50.803520: step 14322, loss = 0.50697 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:35:51.767436 ops/training.py:65 2019-01-16 12:35:51.767385: step 14323, loss = 0.54645 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:35:52.729001 ops/training.py:65 2019-01-16 12:35:52.728954: step 14324, loss = 0.57229 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:35:53.690156 ops/training.py:65 2019-01-16 12:35:53.690105: step 14325, loss = 0.44358 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:35:54.652538 ops/training.py:65 2019-01-16 12:35:54.652487: step 14326, loss = 0.57807 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:35:55.613937 ops/training.py:65 2019-01-16 12:35:55.613883: step 14327, loss = 0.45070 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:35:56.576215 ops/training.py:65 2019-01-16 12:35:56.576158: step 14328, loss = 0.53414 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:35:57.536920 ops/training.py:65 2019-01-16 12:35:57.536874: step 14329, loss = 0.55276 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:35:58.501408 ops/training.py:65 2019-01-16 12:35:58.501344: step 14330, loss = 0.45692 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:35:59.465963 ops/training.py:65 2019-01-16 12:35:59.465894: step 14331, loss = 0.52823 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:36:00.429106 ops/training.py:65 2019-01-16 12:36:00.429041: step 14332, loss = 0.47253 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:36:01.390390 ops/training.py:65 2019-01-16 12:36:01.390325: step 14333, loss = 0.45681 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:36:02.351612 ops/training.py:65 2019-01-16 12:36:02.351565: step 14334, loss = 0.42326 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:36:03.314715 ops/training.py:65 2019-01-16 12:36:03.314663: step 14335, loss = 0.43364 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:36:04.277142 ops/training.py:65 2019-01-16 12:36:04.277072: step 14336, loss = 0.45753 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:36:05.240356 ops/training.py:65 2019-01-16 12:36:05.240315: step 14337, loss = 0.33824 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:36:06.203427 ops/training.py:65 2019-01-16 12:36:06.203360: step 14338, loss = 0.52710 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:36:07.166494 ops/training.py:65 2019-01-16 12:36:07.166442: step 14339, loss = 0.49233 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:36:08.128310 ops/training.py:65 2019-01-16 12:36:08.128259: step 14340, loss = 0.46800 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:36:09.089599 ops/training.py:65 2019-01-16 12:36:09.089553: step 14341, loss = 0.46701 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:36:10.051465 ops/training.py:65 2019-01-16 12:36:10.051411: step 14342, loss = 0.57687 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:36:11.012665 ops/training.py:65 2019-01-16 12:36:11.012602: step 14343, loss = 0.67206 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:36:11.974787 ops/training.py:65 2019-01-16 12:36:11.974733: step 14344, loss = 0.38763 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:36:12.935660 ops/training.py:65 2019-01-16 12:36:12.935605: step 14345, loss = 0.46973 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:36:13.897298 ops/training.py:65 2019-01-16 12:36:13.897230: step 14346, loss = 0.39059 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:36:14.858232 ops/training.py:65 2019-01-16 12:36:14.858161: step 14347, loss = 0.65560 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:36:15.824047 ops/training.py:65 2019-01-16 12:36:15.823977: step 14348, loss = 0.58762 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:36:16.785959 ops/training.py:65 2019-01-16 12:36:16.785910: step 14349, loss = 0.50763 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:36:17.748576 ops/training.py:65 2019-01-16 12:36:17.748508: step 14350, loss = 0.56616 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:36:18.713012 ops/training.py:65 2019-01-16 12:36:18.712947: step 14351, loss = 0.61203 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:36:19.676709 ops/training.py:65 2019-01-16 12:36:19.676644: step 14352, loss = 0.60597 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:36:20.637963 ops/training.py:65 2019-01-16 12:36:20.637913: step 14353, loss = 0.48248 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:36:21.599472 ops/training.py:65 2019-01-16 12:36:21.599423: step 14354, loss = 0.57701 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:36:22.562108 ops/training.py:65 2019-01-16 12:36:22.562054: step 14355, loss = 0.65498 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:36:23.523531 ops/training.py:65 2019-01-16 12:36:23.523479: step 14356, loss = 0.61591 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:36:24.485262 ops/training.py:65 2019-01-16 12:36:24.485215: step 14357, loss = 0.41294 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:36:25.446944 ops/training.py:65 2019-01-16 12:36:25.446875: step 14358, loss = 0.58827 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:36:26.412168 ops/training.py:65 2019-01-16 12:36:26.412106: step 14359, loss = 0.52119 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:36:27.377858 ops/training.py:65 2019-01-16 12:36:27.377806: step 14360, loss = 0.45050 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:36:28.342193 ops/training.py:65 2019-01-16 12:36:28.342145: step 14361, loss = 0.60370 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:36:29.304942 ops/training.py:65 2019-01-16 12:36:29.304874: step 14362, loss = 0.45130 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:36:30.265489 ops/training.py:65 2019-01-16 12:36:30.265424: step 14363, loss = 0.40438 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:36:31.227291 ops/training.py:65 2019-01-16 12:36:31.227216: step 14364, loss = 0.61162 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:36:32.189719 ops/training.py:65 2019-01-16 12:36:32.189669: step 14365, loss = 0.47272 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:36:33.154572 ops/training.py:65 2019-01-16 12:36:33.154522: step 14366, loss = 0.50607 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:36:34.118784 ops/training.py:65 2019-01-16 12:36:34.118734: step 14367, loss = 0.52400 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:36:35.082620 ops/training.py:65 2019-01-16 12:36:35.082574: step 14368, loss = 0.44788 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:36:36.045269 ops/training.py:65 2019-01-16 12:36:36.045196: step 14369, loss = 0.44107 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:36:37.007930 ops/training.py:65 2019-01-16 12:36:37.007863: step 14370, loss = 0.48006 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:36:37.969715 ops/training.py:65 2019-01-16 12:36:37.969664: step 14371, loss = 0.52077 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:36:38.930919 ops/training.py:65 2019-01-16 12:36:38.930873: step 14372, loss = 0.48686 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:36:39.892962 ops/training.py:65 2019-01-16 12:36:39.892913: step 14373, loss = 0.56647 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:36:40.855370 ops/training.py:65 2019-01-16 12:36:40.855300: step 14374, loss = 0.48649 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:36:41.821178 ops/training.py:65 2019-01-16 12:36:41.821119: step 14375, loss = 0.48282 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:36:42.783929 ops/training.py:65 2019-01-16 12:36:42.783858: step 14376, loss = 0.46398 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:36:43.748368 ops/training.py:65 2019-01-16 12:36:43.748317: step 14377, loss = 0.40470 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:36:44.711843 ops/training.py:65 2019-01-16 12:36:44.711792: step 14378, loss = 0.54196 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:36:45.675443 ops/training.py:65 2019-01-16 12:36:45.675390: step 14379, loss = 0.50316 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:36:46.637781 ops/training.py:65 2019-01-16 12:36:46.637732: step 14380, loss = 0.42900 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:36:47.599625 ops/training.py:65 2019-01-16 12:36:47.599572: step 14381, loss = 0.57790 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:36:48.561076 ops/training.py:65 2019-01-16 12:36:48.561028: step 14382, loss = 0.38295 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:36:49.522114 ops/training.py:65 2019-01-16 12:36:49.522062: step 14383, loss = 0.46814 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:36:50.484413 ops/training.py:65 2019-01-16 12:36:50.484366: step 14384, loss = 0.50729 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:36:51.445928 ops/training.py:65 2019-01-16 12:36:51.445880: step 14385, loss = 0.39405 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:36:52.408118 ops/training.py:65 2019-01-16 12:36:52.408070: step 14386, loss = 0.61879 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:36:53.369265 ops/training.py:65 2019-01-16 12:36:53.369206: step 14387, loss = 0.42761 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:36:54.329957 ops/training.py:65 2019-01-16 12:36:54.329884: step 14388, loss = 0.55076 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:36:55.290524 ops/training.py:65 2019-01-16 12:36:55.290457: step 14389, loss = 0.36146 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:36:56.251066 ops/training.py:65 2019-01-16 12:36:56.251015: step 14390, loss = 0.51655 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:36:57.212646 ops/training.py:65 2019-01-16 12:36:57.212592: step 14391, loss = 0.58058 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:36:58.175107 ops/training.py:65 2019-01-16 12:36:58.175059: step 14392, loss = 0.51173 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:36:59.136576 ops/training.py:65 2019-01-16 12:36:59.136526: step 14393, loss = 0.65625 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:37:00.098996 ops/training.py:65 2019-01-16 12:37:00.098943: step 14394, loss = 0.38445 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:37:01.064028 ops/training.py:65 2019-01-16 12:37:01.063975: step 14395, loss = 0.46140 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:37:02.027372 ops/training.py:65 2019-01-16 12:37:02.027321: step 14396, loss = 0.46225 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:37:02.991364 ops/training.py:65 2019-01-16 12:37:02.991298: step 14397, loss = 0.45147 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:37:03.955759 ops/training.py:65 2019-01-16 12:37:03.955703: step 14398, loss = 0.56080 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:37:04.917666 ops/training.py:65 2019-01-16 12:37:04.917601: step 14399, loss = 0.52274 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:37:05.883660 ops/training.py:65 2019-01-16 12:37:05.883596: step 14400, loss = 0.42937 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:37:06.848083 ops/training.py:65 2019-01-16 12:37:06.848013: step 14401, loss = 0.41506 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:37:07.812966 ops/training.py:65 2019-01-16 12:37:07.812912: step 14402, loss = 0.50668 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:37:08.775137 ops/training.py:65 2019-01-16 12:37:08.775088: step 14403, loss = 0.39167 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:37:09.736275 ops/training.py:65 2019-01-16 12:37:09.736220: step 14404, loss = 0.57766 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:37:10.697728 ops/training.py:65 2019-01-16 12:37:10.697673: step 14405, loss = 0.57529 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:37:11.659686 ops/training.py:65 2019-01-16 12:37:11.659625: step 14406, loss = 0.50856 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:37:12.620643 ops/training.py:65 2019-01-16 12:37:12.620588: step 14407, loss = 0.46206 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:37:13.582573 ops/training.py:65 2019-01-16 12:37:13.582502: step 14408, loss = 0.66197 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:37:14.544690 ops/training.py:65 2019-01-16 12:37:14.544615: step 14409, loss = 0.49774 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:37:15.509781 ops/training.py:65 2019-01-16 12:37:15.509731: step 14410, loss = 0.37324 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:37:16.473141 ops/training.py:65 2019-01-16 12:37:16.473088: step 14411, loss = 0.48975 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:37:17.434918 ops/training.py:65 2019-01-16 12:37:17.434867: step 14412, loss = 0.53643 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:37:18.396201 ops/training.py:65 2019-01-16 12:37:18.396153: step 14413, loss = 0.53608 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:37:19.358322 ops/training.py:65 2019-01-16 12:37:19.358269: step 14414, loss = 0.44440 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:37:20.319564 ops/training.py:65 2019-01-16 12:37:20.319515: step 14415, loss = 0.56132 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:37:21.284674 ops/training.py:65 2019-01-16 12:37:21.284625: step 14416, loss = 0.57362 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:37:22.248360 ops/training.py:65 2019-01-16 12:37:22.248301: step 14417, loss = 0.42730 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:37:23.211741 ops/training.py:65 2019-01-16 12:37:23.211669: step 14418, loss = 0.43532 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:37:24.173546 ops/training.py:65 2019-01-16 12:37:24.173499: step 14419, loss = 0.48452 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:37:25.135280 ops/training.py:65 2019-01-16 12:37:25.135204: step 14420, loss = 0.56589 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:37:26.097408 ops/training.py:65 2019-01-16 12:37:26.097330: step 14421, loss = 0.53621 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:37:27.059127 ops/training.py:65 2019-01-16 12:37:27.059041: step 14422, loss = 0.42191 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:37:28.021349 ops/training.py:65 2019-01-16 12:37:28.021278: step 14423, loss = 0.61412 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:37:28.983423 ops/training.py:65 2019-01-16 12:37:28.983366: step 14424, loss = 0.41222 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:37:29.944959 ops/training.py:65 2019-01-16 12:37:29.944890: step 14425, loss = 0.44607 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:37:30.907453 ops/training.py:65 2019-01-16 12:37:30.907387: step 14426, loss = 0.56884 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:37:31.869092 ops/training.py:65 2019-01-16 12:37:31.869044: step 14427, loss = 0.57953 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:37:32.830955 ops/training.py:65 2019-01-16 12:37:32.830902: step 14428, loss = 0.41042 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:37:33.792280 ops/training.py:65 2019-01-16 12:37:33.792234: step 14429, loss = 0.61567 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:37:34.753711 ops/training.py:65 2019-01-16 12:37:34.753656: step 14430, loss = 0.45633 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:37:35.716397 ops/training.py:65 2019-01-16 12:37:35.716344: step 14431, loss = 0.37207 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:37:36.681878 ops/training.py:65 2019-01-16 12:37:36.681827: step 14432, loss = 0.38088 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:37:37.646040 ops/training.py:65 2019-01-16 12:37:37.645991: step 14433, loss = 0.57957 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:37:38.609205 ops/training.py:65 2019-01-16 12:37:38.609153: step 14434, loss = 0.54447 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:37:39.572010 ops/training.py:65 2019-01-16 12:37:39.571963: step 14435, loss = 0.38004 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:37:40.534590 ops/training.py:65 2019-01-16 12:37:40.534538: step 14436, loss = 0.51216 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:37:41.496091 ops/training.py:65 2019-01-16 12:37:41.496035: step 14437, loss = 0.43439 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:37:42.460150 ops/training.py:65 2019-01-16 12:37:42.460103: step 14438, loss = 0.55338 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:37:43.425268 ops/training.py:65 2019-01-16 12:37:43.425218: step 14439, loss = 0.51478 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:37:44.389029 ops/training.py:65 2019-01-16 12:37:44.388976: step 14440, loss = 0.51875 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:37:45.350795 ops/training.py:65 2019-01-16 12:37:45.350746: step 14441, loss = 0.33916 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:37:46.312281 ops/training.py:65 2019-01-16 12:37:46.312229: step 14442, loss = 0.51385 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:37:47.273209 ops/training.py:65 2019-01-16 12:37:47.273137: step 14443, loss = 0.46966 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:37:48.235037 ops/training.py:65 2019-01-16 12:37:48.234972: step 14444, loss = 0.56269 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:37:49.198956 ops/training.py:65 2019-01-16 12:37:49.198907: step 14445, loss = 0.51701 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:37:50.163044 ops/training.py:65 2019-01-16 12:37:50.162997: step 14446, loss = 0.40255 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:37:51.126498 ops/training.py:65 2019-01-16 12:37:51.126450: step 14447, loss = 0.56733 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:37:52.088299 ops/training.py:65 2019-01-16 12:37:52.088249: step 14448, loss = 0.47175 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:37:53.049383 ops/training.py:65 2019-01-16 12:37:53.049331: step 14449, loss = 0.55356 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:37:54.009767 ops/training.py:65 2019-01-16 12:37:54.009719: step 14450, loss = 0.42786 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:37:54.973518 ops/training.py:65 2019-01-16 12:37:54.973469: step 14451, loss = 0.38424 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:37:55.937631 ops/training.py:65 2019-01-16 12:37:55.937577: step 14452, loss = 0.38096 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:37:56.901862 ops/training.py:65 2019-01-16 12:37:56.901810: step 14453, loss = 0.40275 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:37:57.863871 ops/training.py:65 2019-01-16 12:37:57.863824: step 14454, loss = 0.54839 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:37:58.825525 ops/training.py:65 2019-01-16 12:37:58.825474: step 14455, loss = 0.48424 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:37:59.787990 ops/training.py:65 2019-01-16 12:37:59.787937: step 14456, loss = 0.45107 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:38:00.749566 ops/training.py:65 2019-01-16 12:38:00.749512: step 14457, loss = 0.42435 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:38:01.710935 ops/training.py:65 2019-01-16 12:38:01.710886: step 14458, loss = 0.45857 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:38:02.671133 ops/training.py:65 2019-01-16 12:38:02.671081: step 14459, loss = 0.72254 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:38:03.631762 ops/training.py:65 2019-01-16 12:38:03.631712: step 14460, loss = 0.41848 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:38:04.596270 ops/training.py:65 2019-01-16 12:38:04.596217: step 14461, loss = 0.50849 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:38:05.561051 ops/training.py:65 2019-01-16 12:38:05.561003: step 14462, loss = 0.44858 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:38:06.524216 ops/training.py:65 2019-01-16 12:38:06.524166: step 14463, loss = 0.45458 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:38:07.485486 ops/training.py:65 2019-01-16 12:38:07.485438: step 14464, loss = 0.40521 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:38:08.446519 ops/training.py:65 2019-01-16 12:38:08.446474: step 14465, loss = 0.57778 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:38:09.407732 ops/training.py:65 2019-01-16 12:38:09.407682: step 14466, loss = 0.57443 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:38:10.368828 ops/training.py:65 2019-01-16 12:38:10.368774: step 14467, loss = 0.56471 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:38:11.330966 ops/training.py:65 2019-01-16 12:38:11.330897: step 14468, loss = 0.39887 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:38:12.291774 ops/training.py:65 2019-01-16 12:38:12.291728: step 14469, loss = 0.51903 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:38:13.254023 ops/training.py:65 2019-01-16 12:38:13.253971: step 14470, loss = 0.61604 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:38:14.215698 ops/training.py:65 2019-01-16 12:38:14.215646: step 14471, loss = 0.54799 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:38:15.177295 ops/training.py:65 2019-01-16 12:38:15.177243: step 14472, loss = 0.37024 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:38:16.139208 ops/training.py:65 2019-01-16 12:38:16.139161: step 14473, loss = 0.55573 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:38:17.100526 ops/training.py:65 2019-01-16 12:38:17.100477: step 14474, loss = 0.53647 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:38:18.062655 ops/training.py:65 2019-01-16 12:38:18.062606: step 14475, loss = 0.67636 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:38:19.024811 ops/training.py:65 2019-01-16 12:38:19.024763: step 14476, loss = 0.45429 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:38:19.986347 ops/training.py:65 2019-01-16 12:38:19.986299: step 14477, loss = 0.49116 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:38:20.947425 ops/training.py:65 2019-01-16 12:38:20.947374: step 14478, loss = 0.45095 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:38:21.908810 ops/training.py:65 2019-01-16 12:38:21.908760: step 14479, loss = 0.41248 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:38:22.869600 ops/training.py:65 2019-01-16 12:38:22.869545: step 14480, loss = 0.64726 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:38:23.829623 ops/training.py:65 2019-01-16 12:38:23.829573: step 14481, loss = 0.48141 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:38:24.794739 ops/training.py:65 2019-01-16 12:38:24.794687: step 14482, loss = 0.50381 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:38:25.759540 ops/training.py:65 2019-01-16 12:38:25.759482: step 14483, loss = 0.48316 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:38:26.723086 ops/training.py:65 2019-01-16 12:38:26.723013: step 14484, loss = 0.58407 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:38:27.685989 ops/training.py:65 2019-01-16 12:38:27.685942: step 14485, loss = 0.56611 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:38:28.647678 ops/training.py:65 2019-01-16 12:38:28.647627: step 14486, loss = 0.43309 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:38:29.610238 ops/training.py:65 2019-01-16 12:38:29.610187: step 14487, loss = 0.56345 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:38:30.571335 ops/training.py:65 2019-01-16 12:38:30.571281: step 14488, loss = 0.47135 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:38:31.534204 ops/training.py:65 2019-01-16 12:38:31.534152: step 14489, loss = 0.32521 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:38:32.496716 ops/training.py:65 2019-01-16 12:38:32.496665: step 14490, loss = 0.50341 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:38:33.456886 ops/training.py:65 2019-01-16 12:38:33.456838: step 14491, loss = 0.47633 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:38:34.421778 ops/training.py:65 2019-01-16 12:38:34.421723: step 14492, loss = 0.46774 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:38:35.386853 ops/training.py:65 2019-01-16 12:38:35.386801: step 14493, loss = 0.38149 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:38:36.350068 ops/training.py:65 2019-01-16 12:38:36.350017: step 14494, loss = 0.51269 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:38:37.310998 ops/training.py:65 2019-01-16 12:38:37.310950: step 14495, loss = 0.40398 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:38:38.272661 ops/training.py:65 2019-01-16 12:38:38.272599: step 14496, loss = 0.42067 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:38:39.235539 ops/training.py:65 2019-01-16 12:38:39.235467: step 14497, loss = 0.42326 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:38:40.197049 ops/training.py:65 2019-01-16 12:38:40.196994: step 14498, loss = 0.53293 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:38:41.159939 ops/training.py:65 2019-01-16 12:38:41.159870: step 14499, loss = 0.48575 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:38:42.122475 ops/training.py:65 2019-01-16 12:38:42.122398: step 14500, loss = 0.44706 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:38:43.084860 ops/training.py:65 2019-01-16 12:38:43.084810: step 14501, loss = 0.48306 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:38:44.046857 ops/training.py:65 2019-01-16 12:38:44.046804: step 14502, loss = 0.36945 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:38:45.008312 ops/training.py:65 2019-01-16 12:38:45.008258: step 14503, loss = 0.51824 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:38:45.970296 ops/training.py:65 2019-01-16 12:38:45.970242: step 14504, loss = 0.36357 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:38:46.932111 ops/training.py:65 2019-01-16 12:38:46.932043: step 14505, loss = 0.37111 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:38:47.897919 ops/training.py:65 2019-01-16 12:38:47.897853: step 14506, loss = 0.50165 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:38:48.862134 ops/training.py:65 2019-01-16 12:38:48.862086: step 14507, loss = 0.50599 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:38:49.825453 ops/training.py:65 2019-01-16 12:38:49.825381: step 14508, loss = 0.44003 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:38:50.787196 ops/training.py:65 2019-01-16 12:38:50.787105: step 14509, loss = 0.59979 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:38:51.748729 ops/training.py:65 2019-01-16 12:38:51.748677: step 14510, loss = 0.66013 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:38:52.710190 ops/training.py:65 2019-01-16 12:38:52.710144: step 14511, loss = 0.50176 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:38:53.670750 ops/training.py:65 2019-01-16 12:38:53.670701: step 14512, loss = 0.40274 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:38:54.632495 ops/training.py:65 2019-01-16 12:38:54.632441: step 14513, loss = 0.46865 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:38:55.594710 ops/training.py:65 2019-01-16 12:38:55.594654: step 14514, loss = 0.45171 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:38:56.555984 ops/training.py:65 2019-01-16 12:38:56.555931: step 14515, loss = 0.41321 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:38:57.520607 ops/training.py:65 2019-01-16 12:38:57.520558: step 14516, loss = 0.40149 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:38:58.484672 ops/training.py:65 2019-01-16 12:38:58.484621: step 14517, loss = 0.38094 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:38:59.447505 ops/training.py:65 2019-01-16 12:38:59.447454: step 14518, loss = 0.37511 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:39:00.408483 ops/training.py:65 2019-01-16 12:39:00.408429: step 14519, loss = 0.33163 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:39:01.373524 ops/training.py:65 2019-01-16 12:39:01.373475: step 14520, loss = 0.48357 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:39:02.335158 ops/training.py:65 2019-01-16 12:39:02.335103: step 14521, loss = 0.44012 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:39:03.300892 ops/training.py:65 2019-01-16 12:39:03.300835: step 14522, loss = 0.59928 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:39:04.264722 ops/training.py:65 2019-01-16 12:39:04.264651: step 14523, loss = 0.47416 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:39:05.226624 ops/training.py:65 2019-01-16 12:39:05.226553: step 14524, loss = 0.37340 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:39:06.192103 ops/training.py:65 2019-01-16 12:39:06.192037: step 14525, loss = 0.33071 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:39:07.155787 ops/training.py:65 2019-01-16 12:39:07.155734: step 14526, loss = 0.41547 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:39:08.118960 ops/training.py:65 2019-01-16 12:39:08.118915: step 14527, loss = 0.45046 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:39:09.080703 ops/training.py:65 2019-01-16 12:39:09.080655: step 14528, loss = 0.70360 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:39:10.042235 ops/training.py:65 2019-01-16 12:39:10.042184: step 14529, loss = 0.55264 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:39:11.004248 ops/training.py:65 2019-01-16 12:39:11.004198: step 14530, loss = 0.39792 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:39:11.966760 ops/training.py:65 2019-01-16 12:39:11.966687: step 14531, loss = 0.60478 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:39:12.929989 ops/training.py:65 2019-01-16 12:39:12.929916: step 14532, loss = 0.40501 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:39:13.892278 ops/training.py:65 2019-01-16 12:39:13.892228: step 14533, loss = 0.40902 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:39:14.854185 ops/training.py:65 2019-01-16 12:39:14.854133: step 14534, loss = 0.57834 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:39:15.815350 ops/training.py:65 2019-01-16 12:39:15.815304: step 14535, loss = 0.48007 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:39:16.777009 ops/training.py:65 2019-01-16 12:39:16.776957: step 14536, loss = 0.56500 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:39:17.739047 ops/training.py:65 2019-01-16 12:39:17.738994: step 14537, loss = 0.39329 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:39:18.705641 ops/training.py:65 2019-01-16 12:39:18.705590: step 14538, loss = 0.49801 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:39:19.669727 ops/training.py:65 2019-01-16 12:39:19.669658: step 14539, loss = 0.53518 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:39:20.633415 ops/training.py:65 2019-01-16 12:39:20.633345: step 14540, loss = 0.52013 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:39:21.594999 ops/training.py:65 2019-01-16 12:39:21.594927: step 14541, loss = 0.44357 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:39:22.556786 ops/training.py:65 2019-01-16 12:39:22.556737: step 14542, loss = 0.47124 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:39:23.518908 ops/training.py:65 2019-01-16 12:39:23.518851: step 14543, loss = 0.45530 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:39:24.481638 ops/training.py:65 2019-01-16 12:39:24.481587: step 14544, loss = 0.56116 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:39:25.443644 ops/training.py:65 2019-01-16 12:39:25.443589: step 14545, loss = 0.45275 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:39:26.404858 ops/training.py:65 2019-01-16 12:39:26.404803: step 14546, loss = 0.38704 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:39:27.366562 ops/training.py:65 2019-01-16 12:39:27.366509: step 14547, loss = 0.41464 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:39:28.331639 ops/training.py:65 2019-01-16 12:39:28.331591: step 14548, loss = 0.51158 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:39:29.296290 ops/training.py:65 2019-01-16 12:39:29.296241: step 14549, loss = 0.52957 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:39:30.258106 ops/training.py:65 2019-01-16 12:39:30.258054: step 14550, loss = 0.48289 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:39:31.223325 ops/training.py:65 2019-01-16 12:39:31.223276: step 14551, loss = 0.54830 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:39:32.188718 ops/training.py:65 2019-01-16 12:39:32.188668: step 14552, loss = 0.38171 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:39:33.151928 ops/training.py:65 2019-01-16 12:39:33.151876: step 14553, loss = 0.61763 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:39:34.113042 ops/training.py:65 2019-01-16 12:39:34.112990: step 14554, loss = 0.43616 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:39:35.074320 ops/training.py:65 2019-01-16 12:39:35.074270: step 14555, loss = 0.42062 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:39:36.039313 ops/training.py:65 2019-01-16 12:39:36.039261: step 14556, loss = 0.56077 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:39:37.003295 ops/training.py:65 2019-01-16 12:39:37.003243: step 14557, loss = 0.51229 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:39:37.967527 ops/training.py:65 2019-01-16 12:39:37.967481: step 14558, loss = 0.38132 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:39:38.930548 ops/training.py:65 2019-01-16 12:39:38.930498: step 14559, loss = 0.44006 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:39:39.892172 ops/training.py:65 2019-01-16 12:39:39.892117: step 14560, loss = 0.42448 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:39:40.852891 ops/training.py:65 2019-01-16 12:39:40.852839: step 14561, loss = 0.44012 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:39:41.813694 ops/training.py:65 2019-01-16 12:39:41.813647: step 14562, loss = 0.58629 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:39:42.774932 ops/training.py:65 2019-01-16 12:39:42.774879: step 14563, loss = 0.39368 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:39:43.737645 ops/training.py:65 2019-01-16 12:39:43.737594: step 14564, loss = 0.52572 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:39:44.700076 ops/training.py:65 2019-01-16 12:39:44.700022: step 14565, loss = 0.57189 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:39:45.660594 ops/training.py:65 2019-01-16 12:39:45.660540: step 14566, loss = 0.50375 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:39:46.621710 ops/training.py:65 2019-01-16 12:39:46.621658: step 14567, loss = 0.55957 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:39:47.582935 ops/training.py:65 2019-01-16 12:39:47.582883: step 14568, loss = 0.39668 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:39:48.544764 ops/training.py:65 2019-01-16 12:39:48.544718: step 14569, loss = 0.59212 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:39:49.505284 ops/training.py:65 2019-01-16 12:39:49.505236: step 14570, loss = 0.65670 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:39:50.466398 ops/training.py:65 2019-01-16 12:39:50.466340: step 14571, loss = 0.40659 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:39:51.428993 ops/training.py:65 2019-01-16 12:39:51.428933: step 14572, loss = 0.62737 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:39:52.390748 ops/training.py:65 2019-01-16 12:39:52.390695: step 14573, loss = 0.50903 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:39:53.352652 ops/training.py:65 2019-01-16 12:39:53.352606: step 14574, loss = 0.35850 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:39:54.313902 ops/training.py:65 2019-01-16 12:39:54.313844: step 14575, loss = 0.36571 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:39:55.275259 ops/training.py:65 2019-01-16 12:39:55.275206: step 14576, loss = 0.47241 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:39:56.236315 ops/training.py:65 2019-01-16 12:39:56.236265: step 14577, loss = 0.47354 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:39:57.197715 ops/training.py:65 2019-01-16 12:39:57.197644: step 14578, loss = 0.30614 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:39:58.159984 ops/training.py:65 2019-01-16 12:39:58.159908: step 14579, loss = 0.38949 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:39:59.120408 ops/training.py:65 2019-01-16 12:39:59.120344: step 14580, loss = 0.51274 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:40:00.081448 ops/training.py:65 2019-01-16 12:40:00.081386: step 14581, loss = 0.40994 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:40:01.042507 ops/training.py:65 2019-01-16 12:40:01.042457: step 14582, loss = 0.43746 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:40:02.003098 ops/training.py:65 2019-01-16 12:40:02.003042: step 14583, loss = 0.40775 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:40:02.964189 ops/training.py:65 2019-01-16 12:40:02.964119: step 14584, loss = 0.44369 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:40:03.926963 ops/training.py:65 2019-01-16 12:40:03.926897: step 14585, loss = 0.54899 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:40:04.890769 ops/training.py:65 2019-01-16 12:40:04.890718: step 14586, loss = 0.56265 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:40:05.854186 ops/training.py:65 2019-01-16 12:40:05.854133: step 14587, loss = 0.55383 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:40:06.818235 ops/training.py:65 2019-01-16 12:40:06.818181: step 14588, loss = 0.53542 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:40:07.779710 ops/training.py:65 2019-01-16 12:40:07.779665: step 14589, loss = 0.51368 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:40:08.740976 ops/training.py:65 2019-01-16 12:40:08.740927: step 14590, loss = 0.51060 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:40:09.702060 ops/training.py:65 2019-01-16 12:40:09.702009: step 14591, loss = 0.53866 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:40:10.663599 ops/training.py:65 2019-01-16 12:40:10.663536: step 14592, loss = 0.52137 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:40:11.624958 ops/training.py:65 2019-01-16 12:40:11.624892: step 14593, loss = 0.48134 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:40:12.586809 ops/training.py:65 2019-01-16 12:40:12.586738: step 14594, loss = 0.52115 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:40:13.548392 ops/training.py:65 2019-01-16 12:40:13.548340: step 14595, loss = 0.40253 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:40:14.509515 ops/training.py:65 2019-01-16 12:40:14.509464: step 14596, loss = 0.52457 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:40:15.470903 ops/training.py:65 2019-01-16 12:40:15.470856: step 14597, loss = 0.44717 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:40:16.436885 ops/training.py:65 2019-01-16 12:40:16.436834: step 14598, loss = 0.47501 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:40:17.401380 ops/training.py:65 2019-01-16 12:40:17.401330: step 14599, loss = 0.48529 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:40:18.366027 ops/training.py:65 2019-01-16 12:40:18.365976: step 14600, loss = 0.44168 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:40:19.328823 ops/training.py:65 2019-01-16 12:40:19.328776: step 14601, loss = 0.55927 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:40:20.290531 ops/training.py:65 2019-01-16 12:40:20.290477: step 14602, loss = 0.37349 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:40:21.251716 ops/training.py:65 2019-01-16 12:40:21.251666: step 14603, loss = 0.60911 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:40:22.212692 ops/training.py:65 2019-01-16 12:40:22.212642: step 14604, loss = 0.50515 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:40:23.175100 ops/training.py:65 2019-01-16 12:40:23.175053: step 14605, loss = 0.46626 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:40:24.136792 ops/training.py:65 2019-01-16 12:40:24.136744: step 14606, loss = 0.44081 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:40:25.097644 ops/training.py:65 2019-01-16 12:40:25.097592: step 14607, loss = 0.45117 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:40:26.058407 ops/training.py:65 2019-01-16 12:40:26.058352: step 14608, loss = 0.47125 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:40:27.019140 ops/training.py:65 2019-01-16 12:40:27.019068: step 14609, loss = 0.41021 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:40:27.979525 ops/training.py:65 2019-01-16 12:40:27.979459: step 14610, loss = 0.50219 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:40:28.940196 ops/training.py:65 2019-01-16 12:40:28.940127: step 14611, loss = 0.57037 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:40:29.901798 ops/training.py:65 2019-01-16 12:40:29.901735: step 14612, loss = 0.31769 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:40:30.862318 ops/training.py:65 2019-01-16 12:40:30.862251: step 14613, loss = 0.45986 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:40:31.825609 ops/training.py:65 2019-01-16 12:40:31.825560: step 14614, loss = 0.50751 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:40:32.789546 ops/training.py:65 2019-01-16 12:40:32.789495: step 14615, loss = 0.46105 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:40:33.752852 ops/training.py:65 2019-01-16 12:40:33.752805: step 14616, loss = 0.45400 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:40:34.714739 ops/training.py:65 2019-01-16 12:40:34.714685: step 14617, loss = 0.38107 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:40:35.676688 ops/training.py:65 2019-01-16 12:40:35.676636: step 14618, loss = 0.54958 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:40:36.639099 ops/training.py:65 2019-01-16 12:40:36.639047: step 14619, loss = 0.48436 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:40:37.600856 ops/training.py:65 2019-01-16 12:40:37.600800: step 14620, loss = 0.57512 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:40:38.563288 ops/training.py:65 2019-01-16 12:40:38.563239: step 14621, loss = 0.61009 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:40:39.524353 ops/training.py:65 2019-01-16 12:40:39.524303: step 14622, loss = 0.71843 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:40:40.485229 ops/training.py:65 2019-01-16 12:40:40.485177: step 14623, loss = 0.66855 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:40:41.445145 ops/training.py:65 2019-01-16 12:40:41.445086: step 14624, loss = 0.59664 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:40:42.408793 ops/training.py:65 2019-01-16 12:40:42.408738: step 14625, loss = 0.56687 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:40:43.372404 ops/training.py:65 2019-01-16 12:40:43.372331: step 14626, loss = 0.50714 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:40:44.335250 ops/training.py:65 2019-01-16 12:40:44.335183: step 14627, loss = 0.39241 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:40:45.297459 ops/training.py:65 2019-01-16 12:40:45.297410: step 14628, loss = 0.44174 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:40:46.259439 ops/training.py:65 2019-01-16 12:40:46.259369: step 14629, loss = 0.38422 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:40:47.221941 ops/training.py:65 2019-01-16 12:40:47.221869: step 14630, loss = 0.33732 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:40:48.184180 ops/training.py:65 2019-01-16 12:40:48.184112: step 14631, loss = 0.27676 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:40:49.149875 ops/training.py:65 2019-01-16 12:40:49.149803: step 14632, loss = 0.37502 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:40:50.115061 ops/training.py:65 2019-01-16 12:40:50.114992: step 14633, loss = 0.48939 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:40:51.077117 ops/training.py:65 2019-01-16 12:40:51.077061: step 14634, loss = 0.44475 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:40:52.041467 ops/training.py:65 2019-01-16 12:40:52.041413: step 14635, loss = 0.48640 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:40:53.004295 ops/training.py:65 2019-01-16 12:40:53.004247: step 14636, loss = 0.54324 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:40:53.966429 ops/training.py:65 2019-01-16 12:40:53.966365: step 14637, loss = 0.47809 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:40:54.930583 ops/training.py:65 2019-01-16 12:40:54.930510: step 14638, loss = 0.39561 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:40:55.894405 ops/training.py:65 2019-01-16 12:40:55.894340: step 14639, loss = 0.47038 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:40:56.856235 ops/training.py:65 2019-01-16 12:40:56.856188: step 14640, loss = 0.36673 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:40:57.816972 ops/training.py:65 2019-01-16 12:40:57.816904: step 14641, loss = 0.55495 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:40:58.777667 ops/training.py:65 2019-01-16 12:40:58.777597: step 14642, loss = 0.48383 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:40:59.740449 ops/training.py:65 2019-01-16 12:40:59.740381: step 14643, loss = 0.56043 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:41:00.702624 ops/training.py:65 2019-01-16 12:41:00.702570: step 14644, loss = 0.40443 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:41:01.664693 ops/training.py:65 2019-01-16 12:41:01.664644: step 14645, loss = 0.36375 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:41:02.626265 ops/training.py:65 2019-01-16 12:41:02.626217: step 14646, loss = 0.62386 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:41:03.588335 ops/training.py:65 2019-01-16 12:41:03.588286: step 14647, loss = 0.56230 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:41:04.549635 ops/training.py:65 2019-01-16 12:41:04.549564: step 14648, loss = 0.37851 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:41:05.510905 ops/training.py:65 2019-01-16 12:41:05.510830: step 14649, loss = 0.52597 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:41:06.473450 ops/training.py:65 2019-01-16 12:41:06.473400: step 14650, loss = 0.59214 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:41:07.436750 ops/training.py:65 2019-01-16 12:41:07.436708: step 14651, loss = 0.55807 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:41:08.398016 ops/training.py:65 2019-01-16 12:41:08.397967: step 14652, loss = 0.65212 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:41:09.359123 ops/training.py:65 2019-01-16 12:41:09.359066: step 14653, loss = 0.35180 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:41:10.323102 ops/training.py:65 2019-01-16 12:41:10.323049: step 14654, loss = 0.52620 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:41:11.286192 ops/training.py:65 2019-01-16 12:41:11.286137: step 14655, loss = 0.51179 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:41:12.249738 ops/training.py:65 2019-01-16 12:41:12.249670: step 14656, loss = 0.54363 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:41:13.212634 ops/training.py:65 2019-01-16 12:41:13.212565: step 14657, loss = 0.56419 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:41:14.175063 ops/training.py:65 2019-01-16 12:41:14.174998: step 14658, loss = 0.49659 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:41:15.136266 ops/training.py:65 2019-01-16 12:41:15.136202: step 14659, loss = 0.45789 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:41:16.097094 ops/training.py:65 2019-01-16 12:41:16.097028: step 14660, loss = 0.46968 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:41:17.057313 ops/training.py:65 2019-01-16 12:41:17.057249: step 14661, loss = 0.35389 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:41:18.016677 ops/training.py:65 2019-01-16 12:41:18.016615: step 14662, loss = 0.67957 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:41:18.976505 ops/training.py:65 2019-01-16 12:41:18.976452: step 14663, loss = 0.44044 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:41:19.936072 ops/training.py:65 2019-01-16 12:41:19.936014: step 14664, loss = 0.49499 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:41:20.896033 ops/training.py:65 2019-01-16 12:41:20.895986: step 14665, loss = 0.44000 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:41:21.855667 ops/training.py:65 2019-01-16 12:41:21.855598: step 14666, loss = 0.48993 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:41:22.819981 ops/training.py:65 2019-01-16 12:41:22.819937: step 14667, loss = 0.46943 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:41:23.782964 ops/training.py:65 2019-01-16 12:41:23.782915: step 14668, loss = 0.45818 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:41:24.746145 ops/training.py:65 2019-01-16 12:41:24.746099: step 14669, loss = 0.29453 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:41:25.708695 ops/training.py:65 2019-01-16 12:41:25.708627: step 14670, loss = 0.55810 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:41:26.671390 ops/training.py:65 2019-01-16 12:41:26.671342: step 14671, loss = 0.56315 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:41:27.634675 ops/training.py:65 2019-01-16 12:41:27.634625: step 14672, loss = 0.63153 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:41:28.597338 ops/training.py:65 2019-01-16 12:41:28.597286: step 14673, loss = 0.38586 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:41:29.559390 ops/training.py:65 2019-01-16 12:41:29.559335: step 14674, loss = 0.41639 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:41:30.521994 ops/training.py:65 2019-01-16 12:41:30.521949: step 14675, loss = 0.46374 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:41:31.486426 ops/training.py:65 2019-01-16 12:41:31.486375: step 14676, loss = 0.40764 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:41:32.450211 ops/training.py:65 2019-01-16 12:41:32.450159: step 14677, loss = 0.45813 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:41:33.413849 ops/training.py:65 2019-01-16 12:41:33.413784: step 14678, loss = 0.41910 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:41:34.375658 ops/training.py:65 2019-01-16 12:41:34.375609: step 14679, loss = 0.57793 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:41:35.337729 ops/training.py:65 2019-01-16 12:41:35.337680: step 14680, loss = 0.47037 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:41:36.299889 ops/training.py:65 2019-01-16 12:41:36.299840: step 14681, loss = 0.48886 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:41:37.261725 ops/training.py:65 2019-01-16 12:41:37.261670: step 14682, loss = 0.50536 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:41:38.223006 ops/training.py:65 2019-01-16 12:41:38.222957: step 14683, loss = 0.49286 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:41:39.184958 ops/training.py:65 2019-01-16 12:41:39.184908: step 14684, loss = 0.51666 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:41:40.146740 ops/training.py:65 2019-01-16 12:41:40.146689: step 14685, loss = 0.37995 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:41:41.108023 ops/training.py:65 2019-01-16 12:41:41.107967: step 14686, loss = 0.48446 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:41:42.070345 ops/training.py:65 2019-01-16 12:41:42.070299: step 14687, loss = 0.49663 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:41:43.030704 ops/training.py:65 2019-01-16 12:41:43.030655: step 14688, loss = 0.41123 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:41:43.992781 ops/training.py:65 2019-01-16 12:41:43.992714: step 14689, loss = 0.59478 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:41:44.954095 ops/training.py:65 2019-01-16 12:41:44.954033: step 14690, loss = 0.39444 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:41:45.916474 ops/training.py:65 2019-01-16 12:41:45.916424: step 14691, loss = 0.43652 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:41:46.878566 ops/training.py:65 2019-01-16 12:41:46.878512: step 14692, loss = 0.58255 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:41:47.843573 ops/training.py:65 2019-01-16 12:41:47.843517: step 14693, loss = 0.46479 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:41:48.804155 ops/training.py:65 2019-01-16 12:41:48.804103: step 14694, loss = 0.38035 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:41:49.765277 ops/training.py:65 2019-01-16 12:41:49.765224: step 14695, loss = 0.40105 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:41:50.726230 ops/training.py:65 2019-01-16 12:41:50.726170: step 14696, loss = 0.52904 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:41:51.685738 ops/training.py:65 2019-01-16 12:41:51.685673: step 14697, loss = 0.42697 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:41:52.645787 ops/training.py:65 2019-01-16 12:41:52.645738: step 14698, loss = 0.40444 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:41:53.606612 ops/training.py:65 2019-01-16 12:41:53.606566: step 14699, loss = 0.52505 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:41:54.567458 ops/training.py:65 2019-01-16 12:41:54.567400: step 14700, loss = 0.35237 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:41:55.527706 ops/training.py:65 2019-01-16 12:41:55.527645: step 14701, loss = 0.47883 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:41:56.489386 ops/training.py:65 2019-01-16 12:41:56.489341: step 14702, loss = 0.48176 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:41:57.453449 ops/training.py:65 2019-01-16 12:41:57.453402: step 14703, loss = 0.39687 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:41:58.415645 ops/training.py:65 2019-01-16 12:41:58.415592: step 14704, loss = 0.46870 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:41:59.378299 ops/training.py:65 2019-01-16 12:41:59.378231: step 14705, loss = 0.54955 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:42:00.339761 ops/training.py:65 2019-01-16 12:42:00.339717: step 14706, loss = 0.50378 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:42:01.305675 ops/training.py:65 2019-01-16 12:42:01.305619: step 14707, loss = 0.50532 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:42:02.270402 ops/training.py:65 2019-01-16 12:42:02.270349: step 14708, loss = 0.46994 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:42:03.233820 ops/training.py:65 2019-01-16 12:42:03.233763: step 14709, loss = 0.50223 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:42:04.196776 ops/training.py:65 2019-01-16 12:42:04.196728: step 14710, loss = 0.57458 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:42:05.158362 ops/training.py:65 2019-01-16 12:42:05.158314: step 14711, loss = 0.53584 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:42:06.120875 ops/training.py:65 2019-01-16 12:42:06.120822: step 14712, loss = 0.40680 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:42:07.081661 ops/training.py:65 2019-01-16 12:42:07.081605: step 14713, loss = 0.58453 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:42:08.043099 ops/training.py:65 2019-01-16 12:42:08.043049: step 14714, loss = 0.36338 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:42:09.002225 ops/training.py:65 2019-01-16 12:42:09.002167: step 14715, loss = 0.40013 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:42:09.961638 ops/training.py:65 2019-01-16 12:42:09.961573: step 14716, loss = 0.53991 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:42:10.921044 ops/training.py:65 2019-01-16 12:42:10.920991: step 14717, loss = 0.39842 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:42:11.881685 ops/training.py:65 2019-01-16 12:42:11.881626: step 14718, loss = 0.33540 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:42:12.844958 ops/training.py:65 2019-01-16 12:42:12.844909: step 14719, loss = 0.48097 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:42:13.808467 ops/training.py:65 2019-01-16 12:42:13.808417: step 14720, loss = 0.50839 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:42:14.772448 ops/training.py:65 2019-01-16 12:42:14.772397: step 14721, loss = 0.48180 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:42:15.734229 ops/training.py:65 2019-01-16 12:42:15.734181: step 14722, loss = 0.57804 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:42:16.695322 ops/training.py:65 2019-01-16 12:42:16.695274: step 14723, loss = 0.53736 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:42:17.657605 ops/training.py:65 2019-01-16 12:42:17.657544: step 14724, loss = 0.45605 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:42:18.619145 ops/training.py:65 2019-01-16 12:42:18.619074: step 14725, loss = 0.43964 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:42:19.580645 ops/training.py:65 2019-01-16 12:42:19.580596: step 14726, loss = 0.48079 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:42:20.543055 ops/training.py:65 2019-01-16 12:42:20.543005: step 14727, loss = 0.42989 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:42:21.504176 ops/training.py:65 2019-01-16 12:42:21.504125: step 14728, loss = 0.45139 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:42:22.465243 ops/training.py:65 2019-01-16 12:42:22.465192: step 14729, loss = 0.47573 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:42:23.427559 ops/training.py:65 2019-01-16 12:42:23.427510: step 14730, loss = 0.81044 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 12:42:24.389492 ops/training.py:65 2019-01-16 12:42:24.389437: step 14731, loss = 0.35525 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:42:25.351368 ops/training.py:65 2019-01-16 12:42:25.351309: step 14732, loss = 0.36693 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:42:26.312898 ops/training.py:65 2019-01-16 12:42:26.312849: step 14733, loss = 0.40164 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:42:27.275103 ops/training.py:65 2019-01-16 12:42:27.275054: step 14734, loss = 0.54667 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:42:28.236456 ops/training.py:65 2019-01-16 12:42:28.236405: step 14735, loss = 0.52003 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:42:29.197474 ops/training.py:65 2019-01-16 12:42:29.197425: step 14736, loss = 0.46504 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:42:30.158277 ops/training.py:65 2019-01-16 12:42:30.158222: step 14737, loss = 0.49207 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:42:31.119166 ops/training.py:65 2019-01-16 12:42:31.119113: step 14738, loss = 0.54078 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:42:32.079404 ops/training.py:65 2019-01-16 12:42:32.079338: step 14739, loss = 0.52191 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:42:33.040839 ops/training.py:65 2019-01-16 12:42:33.040771: step 14740, loss = 0.46029 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:42:34.002273 ops/training.py:65 2019-01-16 12:42:34.002230: step 14741, loss = 0.53231 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:42:34.965162 ops/training.py:65 2019-01-16 12:42:34.965109: step 14742, loss = 0.45562 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:42:35.929443 ops/training.py:65 2019-01-16 12:42:35.929394: step 14743, loss = 0.38506 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:42:36.892250 ops/training.py:65 2019-01-16 12:42:36.892200: step 14744, loss = 0.63714 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:42:37.855764 ops/training.py:65 2019-01-16 12:42:37.855719: step 14745, loss = 0.37328 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:42:38.817415 ops/training.py:65 2019-01-16 12:42:38.817365: step 14746, loss = 0.34148 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:42:39.778889 ops/training.py:65 2019-01-16 12:42:39.778835: step 14747, loss = 0.37909 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:42:40.740386 ops/training.py:65 2019-01-16 12:42:40.740330: step 14748, loss = 0.50952 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:42:41.700908 ops/training.py:65 2019-01-16 12:42:41.700857: step 14749, loss = 0.45172 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:42:42.662565 ops/training.py:65 2019-01-16 12:42:42.662474: step 14750, loss = 0.38987 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:42:43.624560 ops/training.py:65 2019-01-16 12:42:43.624495: step 14751, loss = 0.44592 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:42:44.586563 ops/training.py:65 2019-01-16 12:42:44.586489: step 14752, loss = 0.54710 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:42:45.551372 ops/training.py:65 2019-01-16 12:42:45.551321: step 14753, loss = 0.61786 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:42:46.515237 ops/training.py:65 2019-01-16 12:42:46.515179: step 14754, loss = 0.65184 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:42:47.476510 ops/training.py:65 2019-01-16 12:42:47.476440: step 14755, loss = 0.48695 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:42:48.438905 ops/training.py:65 2019-01-16 12:42:48.438828: step 14756, loss = 0.64087 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:42:49.400976 ops/training.py:65 2019-01-16 12:42:49.400921: step 14757, loss = 0.47270 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:42:50.364458 ops/training.py:65 2019-01-16 12:42:50.364396: step 14758, loss = 0.60919 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:42:51.327895 ops/training.py:65 2019-01-16 12:42:51.327824: step 14759, loss = 0.42113 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:42:52.291007 ops/training.py:65 2019-01-16 12:42:52.290942: step 14760, loss = 0.32652 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:42:53.252793 ops/training.py:65 2019-01-16 12:42:53.252744: step 14761, loss = 0.64094 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:42:54.215160 ops/training.py:65 2019-01-16 12:42:54.215092: step 14762, loss = 0.57981 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:42:55.175126 ops/training.py:65 2019-01-16 12:42:55.175063: step 14763, loss = 0.48370 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:42:56.136763 ops/training.py:65 2019-01-16 12:42:56.136698: step 14764, loss = 0.36735 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:42:57.096691 ops/training.py:65 2019-01-16 12:42:57.096624: step 14765, loss = 0.51586 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:42:58.055925 ops/training.py:65 2019-01-16 12:42:58.055861: step 14766, loss = 0.41306 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:42:59.018244 ops/training.py:65 2019-01-16 12:42:59.018197: step 14767, loss = 0.48538 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:42:59.980581 ops/training.py:65 2019-01-16 12:42:59.980530: step 14768, loss = 0.56437 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:43:00.941796 ops/training.py:65 2019-01-16 12:43:00.941749: step 14769, loss = 0.48607 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:43:01.903359 ops/training.py:65 2019-01-16 12:43:01.903310: step 14770, loss = 0.48732 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:43:02.864885 ops/training.py:65 2019-01-16 12:43:02.864831: step 14771, loss = 0.44838 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:43:03.827451 ops/training.py:65 2019-01-16 12:43:03.827394: step 14772, loss = 0.62331 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:43:04.789207 ops/training.py:65 2019-01-16 12:43:04.789138: step 14773, loss = 0.53842 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:43:05.750100 ops/training.py:65 2019-01-16 12:43:05.750034: step 14774, loss = 0.46026 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:43:06.711725 ops/training.py:65 2019-01-16 12:43:06.711672: step 14775, loss = 0.67804 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:43:07.673067 ops/training.py:65 2019-01-16 12:43:07.673021: step 14776, loss = 0.45172 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:43:08.634918 ops/training.py:65 2019-01-16 12:43:08.634869: step 14777, loss = 0.50848 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:43:09.600688 ops/training.py:65 2019-01-16 12:43:09.600617: step 14778, loss = 0.50422 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:43:10.565650 ops/training.py:65 2019-01-16 12:43:10.565599: step 14779, loss = 0.44030 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:43:11.529542 ops/training.py:65 2019-01-16 12:43:11.529474: step 14780, loss = 0.41545 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:43:12.491241 ops/training.py:65 2019-01-16 12:43:12.491177: step 14781, loss = 0.46645 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:43:13.452314 ops/training.py:65 2019-01-16 12:43:13.452264: step 14782, loss = 0.36857 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:43:14.412681 ops/training.py:65 2019-01-16 12:43:14.412617: step 14783, loss = 0.50836 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:43:15.376105 ops/training.py:65 2019-01-16 12:43:15.376063: step 14784, loss = 0.39631 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:43:16.341308 ops/training.py:65 2019-01-16 12:43:16.341259: step 14785, loss = 0.57290 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:43:17.305489 ops/training.py:65 2019-01-16 12:43:17.305437: step 14786, loss = 0.31595 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:43:18.266412 ops/training.py:65 2019-01-16 12:43:18.266350: step 14787, loss = 0.46312 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:43:19.228305 ops/training.py:65 2019-01-16 12:43:19.228259: step 14788, loss = 0.36607 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:43:20.190130 ops/training.py:65 2019-01-16 12:43:20.190082: step 14789, loss = 0.36275 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:43:21.152538 ops/training.py:65 2019-01-16 12:43:21.152482: step 14790, loss = 0.60319 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:43:22.117012 ops/training.py:65 2019-01-16 12:43:22.116946: step 14791, loss = 0.48832 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:43:23.080951 ops/training.py:65 2019-01-16 12:43:23.080887: step 14792, loss = 0.47018 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:43:24.042902 ops/training.py:65 2019-01-16 12:43:24.042835: step 14793, loss = 0.47881 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:43:25.004432 ops/training.py:65 2019-01-16 12:43:25.004379: step 14794, loss = 0.49134 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:43:25.965200 ops/training.py:65 2019-01-16 12:43:25.965148: step 14795, loss = 0.41188 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:43:26.928893 ops/training.py:65 2019-01-16 12:43:26.928846: step 14796, loss = 0.50755 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:43:27.893722 ops/training.py:65 2019-01-16 12:43:27.893668: step 14797, loss = 0.48960 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:43:28.857680 ops/training.py:65 2019-01-16 12:43:28.857631: step 14798, loss = 0.39940 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:43:29.819249 ops/training.py:65 2019-01-16 12:43:29.819201: step 14799, loss = 0.37867 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:43:30.780737 ops/training.py:65 2019-01-16 12:43:30.780690: step 14800, loss = 0.46715 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:43:31.741844 ops/training.py:65 2019-01-16 12:43:31.741795: step 14801, loss = 0.58202 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:43:32.702299 ops/training.py:65 2019-01-16 12:43:32.702243: step 14802, loss = 0.57019 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:43:33.664288 ops/training.py:65 2019-01-16 12:43:33.664229: step 14803, loss = 0.52377 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:43:34.625145 ops/training.py:65 2019-01-16 12:43:34.625089: step 14804, loss = 0.52293 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:43:35.585887 ops/training.py:65 2019-01-16 12:43:35.585833: step 14805, loss = 0.46965 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:43:36.545456 ops/training.py:65 2019-01-16 12:43:36.545402: step 14806, loss = 0.67128 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:43:37.506426 ops/training.py:65 2019-01-16 12:43:37.506358: step 14807, loss = 0.38555 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:43:38.468082 ops/training.py:65 2019-01-16 12:43:38.468035: step 14808, loss = 0.43245 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:43:39.429378 ops/training.py:65 2019-01-16 12:43:39.429325: step 14809, loss = 0.41621 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:43:40.393781 ops/training.py:65 2019-01-16 12:43:40.393728: step 14810, loss = 0.39274 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:43:41.357099 ops/training.py:65 2019-01-16 12:43:41.357046: step 14811, loss = 0.46373 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:43:42.320697 ops/training.py:65 2019-01-16 12:43:42.320648: step 14812, loss = 0.51598 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:43:43.282081 ops/training.py:65 2019-01-16 12:43:43.282029: step 14813, loss = 0.40603 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:43:44.244235 ops/training.py:65 2019-01-16 12:43:44.244179: step 14814, loss = 0.32790 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:43:45.205158 ops/training.py:65 2019-01-16 12:43:45.205112: step 14815, loss = 0.46839 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:43:46.170077 ops/training.py:65 2019-01-16 12:43:46.170027: step 14816, loss = 0.55272 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:43:47.132636 ops/training.py:65 2019-01-16 12:43:47.132586: step 14817, loss = 0.46330 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:43:48.097023 ops/training.py:65 2019-01-16 12:43:48.096968: step 14818, loss = 0.71008 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:43:49.058475 ops/training.py:65 2019-01-16 12:43:49.058428: step 14819, loss = 0.49882 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:43:50.020243 ops/training.py:65 2019-01-16 12:43:50.020178: step 14820, loss = 0.58635 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:43:50.981068 ops/training.py:65 2019-01-16 12:43:50.981005: step 14821, loss = 0.38021 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:43:51.945066 ops/training.py:65 2019-01-16 12:43:51.944998: step 14822, loss = 0.41603 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:43:52.908486 ops/training.py:65 2019-01-16 12:43:52.908416: step 14823, loss = 0.46681 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:43:53.871790 ops/training.py:65 2019-01-16 12:43:53.871727: step 14824, loss = 0.43394 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:43:54.834067 ops/training.py:65 2019-01-16 12:43:54.834014: step 14825, loss = 0.43005 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:43:55.795838 ops/training.py:65 2019-01-16 12:43:55.795786: step 14826, loss = 0.51653 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:43:56.756411 ops/training.py:65 2019-01-16 12:43:56.756364: step 14827, loss = 0.37467 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:43:57.717076 ops/training.py:65 2019-01-16 12:43:57.717024: step 14828, loss = 0.47699 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:43:58.678660 ops/training.py:65 2019-01-16 12:43:58.678610: step 14829, loss = 0.45379 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:43:59.640649 ops/training.py:65 2019-01-16 12:43:59.640597: step 14830, loss = 0.55571 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:44:00.601916 ops/training.py:65 2019-01-16 12:44:00.601868: step 14831, loss = 0.50530 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:44:01.563444 ops/training.py:65 2019-01-16 12:44:01.563390: step 14832, loss = 0.46653 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:44:02.527701 ops/training.py:65 2019-01-16 12:44:02.527653: step 14833, loss = 0.45891 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:44:03.491817 ops/training.py:65 2019-01-16 12:44:03.491763: step 14834, loss = 0.38009 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:44:04.456018 ops/training.py:65 2019-01-16 12:44:04.455955: step 14835, loss = 0.52122 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:44:05.417134 ops/training.py:65 2019-01-16 12:44:05.417085: step 14836, loss = 0.58987 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:44:06.379130 ops/training.py:65 2019-01-16 12:44:06.379079: step 14837, loss = 0.49026 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:44:07.341074 ops/training.py:65 2019-01-16 12:44:07.341021: step 14838, loss = 0.48615 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:44:08.303020 ops/training.py:65 2019-01-16 12:44:08.302973: step 14839, loss = 0.54096 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:44:09.266263 ops/training.py:65 2019-01-16 12:44:09.266214: step 14840, loss = 0.43396 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:44:10.230230 ops/training.py:65 2019-01-16 12:44:10.230158: step 14841, loss = 0.54595 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:44:11.193698 ops/training.py:65 2019-01-16 12:44:11.193641: step 14842, loss = 0.40571 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:44:12.156862 ops/training.py:65 2019-01-16 12:44:12.156812: step 14843, loss = 0.59993 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:44:13.117768 ops/training.py:65 2019-01-16 12:44:13.117668: step 14844, loss = 0.54745 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:44:14.079416 ops/training.py:65 2019-01-16 12:44:14.079352: step 14845, loss = 0.46166 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:44:15.039227 ops/training.py:65 2019-01-16 12:44:15.039173: step 14846, loss = 0.42538 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:44:16.003598 ops/training.py:65 2019-01-16 12:44:16.003550: step 14847, loss = 0.56262 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:44:16.967613 ops/training.py:65 2019-01-16 12:44:16.967561: step 14848, loss = 0.41871 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:44:17.928902 ops/training.py:65 2019-01-16 12:44:17.928847: step 14849, loss = 0.51849 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:44:18.890490 ops/training.py:65 2019-01-16 12:44:18.890426: step 14850, loss = 0.47899 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:44:19.853451 ops/training.py:65 2019-01-16 12:44:19.853395: step 14851, loss = 0.49776 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:44:20.818219 ops/training.py:65 2019-01-16 12:44:20.818173: step 14852, loss = 0.41100 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:44:21.781222 ops/training.py:65 2019-01-16 12:44:21.781173: step 14853, loss = 0.48283 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:44:22.745529 ops/training.py:65 2019-01-16 12:44:22.745484: step 14854, loss = 0.56695 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:44:23.709795 ops/training.py:65 2019-01-16 12:44:23.709744: step 14855, loss = 0.46817 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:44:24.671542 ops/training.py:65 2019-01-16 12:44:24.671491: step 14856, loss = 0.37572 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:44:25.633812 ops/training.py:65 2019-01-16 12:44:25.633762: step 14857, loss = 0.46615 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:44:26.594729 ops/training.py:65 2019-01-16 12:44:26.594679: step 14858, loss = 0.43185 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:44:27.559470 ops/training.py:65 2019-01-16 12:44:27.559422: step 14859, loss = 0.50366 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:44:28.523823 ops/training.py:65 2019-01-16 12:44:28.523770: step 14860, loss = 0.47549 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:44:29.486846 ops/training.py:65 2019-01-16 12:44:29.486794: step 14861, loss = 0.46340 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:44:30.451848 ops/training.py:65 2019-01-16 12:44:30.451801: step 14862, loss = 0.63168 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:44:31.415776 ops/training.py:65 2019-01-16 12:44:31.415722: step 14863, loss = 0.49571 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:44:32.378666 ops/training.py:65 2019-01-16 12:44:32.378596: step 14864, loss = 0.49347 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:44:33.341569 ops/training.py:65 2019-01-16 12:44:33.341500: step 14865, loss = 0.43763 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:44:34.304240 ops/training.py:65 2019-01-16 12:44:34.304195: step 14866, loss = 0.44521 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:44:35.265233 ops/training.py:65 2019-01-16 12:44:35.265184: step 14867, loss = 0.53449 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:44:36.227119 ops/training.py:65 2019-01-16 12:44:36.227068: step 14868, loss = 0.53090 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:44:37.190309 ops/training.py:65 2019-01-16 12:44:37.190255: step 14869, loss = 0.34520 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:44:38.155707 ops/training.py:65 2019-01-16 12:44:38.155661: step 14870, loss = 0.50946 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:44:39.117459 ops/training.py:65 2019-01-16 12:44:39.117402: step 14871, loss = 0.54737 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:44:40.079997 ops/training.py:65 2019-01-16 12:44:40.079923: step 14872, loss = 0.54155 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:44:41.042736 ops/training.py:65 2019-01-16 12:44:41.042685: step 14873, loss = 0.56542 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:44:42.006537 ops/training.py:65 2019-01-16 12:44:42.006487: step 14874, loss = 0.49261 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:44:42.969348 ops/training.py:65 2019-01-16 12:44:42.969297: step 14875, loss = 0.38898 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:44:43.931525 ops/training.py:65 2019-01-16 12:44:43.931471: step 14876, loss = 0.50814 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:44:44.893665 ops/training.py:65 2019-01-16 12:44:44.893614: step 14877, loss = 0.45323 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:44:45.855151 ops/training.py:65 2019-01-16 12:44:45.855102: step 14878, loss = 0.48142 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:44:46.815947 ops/training.py:65 2019-01-16 12:44:46.815896: step 14879, loss = 0.39846 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:44:47.777077 ops/training.py:65 2019-01-16 12:44:47.777022: step 14880, loss = 0.49677 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:44:48.738919 ops/training.py:65 2019-01-16 12:44:48.738853: step 14881, loss = 0.55240 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:44:49.700792 ops/training.py:65 2019-01-16 12:44:49.700725: step 14882, loss = 0.36758 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:44:50.662590 ops/training.py:65 2019-01-16 12:44:50.662540: step 14883, loss = 0.54808 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:44:51.623892 ops/training.py:65 2019-01-16 12:44:51.623842: step 14884, loss = 0.64743 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:44:52.584860 ops/training.py:65 2019-01-16 12:44:52.584812: step 14885, loss = 0.46813 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:44:53.546050 ops/training.py:65 2019-01-16 12:44:53.545998: step 14886, loss = 0.40872 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:44:54.510825 ops/training.py:65 2019-01-16 12:44:54.510769: step 14887, loss = 0.47476 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:44:55.474746 ops/training.py:65 2019-01-16 12:44:55.474676: step 14888, loss = 0.46160 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:44:56.435641 ops/training.py:65 2019-01-16 12:44:56.435594: step 14889, loss = 0.36871 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:44:57.396263 ops/training.py:65 2019-01-16 12:44:57.396211: step 14890, loss = 0.42371 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:44:58.357221 ops/training.py:65 2019-01-16 12:44:58.357167: step 14891, loss = 0.37526 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:44:59.318121 ops/training.py:65 2019-01-16 12:44:59.318066: step 14892, loss = 0.46742 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:45:00.279296 ops/training.py:65 2019-01-16 12:45:00.279249: step 14893, loss = 0.48820 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:45:01.240095 ops/training.py:65 2019-01-16 12:45:01.240041: step 14894, loss = 0.40826 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:45:02.200912 ops/training.py:65 2019-01-16 12:45:02.200859: step 14895, loss = 0.42268 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:45:03.162819 ops/training.py:65 2019-01-16 12:45:03.162767: step 14896, loss = 0.54532 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:45:04.123375 ops/training.py:65 2019-01-16 12:45:04.123326: step 14897, loss = 0.35134 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:45:05.085161 ops/training.py:65 2019-01-16 12:45:05.085110: step 14898, loss = 0.40087 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:45:06.049963 ops/training.py:65 2019-01-16 12:45:06.049914: step 14899, loss = 0.51492 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:45:07.012358 ops/training.py:65 2019-01-16 12:45:07.012306: step 14900, loss = 0.35594 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:45:07.973063 ops/training.py:65 2019-01-16 12:45:07.972992: step 14901, loss = 0.63120 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:45:08.938010 ops/training.py:65 2019-01-16 12:45:08.937951: step 14902, loss = 0.54520 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:45:09.901325 ops/training.py:65 2019-01-16 12:45:09.901270: step 14903, loss = 0.56507 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:45:10.863614 ops/training.py:65 2019-01-16 12:45:10.863558: step 14904, loss = 0.37242 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:45:11.824534 ops/training.py:65 2019-01-16 12:45:11.824482: step 14905, loss = 0.59741 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:45:12.787026 ops/training.py:65 2019-01-16 12:45:12.786974: step 14906, loss = 0.35727 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:45:13.751433 ops/training.py:65 2019-01-16 12:45:13.751383: step 14907, loss = 0.48459 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:45:14.714832 ops/training.py:65 2019-01-16 12:45:14.714778: step 14908, loss = 0.37099 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:45:15.677818 ops/training.py:65 2019-01-16 12:45:15.677765: step 14909, loss = 0.47244 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:45:16.639449 ops/training.py:65 2019-01-16 12:45:16.639398: step 14910, loss = 0.41355 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:45:17.602457 ops/training.py:65 2019-01-16 12:45:17.602404: step 14911, loss = 0.43553 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:45:18.564641 ops/training.py:65 2019-01-16 12:45:18.564594: step 14912, loss = 0.46543 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:45:19.527198 ops/training.py:65 2019-01-16 12:45:19.527146: step 14913, loss = 0.43542 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:45:20.490024 ops/training.py:65 2019-01-16 12:45:20.489968: step 14914, loss = 0.45006 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:45:21.451955 ops/training.py:65 2019-01-16 12:45:21.451903: step 14915, loss = 0.51566 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:45:22.414372 ops/training.py:65 2019-01-16 12:45:22.414326: step 14916, loss = 0.34367 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:45:23.377027 ops/training.py:65 2019-01-16 12:45:23.376963: step 14917, loss = 0.57288 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:45:24.339419 ops/training.py:65 2019-01-16 12:45:24.339345: step 14918, loss = 0.31449 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:45:25.300943 ops/training.py:65 2019-01-16 12:45:25.300872: step 14919, loss = 0.53580 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:45:26.262618 ops/training.py:65 2019-01-16 12:45:26.262572: step 14920, loss = 0.57453 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:45:27.224174 ops/training.py:65 2019-01-16 12:45:27.224123: step 14921, loss = 0.47607 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:45:28.185985 ops/training.py:65 2019-01-16 12:45:28.185933: step 14922, loss = 0.44982 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:45:29.148922 ops/training.py:65 2019-01-16 12:45:29.148871: step 14923, loss = 0.59168 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:45:30.111352 ops/training.py:65 2019-01-16 12:45:30.111304: step 14924, loss = 0.41657 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:45:31.073305 ops/training.py:65 2019-01-16 12:45:31.073255: step 14925, loss = 0.40938 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:45:32.035000 ops/training.py:65 2019-01-16 12:45:32.034945: step 14926, loss = 0.33266 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:45:32.997220 ops/training.py:65 2019-01-16 12:45:32.997167: step 14927, loss = 0.46278 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:45:33.963366 ops/training.py:65 2019-01-16 12:45:33.963300: step 14928, loss = 0.40973 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:45:34.928454 ops/training.py:65 2019-01-16 12:45:34.928386: step 14929, loss = 0.38686 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:45:35.892389 ops/training.py:65 2019-01-16 12:45:35.892315: step 14930, loss = 0.37246 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:45:36.854402 ops/training.py:65 2019-01-16 12:45:36.854347: step 14931, loss = 0.40816 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:45:37.816549 ops/training.py:65 2019-01-16 12:45:37.816501: step 14932, loss = 0.46973 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:45:38.778142 ops/training.py:65 2019-01-16 12:45:38.778092: step 14933, loss = 0.41070 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:45:39.739967 ops/training.py:65 2019-01-16 12:45:39.739917: step 14934, loss = 0.48270 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:45:40.702260 ops/training.py:65 2019-01-16 12:45:40.702208: step 14935, loss = 0.33850 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:45:41.663612 ops/training.py:65 2019-01-16 12:45:41.663566: step 14936, loss = 0.53956 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:45:42.625625 ops/training.py:65 2019-01-16 12:45:42.625575: step 14937, loss = 0.41354 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:45:43.587995 ops/training.py:65 2019-01-16 12:45:43.587944: step 14938, loss = 0.50650 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:45:44.549961 ops/training.py:65 2019-01-16 12:45:44.549909: step 14939, loss = 0.44763 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:45:45.511978 ops/training.py:65 2019-01-16 12:45:45.511929: step 14940, loss = 0.32843 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:45:46.474813 ops/training.py:65 2019-01-16 12:45:46.474762: step 14941, loss = 0.63908 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 12:45:47.436116 ops/training.py:65 2019-01-16 12:45:47.436065: step 14942, loss = 0.37942 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:45:48.397966 ops/training.py:65 2019-01-16 12:45:48.397921: step 14943, loss = 0.50364 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:45:49.360015 ops/training.py:65 2019-01-16 12:45:49.359953: step 14944, loss = 0.46410 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:45:50.322420 ops/training.py:65 2019-01-16 12:45:50.322352: step 14945, loss = 0.32339 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:45:51.283657 ops/training.py:65 2019-01-16 12:45:51.283586: step 14946, loss = 0.35698 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:45:52.245143 ops/training.py:65 2019-01-16 12:45:52.245093: step 14947, loss = 0.47358 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:45:53.206556 ops/training.py:65 2019-01-16 12:45:53.206489: step 14948, loss = 0.39569 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:45:54.166451 ops/training.py:65 2019-01-16 12:45:54.166399: step 14949, loss = 0.58546 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:45:55.126957 ops/training.py:65 2019-01-16 12:45:55.126910: step 14950, loss = 0.58649 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:45:56.091106 ops/training.py:65 2019-01-16 12:45:56.091060: step 14951, loss = 0.39491 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:45:57.055713 ops/training.py:65 2019-01-16 12:45:57.055664: step 14952, loss = 0.40399 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:45:58.019821 ops/training.py:65 2019-01-16 12:45:58.019750: step 14953, loss = 0.34284 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:45:58.981589 ops/training.py:65 2019-01-16 12:45:58.981530: step 14954, loss = 0.52665 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:45:59.943586 ops/training.py:65 2019-01-16 12:45:59.943518: step 14955, loss = 0.42287 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:46:00.906122 ops/training.py:65 2019-01-16 12:46:00.906051: step 14956, loss = 0.49584 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:46:01.867650 ops/training.py:65 2019-01-16 12:46:01.867588: step 14957, loss = 0.44378 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:46:02.829910 ops/training.py:65 2019-01-16 12:46:02.829843: step 14958, loss = 0.55090 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:46:03.792322 ops/training.py:65 2019-01-16 12:46:03.792273: step 14959, loss = 0.40231 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:46:04.754628 ops/training.py:65 2019-01-16 12:46:04.754561: step 14960, loss = 0.44700 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:46:05.717207 ops/training.py:65 2019-01-16 12:46:05.717137: step 14961, loss = 0.44809 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:46:06.678983 ops/training.py:65 2019-01-16 12:46:06.678914: step 14962, loss = 0.51945 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:46:07.639726 ops/training.py:65 2019-01-16 12:46:07.639676: step 14963, loss = 0.40768 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:46:08.605430 ops/training.py:65 2019-01-16 12:46:08.605384: step 14964, loss = 0.52996 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:46:09.570463 ops/training.py:65 2019-01-16 12:46:09.570410: step 14965, loss = 0.39891 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:46:10.532447 ops/training.py:65 2019-01-16 12:46:10.532378: step 14966, loss = 0.38748 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:46:11.493816 ops/training.py:65 2019-01-16 12:46:11.493755: step 14967, loss = 0.34555 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:46:12.455370 ops/training.py:65 2019-01-16 12:46:12.455318: step 14968, loss = 0.56351 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:46:13.416577 ops/training.py:65 2019-01-16 12:46:13.416521: step 14969, loss = 0.30309 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:46:14.378368 ops/training.py:65 2019-01-16 12:46:14.378312: step 14970, loss = 0.41111 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:46:15.339143 ops/training.py:65 2019-01-16 12:46:15.339093: step 14971, loss = 0.43123 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:46:16.301148 ops/training.py:65 2019-01-16 12:46:16.301094: step 14972, loss = 0.33272 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:46:17.266256 ops/training.py:65 2019-01-16 12:46:17.266205: step 14973, loss = 0.60319 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:46:18.230784 ops/training.py:65 2019-01-16 12:46:18.230732: step 14974, loss = 0.45739 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:46:19.194762 ops/training.py:65 2019-01-16 12:46:19.194715: step 14975, loss = 0.43681 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:46:20.155892 ops/training.py:65 2019-01-16 12:46:20.155842: step 14976, loss = 0.49306 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:46:21.117592 ops/training.py:65 2019-01-16 12:46:21.117541: step 14977, loss = 0.34161 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:46:22.079463 ops/training.py:65 2019-01-16 12:46:22.079411: step 14978, loss = 0.33779 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:46:23.040923 ops/training.py:65 2019-01-16 12:46:23.040865: step 14979, loss = 0.45669 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:46:24.002415 ops/training.py:65 2019-01-16 12:46:24.002345: step 14980, loss = 0.50608 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:46:24.965608 ops/training.py:65 2019-01-16 12:46:24.965542: step 14981, loss = 0.56276 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:46:25.928174 ops/training.py:65 2019-01-16 12:46:25.928127: step 14982, loss = 0.50642 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:46:26.889820 ops/training.py:65 2019-01-16 12:46:26.889757: step 14983, loss = 0.50926 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:46:27.851749 ops/training.py:65 2019-01-16 12:46:27.851678: step 14984, loss = 0.31743 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:46:28.813544 ops/training.py:65 2019-01-16 12:46:28.813493: step 14985, loss = 0.44241 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:46:29.775239 ops/training.py:65 2019-01-16 12:46:29.775192: step 14986, loss = 0.49276 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:46:30.737238 ops/training.py:65 2019-01-16 12:46:30.737190: step 14987, loss = 0.59221 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:46:31.698589 ops/training.py:65 2019-01-16 12:46:31.698539: step 14988, loss = 0.53040 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:46:32.660007 ops/training.py:65 2019-01-16 12:46:32.659953: step 14989, loss = 0.61339 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:46:33.621770 ops/training.py:65 2019-01-16 12:46:33.621726: step 14990, loss = 0.42383 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:46:34.583047 ops/training.py:65 2019-01-16 12:46:34.582998: step 14991, loss = 0.56267 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:46:35.544775 ops/training.py:65 2019-01-16 12:46:35.544706: step 14992, loss = 0.48088 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:46:36.506410 ops/training.py:65 2019-01-16 12:46:36.506345: step 14993, loss = 0.32136 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:46:37.467729 ops/training.py:65 2019-01-16 12:46:37.467686: step 14994, loss = 0.53530 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:46:38.428704 ops/training.py:65 2019-01-16 12:46:38.428654: step 14995, loss = 0.54961 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:46:39.391136 ops/training.py:65 2019-01-16 12:46:39.391075: step 14996, loss = 0.55815 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:46:40.353094 ops/training.py:65 2019-01-16 12:46:40.353034: step 14997, loss = 0.58679 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:46:41.314646 ops/training.py:65 2019-01-16 12:46:41.314580: step 14998, loss = 0.53529 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:46:42.276579 ops/training.py:65 2019-01-16 12:46:42.276531: step 14999, loss = 0.47080 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:46:43.236704 ops/training.py:65 2019-01-16 12:46:43.236639: step 15000, loss = 0.38981 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:46:44.197572 ops/training.py:65 2019-01-16 12:46:44.197513: step 15001, loss = 0.38318 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:46:45.157016 ops/training.py:65 2019-01-16 12:46:45.156974: step 15002, loss = 0.40550 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:46:46.116606 ops/training.py:65 2019-01-16 12:46:46.116541: step 15003, loss = 0.58480 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:46:47.074820 ops/training.py:65 2019-01-16 12:46:47.074769: step 15004, loss = 0.51007 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:46:48.039016 ops/training.py:65 2019-01-16 12:46:48.038966: step 15005, loss = 0.51572 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:46:49.002899 ops/training.py:65 2019-01-16 12:46:49.002840: step 15006, loss = 0.32112 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:46:49.965962 ops/training.py:65 2019-01-16 12:46:49.965900: step 15007, loss = 0.56708 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:46:50.928017 ops/training.py:65 2019-01-16 12:46:50.927945: step 15008, loss = 0.49916 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:46:51.890401 ops/training.py:65 2019-01-16 12:46:51.890340: step 15009, loss = 0.49528 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:46:52.853147 ops/training.py:65 2019-01-16 12:46:52.853095: step 15010, loss = 0.41955 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:46:53.815435 ops/training.py:65 2019-01-16 12:46:53.815381: step 15011, loss = 0.41610 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:46:54.780449 ops/training.py:65 2019-01-16 12:46:54.780396: step 15012, loss = 0.55012 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:46:55.744169 ops/training.py:65 2019-01-16 12:46:55.744107: step 15013, loss = 0.24505 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:46:56.707489 ops/training.py:65 2019-01-16 12:46:56.707430: step 15014, loss = 0.60149 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:46:57.669091 ops/training.py:65 2019-01-16 12:46:57.669033: step 15015, loss = 0.50269 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:46:58.630984 ops/training.py:65 2019-01-16 12:46:58.630935: step 15016, loss = 0.45052 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:46:59.593152 ops/training.py:65 2019-01-16 12:46:59.593107: step 15017, loss = 0.42382 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:47:00.555335 ops/training.py:65 2019-01-16 12:47:00.555288: step 15018, loss = 0.40531 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:47:01.516935 ops/training.py:65 2019-01-16 12:47:01.516889: step 15019, loss = 0.62460 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:47:02.479641 ops/training.py:65 2019-01-16 12:47:02.479590: step 15020, loss = 0.40837 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:47:03.441536 ops/training.py:65 2019-01-16 12:47:03.441488: step 15021, loss = 0.48358 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:47:04.402969 ops/training.py:65 2019-01-16 12:47:04.402921: step 15022, loss = 0.56809 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:47:05.364799 ops/training.py:65 2019-01-16 12:47:05.364733: step 15023, loss = 0.62157 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:47:06.325403 ops/training.py:65 2019-01-16 12:47:06.325335: step 15024, loss = 0.44632 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:47:07.286664 ops/training.py:65 2019-01-16 12:47:07.286608: step 15025, loss = 0.53280 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:47:08.250454 ops/training.py:65 2019-01-16 12:47:08.250387: step 15026, loss = 0.54088 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:47:09.213564 ops/training.py:65 2019-01-16 12:47:09.213495: step 15027, loss = 0.37885 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:47:10.175405 ops/training.py:65 2019-01-16 12:47:10.175343: step 15028, loss = 0.58613 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:47:11.136505 ops/training.py:65 2019-01-16 12:47:11.136452: step 15029, loss = 0.55488 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:47:12.098106 ops/training.py:65 2019-01-16 12:47:12.098033: step 15030, loss = 0.30978 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:47:13.059890 ops/training.py:65 2019-01-16 12:47:13.059823: step 15031, loss = 0.39636 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:47:14.021127 ops/training.py:65 2019-01-16 12:47:14.021073: step 15032, loss = 0.49971 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:47:14.981825 ops/training.py:65 2019-01-16 12:47:14.981776: step 15033, loss = 0.48237 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:47:15.942484 ops/training.py:65 2019-01-16 12:47:15.942436: step 15034, loss = 0.53209 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:47:16.903016 ops/training.py:65 2019-01-16 12:47:16.902966: step 15035, loss = 0.62076 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:47:17.864095 ops/training.py:65 2019-01-16 12:47:17.864044: step 15036, loss = 0.55181 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:47:18.825455 ops/training.py:65 2019-01-16 12:47:18.825404: step 15037, loss = 0.41271 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:47:19.786857 ops/training.py:65 2019-01-16 12:47:19.786806: step 15038, loss = 0.44112 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:47:20.748027 ops/training.py:65 2019-01-16 12:47:20.747978: step 15039, loss = 0.51539 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:47:21.708838 ops/training.py:65 2019-01-16 12:47:21.708780: step 15040, loss = 0.60663 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:47:22.669567 ops/training.py:65 2019-01-16 12:47:22.669498: step 15041, loss = 0.47133 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:47:23.630349 ops/training.py:65 2019-01-16 12:47:23.630278: step 15042, loss = 0.48484 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:47:24.591079 ops/training.py:65 2019-01-16 12:47:24.591008: step 15043, loss = 0.41846 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:47:25.552075 ops/training.py:65 2019-01-16 12:47:25.552023: step 15044, loss = 0.43248 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:47:26.513334 ops/training.py:65 2019-01-16 12:47:26.513283: step 15045, loss = 0.46867 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:47:27.474206 ops/training.py:65 2019-01-16 12:47:27.474156: step 15046, loss = 0.51669 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:47:28.435235 ops/training.py:65 2019-01-16 12:47:28.435184: step 15047, loss = 0.39341 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:47:29.396368 ops/training.py:65 2019-01-16 12:47:29.396315: step 15048, loss = 0.47687 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:47:30.357613 ops/training.py:65 2019-01-16 12:47:30.357565: step 15049, loss = 0.45991 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:47:31.318071 ops/training.py:65 2019-01-16 12:47:31.318021: step 15050, loss = 0.54441 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:47:32.279644 ops/training.py:65 2019-01-16 12:47:32.279593: step 15051, loss = 0.40151 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:47:33.240767 ops/training.py:65 2019-01-16 12:47:33.240714: step 15052, loss = 0.38539 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:47:34.202039 ops/training.py:65 2019-01-16 12:47:34.201979: step 15053, loss = 0.42207 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:47:35.162884 ops/training.py:65 2019-01-16 12:47:35.162815: step 15054, loss = 0.53001 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:47:36.124691 ops/training.py:65 2019-01-16 12:47:36.124625: step 15055, loss = 0.52436 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:47:37.086213 ops/training.py:65 2019-01-16 12:47:37.086164: step 15056, loss = 0.50129 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:47:38.047592 ops/training.py:65 2019-01-16 12:47:38.047521: step 15057, loss = 0.53871 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:47:39.008499 ops/training.py:65 2019-01-16 12:47:39.008437: step 15058, loss = 0.50445 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:47:39.969744 ops/training.py:65 2019-01-16 12:47:39.969679: step 15059, loss = 0.37164 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:47:40.931401 ops/training.py:65 2019-01-16 12:47:40.931350: step 15060, loss = 0.53218 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:47:41.892066 ops/training.py:65 2019-01-16 12:47:41.892015: step 15061, loss = 0.47349 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:47:42.852590 ops/training.py:65 2019-01-16 12:47:42.852539: step 15062, loss = 0.45537 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:47:43.813532 ops/training.py:65 2019-01-16 12:47:43.813479: step 15063, loss = 0.59624 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:47:44.776199 ops/training.py:65 2019-01-16 12:47:44.776123: step 15064, loss = 0.52479 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:47:45.738491 ops/training.py:65 2019-01-16 12:47:45.738419: step 15065, loss = 0.44397 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:47:46.698856 ops/training.py:65 2019-01-16 12:47:46.698790: step 15066, loss = 0.54052 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:47:47.661905 ops/training.py:65 2019-01-16 12:47:47.661857: step 15067, loss = 0.44139 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:47:48.625126 ops/training.py:65 2019-01-16 12:47:48.625081: step 15068, loss = 0.44804 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:47:49.588705 ops/training.py:65 2019-01-16 12:47:49.588654: step 15069, loss = 0.63076 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:47:50.549503 ops/training.py:65 2019-01-16 12:47:50.549450: step 15070, loss = 0.54655 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:47:51.508644 ops/training.py:65 2019-01-16 12:47:51.508588: step 15071, loss = 0.38480 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:47:52.469264 ops/training.py:65 2019-01-16 12:47:52.469216: step 15072, loss = 0.49999 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:47:53.433397 ops/training.py:65 2019-01-16 12:47:53.433348: step 15073, loss = 0.50666 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:47:54.396622 ops/training.py:65 2019-01-16 12:47:54.396573: step 15074, loss = 0.67391 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:47:55.359216 ops/training.py:65 2019-01-16 12:47:55.359148: step 15075, loss = 0.47554 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:47:56.320974 ops/training.py:65 2019-01-16 12:47:56.320906: step 15076, loss = 0.46185 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:47:57.282357 ops/training.py:65 2019-01-16 12:47:57.282289: step 15077, loss = 0.44119 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:47:58.244582 ops/training.py:65 2019-01-16 12:47:58.244508: step 15078, loss = 0.38679 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:47:59.206050 ops/training.py:65 2019-01-16 12:47:59.205984: step 15079, loss = 0.52682 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:48:00.166678 ops/training.py:65 2019-01-16 12:48:00.166630: step 15080, loss = 0.41457 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:48:01.130426 ops/training.py:65 2019-01-16 12:48:01.130379: step 15081, loss = 0.45169 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:48:02.093645 ops/training.py:65 2019-01-16 12:48:02.093599: step 15082, loss = 0.42931 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:48:03.056390 ops/training.py:65 2019-01-16 12:48:03.056326: step 15083, loss = 0.47332 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:48:04.017596 ops/training.py:65 2019-01-16 12:48:04.017538: step 15084, loss = 0.39801 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:48:04.978488 ops/training.py:65 2019-01-16 12:48:04.978421: step 15085, loss = 0.44998 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:48:05.938373 ops/training.py:65 2019-01-16 12:48:05.938300: step 15086, loss = 0.43824 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:48:06.900453 ops/training.py:65 2019-01-16 12:48:06.900405: step 15087, loss = 0.53143 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:48:07.861625 ops/training.py:65 2019-01-16 12:48:07.861577: step 15088, loss = 0.57837 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:48:08.826596 ops/training.py:65 2019-01-16 12:48:08.826547: step 15089, loss = 0.54269 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:48:09.791157 ops/training.py:65 2019-01-16 12:48:09.791103: step 15090, loss = 0.58691 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:48:10.754771 ops/training.py:65 2019-01-16 12:48:10.754715: step 15091, loss = 0.38360 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:48:11.716467 ops/training.py:65 2019-01-16 12:48:11.716415: step 15092, loss = 0.56345 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:48:12.677599 ops/training.py:65 2019-01-16 12:48:12.677544: step 15093, loss = 0.43914 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:48:13.638602 ops/training.py:65 2019-01-16 12:48:13.638532: step 15094, loss = 0.45154 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:48:14.600387 ops/training.py:65 2019-01-16 12:48:14.600317: step 15095, loss = 0.47061 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:48:15.562438 ops/training.py:65 2019-01-16 12:48:15.562367: step 15096, loss = 0.52798 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:48:16.523095 ops/training.py:65 2019-01-16 12:48:16.523027: step 15097, loss = 0.45092 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:48:17.487858 ops/training.py:65 2019-01-16 12:48:17.487805: step 15098, loss = 0.39790 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:48:18.452146 ops/training.py:65 2019-01-16 12:48:18.452092: step 15099, loss = 0.53515 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:48:19.415496 ops/training.py:65 2019-01-16 12:48:19.415443: step 15100, loss = 0.53380 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:48:20.375292 ops/training.py:65 2019-01-16 12:48:20.375223: step 15101, loss = 0.34583 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:48:21.338003 ops/training.py:65 2019-01-16 12:48:21.337940: step 15102, loss = 0.44769 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:48:22.302023 ops/training.py:65 2019-01-16 12:48:22.301976: step 15103, loss = 0.54947 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:48:23.265009 ops/training.py:65 2019-01-16 12:48:23.264957: step 15104, loss = 0.52001 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:48:24.225872 ops/training.py:65 2019-01-16 12:48:24.225822: step 15105, loss = 0.32970 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:48:25.188473 ops/training.py:65 2019-01-16 12:48:25.188422: step 15106, loss = 0.44793 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:48:26.150475 ops/training.py:65 2019-01-16 12:48:26.150426: step 15107, loss = 0.32603 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:48:27.110804 ops/training.py:65 2019-01-16 12:48:27.110732: step 15108, loss = 0.36014 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:48:28.072828 ops/training.py:65 2019-01-16 12:48:28.072756: step 15109, loss = 0.40818 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:48:29.035149 ops/training.py:65 2019-01-16 12:48:29.035088: step 15110, loss = 0.43740 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:48:29.997562 ops/training.py:65 2019-01-16 12:48:29.997495: step 15111, loss = 0.60711 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:48:30.958366 ops/training.py:65 2019-01-16 12:48:30.958305: step 15112, loss = 0.46429 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:48:31.919928 ops/training.py:65 2019-01-16 12:48:31.919850: step 15113, loss = 0.36818 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:48:32.881495 ops/training.py:65 2019-01-16 12:48:32.881436: step 15114, loss = 0.45010 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:48:33.842221 ops/training.py:65 2019-01-16 12:48:33.842173: step 15115, loss = 0.44173 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:48:34.802760 ops/training.py:65 2019-01-16 12:48:34.802705: step 15116, loss = 0.47300 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:48:35.763422 ops/training.py:65 2019-01-16 12:48:35.763366: step 15117, loss = 0.45704 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:48:36.726166 ops/training.py:65 2019-01-16 12:48:36.726112: step 15118, loss = 0.38889 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:48:37.686319 ops/training.py:65 2019-01-16 12:48:37.686250: step 15119, loss = 0.47781 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:48:38.646539 ops/training.py:65 2019-01-16 12:48:38.646469: step 15120, loss = 0.44321 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:48:39.608066 ops/training.py:65 2019-01-16 12:48:39.608016: step 15121, loss = 0.49720 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:48:40.568237 ops/training.py:65 2019-01-16 12:48:40.568184: step 15122, loss = 0.43760 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:48:41.530991 ops/training.py:65 2019-01-16 12:48:41.530935: step 15123, loss = 0.50624 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:48:42.495414 ops/training.py:65 2019-01-16 12:48:42.495363: step 15124, loss = 0.66658 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:48:43.458280 ops/training.py:65 2019-01-16 12:48:43.458223: step 15125, loss = 0.48736 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:48:44.420225 ops/training.py:65 2019-01-16 12:48:44.420172: step 15126, loss = 0.36631 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:48:45.381305 ops/training.py:65 2019-01-16 12:48:45.381255: step 15127, loss = 0.39571 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:48:46.343064 ops/training.py:65 2019-01-16 12:48:46.343017: step 15128, loss = 0.40161 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:48:47.305079 ops/training.py:65 2019-01-16 12:48:47.305027: step 15129, loss = 0.48371 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:48:48.266621 ops/training.py:65 2019-01-16 12:48:48.266561: step 15130, loss = 0.47316 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:48:49.227869 ops/training.py:65 2019-01-16 12:48:49.227814: step 15131, loss = 0.39359 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:48:50.188558 ops/training.py:65 2019-01-16 12:48:50.188508: step 15132, loss = 0.43353 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:48:51.150676 ops/training.py:65 2019-01-16 12:48:51.150622: step 15133, loss = 0.42489 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:48:52.111845 ops/training.py:65 2019-01-16 12:48:52.111795: step 15134, loss = 0.54840 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:48:53.073761 ops/training.py:65 2019-01-16 12:48:53.073688: step 15135, loss = 0.36572 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:48:54.036195 ops/training.py:65 2019-01-16 12:48:54.036121: step 15136, loss = 0.69353 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:48:54.997047 ops/training.py:65 2019-01-16 12:48:54.996995: step 15137, loss = 0.41734 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:48:55.957476 ops/training.py:65 2019-01-16 12:48:55.957429: step 15138, loss = 0.56656 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:48:56.918741 ops/training.py:65 2019-01-16 12:48:56.918691: step 15139, loss = 0.35936 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:48:57.879917 ops/training.py:65 2019-01-16 12:48:57.879863: step 15140, loss = 0.44784 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:48:58.840541 ops/training.py:65 2019-01-16 12:48:58.840488: step 15141, loss = 0.28420 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 12:48:59.801061 ops/training.py:65 2019-01-16 12:48:59.801012: step 15142, loss = 0.43135 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:49:00.761729 ops/training.py:65 2019-01-16 12:49:00.761674: step 15143, loss = 0.39971 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:49:01.725124 ops/training.py:65 2019-01-16 12:49:01.725063: step 15144, loss = 0.49916 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:49:02.689088 ops/training.py:65 2019-01-16 12:49:02.689023: step 15145, loss = 0.37227 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:49:03.651984 ops/training.py:65 2019-01-16 12:49:03.651929: step 15146, loss = 0.41917 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:49:04.614901 ops/training.py:65 2019-01-16 12:49:04.614845: step 15147, loss = 0.51397 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:49:05.577609 ops/training.py:65 2019-01-16 12:49:05.577544: step 15148, loss = 0.48549 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:49:06.538995 ops/training.py:65 2019-01-16 12:49:06.538937: step 15149, loss = 0.43287 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:49:07.503038 ops/training.py:65 2019-01-16 12:49:07.502980: step 15150, loss = 0.44829 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:49:08.466612 ops/training.py:65 2019-01-16 12:49:08.466554: step 15151, loss = 0.50691 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:49:09.428375 ops/training.py:65 2019-01-16 12:49:09.428314: step 15152, loss = 0.55569 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:49:10.390105 ops/training.py:65 2019-01-16 12:49:10.390044: step 15153, loss = 0.47499 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:49:11.351202 ops/training.py:65 2019-01-16 12:49:11.351152: step 15154, loss = 0.46232 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:49:12.312700 ops/training.py:65 2019-01-16 12:49:12.312639: step 15155, loss = 0.39387 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:49:13.274452 ops/training.py:65 2019-01-16 12:49:13.274388: step 15156, loss = 0.22147 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:49:14.234829 ops/training.py:65 2019-01-16 12:49:14.234764: step 15157, loss = 0.47288 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:49:15.194622 ops/training.py:65 2019-01-16 12:49:15.194565: step 15158, loss = 0.48624 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:49:16.154790 ops/training.py:65 2019-01-16 12:49:16.154735: step 15159, loss = 0.36261 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:49:17.118810 ops/training.py:65 2019-01-16 12:49:17.118750: step 15160, loss = 0.44024 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:49:18.080881 ops/training.py:65 2019-01-16 12:49:18.080821: step 15161, loss = 0.44487 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:49:19.044700 ops/training.py:65 2019-01-16 12:49:19.044641: step 15162, loss = 0.41054 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:49:20.005519 ops/training.py:65 2019-01-16 12:49:20.005460: step 15163, loss = 0.43155 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:49:20.965835 ops/training.py:65 2019-01-16 12:49:20.965771: step 15164, loss = 0.38772 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:49:21.926814 ops/training.py:65 2019-01-16 12:49:21.926757: step 15165, loss = 0.47899 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:49:22.886256 ops/training.py:65 2019-01-16 12:49:22.886189: step 15166, loss = 0.46051 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:49:23.850598 ops/training.py:65 2019-01-16 12:49:23.850527: step 15167, loss = 0.44904 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:49:24.814863 ops/training.py:65 2019-01-16 12:49:24.814796: step 15168, loss = 0.40428 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:49:25.776292 ops/training.py:65 2019-01-16 12:49:25.776240: step 15169, loss = 0.39405 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:49:26.737218 ops/training.py:65 2019-01-16 12:49:26.737168: step 15170, loss = 0.38319 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:49:27.701716 ops/training.py:65 2019-01-16 12:49:27.701664: step 15171, loss = 0.37308 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:49:28.666295 ops/training.py:65 2019-01-16 12:49:28.666245: step 15172, loss = 0.46877 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:49:29.630019 ops/training.py:65 2019-01-16 12:49:29.629964: step 15173, loss = 0.46992 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:49:30.591554 ops/training.py:65 2019-01-16 12:49:30.591504: step 15174, loss = 0.48473 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:49:31.552780 ops/training.py:65 2019-01-16 12:49:31.552734: step 15175, loss = 0.48562 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:49:32.513634 ops/training.py:65 2019-01-16 12:49:32.513585: step 15176, loss = 0.36907 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:49:33.474812 ops/training.py:65 2019-01-16 12:49:33.474767: step 15177, loss = 0.61293 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:49:34.435564 ops/training.py:65 2019-01-16 12:49:34.435513: step 15178, loss = 0.45938 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:49:35.395900 ops/training.py:65 2019-01-16 12:49:35.395846: step 15179, loss = 0.36753 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:49:36.357190 ops/training.py:65 2019-01-16 12:49:36.357137: step 15180, loss = 0.40773 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:49:37.318343 ops/training.py:65 2019-01-16 12:49:37.318294: step 15181, loss = 0.39014 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:49:38.283411 ops/training.py:65 2019-01-16 12:49:38.283356: step 15182, loss = 0.33449 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:49:39.246856 ops/training.py:65 2019-01-16 12:49:39.246794: step 15183, loss = 0.55174 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:49:40.208488 ops/training.py:65 2019-01-16 12:49:40.208417: step 15184, loss = 0.40503 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:49:41.172114 ops/training.py:65 2019-01-16 12:49:41.172048: step 15185, loss = 0.72548 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:49:42.134193 ops/training.py:65 2019-01-16 12:49:42.134135: step 15186, loss = 0.38880 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:49:43.094151 ops/training.py:65 2019-01-16 12:49:43.094095: step 15187, loss = 0.54812 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:49:44.054368 ops/training.py:65 2019-01-16 12:49:44.054312: step 15188, loss = 0.52010 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:49:45.014976 ops/training.py:65 2019-01-16 12:49:45.014925: step 15189, loss = 0.46763 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:49:45.978787 ops/training.py:65 2019-01-16 12:49:45.978739: step 15190, loss = 0.45719 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:49:46.941199 ops/training.py:65 2019-01-16 12:49:46.941146: step 15191, loss = 0.38507 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:49:47.903471 ops/training.py:65 2019-01-16 12:49:47.903417: step 15192, loss = 0.42053 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:49:48.866595 ops/training.py:65 2019-01-16 12:49:48.866544: step 15193, loss = 0.32282 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:49:49.828413 ops/training.py:65 2019-01-16 12:49:49.828357: step 15194, loss = 0.53611 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:49:50.788859 ops/training.py:65 2019-01-16 12:49:50.788794: step 15195, loss = 0.43666 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:49:51.749476 ops/training.py:65 2019-01-16 12:49:51.749421: step 15196, loss = 0.61059 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:49:52.713734 ops/training.py:65 2019-01-16 12:49:52.713680: step 15197, loss = 0.40815 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:49:53.677715 ops/training.py:65 2019-01-16 12:49:53.677664: step 15198, loss = 0.42853 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:49:54.639304 ops/training.py:65 2019-01-16 12:49:54.639251: step 15199, loss = 0.50304 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:49:55.605632 ops/training.py:65 2019-01-16 12:49:55.605563: step 15200, loss = 0.49929 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:49:56.570083 ops/training.py:65 2019-01-16 12:49:56.570033: step 15201, loss = 0.40473 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:49:57.532868 ops/training.py:65 2019-01-16 12:49:57.532797: step 15202, loss = 0.36586 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:49:58.493668 ops/training.py:65 2019-01-16 12:49:58.493598: step 15203, loss = 0.49409 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:49:59.455344 ops/training.py:65 2019-01-16 12:49:59.455281: step 15204, loss = 0.42745 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:50:00.417240 ops/training.py:65 2019-01-16 12:50:00.417187: step 15205, loss = 0.48840 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:50:01.378473 ops/training.py:65 2019-01-16 12:50:01.378424: step 15206, loss = 0.48271 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:50:02.337804 ops/training.py:65 2019-01-16 12:50:02.337754: step 15207, loss = 0.39279 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:50:03.297628 ops/training.py:65 2019-01-16 12:50:03.297568: step 15208, loss = 0.39923 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:50:04.257572 ops/training.py:65 2019-01-16 12:50:04.257505: step 15209, loss = 0.43756 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:50:05.217593 ops/training.py:65 2019-01-16 12:50:05.217522: step 15210, loss = 0.43045 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:50:06.176376 ops/training.py:65 2019-01-16 12:50:06.176307: step 15211, loss = 0.57633 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:50:07.134658 ops/training.py:65 2019-01-16 12:50:07.134610: step 15212, loss = 0.53665 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:50:08.093402 ops/training.py:65 2019-01-16 12:50:08.093338: step 15213, loss = 0.52374 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:50:09.051918 ops/training.py:65 2019-01-16 12:50:09.051867: step 15214, loss = 0.50808 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:50:10.011137 ops/training.py:65 2019-01-16 12:50:10.011078: step 15215, loss = 0.53286 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:50:10.969267 ops/training.py:65 2019-01-16 12:50:10.969216: step 15216, loss = 0.39967 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:50:11.930059 ops/training.py:65 2019-01-16 12:50:11.929990: step 15217, loss = 0.65567 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:50:12.890435 ops/training.py:65 2019-01-16 12:50:12.890365: step 15218, loss = 0.37415 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:50:13.852375 ops/training.py:65 2019-01-16 12:50:13.852304: step 15219, loss = 0.41972 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:50:14.813266 ops/training.py:65 2019-01-16 12:50:14.813224: step 15220, loss = 0.47054 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:50:15.773997 ops/training.py:65 2019-01-16 12:50:15.773947: step 15221, loss = 0.41415 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:50:16.735503 ops/training.py:65 2019-01-16 12:50:16.735445: step 15222, loss = 0.47047 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:50:17.699564 ops/training.py:65 2019-01-16 12:50:17.699516: step 15223, loss = 0.53070 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:50:18.662723 ops/training.py:65 2019-01-16 12:50:18.662649: step 15224, loss = 0.36063 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:50:19.624341 ops/training.py:65 2019-01-16 12:50:19.624270: step 15225, loss = 0.45355 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:50:20.585244 ops/training.py:65 2019-01-16 12:50:20.585190: step 15226, loss = 0.53073 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:50:21.546178 ops/training.py:65 2019-01-16 12:50:21.546121: step 15227, loss = 0.45387 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:50:22.507138 ops/training.py:65 2019-01-16 12:50:22.507075: step 15228, loss = 0.31536 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:50:23.467514 ops/training.py:65 2019-01-16 12:50:23.467444: step 15229, loss = 0.53705 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:50:24.431536 ops/training.py:65 2019-01-16 12:50:24.431469: step 15230, loss = 0.37525 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:50:25.395758 ops/training.py:65 2019-01-16 12:50:25.395687: step 15231, loss = 0.35891 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:50:26.359317 ops/training.py:65 2019-01-16 12:50:26.359268: step 15232, loss = 0.45544 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:50:27.324733 ops/training.py:65 2019-01-16 12:50:27.324678: step 15233, loss = 0.44495 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:50:28.287314 ops/training.py:65 2019-01-16 12:50:28.287240: step 15234, loss = 0.54357 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:50:29.249891 ops/training.py:65 2019-01-16 12:50:29.249827: step 15235, loss = 0.32939 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:50:30.211813 ops/training.py:65 2019-01-16 12:50:30.211767: step 15236, loss = 0.51977 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:50:31.173624 ops/training.py:65 2019-01-16 12:50:31.173574: step 15237, loss = 0.40961 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:50:32.134838 ops/training.py:65 2019-01-16 12:50:32.134786: step 15238, loss = 0.52284 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:50:33.096273 ops/training.py:65 2019-01-16 12:50:33.096221: step 15239, loss = 0.33924 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:50:34.057137 ops/training.py:65 2019-01-16 12:50:34.057086: step 15240, loss = 0.46156 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:50:35.017750 ops/training.py:65 2019-01-16 12:50:35.017699: step 15241, loss = 0.41790 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:50:35.978552 ops/training.py:65 2019-01-16 12:50:35.978502: step 15242, loss = 0.56147 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:50:36.939954 ops/training.py:65 2019-01-16 12:50:36.939907: step 15243, loss = 0.57094 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:50:37.900718 ops/training.py:65 2019-01-16 12:50:37.900649: step 15244, loss = 0.55414 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:50:38.864140 ops/training.py:65 2019-01-16 12:50:38.864066: step 15245, loss = 0.53269 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:50:39.826437 ops/training.py:65 2019-01-16 12:50:39.826372: step 15246, loss = 0.52591 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:50:40.788488 ops/training.py:65 2019-01-16 12:50:40.788433: step 15247, loss = 0.41099 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:50:41.753071 ops/training.py:65 2019-01-16 12:50:41.753004: step 15248, loss = 0.49151 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:50:42.717031 ops/training.py:65 2019-01-16 12:50:42.716960: step 15249, loss = 0.49874 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:50:43.680567 ops/training.py:65 2019-01-16 12:50:43.680493: step 15250, loss = 0.51947 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:50:44.643272 ops/training.py:65 2019-01-16 12:50:44.643212: step 15251, loss = 0.53031 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:50:45.605635 ops/training.py:65 2019-01-16 12:50:45.605587: step 15252, loss = 0.49276 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:50:46.567260 ops/training.py:65 2019-01-16 12:50:46.567215: step 15253, loss = 0.46710 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:50:47.529141 ops/training.py:65 2019-01-16 12:50:47.529088: step 15254, loss = 0.46130 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:50:48.490878 ops/training.py:65 2019-01-16 12:50:48.490825: step 15255, loss = 0.46952 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:50:49.452799 ops/training.py:65 2019-01-16 12:50:49.452734: step 15256, loss = 0.59946 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:50:50.414319 ops/training.py:65 2019-01-16 12:50:50.414252: step 15257, loss = 0.46310 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:50:51.375831 ops/training.py:65 2019-01-16 12:50:51.375762: step 15258, loss = 0.41934 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:50:52.338875 ops/training.py:65 2019-01-16 12:50:52.338805: step 15259, loss = 0.41719 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:50:53.300362 ops/training.py:65 2019-01-16 12:50:53.300318: step 15260, loss = 0.56601 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:50:54.261715 ops/training.py:65 2019-01-16 12:50:54.261673: step 15261, loss = 0.43391 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:50:55.223826 ops/training.py:65 2019-01-16 12:50:55.223772: step 15262, loss = 0.45332 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:50:56.187274 ops/training.py:65 2019-01-16 12:50:56.187199: step 15263, loss = 0.50281 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:50:57.149670 ops/training.py:65 2019-01-16 12:50:57.149598: step 15264, loss = 0.46776 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:50:58.110971 ops/training.py:65 2019-01-16 12:50:58.110915: step 15265, loss = 0.41271 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:50:59.071337 ops/training.py:65 2019-01-16 12:50:59.071275: step 15266, loss = 0.45615 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:51:00.032722 ops/training.py:65 2019-01-16 12:51:00.032651: step 15267, loss = 0.42008 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:51:00.992810 ops/training.py:65 2019-01-16 12:51:00.992754: step 15268, loss = 0.52092 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:51:01.952984 ops/training.py:65 2019-01-16 12:51:01.952925: step 15269, loss = 0.45510 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:51:02.913867 ops/training.py:65 2019-01-16 12:51:02.913811: step 15270, loss = 0.40525 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:51:03.874773 ops/training.py:65 2019-01-16 12:51:03.874728: step 15271, loss = 0.37585 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:51:04.837427 ops/training.py:65 2019-01-16 12:51:04.837374: step 15272, loss = 0.34164 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:51:05.801312 ops/training.py:65 2019-01-16 12:51:05.801261: step 15273, loss = 0.42740 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:51:06.764088 ops/training.py:65 2019-01-16 12:51:06.764033: step 15274, loss = 0.53656 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:51:07.725295 ops/training.py:65 2019-01-16 12:51:07.725246: step 15275, loss = 0.60479 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:51:08.686355 ops/training.py:65 2019-01-16 12:51:08.686304: step 15276, loss = 0.43478 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:51:09.647028 ops/training.py:65 2019-01-16 12:51:09.646973: step 15277, loss = 0.55480 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:51:10.611246 ops/training.py:65 2019-01-16 12:51:10.611197: step 15278, loss = 0.35539 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:51:11.575628 ops/training.py:65 2019-01-16 12:51:11.575557: step 15279, loss = 0.40834 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:51:12.539699 ops/training.py:65 2019-01-16 12:51:12.539632: step 15280, loss = 0.50440 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:51:13.502765 ops/training.py:65 2019-01-16 12:51:13.502697: step 15281, loss = 0.49371 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:51:14.464815 ops/training.py:65 2019-01-16 12:51:14.464749: step 15282, loss = 0.43798 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:51:15.426222 ops/training.py:65 2019-01-16 12:51:15.426159: step 15283, loss = 0.64063 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:51:16.387712 ops/training.py:65 2019-01-16 12:51:16.387661: step 15284, loss = 0.31312 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:51:17.349080 ops/training.py:65 2019-01-16 12:51:17.349026: step 15285, loss = 0.51761 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:51:18.313842 ops/training.py:65 2019-01-16 12:51:18.313790: step 15286, loss = 0.39429 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:51:19.278069 ops/training.py:65 2019-01-16 12:51:19.278022: step 15287, loss = 0.46441 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:51:20.240324 ops/training.py:65 2019-01-16 12:51:20.240275: step 15288, loss = 0.42112 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:51:21.205267 ops/training.py:65 2019-01-16 12:51:21.205217: step 15289, loss = 0.43540 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:51:22.166973 ops/training.py:65 2019-01-16 12:51:22.166926: step 15290, loss = 0.43593 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:51:23.128471 ops/training.py:65 2019-01-16 12:51:23.128402: step 15291, loss = 0.37318 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:51:24.089263 ops/training.py:65 2019-01-16 12:51:24.089202: step 15292, loss = 0.36592 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:51:25.050674 ops/training.py:65 2019-01-16 12:51:25.050624: step 15293, loss = 0.44912 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:51:26.014310 ops/training.py:65 2019-01-16 12:51:26.014258: step 15294, loss = 0.56075 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:51:26.974701 ops/training.py:65 2019-01-16 12:51:26.974638: step 15295, loss = 0.48428 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:51:27.939216 ops/training.py:65 2019-01-16 12:51:27.939145: step 15296, loss = 0.39071 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:51:28.903562 ops/training.py:65 2019-01-16 12:51:28.903498: step 15297, loss = 0.54056 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:51:29.866525 ops/training.py:65 2019-01-16 12:51:29.866476: step 15298, loss = 0.38685 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:51:30.827456 ops/training.py:65 2019-01-16 12:51:30.827409: step 15299, loss = 0.50043 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:51:31.788366 ops/training.py:65 2019-01-16 12:51:31.788319: step 15300, loss = 0.46984 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:51:32.749399 ops/training.py:65 2019-01-16 12:51:32.749343: step 15301, loss = 0.49807 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:51:33.710377 ops/training.py:65 2019-01-16 12:51:33.710316: step 15302, loss = 0.48674 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:51:34.671679 ops/training.py:65 2019-01-16 12:51:34.671631: step 15303, loss = 0.49949 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:51:35.634341 ops/training.py:65 2019-01-16 12:51:35.634292: step 15304, loss = 0.32200 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:51:36.595436 ops/training.py:65 2019-01-16 12:51:36.595385: step 15305, loss = 0.33557 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:51:37.557197 ops/training.py:65 2019-01-16 12:51:37.557149: step 15306, loss = 0.59552 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:51:38.519145 ops/training.py:65 2019-01-16 12:51:38.519095: step 15307, loss = 0.43021 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:51:39.480952 ops/training.py:65 2019-01-16 12:51:39.480902: step 15308, loss = 0.47583 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:51:40.442579 ops/training.py:65 2019-01-16 12:51:40.442523: step 15309, loss = 0.46284 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:51:41.403631 ops/training.py:65 2019-01-16 12:51:41.403583: step 15310, loss = 0.39145 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:51:42.365379 ops/training.py:65 2019-01-16 12:51:42.365331: step 15311, loss = 0.49555 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:51:43.327411 ops/training.py:65 2019-01-16 12:51:43.327357: step 15312, loss = 0.41777 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:51:44.288700 ops/training.py:65 2019-01-16 12:51:44.288643: step 15313, loss = 0.46136 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:51:45.249750 ops/training.py:65 2019-01-16 12:51:45.249700: step 15314, loss = 0.44444 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:51:46.210478 ops/training.py:65 2019-01-16 12:51:46.210435: step 15315, loss = 0.42872 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:51:47.170995 ops/training.py:65 2019-01-16 12:51:47.170934: step 15316, loss = 0.50478 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:51:48.131905 ops/training.py:65 2019-01-16 12:51:48.131841: step 15317, loss = 0.39912 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:51:49.092012 ops/training.py:65 2019-01-16 12:51:49.091966: step 15318, loss = 0.62272 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:51:50.055870 ops/training.py:65 2019-01-16 12:51:50.055798: step 15319, loss = 0.40761 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:51:51.019413 ops/training.py:65 2019-01-16 12:51:51.019352: step 15320, loss = 0.44865 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:51:51.984140 ops/training.py:65 2019-01-16 12:51:51.984091: step 15321, loss = 0.33653 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:51:52.945474 ops/training.py:65 2019-01-16 12:51:52.945426: step 15322, loss = 0.33782 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:51:53.907719 ops/training.py:65 2019-01-16 12:51:53.907670: step 15323, loss = 0.43362 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:51:54.869128 ops/training.py:65 2019-01-16 12:51:54.869077: step 15324, loss = 0.49346 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:51:55.830815 ops/training.py:65 2019-01-16 12:51:55.830764: step 15325, loss = 0.45276 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:51:56.793032 ops/training.py:65 2019-01-16 12:51:56.792985: step 15326, loss = 0.40345 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:51:57.754706 ops/training.py:65 2019-01-16 12:51:57.754636: step 15327, loss = 0.57168 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:51:58.716835 ops/training.py:65 2019-01-16 12:51:58.716770: step 15328, loss = 0.49455 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:51:59.679140 ops/training.py:65 2019-01-16 12:51:59.679087: step 15329, loss = 0.37443 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:52:00.640285 ops/training.py:65 2019-01-16 12:52:00.640233: step 15330, loss = 0.45914 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:52:01.601498 ops/training.py:65 2019-01-16 12:52:01.601446: step 15331, loss = 0.48390 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:52:02.563654 ops/training.py:65 2019-01-16 12:52:02.563582: step 15332, loss = 0.45930 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:52:03.524711 ops/training.py:65 2019-01-16 12:52:03.524648: step 15333, loss = 0.38868 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:52:04.486494 ops/training.py:65 2019-01-16 12:52:04.486448: step 15334, loss = 0.52262 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:52:05.447745 ops/training.py:65 2019-01-16 12:52:05.447693: step 15335, loss = 0.42413 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:52:06.408947 ops/training.py:65 2019-01-16 12:52:06.408896: step 15336, loss = 0.33441 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:52:07.370634 ops/training.py:65 2019-01-16 12:52:07.370588: step 15337, loss = 0.37408 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:52:08.332555 ops/training.py:65 2019-01-16 12:52:08.332506: step 15338, loss = 0.39699 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:52:09.293557 ops/training.py:65 2019-01-16 12:52:09.293501: step 15339, loss = 0.50959 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:52:10.254267 ops/training.py:65 2019-01-16 12:52:10.254215: step 15340, loss = 0.48299 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:52:11.215756 ops/training.py:65 2019-01-16 12:52:11.215694: step 15341, loss = 0.53235 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:52:12.177215 ops/training.py:65 2019-01-16 12:52:12.177145: step 15342, loss = 0.39891 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:52:13.137533 ops/training.py:65 2019-01-16 12:52:13.137480: step 15343, loss = 0.42235 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:52:14.097486 ops/training.py:65 2019-01-16 12:52:14.097430: step 15344, loss = 0.43009 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:52:15.057675 ops/training.py:65 2019-01-16 12:52:15.057609: step 15345, loss = 0.51371 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:52:16.017430 ops/training.py:65 2019-01-16 12:52:16.017381: step 15346, loss = 0.61835 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:52:16.976351 ops/training.py:65 2019-01-16 12:52:16.976285: step 15347, loss = 0.46509 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:52:17.936871 ops/training.py:65 2019-01-16 12:52:17.936819: step 15348, loss = 0.37438 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:52:18.900414 ops/training.py:65 2019-01-16 12:52:18.900371: step 15349, loss = 0.33605 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:52:19.863484 ops/training.py:65 2019-01-16 12:52:19.863427: step 15350, loss = 0.31214 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:52:20.825327 ops/training.py:65 2019-01-16 12:52:20.825279: step 15351, loss = 0.40566 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:52:21.786616 ops/training.py:65 2019-01-16 12:52:21.786565: step 15352, loss = 0.33959 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:52:22.748162 ops/training.py:65 2019-01-16 12:52:22.748111: step 15353, loss = 0.35458 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:52:23.708387 ops/training.py:65 2019-01-16 12:52:23.708336: step 15354, loss = 0.48555 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:52:24.669349 ops/training.py:65 2019-01-16 12:52:24.669297: step 15355, loss = 0.45440 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:52:25.629914 ops/training.py:65 2019-01-16 12:52:25.629862: step 15356, loss = 0.31977 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:52:26.590900 ops/training.py:65 2019-01-16 12:52:26.590848: step 15357, loss = 0.45087 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:52:27.552350 ops/training.py:65 2019-01-16 12:52:27.552299: step 15358, loss = 0.44518 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:52:28.512407 ops/training.py:65 2019-01-16 12:52:28.512357: step 15359, loss = 0.40759 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:52:29.476069 ops/training.py:65 2019-01-16 12:52:29.476019: step 15360, loss = 0.58013 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:52:30.439344 ops/training.py:65 2019-01-16 12:52:30.439292: step 15361, loss = 0.45249 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:52:31.401030 ops/training.py:65 2019-01-16 12:52:31.400961: step 15362, loss = 0.47330 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:52:32.361907 ops/training.py:65 2019-01-16 12:52:32.361838: step 15363, loss = 0.45860 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:52:33.322794 ops/training.py:65 2019-01-16 12:52:33.322720: step 15364, loss = 0.48765 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:52:34.284351 ops/training.py:65 2019-01-16 12:52:34.284303: step 15365, loss = 0.50929 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:52:35.245204 ops/training.py:65 2019-01-16 12:52:35.245153: step 15366, loss = 0.44818 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:52:36.207100 ops/training.py:65 2019-01-16 12:52:36.207053: step 15367, loss = 0.48800 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:52:37.168619 ops/training.py:65 2019-01-16 12:52:37.168562: step 15368, loss = 0.57013 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:52:38.129785 ops/training.py:65 2019-01-16 12:52:38.129734: step 15369, loss = 0.45578 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:52:39.091116 ops/training.py:65 2019-01-16 12:52:39.091062: step 15370, loss = 0.41517 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:52:40.051840 ops/training.py:65 2019-01-16 12:52:40.051768: step 15371, loss = 0.39095 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:52:41.012630 ops/training.py:65 2019-01-16 12:52:41.012580: step 15372, loss = 0.39651 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:52:41.974235 ops/training.py:65 2019-01-16 12:52:41.974169: step 15373, loss = 0.44727 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:52:42.935510 ops/training.py:65 2019-01-16 12:52:42.935443: step 15374, loss = 0.46870 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:52:43.896770 ops/training.py:65 2019-01-16 12:52:43.896699: step 15375, loss = 0.39575 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:52:44.857841 ops/training.py:65 2019-01-16 12:52:44.857794: step 15376, loss = 0.43537 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:52:45.817585 ops/training.py:65 2019-01-16 12:52:45.817533: step 15377, loss = 0.42521 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:52:46.777715 ops/training.py:65 2019-01-16 12:52:46.777660: step 15378, loss = 0.54885 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:52:47.741544 ops/training.py:65 2019-01-16 12:52:47.741488: step 15379, loss = 0.35274 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:52:48.703524 ops/training.py:65 2019-01-16 12:52:48.703457: step 15380, loss = 0.39755 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:52:49.665006 ops/training.py:65 2019-01-16 12:52:49.664940: step 15381, loss = 0.51995 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:52:50.629537 ops/training.py:65 2019-01-16 12:52:50.629486: step 15382, loss = 0.59355 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:52:51.591243 ops/training.py:65 2019-01-16 12:52:51.591173: step 15383, loss = 0.41632 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:52:52.556288 ops/training.py:65 2019-01-16 12:52:52.556224: step 15384, loss = 0.50489 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:52:53.518622 ops/training.py:65 2019-01-16 12:52:53.518552: step 15385, loss = 0.50477 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:52:54.481729 ops/training.py:65 2019-01-16 12:52:54.481667: step 15386, loss = 0.40514 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:52:55.443929 ops/training.py:65 2019-01-16 12:52:55.443864: step 15387, loss = 0.53253 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:52:56.406267 ops/training.py:65 2019-01-16 12:52:56.406200: step 15388, loss = 0.37573 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:52:57.367901 ops/training.py:65 2019-01-16 12:52:57.367840: step 15389, loss = 0.56447 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:52:58.329932 ops/training.py:65 2019-01-16 12:52:58.329853: step 15390, loss = 0.41552 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:52:59.291776 ops/training.py:65 2019-01-16 12:52:59.291711: step 15391, loss = 0.55807 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:53:00.253196 ops/training.py:65 2019-01-16 12:53:00.253152: step 15392, loss = 0.56632 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:53:01.215046 ops/training.py:65 2019-01-16 12:53:01.214994: step 15393, loss = 0.45662 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:53:02.176640 ops/training.py:65 2019-01-16 12:53:02.176591: step 15394, loss = 0.53620 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:53:03.138294 ops/training.py:65 2019-01-16 12:53:03.138239: step 15395, loss = 0.42488 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:53:04.100102 ops/training.py:65 2019-01-16 12:53:04.100052: step 15396, loss = 0.51092 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:53:05.061651 ops/training.py:65 2019-01-16 12:53:05.061594: step 15397, loss = 0.42463 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:53:06.023488 ops/training.py:65 2019-01-16 12:53:06.023416: step 15398, loss = 0.45064 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:53:06.984804 ops/training.py:65 2019-01-16 12:53:06.984733: step 15399, loss = 0.57155 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:53:07.946835 ops/training.py:65 2019-01-16 12:53:07.946773: step 15400, loss = 0.33163 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:53:08.907496 ops/training.py:65 2019-01-16 12:53:08.907444: step 15401, loss = 0.30483 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:53:09.869035 ops/training.py:65 2019-01-16 12:53:09.868983: step 15402, loss = 0.39161 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:53:10.830797 ops/training.py:65 2019-01-16 12:53:10.830744: step 15403, loss = 0.47762 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:53:11.792787 ops/training.py:65 2019-01-16 12:53:11.792717: step 15404, loss = 0.45698 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:53:12.754224 ops/training.py:65 2019-01-16 12:53:12.754173: step 15405, loss = 0.49811 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:53:13.717247 ops/training.py:65 2019-01-16 12:53:13.717192: step 15406, loss = 0.28760 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:53:14.679548 ops/training.py:65 2019-01-16 12:53:14.679489: step 15407, loss = 0.54535 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:53:15.641961 ops/training.py:65 2019-01-16 12:53:15.641911: step 15408, loss = 0.71441 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:53:16.603504 ops/training.py:65 2019-01-16 12:53:16.603445: step 15409, loss = 0.42709 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:53:17.565988 ops/training.py:65 2019-01-16 12:53:17.565914: step 15410, loss = 0.40152 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:53:18.528157 ops/training.py:65 2019-01-16 12:53:18.528091: step 15411, loss = 0.51145 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:53:19.489525 ops/training.py:65 2019-01-16 12:53:19.489436: step 15412, loss = 0.49160 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:53:20.454401 ops/training.py:65 2019-01-16 12:53:20.454337: step 15413, loss = 0.47535 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:53:21.418724 ops/training.py:65 2019-01-16 12:53:21.418666: step 15414, loss = 0.43297 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:53:22.379175 ops/training.py:65 2019-01-16 12:53:22.379108: step 15415, loss = 0.48069 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:53:23.340520 ops/training.py:65 2019-01-16 12:53:23.340452: step 15416, loss = 0.46714 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:53:24.305174 ops/training.py:65 2019-01-16 12:53:24.305108: step 15417, loss = 0.40711 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:53:25.268204 ops/training.py:65 2019-01-16 12:53:25.268153: step 15418, loss = 0.36498 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:53:26.231681 ops/training.py:65 2019-01-16 12:53:26.231629: step 15419, loss = 0.39263 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:53:27.194414 ops/training.py:65 2019-01-16 12:53:27.194357: step 15420, loss = 0.37098 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:53:28.156093 ops/training.py:65 2019-01-16 12:53:28.156036: step 15421, loss = 0.38969 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:53:29.121096 ops/training.py:65 2019-01-16 12:53:29.121048: step 15422, loss = 0.34258 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:53:30.085310 ops/training.py:65 2019-01-16 12:53:30.085264: step 15423, loss = 0.40090 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:53:31.048849 ops/training.py:65 2019-01-16 12:53:31.048799: step 15424, loss = 0.54943 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:53:32.010358 ops/training.py:65 2019-01-16 12:53:32.010306: step 15425, loss = 0.40936 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:53:32.972432 ops/training.py:65 2019-01-16 12:53:32.972376: step 15426, loss = 0.44450 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:53:33.934628 ops/training.py:65 2019-01-16 12:53:33.934580: step 15427, loss = 0.47936 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:53:34.896708 ops/training.py:65 2019-01-16 12:53:34.896655: step 15428, loss = 0.36222 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:53:35.858547 ops/training.py:65 2019-01-16 12:53:35.858493: step 15429, loss = 0.47354 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:53:36.820883 ops/training.py:65 2019-01-16 12:53:36.820825: step 15430, loss = 0.35296 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:53:37.782495 ops/training.py:65 2019-01-16 12:53:37.782445: step 15431, loss = 0.51669 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:53:38.744583 ops/training.py:65 2019-01-16 12:53:38.744532: step 15432, loss = 0.43157 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:53:39.705825 ops/training.py:65 2019-01-16 12:53:39.705775: step 15433, loss = 0.42318 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:53:40.667339 ops/training.py:65 2019-01-16 12:53:40.667283: step 15434, loss = 0.53872 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:53:41.629099 ops/training.py:65 2019-01-16 12:53:41.629035: step 15435, loss = 0.49757 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:53:42.590086 ops/training.py:65 2019-01-16 12:53:42.590015: step 15436, loss = 0.46657 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:53:43.552262 ops/training.py:65 2019-01-16 12:53:43.552189: step 15437, loss = 0.44806 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:53:44.513632 ops/training.py:65 2019-01-16 12:53:44.513562: step 15438, loss = 0.50270 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:53:45.474987 ops/training.py:65 2019-01-16 12:53:45.474937: step 15439, loss = 0.40825 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:53:46.435937 ops/training.py:65 2019-01-16 12:53:46.435885: step 15440, loss = 0.37176 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:53:47.397082 ops/training.py:65 2019-01-16 12:53:47.397030: step 15441, loss = 0.51600 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:53:48.358164 ops/training.py:65 2019-01-16 12:53:48.358108: step 15442, loss = 0.46444 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:53:49.319360 ops/training.py:65 2019-01-16 12:53:49.319308: step 15443, loss = 0.31604 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:53:50.280275 ops/training.py:65 2019-01-16 12:53:50.280222: step 15444, loss = 0.41853 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:53:51.241022 ops/training.py:65 2019-01-16 12:53:51.240972: step 15445, loss = 0.50875 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:53:52.201477 ops/training.py:65 2019-01-16 12:53:52.201417: step 15446, loss = 0.55954 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:53:53.162387 ops/training.py:65 2019-01-16 12:53:53.162337: step 15447, loss = 0.49464 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:53:54.123819 ops/training.py:65 2019-01-16 12:53:54.123763: step 15448, loss = 0.78132 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:53:55.084926 ops/training.py:65 2019-01-16 12:53:55.084865: step 15449, loss = 0.48695 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:53:56.046778 ops/training.py:65 2019-01-16 12:53:56.046708: step 15450, loss = 0.55321 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:53:57.007757 ops/training.py:65 2019-01-16 12:53:57.007689: step 15451, loss = 0.41297 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:53:57.970135 ops/training.py:65 2019-01-16 12:53:57.970079: step 15452, loss = 0.36730 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:53:58.931358 ops/training.py:65 2019-01-16 12:53:58.931303: step 15453, loss = 0.39335 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:53:59.891026 ops/training.py:65 2019-01-16 12:53:59.890971: step 15454, loss = 0.52845 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:54:00.851608 ops/training.py:65 2019-01-16 12:54:00.851558: step 15455, loss = 0.50701 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:54:01.812161 ops/training.py:65 2019-01-16 12:54:01.812103: step 15456, loss = 0.32106 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:54:02.772722 ops/training.py:65 2019-01-16 12:54:02.772647: step 15457, loss = 0.34594 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:54:03.732843 ops/training.py:65 2019-01-16 12:54:03.732775: step 15458, loss = 0.45795 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:54:04.697575 ops/training.py:65 2019-01-16 12:54:04.697525: step 15459, loss = 0.40323 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:54:05.661499 ops/training.py:65 2019-01-16 12:54:05.661446: step 15460, loss = 0.54168 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:54:06.623474 ops/training.py:65 2019-01-16 12:54:06.623427: step 15461, loss = 0.34818 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:54:07.585144 ops/training.py:65 2019-01-16 12:54:07.585085: step 15462, loss = 0.44067 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:54:08.545924 ops/training.py:65 2019-01-16 12:54:08.545858: step 15463, loss = 0.34239 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:54:09.506792 ops/training.py:65 2019-01-16 12:54:09.506732: step 15464, loss = 0.53062 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:54:10.467645 ops/training.py:65 2019-01-16 12:54:10.467578: step 15465, loss = 0.36022 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:54:11.428627 ops/training.py:65 2019-01-16 12:54:11.428573: step 15466, loss = 0.47465 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:54:12.389333 ops/training.py:65 2019-01-16 12:54:12.389268: step 15467, loss = 0.45368 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:54:13.349614 ops/training.py:65 2019-01-16 12:54:13.349556: step 15468, loss = 0.63335 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:54:14.309597 ops/training.py:65 2019-01-16 12:54:14.309529: step 15469, loss = 0.43536 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:54:15.269952 ops/training.py:65 2019-01-16 12:54:15.269826: step 15470, loss = 0.45977 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:54:16.230749 ops/training.py:65 2019-01-16 12:54:16.230696: step 15471, loss = 0.51139 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:54:17.192145 ops/training.py:65 2019-01-16 12:54:17.192077: step 15472, loss = 0.49877 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:54:18.152403 ops/training.py:65 2019-01-16 12:54:18.152333: step 15473, loss = 0.37795 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:54:19.113604 ops/training.py:65 2019-01-16 12:54:19.113554: step 15474, loss = 0.27588 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:54:20.075109 ops/training.py:65 2019-01-16 12:54:20.075046: step 15475, loss = 0.47884 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:54:21.039265 ops/training.py:65 2019-01-16 12:54:21.039196: step 15476, loss = 0.38304 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:54:22.002281 ops/training.py:65 2019-01-16 12:54:22.002217: step 15477, loss = 0.35067 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:54:22.965419 ops/training.py:65 2019-01-16 12:54:22.965349: step 15478, loss = 0.45533 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:54:23.925846 ops/training.py:65 2019-01-16 12:54:23.925795: step 15479, loss = 0.61612 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:54:24.886695 ops/training.py:65 2019-01-16 12:54:24.886638: step 15480, loss = 0.43931 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:54:25.846694 ops/training.py:65 2019-01-16 12:54:25.846622: step 15481, loss = 0.40619 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:54:26.807323 ops/training.py:65 2019-01-16 12:54:26.807265: step 15482, loss = 0.35167 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:54:27.765464 ops/training.py:65 2019-01-16 12:54:27.765400: step 15483, loss = 0.43634 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:54:28.727410 ops/training.py:65 2019-01-16 12:54:28.727345: step 15484, loss = 0.39744 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:54:29.686489 ops/training.py:65 2019-01-16 12:54:29.686422: step 15485, loss = 0.37502 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:54:30.645421 ops/training.py:65 2019-01-16 12:54:30.645378: step 15486, loss = 0.46131 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:54:31.604744 ops/training.py:65 2019-01-16 12:54:31.604676: step 15487, loss = 0.39841 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:54:32.565410 ops/training.py:65 2019-01-16 12:54:32.565343: step 15488, loss = 0.46111 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:54:33.526021 ops/training.py:65 2019-01-16 12:54:33.525967: step 15489, loss = 0.50258 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:54:34.486956 ops/training.py:65 2019-01-16 12:54:34.486906: step 15490, loss = 0.49381 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:54:35.448279 ops/training.py:65 2019-01-16 12:54:35.448213: step 15491, loss = 0.41994 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:54:36.408705 ops/training.py:65 2019-01-16 12:54:36.408652: step 15492, loss = 0.46196 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:54:37.372145 ops/training.py:65 2019-01-16 12:54:37.372088: step 15493, loss = 0.32687 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:54:38.334721 ops/training.py:65 2019-01-16 12:54:38.334672: step 15494, loss = 0.42405 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:54:39.296171 ops/training.py:65 2019-01-16 12:54:39.296121: step 15495, loss = 0.43014 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:54:40.256873 ops/training.py:65 2019-01-16 12:54:40.256821: step 15496, loss = 0.46550 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:54:41.217536 ops/training.py:65 2019-01-16 12:54:41.217482: step 15497, loss = 0.32172 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:54:42.178741 ops/training.py:65 2019-01-16 12:54:42.178673: step 15498, loss = 0.51448 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:54:43.139553 ops/training.py:65 2019-01-16 12:54:43.139500: step 15499, loss = 0.53233 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:54:44.100003 ops/training.py:65 2019-01-16 12:54:44.099937: step 15500, loss = 0.37969 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:54:45.060646 ops/training.py:65 2019-01-16 12:54:45.060576: step 15501, loss = 0.44860 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:54:46.023059 ops/training.py:65 2019-01-16 12:54:46.022999: step 15502, loss = 0.51312 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:54:46.987241 ops/training.py:65 2019-01-16 12:54:46.987172: step 15503, loss = 0.55162 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:54:47.948711 ops/training.py:65 2019-01-16 12:54:47.948639: step 15504, loss = 0.56078 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:54:48.914388 ops/training.py:65 2019-01-16 12:54:48.914321: step 15505, loss = 0.48953 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:54:49.874334 ops/training.py:65 2019-01-16 12:54:49.874264: step 15506, loss = 0.57986 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:54:50.834479 ops/training.py:65 2019-01-16 12:54:50.834425: step 15507, loss = 0.38012 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:54:51.797605 ops/training.py:65 2019-01-16 12:54:51.797554: step 15508, loss = 0.39263 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:54:52.758456 ops/training.py:65 2019-01-16 12:54:52.758401: step 15509, loss = 0.39815 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:54:53.718257 ops/training.py:65 2019-01-16 12:54:53.718207: step 15510, loss = 0.36916 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:54:54.681668 ops/training.py:65 2019-01-16 12:54:54.681610: step 15511, loss = 0.33935 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:54:55.644788 ops/training.py:65 2019-01-16 12:54:55.644735: step 15512, loss = 0.44223 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:54:56.607117 ops/training.py:65 2019-01-16 12:54:56.607069: step 15513, loss = 0.61784 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:54:57.568418 ops/training.py:65 2019-01-16 12:54:57.568362: step 15514, loss = 0.66023 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:54:58.529593 ops/training.py:65 2019-01-16 12:54:58.529519: step 15515, loss = 0.38966 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:54:59.490827 ops/training.py:65 2019-01-16 12:54:59.490768: step 15516, loss = 0.56285 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:55:00.452579 ops/training.py:65 2019-01-16 12:55:00.452534: step 15517, loss = 0.40773 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:55:01.413803 ops/training.py:65 2019-01-16 12:55:01.413753: step 15518, loss = 0.45220 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:55:02.373940 ops/training.py:65 2019-01-16 12:55:02.373887: step 15519, loss = 0.56410 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:55:03.338232 ops/training.py:65 2019-01-16 12:55:03.338176: step 15520, loss = 0.52747 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:55:04.301312 ops/training.py:65 2019-01-16 12:55:04.301266: step 15521, loss = 0.35189 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:55:05.264829 ops/training.py:65 2019-01-16 12:55:05.264777: step 15522, loss = 0.56285 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:55:06.225373 ops/training.py:65 2019-01-16 12:55:06.225324: step 15523, loss = 0.49728 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:55:07.185737 ops/training.py:65 2019-01-16 12:55:07.185680: step 15524, loss = 0.33930 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:55:08.151755 ops/training.py:65 2019-01-16 12:55:08.151688: step 15525, loss = 0.32034 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:55:09.115854 ops/training.py:65 2019-01-16 12:55:09.115791: step 15526, loss = 0.49497 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:55:10.078640 ops/training.py:65 2019-01-16 12:55:10.078572: step 15527, loss = 0.42342 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:55:11.039410 ops/training.py:65 2019-01-16 12:55:11.039356: step 15528, loss = 0.50562 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:55:11.999689 ops/training.py:65 2019-01-16 12:55:11.999620: step 15529, loss = 0.40619 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:55:12.960741 ops/training.py:65 2019-01-16 12:55:12.960688: step 15530, loss = 0.51028 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:55:13.920741 ops/training.py:65 2019-01-16 12:55:13.920684: step 15531, loss = 0.56989 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:55:14.881679 ops/training.py:65 2019-01-16 12:55:14.881619: step 15532, loss = 0.49109 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:55:15.841629 ops/training.py:65 2019-01-16 12:55:15.841561: step 15533, loss = 0.53491 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:55:16.801377 ops/training.py:65 2019-01-16 12:55:16.801307: step 15534, loss = 0.72690 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 12:55:17.760468 ops/training.py:65 2019-01-16 12:55:17.760410: step 15535, loss = 0.49828 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:55:18.719165 ops/training.py:65 2019-01-16 12:55:18.719099: step 15536, loss = 0.47500 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:55:19.681210 ops/training.py:65 2019-01-16 12:55:19.681164: step 15537, loss = 0.57184 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:55:20.644449 ops/training.py:65 2019-01-16 12:55:20.644399: step 15538, loss = 0.46284 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:55:21.605353 ops/training.py:65 2019-01-16 12:55:21.605300: step 15539, loss = 0.47756 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:55:22.569664 ops/training.py:65 2019-01-16 12:55:22.569609: step 15540, loss = 0.41798 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:55:23.532134 ops/training.py:65 2019-01-16 12:55:23.532084: step 15541, loss = 0.42261 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:55:24.493773 ops/training.py:65 2019-01-16 12:55:24.493720: step 15542, loss = 0.35707 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:55:25.454131 ops/training.py:65 2019-01-16 12:55:25.454075: step 15543, loss = 0.58585 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:55:26.415547 ops/training.py:65 2019-01-16 12:55:26.415495: step 15544, loss = 0.36774 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:55:27.375965 ops/training.py:65 2019-01-16 12:55:27.375915: step 15545, loss = 0.52825 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:55:28.336998 ops/training.py:65 2019-01-16 12:55:28.336948: step 15546, loss = 0.46395 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:55:29.297976 ops/training.py:65 2019-01-16 12:55:29.297923: step 15547, loss = 0.56525 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:55:30.262119 ops/training.py:65 2019-01-16 12:55:30.262077: step 15548, loss = 0.32877 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:55:31.225365 ops/training.py:65 2019-01-16 12:55:31.225297: step 15549, loss = 0.62639 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:55:32.186819 ops/training.py:65 2019-01-16 12:55:32.186752: step 15550, loss = 0.64229 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:55:33.150629 ops/training.py:65 2019-01-16 12:55:33.150556: step 15551, loss = 0.50748 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:55:34.114885 ops/training.py:65 2019-01-16 12:55:34.114838: step 15552, loss = 0.41441 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:55:35.078032 ops/training.py:65 2019-01-16 12:55:35.077983: step 15553, loss = 0.42137 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:55:36.039568 ops/training.py:65 2019-01-16 12:55:36.039515: step 15554, loss = 0.34341 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:55:37.000823 ops/training.py:65 2019-01-16 12:55:37.000769: step 15555, loss = 0.32480 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:55:37.961203 ops/training.py:65 2019-01-16 12:55:37.961157: step 15556, loss = 0.36350 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:55:38.926375 ops/training.py:65 2019-01-16 12:55:38.926325: step 15557, loss = 0.40576 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:55:39.891436 ops/training.py:65 2019-01-16 12:55:39.891382: step 15558, loss = 0.44303 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:55:40.853851 ops/training.py:65 2019-01-16 12:55:40.853799: step 15559, loss = 0.40898 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:55:41.815461 ops/training.py:65 2019-01-16 12:55:41.815396: step 15560, loss = 0.44818 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:55:42.777204 ops/training.py:65 2019-01-16 12:55:42.777150: step 15561, loss = 0.46806 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:55:43.738897 ops/training.py:65 2019-01-16 12:55:43.738843: step 15562, loss = 0.44077 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:55:44.700098 ops/training.py:65 2019-01-16 12:55:44.700041: step 15563, loss = 0.30778 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 12:55:45.661090 ops/training.py:65 2019-01-16 12:55:45.661039: step 15564, loss = 0.48637 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:55:46.621251 ops/training.py:65 2019-01-16 12:55:46.621182: step 15565, loss = 0.37414 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:55:47.582017 ops/training.py:65 2019-01-16 12:55:47.581950: step 15566, loss = 0.41350 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:55:48.547312 ops/training.py:65 2019-01-16 12:55:48.547259: step 15567, loss = 0.47507 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:55:49.511160 ops/training.py:65 2019-01-16 12:55:49.511112: step 15568, loss = 0.54729 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:55:50.473795 ops/training.py:65 2019-01-16 12:55:50.473743: step 15569, loss = 0.46779 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:55:51.435772 ops/training.py:65 2019-01-16 12:55:51.435722: step 15570, loss = 0.46019 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:55:52.397500 ops/training.py:65 2019-01-16 12:55:52.397443: step 15571, loss = 0.51536 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:55:53.359095 ops/training.py:65 2019-01-16 12:55:53.359044: step 15572, loss = 0.58121 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:55:54.321159 ops/training.py:65 2019-01-16 12:55:54.321106: step 15573, loss = 0.43511 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:55:55.280982 ops/training.py:65 2019-01-16 12:55:55.280925: step 15574, loss = 0.38306 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:55:56.246009 ops/training.py:65 2019-01-16 12:55:56.245961: step 15575, loss = 0.37374 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:55:57.209583 ops/training.py:65 2019-01-16 12:55:57.209533: step 15576, loss = 0.43419 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:55:58.172997 ops/training.py:65 2019-01-16 12:55:58.172945: step 15577, loss = 0.47078 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:55:59.133782 ops/training.py:65 2019-01-16 12:55:59.133733: step 15578, loss = 0.46257 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:56:00.096053 ops/training.py:65 2019-01-16 12:56:00.096007: step 15579, loss = 0.36766 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:56:01.056595 ops/training.py:65 2019-01-16 12:56:01.056543: step 15580, loss = 0.48659 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:56:02.017335 ops/training.py:65 2019-01-16 12:56:02.017283: step 15581, loss = 0.38158 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:56:02.978176 ops/training.py:65 2019-01-16 12:56:02.978123: step 15582, loss = 0.52902 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:56:03.940117 ops/training.py:65 2019-01-16 12:56:03.940068: step 15583, loss = 0.39309 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:56:04.901929 ops/training.py:65 2019-01-16 12:56:04.901874: step 15584, loss = 0.43173 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:56:05.863617 ops/training.py:65 2019-01-16 12:56:05.863566: step 15585, loss = 0.29325 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:56:06.823731 ops/training.py:65 2019-01-16 12:56:06.823664: step 15586, loss = 0.40042 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:56:07.784773 ops/training.py:65 2019-01-16 12:56:07.784724: step 15587, loss = 0.49758 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:56:08.746774 ops/training.py:65 2019-01-16 12:56:08.746716: step 15588, loss = 0.35266 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:56:09.707623 ops/training.py:65 2019-01-16 12:56:09.707565: step 15589, loss = 0.38357 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:56:10.667442 ops/training.py:65 2019-01-16 12:56:10.667380: step 15590, loss = 0.37888 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:56:11.625348 ops/training.py:65 2019-01-16 12:56:11.625282: step 15591, loss = 0.58855 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:56:12.585870 ops/training.py:65 2019-01-16 12:56:12.585806: step 15592, loss = 0.48158 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:56:13.546195 ops/training.py:65 2019-01-16 12:56:13.546141: step 15593, loss = 0.57249 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:56:14.510337 ops/training.py:65 2019-01-16 12:56:14.510289: step 15594, loss = 0.53765 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:56:15.474051 ops/training.py:65 2019-01-16 12:56:15.474011: step 15595, loss = 0.34974 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:56:16.436590 ops/training.py:65 2019-01-16 12:56:16.436545: step 15596, loss = 0.41072 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:56:17.397980 ops/training.py:65 2019-01-16 12:56:17.397925: step 15597, loss = 0.53523 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:56:18.359087 ops/training.py:65 2019-01-16 12:56:18.359025: step 15598, loss = 0.48800 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:56:19.319161 ops/training.py:65 2019-01-16 12:56:19.319098: step 15599, loss = 0.41522 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:56:20.279146 ops/training.py:65 2019-01-16 12:56:20.279084: step 15600, loss = 0.41312 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:56:21.239086 ops/training.py:65 2019-01-16 12:56:21.239038: step 15601, loss = 0.37057 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:56:22.197688 ops/training.py:65 2019-01-16 12:56:22.197628: step 15602, loss = 0.35582 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:56:23.156626 ops/training.py:65 2019-01-16 12:56:23.156580: step 15603, loss = 0.48254 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:56:24.116772 ops/training.py:65 2019-01-16 12:56:24.116723: step 15604, loss = 0.35339 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:56:25.077241 ops/training.py:65 2019-01-16 12:56:25.077174: step 15605, loss = 0.41916 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:56:26.036228 ops/training.py:65 2019-01-16 12:56:26.036164: step 15606, loss = 0.41306 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:56:26.999299 ops/training.py:65 2019-01-16 12:56:26.999252: step 15607, loss = 0.35029 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:56:27.962783 ops/training.py:65 2019-01-16 12:56:27.962734: step 15608, loss = 0.37643 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:56:28.925268 ops/training.py:65 2019-01-16 12:56:28.925221: step 15609, loss = 0.45678 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:56:29.888110 ops/training.py:65 2019-01-16 12:56:29.888057: step 15610, loss = 0.42303 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:56:30.850199 ops/training.py:65 2019-01-16 12:56:30.850148: step 15611, loss = 0.37823 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:56:31.811064 ops/training.py:65 2019-01-16 12:56:31.810994: step 15612, loss = 0.41018 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:56:32.775744 ops/training.py:65 2019-01-16 12:56:32.775676: step 15613, loss = 0.37467 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:56:33.737345 ops/training.py:65 2019-01-16 12:56:33.737283: step 15614, loss = 0.39410 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:56:34.699997 ops/training.py:65 2019-01-16 12:56:34.699942: step 15615, loss = 0.35428 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:56:35.659617 ops/training.py:65 2019-01-16 12:56:35.659566: step 15616, loss = 0.37428 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:56:36.619955 ops/training.py:65 2019-01-16 12:56:36.619904: step 15617, loss = 0.38260 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:56:37.584456 ops/training.py:65 2019-01-16 12:56:37.584403: step 15618, loss = 0.39232 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:56:38.545558 ops/training.py:65 2019-01-16 12:56:38.545510: step 15619, loss = 0.42220 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:56:39.510237 ops/training.py:65 2019-01-16 12:56:39.510189: step 15620, loss = 0.37601 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:56:40.471442 ops/training.py:65 2019-01-16 12:56:40.471377: step 15621, loss = 0.42102 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:56:41.432558 ops/training.py:65 2019-01-16 12:56:41.432513: step 15622, loss = 0.49110 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:56:42.394564 ops/training.py:65 2019-01-16 12:56:42.394514: step 15623, loss = 0.31562 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:56:43.355582 ops/training.py:65 2019-01-16 12:56:43.355524: step 15624, loss = 0.40464 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:56:44.316019 ops/training.py:65 2019-01-16 12:56:44.315964: step 15625, loss = 0.44486 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:56:45.277107 ops/training.py:65 2019-01-16 12:56:45.277063: step 15626, loss = 0.32167 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:56:46.237308 ops/training.py:65 2019-01-16 12:56:46.237250: step 15627, loss = 0.38371 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:56:47.200889 ops/training.py:65 2019-01-16 12:56:47.200819: step 15628, loss = 0.45067 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:56:48.161324 ops/training.py:65 2019-01-16 12:56:48.161254: step 15629, loss = 0.34527 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:56:49.121020 ops/training.py:65 2019-01-16 12:56:49.120973: step 15630, loss = 0.44814 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:56:50.081606 ops/training.py:65 2019-01-16 12:56:50.081548: step 15631, loss = 0.63282 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:56:51.043774 ops/training.py:65 2019-01-16 12:56:51.043716: step 15632, loss = 0.39141 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:56:52.001835 ops/training.py:65 2019-01-16 12:56:52.001781: step 15633, loss = 0.37371 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:56:52.960263 ops/training.py:65 2019-01-16 12:56:52.960210: step 15634, loss = 0.33591 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:56:53.919878 ops/training.py:65 2019-01-16 12:56:53.919813: step 15635, loss = 0.31591 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:56:54.879231 ops/training.py:65 2019-01-16 12:56:54.879165: step 15636, loss = 0.44275 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:56:55.841904 ops/training.py:65 2019-01-16 12:56:55.841841: step 15637, loss = 0.57951 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:56:56.804935 ops/training.py:65 2019-01-16 12:56:56.804891: step 15638, loss = 0.35917 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:56:57.765895 ops/training.py:65 2019-01-16 12:56:57.765846: step 15639, loss = 0.44378 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:56:58.725948 ops/training.py:65 2019-01-16 12:56:58.725897: step 15640, loss = 0.46299 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:56:59.685846 ops/training.py:65 2019-01-16 12:56:59.685788: step 15641, loss = 0.50528 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:57:00.646209 ops/training.py:65 2019-01-16 12:57:00.646160: step 15642, loss = 0.56752 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:57:01.606630 ops/training.py:65 2019-01-16 12:57:01.606578: step 15643, loss = 0.48863 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:57:02.566463 ops/training.py:65 2019-01-16 12:57:02.566409: step 15644, loss = 0.43431 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:57:03.527286 ops/training.py:65 2019-01-16 12:57:03.527223: step 15645, loss = 0.34032 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:57:04.494625 ops/training.py:65 2019-01-16 12:57:04.494581: step 15646, loss = 0.48555 (33.1 examples/sec; 0.966 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:57:05.456488 ops/training.py:65 2019-01-16 12:57:05.456444: step 15647, loss = 0.39635 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:57:06.418131 ops/training.py:65 2019-01-16 12:57:06.418083: step 15648, loss = 0.37737 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:57:07.381415 ops/training.py:65 2019-01-16 12:57:07.381358: step 15649, loss = 0.53900 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:57:08.342252 ops/training.py:65 2019-01-16 12:57:08.342203: step 15650, loss = 0.63725 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:57:09.302459 ops/training.py:65 2019-01-16 12:57:09.302408: step 15651, loss = 0.49378 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:57:10.264225 ops/training.py:65 2019-01-16 12:57:10.264171: step 15652, loss = 0.35748 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:57:11.226400 ops/training.py:65 2019-01-16 12:57:11.226348: step 15653, loss = 0.42127 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:57:12.187321 ops/training.py:65 2019-01-16 12:57:12.187252: step 15654, loss = 0.38169 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:57:13.151531 ops/training.py:65 2019-01-16 12:57:13.151468: step 15655, loss = 0.37903 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:57:14.115700 ops/training.py:65 2019-01-16 12:57:14.115645: step 15656, loss = 0.62322 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:57:15.079422 ops/training.py:65 2019-01-16 12:57:15.079356: step 15657, loss = 0.49636 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:57:16.041539 ops/training.py:65 2019-01-16 12:57:16.041479: step 15658, loss = 0.36455 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:57:17.003573 ops/training.py:65 2019-01-16 12:57:17.003520: step 15659, loss = 0.43658 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:57:17.966198 ops/training.py:65 2019-01-16 12:57:17.966138: step 15660, loss = 0.37302 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:57:18.927953 ops/training.py:65 2019-01-16 12:57:18.927899: step 15661, loss = 0.32410 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:57:19.888501 ops/training.py:65 2019-01-16 12:57:19.888446: step 15662, loss = 0.41331 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:57:20.851767 ops/training.py:65 2019-01-16 12:57:20.851699: step 15663, loss = 0.33893 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:57:21.814055 ops/training.py:65 2019-01-16 12:57:21.814003: step 15664, loss = 0.52649 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:57:22.774414 ops/training.py:65 2019-01-16 12:57:22.774368: step 15665, loss = 0.57324 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:57:23.735369 ops/training.py:65 2019-01-16 12:57:23.735319: step 15666, loss = 0.42629 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:57:24.696685 ops/training.py:65 2019-01-16 12:57:24.696632: step 15667, loss = 0.50768 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:57:25.657633 ops/training.py:65 2019-01-16 12:57:25.657578: step 15668, loss = 0.42832 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:57:26.620883 ops/training.py:65 2019-01-16 12:57:26.620838: step 15669, loss = 0.28443 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:57:27.581496 ops/training.py:65 2019-01-16 12:57:27.581429: step 15670, loss = 0.50969 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:57:28.543179 ops/training.py:65 2019-01-16 12:57:28.543107: step 15671, loss = 0.59941 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 12:57:29.504625 ops/training.py:65 2019-01-16 12:57:29.504559: step 15672, loss = 0.54996 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:57:30.465607 ops/training.py:65 2019-01-16 12:57:30.465564: step 15673, loss = 0.42181 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:57:31.428312 ops/training.py:65 2019-01-16 12:57:31.428263: step 15674, loss = 0.56029 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:57:32.387162 ops/training.py:65 2019-01-16 12:57:32.387114: step 15675, loss = 0.45896 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:57:33.346154 ops/training.py:65 2019-01-16 12:57:33.346101: step 15676, loss = 0.31761 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:57:34.309708 ops/training.py:65 2019-01-16 12:57:34.309658: step 15677, loss = 0.40477 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:57:35.271157 ops/training.py:65 2019-01-16 12:57:35.271105: step 15678, loss = 0.51733 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:57:36.236967 ops/training.py:65 2019-01-16 12:57:36.236916: step 15679, loss = 0.52212 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:57:37.199026 ops/training.py:65 2019-01-16 12:57:37.198971: step 15680, loss = 0.49793 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:57:38.161801 ops/training.py:65 2019-01-16 12:57:38.161753: step 15681, loss = 0.42753 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:57:39.126962 ops/training.py:65 2019-01-16 12:57:39.126913: step 15682, loss = 0.48931 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:57:40.089768 ops/training.py:65 2019-01-16 12:57:40.089721: step 15683, loss = 0.52421 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:57:41.053202 ops/training.py:65 2019-01-16 12:57:41.053145: step 15684, loss = 0.49445 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:57:42.013548 ops/training.py:65 2019-01-16 12:57:42.013493: step 15685, loss = 0.46345 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:57:42.974392 ops/training.py:65 2019-01-16 12:57:42.974339: step 15686, loss = 0.43323 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:57:43.939524 ops/training.py:65 2019-01-16 12:57:43.939463: step 15687, loss = 0.44392 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:57:44.902801 ops/training.py:65 2019-01-16 12:57:44.902747: step 15688, loss = 0.45755 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:57:45.865084 ops/training.py:65 2019-01-16 12:57:45.865034: step 15689, loss = 0.32831 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:57:46.825335 ops/training.py:65 2019-01-16 12:57:46.825285: step 15690, loss = 0.31831 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:57:47.789544 ops/training.py:65 2019-01-16 12:57:47.789478: step 15691, loss = 0.36141 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:57:48.752822 ops/training.py:65 2019-01-16 12:57:48.752756: step 15692, loss = 0.47719 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:57:49.714385 ops/training.py:65 2019-01-16 12:57:49.714336: step 15693, loss = 0.38047 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:57:50.675444 ops/training.py:65 2019-01-16 12:57:50.675391: step 15694, loss = 0.42266 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:57:51.636144 ops/training.py:65 2019-01-16 12:57:51.636099: step 15695, loss = 0.37849 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:57:52.596503 ops/training.py:65 2019-01-16 12:57:52.596449: step 15696, loss = 0.33801 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:57:53.556822 ops/training.py:65 2019-01-16 12:57:53.556773: step 15697, loss = 0.53061 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:57:54.518196 ops/training.py:65 2019-01-16 12:57:54.518139: step 15698, loss = 0.34532 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:57:55.479070 ops/training.py:65 2019-01-16 12:57:55.479002: step 15699, loss = 0.44647 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:57:56.438770 ops/training.py:65 2019-01-16 12:57:56.438713: step 15700, loss = 0.45739 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:57:57.398020 ops/training.py:65 2019-01-16 12:57:57.397973: step 15701, loss = 0.32624 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:57:58.357887 ops/training.py:65 2019-01-16 12:57:58.357821: step 15702, loss = 0.49674 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:57:59.317108 ops/training.py:65 2019-01-16 12:57:59.317042: step 15703, loss = 0.33684 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:58:00.275888 ops/training.py:65 2019-01-16 12:58:00.275847: step 15704, loss = 0.44555 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:58:01.239399 ops/training.py:65 2019-01-16 12:58:01.239339: step 15705, loss = 0.54717 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:58:02.203801 ops/training.py:65 2019-01-16 12:58:02.203761: step 15706, loss = 0.45908 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:58:03.168472 ops/training.py:65 2019-01-16 12:58:03.168425: step 15707, loss = 0.57779 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:58:04.131740 ops/training.py:65 2019-01-16 12:58:04.131693: step 15708, loss = 0.65989 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 12:58:05.093310 ops/training.py:65 2019-01-16 12:58:05.093240: step 15709, loss = 0.60889 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:58:06.053597 ops/training.py:65 2019-01-16 12:58:06.053523: step 15710, loss = 0.59054 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:58:07.014467 ops/training.py:65 2019-01-16 12:58:07.014397: step 15711, loss = 0.37166 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:58:07.972900 ops/training.py:65 2019-01-16 12:58:07.972854: step 15712, loss = 0.34785 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:58:08.932747 ops/training.py:65 2019-01-16 12:58:08.932698: step 15713, loss = 0.41355 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:58:09.894050 ops/training.py:65 2019-01-16 12:58:09.894000: step 15714, loss = 0.54452 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:58:10.856979 ops/training.py:65 2019-01-16 12:58:10.856922: step 15715, loss = 0.30029 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:58:11.818004 ops/training.py:65 2019-01-16 12:58:11.817936: step 15716, loss = 0.54692 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:58:12.782454 ops/training.py:65 2019-01-16 12:58:12.782404: step 15717, loss = 0.35551 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:58:13.744349 ops/training.py:65 2019-01-16 12:58:13.744306: step 15718, loss = 0.41906 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:58:14.706263 ops/training.py:65 2019-01-16 12:58:14.706221: step 15719, loss = 0.44539 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:58:15.668286 ops/training.py:65 2019-01-16 12:58:15.668238: step 15720, loss = 0.35486 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:58:16.632666 ops/training.py:65 2019-01-16 12:58:16.632611: step 15721, loss = 0.52639 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:58:17.594587 ops/training.py:65 2019-01-16 12:58:17.594546: step 15722, loss = 0.45895 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:58:18.556227 ops/training.py:65 2019-01-16 12:58:18.556173: step 15723, loss = 0.46001 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:58:19.518470 ops/training.py:65 2019-01-16 12:58:19.518423: step 15724, loss = 0.52059 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:58:20.481188 ops/training.py:65 2019-01-16 12:58:20.481140: step 15725, loss = 0.41814 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:58:21.441650 ops/training.py:65 2019-01-16 12:58:21.441603: step 15726, loss = 0.46551 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:58:22.402531 ops/training.py:65 2019-01-16 12:58:22.402472: step 15727, loss = 0.54056 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:58:23.362844 ops/training.py:65 2019-01-16 12:58:23.362793: step 15728, loss = 0.47588 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:58:24.321977 ops/training.py:65 2019-01-16 12:58:24.321928: step 15729, loss = 0.40873 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:58:25.282225 ops/training.py:65 2019-01-16 12:58:25.282173: step 15730, loss = 0.42485 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:58:26.245825 ops/training.py:65 2019-01-16 12:58:26.245785: step 15731, loss = 0.49652 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:58:27.208231 ops/training.py:65 2019-01-16 12:58:27.208187: step 15732, loss = 0.36684 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:58:28.168330 ops/training.py:65 2019-01-16 12:58:28.168235: step 15733, loss = 0.39988 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:58:29.128469 ops/training.py:65 2019-01-16 12:58:29.128408: step 15734, loss = 0.39687 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:58:30.087948 ops/training.py:65 2019-01-16 12:58:30.087889: step 15735, loss = 0.35964 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:58:31.046377 ops/training.py:65 2019-01-16 12:58:31.046310: step 15736, loss = 0.46216 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:58:32.004908 ops/training.py:65 2019-01-16 12:58:32.004834: step 15737, loss = 0.48975 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:58:32.963647 ops/training.py:65 2019-01-16 12:58:32.963595: step 15738, loss = 0.52863 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:58:33.922173 ops/training.py:65 2019-01-16 12:58:33.922129: step 15739, loss = 0.37529 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:58:34.881800 ops/training.py:65 2019-01-16 12:58:34.881746: step 15740, loss = 0.37957 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:58:35.843390 ops/training.py:65 2019-01-16 12:58:35.843323: step 15741, loss = 0.52279 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:58:36.803628 ops/training.py:65 2019-01-16 12:58:36.803583: step 15742, loss = 0.53277 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:58:37.764691 ops/training.py:65 2019-01-16 12:58:37.764637: step 15743, loss = 0.40231 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:58:38.726865 ops/training.py:65 2019-01-16 12:58:38.726810: step 15744, loss = 0.45986 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:58:39.687375 ops/training.py:65 2019-01-16 12:58:39.687317: step 15745, loss = 0.41303 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:58:40.647837 ops/training.py:65 2019-01-16 12:58:40.647785: step 15746, loss = 0.40180 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:58:41.610809 ops/training.py:65 2019-01-16 12:58:41.610753: step 15747, loss = 0.39202 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:58:42.574437 ops/training.py:65 2019-01-16 12:58:42.574385: step 15748, loss = 0.36017 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:58:43.536579 ops/training.py:65 2019-01-16 12:58:43.536514: step 15749, loss = 0.38243 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:58:44.498424 ops/training.py:65 2019-01-16 12:58:44.498353: step 15750, loss = 0.47274 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:58:45.460305 ops/training.py:65 2019-01-16 12:58:45.460232: step 15751, loss = 0.43215 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:58:46.420904 ops/training.py:65 2019-01-16 12:58:46.420833: step 15752, loss = 0.44540 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:58:47.381337 ops/training.py:65 2019-01-16 12:58:47.381283: step 15753, loss = 0.41504 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:58:48.344809 ops/training.py:65 2019-01-16 12:58:48.344764: step 15754, loss = 0.52126 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:58:49.307035 ops/training.py:65 2019-01-16 12:58:49.306983: step 15755, loss = 0.45735 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:58:50.268757 ops/training.py:65 2019-01-16 12:58:50.268690: step 15756, loss = 0.40297 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:58:51.232038 ops/training.py:65 2019-01-16 12:58:51.231973: step 15757, loss = 0.36670 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:58:52.192696 ops/training.py:65 2019-01-16 12:58:52.192628: step 15758, loss = 0.34702 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:58:53.157489 ops/training.py:65 2019-01-16 12:58:53.157430: step 15759, loss = 0.39848 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:58:54.117354 ops/training.py:65 2019-01-16 12:58:54.117284: step 15760, loss = 0.40229 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:58:55.081366 ops/training.py:65 2019-01-16 12:58:55.081301: step 15761, loss = 0.44787 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:58:56.042368 ops/training.py:65 2019-01-16 12:58:56.042302: step 15762, loss = 0.41843 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:58:57.004008 ops/training.py:65 2019-01-16 12:58:57.003939: step 15763, loss = 0.33409 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:58:57.965486 ops/training.py:65 2019-01-16 12:58:57.965424: step 15764, loss = 0.36952 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:58:58.926881 ops/training.py:65 2019-01-16 12:58:58.926816: step 15765, loss = 0.53565 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:58:59.888417 ops/training.py:65 2019-01-16 12:58:59.888349: step 15766, loss = 0.40070 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:59:00.850569 ops/training.py:65 2019-01-16 12:59:00.850504: step 15767, loss = 0.25318 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:59:01.811952 ops/training.py:65 2019-01-16 12:59:01.811878: step 15768, loss = 0.55496 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:59:02.773049 ops/training.py:65 2019-01-16 12:59:02.772986: step 15769, loss = 0.36530 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:59:03.732156 ops/training.py:65 2019-01-16 12:59:03.732102: step 15770, loss = 0.47667 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:59:04.690753 ops/training.py:65 2019-01-16 12:59:04.690700: step 15771, loss = 0.32486 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:59:05.648924 ops/training.py:65 2019-01-16 12:59:05.648871: step 15772, loss = 0.31402 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:59:06.611745 ops/training.py:65 2019-01-16 12:59:06.611712: step 15773, loss = 0.47049 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:59:07.573684 ops/training.py:65 2019-01-16 12:59:07.573624: step 15774, loss = 0.52785 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:59:08.535279 ops/training.py:65 2019-01-16 12:59:08.535206: step 15775, loss = 0.51272 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:59:09.497038 ops/training.py:65 2019-01-16 12:59:09.496962: step 15776, loss = 0.47288 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:59:10.458098 ops/training.py:65 2019-01-16 12:59:10.458024: step 15777, loss = 0.43176 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:59:11.420073 ops/training.py:65 2019-01-16 12:59:11.420016: step 15778, loss = 0.49307 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 12:59:12.381981 ops/training.py:65 2019-01-16 12:59:12.381931: step 15779, loss = 0.32732 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:59:13.343039 ops/training.py:65 2019-01-16 12:59:13.342967: step 15780, loss = 0.43242 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:59:14.303631 ops/training.py:65 2019-01-16 12:59:14.303561: step 15781, loss = 0.53532 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 12:59:15.265064 ops/training.py:65 2019-01-16 12:59:15.264995: step 15782, loss = 0.49097 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:59:16.226302 ops/training.py:65 2019-01-16 12:59:16.226230: step 15783, loss = 0.56028 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:59:17.187089 ops/training.py:65 2019-01-16 12:59:17.187022: step 15784, loss = 0.44777 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:59:18.147799 ops/training.py:65 2019-01-16 12:59:18.147731: step 15785, loss = 0.38461 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:59:19.109287 ops/training.py:65 2019-01-16 12:59:19.109227: step 15786, loss = 0.57801 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 12:59:20.069866 ops/training.py:65 2019-01-16 12:59:20.069783: step 15787, loss = 0.41369 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:59:21.031380 ops/training.py:65 2019-01-16 12:59:21.031313: step 15788, loss = 0.44748 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:59:21.992297 ops/training.py:65 2019-01-16 12:59:21.992235: step 15789, loss = 0.42224 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:59:22.953275 ops/training.py:65 2019-01-16 12:59:22.953206: step 15790, loss = 0.38477 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:59:23.914050 ops/training.py:65 2019-01-16 12:59:23.913981: step 15791, loss = 0.35866 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:59:24.875168 ops/training.py:65 2019-01-16 12:59:24.875099: step 15792, loss = 0.45232 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:59:25.836723 ops/training.py:65 2019-01-16 12:59:25.836656: step 15793, loss = 0.50966 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:59:26.797012 ops/training.py:65 2019-01-16 12:59:26.796946: step 15794, loss = 0.36331 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:59:27.757405 ops/training.py:65 2019-01-16 12:59:27.757355: step 15795, loss = 0.45261 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:59:28.718717 ops/training.py:65 2019-01-16 12:59:28.718651: step 15796, loss = 0.39117 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:59:29.679188 ops/training.py:65 2019-01-16 12:59:29.679128: step 15797, loss = 0.39342 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:59:30.639652 ops/training.py:65 2019-01-16 12:59:30.639588: step 15798, loss = 0.41540 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:59:31.600796 ops/training.py:65 2019-01-16 12:59:31.600726: step 15799, loss = 0.43774 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:59:32.561736 ops/training.py:65 2019-01-16 12:59:32.561668: step 15800, loss = 0.33500 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:59:33.522918 ops/training.py:65 2019-01-16 12:59:33.522848: step 15801, loss = 0.42329 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:59:34.484048 ops/training.py:65 2019-01-16 12:59:34.483978: step 15802, loss = 0.39738 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:59:35.445194 ops/training.py:65 2019-01-16 12:59:35.445126: step 15803, loss = 0.42782 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:59:36.404896 ops/training.py:65 2019-01-16 12:59:36.404849: step 15804, loss = 0.38339 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 12:59:37.364556 ops/training.py:65 2019-01-16 12:59:37.364484: step 15805, loss = 0.32939 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:59:38.328447 ops/training.py:65 2019-01-16 12:59:38.328377: step 15806, loss = 0.35779 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:59:39.292644 ops/training.py:65 2019-01-16 12:59:39.292582: step 15807, loss = 0.45543 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:59:40.256325 ops/training.py:65 2019-01-16 12:59:40.256254: step 15808, loss = 0.39712 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:59:41.218377 ops/training.py:65 2019-01-16 12:59:41.218310: step 15809, loss = 0.43357 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:59:42.180213 ops/training.py:65 2019-01-16 12:59:42.180155: step 15810, loss = 0.43087 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:59:43.141770 ops/training.py:65 2019-01-16 12:59:43.141702: step 15811, loss = 0.41611 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:59:44.102929 ops/training.py:65 2019-01-16 12:59:44.102859: step 15812, loss = 0.44334 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:59:45.064758 ops/training.py:65 2019-01-16 12:59:45.064689: step 15813, loss = 0.34792 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:59:46.026424 ops/training.py:65 2019-01-16 12:59:46.026357: step 15814, loss = 0.37264 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:59:46.988064 ops/training.py:65 2019-01-16 12:59:46.988006: step 15815, loss = 0.37028 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:59:47.948047 ops/training.py:65 2019-01-16 12:59:47.947980: step 15816, loss = 0.42737 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:59:48.908123 ops/training.py:65 2019-01-16 12:59:48.908056: step 15817, loss = 0.33205 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 12:59:49.868501 ops/training.py:65 2019-01-16 12:59:49.868435: step 15818, loss = 0.47746 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:59:50.830683 ops/training.py:65 2019-01-16 12:59:50.830631: step 15819, loss = 0.41480 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:59:51.793957 ops/training.py:65 2019-01-16 12:59:51.793904: step 15820, loss = 0.45794 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:59:52.757237 ops/training.py:65 2019-01-16 12:59:52.757174: step 15821, loss = 0.41777 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 12:59:53.717318 ops/training.py:65 2019-01-16 12:59:53.717254: step 15822, loss = 0.37428 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:59:54.677114 ops/training.py:65 2019-01-16 12:59:54.677048: step 15823, loss = 0.45471 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:59:55.636585 ops/training.py:65 2019-01-16 12:59:55.636519: step 15824, loss = 0.34518 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 12:59:56.600371 ops/training.py:65 2019-01-16 12:59:56.600303: step 15825, loss = 0.42204 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 12:59:57.563953 ops/training.py:65 2019-01-16 12:59:57.563906: step 15826, loss = 0.45535 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 12:59:58.524619 ops/training.py:65 2019-01-16 12:59:58.524548: step 15827, loss = 0.38943 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 12:59:59.484565 ops/training.py:65 2019-01-16 12:59:59.484502: step 15828, loss = 0.44020 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:00:00.445033 ops/training.py:65 2019-01-16 13:00:00.444960: step 15829, loss = 0.54213 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:00:01.409961 ops/training.py:65 2019-01-16 13:00:01.409889: step 15830, loss = 0.38069 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:00:02.373876 ops/training.py:65 2019-01-16 13:00:02.373820: step 15831, loss = 0.38504 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:00:03.334879 ops/training.py:65 2019-01-16 13:00:03.334806: step 15832, loss = 0.35337 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:00:04.295472 ops/training.py:65 2019-01-16 13:00:04.295404: step 15833, loss = 0.31362 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:00:05.255958 ops/training.py:65 2019-01-16 13:00:05.255888: step 15834, loss = 0.28944 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:00:06.215714 ops/training.py:65 2019-01-16 13:00:06.215658: step 15835, loss = 0.49979 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:00:07.177973 ops/training.py:65 2019-01-16 13:00:07.177912: step 15836, loss = 0.32980 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:00:08.141550 ops/training.py:65 2019-01-16 13:00:08.141458: step 15837, loss = 0.42312 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:00:09.104361 ops/training.py:65 2019-01-16 13:00:09.104296: step 15838, loss = 0.44299 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:00:10.066794 ops/training.py:65 2019-01-16 13:00:10.066728: step 15839, loss = 0.35784 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:00:11.028970 ops/training.py:65 2019-01-16 13:00:11.028902: step 15840, loss = 0.38740 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:00:11.990324 ops/training.py:65 2019-01-16 13:00:11.990272: step 15841, loss = 0.41530 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:00:12.951531 ops/training.py:65 2019-01-16 13:00:12.951472: step 15842, loss = 0.33647 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:00:13.912872 ops/training.py:65 2019-01-16 13:00:13.912806: step 15843, loss = 0.36684 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:00:14.874595 ops/training.py:65 2019-01-16 13:00:14.874526: step 15844, loss = 0.42684 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:00:15.836856 ops/training.py:65 2019-01-16 13:00:15.836793: step 15845, loss = 0.45409 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:00:16.799675 ops/training.py:65 2019-01-16 13:00:16.799609: step 15846, loss = 0.34953 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:00:17.760999 ops/training.py:65 2019-01-16 13:00:17.760933: step 15847, loss = 0.36058 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:00:18.723550 ops/training.py:65 2019-01-16 13:00:18.723482: step 15848, loss = 0.50974 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:00:19.685392 ops/training.py:65 2019-01-16 13:00:19.685323: step 15849, loss = 0.38656 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:00:20.647564 ops/training.py:65 2019-01-16 13:00:20.647498: step 15850, loss = 0.43394 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:00:21.608504 ops/training.py:65 2019-01-16 13:00:21.608453: step 15851, loss = 0.47428 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:00:22.572421 ops/training.py:65 2019-01-16 13:00:22.572354: step 15852, loss = 0.51930 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:00:23.536412 ops/training.py:65 2019-01-16 13:00:23.536347: step 15853, loss = 0.37351 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:00:24.500689 ops/training.py:65 2019-01-16 13:00:24.500626: step 15854, loss = 0.34998 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:00:25.463043 ops/training.py:65 2019-01-16 13:00:25.462980: step 15855, loss = 0.42480 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:00:26.424255 ops/training.py:65 2019-01-16 13:00:26.424187: step 15856, loss = 0.41601 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:00:27.385966 ops/training.py:65 2019-01-16 13:00:27.385897: step 15857, loss = 0.51586 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:00:28.348526 ops/training.py:65 2019-01-16 13:00:28.348472: step 15858, loss = 0.39693 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:00:29.310287 ops/training.py:65 2019-01-16 13:00:29.310219: step 15859, loss = 0.41428 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:00:30.274720 ops/training.py:65 2019-01-16 13:00:30.274649: step 15860, loss = 0.51487 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:00:31.238536 ops/training.py:65 2019-01-16 13:00:31.238469: step 15861, loss = 0.31752 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:00:32.201399 ops/training.py:65 2019-01-16 13:00:32.201333: step 15862, loss = 0.51797 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:00:33.163842 ops/training.py:65 2019-01-16 13:00:33.163775: step 15863, loss = 0.37686 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:00:34.126178 ops/training.py:65 2019-01-16 13:00:34.126107: step 15864, loss = 0.39776 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:00:35.087983 ops/training.py:65 2019-01-16 13:00:35.087916: step 15865, loss = 0.24350 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:00:36.049829 ops/training.py:65 2019-01-16 13:00:36.049752: step 15866, loss = 0.46491 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:00:37.010912 ops/training.py:65 2019-01-16 13:00:37.010862: step 15867, loss = 0.54275 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:00:37.971799 ops/training.py:65 2019-01-16 13:00:37.971729: step 15868, loss = 0.39320 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:00:38.932004 ops/training.py:65 2019-01-16 13:00:38.931943: step 15869, loss = 0.62162 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.53125
I0832 2019-01-16 13:00:39.895152 ops/training.py:65 2019-01-16 13:00:39.895086: step 15870, loss = 0.57623 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:00:40.858652 ops/training.py:65 2019-01-16 13:00:40.858584: step 15871, loss = 0.36643 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:00:41.822130 ops/training.py:65 2019-01-16 13:00:41.822076: step 15872, loss = 0.42267 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:00:42.783058 ops/training.py:65 2019-01-16 13:00:42.782998: step 15873, loss = 0.45000 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:00:43.743856 ops/training.py:65 2019-01-16 13:00:43.743793: step 15874, loss = 0.46801 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:00:44.706078 ops/training.py:65 2019-01-16 13:00:44.706009: step 15875, loss = 0.48228 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:00:45.667218 ops/training.py:65 2019-01-16 13:00:45.667151: step 15876, loss = 0.29179 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:00:46.628938 ops/training.py:65 2019-01-16 13:00:46.628868: step 15877, loss = 0.41410 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:00:47.590199 ops/training.py:65 2019-01-16 13:00:47.590132: step 15878, loss = 0.45635 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:00:48.552268 ops/training.py:65 2019-01-16 13:00:48.552199: step 15879, loss = 0.43874 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:00:49.514180 ops/training.py:65 2019-01-16 13:00:49.514110: step 15880, loss = 0.66591 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:00:50.475993 ops/training.py:65 2019-01-16 13:00:50.475926: step 15881, loss = 0.46625 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:00:51.437855 ops/training.py:65 2019-01-16 13:00:51.437789: step 15882, loss = 0.54286 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:00:52.400096 ops/training.py:65 2019-01-16 13:00:52.400030: step 15883, loss = 0.51324 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:00:53.361312 ops/training.py:65 2019-01-16 13:00:53.361243: step 15884, loss = 0.28445 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:00:54.324125 ops/training.py:65 2019-01-16 13:00:54.324059: step 15885, loss = 0.57198 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:00:55.286483 ops/training.py:65 2019-01-16 13:00:55.286411: step 15886, loss = 0.39966 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:00:56.247935 ops/training.py:65 2019-01-16 13:00:56.247868: step 15887, loss = 0.38618 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:00:57.208740 ops/training.py:65 2019-01-16 13:00:57.208672: step 15888, loss = 0.32233 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:00:58.169182 ops/training.py:65 2019-01-16 13:00:58.169127: step 15889, loss = 0.50688 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:00:59.130540 ops/training.py:65 2019-01-16 13:00:59.130476: step 15890, loss = 0.44525 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:01:00.092822 ops/training.py:65 2019-01-16 13:01:00.092753: step 15891, loss = 0.49039 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:01:01.054484 ops/training.py:65 2019-01-16 13:01:01.054421: step 15892, loss = 0.30202 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:01:02.018085 ops/training.py:65 2019-01-16 13:01:02.018029: step 15893, loss = 0.36517 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:01:02.979573 ops/training.py:65 2019-01-16 13:01:02.979500: step 15894, loss = 0.39361 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:01:03.939871 ops/training.py:65 2019-01-16 13:01:03.939799: step 15895, loss = 0.30342 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:01:04.901135 ops/training.py:65 2019-01-16 13:01:04.901074: step 15896, loss = 0.49193 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:01:05.861269 ops/training.py:65 2019-01-16 13:01:05.861217: step 15897, loss = 0.53202 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:01:06.824433 ops/training.py:65 2019-01-16 13:01:06.824384: step 15898, loss = 0.32951 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:01:07.787492 ops/training.py:65 2019-01-16 13:01:07.787424: step 15899, loss = 0.43033 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:01:08.750261 ops/training.py:65 2019-01-16 13:01:08.750192: step 15900, loss = 0.25826 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:01:09.712764 ops/training.py:65 2019-01-16 13:01:09.712700: step 15901, loss = 0.34231 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:01:10.674261 ops/training.py:65 2019-01-16 13:01:10.674194: step 15902, loss = 0.52152 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 13:01:11.634314 ops/training.py:65 2019-01-16 13:01:11.634264: step 15903, loss = 0.43452 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:01:12.594611 ops/training.py:65 2019-01-16 13:01:12.594560: step 15904, loss = 0.45959 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:01:13.559494 ops/training.py:65 2019-01-16 13:01:13.559427: step 15905, loss = 0.36197 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:01:14.524200 ops/training.py:65 2019-01-16 13:01:14.524135: step 15906, loss = 0.32770 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:01:15.486825 ops/training.py:65 2019-01-16 13:01:15.486757: step 15907, loss = 0.41612 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:01:16.448392 ops/training.py:65 2019-01-16 13:01:16.448312: step 15908, loss = 0.39059 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:01:17.409322 ops/training.py:65 2019-01-16 13:01:17.409255: step 15909, loss = 0.27097 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:01:18.370951 ops/training.py:65 2019-01-16 13:01:18.370885: step 15910, loss = 0.48688 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:01:19.332547 ops/training.py:65 2019-01-16 13:01:19.332486: step 15911, loss = 0.44829 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:01:20.293213 ops/training.py:65 2019-01-16 13:01:20.293166: step 15912, loss = 0.43360 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:01:21.253850 ops/training.py:65 2019-01-16 13:01:21.253802: step 15913, loss = 0.47884 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:01:22.215031 ops/training.py:65 2019-01-16 13:01:22.214972: step 15914, loss = 0.33543 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:01:23.177033 ops/training.py:65 2019-01-16 13:01:23.176984: step 15915, loss = 0.45864 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:01:24.138424 ops/training.py:65 2019-01-16 13:01:24.138374: step 15916, loss = 0.40556 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:01:25.099524 ops/training.py:65 2019-01-16 13:01:25.099474: step 15917, loss = 0.41170 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:01:26.059940 ops/training.py:65 2019-01-16 13:01:26.059878: step 15918, loss = 0.46664 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:01:27.020220 ops/training.py:65 2019-01-16 13:01:27.020172: step 15919, loss = 0.39517 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:01:27.981100 ops/training.py:65 2019-01-16 13:01:27.981038: step 15920, loss = 0.42608 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:01:28.941742 ops/training.py:65 2019-01-16 13:01:28.941685: step 15921, loss = 0.60770 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:01:29.902013 ops/training.py:65 2019-01-16 13:01:29.901956: step 15922, loss = 0.42802 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:01:30.862904 ops/training.py:65 2019-01-16 13:01:30.862864: step 15923, loss = 0.49850 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:01:31.823625 ops/training.py:65 2019-01-16 13:01:31.823566: step 15924, loss = 0.48879 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:01:32.783337 ops/training.py:65 2019-01-16 13:01:32.783273: step 15925, loss = 0.34502 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:01:33.744335 ops/training.py:65 2019-01-16 13:01:33.744277: step 15926, loss = 0.41868 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:01:34.704765 ops/training.py:65 2019-01-16 13:01:34.704691: step 15927, loss = 0.46341 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:01:35.665620 ops/training.py:65 2019-01-16 13:01:35.665552: step 15928, loss = 0.38673 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:01:36.626633 ops/training.py:65 2019-01-16 13:01:36.626591: step 15929, loss = 0.40571 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:01:37.588586 ops/training.py:65 2019-01-16 13:01:37.588538: step 15930, loss = 0.41764 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:01:38.549153 ops/training.py:65 2019-01-16 13:01:38.549108: step 15931, loss = 0.41460 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:01:39.509788 ops/training.py:65 2019-01-16 13:01:39.509729: step 15932, loss = 0.49670 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:01:40.468794 ops/training.py:65 2019-01-16 13:01:40.468727: step 15933, loss = 0.37843 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:01:41.428333 ops/training.py:65 2019-01-16 13:01:41.428266: step 15934, loss = 0.55821 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:01:42.387629 ops/training.py:65 2019-01-16 13:01:42.387573: step 15935, loss = 0.49141 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:01:43.347492 ops/training.py:65 2019-01-16 13:01:43.347419: step 15936, loss = 0.31140 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:01:44.307146 ops/training.py:65 2019-01-16 13:01:44.307085: step 15937, loss = 0.43687 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:01:45.271908 ops/training.py:65 2019-01-16 13:01:45.271846: step 15938, loss = 0.52525 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:01:46.236159 ops/training.py:65 2019-01-16 13:01:46.236092: step 15939, loss = 0.36342 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:01:47.198557 ops/training.py:65 2019-01-16 13:01:47.198504: step 15940, loss = 0.45251 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:01:48.159859 ops/training.py:65 2019-01-16 13:01:48.159795: step 15941, loss = 0.47366 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:01:49.121484 ops/training.py:65 2019-01-16 13:01:49.121421: step 15942, loss = 0.48734 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:01:50.082712 ops/training.py:65 2019-01-16 13:01:50.082618: step 15943, loss = 0.45291 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:01:51.042762 ops/training.py:65 2019-01-16 13:01:51.042697: step 15944, loss = 0.55857 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 13:01:52.003049 ops/training.py:65 2019-01-16 13:01:52.002991: step 15945, loss = 0.43415 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:01:52.962832 ops/training.py:65 2019-01-16 13:01:52.962767: step 15946, loss = 0.47596 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:01:53.922845 ops/training.py:65 2019-01-16 13:01:53.922779: step 15947, loss = 0.41336 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:01:54.882445 ops/training.py:65 2019-01-16 13:01:54.882386: step 15948, loss = 0.42372 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:01:55.841353 ops/training.py:65 2019-01-16 13:01:55.841295: step 15949, loss = 0.49573 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:01:56.801442 ops/training.py:65 2019-01-16 13:01:56.801376: step 15950, loss = 0.34434 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:01:57.763040 ops/training.py:65 2019-01-16 13:01:57.762969: step 15951, loss = 0.48948 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:01:58.726614 ops/training.py:65 2019-01-16 13:01:58.726547: step 15952, loss = 0.48327 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:01:59.687601 ops/training.py:65 2019-01-16 13:01:59.687533: step 15953, loss = 0.44862 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:02:00.648538 ops/training.py:65 2019-01-16 13:02:00.648471: step 15954, loss = 0.41297 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:02:01.612666 ops/training.py:65 2019-01-16 13:02:01.612599: step 15955, loss = 0.37642 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:02:02.576490 ops/training.py:65 2019-01-16 13:02:02.576428: step 15956, loss = 0.37636 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:02:03.539713 ops/training.py:65 2019-01-16 13:02:03.539645: step 15957, loss = 0.40609 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:02:04.502440 ops/training.py:65 2019-01-16 13:02:04.502356: step 15958, loss = 0.39159 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:02:05.463703 ops/training.py:65 2019-01-16 13:02:05.463621: step 15959, loss = 0.47025 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:02:06.424510 ops/training.py:65 2019-01-16 13:02:06.424415: step 15960, loss = 0.46255 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:02:07.385913 ops/training.py:65 2019-01-16 13:02:07.385860: step 15961, loss = 0.40417 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:02:08.347373 ops/training.py:65 2019-01-16 13:02:08.347299: step 15962, loss = 0.37525 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:02:09.308635 ops/training.py:65 2019-01-16 13:02:09.308582: step 15963, loss = 0.38757 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:02:10.269719 ops/training.py:65 2019-01-16 13:02:10.269656: step 15964, loss = 0.34839 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:02:11.230886 ops/training.py:65 2019-01-16 13:02:11.230819: step 15965, loss = 0.36211 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:02:12.192363 ops/training.py:65 2019-01-16 13:02:12.192296: step 15966, loss = 0.37809 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:02:13.153557 ops/training.py:65 2019-01-16 13:02:13.153489: step 15967, loss = 0.52756 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:02:14.114300 ops/training.py:65 2019-01-16 13:02:14.114246: step 15968, loss = 0.29963 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:02:15.075045 ops/training.py:65 2019-01-16 13:02:15.074978: step 15969, loss = 0.34565 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:02:16.037061 ops/training.py:65 2019-01-16 13:02:16.036991: step 15970, loss = 0.37196 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:02:16.998026 ops/training.py:65 2019-01-16 13:02:16.997960: step 15971, loss = 0.52621 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:02:17.959051 ops/training.py:65 2019-01-16 13:02:17.959005: step 15972, loss = 0.32328 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:02:18.919559 ops/training.py:65 2019-01-16 13:02:18.919508: step 15973, loss = 0.43123 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:02:19.880213 ops/training.py:65 2019-01-16 13:02:19.880146: step 15974, loss = 0.45064 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:02:20.840905 ops/training.py:65 2019-01-16 13:02:20.840852: step 15975, loss = 0.48170 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:02:21.801257 ops/training.py:65 2019-01-16 13:02:21.801216: step 15976, loss = 0.54699 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 13:02:22.760682 ops/training.py:65 2019-01-16 13:02:22.760639: step 15977, loss = 0.41688 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:02:23.722150 ops/training.py:65 2019-01-16 13:02:23.722112: step 15978, loss = 0.33129 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:02:24.683041 ops/training.py:65 2019-01-16 13:02:24.682986: step 15979, loss = 0.31607 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:02:25.642833 ops/training.py:65 2019-01-16 13:02:25.642773: step 15980, loss = 0.40959 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:02:26.603124 ops/training.py:65 2019-01-16 13:02:26.603071: step 15981, loss = 0.33345 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:02:27.563235 ops/training.py:65 2019-01-16 13:02:27.563197: step 15982, loss = 0.29949 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:02:28.524378 ops/training.py:65 2019-01-16 13:02:28.524326: step 15983, loss = 0.37350 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:02:29.485293 ops/training.py:65 2019-01-16 13:02:29.485248: step 15984, loss = 0.42674 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:02:30.445740 ops/training.py:65 2019-01-16 13:02:30.445671: step 15985, loss = 0.60654 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 13:02:31.406798 ops/training.py:65 2019-01-16 13:02:31.406746: step 15986, loss = 0.36148 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:02:32.367389 ops/training.py:65 2019-01-16 13:02:32.367335: step 15987, loss = 0.40053 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:02:33.327695 ops/training.py:65 2019-01-16 13:02:33.327650: step 15988, loss = 0.49002 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:02:34.288431 ops/training.py:65 2019-01-16 13:02:34.288387: step 15989, loss = 0.49399 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:02:35.248686 ops/training.py:65 2019-01-16 13:02:35.248637: step 15990, loss = 0.38546 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:02:36.209610 ops/training.py:65 2019-01-16 13:02:36.209554: step 15991, loss = 0.64066 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 13:02:37.170482 ops/training.py:65 2019-01-16 13:02:37.170420: step 15992, loss = 0.59910 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:02:38.130861 ops/training.py:65 2019-01-16 13:02:38.130799: step 15993, loss = 0.59457 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 13:02:39.091723 ops/training.py:65 2019-01-16 13:02:39.091672: step 15994, loss = 0.37625 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:02:40.052488 ops/training.py:65 2019-01-16 13:02:40.052422: step 15995, loss = 0.38727 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:02:41.015694 ops/training.py:65 2019-01-16 13:02:41.015648: step 15996, loss = 0.49938 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 13:02:41.979081 ops/training.py:65 2019-01-16 13:02:41.979015: step 15997, loss = 0.31013 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:02:42.943117 ops/training.py:65 2019-01-16 13:02:42.943060: step 15998, loss = 0.33523 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:02:43.903859 ops/training.py:65 2019-01-16 13:02:43.903807: step 15999, loss = 0.55657 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:07:23.248925 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I0832 2019-01-16 13:07:23.249710 ops/training.py:41 2019-01-16 13:07:23.249663: step 16000, loss = 0.50 (0.1 examples/sec; 278.384 sec/batch) | Training accuracy = 0.71875 | Validation accuracy = 0.68685 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_08_07_39_512188
I0832 2019-01-16 13:07:24.213571 ops/training.py:65 2019-01-16 13:07:24.213526: step 16001, loss = 0.44551 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:07:25.175916 ops/training.py:65 2019-01-16 13:07:25.175874: step 16002, loss = 0.37330 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:07:26.137320 ops/training.py:65 2019-01-16 13:07:26.137270: step 16003, loss = 0.44857 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:07:27.098453 ops/training.py:65 2019-01-16 13:07:27.098406: step 16004, loss = 0.46352 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:07:28.058416 ops/training.py:65 2019-01-16 13:07:28.058357: step 16005, loss = 0.47091 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:07:29.020408 ops/training.py:65 2019-01-16 13:07:29.020338: step 16006, loss = 0.49189 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:07:29.981047 ops/training.py:65 2019-01-16 13:07:29.980996: step 16007, loss = 0.32513 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:07:30.942978 ops/training.py:65 2019-01-16 13:07:30.942915: step 16008, loss = 0.34575 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:07:31.907622 ops/training.py:65 2019-01-16 13:07:31.907582: step 16009, loss = 0.46167 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:07:32.871549 ops/training.py:65 2019-01-16 13:07:32.871507: step 16010, loss = 0.46213 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:07:33.834964 ops/training.py:65 2019-01-16 13:07:33.834924: step 16011, loss = 0.47282 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:07:34.796116 ops/training.py:65 2019-01-16 13:07:34.796076: step 16012, loss = 0.43624 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:07:35.757268 ops/training.py:65 2019-01-16 13:07:35.757225: step 16013, loss = 0.40061 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:07:36.718305 ops/training.py:65 2019-01-16 13:07:36.718255: step 16014, loss = 0.45646 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:07:37.679959 ops/training.py:65 2019-01-16 13:07:37.679907: step 16015, loss = 0.56025 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:07:38.641229 ops/training.py:65 2019-01-16 13:07:38.641175: step 16016, loss = 0.56444 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:07:39.602426 ops/training.py:65 2019-01-16 13:07:39.602386: step 16017, loss = 0.35304 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:07:40.563703 ops/training.py:65 2019-01-16 13:07:40.563659: step 16018, loss = 0.38925 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:07:41.523748 ops/training.py:65 2019-01-16 13:07:41.523678: step 16019, loss = 0.36606 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:07:42.487960 ops/training.py:65 2019-01-16 13:07:42.487905: step 16020, loss = 0.40957 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:07:43.451576 ops/training.py:65 2019-01-16 13:07:43.451508: step 16021, loss = 0.37769 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:07:44.415496 ops/training.py:65 2019-01-16 13:07:44.415448: step 16022, loss = 0.61753 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 13:07:45.377724 ops/training.py:65 2019-01-16 13:07:45.377671: step 16023, loss = 0.40411 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:07:46.339063 ops/training.py:65 2019-01-16 13:07:46.339011: step 16024, loss = 0.48186 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:07:47.299187 ops/training.py:65 2019-01-16 13:07:47.299136: step 16025, loss = 0.37895 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:07:48.260333 ops/training.py:65 2019-01-16 13:07:48.260279: step 16026, loss = 0.50581 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:07:49.220667 ops/training.py:65 2019-01-16 13:07:49.220588: step 16027, loss = 0.41553 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:07:50.180684 ops/training.py:65 2019-01-16 13:07:50.180616: step 16028, loss = 0.39495 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:07:51.143821 ops/training.py:65 2019-01-16 13:07:51.143777: step 16029, loss = 0.28416 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:07:52.107807 ops/training.py:65 2019-01-16 13:07:52.107764: step 16030, loss = 0.38441 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:07:53.071435 ops/training.py:65 2019-01-16 13:07:53.071382: step 16031, loss = 0.38837 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:07:54.033452 ops/training.py:65 2019-01-16 13:07:54.033410: step 16032, loss = 0.38167 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:07:54.994912 ops/training.py:65 2019-01-16 13:07:54.994868: step 16033, loss = 0.41332 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:07:55.956612 ops/training.py:65 2019-01-16 13:07:55.956570: step 16034, loss = 0.33674 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:07:56.918443 ops/training.py:65 2019-01-16 13:07:56.918402: step 16035, loss = 0.44205 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:07:57.880826 ops/training.py:65 2019-01-16 13:07:57.880779: step 16036, loss = 0.40011 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:07:58.841772 ops/training.py:65 2019-01-16 13:07:58.841722: step 16037, loss = 0.35672 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:07:59.803298 ops/training.py:65 2019-01-16 13:07:59.803246: step 16038, loss = 0.36536 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:08:00.765259 ops/training.py:65 2019-01-16 13:08:00.765207: step 16039, loss = 0.54361 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:08:01.726367 ops/training.py:65 2019-01-16 13:08:01.726314: step 16040, loss = 0.28995 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:08:02.687803 ops/training.py:65 2019-01-16 13:08:02.687753: step 16041, loss = 0.46167 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:08:03.647892 ops/training.py:65 2019-01-16 13:08:03.647839: step 16042, loss = 0.37708 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:08:04.608939 ops/training.py:65 2019-01-16 13:08:04.608887: step 16043, loss = 0.36498 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:08:05.569073 ops/training.py:65 2019-01-16 13:08:05.569022: step 16044, loss = 0.40974 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:08:06.533672 ops/training.py:65 2019-01-16 13:08:06.533605: step 16045, loss = 0.35572 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:08:07.498167 ops/training.py:65 2019-01-16 13:08:07.498097: step 16046, loss = 0.49210 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:08:08.461809 ops/training.py:65 2019-01-16 13:08:08.461741: step 16047, loss = 0.33219 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:08:09.424286 ops/training.py:65 2019-01-16 13:08:09.424226: step 16048, loss = 0.33209 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:08:10.386048 ops/training.py:65 2019-01-16 13:08:10.385994: step 16049, loss = 0.41611 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:08:11.348242 ops/training.py:65 2019-01-16 13:08:11.348195: step 16050, loss = 0.49400 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:08:12.309279 ops/training.py:65 2019-01-16 13:08:12.309221: step 16051, loss = 0.34626 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:08:13.269624 ops/training.py:65 2019-01-16 13:08:13.269559: step 16052, loss = 0.42367 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:08:14.231320 ops/training.py:65 2019-01-16 13:08:14.231236: step 16053, loss = 0.41488 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:08:15.192346 ops/training.py:65 2019-01-16 13:08:15.192287: step 16054, loss = 0.34332 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:08:16.154222 ops/training.py:65 2019-01-16 13:08:16.154169: step 16055, loss = 0.29399 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:08:17.115930 ops/training.py:65 2019-01-16 13:08:17.115865: step 16056, loss = 0.55934 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:08:18.080006 ops/training.py:65 2019-01-16 13:08:18.079937: step 16057, loss = 0.50647 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:08:19.041726 ops/training.py:65 2019-01-16 13:08:19.041658: step 16058, loss = 0.33069 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:08:20.002654 ops/training.py:65 2019-01-16 13:08:20.002602: step 16059, loss = 0.50974 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:08:20.963331 ops/training.py:65 2019-01-16 13:08:20.963280: step 16060, loss = 0.46308 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:08:21.928921 ops/training.py:65 2019-01-16 13:08:21.928877: step 16061, loss = 0.31948 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:08:22.893197 ops/training.py:65 2019-01-16 13:08:22.893146: step 16062, loss = 0.40734 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:08:23.856876 ops/training.py:65 2019-01-16 13:08:23.856822: step 16063, loss = 0.39203 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:08:24.819630 ops/training.py:65 2019-01-16 13:08:24.819577: step 16064, loss = 0.42894 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:08:25.780410 ops/training.py:65 2019-01-16 13:08:25.780336: step 16065, loss = 0.42705 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:08:26.741036 ops/training.py:65 2019-01-16 13:08:26.740963: step 16066, loss = 0.38512 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:08:27.701948 ops/training.py:65 2019-01-16 13:08:27.701890: step 16067, loss = 0.47692 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:08:28.661639 ops/training.py:65 2019-01-16 13:08:28.661575: step 16068, loss = 0.54861 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:08:29.624067 ops/training.py:65 2019-01-16 13:08:29.624008: step 16069, loss = 0.30998 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:08:30.584715 ops/training.py:65 2019-01-16 13:08:30.584642: step 16070, loss = 0.67548 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 13:08:31.546111 ops/training.py:65 2019-01-16 13:08:31.546044: step 16071, loss = 0.41690 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:08:32.506696 ops/training.py:65 2019-01-16 13:08:32.506636: step 16072, loss = 0.39994 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:08:33.470198 ops/training.py:65 2019-01-16 13:08:33.470150: step 16073, loss = 0.35822 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:08:34.434802 ops/training.py:65 2019-01-16 13:08:34.434750: step 16074, loss = 0.42593 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:08:35.398524 ops/training.py:65 2019-01-16 13:08:35.398475: step 16075, loss = 0.49788 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:08:36.360879 ops/training.py:65 2019-01-16 13:08:36.360816: step 16076, loss = 0.34332 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:08:37.323329 ops/training.py:65 2019-01-16 13:08:37.323257: step 16077, loss = 0.34531 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:08:38.285852 ops/training.py:65 2019-01-16 13:08:38.285799: step 16078, loss = 0.48509 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:08:39.247720 ops/training.py:65 2019-01-16 13:08:39.247673: step 16079, loss = 0.40292 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:08:40.210034 ops/training.py:65 2019-01-16 13:08:40.209966: step 16080, loss = 0.41028 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:08:41.171767 ops/training.py:65 2019-01-16 13:08:41.171698: step 16081, loss = 0.37424 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:08:42.133764 ops/training.py:65 2019-01-16 13:08:42.133707: step 16082, loss = 0.48772 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:08:43.093625 ops/training.py:65 2019-01-16 13:08:43.093557: step 16083, loss = 0.62296 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:08:44.055543 ops/training.py:65 2019-01-16 13:08:44.055475: step 16084, loss = 0.41429 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:08:45.016855 ops/training.py:65 2019-01-16 13:08:45.016810: step 16085, loss = 0.42090 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:08:45.976153 ops/training.py:65 2019-01-16 13:08:45.976081: step 16086, loss = 0.42065 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:08:46.940838 ops/training.py:65 2019-01-16 13:08:46.940789: step 16087, loss = 0.36689 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:08:47.904888 ops/training.py:65 2019-01-16 13:08:47.904840: step 16088, loss = 0.43971 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:08:48.868433 ops/training.py:65 2019-01-16 13:08:48.868382: step 16089, loss = 0.50457 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:08:49.830566 ops/training.py:65 2019-01-16 13:08:49.830514: step 16090, loss = 0.41872 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:08:50.792041 ops/training.py:65 2019-01-16 13:08:50.791987: step 16091, loss = 0.48846 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:08:51.754604 ops/training.py:65 2019-01-16 13:08:51.754553: step 16092, loss = 0.67387 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 13:08:52.716057 ops/training.py:65 2019-01-16 13:08:52.716005: step 16093, loss = 0.46479 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:08:53.677947 ops/training.py:65 2019-01-16 13:08:53.677892: step 16094, loss = 0.33541 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:08:54.639753 ops/training.py:65 2019-01-16 13:08:54.639684: step 16095, loss = 0.31256 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:08:55.601384 ops/training.py:65 2019-01-16 13:08:55.601317: step 16096, loss = 0.46074 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:08:56.562191 ops/training.py:65 2019-01-16 13:08:56.562140: step 16097, loss = 0.46953 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:08:57.526340 ops/training.py:65 2019-01-16 13:08:57.526291: step 16098, loss = 0.51622 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:08:58.488134 ops/training.py:65 2019-01-16 13:08:58.488085: step 16099, loss = 0.47472 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:08:59.448616 ops/training.py:65 2019-01-16 13:08:59.448549: step 16100, loss = 0.33174 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:09:00.411266 ops/training.py:65 2019-01-16 13:09:00.411207: step 16101, loss = 0.47384 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:09:01.372045 ops/training.py:65 2019-01-16 13:09:01.371979: step 16102, loss = 0.38092 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:09:02.331639 ops/training.py:65 2019-01-16 13:09:02.331577: step 16103, loss = 0.52194 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 13:09:03.294872 ops/training.py:65 2019-01-16 13:09:03.294805: step 16104, loss = 0.36793 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:09:04.257477 ops/training.py:65 2019-01-16 13:09:04.257407: step 16105, loss = 0.37928 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:09:05.218760 ops/training.py:65 2019-01-16 13:09:05.218699: step 16106, loss = 0.39002 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:09:06.179177 ops/training.py:65 2019-01-16 13:09:06.179113: step 16107, loss = 0.47287 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:09:07.140454 ops/training.py:65 2019-01-16 13:09:07.140406: step 16108, loss = 0.52264 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:09:08.103616 ops/training.py:65 2019-01-16 13:09:08.103559: step 16109, loss = 0.37910 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:09:09.067873 ops/training.py:65 2019-01-16 13:09:09.067824: step 16110, loss = 0.40392 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:09:10.031718 ops/training.py:65 2019-01-16 13:09:10.031671: step 16111, loss = 0.39217 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:09:10.994704 ops/training.py:65 2019-01-16 13:09:10.994648: step 16112, loss = 0.28953 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:09:11.955710 ops/training.py:65 2019-01-16 13:09:11.955642: step 16113, loss = 0.37771 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:09:12.918683 ops/training.py:65 2019-01-16 13:09:12.918630: step 16114, loss = 0.34206 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:09:13.881775 ops/training.py:65 2019-01-16 13:09:13.881717: step 16115, loss = 0.38122 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:09:14.846130 ops/training.py:65 2019-01-16 13:09:14.846061: step 16116, loss = 0.37249 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:09:15.811352 ops/training.py:65 2019-01-16 13:09:15.811299: step 16117, loss = 0.45745 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:09:16.775135 ops/training.py:65 2019-01-16 13:09:16.775086: step 16118, loss = 0.45173 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:09:17.738147 ops/training.py:65 2019-01-16 13:09:17.738097: step 16119, loss = 0.34310 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:09:18.700394 ops/training.py:65 2019-01-16 13:09:18.700344: step 16120, loss = 0.48035 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:09:19.661017 ops/training.py:65 2019-01-16 13:09:19.660959: step 16121, loss = 0.35930 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:09:20.624010 ops/training.py:65 2019-01-16 13:09:20.623963: step 16122, loss = 0.38403 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:09:21.588405 ops/training.py:65 2019-01-16 13:09:21.588351: step 16123, loss = 0.40292 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:09:22.550506 ops/training.py:65 2019-01-16 13:09:22.550434: step 16124, loss = 0.37341 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:09:23.511997 ops/training.py:65 2019-01-16 13:09:23.511922: step 16125, loss = 0.47548 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:09:24.472558 ops/training.py:65 2019-01-16 13:09:24.472507: step 16126, loss = 0.28928 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:09:25.437807 ops/training.py:65 2019-01-16 13:09:25.437757: step 16127, loss = 0.37791 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:09:26.401365 ops/training.py:65 2019-01-16 13:09:26.401313: step 16128, loss = 0.36408 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:09:27.365178 ops/training.py:65 2019-01-16 13:09:27.365124: step 16129, loss = 0.34461 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:09:28.326395 ops/training.py:65 2019-01-16 13:09:28.326347: step 16130, loss = 0.35513 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:09:29.288251 ops/training.py:65 2019-01-16 13:09:29.288201: step 16131, loss = 0.52486 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:09:30.250181 ops/training.py:65 2019-01-16 13:09:30.250137: step 16132, loss = 0.34148 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:09:31.212597 ops/training.py:65 2019-01-16 13:09:31.212522: step 16133, loss = 0.44756 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:09:32.174086 ops/training.py:65 2019-01-16 13:09:32.174033: step 16134, loss = 0.37361 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:09:33.135263 ops/training.py:65 2019-01-16 13:09:33.135211: step 16135, loss = 0.36486 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:09:34.099462 ops/training.py:65 2019-01-16 13:09:34.099412: step 16136, loss = 0.45795 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:09:35.061647 ops/training.py:65 2019-01-16 13:09:35.061592: step 16137, loss = 0.56024 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:09:36.023864 ops/training.py:65 2019-01-16 13:09:36.023814: step 16138, loss = 0.34326 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:09:36.984953 ops/training.py:65 2019-01-16 13:09:36.984909: step 16139, loss = 0.49810 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:09:37.945400 ops/training.py:65 2019-01-16 13:09:37.945344: step 16140, loss = 0.43617 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:09:38.909922 ops/training.py:65 2019-01-16 13:09:38.909871: step 16141, loss = 0.37771 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:09:39.873891 ops/training.py:65 2019-01-16 13:09:39.873842: step 16142, loss = 0.44876 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:09:40.836428 ops/training.py:65 2019-01-16 13:09:40.836379: step 16143, loss = 0.38080 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:09:41.797495 ops/training.py:65 2019-01-16 13:09:41.797442: step 16144, loss = 0.40018 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:09:42.762670 ops/training.py:65 2019-01-16 13:09:42.762626: step 16145, loss = 0.35993 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:09:43.727239 ops/training.py:65 2019-01-16 13:09:43.727171: step 16146, loss = 0.43120 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:09:44.692122 ops/training.py:65 2019-01-16 13:09:44.692068: step 16147, loss = 0.41219 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:09:45.653982 ops/training.py:65 2019-01-16 13:09:45.653936: step 16148, loss = 0.40857 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:09:46.615844 ops/training.py:65 2019-01-16 13:09:46.615795: step 16149, loss = 0.38110 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:09:47.576335 ops/training.py:65 2019-01-16 13:09:47.576283: step 16150, loss = 0.46832 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:09:48.541887 ops/training.py:65 2019-01-16 13:09:48.541840: step 16151, loss = 0.48159 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:09:49.506622 ops/training.py:65 2019-01-16 13:09:49.506571: step 16152, loss = 0.39036 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:09:50.469649 ops/training.py:65 2019-01-16 13:09:50.469603: step 16153, loss = 0.51443 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:09:51.430558 ops/training.py:65 2019-01-16 13:09:51.430507: step 16154, loss = 0.41025 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:09:52.391877 ops/training.py:65 2019-01-16 13:09:52.391822: step 16155, loss = 0.36726 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:09:53.357415 ops/training.py:65 2019-01-16 13:09:53.357335: step 16156, loss = 0.33425 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:09:54.321564 ops/training.py:65 2019-01-16 13:09:54.321470: step 16157, loss = 0.44814 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:09:55.285499 ops/training.py:65 2019-01-16 13:09:55.285405: step 16158, loss = 0.51665 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:09:56.248690 ops/training.py:65 2019-01-16 13:09:56.248591: step 16159, loss = 0.55687 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:09:57.213346 ops/training.py:65 2019-01-16 13:09:57.213258: step 16160, loss = 0.40336 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:09:58.176121 ops/training.py:65 2019-01-16 13:09:58.176026: step 16161, loss = 0.30979 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:09:59.139799 ops/training.py:65 2019-01-16 13:09:59.139712: step 16162, loss = 0.34810 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:10:00.102196 ops/training.py:65 2019-01-16 13:10:00.102141: step 16163, loss = 0.42348 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:10:01.064877 ops/training.py:65 2019-01-16 13:10:01.064808: step 16164, loss = 0.30564 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:10:02.030321 ops/training.py:65 2019-01-16 13:10:02.030246: step 16165, loss = 0.27068 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:10:02.994312 ops/training.py:65 2019-01-16 13:10:02.994223: step 16166, loss = 0.27702 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:10:03.956730 ops/training.py:65 2019-01-16 13:10:03.956636: step 16167, loss = 0.49342 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:10:04.919319 ops/training.py:65 2019-01-16 13:10:04.919231: step 16168, loss = 0.55157 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:10:05.881879 ops/training.py:65 2019-01-16 13:10:05.881782: step 16169, loss = 0.45787 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:10:06.844818 ops/training.py:65 2019-01-16 13:10:06.844723: step 16170, loss = 0.47063 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:10:07.806955 ops/training.py:65 2019-01-16 13:10:07.806883: step 16171, loss = 0.31316 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:10:08.769004 ops/training.py:65 2019-01-16 13:10:08.768905: step 16172, loss = 0.32493 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:10:09.731707 ops/training.py:65 2019-01-16 13:10:09.731617: step 16173, loss = 0.36269 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:10:10.694104 ops/training.py:65 2019-01-16 13:10:10.694047: step 16174, loss = 0.59838 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:10:11.657286 ops/training.py:65 2019-01-16 13:10:11.657215: step 16175, loss = 0.42121 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:10:12.621866 ops/training.py:65 2019-01-16 13:10:12.621788: step 16176, loss = 0.46717 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:10:13.585147 ops/training.py:65 2019-01-16 13:10:13.585057: step 16177, loss = 0.35927 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:10:14.547816 ops/training.py:65 2019-01-16 13:10:14.547722: step 16178, loss = 0.43508 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:10:15.509927 ops/training.py:65 2019-01-16 13:10:15.509858: step 16179, loss = 0.38578 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:10:16.471804 ops/training.py:65 2019-01-16 13:10:16.471708: step 16180, loss = 0.26299 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:10:17.434614 ops/training.py:65 2019-01-16 13:10:17.434520: step 16181, loss = 0.35923 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:10:18.399562 ops/training.py:65 2019-01-16 13:10:18.399440: step 16182, loss = 0.40702 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:10:19.364210 ops/training.py:65 2019-01-16 13:10:19.364126: step 16183, loss = 0.32760 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:10:20.326523 ops/training.py:65 2019-01-16 13:10:20.326401: step 16184, loss = 0.37324 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:10:21.287626 ops/training.py:65 2019-01-16 13:10:21.287550: step 16185, loss = 0.50099 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:10:22.248463 ops/training.py:65 2019-01-16 13:10:22.248371: step 16186, loss = 0.32017 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:10:23.210343 ops/training.py:65 2019-01-16 13:10:23.210252: step 16187, loss = 0.53918 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:10:24.171789 ops/training.py:65 2019-01-16 13:10:24.171699: step 16188, loss = 0.56980 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 13:10:25.133459 ops/training.py:65 2019-01-16 13:10:25.133372: step 16189, loss = 0.36223 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:10:26.094919 ops/training.py:65 2019-01-16 13:10:26.094784: step 16190, loss = 0.32138 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:10:27.056666 ops/training.py:65 2019-01-16 13:10:27.056585: step 16191, loss = 0.34080 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:10:28.019084 ops/training.py:65 2019-01-16 13:10:28.018986: step 16192, loss = 0.41325 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:10:28.983267 ops/training.py:65 2019-01-16 13:10:28.983142: step 16193, loss = 0.46165 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:10:29.946515 ops/training.py:65 2019-01-16 13:10:29.946439: step 16194, loss = 0.47764 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:10:30.906594 ops/training.py:65 2019-01-16 13:10:30.906499: step 16195, loss = 0.50853 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:10:31.867126 ops/training.py:65 2019-01-16 13:10:31.867060: step 16196, loss = 0.58752 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:10:32.826893 ops/training.py:65 2019-01-16 13:10:32.826833: step 16197, loss = 0.57183 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:10:33.790054 ops/training.py:65 2019-01-16 13:10:33.789998: step 16198, loss = 0.35863 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:10:34.750726 ops/training.py:65 2019-01-16 13:10:34.750664: step 16199, loss = 0.41573 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:10:35.709035 ops/training.py:65 2019-01-16 13:10:35.708974: step 16200, loss = 0.44487 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:10:36.669332 ops/training.py:65 2019-01-16 13:10:36.669285: step 16201, loss = 0.36787 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:10:37.633590 ops/training.py:65 2019-01-16 13:10:37.633543: step 16202, loss = 0.33256 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:10:38.596629 ops/training.py:65 2019-01-16 13:10:38.596594: step 16203, loss = 0.48061 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:10:39.557496 ops/training.py:65 2019-01-16 13:10:39.557410: step 16204, loss = 0.33825 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:10:40.518213 ops/training.py:65 2019-01-16 13:10:40.518115: step 16205, loss = 0.34104 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:10:41.478519 ops/training.py:65 2019-01-16 13:10:41.478454: step 16206, loss = 0.29677 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:10:42.441483 ops/training.py:65 2019-01-16 13:10:42.441411: step 16207, loss = 0.34214 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:10:43.404769 ops/training.py:65 2019-01-16 13:10:43.404675: step 16208, loss = 0.38205 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:10:44.367266 ops/training.py:65 2019-01-16 13:10:44.367189: step 16209, loss = 0.32384 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:10:45.329780 ops/training.py:65 2019-01-16 13:10:45.329678: step 16210, loss = 0.36194 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:10:46.291953 ops/training.py:65 2019-01-16 13:10:46.291847: step 16211, loss = 0.33451 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:10:47.256681 ops/training.py:65 2019-01-16 13:10:47.256591: step 16212, loss = 0.40749 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:10:48.222017 ops/training.py:65 2019-01-16 13:10:48.221917: step 16213, loss = 0.40825 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:10:49.185929 ops/training.py:65 2019-01-16 13:10:49.185841: step 16214, loss = 0.40041 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:10:50.149069 ops/training.py:65 2019-01-16 13:10:50.148990: step 16215, loss = 0.48701 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:10:51.113886 ops/training.py:65 2019-01-16 13:10:51.113813: step 16216, loss = 0.36160 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:10:52.075745 ops/training.py:65 2019-01-16 13:10:52.075651: step 16217, loss = 0.44864 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:10:53.040291 ops/training.py:65 2019-01-16 13:10:53.040195: step 16218, loss = 0.53285 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:10:54.004709 ops/training.py:65 2019-01-16 13:10:54.004627: step 16219, loss = 0.52242 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:10:54.966863 ops/training.py:65 2019-01-16 13:10:54.966774: step 16220, loss = 0.39052 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:10:55.929310 ops/training.py:65 2019-01-16 13:10:55.929180: step 16221, loss = 0.42519 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:10:56.891878 ops/training.py:65 2019-01-16 13:10:56.891781: step 16222, loss = 0.43285 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:10:57.855876 ops/training.py:65 2019-01-16 13:10:57.855795: step 16223, loss = 0.49977 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:10:58.819204 ops/training.py:65 2019-01-16 13:10:58.819116: step 16224, loss = 0.45649 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:10:59.781208 ops/training.py:65 2019-01-16 13:10:59.781139: step 16225, loss = 0.40604 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:11:00.742799 ops/training.py:65 2019-01-16 13:11:00.742723: step 16226, loss = 0.41918 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:11:01.705733 ops/training.py:65 2019-01-16 13:11:01.705651: step 16227, loss = 0.39554 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:11:02.667958 ops/training.py:65 2019-01-16 13:11:02.667877: step 16228, loss = 0.45463 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:11:03.631802 ops/training.py:65 2019-01-16 13:11:03.631718: step 16229, loss = 0.36659 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:11:04.593473 ops/training.py:65 2019-01-16 13:11:04.593384: step 16230, loss = 0.34296 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:11:05.555940 ops/training.py:65 2019-01-16 13:11:05.555852: step 16231, loss = 0.27274 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:11:06.518066 ops/training.py:65 2019-01-16 13:11:06.517996: step 16232, loss = 0.45346 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:11:07.479010 ops/training.py:65 2019-01-16 13:11:07.478920: step 16233, loss = 0.40891 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:11:08.441224 ops/training.py:65 2019-01-16 13:11:08.441129: step 16234, loss = 0.48820 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:11:09.403890 ops/training.py:65 2019-01-16 13:11:09.403806: step 16235, loss = 0.49567 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:11:10.366734 ops/training.py:65 2019-01-16 13:11:10.366650: step 16236, loss = 0.37229 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:11:11.329348 ops/training.py:65 2019-01-16 13:11:11.329260: step 16237, loss = 0.42741 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:11:12.290877 ops/training.py:65 2019-01-16 13:11:12.290806: step 16238, loss = 0.60626 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 13:11:13.252297 ops/training.py:65 2019-01-16 13:11:13.252217: step 16239, loss = 0.38454 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:11:14.213746 ops/training.py:65 2019-01-16 13:11:14.213682: step 16240, loss = 0.49853 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:11:15.174991 ops/training.py:65 2019-01-16 13:11:15.174905: step 16241, loss = 0.49834 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:11:16.137820 ops/training.py:65 2019-01-16 13:11:16.137731: step 16242, loss = 0.30243 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:11:17.099809 ops/training.py:65 2019-01-16 13:11:17.099717: step 16243, loss = 0.39556 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:11:18.063202 ops/training.py:65 2019-01-16 13:11:18.063101: step 16244, loss = 0.38745 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:11:19.028580 ops/training.py:65 2019-01-16 13:11:19.028483: step 16245, loss = 0.32357 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:11:19.990813 ops/training.py:65 2019-01-16 13:11:19.990720: step 16246, loss = 0.57508 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:11:20.952338 ops/training.py:65 2019-01-16 13:11:20.952245: step 16247, loss = 0.27540 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:11:21.916512 ops/training.py:65 2019-01-16 13:11:21.916450: step 16248, loss = 0.33469 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:11:22.879739 ops/training.py:65 2019-01-16 13:11:22.879656: step 16249, loss = 0.43973 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:11:23.842381 ops/training.py:65 2019-01-16 13:11:23.842304: step 16250, loss = 0.48691 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:11:24.803775 ops/training.py:65 2019-01-16 13:11:24.803708: step 16251, loss = 0.35055 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:11:25.761974 ops/training.py:65 2019-01-16 13:11:25.761909: step 16252, loss = 0.44302 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:11:26.720543 ops/training.py:65 2019-01-16 13:11:26.720479: step 16253, loss = 0.56444 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:11:27.679131 ops/training.py:65 2019-01-16 13:11:27.679062: step 16254, loss = 0.35662 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:11:28.637486 ops/training.py:65 2019-01-16 13:11:28.637424: step 16255, loss = 0.59962 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:11:29.596883 ops/training.py:65 2019-01-16 13:11:29.596814: step 16256, loss = 0.49839 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:11:30.555786 ops/training.py:65 2019-01-16 13:11:30.555717: step 16257, loss = 0.47748 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:11:31.515025 ops/training.py:65 2019-01-16 13:11:31.514950: step 16258, loss = 0.47447 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:11:32.479107 ops/training.py:65 2019-01-16 13:11:32.479068: step 16259, loss = 0.39451 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:11:33.443251 ops/training.py:65 2019-01-16 13:11:33.443199: step 16260, loss = 0.33145 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:11:34.404847 ops/training.py:65 2019-01-16 13:11:34.404792: step 16261, loss = 0.55259 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 13:11:35.366858 ops/training.py:65 2019-01-16 13:11:35.366782: step 16262, loss = 0.40965 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:11:36.331615 ops/training.py:65 2019-01-16 13:11:36.331531: step 16263, loss = 0.37483 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:11:37.296288 ops/training.py:65 2019-01-16 13:11:37.296194: step 16264, loss = 0.39363 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:11:38.259799 ops/training.py:65 2019-01-16 13:11:38.259704: step 16265, loss = 0.50865 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:11:39.222219 ops/training.py:65 2019-01-16 13:11:39.222127: step 16266, loss = 0.26636 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:11:40.184570 ops/training.py:65 2019-01-16 13:11:40.184469: step 16267, loss = 0.39685 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:11:41.148851 ops/training.py:65 2019-01-16 13:11:41.148758: step 16268, loss = 0.42926 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:11:42.111539 ops/training.py:65 2019-01-16 13:11:42.111442: step 16269, loss = 0.50500 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:11:43.076955 ops/training.py:65 2019-01-16 13:11:43.076879: step 16270, loss = 0.44556 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:11:44.038789 ops/training.py:65 2019-01-16 13:11:44.038689: step 16271, loss = 0.37123 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:11:45.000793 ops/training.py:65 2019-01-16 13:11:45.000705: step 16272, loss = 0.35807 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:11:45.962714 ops/training.py:65 2019-01-16 13:11:45.962617: step 16273, loss = 0.33948 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:11:46.923198 ops/training.py:65 2019-01-16 13:11:46.923112: step 16274, loss = 0.40584 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:11:47.888862 ops/training.py:65 2019-01-16 13:11:47.888788: step 16275, loss = 0.64095 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:11:48.850447 ops/training.py:65 2019-01-16 13:11:48.850353: step 16276, loss = 0.56287 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:11:49.811065 ops/training.py:65 2019-01-16 13:11:49.810970: step 16277, loss = 0.32490 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:11:50.773702 ops/training.py:65 2019-01-16 13:11:50.773613: step 16278, loss = 0.40844 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:11:51.740477 ops/training.py:65 2019-01-16 13:11:51.740416: step 16279, loss = 0.27313 (33.1 examples/sec; 0.966 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:11:52.703357 ops/training.py:65 2019-01-16 13:11:52.703261: step 16280, loss = 0.31243 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:11:53.666781 ops/training.py:65 2019-01-16 13:11:53.666709: step 16281, loss = 0.37904 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:11:54.629101 ops/training.py:65 2019-01-16 13:11:54.629004: step 16282, loss = 0.50093 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:11:55.591231 ops/training.py:65 2019-01-16 13:11:55.591138: step 16283, loss = 0.37192 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:11:56.552804 ops/training.py:65 2019-01-16 13:11:56.552737: step 16284, loss = 0.38675 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:11:57.513343 ops/training.py:65 2019-01-16 13:11:57.513260: step 16285, loss = 0.45783 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:11:58.475227 ops/training.py:65 2019-01-16 13:11:58.475140: step 16286, loss = 0.56997 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:11:59.440757 ops/training.py:65 2019-01-16 13:11:59.440666: step 16287, loss = 0.74926 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 13:12:00.404498 ops/training.py:65 2019-01-16 13:12:00.404400: step 16288, loss = 0.36729 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:12:01.366354 ops/training.py:65 2019-01-16 13:12:01.366256: step 16289, loss = 0.51795 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:12:02.328508 ops/training.py:65 2019-01-16 13:12:02.328422: step 16290, loss = 0.36049 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:12:03.290666 ops/training.py:65 2019-01-16 13:12:03.290573: step 16291, loss = 0.33523 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:12:04.252824 ops/training.py:65 2019-01-16 13:12:04.252732: step 16292, loss = 0.36128 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:12:05.215090 ops/training.py:65 2019-01-16 13:12:05.215012: step 16293, loss = 0.43378 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:12:06.176963 ops/training.py:65 2019-01-16 13:12:06.176895: step 16294, loss = 0.29774 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:12:07.138288 ops/training.py:65 2019-01-16 13:12:07.138198: step 16295, loss = 0.44163 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:12:08.101205 ops/training.py:65 2019-01-16 13:12:08.101128: step 16296, loss = 0.40516 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:12:09.063028 ops/training.py:65 2019-01-16 13:12:09.062976: step 16297, loss = 0.38415 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:12:10.024239 ops/training.py:65 2019-01-16 13:12:10.024149: step 16298, loss = 0.34763 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:12:10.985920 ops/training.py:65 2019-01-16 13:12:10.985829: step 16299, loss = 0.34539 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:12:11.947763 ops/training.py:65 2019-01-16 13:12:11.947671: step 16300, loss = 0.50335 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:12:12.908338 ops/training.py:65 2019-01-16 13:12:12.908272: step 16301, loss = 0.34273 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:12:13.870912 ops/training.py:65 2019-01-16 13:12:13.870826: step 16302, loss = 0.44463 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:12:14.832752 ops/training.py:65 2019-01-16 13:12:14.832654: step 16303, loss = 0.45836 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:12:15.794507 ops/training.py:65 2019-01-16 13:12:15.794423: step 16304, loss = 0.42688 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:12:16.755559 ops/training.py:65 2019-01-16 13:12:16.755480: step 16305, loss = 0.42092 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:12:17.719299 ops/training.py:65 2019-01-16 13:12:17.719202: step 16306, loss = 0.44152 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:12:18.683417 ops/training.py:65 2019-01-16 13:12:18.683324: step 16307, loss = 0.29954 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:12:19.645901 ops/training.py:65 2019-01-16 13:12:19.645809: step 16308, loss = 0.26457 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:12:20.608504 ops/training.py:65 2019-01-16 13:12:20.608408: step 16309, loss = 0.49399 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:12:21.570845 ops/training.py:65 2019-01-16 13:12:21.570748: step 16310, loss = 0.38779 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:12:22.532196 ops/training.py:65 2019-01-16 13:12:22.532100: step 16311, loss = 0.41749 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:12:23.494196 ops/training.py:65 2019-01-16 13:12:23.494122: step 16312, loss = 0.54846 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:12:24.457169 ops/training.py:65 2019-01-16 13:12:24.457072: step 16313, loss = 0.50245 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:12:25.418479 ops/training.py:65 2019-01-16 13:12:25.418384: step 16314, loss = 0.38165 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:12:26.380379 ops/training.py:65 2019-01-16 13:12:26.380287: step 16315, loss = 0.48411 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:12:27.342175 ops/training.py:65 2019-01-16 13:12:27.342078: step 16316, loss = 0.26496 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 13:12:28.304665 ops/training.py:65 2019-01-16 13:12:28.304577: step 16317, loss = 0.43576 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:12:29.267307 ops/training.py:65 2019-01-16 13:12:29.267220: step 16318, loss = 0.41538 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:12:30.230630 ops/training.py:65 2019-01-16 13:12:30.230535: step 16319, loss = 0.38068 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:12:31.192407 ops/training.py:65 2019-01-16 13:12:31.192314: step 16320, loss = 0.45516 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:12:32.155392 ops/training.py:65 2019-01-16 13:12:32.155300: step 16321, loss = 0.50335 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:12:33.117872 ops/training.py:65 2019-01-16 13:12:33.117783: step 16322, loss = 0.41618 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:12:34.079370 ops/training.py:65 2019-01-16 13:12:34.079273: step 16323, loss = 0.26099 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:12:35.041167 ops/training.py:65 2019-01-16 13:12:35.041084: step 16324, loss = 0.23703 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:12:36.002709 ops/training.py:65 2019-01-16 13:12:36.002630: step 16325, loss = 0.32453 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:12:36.964125 ops/training.py:65 2019-01-16 13:12:36.964036: step 16326, loss = 0.40121 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:12:37.926153 ops/training.py:65 2019-01-16 13:12:37.926069: step 16327, loss = 0.58639 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:12:38.889085 ops/training.py:65 2019-01-16 13:12:38.889017: step 16328, loss = 0.38718 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:12:39.851750 ops/training.py:65 2019-01-16 13:12:39.851669: step 16329, loss = 0.49132 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:12:40.815291 ops/training.py:65 2019-01-16 13:12:40.815199: step 16330, loss = 0.36531 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:12:41.777630 ops/training.py:65 2019-01-16 13:12:41.777531: step 16331, loss = 0.64954 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 13:12:42.740385 ops/training.py:65 2019-01-16 13:12:42.740302: step 16332, loss = 0.31858 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:12:43.702409 ops/training.py:65 2019-01-16 13:12:43.702315: step 16333, loss = 0.46837 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:12:44.664653 ops/training.py:65 2019-01-16 13:12:44.664555: step 16334, loss = 0.44514 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:12:45.629835 ops/training.py:65 2019-01-16 13:12:45.629739: step 16335, loss = 0.25020 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:12:46.593457 ops/training.py:65 2019-01-16 13:12:46.593330: step 16336, loss = 0.42449 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:12:47.556165 ops/training.py:65 2019-01-16 13:12:47.556066: step 16337, loss = 0.35903 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:12:48.518369 ops/training.py:65 2019-01-16 13:12:48.518271: step 16338, loss = 0.45334 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:12:49.480402 ops/training.py:65 2019-01-16 13:12:49.480305: step 16339, loss = 0.32662 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:12:50.444727 ops/training.py:65 2019-01-16 13:12:50.444629: step 16340, loss = 0.28321 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:12:51.408712 ops/training.py:65 2019-01-16 13:12:51.408617: step 16341, loss = 0.61331 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:12:52.373019 ops/training.py:65 2019-01-16 13:12:52.372921: step 16342, loss = 0.35105 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:12:53.334828 ops/training.py:65 2019-01-16 13:12:53.334746: step 16343, loss = 0.40286 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:12:54.297171 ops/training.py:65 2019-01-16 13:12:54.297066: step 16344, loss = 0.49297 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:12:55.259549 ops/training.py:65 2019-01-16 13:12:55.259450: step 16345, loss = 0.40411 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:12:56.220644 ops/training.py:65 2019-01-16 13:12:56.220555: step 16346, loss = 0.42592 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:12:57.180008 ops/training.py:65 2019-01-16 13:12:57.179910: step 16347, loss = 0.40497 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:12:58.140344 ops/training.py:65 2019-01-16 13:12:58.140268: step 16348, loss = 0.46316 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:12:59.099527 ops/training.py:65 2019-01-16 13:12:59.099455: step 16349, loss = 0.37670 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:13:00.063664 ops/training.py:65 2019-01-16 13:13:00.063576: step 16350, loss = 0.40501 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:13:01.028475 ops/training.py:65 2019-01-16 13:13:01.028383: step 16351, loss = 0.41274 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:13:01.991814 ops/training.py:65 2019-01-16 13:13:01.991736: step 16352, loss = 0.45319 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:13:02.953792 ops/training.py:65 2019-01-16 13:13:02.953699: step 16353, loss = 0.41538 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:13:03.916617 ops/training.py:65 2019-01-16 13:13:03.916520: step 16354, loss = 0.47466 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:13:04.879255 ops/training.py:65 2019-01-16 13:13:04.879159: step 16355, loss = 0.46994 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:13:05.841253 ops/training.py:65 2019-01-16 13:13:05.841158: step 16356, loss = 0.47352 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:13:06.803491 ops/training.py:65 2019-01-16 13:13:06.803404: step 16357, loss = 0.42649 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:13:07.766509 ops/training.py:65 2019-01-16 13:13:07.766421: step 16358, loss = 0.35678 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:13:08.728876 ops/training.py:65 2019-01-16 13:13:08.728795: step 16359, loss = 0.46420 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:13:09.690652 ops/training.py:65 2019-01-16 13:13:09.690565: step 16360, loss = 0.29510 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:13:10.652816 ops/training.py:65 2019-01-16 13:13:10.652727: step 16361, loss = 0.34145 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:13:11.614250 ops/training.py:65 2019-01-16 13:13:11.614152: step 16362, loss = 0.35459 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:13:12.575984 ops/training.py:65 2019-01-16 13:13:12.575882: step 16363, loss = 0.39864 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:13:13.538013 ops/training.py:65 2019-01-16 13:13:13.537921: step 16364, loss = 0.41852 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:13:14.500309 ops/training.py:65 2019-01-16 13:13:14.500214: step 16365, loss = 0.55048 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:13:15.462128 ops/training.py:65 2019-01-16 13:13:15.462034: step 16366, loss = 0.36435 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:13:16.424637 ops/training.py:65 2019-01-16 13:13:16.424536: step 16367, loss = 0.51760 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:13:17.386526 ops/training.py:65 2019-01-16 13:13:17.386430: step 16368, loss = 0.35996 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:13:18.349111 ops/training.py:65 2019-01-16 13:13:18.348976: step 16369, loss = 0.34426 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:13:19.314262 ops/training.py:65 2019-01-16 13:13:19.314189: step 16370, loss = 0.35745 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:13:20.278609 ops/training.py:65 2019-01-16 13:13:20.278514: step 16371, loss = 0.37491 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:13:21.242717 ops/training.py:65 2019-01-16 13:13:21.242622: step 16372, loss = 0.47376 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:13:22.205891 ops/training.py:65 2019-01-16 13:13:22.205792: step 16373, loss = 0.48611 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:13:23.168060 ops/training.py:65 2019-01-16 13:13:23.167986: step 16374, loss = 0.36509 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:13:24.130097 ops/training.py:65 2019-01-16 13:13:24.129998: step 16375, loss = 0.34430 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:13:25.092345 ops/training.py:65 2019-01-16 13:13:25.092263: step 16376, loss = 0.32837 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:13:26.054668 ops/training.py:65 2019-01-16 13:13:26.054576: step 16377, loss = 0.41473 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:13:27.016981 ops/training.py:65 2019-01-16 13:13:27.016883: step 16378, loss = 0.42691 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:13:27.979429 ops/training.py:65 2019-01-16 13:13:27.979330: step 16379, loss = 0.52497 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:13:28.941809 ops/training.py:65 2019-01-16 13:13:28.941708: step 16380, loss = 0.51621 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:13:29.904327 ops/training.py:65 2019-01-16 13:13:29.904234: step 16381, loss = 0.56522 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:13:30.867963 ops/training.py:65 2019-01-16 13:13:30.867861: step 16382, loss = 0.44062 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:13:31.830784 ops/training.py:65 2019-01-16 13:13:31.830681: step 16383, loss = 0.48548 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:13:32.793528 ops/training.py:65 2019-01-16 13:13:32.793430: step 16384, loss = 0.34866 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:13:33.755504 ops/training.py:65 2019-01-16 13:13:33.755404: step 16385, loss = 0.42270 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:13:34.716804 ops/training.py:65 2019-01-16 13:13:34.716722: step 16386, loss = 0.47785 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:13:35.680432 ops/training.py:65 2019-01-16 13:13:35.680358: step 16387, loss = 0.36100 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:13:36.643300 ops/training.py:65 2019-01-16 13:13:36.643203: step 16388, loss = 0.45434 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:13:37.605603 ops/training.py:65 2019-01-16 13:13:37.605503: step 16389, loss = 0.31877 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:13:38.571084 ops/training.py:65 2019-01-16 13:13:38.571009: step 16390, loss = 0.51513 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:13:39.533796 ops/training.py:65 2019-01-16 13:13:39.533712: step 16391, loss = 0.35684 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:13:40.496544 ops/training.py:65 2019-01-16 13:13:40.496447: step 16392, loss = 0.45843 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:13:41.457418 ops/training.py:65 2019-01-16 13:13:41.457330: step 16393, loss = 0.34195 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:13:42.423552 ops/training.py:65 2019-01-16 13:13:42.423476: step 16394, loss = 0.40694 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:13:43.387941 ops/training.py:65 2019-01-16 13:13:43.387851: step 16395, loss = 0.33659 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:13:44.350459 ops/training.py:65 2019-01-16 13:13:44.350364: step 16396, loss = 0.47539 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:13:45.313165 ops/training.py:65 2019-01-16 13:13:45.313070: step 16397, loss = 0.39914 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:13:46.275124 ops/training.py:65 2019-01-16 13:13:46.275032: step 16398, loss = 0.44495 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:13:47.236678 ops/training.py:65 2019-01-16 13:13:47.236599: step 16399, loss = 0.31844 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:13:48.198951 ops/training.py:65 2019-01-16 13:13:48.198861: step 16400, loss = 0.43890 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:13:49.160088 ops/training.py:65 2019-01-16 13:13:49.159989: step 16401, loss = 0.40642 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:13:50.121970 ops/training.py:65 2019-01-16 13:13:50.121872: step 16402, loss = 0.34218 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:13:51.082733 ops/training.py:65 2019-01-16 13:13:51.082657: step 16403, loss = 0.62040 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 13:13:52.046011 ops/training.py:65 2019-01-16 13:13:52.045911: step 16404, loss = 0.42490 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:13:53.008389 ops/training.py:65 2019-01-16 13:13:53.008290: step 16405, loss = 0.37677 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:13:53.970655 ops/training.py:65 2019-01-16 13:13:53.970571: step 16406, loss = 0.53740 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:13:54.933287 ops/training.py:65 2019-01-16 13:13:54.933193: step 16407, loss = 0.43999 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:13:55.895562 ops/training.py:65 2019-01-16 13:13:55.895460: step 16408, loss = 0.48883 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:13:56.857525 ops/training.py:65 2019-01-16 13:13:56.857443: step 16409, loss = 0.43970 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:13:57.819339 ops/training.py:65 2019-01-16 13:13:57.819236: step 16410, loss = 0.62102 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 13:13:58.782389 ops/training.py:65 2019-01-16 13:13:58.782293: step 16411, loss = 0.43230 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:13:59.745065 ops/training.py:65 2019-01-16 13:13:59.744969: step 16412, loss = 0.57365 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 13:14:00.711447 ops/training.py:65 2019-01-16 13:14:00.711350: step 16413, loss = 0.47772 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:14:01.675180 ops/training.py:65 2019-01-16 13:14:01.675082: step 16414, loss = 0.47608 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:14:02.638156 ops/training.py:65 2019-01-16 13:14:02.638070: step 16415, loss = 0.34219 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:14:03.600392 ops/training.py:65 2019-01-16 13:14:03.600296: step 16416, loss = 0.53560 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 13:14:04.562076 ops/training.py:65 2019-01-16 13:14:04.561986: step 16417, loss = 0.32198 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:14:05.523383 ops/training.py:65 2019-01-16 13:14:05.523289: step 16418, loss = 0.39177 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:14:06.485068 ops/training.py:65 2019-01-16 13:14:06.484971: step 16419, loss = 0.37163 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:14:07.447497 ops/training.py:65 2019-01-16 13:14:07.447401: step 16420, loss = 0.45836 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:14:08.410659 ops/training.py:65 2019-01-16 13:14:08.410586: step 16421, loss = 0.40037 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:14:09.373293 ops/training.py:65 2019-01-16 13:14:09.373201: step 16422, loss = 0.44058 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:14:10.335723 ops/training.py:65 2019-01-16 13:14:10.335626: step 16423, loss = 0.37392 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:14:11.297716 ops/training.py:65 2019-01-16 13:14:11.297628: step 16424, loss = 0.65749 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 13:14:12.259272 ops/training.py:65 2019-01-16 13:14:12.259172: step 16425, loss = 0.39193 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:14:13.223254 ops/training.py:65 2019-01-16 13:14:13.223174: step 16426, loss = 0.54244 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:14:14.187788 ops/training.py:65 2019-01-16 13:14:14.187691: step 16427, loss = 0.42410 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:14:15.151477 ops/training.py:65 2019-01-16 13:14:15.151380: step 16428, loss = 0.42396 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:14:16.113032 ops/training.py:65 2019-01-16 13:14:16.112932: step 16429, loss = 0.44339 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:14:17.073076 ops/training.py:65 2019-01-16 13:14:17.072983: step 16430, loss = 0.37951 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:14:18.037485 ops/training.py:65 2019-01-16 13:14:18.037396: step 16431, loss = 0.38089 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:14:19.000882 ops/training.py:65 2019-01-16 13:14:19.000786: step 16432, loss = 0.37479 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:14:19.965221 ops/training.py:65 2019-01-16 13:14:19.965126: step 16433, loss = 0.35180 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:14:20.927848 ops/training.py:65 2019-01-16 13:14:20.927757: step 16434, loss = 0.45021 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:14:21.890342 ops/training.py:65 2019-01-16 13:14:21.890248: step 16435, loss = 0.40712 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:14:22.852576 ops/training.py:65 2019-01-16 13:14:22.852485: step 16436, loss = 0.40140 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:14:23.813058 ops/training.py:65 2019-01-16 13:14:23.812930: step 16437, loss = 0.48079 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:14:24.774103 ops/training.py:65 2019-01-16 13:14:24.774005: step 16438, loss = 0.33802 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:14:25.737695 ops/training.py:65 2019-01-16 13:14:25.737629: step 16439, loss = 0.34187 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:14:26.699441 ops/training.py:65 2019-01-16 13:14:26.699354: step 16440, loss = 0.57798 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 13:14:27.660150 ops/training.py:65 2019-01-16 13:14:27.660073: step 16441, loss = 0.42953 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:14:28.620345 ops/training.py:65 2019-01-16 13:14:28.620273: step 16442, loss = 0.45315 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:14:29.580617 ops/training.py:65 2019-01-16 13:14:29.580522: step 16443, loss = 0.63526 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:14:30.545462 ops/training.py:65 2019-01-16 13:14:30.545369: step 16444, loss = 0.49799 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:14:31.508651 ops/training.py:65 2019-01-16 13:14:31.508555: step 16445, loss = 0.40183 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:14:32.472489 ops/training.py:65 2019-01-16 13:14:32.472402: step 16446, loss = 0.51340 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 13:14:33.435642 ops/training.py:65 2019-01-16 13:14:33.435548: step 16447, loss = 0.35506 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:14:34.398042 ops/training.py:65 2019-01-16 13:14:34.397945: step 16448, loss = 0.47227 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:14:35.360576 ops/training.py:65 2019-01-16 13:14:35.360477: step 16449, loss = 0.26630 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:14:36.323411 ops/training.py:65 2019-01-16 13:14:36.323313: step 16450, loss = 0.43449 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:14:37.285066 ops/training.py:65 2019-01-16 13:14:37.284971: step 16451, loss = 0.50226 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:14:38.246396 ops/training.py:65 2019-01-16 13:14:38.246322: step 16452, loss = 0.37715 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:14:39.207497 ops/training.py:65 2019-01-16 13:14:39.207404: step 16453, loss = 0.48885 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:14:40.170429 ops/training.py:65 2019-01-16 13:14:40.170329: step 16454, loss = 0.37833 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:14:41.132202 ops/training.py:65 2019-01-16 13:14:41.132105: step 16455, loss = 0.58568 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:14:42.093847 ops/training.py:65 2019-01-16 13:14:42.093752: step 16456, loss = 0.36172 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:14:43.055634 ops/training.py:65 2019-01-16 13:14:43.055559: step 16457, loss = 0.47267 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:14:44.018296 ops/training.py:65 2019-01-16 13:14:44.018204: step 16458, loss = 0.38217 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:14:44.980222 ops/training.py:65 2019-01-16 13:14:44.980134: step 16459, loss = 0.48803 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:14:45.942110 ops/training.py:65 2019-01-16 13:14:45.942015: step 16460, loss = 0.27341 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:14:46.903728 ops/training.py:65 2019-01-16 13:14:46.903631: step 16461, loss = 0.39436 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:14:47.864809 ops/training.py:65 2019-01-16 13:14:47.864715: step 16462, loss = 0.38512 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:14:48.826837 ops/training.py:65 2019-01-16 13:14:48.826759: step 16463, loss = 0.39858 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:14:49.788673 ops/training.py:65 2019-01-16 13:14:49.788580: step 16464, loss = 0.47100 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:14:50.750046 ops/training.py:65 2019-01-16 13:14:50.749953: step 16465, loss = 0.35137 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:14:51.711473 ops/training.py:65 2019-01-16 13:14:51.711343: step 16466, loss = 0.41732 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:14:52.673418 ops/training.py:65 2019-01-16 13:14:52.673326: step 16467, loss = 0.41334 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:14:53.636600 ops/training.py:65 2019-01-16 13:14:53.636513: step 16468, loss = 0.35575 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:14:54.601975 ops/training.py:65 2019-01-16 13:14:54.601904: step 16469, loss = 0.31025 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:14:55.565164 ops/training.py:65 2019-01-16 13:14:55.565078: step 16470, loss = 0.43309 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:14:56.527747 ops/training.py:65 2019-01-16 13:14:56.527665: step 16471, loss = 0.40992 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:14:57.492046 ops/training.py:65 2019-01-16 13:14:57.491976: step 16472, loss = 0.57285 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:14:58.457021 ops/training.py:65 2019-01-16 13:14:58.456929: step 16473, loss = 0.36666 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:14:59.419884 ops/training.py:65 2019-01-16 13:14:59.419811: step 16474, loss = 0.37839 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:15:00.382019 ops/training.py:65 2019-01-16 13:15:00.381941: step 16475, loss = 0.42414 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:15:01.352203 ops/training.py:65 2019-01-16 13:15:01.352132: step 16476, loss = 0.22676 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:15:02.313620 ops/training.py:65 2019-01-16 13:15:02.313544: step 16477, loss = 0.35955 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:15:03.275921 ops/training.py:65 2019-01-16 13:15:03.275831: step 16478, loss = 0.35926 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:15:04.238294 ops/training.py:65 2019-01-16 13:15:04.238207: step 16479, loss = 0.48455 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:15:05.199382 ops/training.py:65 2019-01-16 13:15:05.199283: step 16480, loss = 0.46613 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:15:06.160101 ops/training.py:65 2019-01-16 13:15:06.160021: step 16481, loss = 0.37409 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:15:07.124555 ops/training.py:65 2019-01-16 13:15:07.124465: step 16482, loss = 0.44699 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:15:08.086810 ops/training.py:65 2019-01-16 13:15:08.086707: step 16483, loss = 0.50700 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:15:09.052348 ops/training.py:65 2019-01-16 13:15:09.052257: step 16484, loss = 0.36699 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:15:10.017224 ops/training.py:65 2019-01-16 13:15:10.017132: step 16485, loss = 0.38161 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:15:10.980397 ops/training.py:65 2019-01-16 13:15:10.980309: step 16486, loss = 0.48836 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:15:11.942404 ops/training.py:65 2019-01-16 13:15:11.942310: step 16487, loss = 0.44724 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:15:12.904938 ops/training.py:65 2019-01-16 13:15:12.904872: step 16488, loss = 0.32587 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:15:13.867615 ops/training.py:65 2019-01-16 13:15:13.867523: step 16489, loss = 0.31723 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:15:14.830544 ops/training.py:65 2019-01-16 13:15:14.830464: step 16490, loss = 0.44134 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:15:15.792468 ops/training.py:65 2019-01-16 13:15:15.792386: step 16491, loss = 0.58536 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:15:16.754794 ops/training.py:65 2019-01-16 13:15:16.754699: step 16492, loss = 0.41515 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:15:17.716133 ops/training.py:65 2019-01-16 13:15:17.716042: step 16493, loss = 0.49807 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:15:18.677918 ops/training.py:65 2019-01-16 13:15:18.677825: step 16494, loss = 0.45640 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:15:19.639778 ops/training.py:65 2019-01-16 13:15:19.639688: step 16495, loss = 0.39013 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:15:20.602025 ops/training.py:65 2019-01-16 13:15:20.601944: step 16496, loss = 0.47242 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:15:21.563812 ops/training.py:65 2019-01-16 13:15:21.563746: step 16497, loss = 0.46649 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:15:22.525472 ops/training.py:65 2019-01-16 13:15:22.525399: step 16498, loss = 0.46070 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:15:23.488133 ops/training.py:65 2019-01-16 13:15:23.488063: step 16499, loss = 0.40618 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:15:24.449513 ops/training.py:65 2019-01-16 13:15:24.449467: step 16500, loss = 0.53545 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:15:25.409875 ops/training.py:65 2019-01-16 13:15:25.409823: step 16501, loss = 0.57147 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:15:26.370265 ops/training.py:65 2019-01-16 13:15:26.370223: step 16502, loss = 0.47226 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:15:27.329152 ops/training.py:65 2019-01-16 13:15:27.329104: step 16503, loss = 0.33588 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:15:28.287750 ops/training.py:65 2019-01-16 13:15:28.287700: step 16504, loss = 0.63116 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:15:29.247684 ops/training.py:65 2019-01-16 13:15:29.247633: step 16505, loss = 0.49497 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:15:30.210894 ops/training.py:65 2019-01-16 13:15:30.210842: step 16506, loss = 0.42765 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:15:31.174514 ops/training.py:65 2019-01-16 13:15:31.174459: step 16507, loss = 0.40120 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:15:32.138346 ops/training.py:65 2019-01-16 13:15:32.138278: step 16508, loss = 0.33405 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:15:33.100220 ops/training.py:65 2019-01-16 13:15:33.100167: step 16509, loss = 0.39187 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:15:34.062814 ops/training.py:65 2019-01-16 13:15:34.062743: step 16510, loss = 0.49532 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:15:35.026107 ops/training.py:65 2019-01-16 13:15:35.026051: step 16511, loss = 0.42149 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:15:35.987758 ops/training.py:65 2019-01-16 13:15:35.987684: step 16512, loss = 0.35341 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:15:36.949323 ops/training.py:65 2019-01-16 13:15:36.949263: step 16513, loss = 0.43241 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:15:37.910757 ops/training.py:65 2019-01-16 13:15:37.910688: step 16514, loss = 0.30867 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:15:38.870941 ops/training.py:65 2019-01-16 13:15:38.870870: step 16515, loss = 0.38583 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:15:39.831800 ops/training.py:65 2019-01-16 13:15:39.831735: step 16516, loss = 0.43423 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:15:40.791996 ops/training.py:65 2019-01-16 13:15:40.791932: step 16517, loss = 0.40625 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:15:41.753426 ops/training.py:65 2019-01-16 13:15:41.753358: step 16518, loss = 0.46603 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:15:42.715021 ops/training.py:65 2019-01-16 13:15:42.714964: step 16519, loss = 0.39463 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:15:43.677689 ops/training.py:65 2019-01-16 13:15:43.677617: step 16520, loss = 0.37615 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:15:44.639955 ops/training.py:65 2019-01-16 13:15:44.639902: step 16521, loss = 0.47601 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:15:45.600996 ops/training.py:65 2019-01-16 13:15:45.600928: step 16522, loss = 0.38481 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:15:46.563475 ops/training.py:65 2019-01-16 13:15:46.563398: step 16523, loss = 0.34407 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:15:47.526559 ops/training.py:65 2019-01-16 13:15:47.526486: step 16524, loss = 0.38125 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:15:48.488252 ops/training.py:65 2019-01-16 13:15:48.488198: step 16525, loss = 0.40502 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:15:49.449949 ops/training.py:65 2019-01-16 13:15:49.449900: step 16526, loss = 0.38096 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:15:50.413127 ops/training.py:65 2019-01-16 13:15:50.413079: step 16527, loss = 0.34705 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:15:51.377476 ops/training.py:65 2019-01-16 13:15:51.377405: step 16528, loss = 0.32543 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:15:52.338912 ops/training.py:65 2019-01-16 13:15:52.338836: step 16529, loss = 0.46935 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:15:53.301081 ops/training.py:65 2019-01-16 13:15:53.301012: step 16530, loss = 0.55263 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:15:54.264812 ops/training.py:65 2019-01-16 13:15:54.264758: step 16531, loss = 0.42240 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:15:55.227844 ops/training.py:65 2019-01-16 13:15:55.227778: step 16532, loss = 0.63565 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:15:56.189918 ops/training.py:65 2019-01-16 13:15:56.189866: step 16533, loss = 0.31604 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:15:57.151139 ops/training.py:65 2019-01-16 13:15:57.151067: step 16534, loss = 0.32874 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:15:58.113252 ops/training.py:65 2019-01-16 13:15:58.113178: step 16535, loss = 0.50165 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:15:59.074850 ops/training.py:65 2019-01-16 13:15:59.074777: step 16536, loss = 0.40367 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:16:00.036593 ops/training.py:65 2019-01-16 13:16:00.036540: step 16537, loss = 0.45857 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:16:00.998093 ops/training.py:65 2019-01-16 13:16:00.998024: step 16538, loss = 0.42312 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:16:01.959185 ops/training.py:65 2019-01-16 13:16:01.959121: step 16539, loss = 0.42613 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:16:02.920631 ops/training.py:65 2019-01-16 13:16:02.920561: step 16540, loss = 0.29732 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:16:03.882590 ops/training.py:65 2019-01-16 13:16:03.882517: step 16541, loss = 0.39820 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:16:04.844289 ops/training.py:65 2019-01-16 13:16:04.844220: step 16542, loss = 0.35934 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:16:05.805729 ops/training.py:65 2019-01-16 13:16:05.805662: step 16543, loss = 0.48284 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:16:06.767028 ops/training.py:65 2019-01-16 13:16:06.766959: step 16544, loss = 0.52256 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:16:07.728342 ops/training.py:65 2019-01-16 13:16:07.728269: step 16545, loss = 0.46575 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:16:08.689316 ops/training.py:65 2019-01-16 13:16:08.689250: step 16546, loss = 0.43167 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:16:09.651659 ops/training.py:65 2019-01-16 13:16:09.651593: step 16547, loss = 0.44532 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:16:10.616679 ops/training.py:65 2019-01-16 13:16:10.616628: step 16548, loss = 0.52368 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:16:11.581610 ops/training.py:65 2019-01-16 13:16:11.581539: step 16549, loss = 0.36828 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:16:12.542940 ops/training.py:65 2019-01-16 13:16:12.542886: step 16550, loss = 0.37430 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:16:13.502817 ops/training.py:65 2019-01-16 13:16:13.502760: step 16551, loss = 0.48887 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:16:14.466976 ops/training.py:65 2019-01-16 13:16:14.466942: step 16552, loss = 0.39619 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:16:15.431424 ops/training.py:65 2019-01-16 13:16:15.431393: step 16553, loss = 0.33691 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:16:16.395069 ops/training.py:65 2019-01-16 13:16:16.395040: step 16554, loss = 0.51867 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:16:17.356110 ops/training.py:65 2019-01-16 13:16:17.356082: step 16555, loss = 0.48710 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:16:18.316273 ops/training.py:65 2019-01-16 13:16:18.316241: step 16556, loss = 0.29264 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:16:19.280089 ops/training.py:65 2019-01-16 13:16:19.280058: step 16557, loss = 0.46099 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:16:20.244087 ops/training.py:65 2019-01-16 13:16:20.244059: step 16558, loss = 0.54971 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 13:16:21.207348 ops/training.py:65 2019-01-16 13:16:21.207321: step 16559, loss = 0.48791 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:16:22.167747 ops/training.py:65 2019-01-16 13:16:22.167704: step 16560, loss = 0.36960 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:16:23.129439 ops/training.py:65 2019-01-16 13:16:23.129382: step 16561, loss = 0.38736 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:16:24.091015 ops/training.py:65 2019-01-16 13:16:24.090978: step 16562, loss = 0.34667 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:16:25.055921 ops/training.py:65 2019-01-16 13:16:25.055892: step 16563, loss = 0.35548 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:16:26.017825 ops/training.py:65 2019-01-16 13:16:26.017756: step 16564, loss = 0.31198 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:16:26.981014 ops/training.py:65 2019-01-16 13:16:26.980977: step 16565, loss = 0.30897 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:16:27.944797 ops/training.py:65 2019-01-16 13:16:27.944767: step 16566, loss = 0.24310 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:16:28.906316 ops/training.py:65 2019-01-16 13:16:28.906288: step 16567, loss = 0.41477 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:16:29.866457 ops/training.py:65 2019-01-16 13:16:29.866422: step 16568, loss = 0.46282 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:16:30.827275 ops/training.py:65 2019-01-16 13:16:30.827245: step 16569, loss = 0.38599 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:16:31.789257 ops/training.py:65 2019-01-16 13:16:31.789217: step 16570, loss = 0.46502 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:16:32.751209 ops/training.py:65 2019-01-16 13:16:32.751160: step 16571, loss = 0.48852 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:16:33.709746 ops/training.py:65 2019-01-16 13:16:33.709693: step 16572, loss = 0.38873 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:16:34.667940 ops/training.py:65 2019-01-16 13:16:34.667893: step 16573, loss = 0.41295 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:16:35.625985 ops/training.py:65 2019-01-16 13:16:35.625935: step 16574, loss = 0.36068 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:16:36.589273 ops/training.py:65 2019-01-16 13:16:36.589239: step 16575, loss = 0.36370 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:16:37.553072 ops/training.py:65 2019-01-16 13:16:37.553040: step 16576, loss = 0.38812 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:16:38.515605 ops/training.py:65 2019-01-16 13:16:38.515575: step 16577, loss = 0.62525 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:16:39.476526 ops/training.py:65 2019-01-16 13:16:39.476499: step 16578, loss = 0.54009 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:16:40.437698 ops/training.py:65 2019-01-16 13:16:40.437670: step 16579, loss = 0.35108 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:16:41.399247 ops/training.py:65 2019-01-16 13:16:41.399216: step 16580, loss = 0.44186 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:16:42.360270 ops/training.py:65 2019-01-16 13:16:42.360238: step 16581, loss = 0.35899 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:16:43.321243 ops/training.py:65 2019-01-16 13:16:43.321197: step 16582, loss = 0.43911 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:16:44.283002 ops/training.py:65 2019-01-16 13:16:44.282970: step 16583, loss = 0.43239 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:16:45.244802 ops/training.py:65 2019-01-16 13:16:45.244772: step 16584, loss = 0.36906 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:16:46.206160 ops/training.py:65 2019-01-16 13:16:46.206122: step 16585, loss = 0.39542 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:16:47.168300 ops/training.py:65 2019-01-16 13:16:47.168270: step 16586, loss = 0.36243 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:16:48.130372 ops/training.py:65 2019-01-16 13:16:48.130332: step 16587, loss = 0.40491 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:16:49.090003 ops/training.py:65 2019-01-16 13:16:49.089960: step 16588, loss = 0.40627 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:16:50.052432 ops/training.py:65 2019-01-16 13:16:50.052401: step 16589, loss = 0.23455 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:16:51.014022 ops/training.py:65 2019-01-16 13:16:51.013978: step 16590, loss = 0.35285 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:16:51.977652 ops/training.py:65 2019-01-16 13:16:51.977614: step 16591, loss = 0.47317 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:16:52.939165 ops/training.py:65 2019-01-16 13:16:52.939119: step 16592, loss = 0.27182 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:16:53.897994 ops/training.py:65 2019-01-16 13:16:53.897948: step 16593, loss = 0.22328 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:16:54.860852 ops/training.py:65 2019-01-16 13:16:54.860820: step 16594, loss = 0.30807 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:16:55.824657 ops/training.py:65 2019-01-16 13:16:55.824616: step 16595, loss = 0.42970 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:16:56.786024 ops/training.py:65 2019-01-16 13:16:56.785972: step 16596, loss = 0.36813 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:16:57.749841 ops/training.py:65 2019-01-16 13:16:57.749799: step 16597, loss = 0.50209 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:16:58.713712 ops/training.py:65 2019-01-16 13:16:58.713669: step 16598, loss = 0.35566 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:16:59.676008 ops/training.py:65 2019-01-16 13:16:59.675936: step 16599, loss = 0.37553 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:17:00.637930 ops/training.py:65 2019-01-16 13:17:00.637877: step 16600, loss = 0.56458 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:17:01.597554 ops/training.py:65 2019-01-16 13:17:01.597512: step 16601, loss = 0.45435 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:17:02.561825 ops/training.py:65 2019-01-16 13:17:02.561789: step 16602, loss = 0.33556 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:17:03.527384 ops/training.py:65 2019-01-16 13:17:03.527354: step 16603, loss = 0.40536 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:17:04.491044 ops/training.py:65 2019-01-16 13:17:04.491015: step 16604, loss = 0.53530 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:17:05.451443 ops/training.py:65 2019-01-16 13:17:05.451415: step 16605, loss = 0.34581 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:17:06.412549 ops/training.py:65 2019-01-16 13:17:06.412521: step 16606, loss = 0.49160 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:17:07.374367 ops/training.py:65 2019-01-16 13:17:07.374308: step 16607, loss = 0.33011 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:17:08.336171 ops/training.py:65 2019-01-16 13:17:08.336103: step 16608, loss = 0.38392 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:17:09.299197 ops/training.py:65 2019-01-16 13:17:09.299133: step 16609, loss = 0.41554 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:17:10.261884 ops/training.py:65 2019-01-16 13:17:10.261835: step 16610, loss = 0.32150 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:17:11.225396 ops/training.py:65 2019-01-16 13:17:11.225354: step 16611, loss = 0.46523 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:17:12.190572 ops/training.py:65 2019-01-16 13:17:12.190501: step 16612, loss = 0.52165 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:17:13.153136 ops/training.py:65 2019-01-16 13:17:13.153081: step 16613, loss = 0.56241 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:17:14.115693 ops/training.py:65 2019-01-16 13:17:14.115630: step 16614, loss = 0.44778 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:17:15.076956 ops/training.py:65 2019-01-16 13:17:15.076912: step 16615, loss = 0.50903 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:17:16.035693 ops/training.py:65 2019-01-16 13:17:16.035649: step 16616, loss = 0.41485 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:17:16.994897 ops/training.py:65 2019-01-16 13:17:16.994850: step 16617, loss = 0.27062 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:17:17.957865 ops/training.py:65 2019-01-16 13:17:17.957821: step 16618, loss = 0.39352 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:17:18.918578 ops/training.py:65 2019-01-16 13:17:18.918524: step 16619, loss = 0.35749 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:17:19.882305 ops/training.py:65 2019-01-16 13:17:19.882254: step 16620, loss = 0.26586 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:17:20.846591 ops/training.py:65 2019-01-16 13:17:20.846503: step 16621, loss = 0.40304 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:17:21.809376 ops/training.py:65 2019-01-16 13:17:21.809285: step 16622, loss = 0.32428 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:17:22.772164 ops/training.py:65 2019-01-16 13:17:22.772095: step 16623, loss = 0.48334 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:17:23.734816 ops/training.py:65 2019-01-16 13:17:23.734756: step 16624, loss = 0.41000 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:17:24.695565 ops/training.py:65 2019-01-16 13:17:24.695521: step 16625, loss = 0.37079 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:17:25.654185 ops/training.py:65 2019-01-16 13:17:25.654135: step 16626, loss = 0.42176 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:17:26.614149 ops/training.py:65 2019-01-16 13:17:26.614100: step 16627, loss = 0.30313 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:17:27.572896 ops/training.py:65 2019-01-16 13:17:27.572849: step 16628, loss = 0.37224 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:17:28.532414 ops/training.py:65 2019-01-16 13:17:28.532367: step 16629, loss = 0.28463 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:17:29.490864 ops/training.py:65 2019-01-16 13:17:29.490822: step 16630, loss = 0.47677 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:17:30.449199 ops/training.py:65 2019-01-16 13:17:30.449150: step 16631, loss = 0.32145 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:17:31.411637 ops/training.py:65 2019-01-16 13:17:31.411594: step 16632, loss = 0.46529 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:17:32.373626 ops/training.py:65 2019-01-16 13:17:32.373559: step 16633, loss = 0.32575 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:17:33.338216 ops/training.py:65 2019-01-16 13:17:33.338171: step 16634, loss = 0.37719 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:17:34.302341 ops/training.py:65 2019-01-16 13:17:34.302305: step 16635, loss = 0.40996 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:17:35.265398 ops/training.py:65 2019-01-16 13:17:35.265349: step 16636, loss = 0.57076 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:17:36.226619 ops/training.py:65 2019-01-16 13:17:36.226566: step 16637, loss = 0.41633 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:17:37.187199 ops/training.py:65 2019-01-16 13:17:37.187153: step 16638, loss = 0.38105 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:17:38.149114 ops/training.py:65 2019-01-16 13:17:38.149063: step 16639, loss = 0.43546 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:17:39.111128 ops/training.py:65 2019-01-16 13:17:39.111064: step 16640, loss = 0.50865 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:17:40.070803 ops/training.py:65 2019-01-16 13:17:40.070755: step 16641, loss = 0.35002 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:17:41.032852 ops/training.py:65 2019-01-16 13:17:41.032787: step 16642, loss = 0.32165 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:17:41.996158 ops/training.py:65 2019-01-16 13:17:41.996091: step 16643, loss = 0.51380 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:17:42.959410 ops/training.py:65 2019-01-16 13:17:42.959355: step 16644, loss = 0.42438 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:17:43.922605 ops/training.py:65 2019-01-16 13:17:43.922508: step 16645, loss = 0.30167 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:17:44.884120 ops/training.py:65 2019-01-16 13:17:44.884068: step 16646, loss = 0.37086 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:17:45.846572 ops/training.py:65 2019-01-16 13:17:45.846500: step 16647, loss = 0.48243 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:17:46.811060 ops/training.py:65 2019-01-16 13:17:46.810983: step 16648, loss = 0.34954 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:17:47.775029 ops/training.py:65 2019-01-16 13:17:47.774953: step 16649, loss = 0.35400 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:17:48.736611 ops/training.py:65 2019-01-16 13:17:48.736559: step 16650, loss = 0.30122 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:17:49.698802 ops/training.py:65 2019-01-16 13:17:49.698758: step 16651, loss = 0.27103 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:17:50.660152 ops/training.py:65 2019-01-16 13:17:50.660087: step 16652, loss = 0.44189 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:17:51.620903 ops/training.py:65 2019-01-16 13:17:51.620838: step 16653, loss = 0.41812 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:17:52.582189 ops/training.py:65 2019-01-16 13:17:52.582117: step 16654, loss = 0.37070 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:17:53.544129 ops/training.py:65 2019-01-16 13:17:53.544064: step 16655, loss = 0.33751 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:17:54.506866 ops/training.py:65 2019-01-16 13:17:54.506799: step 16656, loss = 0.41496 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:17:55.469304 ops/training.py:65 2019-01-16 13:17:55.469249: step 16657, loss = 0.45570 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:17:56.429584 ops/training.py:65 2019-01-16 13:17:56.429524: step 16658, loss = 0.33233 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:17:57.393160 ops/training.py:65 2019-01-16 13:17:57.393111: step 16659, loss = 0.31434 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:17:58.359435 ops/training.py:65 2019-01-16 13:17:58.359372: step 16660, loss = 0.31461 (33.1 examples/sec; 0.965 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:17:59.321548 ops/training.py:65 2019-01-16 13:17:59.321482: step 16661, loss = 0.33516 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:18:00.282372 ops/training.py:65 2019-01-16 13:18:00.282326: step 16662, loss = 0.37342 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:18:01.241087 ops/training.py:65 2019-01-16 13:18:01.241044: step 16663, loss = 0.31097 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:18:02.203845 ops/training.py:65 2019-01-16 13:18:02.203796: step 16664, loss = 0.27991 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:18:03.168156 ops/training.py:65 2019-01-16 13:18:03.168096: step 16665, loss = 0.52362 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:18:04.132191 ops/training.py:65 2019-01-16 13:18:04.132127: step 16666, loss = 0.39616 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:18:05.093828 ops/training.py:65 2019-01-16 13:18:05.093776: step 16667, loss = 0.34194 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:18:06.054891 ops/training.py:65 2019-01-16 13:18:06.054821: step 16668, loss = 0.34353 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:18:07.015746 ops/training.py:65 2019-01-16 13:18:07.015672: step 16669, loss = 0.35428 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:18:07.977273 ops/training.py:65 2019-01-16 13:18:07.977200: step 16670, loss = 0.38220 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:18:08.940307 ops/training.py:65 2019-01-16 13:18:08.940236: step 16671, loss = 0.26641 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:18:09.904141 ops/training.py:65 2019-01-16 13:18:09.904096: step 16672, loss = 0.58219 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 13:18:10.867463 ops/training.py:65 2019-01-16 13:18:10.867404: step 16673, loss = 0.39507 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:18:11.830641 ops/training.py:65 2019-01-16 13:18:11.830567: step 16674, loss = 0.45528 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:18:12.792304 ops/training.py:65 2019-01-16 13:18:12.792244: step 16675, loss = 0.29107 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:18:13.753703 ops/training.py:65 2019-01-16 13:18:13.753633: step 16676, loss = 0.33176 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:18:14.714023 ops/training.py:65 2019-01-16 13:18:14.713972: step 16677, loss = 0.23608 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:18:15.675834 ops/training.py:65 2019-01-16 13:18:15.675779: step 16678, loss = 0.49173 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:18:16.637094 ops/training.py:65 2019-01-16 13:18:16.637027: step 16679, loss = 0.31310 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:18:17.599861 ops/training.py:65 2019-01-16 13:18:17.599799: step 16680, loss = 0.25163 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:18:18.560391 ops/training.py:65 2019-01-16 13:18:18.560331: step 16681, loss = 0.35516 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:18:19.520574 ops/training.py:65 2019-01-16 13:18:19.520513: step 16682, loss = 0.43909 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:18:20.479947 ops/training.py:65 2019-01-16 13:18:20.479878: step 16683, loss = 0.43584 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:18:21.438188 ops/training.py:65 2019-01-16 13:18:21.438121: step 16684, loss = 0.34362 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:18:22.396571 ops/training.py:65 2019-01-16 13:18:22.396502: step 16685, loss = 0.29912 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:18:23.355285 ops/training.py:65 2019-01-16 13:18:23.355214: step 16686, loss = 0.43252 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:18:24.313614 ops/training.py:65 2019-01-16 13:18:24.313543: step 16687, loss = 0.34503 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:18:25.272125 ops/training.py:65 2019-01-16 13:18:25.272056: step 16688, loss = 0.28150 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:18:26.230127 ops/training.py:65 2019-01-16 13:18:26.230058: step 16689, loss = 0.46197 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:18:27.190699 ops/training.py:65 2019-01-16 13:18:27.190644: step 16690, loss = 0.37928 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:18:28.149861 ops/training.py:65 2019-01-16 13:18:28.149818: step 16691, loss = 0.32418 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:18:29.112197 ops/training.py:65 2019-01-16 13:18:29.112143: step 16692, loss = 0.41757 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:18:30.076050 ops/training.py:65 2019-01-16 13:18:30.075987: step 16693, loss = 0.39645 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:18:31.039207 ops/training.py:65 2019-01-16 13:18:31.039120: step 16694, loss = 0.39576 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:18:32.000906 ops/training.py:65 2019-01-16 13:18:32.000828: step 16695, loss = 0.38527 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:18:32.963769 ops/training.py:65 2019-01-16 13:18:32.963721: step 16696, loss = 0.41305 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:18:33.924718 ops/training.py:65 2019-01-16 13:18:33.924673: step 16697, loss = 0.38933 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:18:34.886979 ops/training.py:65 2019-01-16 13:18:34.886925: step 16698, loss = 0.31439 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:18:35.850901 ops/training.py:65 2019-01-16 13:18:35.850824: step 16699, loss = 0.57874 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:18:36.815075 ops/training.py:65 2019-01-16 13:18:36.814998: step 16700, loss = 0.45966 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:18:37.776829 ops/training.py:65 2019-01-16 13:18:37.776758: step 16701, loss = 0.33391 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:18:38.738927 ops/training.py:65 2019-01-16 13:18:38.738856: step 16702, loss = 0.34812 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:18:39.700384 ops/training.py:65 2019-01-16 13:18:39.700317: step 16703, loss = 0.50213 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:18:40.661519 ops/training.py:65 2019-01-16 13:18:40.661446: step 16704, loss = 0.40449 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:18:41.622592 ops/training.py:65 2019-01-16 13:18:41.622526: step 16705, loss = 0.46189 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:18:42.584948 ops/training.py:65 2019-01-16 13:18:42.584894: step 16706, loss = 0.52273 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:18:43.546667 ops/training.py:65 2019-01-16 13:18:43.546613: step 16707, loss = 0.31381 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:18:44.509245 ops/training.py:65 2019-01-16 13:18:44.509194: step 16708, loss = 0.39563 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:18:45.470777 ops/training.py:65 2019-01-16 13:18:45.470728: step 16709, loss = 0.45450 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:18:46.433840 ops/training.py:65 2019-01-16 13:18:46.433788: step 16710, loss = 0.32652 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:18:47.398074 ops/training.py:65 2019-01-16 13:18:47.398003: step 16711, loss = 0.40279 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:18:48.362035 ops/training.py:65 2019-01-16 13:18:48.361968: step 16712, loss = 0.33569 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:18:49.327781 ops/training.py:65 2019-01-16 13:18:49.327715: step 16713, loss = 0.52942 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:18:50.288560 ops/training.py:65 2019-01-16 13:18:50.288490: step 16714, loss = 0.38480 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:18:51.249751 ops/training.py:65 2019-01-16 13:18:51.249680: step 16715, loss = 0.34995 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:18:52.210915 ops/training.py:65 2019-01-16 13:18:52.210844: step 16716, loss = 0.38503 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:18:53.171949 ops/training.py:65 2019-01-16 13:18:53.171878: step 16717, loss = 0.36314 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:18:54.132971 ops/training.py:65 2019-01-16 13:18:54.132902: step 16718, loss = 0.29626 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:18:55.093770 ops/training.py:65 2019-01-16 13:18:55.093695: step 16719, loss = 0.52758 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:18:56.055534 ops/training.py:65 2019-01-16 13:18:56.055461: step 16720, loss = 0.32941 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:18:57.017115 ops/training.py:65 2019-01-16 13:18:57.017044: step 16721, loss = 0.40455 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:18:57.978235 ops/training.py:65 2019-01-16 13:18:57.978184: step 16722, loss = 0.38091 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:18:58.940150 ops/training.py:65 2019-01-16 13:18:58.940075: step 16723, loss = 0.51582 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:18:59.901506 ops/training.py:65 2019-01-16 13:18:59.901455: step 16724, loss = 0.28849 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:19:00.862773 ops/training.py:65 2019-01-16 13:19:00.862703: step 16725, loss = 0.42065 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:19:01.823540 ops/training.py:65 2019-01-16 13:19:01.823470: step 16726, loss = 0.38035 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:19:02.785166 ops/training.py:65 2019-01-16 13:19:02.785096: step 16727, loss = 0.52476 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:19:03.746363 ops/training.py:65 2019-01-16 13:19:03.746294: step 16728, loss = 0.39476 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:19:04.706910 ops/training.py:65 2019-01-16 13:19:04.706840: step 16729, loss = 0.37681 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:19:05.667919 ops/training.py:65 2019-01-16 13:19:05.667846: step 16730, loss = 0.39173 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:19:06.629497 ops/training.py:65 2019-01-16 13:19:06.629428: step 16731, loss = 0.45661 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:19:07.590957 ops/training.py:65 2019-01-16 13:19:07.590882: step 16732, loss = 0.38064 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:19:08.552592 ops/training.py:65 2019-01-16 13:19:08.552520: step 16733, loss = 0.44087 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:19:09.513720 ops/training.py:65 2019-01-16 13:19:09.513648: step 16734, loss = 0.27345 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:19:10.474313 ops/training.py:65 2019-01-16 13:19:10.474240: step 16735, loss = 0.30282 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:19:11.436347 ops/training.py:65 2019-01-16 13:19:11.436276: step 16736, loss = 0.45115 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:19:12.398557 ops/training.py:65 2019-01-16 13:19:12.398483: step 16737, loss = 0.45491 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:19:13.360165 ops/training.py:65 2019-01-16 13:19:13.360116: step 16738, loss = 0.38097 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:19:14.321444 ops/training.py:65 2019-01-16 13:19:14.321384: step 16739, loss = 0.45385 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:19:15.283355 ops/training.py:65 2019-01-16 13:19:15.283302: step 16740, loss = 0.50390 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:19:16.245496 ops/training.py:65 2019-01-16 13:19:16.245421: step 16741, loss = 0.35995 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:19:17.206947 ops/training.py:65 2019-01-16 13:19:17.206873: step 16742, loss = 0.38197 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:19:18.171006 ops/training.py:65 2019-01-16 13:19:18.170953: step 16743, loss = 0.41619 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:19:19.135953 ops/training.py:65 2019-01-16 13:19:19.135882: step 16744, loss = 0.31048 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:19:20.099915 ops/training.py:65 2019-01-16 13:19:20.099844: step 16745, loss = 0.33343 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:19:21.061956 ops/training.py:65 2019-01-16 13:19:21.061886: step 16746, loss = 0.30519 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:19:22.022963 ops/training.py:65 2019-01-16 13:19:22.022893: step 16747, loss = 0.53850 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:19:22.984010 ops/training.py:65 2019-01-16 13:19:22.983937: step 16748, loss = 0.43439 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:19:23.946548 ops/training.py:65 2019-01-16 13:19:23.946473: step 16749, loss = 0.34559 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:19:24.908502 ops/training.py:65 2019-01-16 13:19:24.908428: step 16750, loss = 0.43457 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:19:25.869812 ops/training.py:65 2019-01-16 13:19:25.869740: step 16751, loss = 0.28773 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:19:26.830313 ops/training.py:65 2019-01-16 13:19:26.830245: step 16752, loss = 0.29541 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:19:27.791630 ops/training.py:65 2019-01-16 13:19:27.791578: step 16753, loss = 0.44159 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:19:28.753274 ops/training.py:65 2019-01-16 13:19:28.753201: step 16754, loss = 0.43513 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:19:29.714924 ops/training.py:65 2019-01-16 13:19:29.714872: step 16755, loss = 0.34165 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:19:30.676015 ops/training.py:65 2019-01-16 13:19:30.675940: step 16756, loss = 0.31202 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:19:31.637026 ops/training.py:65 2019-01-16 13:19:31.636976: step 16757, loss = 0.31818 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:19:32.595668 ops/training.py:65 2019-01-16 13:19:32.595619: step 16758, loss = 0.32668 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:19:33.555890 ops/training.py:65 2019-01-16 13:19:33.555840: step 16759, loss = 0.36366 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:19:34.519925 ops/training.py:65 2019-01-16 13:19:34.519873: step 16760, loss = 0.38854 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:19:35.484188 ops/training.py:65 2019-01-16 13:19:35.484134: step 16761, loss = 0.43599 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:19:36.446638 ops/training.py:65 2019-01-16 13:19:36.446570: step 16762, loss = 0.36394 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:19:37.406847 ops/training.py:65 2019-01-16 13:19:37.406777: step 16763, loss = 0.37441 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:19:38.368060 ops/training.py:65 2019-01-16 13:19:38.367991: step 16764, loss = 0.31835 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:19:39.328264 ops/training.py:65 2019-01-16 13:19:39.328199: step 16765, loss = 0.29815 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:19:40.289298 ops/training.py:65 2019-01-16 13:19:40.289227: step 16766, loss = 0.38652 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:19:41.250165 ops/training.py:65 2019-01-16 13:19:41.250092: step 16767, loss = 0.40821 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:19:42.210772 ops/training.py:65 2019-01-16 13:19:42.210696: step 16768, loss = 0.46772 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:19:43.171777 ops/training.py:65 2019-01-16 13:19:43.171726: step 16769, loss = 0.45137 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:19:44.135893 ops/training.py:65 2019-01-16 13:19:44.135836: step 16770, loss = 0.42262 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:19:45.100258 ops/training.py:65 2019-01-16 13:19:45.100209: step 16771, loss = 0.46872 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:19:46.063820 ops/training.py:65 2019-01-16 13:19:46.063751: step 16772, loss = 0.42054 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:19:47.025329 ops/training.py:65 2019-01-16 13:19:47.025273: step 16773, loss = 0.64019 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:19:47.986603 ops/training.py:65 2019-01-16 13:19:47.986558: step 16774, loss = 0.30256 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:19:48.947811 ops/training.py:65 2019-01-16 13:19:48.947753: step 16775, loss = 0.44008 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:19:49.909034 ops/training.py:65 2019-01-16 13:19:49.908975: step 16776, loss = 0.50983 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:19:50.870463 ops/training.py:65 2019-01-16 13:19:50.870412: step 16777, loss = 0.35948 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:19:51.832109 ops/training.py:65 2019-01-16 13:19:51.832044: step 16778, loss = 0.50483 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:19:52.794334 ops/training.py:65 2019-01-16 13:19:52.794264: step 16779, loss = 0.43253 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:19:53.757656 ops/training.py:65 2019-01-16 13:19:53.757589: step 16780, loss = 0.50048 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:19:54.718246 ops/training.py:65 2019-01-16 13:19:54.718179: step 16781, loss = 0.34723 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:19:55.678890 ops/training.py:65 2019-01-16 13:19:55.678842: step 16782, loss = 0.35678 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:19:56.638879 ops/training.py:65 2019-01-16 13:19:56.638832: step 16783, loss = 0.42316 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:19:57.597315 ops/training.py:65 2019-01-16 13:19:57.597271: step 16784, loss = 0.38408 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:19:58.555726 ops/training.py:65 2019-01-16 13:19:58.555678: step 16785, loss = 0.32962 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:19:59.514830 ops/training.py:65 2019-01-16 13:19:59.514785: step 16786, loss = 0.29298 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:20:00.474791 ops/training.py:65 2019-01-16 13:20:00.474745: step 16787, loss = 0.45308 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:20:01.433886 ops/training.py:65 2019-01-16 13:20:01.433841: step 16788, loss = 0.37060 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:20:02.392754 ops/training.py:65 2019-01-16 13:20:02.392703: step 16789, loss = 0.42079 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:20:03.353107 ops/training.py:65 2019-01-16 13:20:03.353054: step 16790, loss = 0.35096 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:20:04.315984 ops/training.py:65 2019-01-16 13:20:04.315937: step 16791, loss = 0.50159 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:20:05.280123 ops/training.py:65 2019-01-16 13:20:05.280051: step 16792, loss = 0.37839 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:20:06.242288 ops/training.py:65 2019-01-16 13:20:06.242221: step 16793, loss = 0.50591 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:20:07.203064 ops/training.py:65 2019-01-16 13:20:07.203002: step 16794, loss = 0.36317 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:20:08.164656 ops/training.py:65 2019-01-16 13:20:08.164600: step 16795, loss = 0.44900 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:20:09.126690 ops/training.py:65 2019-01-16 13:20:09.126631: step 16796, loss = 0.46960 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:20:10.087075 ops/training.py:65 2019-01-16 13:20:10.087023: step 16797, loss = 0.44798 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:20:11.047028 ops/training.py:65 2019-01-16 13:20:11.046972: step 16798, loss = 0.26998 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:20:12.006989 ops/training.py:65 2019-01-16 13:20:12.006921: step 16799, loss = 0.44329 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:20:12.971177 ops/training.py:65 2019-01-16 13:20:12.971112: step 16800, loss = 0.40920 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:20:13.933408 ops/training.py:65 2019-01-16 13:20:13.933345: step 16801, loss = 0.25538 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:20:14.897500 ops/training.py:65 2019-01-16 13:20:14.897451: step 16802, loss = 0.46575 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:20:15.861586 ops/training.py:65 2019-01-16 13:20:15.861513: step 16803, loss = 0.37335 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:20:16.825767 ops/training.py:65 2019-01-16 13:20:16.825703: step 16804, loss = 0.54378 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:20:17.788238 ops/training.py:65 2019-01-16 13:20:17.788170: step 16805, loss = 0.62608 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:20:18.750113 ops/training.py:65 2019-01-16 13:20:18.750041: step 16806, loss = 0.39308 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:20:19.719906 ops/training.py:65 2019-01-16 13:20:19.719860: step 16807, loss = 0.40944 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:20:20.684536 ops/training.py:65 2019-01-16 13:20:20.684485: step 16808, loss = 0.35746 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:20:21.647164 ops/training.py:65 2019-01-16 13:20:21.647096: step 16809, loss = 0.35832 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:20:22.612320 ops/training.py:65 2019-01-16 13:20:22.612271: step 16810, loss = 0.43857 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:20:23.577408 ops/training.py:65 2019-01-16 13:20:23.577363: step 16811, loss = 0.46348 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:20:24.541517 ops/training.py:65 2019-01-16 13:20:24.541448: step 16812, loss = 0.35420 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:20:25.502994 ops/training.py:65 2019-01-16 13:20:25.502928: step 16813, loss = 0.44733 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:20:26.464004 ops/training.py:65 2019-01-16 13:20:26.463932: step 16814, loss = 0.39858 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:20:27.425007 ops/training.py:65 2019-01-16 13:20:27.424934: step 16815, loss = 0.38559 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:20:28.387335 ops/training.py:65 2019-01-16 13:20:28.387269: step 16816, loss = 0.35049 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:20:29.349161 ops/training.py:65 2019-01-16 13:20:29.349101: step 16817, loss = 0.41365 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:20:30.310967 ops/training.py:65 2019-01-16 13:20:30.310900: step 16818, loss = 0.38871 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:20:31.272731 ops/training.py:65 2019-01-16 13:20:31.272662: step 16819, loss = 0.51327 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:20:32.236423 ops/training.py:65 2019-01-16 13:20:32.236363: step 16820, loss = 0.43064 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:20:33.197826 ops/training.py:65 2019-01-16 13:20:33.197756: step 16821, loss = 0.42211 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:20:34.159066 ops/training.py:65 2019-01-16 13:20:34.158998: step 16822, loss = 0.44184 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:20:35.119610 ops/training.py:65 2019-01-16 13:20:35.119540: step 16823, loss = 0.39829 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:20:36.080597 ops/training.py:65 2019-01-16 13:20:36.080526: step 16824, loss = 0.29734 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:20:37.042548 ops/training.py:65 2019-01-16 13:20:37.042464: step 16825, loss = 0.37484 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:20:38.004311 ops/training.py:65 2019-01-16 13:20:38.004243: step 16826, loss = 0.41115 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:20:38.965687 ops/training.py:65 2019-01-16 13:20:38.965622: step 16827, loss = 0.33354 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:20:39.929272 ops/training.py:65 2019-01-16 13:20:39.929207: step 16828, loss = 0.43619 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:20:40.894043 ops/training.py:65 2019-01-16 13:20:40.893972: step 16829, loss = 0.60210 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 13:20:41.857098 ops/training.py:65 2019-01-16 13:20:41.857027: step 16830, loss = 0.48580 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:20:42.817659 ops/training.py:65 2019-01-16 13:20:42.817603: step 16831, loss = 0.35000 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:20:43.778838 ops/training.py:65 2019-01-16 13:20:43.778768: step 16832, loss = 0.32558 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:20:44.739183 ops/training.py:65 2019-01-16 13:20:44.739113: step 16833, loss = 0.40707 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:20:45.704594 ops/training.py:65 2019-01-16 13:20:45.704525: step 16834, loss = 0.38471 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:20:46.668018 ops/training.py:65 2019-01-16 13:20:46.667946: step 16835, loss = 0.32186 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:20:47.630345 ops/training.py:65 2019-01-16 13:20:47.630276: step 16836, loss = 0.43522 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:20:48.591893 ops/training.py:65 2019-01-16 13:20:48.591829: step 16837, loss = 0.42739 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:20:49.555073 ops/training.py:65 2019-01-16 13:20:49.555021: step 16838, loss = 0.31353 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:20:50.518656 ops/training.py:65 2019-01-16 13:20:50.518584: step 16839, loss = 0.33300 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:20:51.482243 ops/training.py:65 2019-01-16 13:20:51.482170: step 16840, loss = 0.31252 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:20:52.445589 ops/training.py:65 2019-01-16 13:20:52.445514: step 16841, loss = 0.37656 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:20:53.408243 ops/training.py:65 2019-01-16 13:20:53.408172: step 16842, loss = 0.43015 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:20:54.372858 ops/training.py:65 2019-01-16 13:20:54.372782: step 16843, loss = 0.31848 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:20:55.334817 ops/training.py:65 2019-01-16 13:20:55.334741: step 16844, loss = 0.51455 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:20:56.296734 ops/training.py:65 2019-01-16 13:20:56.296658: step 16845, loss = 0.40544 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:20:57.262071 ops/training.py:65 2019-01-16 13:20:57.262000: step 16846, loss = 0.43683 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:20:58.225642 ops/training.py:65 2019-01-16 13:20:58.225566: step 16847, loss = 0.36292 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:20:59.190293 ops/training.py:65 2019-01-16 13:20:59.190218: step 16848, loss = 0.37662 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:21:00.151452 ops/training.py:65 2019-01-16 13:21:00.151377: step 16849, loss = 0.30592 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:21:01.112972 ops/training.py:65 2019-01-16 13:21:01.112900: step 16850, loss = 0.38135 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:21:02.077076 ops/training.py:65 2019-01-16 13:21:02.077010: step 16851, loss = 0.38130 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:21:03.040148 ops/training.py:65 2019-01-16 13:21:03.040081: step 16852, loss = 0.28016 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:21:04.003997 ops/training.py:65 2019-01-16 13:21:04.003929: step 16853, loss = 0.43014 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:21:04.965962 ops/training.py:65 2019-01-16 13:21:04.965896: step 16854, loss = 0.43618 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:21:05.933848 ops/training.py:65 2019-01-16 13:21:05.933775: step 16855, loss = 0.49632 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:21:06.897261 ops/training.py:65 2019-01-16 13:21:06.897190: step 16856, loss = 0.33416 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:21:07.860571 ops/training.py:65 2019-01-16 13:21:07.860498: step 16857, loss = 0.39225 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:21:08.822264 ops/training.py:65 2019-01-16 13:21:08.822188: step 16858, loss = 0.33072 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:21:09.783907 ops/training.py:65 2019-01-16 13:21:09.783830: step 16859, loss = 0.37929 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:21:10.745324 ops/training.py:65 2019-01-16 13:21:10.745255: step 16860, loss = 0.33210 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:21:11.706032 ops/training.py:65 2019-01-16 13:21:11.705963: step 16861, loss = 0.38597 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:21:12.666027 ops/training.py:65 2019-01-16 13:21:12.665958: step 16862, loss = 0.38540 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:21:13.626853 ops/training.py:65 2019-01-16 13:21:13.626786: step 16863, loss = 0.35523 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:21:14.587086 ops/training.py:65 2019-01-16 13:21:14.587020: step 16864, loss = 0.40993 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:21:15.548385 ops/training.py:65 2019-01-16 13:21:15.548316: step 16865, loss = 0.48639 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:21:16.509163 ops/training.py:65 2019-01-16 13:21:16.509094: step 16866, loss = 0.56732 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:21:17.470263 ops/training.py:65 2019-01-16 13:21:17.470195: step 16867, loss = 0.34418 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:21:18.431413 ops/training.py:65 2019-01-16 13:21:18.431345: step 16868, loss = 0.45776 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:21:19.392961 ops/training.py:65 2019-01-16 13:21:19.392896: step 16869, loss = 0.55359 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:21:20.353934 ops/training.py:65 2019-01-16 13:21:20.353865: step 16870, loss = 0.31038 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:21:21.315606 ops/training.py:65 2019-01-16 13:21:21.315537: step 16871, loss = 0.40216 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:21:22.276277 ops/training.py:65 2019-01-16 13:21:22.276210: step 16872, loss = 0.41725 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:21:23.240278 ops/training.py:65 2019-01-16 13:21:23.240214: step 16873, loss = 0.41568 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:21:24.203043 ops/training.py:65 2019-01-16 13:21:24.202977: step 16874, loss = 0.53963 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:21:25.165765 ops/training.py:65 2019-01-16 13:21:25.165696: step 16875, loss = 0.36902 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:21:26.126916 ops/training.py:65 2019-01-16 13:21:26.126847: step 16876, loss = 0.53426 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:21:27.088072 ops/training.py:65 2019-01-16 13:21:27.088010: step 16877, loss = 0.41160 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:21:28.051879 ops/training.py:65 2019-01-16 13:21:28.051810: step 16878, loss = 0.34194 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:21:29.013258 ops/training.py:65 2019-01-16 13:21:29.013191: step 16879, loss = 0.21892 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:21:29.975010 ops/training.py:65 2019-01-16 13:21:29.974945: step 16880, loss = 0.32271 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:21:30.937141 ops/training.py:65 2019-01-16 13:21:30.937079: step 16881, loss = 0.36603 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:21:31.901587 ops/training.py:65 2019-01-16 13:21:31.901521: step 16882, loss = 0.44493 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:21:32.864905 ops/training.py:65 2019-01-16 13:21:32.864837: step 16883, loss = 0.47478 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:21:33.827151 ops/training.py:65 2019-01-16 13:21:33.827082: step 16884, loss = 0.43247 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:21:34.788898 ops/training.py:65 2019-01-16 13:21:34.788828: step 16885, loss = 0.25074 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:21:35.753419 ops/training.py:65 2019-01-16 13:21:35.753354: step 16886, loss = 0.42707 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:21:36.716653 ops/training.py:65 2019-01-16 13:21:36.716585: step 16887, loss = 0.30032 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:21:37.678866 ops/training.py:65 2019-01-16 13:21:37.678814: step 16888, loss = 0.52839 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:21:38.640307 ops/training.py:65 2019-01-16 13:21:38.640239: step 16889, loss = 0.38657 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:21:39.601579 ops/training.py:65 2019-01-16 13:21:39.601515: step 16890, loss = 0.31149 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:21:40.563067 ops/training.py:65 2019-01-16 13:21:40.562999: step 16891, loss = 0.41882 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:21:41.524326 ops/training.py:65 2019-01-16 13:21:41.524259: step 16892, loss = 0.49801 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:21:42.486010 ops/training.py:65 2019-01-16 13:21:42.485944: step 16893, loss = 0.33596 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:21:43.450005 ops/training.py:65 2019-01-16 13:21:43.449935: step 16894, loss = 0.38744 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:21:44.413649 ops/training.py:65 2019-01-16 13:21:44.413579: step 16895, loss = 0.30447 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:21:45.376073 ops/training.py:65 2019-01-16 13:21:45.376004: step 16896, loss = 0.45857 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:21:46.336877 ops/training.py:65 2019-01-16 13:21:46.336808: step 16897, loss = 0.32842 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:21:47.297684 ops/training.py:65 2019-01-16 13:21:47.297615: step 16898, loss = 0.38275 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:21:48.257967 ops/training.py:65 2019-01-16 13:21:48.257908: step 16899, loss = 0.35224 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:21:49.219264 ops/training.py:65 2019-01-16 13:21:49.219205: step 16900, loss = 0.34270 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:21:50.180143 ops/training.py:65 2019-01-16 13:21:50.180073: step 16901, loss = 0.30094 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:21:51.141688 ops/training.py:65 2019-01-16 13:21:51.141618: step 16902, loss = 0.33790 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:21:52.102793 ops/training.py:65 2019-01-16 13:21:52.102726: step 16903, loss = 0.31270 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:21:53.063383 ops/training.py:65 2019-01-16 13:21:53.063327: step 16904, loss = 0.35159 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:21:54.025692 ops/training.py:65 2019-01-16 13:21:54.025622: step 16905, loss = 0.38503 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:21:54.986942 ops/training.py:65 2019-01-16 13:21:54.986872: step 16906, loss = 0.27236 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:21:55.947331 ops/training.py:65 2019-01-16 13:21:55.947243: step 16907, loss = 0.56207 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:21:56.908058 ops/training.py:65 2019-01-16 13:21:56.907973: step 16908, loss = 0.36762 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:21:57.870031 ops/training.py:65 2019-01-16 13:21:57.869956: step 16909, loss = 0.43155 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:21:58.830820 ops/training.py:65 2019-01-16 13:21:58.830753: step 16910, loss = 0.38886 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:21:59.791561 ops/training.py:65 2019-01-16 13:21:59.791499: step 16911, loss = 0.37243 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:22:00.752713 ops/training.py:65 2019-01-16 13:22:00.752629: step 16912, loss = 0.43803 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:22:01.713394 ops/training.py:65 2019-01-16 13:22:01.713309: step 16913, loss = 0.40182 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:22:02.674229 ops/training.py:65 2019-01-16 13:22:02.674165: step 16914, loss = 0.47519 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:22:03.635145 ops/training.py:65 2019-01-16 13:22:03.635074: step 16915, loss = 0.35185 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:22:04.595884 ops/training.py:65 2019-01-16 13:22:04.595815: step 16916, loss = 0.33311 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:22:05.556706 ops/training.py:65 2019-01-16 13:22:05.556640: step 16917, loss = 0.47200 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:22:06.517472 ops/training.py:65 2019-01-16 13:22:06.517404: step 16918, loss = 0.39773 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:22:07.478513 ops/training.py:65 2019-01-16 13:22:07.478444: step 16919, loss = 0.33361 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:22:08.440100 ops/training.py:65 2019-01-16 13:22:08.440045: step 16920, loss = 0.31276 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:22:09.400696 ops/training.py:65 2019-01-16 13:22:09.400631: step 16921, loss = 0.31275 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:22:10.362412 ops/training.py:65 2019-01-16 13:22:10.362346: step 16922, loss = 0.30900 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:22:11.327648 ops/training.py:65 2019-01-16 13:22:11.327581: step 16923, loss = 0.47041 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:22:12.288677 ops/training.py:65 2019-01-16 13:22:12.288607: step 16924, loss = 0.45985 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:22:13.252764 ops/training.py:65 2019-01-16 13:22:13.252710: step 16925, loss = 0.40535 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:22:14.216471 ops/training.py:65 2019-01-16 13:22:14.216382: step 16926, loss = 0.38141 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:22:15.179153 ops/training.py:65 2019-01-16 13:22:15.179066: step 16927, loss = 0.50991 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:22:16.142093 ops/training.py:65 2019-01-16 13:22:16.142022: step 16928, loss = 0.43400 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:22:17.103494 ops/training.py:65 2019-01-16 13:22:17.103423: step 16929, loss = 0.32064 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:22:18.063059 ops/training.py:65 2019-01-16 13:22:18.062990: step 16930, loss = 0.44839 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:22:19.023409 ops/training.py:65 2019-01-16 13:22:19.023338: step 16931, loss = 0.35026 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:22:19.984131 ops/training.py:65 2019-01-16 13:22:19.984066: step 16932, loss = 0.39295 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:22:20.945170 ops/training.py:65 2019-01-16 13:22:20.945081: step 16933, loss = 0.42334 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:22:21.909794 ops/training.py:65 2019-01-16 13:22:21.909725: step 16934, loss = 0.44132 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:22:22.873265 ops/training.py:65 2019-01-16 13:22:22.873215: step 16935, loss = 0.39714 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:22:23.836620 ops/training.py:65 2019-01-16 13:22:23.836551: step 16936, loss = 0.42601 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:22:24.797990 ops/training.py:65 2019-01-16 13:22:24.797917: step 16937, loss = 0.38642 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:22:25.760189 ops/training.py:65 2019-01-16 13:22:25.760120: step 16938, loss = 0.40185 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:22:26.722370 ops/training.py:65 2019-01-16 13:22:26.722301: step 16939, loss = 0.47696 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:22:27.684730 ops/training.py:65 2019-01-16 13:22:27.684656: step 16940, loss = 0.42495 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:22:28.644930 ops/training.py:65 2019-01-16 13:22:28.644860: step 16941, loss = 0.37778 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:22:29.609086 ops/training.py:65 2019-01-16 13:22:29.609024: step 16942, loss = 0.41087 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:22:30.572492 ops/training.py:65 2019-01-16 13:22:30.572410: step 16943, loss = 0.45801 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:22:31.534987 ops/training.py:65 2019-01-16 13:22:31.534918: step 16944, loss = 0.62834 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:22:32.497134 ops/training.py:65 2019-01-16 13:22:32.497064: step 16945, loss = 0.47492 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:22:33.458865 ops/training.py:65 2019-01-16 13:22:33.458795: step 16946, loss = 0.50395 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:22:34.420472 ops/training.py:65 2019-01-16 13:22:34.420387: step 16947, loss = 0.53740 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:22:35.381467 ops/training.py:65 2019-01-16 13:22:35.381397: step 16948, loss = 0.58918 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 13:22:36.344067 ops/training.py:65 2019-01-16 13:22:36.343998: step 16949, loss = 0.56237 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:22:37.305529 ops/training.py:65 2019-01-16 13:22:37.305461: step 16950, loss = 0.33594 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:22:38.265860 ops/training.py:65 2019-01-16 13:22:38.265811: step 16951, loss = 0.50674 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:22:39.226100 ops/training.py:65 2019-01-16 13:22:39.226038: step 16952, loss = 0.56600 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:22:40.187338 ops/training.py:65 2019-01-16 13:22:40.187267: step 16953, loss = 0.35141 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:22:41.147720 ops/training.py:65 2019-01-16 13:22:41.147646: step 16954, loss = 0.38868 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:22:42.108348 ops/training.py:65 2019-01-16 13:22:42.108294: step 16955, loss = 0.32413 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:22:43.067158 ops/training.py:65 2019-01-16 13:22:43.067105: step 16956, loss = 0.50248 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:22:44.027490 ops/training.py:65 2019-01-16 13:22:44.027423: step 16957, loss = 0.50934 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:22:44.988132 ops/training.py:65 2019-01-16 13:22:44.988064: step 16958, loss = 0.45067 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:22:45.948294 ops/training.py:65 2019-01-16 13:22:45.948237: step 16959, loss = 0.38144 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:22:46.910294 ops/training.py:65 2019-01-16 13:22:46.910230: step 16960, loss = 0.37878 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:22:47.872570 ops/training.py:65 2019-01-16 13:22:47.872506: step 16961, loss = 0.39775 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:22:48.834843 ops/training.py:65 2019-01-16 13:22:48.834775: step 16962, loss = 0.40481 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:22:49.795579 ops/training.py:65 2019-01-16 13:22:49.795513: step 16963, loss = 0.41479 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:22:50.756487 ops/training.py:65 2019-01-16 13:22:50.756426: step 16964, loss = 0.40160 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:22:51.717329 ops/training.py:65 2019-01-16 13:22:51.717265: step 16965, loss = 0.28785 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:22:52.678297 ops/training.py:65 2019-01-16 13:22:52.678234: step 16966, loss = 0.43260 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:22:53.639959 ops/training.py:65 2019-01-16 13:22:53.639901: step 16967, loss = 0.25573 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:22:54.600788 ops/training.py:65 2019-01-16 13:22:54.600722: step 16968, loss = 0.40205 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:22:55.561688 ops/training.py:65 2019-01-16 13:22:55.561619: step 16969, loss = 0.47642 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:22:56.521924 ops/training.py:65 2019-01-16 13:22:56.521857: step 16970, loss = 0.29770 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:22:57.487311 ops/training.py:65 2019-01-16 13:22:57.487244: step 16971, loss = 0.40842 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:22:58.450688 ops/training.py:65 2019-01-16 13:22:58.450620: step 16972, loss = 0.40500 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:22:59.413322 ops/training.py:65 2019-01-16 13:22:59.413256: step 16973, loss = 0.43404 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:23:00.374821 ops/training.py:65 2019-01-16 13:23:00.374754: step 16974, loss = 0.30592 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:23:01.335490 ops/training.py:65 2019-01-16 13:23:01.335424: step 16975, loss = 0.38533 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:23:02.296343 ops/training.py:65 2019-01-16 13:23:02.296272: step 16976, loss = 0.40313 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:23:03.257458 ops/training.py:65 2019-01-16 13:23:03.257393: step 16977, loss = 0.40147 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:23:04.218507 ops/training.py:65 2019-01-16 13:23:04.218438: step 16978, loss = 0.44702 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:23:05.178916 ops/training.py:65 2019-01-16 13:23:05.178850: step 16979, loss = 0.42827 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:23:06.139797 ops/training.py:65 2019-01-16 13:23:06.139720: step 16980, loss = 0.62933 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:23:07.099870 ops/training.py:65 2019-01-16 13:23:07.099798: step 16981, loss = 0.40510 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:23:08.063110 ops/training.py:65 2019-01-16 13:23:08.063052: step 16982, loss = 0.45225 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:23:09.027922 ops/training.py:65 2019-01-16 13:23:09.027852: step 16983, loss = 0.46680 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:23:09.991712 ops/training.py:65 2019-01-16 13:23:09.991642: step 16984, loss = 0.54982 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:23:10.953244 ops/training.py:65 2019-01-16 13:23:10.953175: step 16985, loss = 0.30259 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:23:11.915339 ops/training.py:65 2019-01-16 13:23:11.915270: step 16986, loss = 0.68710 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 13:23:12.877056 ops/training.py:65 2019-01-16 13:23:12.876985: step 16987, loss = 0.35552 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:23:13.838459 ops/training.py:65 2019-01-16 13:23:13.838386: step 16988, loss = 0.40246 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:23:14.803471 ops/training.py:65 2019-01-16 13:23:14.803401: step 16989, loss = 0.37994 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:23:15.766284 ops/training.py:65 2019-01-16 13:23:15.766218: step 16990, loss = 0.43972 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:23:16.727435 ops/training.py:65 2019-01-16 13:23:16.727363: step 16991, loss = 0.35305 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:23:17.688046 ops/training.py:65 2019-01-16 13:23:17.687976: step 16992, loss = 0.29724 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:23:18.650348 ops/training.py:65 2019-01-16 13:23:18.650280: step 16993, loss = 0.41671 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:23:19.614672 ops/training.py:65 2019-01-16 13:23:19.614606: step 16994, loss = 0.30953 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:23:20.576267 ops/training.py:65 2019-01-16 13:23:20.576198: step 16995, loss = 0.34540 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:23:21.538796 ops/training.py:65 2019-01-16 13:23:21.538723: step 16996, loss = 0.35189 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:23:22.499318 ops/training.py:65 2019-01-16 13:23:22.499247: step 16997, loss = 0.41504 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:23:23.460162 ops/training.py:65 2019-01-16 13:23:23.460096: step 16998, loss = 0.55624 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:23:24.423955 ops/training.py:65 2019-01-16 13:23:24.423887: step 16999, loss = 0.48407 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:23:25.386682 ops/training.py:65 2019-01-16 13:23:25.386613: step 17000, loss = 0.36873 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:23:26.349852 ops/training.py:65 2019-01-16 13:23:26.349781: step 17001, loss = 0.40906 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:23:27.310934 ops/training.py:65 2019-01-16 13:23:27.310864: step 17002, loss = 0.35312 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:23:28.272357 ops/training.py:65 2019-01-16 13:23:28.272290: step 17003, loss = 0.47370 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:23:29.234207 ops/training.py:65 2019-01-16 13:23:29.234145: step 17004, loss = 0.38204 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:23:30.195168 ops/training.py:65 2019-01-16 13:23:30.195099: step 17005, loss = 0.33928 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:23:31.155823 ops/training.py:65 2019-01-16 13:23:31.155753: step 17006, loss = 0.54514 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:23:32.116740 ops/training.py:65 2019-01-16 13:23:32.116677: step 17007, loss = 0.31976 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:23:33.077111 ops/training.py:65 2019-01-16 13:23:33.077044: step 17008, loss = 0.54351 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:23:34.038023 ops/training.py:65 2019-01-16 13:23:34.037950: step 17009, loss = 0.35287 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:23:34.999039 ops/training.py:65 2019-01-16 13:23:34.998970: step 17010, loss = 0.32846 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:23:35.960406 ops/training.py:65 2019-01-16 13:23:35.960335: step 17011, loss = 0.40133 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:23:36.921960 ops/training.py:65 2019-01-16 13:23:36.921891: step 17012, loss = 0.39068 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:23:37.882735 ops/training.py:65 2019-01-16 13:23:37.882682: step 17013, loss = 0.52525 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:23:38.843310 ops/training.py:65 2019-01-16 13:23:38.843232: step 17014, loss = 0.40594 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:23:39.804492 ops/training.py:65 2019-01-16 13:23:39.804427: step 17015, loss = 0.28539 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:23:40.765308 ops/training.py:65 2019-01-16 13:23:40.765247: step 17016, loss = 0.54070 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:23:41.727135 ops/training.py:65 2019-01-16 13:23:41.727068: step 17017, loss = 0.53036 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:23:42.689067 ops/training.py:65 2019-01-16 13:23:42.688997: step 17018, loss = 0.27200 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:23:43.650050 ops/training.py:65 2019-01-16 13:23:43.649985: step 17019, loss = 0.51795 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:23:44.611337 ops/training.py:65 2019-01-16 13:23:44.611269: step 17020, loss = 0.24753 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:23:45.572448 ops/training.py:65 2019-01-16 13:23:45.572374: step 17021, loss = 0.32193 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:23:46.533129 ops/training.py:65 2019-01-16 13:23:46.533057: step 17022, loss = 0.49583 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:23:47.494301 ops/training.py:65 2019-01-16 13:23:47.494213: step 17023, loss = 0.33869 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:23:48.456555 ops/training.py:65 2019-01-16 13:23:48.456486: step 17024, loss = 0.45986 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:23:49.417232 ops/training.py:65 2019-01-16 13:23:49.417161: step 17025, loss = 0.33857 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:23:50.378518 ops/training.py:65 2019-01-16 13:23:50.378452: step 17026, loss = 0.37080 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:23:51.339347 ops/training.py:65 2019-01-16 13:23:51.339272: step 17027, loss = 0.30390 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:23:52.302039 ops/training.py:65 2019-01-16 13:23:52.301971: step 17028, loss = 0.49831 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:23:53.263267 ops/training.py:65 2019-01-16 13:23:53.263209: step 17029, loss = 0.35812 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:23:54.226732 ops/training.py:65 2019-01-16 13:23:54.226640: step 17030, loss = 0.45701 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:23:55.190742 ops/training.py:65 2019-01-16 13:23:55.190678: step 17031, loss = 0.25528 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:23:56.154065 ops/training.py:65 2019-01-16 13:23:56.153968: step 17032, loss = 0.43348 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:23:57.115405 ops/training.py:65 2019-01-16 13:23:57.115346: step 17033, loss = 0.39075 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:23:58.076503 ops/training.py:65 2019-01-16 13:23:58.076438: step 17034, loss = 0.44812 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:23:59.038289 ops/training.py:65 2019-01-16 13:23:59.038220: step 17035, loss = 0.40721 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:23:59.999052 ops/training.py:65 2019-01-16 13:23:59.998988: step 17036, loss = 0.44138 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:24:00.960754 ops/training.py:65 2019-01-16 13:24:00.960682: step 17037, loss = 0.31660 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:24:01.922056 ops/training.py:65 2019-01-16 13:24:01.921994: step 17038, loss = 0.61493 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:24:02.883808 ops/training.py:65 2019-01-16 13:24:02.883741: step 17039, loss = 0.38490 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:24:03.846417 ops/training.py:65 2019-01-16 13:24:03.846344: step 17040, loss = 0.25750 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:24:04.808427 ops/training.py:65 2019-01-16 13:24:04.808365: step 17041, loss = 0.43858 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:24:05.769719 ops/training.py:65 2019-01-16 13:24:05.769653: step 17042, loss = 0.35929 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:24:06.730377 ops/training.py:65 2019-01-16 13:24:06.730292: step 17043, loss = 0.30017 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:24:07.693071 ops/training.py:65 2019-01-16 13:24:07.692997: step 17044, loss = 0.26491 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:24:08.655199 ops/training.py:65 2019-01-16 13:24:08.655125: step 17045, loss = 0.38364 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:24:09.616839 ops/training.py:65 2019-01-16 13:24:09.616781: step 17046, loss = 0.39434 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:24:10.577369 ops/training.py:65 2019-01-16 13:24:10.577297: step 17047, loss = 0.29837 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:24:11.538325 ops/training.py:65 2019-01-16 13:24:11.538289: step 17048, loss = 0.31862 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:24:12.499224 ops/training.py:65 2019-01-16 13:24:12.499198: step 17049, loss = 0.33312 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:24:13.460824 ops/training.py:65 2019-01-16 13:24:13.460791: step 17050, loss = 0.37446 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:24:14.422128 ops/training.py:65 2019-01-16 13:24:14.422101: step 17051, loss = 0.51501 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:24:15.384143 ops/training.py:65 2019-01-16 13:24:15.384115: step 17052, loss = 0.27208 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:24:16.345706 ops/training.py:65 2019-01-16 13:24:16.345679: step 17053, loss = 0.47589 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:24:17.306809 ops/training.py:65 2019-01-16 13:24:17.306782: step 17054, loss = 0.40320 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:24:18.267875 ops/training.py:65 2019-01-16 13:24:18.267848: step 17055, loss = 0.46771 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:24:19.229150 ops/training.py:65 2019-01-16 13:24:19.229123: step 17056, loss = 0.37340 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:24:20.190330 ops/training.py:65 2019-01-16 13:24:20.190302: step 17057, loss = 0.40822 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:24:21.150864 ops/training.py:65 2019-01-16 13:24:21.150834: step 17058, loss = 0.42363 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:24:22.112243 ops/training.py:65 2019-01-16 13:24:22.112207: step 17059, loss = 0.47009 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:24:23.074663 ops/training.py:65 2019-01-16 13:24:23.074630: step 17060, loss = 0.45277 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:24:24.035403 ops/training.py:65 2019-01-16 13:24:24.035373: step 17061, loss = 0.42909 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:24:24.994751 ops/training.py:65 2019-01-16 13:24:24.994690: step 17062, loss = 0.30575 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:24:25.954917 ops/training.py:65 2019-01-16 13:24:25.954853: step 17063, loss = 0.39412 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:24:26.914904 ops/training.py:65 2019-01-16 13:24:26.914856: step 17064, loss = 0.42837 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:24:27.873061 ops/training.py:65 2019-01-16 13:24:27.873009: step 17065, loss = 0.32048 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:24:28.832449 ops/training.py:65 2019-01-16 13:24:28.832418: step 17066, loss = 0.38998 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:24:29.793600 ops/training.py:65 2019-01-16 13:24:29.793571: step 17067, loss = 0.26728 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:24:30.756572 ops/training.py:65 2019-01-16 13:24:30.756545: step 17068, loss = 0.47460 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:24:31.719737 ops/training.py:65 2019-01-16 13:24:31.719704: step 17069, loss = 0.31925 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:24:32.682729 ops/training.py:65 2019-01-16 13:24:32.682696: step 17070, loss = 0.64159 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 13:24:33.643380 ops/training.py:65 2019-01-16 13:24:33.643350: step 17071, loss = 0.32129 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:24:34.604282 ops/training.py:65 2019-01-16 13:24:34.604254: step 17072, loss = 0.56723 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:24:35.565131 ops/training.py:65 2019-01-16 13:24:35.565100: step 17073, loss = 0.75936 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 13:24:36.526172 ops/training.py:65 2019-01-16 13:24:36.526140: step 17074, loss = 0.42306 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:24:37.487366 ops/training.py:65 2019-01-16 13:24:37.487333: step 17075, loss = 0.39773 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:24:38.448048 ops/training.py:65 2019-01-16 13:24:38.448009: step 17076, loss = 0.40247 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:24:39.409175 ops/training.py:65 2019-01-16 13:24:39.409111: step 17077, loss = 0.32634 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:24:40.370025 ops/training.py:65 2019-01-16 13:24:40.369947: step 17078, loss = 0.48570 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:24:41.331374 ops/training.py:65 2019-01-16 13:24:41.331323: step 17079, loss = 0.30201 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:24:42.293115 ops/training.py:65 2019-01-16 13:24:42.293045: step 17080, loss = 0.60419 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 13:24:43.256210 ops/training.py:65 2019-01-16 13:24:43.256155: step 17081, loss = 0.51332 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:24:44.217748 ops/training.py:65 2019-01-16 13:24:44.217677: step 17082, loss = 0.35901 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:24:45.180077 ops/training.py:65 2019-01-16 13:24:45.180006: step 17083, loss = 0.37074 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:24:46.140912 ops/training.py:65 2019-01-16 13:24:46.140838: step 17084, loss = 0.23536 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:24:47.101320 ops/training.py:65 2019-01-16 13:24:47.101273: step 17085, loss = 0.39746 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:24:48.064264 ops/training.py:65 2019-01-16 13:24:48.064206: step 17086, loss = 0.31159 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:24:49.027491 ops/training.py:65 2019-01-16 13:24:49.027407: step 17087, loss = 0.39275 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:24:49.990421 ops/training.py:65 2019-01-16 13:24:49.990352: step 17088, loss = 0.41732 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:24:50.951587 ops/training.py:65 2019-01-16 13:24:50.951512: step 17089, loss = 0.53879 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:24:51.912855 ops/training.py:65 2019-01-16 13:24:51.912806: step 17090, loss = 0.44887 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:24:52.873996 ops/training.py:65 2019-01-16 13:24:52.873952: step 17091, loss = 0.40108 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:24:53.836319 ops/training.py:65 2019-01-16 13:24:53.836278: step 17092, loss = 0.27853 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:24:54.797282 ops/training.py:65 2019-01-16 13:24:54.797248: step 17093, loss = 0.45400 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:24:55.758494 ops/training.py:65 2019-01-16 13:24:55.758430: step 17094, loss = 0.30807 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:24:56.722574 ops/training.py:65 2019-01-16 13:24:56.722501: step 17095, loss = 0.29037 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:24:57.685569 ops/training.py:65 2019-01-16 13:24:57.685473: step 17096, loss = 0.37326 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:24:58.648718 ops/training.py:65 2019-01-16 13:24:58.648645: step 17097, loss = 0.17889 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:24:59.612678 ops/training.py:65 2019-01-16 13:24:59.612607: step 17098, loss = 0.31991 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:25:00.576189 ops/training.py:65 2019-01-16 13:25:00.576128: step 17099, loss = 0.41163 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:25:01.540516 ops/training.py:65 2019-01-16 13:25:01.540446: step 17100, loss = 0.34073 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:25:02.505506 ops/training.py:65 2019-01-16 13:25:02.505434: step 17101, loss = 0.43622 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:25:03.469834 ops/training.py:65 2019-01-16 13:25:03.469765: step 17102, loss = 0.40494 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:25:04.433190 ops/training.py:65 2019-01-16 13:25:04.433122: step 17103, loss = 0.38813 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:25:05.395788 ops/training.py:65 2019-01-16 13:25:05.395717: step 17104, loss = 0.30265 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:25:06.359195 ops/training.py:65 2019-01-16 13:25:06.359126: step 17105, loss = 0.30193 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:25:07.322018 ops/training.py:65 2019-01-16 13:25:07.321946: step 17106, loss = 0.42080 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:25:08.285141 ops/training.py:65 2019-01-16 13:25:08.285073: step 17107, loss = 0.44163 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:25:09.245894 ops/training.py:65 2019-01-16 13:25:09.245843: step 17108, loss = 0.37999 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:25:10.205483 ops/training.py:65 2019-01-16 13:25:10.205434: step 17109, loss = 0.41355 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:25:11.164556 ops/training.py:65 2019-01-16 13:25:11.164511: step 17110, loss = 0.37656 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:25:12.122977 ops/training.py:65 2019-01-16 13:25:12.122932: step 17111, loss = 0.34398 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:25:13.086641 ops/training.py:65 2019-01-16 13:25:13.086586: step 17112, loss = 0.39696 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:25:14.050198 ops/training.py:65 2019-01-16 13:25:14.050133: step 17113, loss = 0.44377 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:25:15.012968 ops/training.py:65 2019-01-16 13:25:15.012899: step 17114, loss = 0.36846 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:25:15.977800 ops/training.py:65 2019-01-16 13:25:15.977732: step 17115, loss = 0.48102 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:25:16.942662 ops/training.py:65 2019-01-16 13:25:16.942592: step 17116, loss = 0.39104 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:25:17.907275 ops/training.py:65 2019-01-16 13:25:17.907207: step 17117, loss = 0.26442 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:25:18.871736 ops/training.py:65 2019-01-16 13:25:18.871666: step 17118, loss = 0.34153 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:25:19.835358 ops/training.py:65 2019-01-16 13:25:19.835295: step 17119, loss = 0.33020 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:25:20.798515 ops/training.py:65 2019-01-16 13:25:20.798444: step 17120, loss = 0.54620 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:25:21.762090 ops/training.py:65 2019-01-16 13:25:21.762001: step 17121, loss = 0.30622 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:25:22.725645 ops/training.py:65 2019-01-16 13:25:22.725595: step 17122, loss = 0.58976 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:25:23.688942 ops/training.py:65 2019-01-16 13:25:23.688890: step 17123, loss = 0.31589 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:25:24.652373 ops/training.py:65 2019-01-16 13:25:24.652303: step 17124, loss = 0.45792 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:25:25.615496 ops/training.py:65 2019-01-16 13:25:25.615411: step 17125, loss = 0.47194 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:25:26.578814 ops/training.py:65 2019-01-16 13:25:26.578763: step 17126, loss = 0.23494 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:25:27.542601 ops/training.py:65 2019-01-16 13:25:27.542531: step 17127, loss = 0.37677 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:25:28.504865 ops/training.py:65 2019-01-16 13:25:28.504795: step 17128, loss = 0.48051 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:25:29.466376 ops/training.py:65 2019-01-16 13:25:29.466324: step 17129, loss = 0.39291 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:25:30.425802 ops/training.py:65 2019-01-16 13:25:30.425752: step 17130, loss = 0.35092 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:25:31.383615 ops/training.py:65 2019-01-16 13:25:31.383567: step 17131, loss = 0.35426 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:25:32.347062 ops/training.py:65 2019-01-16 13:25:32.347010: step 17132, loss = 0.33393 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:25:33.311016 ops/training.py:65 2019-01-16 13:25:33.310944: step 17133, loss = 0.33438 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:25:34.274358 ops/training.py:65 2019-01-16 13:25:34.274288: step 17134, loss = 0.46059 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:25:35.236434 ops/training.py:65 2019-01-16 13:25:35.236363: step 17135, loss = 0.45966 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:25:36.199749 ops/training.py:65 2019-01-16 13:25:36.199673: step 17136, loss = 0.35759 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:25:37.160834 ops/training.py:65 2019-01-16 13:25:37.160786: step 17137, loss = 0.35086 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:25:38.125691 ops/training.py:65 2019-01-16 13:25:38.125649: step 17138, loss = 0.43671 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:25:39.089004 ops/training.py:65 2019-01-16 13:25:39.088936: step 17139, loss = 0.57391 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 13:25:40.051940 ops/training.py:65 2019-01-16 13:25:40.051871: step 17140, loss = 0.48342 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:25:41.014738 ops/training.py:65 2019-01-16 13:25:41.014667: step 17141, loss = 0.37071 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:25:41.976505 ops/training.py:65 2019-01-16 13:25:41.976453: step 17142, loss = 0.39048 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:25:42.937748 ops/training.py:65 2019-01-16 13:25:42.937695: step 17143, loss = 0.38979 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:25:43.901084 ops/training.py:65 2019-01-16 13:25:43.901015: step 17144, loss = 0.24201 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:25:44.864207 ops/training.py:65 2019-01-16 13:25:44.864135: step 17145, loss = 0.40074 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:25:45.827683 ops/training.py:65 2019-01-16 13:25:45.827616: step 17146, loss = 0.47629 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:25:46.790739 ops/training.py:65 2019-01-16 13:25:46.790672: step 17147, loss = 0.31173 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:25:47.754127 ops/training.py:65 2019-01-16 13:25:47.754071: step 17148, loss = 0.36303 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:25:48.717269 ops/training.py:65 2019-01-16 13:25:48.717203: step 17149, loss = 0.39427 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:25:49.680289 ops/training.py:65 2019-01-16 13:25:49.680217: step 17150, loss = 0.31402 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:25:50.645988 ops/training.py:65 2019-01-16 13:25:50.645904: step 17151, loss = 0.61963 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:25:51.609885 ops/training.py:65 2019-01-16 13:25:51.609816: step 17152, loss = 0.34149 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:25:52.572574 ops/training.py:65 2019-01-16 13:25:52.572509: step 17153, loss = 0.44298 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:25:53.535869 ops/training.py:65 2019-01-16 13:25:53.535820: step 17154, loss = 0.50668 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:25:54.498714 ops/training.py:65 2019-01-16 13:25:54.498650: step 17155, loss = 0.30997 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:25:55.462162 ops/training.py:65 2019-01-16 13:25:55.462099: step 17156, loss = 0.36496 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:25:56.425657 ops/training.py:65 2019-01-16 13:25:56.425589: step 17157, loss = 0.31459 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:25:57.388351 ops/training.py:65 2019-01-16 13:25:57.388303: step 17158, loss = 0.43967 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:25:58.350106 ops/training.py:65 2019-01-16 13:25:58.350034: step 17159, loss = 0.32348 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:25:59.315016 ops/training.py:65 2019-01-16 13:25:59.314960: step 17160, loss = 0.41352 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:26:00.277742 ops/training.py:65 2019-01-16 13:26:00.277674: step 17161, loss = 0.42368 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:26:01.240452 ops/training.py:65 2019-01-16 13:26:01.240383: step 17162, loss = 0.43709 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:26:02.202831 ops/training.py:65 2019-01-16 13:26:02.202763: step 17163, loss = 0.40226 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:26:03.166125 ops/training.py:65 2019-01-16 13:26:03.166050: step 17164, loss = 0.40740 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:26:04.127650 ops/training.py:65 2019-01-16 13:26:04.127576: step 17165, loss = 0.39300 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:26:05.091716 ops/training.py:65 2019-01-16 13:26:05.091662: step 17166, loss = 0.30883 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:26:06.054283 ops/training.py:65 2019-01-16 13:26:06.054209: step 17167, loss = 0.36485 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:26:07.016378 ops/training.py:65 2019-01-16 13:26:07.016312: step 17168, loss = 0.28207 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:26:07.978609 ops/training.py:65 2019-01-16 13:26:07.978558: step 17169, loss = 0.42145 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:26:08.941331 ops/training.py:65 2019-01-16 13:26:08.941257: step 17170, loss = 0.43587 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:26:09.903912 ops/training.py:65 2019-01-16 13:26:09.903835: step 17171, loss = 0.38207 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:26:10.868021 ops/training.py:65 2019-01-16 13:26:10.867947: step 17172, loss = 0.26649 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:26:11.829934 ops/training.py:65 2019-01-16 13:26:11.829864: step 17173, loss = 0.27450 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:26:12.793331 ops/training.py:65 2019-01-16 13:26:12.793281: step 17174, loss = 0.30107 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:26:13.755793 ops/training.py:65 2019-01-16 13:26:13.755729: step 17175, loss = 0.30018 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:26:14.719307 ops/training.py:65 2019-01-16 13:26:14.719232: step 17176, loss = 0.24266 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:26:15.682718 ops/training.py:65 2019-01-16 13:26:15.682649: step 17177, loss = 0.28496 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:26:16.646035 ops/training.py:65 2019-01-16 13:26:16.645961: step 17178, loss = 0.42510 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:26:17.609100 ops/training.py:65 2019-01-16 13:26:17.609029: step 17179, loss = 0.44295 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:26:18.569764 ops/training.py:65 2019-01-16 13:26:18.569688: step 17180, loss = 0.44536 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:26:19.529608 ops/training.py:65 2019-01-16 13:26:19.529541: step 17181, loss = 0.33634 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:26:20.488786 ops/training.py:65 2019-01-16 13:26:20.488735: step 17182, loss = 0.39581 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:26:21.446028 ops/training.py:65 2019-01-16 13:26:21.445981: step 17183, loss = 0.36278 (33.5 examples/sec; 0.956 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:26:22.407630 ops/training.py:65 2019-01-16 13:26:22.407583: step 17184, loss = 0.26866 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:26:23.370483 ops/training.py:65 2019-01-16 13:26:23.370412: step 17185, loss = 0.36074 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:26:24.331703 ops/training.py:65 2019-01-16 13:26:24.331661: step 17186, loss = 0.35287 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:26:25.290234 ops/training.py:65 2019-01-16 13:26:25.290193: step 17187, loss = 0.35229 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:26:26.248763 ops/training.py:65 2019-01-16 13:26:26.248713: step 17188, loss = 0.43924 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:26:27.207751 ops/training.py:65 2019-01-16 13:26:27.207702: step 17189, loss = 0.43844 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:26:28.170209 ops/training.py:65 2019-01-16 13:26:28.170165: step 17190, loss = 0.38302 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:26:29.133247 ops/training.py:65 2019-01-16 13:26:29.133175: step 17191, loss = 0.37910 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:26:30.096146 ops/training.py:65 2019-01-16 13:26:30.096077: step 17192, loss = 0.42237 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:26:31.058942 ops/training.py:65 2019-01-16 13:26:31.058891: step 17193, loss = 0.39247 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:26:32.021375 ops/training.py:65 2019-01-16 13:26:32.021326: step 17194, loss = 0.30043 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:26:32.985657 ops/training.py:65 2019-01-16 13:26:32.985585: step 17195, loss = 0.35200 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:26:33.948020 ops/training.py:65 2019-01-16 13:26:33.947948: step 17196, loss = 0.48971 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:26:34.911338 ops/training.py:65 2019-01-16 13:26:34.911268: step 17197, loss = 0.30414 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:26:35.873352 ops/training.py:65 2019-01-16 13:26:35.873280: step 17198, loss = 0.34621 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:26:36.835463 ops/training.py:65 2019-01-16 13:26:36.835394: step 17199, loss = 0.41576 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:26:37.797823 ops/training.py:65 2019-01-16 13:26:37.797750: step 17200, loss = 0.30971 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:26:38.760226 ops/training.py:65 2019-01-16 13:26:38.760176: step 17201, loss = 0.40670 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:26:39.722388 ops/training.py:65 2019-01-16 13:26:39.722323: step 17202, loss = 0.43353 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:26:40.684518 ops/training.py:65 2019-01-16 13:26:40.684466: step 17203, loss = 0.30501 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:26:41.645911 ops/training.py:65 2019-01-16 13:26:41.645840: step 17204, loss = 0.30387 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:26:42.607014 ops/training.py:65 2019-01-16 13:26:42.606961: step 17205, loss = 0.36554 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:26:43.570278 ops/training.py:65 2019-01-16 13:26:43.570206: step 17206, loss = 0.34133 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:26:44.531447 ops/training.py:65 2019-01-16 13:26:44.531373: step 17207, loss = 0.39920 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:26:45.491874 ops/training.py:65 2019-01-16 13:26:45.491824: step 17208, loss = 0.41316 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:26:46.450278 ops/training.py:65 2019-01-16 13:26:46.450230: step 17209, loss = 0.35060 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:26:47.412831 ops/training.py:65 2019-01-16 13:26:47.412784: step 17210, loss = 0.42963 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:26:48.375798 ops/training.py:65 2019-01-16 13:26:48.375746: step 17211, loss = 0.40444 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:26:49.339013 ops/training.py:65 2019-01-16 13:26:49.338947: step 17212, loss = 0.33475 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:26:50.299531 ops/training.py:65 2019-01-16 13:26:50.299479: step 17213, loss = 0.33867 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:26:51.257837 ops/training.py:65 2019-01-16 13:26:51.257794: step 17214, loss = 0.27762 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:26:52.217237 ops/training.py:65 2019-01-16 13:26:52.217188: step 17215, loss = 0.35433 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:26:53.175519 ops/training.py:65 2019-01-16 13:26:53.175480: step 17216, loss = 0.37692 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:26:54.133675 ops/training.py:65 2019-01-16 13:26:54.133628: step 17217, loss = 0.32144 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:26:55.091714 ops/training.py:65 2019-01-16 13:26:55.091667: step 17218, loss = 0.25780 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:26:56.053644 ops/training.py:65 2019-01-16 13:26:56.053587: step 17219, loss = 0.28850 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:26:57.016548 ops/training.py:65 2019-01-16 13:26:57.016480: step 17220, loss = 0.32345 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:26:57.978225 ops/training.py:65 2019-01-16 13:26:57.978174: step 17221, loss = 0.30362 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:26:58.940867 ops/training.py:65 2019-01-16 13:26:58.940799: step 17222, loss = 0.37060 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:26:59.903132 ops/training.py:65 2019-01-16 13:26:59.903069: step 17223, loss = 0.28331 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:27:00.864628 ops/training.py:65 2019-01-16 13:27:00.864560: step 17224, loss = 0.48087 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:27:01.825560 ops/training.py:65 2019-01-16 13:27:01.825494: step 17225, loss = 0.39655 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:27:02.786863 ops/training.py:65 2019-01-16 13:27:02.786802: step 17226, loss = 0.23741 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:27:03.749016 ops/training.py:65 2019-01-16 13:27:03.748945: step 17227, loss = 0.40359 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:27:04.710970 ops/training.py:65 2019-01-16 13:27:04.710898: step 17228, loss = 0.34252 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:27:05.672200 ops/training.py:65 2019-01-16 13:27:05.672128: step 17229, loss = 0.49374 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:27:06.633286 ops/training.py:65 2019-01-16 13:27:06.633211: step 17230, loss = 0.22002 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:27:07.595650 ops/training.py:65 2019-01-16 13:27:07.595576: step 17231, loss = 0.49509 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:27:08.557273 ops/training.py:65 2019-01-16 13:27:08.557231: step 17232, loss = 0.25860 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:27:09.519515 ops/training.py:65 2019-01-16 13:27:09.519464: step 17233, loss = 0.30658 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:27:10.482671 ops/training.py:65 2019-01-16 13:27:10.482596: step 17234, loss = 0.26649 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:27:11.444396 ops/training.py:65 2019-01-16 13:27:11.444326: step 17235, loss = 0.42161 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:27:12.407384 ops/training.py:65 2019-01-16 13:27:12.407329: step 17236, loss = 0.41151 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:27:13.369905 ops/training.py:65 2019-01-16 13:27:13.369855: step 17237, loss = 0.23819 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:27:14.331533 ops/training.py:65 2019-01-16 13:27:14.331468: step 17238, loss = 0.35059 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:27:15.292643 ops/training.py:65 2019-01-16 13:27:15.292575: step 17239, loss = 0.31022 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:27:16.255026 ops/training.py:65 2019-01-16 13:27:16.254952: step 17240, loss = 0.36860 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:27:17.217870 ops/training.py:65 2019-01-16 13:27:17.217799: step 17241, loss = 0.38068 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:27:18.180125 ops/training.py:65 2019-01-16 13:27:18.180052: step 17242, loss = 0.41296 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:27:19.142186 ops/training.py:65 2019-01-16 13:27:19.142099: step 17243, loss = 0.26235 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:27:20.104608 ops/training.py:65 2019-01-16 13:27:20.104543: step 17244, loss = 0.29151 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:27:21.067271 ops/training.py:65 2019-01-16 13:27:21.067199: step 17245, loss = 0.40502 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:27:22.029068 ops/training.py:65 2019-01-16 13:27:22.028993: step 17246, loss = 0.40166 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:27:22.990707 ops/training.py:65 2019-01-16 13:27:22.990655: step 17247, loss = 0.40012 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:27:23.953808 ops/training.py:65 2019-01-16 13:27:23.953742: step 17248, loss = 0.34044 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:27:24.916568 ops/training.py:65 2019-01-16 13:27:24.916519: step 17249, loss = 0.41569 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:27:25.877853 ops/training.py:65 2019-01-16 13:27:25.877786: step 17250, loss = 0.35225 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:27:26.839600 ops/training.py:65 2019-01-16 13:27:26.839527: step 17251, loss = 0.33283 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:27:27.801163 ops/training.py:65 2019-01-16 13:27:27.801089: step 17252, loss = 0.35647 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:27:28.762224 ops/training.py:65 2019-01-16 13:27:28.762175: step 17253, loss = 0.36316 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:27:29.722003 ops/training.py:65 2019-01-16 13:27:29.721957: step 17254, loss = 0.30607 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:27:30.685890 ops/training.py:65 2019-01-16 13:27:30.685845: step 17255, loss = 0.33093 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:27:31.649367 ops/training.py:65 2019-01-16 13:27:31.649293: step 17256, loss = 0.38732 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:27:32.610917 ops/training.py:65 2019-01-16 13:27:32.610842: step 17257, loss = 0.38033 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:27:33.572722 ops/training.py:65 2019-01-16 13:27:33.572678: step 17258, loss = 0.41379 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:27:34.531071 ops/training.py:65 2019-01-16 13:27:34.531024: step 17259, loss = 0.46911 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:27:35.489043 ops/training.py:65 2019-01-16 13:27:35.488996: step 17260, loss = 0.36486 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:27:36.448363 ops/training.py:65 2019-01-16 13:27:36.448315: step 17261, loss = 0.32834 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:27:37.411792 ops/training.py:65 2019-01-16 13:27:37.411749: step 17262, loss = 0.32289 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:27:38.374591 ops/training.py:65 2019-01-16 13:27:38.374542: step 17263, loss = 0.35005 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:27:39.334704 ops/training.py:65 2019-01-16 13:27:39.334664: step 17264, loss = 0.31898 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:27:40.296857 ops/training.py:65 2019-01-16 13:27:40.296786: step 17265, loss = 0.27197 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:27:41.258210 ops/training.py:65 2019-01-16 13:27:41.258137: step 17266, loss = 0.32582 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:27:42.220171 ops/training.py:65 2019-01-16 13:27:42.220115: step 17267, loss = 0.37016 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:27:43.181936 ops/training.py:65 2019-01-16 13:27:43.181862: step 17268, loss = 0.49504 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:27:44.145203 ops/training.py:65 2019-01-16 13:27:44.145127: step 17269, loss = 0.55307 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:27:45.108172 ops/training.py:65 2019-01-16 13:27:45.108125: step 17270, loss = 0.23318 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:27:46.069876 ops/training.py:65 2019-01-16 13:27:46.069804: step 17271, loss = 0.35278 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:27:47.031573 ops/training.py:65 2019-01-16 13:27:47.031500: step 17272, loss = 0.45199 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:27:47.993950 ops/training.py:65 2019-01-16 13:27:47.993896: step 17273, loss = 0.26234 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:27:48.955922 ops/training.py:65 2019-01-16 13:27:48.955847: step 17274, loss = 0.36335 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:27:49.918034 ops/training.py:65 2019-01-16 13:27:49.917965: step 17275, loss = 0.37465 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:27:50.879786 ops/training.py:65 2019-01-16 13:27:50.879711: step 17276, loss = 0.34525 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:27:51.841302 ops/training.py:65 2019-01-16 13:27:51.841225: step 17277, loss = 0.42390 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:27:52.803721 ops/training.py:65 2019-01-16 13:27:52.803670: step 17278, loss = 0.31535 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:27:53.765281 ops/training.py:65 2019-01-16 13:27:53.765208: step 17279, loss = 0.37584 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:27:54.727711 ops/training.py:65 2019-01-16 13:27:54.727662: step 17280, loss = 0.33240 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:27:55.690655 ops/training.py:65 2019-01-16 13:27:55.690587: step 17281, loss = 0.36991 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:27:56.652487 ops/training.py:65 2019-01-16 13:27:56.652418: step 17282, loss = 0.40701 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:27:57.613403 ops/training.py:65 2019-01-16 13:27:57.613334: step 17283, loss = 0.37709 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:27:58.576252 ops/training.py:65 2019-01-16 13:27:58.576180: step 17284, loss = 0.37234 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:27:59.538441 ops/training.py:65 2019-01-16 13:27:59.538372: step 17285, loss = 0.37226 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:28:00.500399 ops/training.py:65 2019-01-16 13:28:00.500350: step 17286, loss = 0.24786 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:28:01.461783 ops/training.py:65 2019-01-16 13:28:01.461713: step 17287, loss = 0.50504 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 13:28:02.424924 ops/training.py:65 2019-01-16 13:28:02.424878: step 17288, loss = 0.45063 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:28:03.387151 ops/training.py:65 2019-01-16 13:28:03.387079: step 17289, loss = 0.40720 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:28:04.349559 ops/training.py:65 2019-01-16 13:28:04.349490: step 17290, loss = 0.44706 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:28:05.310808 ops/training.py:65 2019-01-16 13:28:05.310742: step 17291, loss = 0.37775 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:28:06.272124 ops/training.py:65 2019-01-16 13:28:06.272053: step 17292, loss = 0.32468 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:28:07.233874 ops/training.py:65 2019-01-16 13:28:07.233824: step 17293, loss = 0.61240 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:28:08.196688 ops/training.py:65 2019-01-16 13:28:08.196614: step 17294, loss = 0.65971 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 13:28:09.157775 ops/training.py:65 2019-01-16 13:28:09.157704: step 17295, loss = 0.34731 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:28:10.118199 ops/training.py:65 2019-01-16 13:28:10.118126: step 17296, loss = 0.32948 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:28:11.079636 ops/training.py:65 2019-01-16 13:28:11.079569: step 17297, loss = 0.34918 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:28:12.039995 ops/training.py:65 2019-01-16 13:28:12.039918: step 17298, loss = 0.40684 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:28:13.001491 ops/training.py:65 2019-01-16 13:28:13.001437: step 17299, loss = 0.41471 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:28:13.964397 ops/training.py:65 2019-01-16 13:28:13.964327: step 17300, loss = 0.41586 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:28:14.925975 ops/training.py:65 2019-01-16 13:28:14.925925: step 17301, loss = 0.41052 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:28:15.885632 ops/training.py:65 2019-01-16 13:28:15.885582: step 17302, loss = 0.28321 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:28:16.843812 ops/training.py:65 2019-01-16 13:28:16.843769: step 17303, loss = 0.39995 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:28:17.802786 ops/training.py:65 2019-01-16 13:28:17.802740: step 17304, loss = 0.39899 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:28:18.762238 ops/training.py:65 2019-01-16 13:28:18.762191: step 17305, loss = 0.31880 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:28:19.724927 ops/training.py:65 2019-01-16 13:28:19.724881: step 17306, loss = 0.24031 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:28:20.688039 ops/training.py:65 2019-01-16 13:28:20.687966: step 17307, loss = 0.42846 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:28:21.650894 ops/training.py:65 2019-01-16 13:28:21.650837: step 17308, loss = 0.41291 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:28:22.613963 ops/training.py:65 2019-01-16 13:28:22.613908: step 17309, loss = 0.45864 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:28:23.574636 ops/training.py:65 2019-01-16 13:28:23.574586: step 17310, loss = 0.33567 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:28:24.537403 ops/training.py:65 2019-01-16 13:28:24.537359: step 17311, loss = 0.28956 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:28:25.500396 ops/training.py:65 2019-01-16 13:28:25.500326: step 17312, loss = 0.40301 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:28:26.462638 ops/training.py:65 2019-01-16 13:28:26.462585: step 17313, loss = 0.33063 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:28:27.424151 ops/training.py:65 2019-01-16 13:28:27.424080: step 17314, loss = 0.29309 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:28:28.386983 ops/training.py:65 2019-01-16 13:28:28.386912: step 17315, loss = 0.45759 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:28:29.349588 ops/training.py:65 2019-01-16 13:28:29.349522: step 17316, loss = 0.43618 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:28:30.311976 ops/training.py:65 2019-01-16 13:28:30.311907: step 17317, loss = 0.26506 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:28:31.274009 ops/training.py:65 2019-01-16 13:28:31.273937: step 17318, loss = 0.35782 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:28:32.235994 ops/training.py:65 2019-01-16 13:28:32.235922: step 17319, loss = 0.32304 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:28:33.198070 ops/training.py:65 2019-01-16 13:28:33.198007: step 17320, loss = 0.35742 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:28:34.159729 ops/training.py:65 2019-01-16 13:28:34.159682: step 17321, loss = 0.30554 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:28:35.118851 ops/training.py:65 2019-01-16 13:28:35.118804: step 17322, loss = 0.25190 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:28:36.078757 ops/training.py:65 2019-01-16 13:28:36.078703: step 17323, loss = 0.50355 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:28:37.037522 ops/training.py:65 2019-01-16 13:28:37.037475: step 17324, loss = 0.33274 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:28:38.002079 ops/training.py:65 2019-01-16 13:28:38.002024: step 17325, loss = 0.34200 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:28:38.964486 ops/training.py:65 2019-01-16 13:28:38.964433: step 17326, loss = 0.45544 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:28:39.925654 ops/training.py:65 2019-01-16 13:28:39.925606: step 17327, loss = 0.33374 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:28:40.892734 ops/training.py:65 2019-01-16 13:28:40.892688: step 17328, loss = 0.18187 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:28:41.854934 ops/training.py:65 2019-01-16 13:28:41.854883: step 17329, loss = 0.24816 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:28:42.816759 ops/training.py:65 2019-01-16 13:28:42.816705: step 17330, loss = 0.33147 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:28:43.777255 ops/training.py:65 2019-01-16 13:28:43.777181: step 17331, loss = 0.28405 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:28:44.737821 ops/training.py:65 2019-01-16 13:28:44.737771: step 17332, loss = 0.47816 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:28:45.695709 ops/training.py:65 2019-01-16 13:28:45.695663: step 17333, loss = 0.43320 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:28:46.653515 ops/training.py:65 2019-01-16 13:28:46.653466: step 17334, loss = 0.32441 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:28:47.610648 ops/training.py:65 2019-01-16 13:28:47.610605: step 17335, loss = 0.32375 (33.5 examples/sec; 0.956 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:28:48.568591 ops/training.py:65 2019-01-16 13:28:48.568541: step 17336, loss = 0.32777 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:28:49.532281 ops/training.py:65 2019-01-16 13:28:49.532240: step 17337, loss = 0.30432 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:28:50.495712 ops/training.py:65 2019-01-16 13:28:50.495632: step 17338, loss = 0.24608 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:28:51.457659 ops/training.py:65 2019-01-16 13:28:51.457611: step 17339, loss = 0.45387 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:28:52.418508 ops/training.py:65 2019-01-16 13:28:52.418460: step 17340, loss = 0.44791 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:28:53.379222 ops/training.py:65 2019-01-16 13:28:53.379149: step 17341, loss = 0.28607 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:28:54.344737 ops/training.py:65 2019-01-16 13:28:54.344685: step 17342, loss = 0.36594 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:28:55.309342 ops/training.py:65 2019-01-16 13:28:55.309292: step 17343, loss = 0.41521 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:28:56.271588 ops/training.py:65 2019-01-16 13:28:56.271535: step 17344, loss = 0.41703 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:28:57.233690 ops/training.py:65 2019-01-16 13:28:57.233642: step 17345, loss = 0.27995 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:28:58.194186 ops/training.py:65 2019-01-16 13:28:58.194130: step 17346, loss = 0.37081 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:28:59.154203 ops/training.py:65 2019-01-16 13:28:59.154145: step 17347, loss = 0.31204 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:29:00.119906 ops/training.py:65 2019-01-16 13:29:00.119855: step 17348, loss = 0.54407 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:29:01.085145 ops/training.py:65 2019-01-16 13:29:01.085093: step 17349, loss = 0.41390 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:29:02.048468 ops/training.py:65 2019-01-16 13:29:02.048414: step 17350, loss = 0.54022 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:29:03.009607 ops/training.py:65 2019-01-16 13:29:03.009546: step 17351, loss = 0.29908 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:29:03.975639 ops/training.py:65 2019-01-16 13:29:03.975592: step 17352, loss = 0.49785 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:29:04.940866 ops/training.py:65 2019-01-16 13:29:04.940829: step 17353, loss = 0.34200 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:29:05.903998 ops/training.py:65 2019-01-16 13:29:05.903936: step 17354, loss = 0.42822 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:29:06.866466 ops/training.py:65 2019-01-16 13:29:06.866400: step 17355, loss = 0.46462 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:29:07.827141 ops/training.py:65 2019-01-16 13:29:07.827076: step 17356, loss = 0.36001 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:29:08.789502 ops/training.py:65 2019-01-16 13:29:08.789440: step 17357, loss = 0.26987 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:29:09.751287 ops/training.py:65 2019-01-16 13:29:09.751234: step 17358, loss = 0.39860 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:29:10.712542 ops/training.py:65 2019-01-16 13:29:10.712483: step 17359, loss = 0.50517 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:29:11.673834 ops/training.py:65 2019-01-16 13:29:11.673777: step 17360, loss = 0.45899 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:29:12.635997 ops/training.py:65 2019-01-16 13:29:12.635948: step 17361, loss = 0.27727 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:29:13.598082 ops/training.py:65 2019-01-16 13:29:13.598026: step 17362, loss = 0.54155 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:29:14.557616 ops/training.py:65 2019-01-16 13:29:14.557549: step 17363, loss = 0.39148 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:29:15.517744 ops/training.py:65 2019-01-16 13:29:15.517683: step 17364, loss = 0.49652 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:29:16.484039 ops/training.py:65 2019-01-16 13:29:16.483985: step 17365, loss = 0.38962 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:29:17.448310 ops/training.py:65 2019-01-16 13:29:17.448254: step 17366, loss = 0.35970 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:29:18.411398 ops/training.py:65 2019-01-16 13:29:18.411350: step 17367, loss = 0.35681 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:29:19.374799 ops/training.py:65 2019-01-16 13:29:19.374755: step 17368, loss = 0.33495 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:29:20.337564 ops/training.py:65 2019-01-16 13:29:20.337517: step 17369, loss = 0.32456 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:29:21.299497 ops/training.py:65 2019-01-16 13:29:21.299454: step 17370, loss = 0.34462 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:29:22.261672 ops/training.py:65 2019-01-16 13:29:22.261637: step 17371, loss = 0.33189 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:29:23.221128 ops/training.py:65 2019-01-16 13:29:23.221049: step 17372, loss = 0.47029 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:29:24.181335 ops/training.py:65 2019-01-16 13:29:24.181284: step 17373, loss = 0.45048 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:29:25.139492 ops/training.py:65 2019-01-16 13:29:25.139439: step 17374, loss = 0.53570 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:29:26.098674 ops/training.py:65 2019-01-16 13:29:26.098615: step 17375, loss = 0.34848 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:29:27.058949 ops/training.py:65 2019-01-16 13:29:27.058864: step 17376, loss = 0.26013 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:29:28.021075 ops/training.py:65 2019-01-16 13:29:28.021015: step 17377, loss = 0.30136 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:29:28.982442 ops/training.py:65 2019-01-16 13:29:28.982366: step 17378, loss = 0.36082 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:29:29.945444 ops/training.py:65 2019-01-16 13:29:29.945374: step 17379, loss = 0.30443 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:29:30.908597 ops/training.py:65 2019-01-16 13:29:30.908523: step 17380, loss = 0.29135 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:29:31.872431 ops/training.py:65 2019-01-16 13:29:31.872362: step 17381, loss = 0.36390 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:29:32.836061 ops/training.py:65 2019-01-16 13:29:32.835987: step 17382, loss = 0.54312 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:29:33.795248 ops/training.py:65 2019-01-16 13:29:33.795181: step 17383, loss = 0.33205 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:29:34.760365 ops/training.py:65 2019-01-16 13:29:34.760325: step 17384, loss = 0.32249 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:29:35.722548 ops/training.py:65 2019-01-16 13:29:35.722495: step 17385, loss = 0.22512 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:29:36.685612 ops/training.py:65 2019-01-16 13:29:36.685539: step 17386, loss = 0.28549 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:29:37.647473 ops/training.py:65 2019-01-16 13:29:37.647425: step 17387, loss = 0.29754 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:29:38.608589 ops/training.py:65 2019-01-16 13:29:38.608546: step 17388, loss = 0.28258 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:29:39.568063 ops/training.py:65 2019-01-16 13:29:39.567991: step 17389, loss = 0.36549 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:29:40.527583 ops/training.py:65 2019-01-16 13:29:40.527524: step 17390, loss = 0.45150 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:29:41.486684 ops/training.py:65 2019-01-16 13:29:41.486619: step 17391, loss = 0.37981 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:29:42.451269 ops/training.py:65 2019-01-16 13:29:42.451219: step 17392, loss = 0.25293 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:29:43.415135 ops/training.py:65 2019-01-16 13:29:43.415070: step 17393, loss = 0.38660 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:29:44.375280 ops/training.py:65 2019-01-16 13:29:44.375208: step 17394, loss = 0.53427 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:29:45.335716 ops/training.py:65 2019-01-16 13:29:45.335653: step 17395, loss = 0.45839 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:29:46.295654 ops/training.py:65 2019-01-16 13:29:46.295591: step 17396, loss = 0.31010 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:29:47.255751 ops/training.py:65 2019-01-16 13:29:47.255684: step 17397, loss = 0.41088 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:29:48.216570 ops/training.py:65 2019-01-16 13:29:48.216510: step 17398, loss = 0.38574 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:29:49.180055 ops/training.py:65 2019-01-16 13:29:49.180004: step 17399, loss = 0.36987 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:29:50.145029 ops/training.py:65 2019-01-16 13:29:50.144962: step 17400, loss = 0.32511 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:29:51.108103 ops/training.py:65 2019-01-16 13:29:51.108034: step 17401, loss = 0.40719 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:29:52.069443 ops/training.py:65 2019-01-16 13:29:52.069369: step 17402, loss = 0.21763 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:29:53.031360 ops/training.py:65 2019-01-16 13:29:53.031294: step 17403, loss = 0.35745 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:29:53.992280 ops/training.py:65 2019-01-16 13:29:53.992190: step 17404, loss = 0.39730 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:29:54.957728 ops/training.py:65 2019-01-16 13:29:54.957651: step 17405, loss = 0.34695 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:29:55.922005 ops/training.py:65 2019-01-16 13:29:55.921935: step 17406, loss = 0.34345 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:29:56.886118 ops/training.py:65 2019-01-16 13:29:56.886047: step 17407, loss = 0.31155 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:29:57.848090 ops/training.py:65 2019-01-16 13:29:57.848015: step 17408, loss = 0.46543 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:29:58.810827 ops/training.py:65 2019-01-16 13:29:58.810755: step 17409, loss = 0.34205 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:29:59.774008 ops/training.py:65 2019-01-16 13:29:59.773932: step 17410, loss = 0.43693 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:30:00.736056 ops/training.py:65 2019-01-16 13:30:00.735983: step 17411, loss = 0.38983 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:30:01.698524 ops/training.py:65 2019-01-16 13:30:01.698449: step 17412, loss = 0.36747 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:30:02.660716 ops/training.py:65 2019-01-16 13:30:02.660640: step 17413, loss = 0.42449 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:30:03.622273 ops/training.py:65 2019-01-16 13:30:03.622198: step 17414, loss = 0.51449 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:30:04.584698 ops/training.py:65 2019-01-16 13:30:04.584628: step 17415, loss = 0.30150 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:30:05.547194 ops/training.py:65 2019-01-16 13:30:05.547123: step 17416, loss = 0.34814 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:30:06.508943 ops/training.py:65 2019-01-16 13:30:06.508862: step 17417, loss = 0.41704 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:30:07.470653 ops/training.py:65 2019-01-16 13:30:07.470576: step 17418, loss = 0.34124 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:30:08.433647 ops/training.py:65 2019-01-16 13:30:08.433610: step 17419, loss = 0.37198 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:30:09.395996 ops/training.py:65 2019-01-16 13:30:09.395938: step 17420, loss = 0.51631 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:30:10.357831 ops/training.py:65 2019-01-16 13:30:10.357764: step 17421, loss = 0.29325 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:30:11.326145 ops/training.py:65 2019-01-16 13:30:11.326110: step 17422, loss = 0.41355 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:30:12.288396 ops/training.py:65 2019-01-16 13:30:12.288353: step 17423, loss = 0.31731 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:30:13.250064 ops/training.py:65 2019-01-16 13:30:13.249999: step 17424, loss = 0.28363 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:30:14.211905 ops/training.py:65 2019-01-16 13:30:14.211836: step 17425, loss = 0.43464 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:30:15.173889 ops/training.py:65 2019-01-16 13:30:15.173812: step 17426, loss = 0.28786 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:30:16.137330 ops/training.py:65 2019-01-16 13:30:16.137275: step 17427, loss = 0.41282 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:30:17.099652 ops/training.py:65 2019-01-16 13:30:17.099620: step 17428, loss = 0.28628 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:30:18.061835 ops/training.py:65 2019-01-16 13:30:18.061804: step 17429, loss = 0.36132 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:30:19.024133 ops/training.py:65 2019-01-16 13:30:19.024104: step 17430, loss = 0.43416 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:30:19.986127 ops/training.py:65 2019-01-16 13:30:19.986099: step 17431, loss = 0.39925 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:30:20.949664 ops/training.py:65 2019-01-16 13:30:20.949632: step 17432, loss = 0.33885 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:30:21.913182 ops/training.py:65 2019-01-16 13:30:21.913104: step 17433, loss = 0.39375 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:30:22.874314 ops/training.py:65 2019-01-16 13:30:22.874232: step 17434, loss = 0.38280 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:30:23.840744 ops/training.py:65 2019-01-16 13:30:23.840689: step 17435, loss = 0.36527 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:30:24.804726 ops/training.py:65 2019-01-16 13:30:24.804647: step 17436, loss = 0.36645 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:30:25.764741 ops/training.py:65 2019-01-16 13:30:25.764660: step 17437, loss = 0.36149 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:30:26.729845 ops/training.py:65 2019-01-16 13:30:26.729762: step 17438, loss = 0.38059 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:30:27.690907 ops/training.py:65 2019-01-16 13:30:27.690827: step 17439, loss = 0.47598 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:30:28.651387 ops/training.py:65 2019-01-16 13:30:28.651300: step 17440, loss = 0.41957 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:30:29.614695 ops/training.py:65 2019-01-16 13:30:29.614614: step 17441, loss = 0.28441 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:30:30.576056 ops/training.py:65 2019-01-16 13:30:30.575974: step 17442, loss = 0.47760 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:30:31.539701 ops/training.py:65 2019-01-16 13:30:31.539619: step 17443, loss = 0.54681 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:30:32.501050 ops/training.py:65 2019-01-16 13:30:32.500972: step 17444, loss = 0.43616 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:30:33.461948 ops/training.py:65 2019-01-16 13:30:33.461866: step 17445, loss = 0.33415 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:30:34.421996 ops/training.py:65 2019-01-16 13:30:34.421921: step 17446, loss = 0.43840 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:30:35.385715 ops/training.py:65 2019-01-16 13:30:35.385633: step 17447, loss = 0.27842 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:30:36.347941 ops/training.py:65 2019-01-16 13:30:36.347879: step 17448, loss = 0.39475 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:30:37.308283 ops/training.py:65 2019-01-16 13:30:37.308206: step 17449, loss = 0.40438 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:30:38.268504 ops/training.py:65 2019-01-16 13:30:38.268423: step 17450, loss = 0.25108 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:30:39.232831 ops/training.py:65 2019-01-16 13:30:39.232756: step 17451, loss = 0.45173 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:30:40.195269 ops/training.py:65 2019-01-16 13:30:40.195189: step 17452, loss = 0.66724 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.5625
I0832 2019-01-16 13:30:41.156663 ops/training.py:65 2019-01-16 13:30:41.156585: step 17453, loss = 0.23041 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:30:42.117584 ops/training.py:65 2019-01-16 13:30:42.117480: step 17454, loss = 0.45681 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:30:43.081589 ops/training.py:65 2019-01-16 13:30:43.081510: step 17455, loss = 0.37935 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:30:44.042829 ops/training.py:65 2019-01-16 13:30:44.042751: step 17456, loss = 0.36393 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:30:45.002421 ops/training.py:65 2019-01-16 13:30:45.002344: step 17457, loss = 0.41474 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:30:45.962594 ops/training.py:65 2019-01-16 13:30:45.962517: step 17458, loss = 0.45058 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:30:46.923337 ops/training.py:65 2019-01-16 13:30:46.923257: step 17459, loss = 0.35888 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:30:47.883265 ops/training.py:65 2019-01-16 13:30:47.883186: step 17460, loss = 0.39918 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:30:48.843386 ops/training.py:65 2019-01-16 13:30:48.843308: step 17461, loss = 0.25433 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:30:49.803471 ops/training.py:65 2019-01-16 13:30:49.803395: step 17462, loss = 0.31776 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:30:50.763485 ops/training.py:65 2019-01-16 13:30:50.763403: step 17463, loss = 0.31561 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:30:51.727490 ops/training.py:65 2019-01-16 13:30:51.727417: step 17464, loss = 0.36017 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:30:52.688760 ops/training.py:65 2019-01-16 13:30:52.688676: step 17465, loss = 0.38096 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:30:53.650236 ops/training.py:65 2019-01-16 13:30:53.650156: step 17466, loss = 0.54781 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:30:54.611380 ops/training.py:65 2019-01-16 13:30:54.611299: step 17467, loss = 0.32971 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:30:55.572576 ops/training.py:65 2019-01-16 13:30:55.572498: step 17468, loss = 0.45283 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:30:56.534179 ops/training.py:65 2019-01-16 13:30:56.534098: step 17469, loss = 0.24294 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:30:57.494571 ops/training.py:65 2019-01-16 13:30:57.494501: step 17470, loss = 0.39930 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:30:58.455367 ops/training.py:65 2019-01-16 13:30:58.455293: step 17471, loss = 0.33158 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:30:59.417418 ops/training.py:65 2019-01-16 13:30:59.417339: step 17472, loss = 0.33955 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:31:00.378387 ops/training.py:65 2019-01-16 13:31:00.378308: step 17473, loss = 0.22443 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:31:01.338910 ops/training.py:65 2019-01-16 13:31:01.338827: step 17474, loss = 0.31068 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:31:02.299913 ops/training.py:65 2019-01-16 13:31:02.299833: step 17475, loss = 0.37713 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:31:03.260497 ops/training.py:65 2019-01-16 13:31:03.260425: step 17476, loss = 0.29028 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:31:04.221983 ops/training.py:65 2019-01-16 13:31:04.221903: step 17477, loss = 0.30182 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:31:05.183410 ops/training.py:65 2019-01-16 13:31:05.183329: step 17478, loss = 0.34830 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:31:06.143667 ops/training.py:65 2019-01-16 13:31:06.143585: step 17479, loss = 0.35883 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:31:07.104839 ops/training.py:65 2019-01-16 13:31:07.104759: step 17480, loss = 0.39195 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:31:08.066230 ops/training.py:65 2019-01-16 13:31:08.066149: step 17481, loss = 0.42218 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:31:09.027218 ops/training.py:65 2019-01-16 13:31:09.027139: step 17482, loss = 0.24804 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:31:09.987437 ops/training.py:65 2019-01-16 13:31:09.987359: step 17483, loss = 0.51518 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:31:10.947231 ops/training.py:65 2019-01-16 13:31:10.947156: step 17484, loss = 0.49011 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:31:11.911137 ops/training.py:65 2019-01-16 13:31:11.911060: step 17485, loss = 0.41697 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:31:12.872373 ops/training.py:65 2019-01-16 13:31:12.872307: step 17486, loss = 0.40032 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:31:13.833102 ops/training.py:65 2019-01-16 13:31:13.833022: step 17487, loss = 0.42137 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:31:14.793326 ops/training.py:65 2019-01-16 13:31:14.793248: step 17488, loss = 0.41685 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:31:15.754176 ops/training.py:65 2019-01-16 13:31:15.754090: step 17489, loss = 0.37043 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:31:16.720013 ops/training.py:65 2019-01-16 13:31:16.719946: step 17490, loss = 0.24552 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:31:17.683718 ops/training.py:65 2019-01-16 13:31:17.683663: step 17491, loss = 0.37014 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:31:18.646728 ops/training.py:65 2019-01-16 13:31:18.646682: step 17492, loss = 0.23846 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:31:19.607453 ops/training.py:65 2019-01-16 13:31:19.607369: step 17493, loss = 0.33408 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:31:20.569008 ops/training.py:65 2019-01-16 13:31:20.568925: step 17494, loss = 0.48646 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:31:21.530620 ops/training.py:65 2019-01-16 13:31:21.530540: step 17495, loss = 0.22604 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:31:22.491899 ops/training.py:65 2019-01-16 13:31:22.491816: step 17496, loss = 0.29617 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:31:23.451348 ops/training.py:65 2019-01-16 13:31:23.451265: step 17497, loss = 0.39416 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:31:24.411901 ops/training.py:65 2019-01-16 13:31:24.411815: step 17498, loss = 0.33688 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:31:25.377335 ops/training.py:65 2019-01-16 13:31:25.377275: step 17499, loss = 0.23380 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:31:26.339705 ops/training.py:65 2019-01-16 13:31:26.339641: step 17500, loss = 0.42201 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:31:27.300609 ops/training.py:65 2019-01-16 13:31:27.300524: step 17501, loss = 0.47017 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:31:28.264689 ops/training.py:65 2019-01-16 13:31:28.264646: step 17502, loss = 0.27991 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:31:29.225397 ops/training.py:65 2019-01-16 13:31:29.225316: step 17503, loss = 0.20153 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:31:30.185350 ops/training.py:65 2019-01-16 13:31:30.185268: step 17504, loss = 0.29024 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:31:31.150460 ops/training.py:65 2019-01-16 13:31:31.150415: step 17505, loss = 0.42901 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:31:32.113056 ops/training.py:65 2019-01-16 13:31:32.113022: step 17506, loss = 0.26684 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:31:33.074399 ops/training.py:65 2019-01-16 13:31:33.074320: step 17507, loss = 0.45193 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:31:34.038558 ops/training.py:65 2019-01-16 13:31:34.038502: step 17508, loss = 0.25508 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:31:35.001150 ops/training.py:65 2019-01-16 13:31:35.001108: step 17509, loss = 0.35377 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:31:35.963024 ops/training.py:65 2019-01-16 13:31:35.962966: step 17510, loss = 0.39199 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:31:36.924649 ops/training.py:65 2019-01-16 13:31:36.924563: step 17511, loss = 0.38940 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:31:37.888883 ops/training.py:65 2019-01-16 13:31:37.888816: step 17512, loss = 0.24549 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:31:38.853202 ops/training.py:65 2019-01-16 13:31:38.853130: step 17513, loss = 0.44877 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:31:39.815969 ops/training.py:65 2019-01-16 13:31:39.815902: step 17514, loss = 0.30361 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:31:40.777393 ops/training.py:65 2019-01-16 13:31:40.777335: step 17515, loss = 0.46611 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:31:41.739789 ops/training.py:65 2019-01-16 13:31:41.739727: step 17516, loss = 0.38781 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:31:42.702329 ops/training.py:65 2019-01-16 13:31:42.702266: step 17517, loss = 0.38394 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:31:43.663775 ops/training.py:65 2019-01-16 13:31:43.663738: step 17518, loss = 0.25607 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:31:44.625188 ops/training.py:65 2019-01-16 13:31:44.625147: step 17519, loss = 0.49691 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 13:31:45.586598 ops/training.py:65 2019-01-16 13:31:45.586536: step 17520, loss = 0.24370 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:31:46.547900 ops/training.py:65 2019-01-16 13:31:46.547842: step 17521, loss = 0.29632 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:31:47.510042 ops/training.py:65 2019-01-16 13:31:47.509978: step 17522, loss = 0.30309 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:31:48.469833 ops/training.py:65 2019-01-16 13:31:48.469760: step 17523, loss = 0.50922 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:31:49.434246 ops/training.py:65 2019-01-16 13:31:49.434194: step 17524, loss = 0.46581 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:31:50.397602 ops/training.py:65 2019-01-16 13:31:50.397523: step 17525, loss = 0.34154 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:31:51.360039 ops/training.py:65 2019-01-16 13:31:51.359977: step 17526, loss = 0.40078 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:31:52.321982 ops/training.py:65 2019-01-16 13:31:52.321921: step 17527, loss = 0.47884 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:31:53.283905 ops/training.py:65 2019-01-16 13:31:53.283837: step 17528, loss = 0.38512 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:31:54.245740 ops/training.py:65 2019-01-16 13:31:54.245677: step 17529, loss = 0.32330 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:31:55.207354 ops/training.py:65 2019-01-16 13:31:55.207290: step 17530, loss = 0.31847 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:31:56.168265 ops/training.py:65 2019-01-16 13:31:56.168186: step 17531, loss = 0.32876 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:31:57.221518 ops/training.py:65 2019-01-16 13:31:57.221459: step 17532, loss = 0.29270 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:31:58.185948 ops/training.py:65 2019-01-16 13:31:58.185888: step 17533, loss = 0.32453 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:31:59.148581 ops/training.py:65 2019-01-16 13:31:59.148508: step 17534, loss = 0.24111 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:32:00.110968 ops/training.py:65 2019-01-16 13:32:00.110890: step 17535, loss = 0.38521 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:32:01.070754 ops/training.py:65 2019-01-16 13:32:01.070685: step 17536, loss = 0.40422 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:32:02.124857 ops/training.py:65 2019-01-16 13:32:02.124793: step 17537, loss = 0.44615 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:32:03.088489 ops/training.py:65 2019-01-16 13:32:03.088431: step 17538, loss = 0.36798 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:32:04.050483 ops/training.py:65 2019-01-16 13:32:04.050412: step 17539, loss = 0.25929 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:32:05.011556 ops/training.py:65 2019-01-16 13:32:05.011495: step 17540, loss = 0.24903 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:32:05.972939 ops/training.py:65 2019-01-16 13:32:05.972872: step 17541, loss = 0.26467 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:32:06.934073 ops/training.py:65 2019-01-16 13:32:06.934003: step 17542, loss = 0.37693 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:32:07.894918 ops/training.py:65 2019-01-16 13:32:07.894854: step 17543, loss = 0.28798 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 13:32:08.856125 ops/training.py:65 2019-01-16 13:32:08.856064: step 17544, loss = 0.28991 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:32:09.817851 ops/training.py:65 2019-01-16 13:32:09.817785: step 17545, loss = 0.32843 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:32:10.780012 ops/training.py:65 2019-01-16 13:32:10.779946: step 17546, loss = 0.24275 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:32:11.741870 ops/training.py:65 2019-01-16 13:32:11.741810: step 17547, loss = 0.48617 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:32:12.701004 ops/training.py:65 2019-01-16 13:32:12.700941: step 17548, loss = 0.29074 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:32:13.665144 ops/training.py:65 2019-01-16 13:32:13.665085: step 17549, loss = 0.37131 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:32:14.628162 ops/training.py:65 2019-01-16 13:32:14.628094: step 17550, loss = 0.20473 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:32:15.591369 ops/training.py:65 2019-01-16 13:32:15.591292: step 17551, loss = 0.42105 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:32:16.552986 ops/training.py:65 2019-01-16 13:32:16.552915: step 17552, loss = 0.48982 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:32:17.513055 ops/training.py:65 2019-01-16 13:32:17.512975: step 17553, loss = 0.40470 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:32:18.477235 ops/training.py:65 2019-01-16 13:32:18.477165: step 17554, loss = 0.35426 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:32:19.440377 ops/training.py:65 2019-01-16 13:32:19.440305: step 17555, loss = 0.39615 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:32:20.402449 ops/training.py:65 2019-01-16 13:32:20.402383: step 17556, loss = 0.41909 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:32:21.363569 ops/training.py:65 2019-01-16 13:32:21.363501: step 17557, loss = 0.24610 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:32:22.325321 ops/training.py:65 2019-01-16 13:32:22.325244: step 17558, loss = 0.41425 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:32:23.286332 ops/training.py:65 2019-01-16 13:32:23.286253: step 17559, loss = 0.31627 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:32:24.248063 ops/training.py:65 2019-01-16 13:32:24.247982: step 17560, loss = 0.41677 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:32:25.209726 ops/training.py:65 2019-01-16 13:32:25.209643: step 17561, loss = 0.38724 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:32:26.170103 ops/training.py:65 2019-01-16 13:32:26.170023: step 17562, loss = 0.25663 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:32:27.134539 ops/training.py:65 2019-01-16 13:32:27.134464: step 17563, loss = 0.33522 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:32:28.099331 ops/training.py:65 2019-01-16 13:32:28.099258: step 17564, loss = 0.31101 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:32:29.062780 ops/training.py:65 2019-01-16 13:32:29.062710: step 17565, loss = 0.48439 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:32:30.025001 ops/training.py:65 2019-01-16 13:32:30.024926: step 17566, loss = 0.38664 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:32:30.986657 ops/training.py:65 2019-01-16 13:32:30.986577: step 17567, loss = 0.38380 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:32:31.948400 ops/training.py:65 2019-01-16 13:32:31.948317: step 17568, loss = 0.39023 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:32:32.909861 ops/training.py:65 2019-01-16 13:32:32.909779: step 17569, loss = 0.40911 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:32:33.871200 ops/training.py:65 2019-01-16 13:32:33.871130: step 17570, loss = 0.49103 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:32:34.832874 ops/training.py:65 2019-01-16 13:32:34.832774: step 17571, loss = 0.42903 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:32:35.793707 ops/training.py:65 2019-01-16 13:32:35.793625: step 17572, loss = 0.27002 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:32:36.753753 ops/training.py:65 2019-01-16 13:32:36.753675: step 17573, loss = 0.32930 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:32:37.718272 ops/training.py:65 2019-01-16 13:32:37.718191: step 17574, loss = 0.32218 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:32:38.682275 ops/training.py:65 2019-01-16 13:32:38.682195: step 17575, loss = 0.35860 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:32:39.644974 ops/training.py:65 2019-01-16 13:32:39.644907: step 17576, loss = 0.35684 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:32:40.607174 ops/training.py:65 2019-01-16 13:32:40.607107: step 17577, loss = 0.35293 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:32:41.569780 ops/training.py:65 2019-01-16 13:32:41.569722: step 17578, loss = 0.34449 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:32:42.529788 ops/training.py:65 2019-01-16 13:32:42.529720: step 17579, loss = 0.34881 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:32:43.495384 ops/training.py:65 2019-01-16 13:32:43.495310: step 17580, loss = 0.48065 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:32:44.461520 ops/training.py:65 2019-01-16 13:32:44.461452: step 17581, loss = 0.49953 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:32:45.424549 ops/training.py:65 2019-01-16 13:32:45.424481: step 17582, loss = 0.31000 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:32:46.386867 ops/training.py:65 2019-01-16 13:32:46.386793: step 17583, loss = 0.40996 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:32:47.349394 ops/training.py:65 2019-01-16 13:32:47.349322: step 17584, loss = 0.41899 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:32:48.311748 ops/training.py:65 2019-01-16 13:32:48.311691: step 17585, loss = 0.39802 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:32:49.273541 ops/training.py:65 2019-01-16 13:32:49.273473: step 17586, loss = 0.34975 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:32:50.235458 ops/training.py:65 2019-01-16 13:32:50.235386: step 17587, loss = 0.40417 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:32:51.197298 ops/training.py:65 2019-01-16 13:32:51.197221: step 17588, loss = 0.42494 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:32:52.159380 ops/training.py:65 2019-01-16 13:32:52.159300: step 17589, loss = 0.27828 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:32:53.120915 ops/training.py:65 2019-01-16 13:32:53.120853: step 17590, loss = 0.34556 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:32:54.080978 ops/training.py:65 2019-01-16 13:32:54.080897: step 17591, loss = 0.54860 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:32:55.045730 ops/training.py:65 2019-01-16 13:32:55.045645: step 17592, loss = 0.34076 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:32:56.011419 ops/training.py:65 2019-01-16 13:32:56.011353: step 17593, loss = 0.35389 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:32:56.974802 ops/training.py:65 2019-01-16 13:32:56.974737: step 17594, loss = 0.57467 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:32:57.936888 ops/training.py:65 2019-01-16 13:32:57.936817: step 17595, loss = 0.45908 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:32:58.898925 ops/training.py:65 2019-01-16 13:32:58.898850: step 17596, loss = 0.32986 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:32:59.861306 ops/training.py:65 2019-01-16 13:32:59.861230: step 17597, loss = 0.38164 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:33:00.823479 ops/training.py:65 2019-01-16 13:33:00.823403: step 17598, loss = 0.50496 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:33:01.785938 ops/training.py:65 2019-01-16 13:33:01.785863: step 17599, loss = 0.48570 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:33:02.748167 ops/training.py:65 2019-01-16 13:33:02.748088: step 17600, loss = 0.43218 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:33:03.710183 ops/training.py:65 2019-01-16 13:33:03.710113: step 17601, loss = 0.32881 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:33:04.669725 ops/training.py:65 2019-01-16 13:33:04.669648: step 17602, loss = 0.32605 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:33:05.629653 ops/training.py:65 2019-01-16 13:33:05.629574: step 17603, loss = 0.32354 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:33:06.593347 ops/training.py:65 2019-01-16 13:33:06.593245: step 17604, loss = 0.37967 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:33:07.557786 ops/training.py:65 2019-01-16 13:33:07.557694: step 17605, loss = 0.44273 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:33:08.520577 ops/training.py:65 2019-01-16 13:33:08.520503: step 17606, loss = 0.37636 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:33:09.481073 ops/training.py:65 2019-01-16 13:33:09.480988: step 17607, loss = 0.31214 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:33:10.446910 ops/training.py:65 2019-01-16 13:33:10.446852: step 17608, loss = 0.34984 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:33:11.407916 ops/training.py:65 2019-01-16 13:33:11.407868: step 17609, loss = 0.42602 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:33:12.368703 ops/training.py:65 2019-01-16 13:33:12.368635: step 17610, loss = 0.20160 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:33:13.333508 ops/training.py:65 2019-01-16 13:33:13.333441: step 17611, loss = 0.32061 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:33:14.298344 ops/training.py:65 2019-01-16 13:33:14.298259: step 17612, loss = 0.44955 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:33:15.261027 ops/training.py:65 2019-01-16 13:33:15.260945: step 17613, loss = 0.51688 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:33:16.222474 ops/training.py:65 2019-01-16 13:33:16.222413: step 17614, loss = 0.26773 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:33:17.183495 ops/training.py:65 2019-01-16 13:33:17.183411: step 17615, loss = 0.39410 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:33:18.148547 ops/training.py:65 2019-01-16 13:33:18.148470: step 17616, loss = 0.32038 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:33:19.112973 ops/training.py:65 2019-01-16 13:33:19.112896: step 17617, loss = 0.35285 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:33:20.075889 ops/training.py:65 2019-01-16 13:33:20.075792: step 17618, loss = 0.43898 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:33:21.038811 ops/training.py:65 2019-01-16 13:33:21.038734: step 17619, loss = 0.53542 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:33:21.999938 ops/training.py:65 2019-01-16 13:33:21.999857: step 17620, loss = 0.30623 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:33:22.962410 ops/training.py:65 2019-01-16 13:33:22.962332: step 17621, loss = 0.44550 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:33:23.923575 ops/training.py:65 2019-01-16 13:33:23.923501: step 17622, loss = 0.34966 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:33:24.887862 ops/training.py:65 2019-01-16 13:33:24.887791: step 17623, loss = 0.31746 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:33:25.853006 ops/training.py:65 2019-01-16 13:33:25.852940: step 17624, loss = 0.31516 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:33:26.814686 ops/training.py:65 2019-01-16 13:33:26.814609: step 17625, loss = 0.31288 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:33:27.775714 ops/training.py:65 2019-01-16 13:33:27.775628: step 17626, loss = 0.35736 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:33:28.739925 ops/training.py:65 2019-01-16 13:33:28.739843: step 17627, loss = 0.37869 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:33:29.705059 ops/training.py:65 2019-01-16 13:33:29.704996: step 17628, loss = 0.37947 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:33:30.668247 ops/training.py:65 2019-01-16 13:33:30.668142: step 17629, loss = 0.40097 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:33:31.629736 ops/training.py:65 2019-01-16 13:33:31.629665: step 17630, loss = 0.33381 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:33:32.591708 ops/training.py:65 2019-01-16 13:33:32.591627: step 17631, loss = 0.38806 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:33:33.556284 ops/training.py:65 2019-01-16 13:33:33.556211: step 17632, loss = 0.26865 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:33:34.520210 ops/training.py:65 2019-01-16 13:33:34.520143: step 17633, loss = 0.41966 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:33:35.484537 ops/training.py:65 2019-01-16 13:33:35.484470: step 17634, loss = 0.60001 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:33:36.446649 ops/training.py:65 2019-01-16 13:33:36.446575: step 17635, loss = 0.32907 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:33:37.408831 ops/training.py:65 2019-01-16 13:33:37.408736: step 17636, loss = 0.29444 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:33:38.371058 ops/training.py:65 2019-01-16 13:33:38.370973: step 17637, loss = 0.36217 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:33:39.333248 ops/training.py:65 2019-01-16 13:33:39.333166: step 17638, loss = 0.40867 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:33:40.296010 ops/training.py:65 2019-01-16 13:33:40.295936: step 17639, loss = 0.40091 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:33:41.258693 ops/training.py:65 2019-01-16 13:33:41.258602: step 17640, loss = 0.42856 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:33:42.221627 ops/training.py:65 2019-01-16 13:33:42.221563: step 17641, loss = 0.46724 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:33:43.183628 ops/training.py:65 2019-01-16 13:33:43.183562: step 17642, loss = 0.53363 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:33:44.145496 ops/training.py:65 2019-01-16 13:33:44.145442: step 17643, loss = 0.47389 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:33:45.107697 ops/training.py:65 2019-01-16 13:33:45.107620: step 17644, loss = 0.42646 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:33:46.069194 ops/training.py:65 2019-01-16 13:33:46.069125: step 17645, loss = 0.22315 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:33:47.030681 ops/training.py:65 2019-01-16 13:33:47.030617: step 17646, loss = 0.52350 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:33:47.991979 ops/training.py:65 2019-01-16 13:33:47.991913: step 17647, loss = 0.22832 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:33:48.953019 ops/training.py:65 2019-01-16 13:33:48.952988: step 17648, loss = 0.43118 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:33:49.913925 ops/training.py:65 2019-01-16 13:33:49.913893: step 17649, loss = 0.23989 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:33:50.878998 ops/training.py:65 2019-01-16 13:33:50.878969: step 17650, loss = 0.45784 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:33:51.842332 ops/training.py:65 2019-01-16 13:33:51.842303: step 17651, loss = 0.30453 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:33:52.805640 ops/training.py:65 2019-01-16 13:33:52.805600: step 17652, loss = 0.46216 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:33:53.766906 ops/training.py:65 2019-01-16 13:33:53.766856: step 17653, loss = 0.44624 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:33:54.729756 ops/training.py:65 2019-01-16 13:33:54.729715: step 17654, loss = 0.40997 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:33:55.693427 ops/training.py:65 2019-01-16 13:33:55.693353: step 17655, loss = 0.39473 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:33:56.657053 ops/training.py:65 2019-01-16 13:33:56.657008: step 17656, loss = 0.33148 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:33:57.618393 ops/training.py:65 2019-01-16 13:33:57.618346: step 17657, loss = 0.33026 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:33:58.579597 ops/training.py:65 2019-01-16 13:33:58.579526: step 17658, loss = 0.26078 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:33:59.543014 ops/training.py:65 2019-01-16 13:33:59.542957: step 17659, loss = 0.20022 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:34:00.504526 ops/training.py:65 2019-01-16 13:34:00.504473: step 17660, loss = 0.39057 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:34:01.466356 ops/training.py:65 2019-01-16 13:34:01.466306: step 17661, loss = 0.32982 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:34:02.427873 ops/training.py:65 2019-01-16 13:34:02.427802: step 17662, loss = 0.51603 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:34:03.389586 ops/training.py:65 2019-01-16 13:34:03.389516: step 17663, loss = 0.25216 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:34:04.351952 ops/training.py:65 2019-01-16 13:34:04.351890: step 17664, loss = 0.48126 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:34:05.312826 ops/training.py:65 2019-01-16 13:34:05.312762: step 17665, loss = 0.25208 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:34:06.273706 ops/training.py:65 2019-01-16 13:34:06.273639: step 17666, loss = 0.29964 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:34:07.234366 ops/training.py:65 2019-01-16 13:34:07.234307: step 17667, loss = 0.28011 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:34:08.195187 ops/training.py:65 2019-01-16 13:34:08.195127: step 17668, loss = 0.42487 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:34:09.156018 ops/training.py:65 2019-01-16 13:34:09.155941: step 17669, loss = 0.43270 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:34:10.116161 ops/training.py:65 2019-01-16 13:34:10.116092: step 17670, loss = 0.30027 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:34:11.076904 ops/training.py:65 2019-01-16 13:34:11.076835: step 17671, loss = 0.36022 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:34:12.037539 ops/training.py:65 2019-01-16 13:34:12.037472: step 17672, loss = 0.36228 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:34:12.998016 ops/training.py:65 2019-01-16 13:34:12.997950: step 17673, loss = 0.36728 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:34:13.958425 ops/training.py:65 2019-01-16 13:34:13.958390: step 17674, loss = 0.55742 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 13:34:14.919776 ops/training.py:65 2019-01-16 13:34:14.919711: step 17675, loss = 0.36272 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:34:15.883658 ops/training.py:65 2019-01-16 13:34:15.883599: step 17676, loss = 0.36877 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:34:16.845912 ops/training.py:65 2019-01-16 13:34:16.845855: step 17677, loss = 0.41069 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:34:17.806849 ops/training.py:65 2019-01-16 13:34:17.806770: step 17678, loss = 0.49384 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:34:18.767172 ops/training.py:65 2019-01-16 13:34:18.767105: step 17679, loss = 0.29146 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:34:19.728234 ops/training.py:65 2019-01-16 13:34:19.728166: step 17680, loss = 0.35298 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:34:20.689072 ops/training.py:65 2019-01-16 13:34:20.688982: step 17681, loss = 0.45440 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:34:21.650054 ops/training.py:65 2019-01-16 13:34:21.649967: step 17682, loss = 0.23578 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:34:22.611345 ops/training.py:65 2019-01-16 13:34:22.611262: step 17683, loss = 0.37244 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:34:23.572060 ops/training.py:65 2019-01-16 13:34:23.571977: step 17684, loss = 0.25837 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:34:24.532743 ops/training.py:65 2019-01-16 13:34:24.532664: step 17685, loss = 0.35844 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:34:25.493442 ops/training.py:65 2019-01-16 13:34:25.493364: step 17686, loss = 0.25340 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:34:26.458339 ops/training.py:65 2019-01-16 13:34:26.458266: step 17687, loss = 0.37105 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:34:27.418395 ops/training.py:65 2019-01-16 13:34:27.418325: step 17688, loss = 0.38446 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:34:28.379253 ops/training.py:65 2019-01-16 13:34:28.379175: step 17689, loss = 0.33648 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:34:29.340148 ops/training.py:65 2019-01-16 13:34:29.340074: step 17690, loss = 0.30255 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:34:30.301450 ops/training.py:65 2019-01-16 13:34:30.301382: step 17691, loss = 0.41110 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:34:31.265364 ops/training.py:65 2019-01-16 13:34:31.265296: step 17692, loss = 0.47223 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:34:32.229258 ops/training.py:65 2019-01-16 13:34:32.229190: step 17693, loss = 0.47696 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:34:33.192270 ops/training.py:65 2019-01-16 13:34:33.192208: step 17694, loss = 0.25149 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:34:34.154166 ops/training.py:65 2019-01-16 13:34:34.154092: step 17695, loss = 0.42592 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:34:35.115109 ops/training.py:65 2019-01-16 13:34:35.115038: step 17696, loss = 0.30285 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:34:36.076439 ops/training.py:65 2019-01-16 13:34:36.076369: step 17697, loss = 0.24670 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:34:37.037305 ops/training.py:65 2019-01-16 13:34:37.037236: step 17698, loss = 0.28028 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:34:37.999372 ops/training.py:65 2019-01-16 13:34:37.999316: step 17699, loss = 0.35086 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:34:38.960171 ops/training.py:65 2019-01-16 13:34:38.960107: step 17700, loss = 0.38823 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:34:39.920638 ops/training.py:65 2019-01-16 13:34:39.920566: step 17701, loss = 0.30623 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:34:40.884709 ops/training.py:65 2019-01-16 13:34:40.884632: step 17702, loss = 0.26500 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:34:41.848010 ops/training.py:65 2019-01-16 13:34:41.847952: step 17703, loss = 0.44871 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:34:42.809950 ops/training.py:65 2019-01-16 13:34:42.809886: step 17704, loss = 0.34600 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:34:43.770223 ops/training.py:65 2019-01-16 13:34:43.770166: step 17705, loss = 0.29731 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:34:44.730911 ops/training.py:65 2019-01-16 13:34:44.730856: step 17706, loss = 0.35722 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:34:45.691180 ops/training.py:65 2019-01-16 13:34:45.691130: step 17707, loss = 0.52654 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:34:46.650773 ops/training.py:65 2019-01-16 13:34:46.650693: step 17708, loss = 0.29124 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:34:47.614146 ops/training.py:65 2019-01-16 13:34:47.614069: step 17709, loss = 0.36387 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:34:48.574707 ops/training.py:65 2019-01-16 13:34:48.574631: step 17710, loss = 0.30705 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:34:49.538947 ops/training.py:65 2019-01-16 13:34:49.538881: step 17711, loss = 0.37560 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:34:50.502956 ops/training.py:65 2019-01-16 13:34:50.502880: step 17712, loss = 0.37864 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:34:51.465459 ops/training.py:65 2019-01-16 13:34:51.465382: step 17713, loss = 0.36080 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:34:53.431166 ops/training.py:65 2019-01-16 13:34:53.431089: step 17714, loss = 0.47175 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:34:54.392909 ops/training.py:65 2019-01-16 13:34:54.392838: step 17715, loss = 0.40547 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:34:55.354436 ops/training.py:65 2019-01-16 13:34:55.354363: step 17716, loss = 0.37435 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:34:56.315167 ops/training.py:65 2019-01-16 13:34:56.315093: step 17717, loss = 0.40789 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:34:57.276023 ops/training.py:65 2019-01-16 13:34:57.275949: step 17718, loss = 0.31479 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:34:58.236911 ops/training.py:65 2019-01-16 13:34:58.236843: step 17719, loss = 0.28319 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:34:59.198560 ops/training.py:65 2019-01-16 13:34:59.198493: step 17720, loss = 0.41901 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:35:00.159049 ops/training.py:65 2019-01-16 13:35:00.158975: step 17721, loss = 0.34308 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:35:01.121156 ops/training.py:65 2019-01-16 13:35:01.121086: step 17722, loss = 0.26654 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:35:02.081486 ops/training.py:65 2019-01-16 13:35:02.081399: step 17723, loss = 0.50466 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:35:03.045525 ops/training.py:65 2019-01-16 13:35:03.045449: step 17724, loss = 0.37768 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:35:04.006147 ops/training.py:65 2019-01-16 13:35:04.006073: step 17725, loss = 0.40264 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:35:04.969308 ops/training.py:65 2019-01-16 13:35:04.969238: step 17726, loss = 0.37221 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:35:05.932305 ops/training.py:65 2019-01-16 13:35:05.932228: step 17727, loss = 0.26384 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:35:06.894886 ops/training.py:65 2019-01-16 13:35:06.894805: step 17728, loss = 0.31843 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:35:07.856881 ops/training.py:65 2019-01-16 13:35:07.856817: step 17729, loss = 0.50109 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 13:35:08.817190 ops/training.py:65 2019-01-16 13:35:08.817120: step 17730, loss = 0.32097 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:35:09.782162 ops/training.py:65 2019-01-16 13:35:09.782083: step 17731, loss = 0.32101 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:35:10.743347 ops/training.py:65 2019-01-16 13:35:10.743270: step 17732, loss = 0.29898 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:35:11.703989 ops/training.py:65 2019-01-16 13:35:11.703909: step 17733, loss = 0.33700 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:35:12.664391 ops/training.py:65 2019-01-16 13:35:12.664309: step 17734, loss = 0.31353 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:35:13.625410 ops/training.py:65 2019-01-16 13:35:13.625301: step 17735, loss = 0.37068 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:35:14.585992 ops/training.py:65 2019-01-16 13:35:14.585898: step 17736, loss = 0.52744 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:35:15.546946 ops/training.py:65 2019-01-16 13:35:15.546847: step 17737, loss = 0.36908 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:35:16.511270 ops/training.py:65 2019-01-16 13:35:16.511179: step 17738, loss = 0.40288 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:35:17.474823 ops/training.py:65 2019-01-16 13:35:17.474726: step 17739, loss = 0.32014 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:35:18.437647 ops/training.py:65 2019-01-16 13:35:18.437568: step 17740, loss = 0.38819 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:35:19.399048 ops/training.py:65 2019-01-16 13:35:19.398973: step 17741, loss = 0.33042 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:35:20.360313 ops/training.py:65 2019-01-16 13:35:20.360219: step 17742, loss = 0.26451 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:35:21.321786 ops/training.py:65 2019-01-16 13:35:21.321701: step 17743, loss = 0.31976 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:35:22.283146 ops/training.py:65 2019-01-16 13:35:22.283053: step 17744, loss = 0.54062 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.59375
I0832 2019-01-16 13:35:23.244371 ops/training.py:65 2019-01-16 13:35:23.244282: step 17745, loss = 0.64944 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 13:35:24.204767 ops/training.py:65 2019-01-16 13:35:24.204673: step 17746, loss = 0.43372 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:35:25.166753 ops/training.py:65 2019-01-16 13:35:25.166661: step 17747, loss = 0.33673 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:35:26.127337 ops/training.py:65 2019-01-16 13:35:26.127237: step 17748, loss = 0.35390 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:35:27.087438 ops/training.py:65 2019-01-16 13:35:27.087378: step 17749, loss = 0.47896 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:35:28.046775 ops/training.py:65 2019-01-16 13:35:28.046708: step 17750, loss = 0.29085 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:35:29.005465 ops/training.py:65 2019-01-16 13:35:29.005386: step 17751, loss = 0.35502 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:35:29.964532 ops/training.py:65 2019-01-16 13:35:29.964466: step 17752, loss = 0.34999 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:35:30.923176 ops/training.py:65 2019-01-16 13:35:30.923108: step 17753, loss = 0.50817 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:35:31.881102 ops/training.py:65 2019-01-16 13:35:31.881041: step 17754, loss = 0.43293 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:35:32.839088 ops/training.py:65 2019-01-16 13:35:32.839024: step 17755, loss = 0.39684 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:35:33.797058 ops/training.py:65 2019-01-16 13:35:33.796995: step 17756, loss = 0.49630 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:35:34.760080 ops/training.py:65 2019-01-16 13:35:34.760034: step 17757, loss = 0.40841 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:35:35.722114 ops/training.py:65 2019-01-16 13:35:35.722080: step 17758, loss = 0.37446 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:35:36.683332 ops/training.py:65 2019-01-16 13:35:36.683296: step 17759, loss = 0.37940 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:35:37.643776 ops/training.py:65 2019-01-16 13:35:37.643737: step 17760, loss = 0.26918 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:35:38.604650 ops/training.py:65 2019-01-16 13:35:38.604577: step 17761, loss = 0.27246 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:35:39.565198 ops/training.py:65 2019-01-16 13:35:39.565104: step 17762, loss = 0.24955 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:35:40.524390 ops/training.py:65 2019-01-16 13:35:40.524309: step 17763, loss = 0.32280 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:35:41.484789 ops/training.py:65 2019-01-16 13:35:41.484706: step 17764, loss = 0.40909 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:35:42.447695 ops/training.py:65 2019-01-16 13:35:42.447596: step 17765, loss = 0.23889 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:35:43.410781 ops/training.py:65 2019-01-16 13:35:43.410673: step 17766, loss = 0.45968 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:35:44.373831 ops/training.py:65 2019-01-16 13:35:44.373737: step 17767, loss = 0.20106 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 13:35:45.336127 ops/training.py:65 2019-01-16 13:35:45.336023: step 17768, loss = 0.40621 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:35:46.298283 ops/training.py:65 2019-01-16 13:35:46.298181: step 17769, loss = 0.40500 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:35:47.262801 ops/training.py:65 2019-01-16 13:35:47.262695: step 17770, loss = 0.39133 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:35:48.223200 ops/training.py:65 2019-01-16 13:35:48.223105: step 17771, loss = 0.39571 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:35:49.184397 ops/training.py:65 2019-01-16 13:35:49.184296: step 17772, loss = 0.56058 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:35:50.149034 ops/training.py:65 2019-01-16 13:35:50.148965: step 17773, loss = 0.36952 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:35:51.110700 ops/training.py:65 2019-01-16 13:35:51.110623: step 17774, loss = 0.20792 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:35:52.071727 ops/training.py:65 2019-01-16 13:35:52.071626: step 17775, loss = 0.40743 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:35:53.036409 ops/training.py:65 2019-01-16 13:35:53.036294: step 17776, loss = 0.35724 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:35:53.997126 ops/training.py:65 2019-01-16 13:35:53.997019: step 17777, loss = 0.32051 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:35:54.956908 ops/training.py:65 2019-01-16 13:35:54.956808: step 17778, loss = 0.29794 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:35:55.920071 ops/training.py:65 2019-01-16 13:35:55.920001: step 17779, loss = 0.33984 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:35:56.880866 ops/training.py:65 2019-01-16 13:35:56.880790: step 17780, loss = 0.27135 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:35:57.841829 ops/training.py:65 2019-01-16 13:35:57.841732: step 17781, loss = 0.32362 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:35:58.802187 ops/training.py:65 2019-01-16 13:35:58.802115: step 17782, loss = 0.31649 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:35:59.762663 ops/training.py:65 2019-01-16 13:35:59.762587: step 17783, loss = 0.30002 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:36:00.722599 ops/training.py:65 2019-01-16 13:36:00.722518: step 17784, loss = 0.23667 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:36:01.682643 ops/training.py:65 2019-01-16 13:36:01.682569: step 17785, loss = 0.49128 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:36:02.643242 ops/training.py:65 2019-01-16 13:36:02.643139: step 17786, loss = 0.30263 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:36:03.608246 ops/training.py:65 2019-01-16 13:36:03.608147: step 17787, loss = 0.40934 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:36:04.572140 ops/training.py:65 2019-01-16 13:36:04.572061: step 17788, loss = 0.32132 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:36:05.534197 ops/training.py:65 2019-01-16 13:36:05.534118: step 17789, loss = 0.36221 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:36:06.495013 ops/training.py:65 2019-01-16 13:36:06.494914: step 17790, loss = 0.26915 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:36:07.456387 ops/training.py:65 2019-01-16 13:36:07.456287: step 17791, loss = 0.30250 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:36:08.417921 ops/training.py:65 2019-01-16 13:36:08.417810: step 17792, loss = 0.40904 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:36:09.379446 ops/training.py:65 2019-01-16 13:36:09.379346: step 17793, loss = 0.23451 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:36:10.342180 ops/training.py:65 2019-01-16 13:36:10.342064: step 17794, loss = 0.42170 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:36:11.305406 ops/training.py:65 2019-01-16 13:36:11.305294: step 17795, loss = 0.35809 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:36:12.268788 ops/training.py:65 2019-01-16 13:36:12.268706: step 17796, loss = 0.25516 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:36:13.229627 ops/training.py:65 2019-01-16 13:36:13.229553: step 17797, loss = 0.42896 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:36:14.193205 ops/training.py:65 2019-01-16 13:36:14.193099: step 17798, loss = 0.32403 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:36:15.155270 ops/training.py:65 2019-01-16 13:36:15.155179: step 17799, loss = 0.41699 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:36:16.120831 ops/training.py:65 2019-01-16 13:36:16.120759: step 17800, loss = 0.33196 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:36:17.084270 ops/training.py:65 2019-01-16 13:36:17.084210: step 17801, loss = 0.36360 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:36:18.046270 ops/training.py:65 2019-01-16 13:36:18.046150: step 17802, loss = 0.25100 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:36:19.008277 ops/training.py:65 2019-01-16 13:36:19.008175: step 17803, loss = 0.31204 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:36:19.972459 ops/training.py:65 2019-01-16 13:36:19.972385: step 17804, loss = 0.35792 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:36:20.933417 ops/training.py:65 2019-01-16 13:36:20.933327: step 17805, loss = 0.44835 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:36:21.894917 ops/training.py:65 2019-01-16 13:36:21.894846: step 17806, loss = 0.38552 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:36:22.855601 ops/training.py:65 2019-01-16 13:36:22.855526: step 17807, loss = 0.38772 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:36:23.816759 ops/training.py:65 2019-01-16 13:36:23.816684: step 17808, loss = 0.38490 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:36:24.778566 ops/training.py:65 2019-01-16 13:36:24.778499: step 17809, loss = 0.38365 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:36:25.739271 ops/training.py:65 2019-01-16 13:36:25.739180: step 17810, loss = 0.29005 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:36:26.700784 ops/training.py:65 2019-01-16 13:36:26.700727: step 17811, loss = 0.48206 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:36:27.661994 ops/training.py:65 2019-01-16 13:36:27.661920: step 17812, loss = 0.24239 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:36:28.622597 ops/training.py:65 2019-01-16 13:36:28.622518: step 17813, loss = 0.33094 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:36:29.583745 ops/training.py:65 2019-01-16 13:36:29.583665: step 17814, loss = 0.23218 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:36:30.544392 ops/training.py:65 2019-01-16 13:36:30.544297: step 17815, loss = 0.37161 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:36:31.508638 ops/training.py:65 2019-01-16 13:36:31.508524: step 17816, loss = 0.46687 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:36:32.472481 ops/training.py:65 2019-01-16 13:36:32.472381: step 17817, loss = 0.47052 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:36:33.432271 ops/training.py:65 2019-01-16 13:36:33.432184: step 17818, loss = 0.35068 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:36:34.392640 ops/training.py:65 2019-01-16 13:36:34.392568: step 17819, loss = 0.33845 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:36:35.358461 ops/training.py:65 2019-01-16 13:36:35.358359: step 17820, loss = 0.40426 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:36:36.321853 ops/training.py:65 2019-01-16 13:36:36.321768: step 17821, loss = 0.30000 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:36:37.283997 ops/training.py:65 2019-01-16 13:36:37.283897: step 17822, loss = 0.37762 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:36:38.245536 ops/training.py:65 2019-01-16 13:36:38.245435: step 17823, loss = 0.48113 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:36:39.207362 ops/training.py:65 2019-01-16 13:36:39.207200: step 17824, loss = 0.23886 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:36:40.168046 ops/training.py:65 2019-01-16 13:36:40.167938: step 17825, loss = 0.32751 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:36:41.132399 ops/training.py:65 2019-01-16 13:36:41.132324: step 17826, loss = 0.30523 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:36:42.095008 ops/training.py:65 2019-01-16 13:36:42.094927: step 17827, loss = 0.37019 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:36:43.059082 ops/training.py:65 2019-01-16 13:36:43.059003: step 17828, loss = 0.32481 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:36:44.024039 ops/training.py:65 2019-01-16 13:36:44.023924: step 17829, loss = 0.34876 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:36:44.987409 ops/training.py:65 2019-01-16 13:36:44.987315: step 17830, loss = 0.32304 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:36:45.949258 ops/training.py:65 2019-01-16 13:36:45.949133: step 17831, loss = 0.33736 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:36:46.911365 ops/training.py:65 2019-01-16 13:36:46.911263: step 17832, loss = 0.34978 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:36:47.874639 ops/training.py:65 2019-01-16 13:36:47.874553: step 17833, loss = 0.26385 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:36:48.836529 ops/training.py:65 2019-01-16 13:36:48.836447: step 17834, loss = 0.32856 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:36:49.796431 ops/training.py:65 2019-01-16 13:36:49.796363: step 17835, loss = 0.36956 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:36:50.757571 ops/training.py:65 2019-01-16 13:36:50.757467: step 17836, loss = 0.37936 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:36:51.722595 ops/training.py:65 2019-01-16 13:36:51.722500: step 17837, loss = 0.35705 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:36:52.684676 ops/training.py:65 2019-01-16 13:36:52.684578: step 17838, loss = 0.38621 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:36:53.649083 ops/training.py:65 2019-01-16 13:36:53.648986: step 17839, loss = 0.24570 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:36:54.613067 ops/training.py:65 2019-01-16 13:36:54.612972: step 17840, loss = 0.23771 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:36:55.575975 ops/training.py:65 2019-01-16 13:36:55.575872: step 17841, loss = 0.32391 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:36:56.536784 ops/training.py:65 2019-01-16 13:36:56.536688: step 17842, loss = 0.35483 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:36:57.501097 ops/training.py:65 2019-01-16 13:36:57.501004: step 17843, loss = 0.29289 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:36:58.465389 ops/training.py:65 2019-01-16 13:36:58.465296: step 17844, loss = 0.36035 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:36:59.427116 ops/training.py:65 2019-01-16 13:36:59.427027: step 17845, loss = 0.31221 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:37:00.388689 ops/training.py:65 2019-01-16 13:37:00.388594: step 17846, loss = 0.41360 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:37:01.350794 ops/training.py:65 2019-01-16 13:37:01.350708: step 17847, loss = 0.33958 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:37:02.312898 ops/training.py:65 2019-01-16 13:37:02.312797: step 17848, loss = 0.32341 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:37:03.274712 ops/training.py:65 2019-01-16 13:37:03.274614: step 17849, loss = 0.41670 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:37:04.239508 ops/training.py:65 2019-01-16 13:37:04.239409: step 17850, loss = 0.33931 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:37:05.203549 ops/training.py:65 2019-01-16 13:37:05.203457: step 17851, loss = 0.35738 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:37:06.165792 ops/training.py:65 2019-01-16 13:37:06.165705: step 17852, loss = 0.29105 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:37:07.127083 ops/training.py:65 2019-01-16 13:37:07.126991: step 17853, loss = 0.47199 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:37:08.087716 ops/training.py:65 2019-01-16 13:37:08.087616: step 17854, loss = 0.44847 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:37:09.052528 ops/training.py:65 2019-01-16 13:37:09.052434: step 17855, loss = 0.50848 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:37:10.013724 ops/training.py:65 2019-01-16 13:37:10.013632: step 17856, loss = 0.42332 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:37:10.977992 ops/training.py:65 2019-01-16 13:37:10.977896: step 17857, loss = 0.27737 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:37:11.941670 ops/training.py:65 2019-01-16 13:37:11.941600: step 17858, loss = 0.43834 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:37:12.902315 ops/training.py:65 2019-01-16 13:37:12.902235: step 17859, loss = 0.23503 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:37:13.862978 ops/training.py:65 2019-01-16 13:37:13.862878: step 17860, loss = 0.22291 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:37:14.824182 ops/training.py:65 2019-01-16 13:37:14.824080: step 17861, loss = 0.28325 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:37:15.785070 ops/training.py:65 2019-01-16 13:37:15.784970: step 17862, loss = 0.46595 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:37:16.746230 ops/training.py:65 2019-01-16 13:37:16.746138: step 17863, loss = 0.49686 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:37:17.707710 ops/training.py:65 2019-01-16 13:37:17.707635: step 17864, loss = 0.25491 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:37:18.668832 ops/training.py:65 2019-01-16 13:37:18.668743: step 17865, loss = 0.30239 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:37:19.630345 ops/training.py:65 2019-01-16 13:37:19.630265: step 17866, loss = 0.27642 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:37:20.592038 ops/training.py:65 2019-01-16 13:37:20.591958: step 17867, loss = 0.54673 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:37:21.554001 ops/training.py:65 2019-01-16 13:37:21.553907: step 17868, loss = 0.43488 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:37:22.514117 ops/training.py:65 2019-01-16 13:37:22.514017: step 17869, loss = 0.30024 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:37:23.479050 ops/training.py:65 2019-01-16 13:37:23.478958: step 17870, loss = 0.47033 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:37:24.440558 ops/training.py:65 2019-01-16 13:37:24.440460: step 17871, loss = 0.35820 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:37:25.405294 ops/training.py:65 2019-01-16 13:37:25.405201: step 17872, loss = 0.26097 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:37:26.368987 ops/training.py:65 2019-01-16 13:37:26.368899: step 17873, loss = 0.29103 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:37:27.331528 ops/training.py:65 2019-01-16 13:37:27.331434: step 17874, loss = 0.39435 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:37:28.293784 ops/training.py:65 2019-01-16 13:37:28.293708: step 17875, loss = 0.26914 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:37:29.255441 ops/training.py:65 2019-01-16 13:37:29.255361: step 17876, loss = 0.26275 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:37:30.216733 ops/training.py:65 2019-01-16 13:37:30.216650: step 17877, loss = 0.42638 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:37:31.177917 ops/training.py:65 2019-01-16 13:37:31.177824: step 17878, loss = 0.31466 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:37:32.139313 ops/training.py:65 2019-01-16 13:37:32.139221: step 17879, loss = 0.35537 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:37:33.100464 ops/training.py:65 2019-01-16 13:37:33.100368: step 17880, loss = 0.28944 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:37:34.062001 ops/training.py:65 2019-01-16 13:37:34.061903: step 17881, loss = 0.19196 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:37:35.023977 ops/training.py:65 2019-01-16 13:37:35.023880: step 17882, loss = 0.27887 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:37:35.985220 ops/training.py:65 2019-01-16 13:37:35.985123: step 17883, loss = 0.39296 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:37:36.949772 ops/training.py:65 2019-01-16 13:37:36.949677: step 17884, loss = 0.36039 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:37:37.913722 ops/training.py:65 2019-01-16 13:37:37.913624: step 17885, loss = 0.28104 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:37:38.876730 ops/training.py:65 2019-01-16 13:37:38.876643: step 17886, loss = 0.32511 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:37:39.838128 ops/training.py:65 2019-01-16 13:37:39.838041: step 17887, loss = 0.23449 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:37:40.800029 ops/training.py:65 2019-01-16 13:37:40.799933: step 17888, loss = 0.29542 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:37:41.761350 ops/training.py:65 2019-01-16 13:37:41.761273: step 17889, loss = 0.40446 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:37:42.722686 ops/training.py:65 2019-01-16 13:37:42.722583: step 17890, loss = 0.58719 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 13:37:43.683508 ops/training.py:65 2019-01-16 13:37:43.683422: step 17891, loss = 0.36321 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:37:44.644783 ops/training.py:65 2019-01-16 13:37:44.644700: step 17892, loss = 0.36551 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:37:45.605788 ops/training.py:65 2019-01-16 13:37:45.605686: step 17893, loss = 0.37037 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:37:46.568352 ops/training.py:65 2019-01-16 13:37:46.568255: step 17894, loss = 0.36156 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:37:47.531231 ops/training.py:65 2019-01-16 13:37:47.531134: step 17895, loss = 0.45526 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:37:48.492352 ops/training.py:65 2019-01-16 13:37:48.492274: step 17896, loss = 0.30041 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:37:49.453131 ops/training.py:65 2019-01-16 13:37:49.453037: step 17897, loss = 0.28011 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:37:50.418195 ops/training.py:65 2019-01-16 13:37:50.418099: step 17898, loss = 0.35926 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:37:51.382477 ops/training.py:65 2019-01-16 13:37:51.382381: step 17899, loss = 0.31340 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:37:52.345426 ops/training.py:65 2019-01-16 13:37:52.345305: step 17900, loss = 0.40524 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:37:53.308126 ops/training.py:65 2019-01-16 13:37:53.308030: step 17901, loss = 0.26439 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:37:54.270561 ops/training.py:65 2019-01-16 13:37:54.270466: step 17902, loss = 0.34582 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:37:55.230792 ops/training.py:65 2019-01-16 13:37:55.230695: step 17903, loss = 0.25322 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:37:56.194964 ops/training.py:65 2019-01-16 13:37:56.194868: step 17904, loss = 0.35400 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:37:57.159774 ops/training.py:65 2019-01-16 13:37:57.159700: step 17905, loss = 0.39421 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:37:58.122495 ops/training.py:65 2019-01-16 13:37:58.122401: step 17906, loss = 0.32339 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:37:59.084201 ops/training.py:65 2019-01-16 13:37:59.084099: step 17907, loss = 0.26172 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:38:00.046981 ops/training.py:65 2019-01-16 13:38:00.046887: step 17908, loss = 0.28769 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:38:01.008135 ops/training.py:65 2019-01-16 13:38:01.008052: step 17909, loss = 0.36402 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:38:01.973824 ops/training.py:65 2019-01-16 13:38:01.973734: step 17910, loss = 0.31070 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:38:02.937302 ops/training.py:65 2019-01-16 13:38:02.937238: step 17911, loss = 0.42306 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:38:03.899514 ops/training.py:65 2019-01-16 13:38:03.899420: step 17912, loss = 0.29920 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:38:04.862102 ops/training.py:65 2019-01-16 13:38:04.862012: step 17913, loss = 0.46897 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:38:05.823667 ops/training.py:65 2019-01-16 13:38:05.823571: step 17914, loss = 0.28370 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:38:06.785096 ops/training.py:65 2019-01-16 13:38:06.785018: step 17915, loss = 0.36602 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:38:07.746774 ops/training.py:65 2019-01-16 13:38:07.746685: step 17916, loss = 0.29836 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:38:08.707856 ops/training.py:65 2019-01-16 13:38:08.707769: step 17917, loss = 0.45093 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:38:09.669229 ops/training.py:65 2019-01-16 13:38:09.669159: step 17918, loss = 0.28795 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:38:10.630386 ops/training.py:65 2019-01-16 13:38:10.630292: step 17919, loss = 0.55251 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:38:11.591514 ops/training.py:65 2019-01-16 13:38:11.591418: step 17920, loss = 0.26177 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:38:12.552754 ops/training.py:65 2019-01-16 13:38:12.552663: step 17921, loss = 0.30473 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:38:13.512683 ops/training.py:65 2019-01-16 13:38:13.512605: step 17922, loss = 0.46605 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:38:14.477184 ops/training.py:65 2019-01-16 13:38:14.477084: step 17923, loss = 0.36659 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:38:15.437419 ops/training.py:65 2019-01-16 13:38:15.437326: step 17924, loss = 0.36089 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:38:16.401253 ops/training.py:65 2019-01-16 13:38:16.401165: step 17925, loss = 0.39753 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:38:17.363848 ops/training.py:65 2019-01-16 13:38:17.363753: step 17926, loss = 0.24665 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:38:18.325607 ops/training.py:65 2019-01-16 13:38:18.325518: step 17927, loss = 0.43902 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:38:19.286848 ops/training.py:65 2019-01-16 13:38:19.286764: step 17928, loss = 0.37401 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:38:20.248197 ops/training.py:65 2019-01-16 13:38:20.248103: step 17929, loss = 0.30557 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:38:21.208803 ops/training.py:65 2019-01-16 13:38:21.208707: step 17930, loss = 0.40561 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:38:22.174068 ops/training.py:65 2019-01-16 13:38:22.173971: step 17931, loss = 0.40329 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:38:23.138272 ops/training.py:65 2019-01-16 13:38:23.138176: step 17932, loss = 0.38300 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:38:24.101614 ops/training.py:65 2019-01-16 13:38:24.101519: step 17933, loss = 0.23830 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:38:25.064149 ops/training.py:65 2019-01-16 13:38:25.064048: step 17934, loss = 0.29581 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:38:26.025194 ops/training.py:65 2019-01-16 13:38:26.025103: step 17935, loss = 0.37685 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:38:26.986661 ops/training.py:65 2019-01-16 13:38:26.986587: step 17936, loss = 0.32451 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:38:27.948537 ops/training.py:65 2019-01-16 13:38:27.948443: step 17937, loss = 0.47085 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:38:28.909693 ops/training.py:65 2019-01-16 13:38:28.909604: step 17938, loss = 0.38461 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:38:29.870715 ops/training.py:65 2019-01-16 13:38:29.870627: step 17939, loss = 0.41329 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:38:30.831660 ops/training.py:65 2019-01-16 13:38:30.831568: step 17940, loss = 0.29682 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:38:31.793255 ops/training.py:65 2019-01-16 13:38:31.793162: step 17941, loss = 0.49333 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:38:32.756948 ops/training.py:65 2019-01-16 13:38:32.756874: step 17942, loss = 0.36518 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:38:33.720669 ops/training.py:65 2019-01-16 13:38:33.720572: step 17943, loss = 0.36022 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:38:34.683506 ops/training.py:65 2019-01-16 13:38:34.683405: step 17944, loss = 0.26204 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:38:35.645763 ops/training.py:65 2019-01-16 13:38:35.645674: step 17945, loss = 0.33945 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:38:36.606765 ops/training.py:65 2019-01-16 13:38:36.606673: step 17946, loss = 0.43755 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:38:37.567625 ops/training.py:65 2019-01-16 13:38:37.567528: step 17947, loss = 0.32736 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:38:38.527581 ops/training.py:65 2019-01-16 13:38:38.527497: step 17948, loss = 0.35518 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:38:39.487640 ops/training.py:65 2019-01-16 13:38:39.487553: step 17949, loss = 0.26113 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:38:40.447752 ops/training.py:65 2019-01-16 13:38:40.447661: step 17950, loss = 0.29200 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:38:41.408587 ops/training.py:65 2019-01-16 13:38:41.408495: step 17951, loss = 0.27912 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:38:42.370386 ops/training.py:65 2019-01-16 13:38:42.370289: step 17952, loss = 0.45531 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:38:43.329944 ops/training.py:65 2019-01-16 13:38:43.329870: step 17953, loss = 0.37789 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:38:44.290238 ops/training.py:65 2019-01-16 13:38:44.290145: step 17954, loss = 0.29095 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:38:45.249741 ops/training.py:65 2019-01-16 13:38:45.249644: step 17955, loss = 0.29661 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:38:46.213269 ops/training.py:65 2019-01-16 13:38:46.213170: step 17956, loss = 0.39888 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:38:47.176812 ops/training.py:65 2019-01-16 13:38:47.176714: step 17957, loss = 0.26842 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:38:48.139767 ops/training.py:65 2019-01-16 13:38:48.139676: step 17958, loss = 0.26353 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:38:49.101077 ops/training.py:65 2019-01-16 13:38:49.100985: step 17959, loss = 0.27351 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:38:50.061527 ops/training.py:65 2019-01-16 13:38:50.061432: step 17960, loss = 0.26161 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:38:51.021702 ops/training.py:65 2019-01-16 13:38:51.021603: step 17961, loss = 0.27564 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:38:51.985436 ops/training.py:65 2019-01-16 13:38:51.985338: step 17962, loss = 0.47228 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:38:52.947722 ops/training.py:65 2019-01-16 13:38:52.947628: step 17963, loss = 0.43102 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:38:53.909998 ops/training.py:65 2019-01-16 13:38:53.909900: step 17964, loss = 0.52215 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:38:54.871547 ops/training.py:65 2019-01-16 13:38:54.871455: step 17965, loss = 0.46985 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:38:55.833383 ops/training.py:65 2019-01-16 13:38:55.833291: step 17966, loss = 0.40359 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:38:56.795476 ops/training.py:65 2019-01-16 13:38:56.795400: step 17967, loss = 0.39553 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:38:57.756597 ops/training.py:65 2019-01-16 13:38:57.756500: step 17968, loss = 0.27975 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:38:58.717062 ops/training.py:65 2019-01-16 13:38:58.716974: step 17969, loss = 0.69540 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.625
I0832 2019-01-16 13:38:59.677123 ops/training.py:65 2019-01-16 13:38:59.677033: step 17970, loss = 0.39772 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:39:00.637659 ops/training.py:65 2019-01-16 13:39:00.637564: step 17971, loss = 0.40524 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:39:01.598579 ops/training.py:65 2019-01-16 13:39:01.598499: step 17972, loss = 0.31150 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:39:02.558756 ops/training.py:65 2019-01-16 13:39:02.558661: step 17973, loss = 0.24093 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:39:03.519498 ops/training.py:65 2019-01-16 13:39:03.519405: step 17974, loss = 0.31588 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:39:04.479820 ops/training.py:65 2019-01-16 13:39:04.479728: step 17975, loss = 0.40810 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:39:05.440282 ops/training.py:65 2019-01-16 13:39:05.440189: step 17976, loss = 0.29840 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:39:06.400671 ops/training.py:65 2019-01-16 13:39:06.400578: step 17977, loss = 0.21990 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:39:07.361348 ops/training.py:65 2019-01-16 13:39:07.361251: step 17978, loss = 0.36749 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:39:08.321260 ops/training.py:65 2019-01-16 13:39:08.321167: step 17979, loss = 0.26882 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:39:09.284903 ops/training.py:65 2019-01-16 13:39:09.284810: step 17980, loss = 0.38740 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:39:10.248178 ops/training.py:65 2019-01-16 13:39:10.248081: step 17981, loss = 0.34148 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:39:11.210017 ops/training.py:65 2019-01-16 13:39:11.209903: step 17982, loss = 0.34401 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:39:12.170288 ops/training.py:65 2019-01-16 13:39:12.170192: step 17983, loss = 0.32978 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:39:13.130963 ops/training.py:65 2019-01-16 13:39:13.130882: step 17984, loss = 0.25754 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:39:14.091260 ops/training.py:65 2019-01-16 13:39:14.091165: step 17985, loss = 0.33689 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:39:15.050834 ops/training.py:65 2019-01-16 13:39:15.050740: step 17986, loss = 0.29088 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:39:16.010230 ops/training.py:65 2019-01-16 13:39:16.010143: step 17987, loss = 0.23710 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:39:16.972693 ops/training.py:65 2019-01-16 13:39:16.972605: step 17988, loss = 0.37079 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:39:17.935065 ops/training.py:65 2019-01-16 13:39:17.934988: step 17989, loss = 0.58294 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:39:18.899827 ops/training.py:65 2019-01-16 13:39:18.899733: step 17990, loss = 0.34627 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:39:19.862186 ops/training.py:65 2019-01-16 13:39:19.862094: step 17991, loss = 0.23514 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:39:20.824966 ops/training.py:65 2019-01-16 13:39:20.824870: step 17992, loss = 0.42091 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:39:21.787136 ops/training.py:65 2019-01-16 13:39:21.787037: step 17993, loss = 0.29816 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:39:22.748885 ops/training.py:65 2019-01-16 13:39:22.748789: step 17994, loss = 0.22857 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:39:23.709627 ops/training.py:65 2019-01-16 13:39:23.709531: step 17995, loss = 0.55880 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:39:24.674097 ops/training.py:65 2019-01-16 13:39:24.674013: step 17996, loss = 0.30639 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:39:25.636359 ops/training.py:65 2019-01-16 13:39:25.636262: step 17997, loss = 0.35651 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:39:26.598242 ops/training.py:65 2019-01-16 13:39:26.598154: step 17998, loss = 0.30403 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:39:27.559375 ops/training.py:65 2019-01-16 13:39:27.559283: step 17999, loss = 0.49798 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:44:06.610716 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I0832 2019-01-16 13:44:06.611984 ops/training.py:41 2019-01-16 13:44:06.611919: step 18000, loss = 0.40 (0.1 examples/sec; 278.091 sec/batch) | Training accuracy = 0.78125 | Validation accuracy = 0.68765 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_08_07_39_512188
I0832 2019-01-16 13:44:07.575649 ops/training.py:65 2019-01-16 13:44:07.575497: step 18001, loss = 0.31519 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:44:08.538758 ops/training.py:65 2019-01-16 13:44:08.538675: step 18002, loss = 0.33632 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:44:09.500410 ops/training.py:65 2019-01-16 13:44:09.500318: step 18003, loss = 0.34526 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:44:10.462748 ops/training.py:65 2019-01-16 13:44:10.462641: step 18004, loss = 0.29210 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:44:11.425894 ops/training.py:65 2019-01-16 13:44:11.425822: step 18005, loss = 0.33181 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:44:12.387836 ops/training.py:65 2019-01-16 13:44:12.387759: step 18006, loss = 0.36225 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:44:13.350132 ops/training.py:65 2019-01-16 13:44:13.350054: step 18007, loss = 0.34383 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:44:14.313152 ops/training.py:65 2019-01-16 13:44:14.313047: step 18008, loss = 0.33884 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:44:15.275661 ops/training.py:65 2019-01-16 13:44:15.275578: step 18009, loss = 0.36839 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:44:16.237899 ops/training.py:65 2019-01-16 13:44:16.237831: step 18010, loss = 0.41216 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:44:17.199816 ops/training.py:65 2019-01-16 13:44:17.199737: step 18011, loss = 0.24066 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:44:18.162996 ops/training.py:65 2019-01-16 13:44:18.162923: step 18012, loss = 0.43329 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:44:19.125047 ops/training.py:65 2019-01-16 13:44:19.124948: step 18013, loss = 0.20393 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:44:20.087960 ops/training.py:65 2019-01-16 13:44:20.087876: step 18014, loss = 0.42853 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:44:21.049715 ops/training.py:65 2019-01-16 13:44:21.049628: step 18015, loss = 0.20702 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:44:22.012478 ops/training.py:65 2019-01-16 13:44:22.012376: step 18016, loss = 0.32237 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:44:22.974127 ops/training.py:65 2019-01-16 13:44:22.974041: step 18017, loss = 0.24460 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:44:23.937124 ops/training.py:65 2019-01-16 13:44:23.937045: step 18018, loss = 0.23064 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:44:24.899328 ops/training.py:65 2019-01-16 13:44:24.899248: step 18019, loss = 0.38082 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:44:25.860753 ops/training.py:65 2019-01-16 13:44:25.860666: step 18020, loss = 0.22189 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:44:26.823541 ops/training.py:65 2019-01-16 13:44:26.823445: step 18021, loss = 0.40555 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:44:27.785321 ops/training.py:65 2019-01-16 13:44:27.785206: step 18022, loss = 0.21364 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:44:28.747749 ops/training.py:65 2019-01-16 13:44:28.747655: step 18023, loss = 0.27703 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:44:29.712373 ops/training.py:65 2019-01-16 13:44:29.712280: step 18024, loss = 0.29718 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:44:30.676273 ops/training.py:65 2019-01-16 13:44:30.676167: step 18025, loss = 0.34760 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:44:31.639412 ops/training.py:65 2019-01-16 13:44:31.639321: step 18026, loss = 0.25890 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:44:32.600205 ops/training.py:65 2019-01-16 13:44:32.600135: step 18027, loss = 0.20084 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:44:33.561927 ops/training.py:65 2019-01-16 13:44:33.561831: step 18028, loss = 0.28057 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:44:34.523977 ops/training.py:65 2019-01-16 13:44:34.523890: step 18029, loss = 0.24498 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:44:35.488025 ops/training.py:65 2019-01-16 13:44:35.487916: step 18030, loss = 0.39388 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:44:36.450755 ops/training.py:65 2019-01-16 13:44:36.450694: step 18031, loss = 0.50966 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:44:37.412780 ops/training.py:65 2019-01-16 13:44:37.412705: step 18032, loss = 0.35967 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:44:38.375294 ops/training.py:65 2019-01-16 13:44:38.375189: step 18033, loss = 0.44924 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:44:39.337208 ops/training.py:65 2019-01-16 13:44:39.337119: step 18034, loss = 0.34635 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:44:40.299896 ops/training.py:65 2019-01-16 13:44:40.299799: step 18035, loss = 0.45113 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:44:41.264242 ops/training.py:65 2019-01-16 13:44:41.264171: step 18036, loss = 0.34016 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:44:42.226399 ops/training.py:65 2019-01-16 13:44:42.226300: step 18037, loss = 0.40078 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:44:43.187350 ops/training.py:65 2019-01-16 13:44:43.187268: step 18038, loss = 0.29276 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:44:44.151128 ops/training.py:65 2019-01-16 13:44:44.151043: step 18039, loss = 0.37291 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:44:45.113127 ops/training.py:65 2019-01-16 13:44:45.113025: step 18040, loss = 0.32576 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:44:46.074976 ops/training.py:65 2019-01-16 13:44:46.074885: step 18041, loss = 0.39519 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:44:47.036022 ops/training.py:65 2019-01-16 13:44:47.035924: step 18042, loss = 0.33984 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:44:47.998243 ops/training.py:65 2019-01-16 13:44:47.998142: step 18043, loss = 0.40532 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:44:48.960386 ops/training.py:65 2019-01-16 13:44:48.960283: step 18044, loss = 0.22916 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:44:49.925130 ops/training.py:65 2019-01-16 13:44:49.925020: step 18045, loss = 0.37680 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:44:50.886862 ops/training.py:65 2019-01-16 13:44:50.886746: step 18046, loss = 0.22119 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:44:51.850701 ops/training.py:65 2019-01-16 13:44:51.850605: step 18047, loss = 0.40426 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:44:52.812519 ops/training.py:65 2019-01-16 13:44:52.812437: step 18048, loss = 0.37776 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:44:53.776220 ops/training.py:65 2019-01-16 13:44:53.776117: step 18049, loss = 0.47576 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:44:54.737999 ops/training.py:65 2019-01-16 13:44:54.737900: step 18050, loss = 0.31004 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:44:55.699665 ops/training.py:65 2019-01-16 13:44:55.699564: step 18051, loss = 0.37435 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:44:56.661931 ops/training.py:65 2019-01-16 13:44:56.661829: step 18052, loss = 0.43598 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:44:57.622715 ops/training.py:65 2019-01-16 13:44:57.622623: step 18053, loss = 0.22709 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:44:58.583903 ops/training.py:65 2019-01-16 13:44:58.583807: step 18054, loss = 0.43803 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:44:59.544733 ops/training.py:65 2019-01-16 13:44:59.544637: step 18055, loss = 0.37635 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:45:00.506254 ops/training.py:65 2019-01-16 13:45:00.506157: step 18056, loss = 0.25689 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:45:01.468841 ops/training.py:65 2019-01-16 13:45:01.468748: step 18057, loss = 0.29810 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:45:02.430111 ops/training.py:65 2019-01-16 13:45:02.430010: step 18058, loss = 0.24137 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:45:03.391520 ops/training.py:65 2019-01-16 13:45:03.391421: step 18059, loss = 0.35781 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:45:04.354052 ops/training.py:65 2019-01-16 13:45:04.353953: step 18060, loss = 0.34686 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:45:05.317206 ops/training.py:65 2019-01-16 13:45:05.317088: step 18061, loss = 0.31261 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:45:06.280895 ops/training.py:65 2019-01-16 13:45:06.280787: step 18062, loss = 0.24383 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:45:07.242034 ops/training.py:65 2019-01-16 13:45:07.241938: step 18063, loss = 0.27445 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:45:08.204373 ops/training.py:65 2019-01-16 13:45:08.204278: step 18064, loss = 0.26547 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:45:09.167608 ops/training.py:65 2019-01-16 13:45:09.167494: step 18065, loss = 0.29488 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:45:10.130412 ops/training.py:65 2019-01-16 13:45:10.130298: step 18066, loss = 0.51417 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:45:11.096978 ops/training.py:65 2019-01-16 13:45:11.096879: step 18067, loss = 0.35135 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:45:12.057971 ops/training.py:65 2019-01-16 13:45:12.057876: step 18068, loss = 0.33890 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:45:13.022211 ops/training.py:65 2019-01-16 13:45:13.022106: step 18069, loss = 0.41437 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:45:13.986006 ops/training.py:65 2019-01-16 13:45:13.985926: step 18070, loss = 0.26560 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:45:14.950726 ops/training.py:65 2019-01-16 13:45:14.950630: step 18071, loss = 0.30820 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:45:15.913227 ops/training.py:65 2019-01-16 13:45:15.913127: step 18072, loss = 0.35522 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:45:16.874930 ops/training.py:65 2019-01-16 13:45:16.874827: step 18073, loss = 0.36435 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:45:17.837267 ops/training.py:65 2019-01-16 13:45:17.837161: step 18074, loss = 0.22440 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 13:45:18.798878 ops/training.py:65 2019-01-16 13:45:18.798772: step 18075, loss = 0.26300 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:45:19.760534 ops/training.py:65 2019-01-16 13:45:19.760459: step 18076, loss = 0.35120 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:45:20.722495 ops/training.py:65 2019-01-16 13:45:20.722404: step 18077, loss = 0.41665 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:45:21.684410 ops/training.py:65 2019-01-16 13:45:21.684290: step 18078, loss = 0.36279 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:45:22.647452 ops/training.py:65 2019-01-16 13:45:22.647333: step 18079, loss = 0.21865 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 13:45:23.610215 ops/training.py:65 2019-01-16 13:45:23.610116: step 18080, loss = 0.38098 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:45:24.572361 ops/training.py:65 2019-01-16 13:45:24.572288: step 18081, loss = 0.27064 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:45:25.533902 ops/training.py:65 2019-01-16 13:45:25.533832: step 18082, loss = 0.34023 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:45:26.495491 ops/training.py:65 2019-01-16 13:45:26.495387: step 18083, loss = 0.40825 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:45:27.458678 ops/training.py:65 2019-01-16 13:45:27.458571: step 18084, loss = 0.27728 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:45:28.420466 ops/training.py:65 2019-01-16 13:45:28.420361: step 18085, loss = 0.53892 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:45:29.386272 ops/training.py:65 2019-01-16 13:45:29.386139: step 18086, loss = 0.33707 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:45:30.351202 ops/training.py:65 2019-01-16 13:45:30.351082: step 18087, loss = 0.31931 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:45:31.313224 ops/training.py:65 2019-01-16 13:45:31.313101: step 18088, loss = 0.29369 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:45:32.275496 ops/training.py:65 2019-01-16 13:45:32.275402: step 18089, loss = 0.27829 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:45:33.237721 ops/training.py:65 2019-01-16 13:45:33.237611: step 18090, loss = 0.35779 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:45:34.202232 ops/training.py:65 2019-01-16 13:45:34.202135: step 18091, loss = 0.20894 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:45:35.166015 ops/training.py:65 2019-01-16 13:45:35.165924: step 18092, loss = 0.42790 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:45:36.128881 ops/training.py:65 2019-01-16 13:45:36.128783: step 18093, loss = 0.40578 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:45:37.090664 ops/training.py:65 2019-01-16 13:45:37.090567: step 18094, loss = 0.40818 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:45:38.051968 ops/training.py:65 2019-01-16 13:45:38.051869: step 18095, loss = 0.24704 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:45:39.013857 ops/training.py:65 2019-01-16 13:45:39.013758: step 18096, loss = 0.48113 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:45:39.977046 ops/training.py:65 2019-01-16 13:45:39.976940: step 18097, loss = 0.45847 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:45:40.939954 ops/training.py:65 2019-01-16 13:45:40.939850: step 18098, loss = 0.31664 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:45:41.902707 ops/training.py:65 2019-01-16 13:45:41.902627: step 18099, loss = 0.34446 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:45:42.866556 ops/training.py:65 2019-01-16 13:45:42.866454: step 18100, loss = 0.34532 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:45:43.830690 ops/training.py:65 2019-01-16 13:45:43.830611: step 18101, loss = 0.40166 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:45:44.792209 ops/training.py:65 2019-01-16 13:45:44.792100: step 18102, loss = 0.27092 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:45:45.757164 ops/training.py:65 2019-01-16 13:45:45.757061: step 18103, loss = 0.32257 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:45:46.719041 ops/training.py:65 2019-01-16 13:45:46.718952: step 18104, loss = 0.33443 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:45:47.681389 ops/training.py:65 2019-01-16 13:45:47.681291: step 18105, loss = 0.38511 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:45:48.642641 ops/training.py:65 2019-01-16 13:45:48.642559: step 18106, loss = 0.29664 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:45:49.603509 ops/training.py:65 2019-01-16 13:45:49.603413: step 18107, loss = 0.25815 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:45:50.568208 ops/training.py:65 2019-01-16 13:45:50.568104: step 18108, loss = 0.29876 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:45:51.530646 ops/training.py:65 2019-01-16 13:45:51.530530: step 18109, loss = 0.28433 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:45:52.492486 ops/training.py:65 2019-01-16 13:45:52.492372: step 18110, loss = 0.45117 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:45:53.454557 ops/training.py:65 2019-01-16 13:45:53.454469: step 18111, loss = 0.26734 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:45:54.416783 ops/training.py:65 2019-01-16 13:45:54.416703: step 18112, loss = 0.20721 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:45:55.378677 ops/training.py:65 2019-01-16 13:45:55.378594: step 18113, loss = 0.26340 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:45:56.340149 ops/training.py:65 2019-01-16 13:45:56.340062: step 18114, loss = 0.32289 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:45:57.301681 ops/training.py:65 2019-01-16 13:45:57.301585: step 18115, loss = 0.39592 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:45:58.263462 ops/training.py:65 2019-01-16 13:45:58.263339: step 18116, loss = 0.30413 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:45:59.227274 ops/training.py:65 2019-01-16 13:45:59.227175: step 18117, loss = 0.15707 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:46:00.189609 ops/training.py:65 2019-01-16 13:46:00.189507: step 18118, loss = 0.48362 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:46:01.152905 ops/training.py:65 2019-01-16 13:46:01.152798: step 18119, loss = 0.39510 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:46:02.114560 ops/training.py:65 2019-01-16 13:46:02.114459: step 18120, loss = 0.28330 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:46:03.077005 ops/training.py:65 2019-01-16 13:46:03.076902: step 18121, loss = 0.24699 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:46:04.038931 ops/training.py:65 2019-01-16 13:46:04.038864: step 18122, loss = 0.36729 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:46:05.001017 ops/training.py:65 2019-01-16 13:46:05.000936: step 18123, loss = 0.44039 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:46:05.964276 ops/training.py:65 2019-01-16 13:46:05.964192: step 18124, loss = 0.37969 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:46:06.926078 ops/training.py:65 2019-01-16 13:46:06.925998: step 18125, loss = 0.32697 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:46:07.889015 ops/training.py:65 2019-01-16 13:46:07.888938: step 18126, loss = 0.31770 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:46:08.851443 ops/training.py:65 2019-01-16 13:46:08.851386: step 18127, loss = 0.35568 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:46:09.813528 ops/training.py:65 2019-01-16 13:46:09.813425: step 18128, loss = 0.42261 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:46:10.775169 ops/training.py:65 2019-01-16 13:46:10.775067: step 18129, loss = 0.39556 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:46:11.738160 ops/training.py:65 2019-01-16 13:46:11.738094: step 18130, loss = 0.22668 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:46:12.700313 ops/training.py:65 2019-01-16 13:46:12.700215: step 18131, loss = 0.34871 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:46:13.662140 ops/training.py:65 2019-01-16 13:46:13.662044: step 18132, loss = 0.22885 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:46:14.624377 ops/training.py:65 2019-01-16 13:46:14.624280: step 18133, loss = 0.43789 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:46:15.585499 ops/training.py:65 2019-01-16 13:46:15.585402: step 18134, loss = 0.20991 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:46:16.546601 ops/training.py:65 2019-01-16 13:46:16.546497: step 18135, loss = 0.37185 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:46:17.510625 ops/training.py:65 2019-01-16 13:46:17.510520: step 18136, loss = 0.26596 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:46:18.473099 ops/training.py:65 2019-01-16 13:46:18.472980: step 18137, loss = 0.25104 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:46:19.435840 ops/training.py:65 2019-01-16 13:46:19.435743: step 18138, loss = 0.37467 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:46:20.398513 ops/training.py:65 2019-01-16 13:46:20.398411: step 18139, loss = 0.26504 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:46:21.360976 ops/training.py:65 2019-01-16 13:46:21.360871: step 18140, loss = 0.39727 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:46:22.327159 ops/training.py:65 2019-01-16 13:46:22.327054: step 18141, loss = 0.27743 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:46:23.291574 ops/training.py:65 2019-01-16 13:46:23.291473: step 18142, loss = 0.36664 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:46:24.254146 ops/training.py:65 2019-01-16 13:46:24.254043: step 18143, loss = 0.23694 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:46:25.216340 ops/training.py:65 2019-01-16 13:46:25.216263: step 18144, loss = 0.37468 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:46:26.178480 ops/training.py:65 2019-01-16 13:46:26.178399: step 18145, loss = 0.32651 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:46:27.140529 ops/training.py:65 2019-01-16 13:46:27.140436: step 18146, loss = 0.43431 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:46:28.103811 ops/training.py:65 2019-01-16 13:46:28.103718: step 18147, loss = 0.36242 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:46:29.065168 ops/training.py:65 2019-01-16 13:46:29.065076: step 18148, loss = 0.43156 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:46:30.029365 ops/training.py:65 2019-01-16 13:46:30.029273: step 18149, loss = 0.25906 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:46:30.991299 ops/training.py:65 2019-01-16 13:46:30.991201: step 18150, loss = 0.34065 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:46:31.953019 ops/training.py:65 2019-01-16 13:46:31.952921: step 18151, loss = 0.40310 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:46:32.915756 ops/training.py:65 2019-01-16 13:46:32.915645: step 18152, loss = 0.31564 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:46:33.878461 ops/training.py:65 2019-01-16 13:46:33.878367: step 18153, loss = 0.38321 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:46:34.840847 ops/training.py:65 2019-01-16 13:46:34.840750: step 18154, loss = 0.35122 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:46:35.803949 ops/training.py:65 2019-01-16 13:46:35.803853: step 18155, loss = 0.53108 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:46:36.766330 ops/training.py:65 2019-01-16 13:46:36.766233: step 18156, loss = 0.42460 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:46:37.727867 ops/training.py:65 2019-01-16 13:46:37.727776: step 18157, loss = 0.26449 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:46:38.690271 ops/training.py:65 2019-01-16 13:46:38.690177: step 18158, loss = 0.31699 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:46:39.653252 ops/training.py:65 2019-01-16 13:46:39.653160: step 18159, loss = 0.30977 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:46:40.616013 ops/training.py:65 2019-01-16 13:46:40.615914: step 18160, loss = 0.31640 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:46:41.577687 ops/training.py:65 2019-01-16 13:46:41.577610: step 18161, loss = 0.24465 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:46:42.539065 ops/training.py:65 2019-01-16 13:46:42.538975: step 18162, loss = 0.36452 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:46:43.501363 ops/training.py:65 2019-01-16 13:46:43.501285: step 18163, loss = 0.20934 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:46:44.463785 ops/training.py:65 2019-01-16 13:46:44.463696: step 18164, loss = 0.38004 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:46:45.426224 ops/training.py:65 2019-01-16 13:46:45.426134: step 18165, loss = 0.22254 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:46:46.389187 ops/training.py:65 2019-01-16 13:46:46.389091: step 18166, loss = 0.28883 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:46:47.352086 ops/training.py:65 2019-01-16 13:46:47.352009: step 18167, loss = 0.32190 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:46:48.316694 ops/training.py:65 2019-01-16 13:46:48.316602: step 18168, loss = 0.46818 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:46:49.278974 ops/training.py:65 2019-01-16 13:46:49.278881: step 18169, loss = 0.33580 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:46:50.243065 ops/training.py:65 2019-01-16 13:46:50.242973: step 18170, loss = 0.25238 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:46:51.204786 ops/training.py:65 2019-01-16 13:46:51.204689: step 18171, loss = 0.27177 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:46:52.167299 ops/training.py:65 2019-01-16 13:46:52.167206: step 18172, loss = 0.26231 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:46:53.128568 ops/training.py:65 2019-01-16 13:46:53.128469: step 18173, loss = 0.27157 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:46:54.089527 ops/training.py:65 2019-01-16 13:46:54.089437: step 18174, loss = 0.27274 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:46:55.051193 ops/training.py:65 2019-01-16 13:46:55.051097: step 18175, loss = 0.41185 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:46:56.012730 ops/training.py:65 2019-01-16 13:46:56.012639: step 18176, loss = 0.33658 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:46:56.974685 ops/training.py:65 2019-01-16 13:46:56.974594: step 18177, loss = 0.32328 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:46:57.935954 ops/training.py:65 2019-01-16 13:46:57.935853: step 18178, loss = 0.33514 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:46:58.897129 ops/training.py:65 2019-01-16 13:46:58.897039: step 18179, loss = 0.33065 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:46:59.862161 ops/training.py:65 2019-01-16 13:46:59.862066: step 18180, loss = 0.22514 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:47:00.823677 ops/training.py:65 2019-01-16 13:47:00.823583: step 18181, loss = 0.28271 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:47:01.786118 ops/training.py:65 2019-01-16 13:47:01.786034: step 18182, loss = 0.25396 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:47:02.747430 ops/training.py:65 2019-01-16 13:47:02.747354: step 18183, loss = 0.25872 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:47:03.708679 ops/training.py:65 2019-01-16 13:47:03.708588: step 18184, loss = 0.29708 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:47:04.671839 ops/training.py:65 2019-01-16 13:47:04.671749: step 18185, loss = 0.15623 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:47:05.633386 ops/training.py:65 2019-01-16 13:47:05.633285: step 18186, loss = 0.25909 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:47:06.594483 ops/training.py:65 2019-01-16 13:47:06.594390: step 18187, loss = 0.34132 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:47:07.555037 ops/training.py:65 2019-01-16 13:47:07.554938: step 18188, loss = 0.34745 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:47:08.519903 ops/training.py:65 2019-01-16 13:47:08.519806: step 18189, loss = 0.30354 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:47:09.481516 ops/training.py:65 2019-01-16 13:47:09.481426: step 18190, loss = 0.26656 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:47:10.444145 ops/training.py:65 2019-01-16 13:47:10.444046: step 18191, loss = 0.31718 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:47:11.405835 ops/training.py:65 2019-01-16 13:47:11.405761: step 18192, loss = 0.21388 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:47:12.367830 ops/training.py:65 2019-01-16 13:47:12.367752: step 18193, loss = 0.35160 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:47:13.329344 ops/training.py:65 2019-01-16 13:47:13.329266: step 18194, loss = 0.38031 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:47:14.293777 ops/training.py:65 2019-01-16 13:47:14.293707: step 18195, loss = 0.29828 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:47:15.254847 ops/training.py:65 2019-01-16 13:47:15.254774: step 18196, loss = 0.35418 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:47:16.217009 ops/training.py:65 2019-01-16 13:47:16.216930: step 18197, loss = 0.22686 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:47:17.178399 ops/training.py:65 2019-01-16 13:47:17.178310: step 18198, loss = 0.26027 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:47:18.140615 ops/training.py:65 2019-01-16 13:47:18.140523: step 18199, loss = 0.14690 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 13:47:19.101252 ops/training.py:65 2019-01-16 13:47:19.101161: step 18200, loss = 0.36925 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:47:20.063375 ops/training.py:65 2019-01-16 13:47:20.063281: step 18201, loss = 0.27042 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:47:21.025320 ops/training.py:65 2019-01-16 13:47:21.025228: step 18202, loss = 0.42290 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:47:21.986534 ops/training.py:65 2019-01-16 13:47:21.986443: step 18203, loss = 0.44615 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:47:22.948563 ops/training.py:65 2019-01-16 13:47:22.948473: step 18204, loss = 0.39791 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:47:23.911943 ops/training.py:65 2019-01-16 13:47:23.911846: step 18205, loss = 0.45377 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:47:24.873687 ops/training.py:65 2019-01-16 13:47:24.873598: step 18206, loss = 0.33265 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:47:25.835369 ops/training.py:65 2019-01-16 13:47:25.835274: step 18207, loss = 0.34598 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:47:26.797753 ops/training.py:65 2019-01-16 13:47:26.797652: step 18208, loss = 0.29791 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:47:27.763318 ops/training.py:65 2019-01-16 13:47:27.763220: step 18209, loss = 0.33889 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:47:28.726814 ops/training.py:65 2019-01-16 13:47:28.726717: step 18210, loss = 0.30452 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:47:29.688890 ops/training.py:65 2019-01-16 13:47:29.688806: step 18211, loss = 0.31884 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:47:30.650992 ops/training.py:65 2019-01-16 13:47:30.650912: step 18212, loss = 0.24911 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:47:31.614043 ops/training.py:65 2019-01-16 13:47:31.613947: step 18213, loss = 0.33124 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:47:32.576019 ops/training.py:65 2019-01-16 13:47:32.575947: step 18214, loss = 0.40958 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:47:33.538038 ops/training.py:65 2019-01-16 13:47:33.537952: step 18215, loss = 0.41364 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:47:34.500577 ops/training.py:65 2019-01-16 13:47:34.500486: step 18216, loss = 0.43098 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:47:35.462666 ops/training.py:65 2019-01-16 13:47:35.462570: step 18217, loss = 0.39170 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:47:36.425813 ops/training.py:65 2019-01-16 13:47:36.425719: step 18218, loss = 0.36231 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:47:37.388732 ops/training.py:65 2019-01-16 13:47:37.388634: step 18219, loss = 0.31834 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:47:38.350693 ops/training.py:65 2019-01-16 13:47:38.350602: step 18220, loss = 0.33734 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:47:39.313085 ops/training.py:65 2019-01-16 13:47:39.312990: step 18221, loss = 0.31367 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:47:40.274628 ops/training.py:65 2019-01-16 13:47:40.274539: step 18222, loss = 0.33651 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:47:41.236216 ops/training.py:65 2019-01-16 13:47:41.236128: step 18223, loss = 0.33580 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:47:42.198366 ops/training.py:65 2019-01-16 13:47:42.198278: step 18224, loss = 0.33203 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:47:43.162419 ops/training.py:65 2019-01-16 13:47:43.162323: step 18225, loss = 0.35035 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:47:44.125057 ops/training.py:65 2019-01-16 13:47:44.124978: step 18226, loss = 0.16327 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:47:45.086983 ops/training.py:65 2019-01-16 13:47:45.086892: step 18227, loss = 0.34406 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:47:46.049072 ops/training.py:65 2019-01-16 13:47:46.049000: step 18228, loss = 0.42293 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:47:47.011305 ops/training.py:65 2019-01-16 13:47:47.011210: step 18229, loss = 0.49242 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:47:47.974435 ops/training.py:65 2019-01-16 13:47:47.974355: step 18230, loss = 0.21108 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:47:48.937452 ops/training.py:65 2019-01-16 13:47:48.937362: step 18231, loss = 0.21652 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:47:49.899186 ops/training.py:65 2019-01-16 13:47:49.899091: step 18232, loss = 0.30890 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:47:50.861185 ops/training.py:65 2019-01-16 13:47:50.861099: step 18233, loss = 0.37117 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:47:51.825197 ops/training.py:65 2019-01-16 13:47:51.825099: step 18234, loss = 0.24289 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:47:52.789568 ops/training.py:65 2019-01-16 13:47:52.789471: step 18235, loss = 0.37969 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:47:53.752046 ops/training.py:65 2019-01-16 13:47:53.751951: step 18236, loss = 0.41849 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:47:54.714953 ops/training.py:65 2019-01-16 13:47:54.714853: step 18237, loss = 0.27953 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:47:55.677809 ops/training.py:65 2019-01-16 13:47:55.677705: step 18238, loss = 0.40817 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:47:56.640619 ops/training.py:65 2019-01-16 13:47:56.640521: step 18239, loss = 0.29735 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:47:57.603086 ops/training.py:65 2019-01-16 13:47:57.602990: step 18240, loss = 0.50952 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:47:58.566260 ops/training.py:65 2019-01-16 13:47:58.566192: step 18241, loss = 0.43353 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:47:59.526988 ops/training.py:65 2019-01-16 13:47:59.526896: step 18242, loss = 0.32508 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:48:00.488111 ops/training.py:65 2019-01-16 13:48:00.488025: step 18243, loss = 0.28512 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:48:01.449156 ops/training.py:65 2019-01-16 13:48:01.449067: step 18244, loss = 0.34949 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:48:02.410088 ops/training.py:65 2019-01-16 13:48:02.410010: step 18245, loss = 0.36551 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:48:03.371274 ops/training.py:65 2019-01-16 13:48:03.371187: step 18246, loss = 0.41217 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:48:04.332144 ops/training.py:65 2019-01-16 13:48:04.332040: step 18247, loss = 0.35183 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:48:05.294559 ops/training.py:65 2019-01-16 13:48:05.294464: step 18248, loss = 0.40931 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:48:06.256515 ops/training.py:65 2019-01-16 13:48:06.256428: step 18249, loss = 0.25573 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:48:07.217671 ops/training.py:65 2019-01-16 13:48:07.217583: step 18250, loss = 0.33481 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:48:08.179235 ops/training.py:65 2019-01-16 13:48:08.179139: step 18251, loss = 0.26647 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:48:09.141173 ops/training.py:65 2019-01-16 13:48:09.141072: step 18252, loss = 0.31012 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:48:10.105870 ops/training.py:65 2019-01-16 13:48:10.105778: step 18253, loss = 0.34376 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:48:11.068338 ops/training.py:65 2019-01-16 13:48:11.068243: step 18254, loss = 0.49835 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:48:12.030739 ops/training.py:65 2019-01-16 13:48:12.030644: step 18255, loss = 0.30968 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:48:12.995153 ops/training.py:65 2019-01-16 13:48:12.995065: step 18256, loss = 0.34651 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:48:13.957044 ops/training.py:65 2019-01-16 13:48:13.956965: step 18257, loss = 0.30152 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:48:14.918780 ops/training.py:65 2019-01-16 13:48:14.918694: step 18258, loss = 0.39599 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:48:15.883243 ops/training.py:65 2019-01-16 13:48:15.883168: step 18259, loss = 0.29818 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:48:16.844845 ops/training.py:65 2019-01-16 13:48:16.844747: step 18260, loss = 0.50883 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:48:17.806098 ops/training.py:65 2019-01-16 13:48:17.806020: step 18261, loss = 0.49544 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:48:18.768636 ops/training.py:65 2019-01-16 13:48:18.768538: step 18262, loss = 0.36061 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:48:19.730763 ops/training.py:65 2019-01-16 13:48:19.730670: step 18263, loss = 0.37749 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:48:20.691854 ops/training.py:65 2019-01-16 13:48:20.691760: step 18264, loss = 0.21464 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:48:21.653993 ops/training.py:65 2019-01-16 13:48:21.653897: step 18265, loss = 0.29318 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:48:22.615716 ops/training.py:65 2019-01-16 13:48:22.615626: step 18266, loss = 0.25539 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:48:23.580897 ops/training.py:65 2019-01-16 13:48:23.580804: step 18267, loss = 0.41297 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:48:24.544150 ops/training.py:65 2019-01-16 13:48:24.544057: step 18268, loss = 0.33131 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:48:25.509695 ops/training.py:65 2019-01-16 13:48:25.509596: step 18269, loss = 0.26125 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:48:26.471015 ops/training.py:65 2019-01-16 13:48:26.470917: step 18270, loss = 0.42664 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:48:27.432930 ops/training.py:65 2019-01-16 13:48:27.432813: step 18271, loss = 0.25026 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:48:28.395206 ops/training.py:65 2019-01-16 13:48:28.395136: step 18272, loss = 0.42507 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:48:29.356166 ops/training.py:65 2019-01-16 13:48:29.356104: step 18273, loss = 0.20070 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:48:30.315702 ops/training.py:65 2019-01-16 13:48:30.315630: step 18274, loss = 0.31785 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:48:31.275957 ops/training.py:65 2019-01-16 13:48:31.275869: step 18275, loss = 0.33842 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:48:32.239112 ops/training.py:65 2019-01-16 13:48:32.239014: step 18276, loss = 0.30936 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:48:33.203488 ops/training.py:65 2019-01-16 13:48:33.203396: step 18277, loss = 0.20231 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:48:34.166862 ops/training.py:65 2019-01-16 13:48:34.166760: step 18278, loss = 0.38887 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:48:35.128980 ops/training.py:65 2019-01-16 13:48:35.128876: step 18279, loss = 0.33518 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:48:36.091673 ops/training.py:65 2019-01-16 13:48:36.091594: step 18280, loss = 0.37522 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:48:37.053290 ops/training.py:65 2019-01-16 13:48:37.053214: step 18281, loss = 0.23374 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:48:38.014048 ops/training.py:65 2019-01-16 13:48:38.013968: step 18282, loss = 0.27129 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:48:38.976830 ops/training.py:65 2019-01-16 13:48:38.976737: step 18283, loss = 0.46660 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:48:39.939191 ops/training.py:65 2019-01-16 13:48:39.939098: step 18284, loss = 0.26714 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:48:40.901204 ops/training.py:65 2019-01-16 13:48:40.901111: step 18285, loss = 0.29540 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:48:41.862109 ops/training.py:65 2019-01-16 13:48:41.862014: step 18286, loss = 0.29787 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:48:42.822969 ops/training.py:65 2019-01-16 13:48:42.822876: step 18287, loss = 0.36110 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:48:43.783816 ops/training.py:65 2019-01-16 13:48:43.783745: step 18288, loss = 0.37442 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:48:44.745458 ops/training.py:65 2019-01-16 13:48:44.745362: step 18289, loss = 0.25311 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:48:45.706873 ops/training.py:65 2019-01-16 13:48:45.706798: step 18290, loss = 0.25927 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:48:46.668646 ops/training.py:65 2019-01-16 13:48:46.668521: step 18291, loss = 0.26965 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:48:47.631918 ops/training.py:65 2019-01-16 13:48:47.631835: step 18292, loss = 0.29513 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:48:48.595391 ops/training.py:65 2019-01-16 13:48:48.595294: step 18293, loss = 0.32346 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:48:49.558744 ops/training.py:65 2019-01-16 13:48:49.558658: step 18294, loss = 0.27822 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:48:50.522884 ops/training.py:65 2019-01-16 13:48:50.522784: step 18295, loss = 0.23444 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:48:51.487292 ops/training.py:65 2019-01-16 13:48:51.487197: step 18296, loss = 0.35223 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:48:52.452067 ops/training.py:65 2019-01-16 13:48:52.451970: step 18297, loss = 0.31784 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:48:53.415285 ops/training.py:65 2019-01-16 13:48:53.415189: step 18298, loss = 0.28982 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:48:54.378949 ops/training.py:65 2019-01-16 13:48:54.378852: step 18299, loss = 0.29603 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:48:55.343325 ops/training.py:65 2019-01-16 13:48:55.343229: step 18300, loss = 0.30641 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:48:56.304676 ops/training.py:65 2019-01-16 13:48:56.304551: step 18301, loss = 0.30534 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:48:57.266398 ops/training.py:65 2019-01-16 13:48:57.266301: step 18302, loss = 0.21388 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:48:58.228668 ops/training.py:65 2019-01-16 13:48:58.228570: step 18303, loss = 0.32566 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:48:59.190825 ops/training.py:65 2019-01-16 13:48:59.190731: step 18304, loss = 0.30308 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:49:00.152943 ops/training.py:65 2019-01-16 13:49:00.152851: step 18305, loss = 0.25823 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:49:01.116170 ops/training.py:65 2019-01-16 13:49:01.116081: step 18306, loss = 0.24312 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:49:02.079606 ops/training.py:65 2019-01-16 13:49:02.079512: step 18307, loss = 0.35398 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:49:03.044066 ops/training.py:65 2019-01-16 13:49:03.043986: step 18308, loss = 0.34974 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:49:04.007298 ops/training.py:65 2019-01-16 13:49:04.007198: step 18309, loss = 0.39840 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:49:04.969510 ops/training.py:65 2019-01-16 13:49:04.969419: step 18310, loss = 0.21596 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:49:05.930677 ops/training.py:65 2019-01-16 13:49:05.930617: step 18311, loss = 0.31797 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:49:06.892486 ops/training.py:65 2019-01-16 13:49:06.892450: step 18312, loss = 0.58933 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:49:07.853906 ops/training.py:65 2019-01-16 13:49:07.853870: step 18313, loss = 0.41017 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:49:08.815922 ops/training.py:65 2019-01-16 13:49:08.815844: step 18314, loss = 0.34706 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:49:09.778060 ops/training.py:65 2019-01-16 13:49:09.778000: step 18315, loss = 0.28634 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:49:10.738558 ops/training.py:65 2019-01-16 13:49:10.738488: step 18316, loss = 0.31892 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:49:11.700059 ops/training.py:65 2019-01-16 13:49:11.700008: step 18317, loss = 0.25141 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:49:12.661526 ops/training.py:65 2019-01-16 13:49:12.661474: step 18318, loss = 0.28927 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:49:13.625186 ops/training.py:65 2019-01-16 13:49:13.625113: step 18319, loss = 0.26128 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:49:14.587649 ops/training.py:65 2019-01-16 13:49:14.587561: step 18320, loss = 0.32703 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:49:15.553756 ops/training.py:65 2019-01-16 13:49:15.553677: step 18321, loss = 0.27127 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:49:16.517003 ops/training.py:65 2019-01-16 13:49:16.516902: step 18322, loss = 0.28489 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:49:17.479315 ops/training.py:65 2019-01-16 13:49:17.479239: step 18323, loss = 0.39906 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:49:18.443814 ops/training.py:65 2019-01-16 13:49:18.443717: step 18324, loss = 0.33144 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:49:19.407310 ops/training.py:65 2019-01-16 13:49:19.407220: step 18325, loss = 0.35520 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:49:20.370239 ops/training.py:65 2019-01-16 13:49:20.370146: step 18326, loss = 0.20232 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:49:21.333974 ops/training.py:65 2019-01-16 13:49:21.333879: step 18327, loss = 0.52668 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:49:22.296439 ops/training.py:65 2019-01-16 13:49:22.296353: step 18328, loss = 0.29772 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:49:23.261762 ops/training.py:65 2019-01-16 13:49:23.261669: step 18329, loss = 0.27578 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:49:24.223723 ops/training.py:65 2019-01-16 13:49:24.223632: step 18330, loss = 0.25297 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:49:25.187940 ops/training.py:65 2019-01-16 13:49:25.187846: step 18331, loss = 0.22533 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:49:26.150009 ops/training.py:65 2019-01-16 13:49:26.149888: step 18332, loss = 0.26515 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:49:27.111800 ops/training.py:65 2019-01-16 13:49:27.111694: step 18333, loss = 0.37017 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:49:28.073914 ops/training.py:65 2019-01-16 13:49:28.073818: step 18334, loss = 0.24353 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:49:29.037265 ops/training.py:65 2019-01-16 13:49:29.037176: step 18335, loss = 0.32313 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:49:30.001970 ops/training.py:65 2019-01-16 13:49:30.001880: step 18336, loss = 0.44914 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:49:30.963147 ops/training.py:65 2019-01-16 13:49:30.963071: step 18337, loss = 0.32160 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:49:31.924721 ops/training.py:65 2019-01-16 13:49:31.924625: step 18338, loss = 0.32572 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:49:32.886622 ops/training.py:65 2019-01-16 13:49:32.886548: step 18339, loss = 0.34480 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:49:33.849153 ops/training.py:65 2019-01-16 13:49:33.849059: step 18340, loss = 0.20790 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:49:34.811749 ops/training.py:65 2019-01-16 13:49:34.811663: step 18341, loss = 0.25991 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:49:35.774263 ops/training.py:65 2019-01-16 13:49:35.774165: step 18342, loss = 0.42382 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:49:36.736525 ops/training.py:65 2019-01-16 13:49:36.736410: step 18343, loss = 0.25720 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:49:37.699218 ops/training.py:65 2019-01-16 13:49:37.699112: step 18344, loss = 0.28393 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:49:38.662200 ops/training.py:65 2019-01-16 13:49:38.662138: step 18345, loss = 0.45125 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:49:39.625094 ops/training.py:65 2019-01-16 13:49:39.624992: step 18346, loss = 0.37306 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:49:40.587546 ops/training.py:65 2019-01-16 13:49:40.587442: step 18347, loss = 0.27999 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:49:41.550229 ops/training.py:65 2019-01-16 13:49:41.550127: step 18348, loss = 0.46611 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:49:42.512006 ops/training.py:65 2019-01-16 13:49:42.511909: step 18349, loss = 0.24480 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:49:43.473928 ops/training.py:65 2019-01-16 13:49:43.473824: step 18350, loss = 0.45683 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:49:44.438440 ops/training.py:65 2019-01-16 13:49:44.438354: step 18351, loss = 0.32309 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:49:45.398675 ops/training.py:65 2019-01-16 13:49:45.398603: step 18352, loss = 0.28160 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:49:46.362861 ops/training.py:65 2019-01-16 13:49:46.362765: step 18353, loss = 0.31391 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:49:47.326463 ops/training.py:65 2019-01-16 13:49:47.326367: step 18354, loss = 0.29860 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:49:48.290756 ops/training.py:65 2019-01-16 13:49:48.290657: step 18355, loss = 0.31805 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:49:49.253135 ops/training.py:65 2019-01-16 13:49:49.253033: step 18356, loss = 0.30110 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:49:50.215873 ops/training.py:65 2019-01-16 13:49:50.215777: step 18357, loss = 0.34156 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:49:51.177307 ops/training.py:65 2019-01-16 13:49:51.177207: step 18358, loss = 0.22611 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:49:52.138455 ops/training.py:65 2019-01-16 13:49:52.138357: step 18359, loss = 0.29482 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:49:53.100049 ops/training.py:65 2019-01-16 13:49:53.099947: step 18360, loss = 0.33584 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:49:54.061860 ops/training.py:65 2019-01-16 13:49:54.061753: step 18361, loss = 0.28959 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:49:55.023378 ops/training.py:65 2019-01-16 13:49:55.023279: step 18362, loss = 0.31655 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:49:55.986240 ops/training.py:65 2019-01-16 13:49:55.986124: step 18363, loss = 0.23562 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:49:56.953902 ops/training.py:65 2019-01-16 13:49:56.953812: step 18364, loss = 0.27092 (33.1 examples/sec; 0.966 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:49:57.918552 ops/training.py:65 2019-01-16 13:49:57.918439: step 18365, loss = 0.41170 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:49:58.880922 ops/training.py:65 2019-01-16 13:49:58.880819: step 18366, loss = 0.36916 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:49:59.842344 ops/training.py:65 2019-01-16 13:49:59.842238: step 18367, loss = 0.19246 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:50:00.808888 ops/training.py:65 2019-01-16 13:50:00.808723: step 18368, loss = 0.30308 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:50:01.772976 ops/training.py:65 2019-01-16 13:50:01.772872: step 18369, loss = 0.28512 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:50:02.735815 ops/training.py:65 2019-01-16 13:50:02.735743: step 18370, loss = 0.40923 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:50:03.697922 ops/training.py:65 2019-01-16 13:50:03.697817: step 18371, loss = 0.35299 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:50:04.659532 ops/training.py:65 2019-01-16 13:50:04.659434: step 18372, loss = 0.42240 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:50:05.621238 ops/training.py:65 2019-01-16 13:50:05.621144: step 18373, loss = 0.32842 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:50:06.582077 ops/training.py:65 2019-01-16 13:50:06.581981: step 18374, loss = 0.25862 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:50:07.543410 ops/training.py:65 2019-01-16 13:50:07.543302: step 18375, loss = 0.59620 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:50:08.505821 ops/training.py:65 2019-01-16 13:50:08.505723: step 18376, loss = 0.26007 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:50:09.470262 ops/training.py:65 2019-01-16 13:50:09.470168: step 18377, loss = 0.35030 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:50:10.432360 ops/training.py:65 2019-01-16 13:50:10.432257: step 18378, loss = 0.29451 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:50:11.394635 ops/training.py:65 2019-01-16 13:50:11.394536: step 18379, loss = 0.28482 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:50:12.355715 ops/training.py:65 2019-01-16 13:50:12.355621: step 18380, loss = 0.36410 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:50:13.317126 ops/training.py:65 2019-01-16 13:50:13.317026: step 18381, loss = 0.27494 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:50:14.278099 ops/training.py:65 2019-01-16 13:50:14.278006: step 18382, loss = 0.36783 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:50:15.240123 ops/training.py:65 2019-01-16 13:50:15.240027: step 18383, loss = 0.34041 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:50:16.201956 ops/training.py:65 2019-01-16 13:50:16.201861: step 18384, loss = 0.37123 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:50:17.162938 ops/training.py:65 2019-01-16 13:50:17.162848: step 18385, loss = 0.36103 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:50:18.124185 ops/training.py:65 2019-01-16 13:50:18.124091: step 18386, loss = 0.35558 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:50:19.089268 ops/training.py:65 2019-01-16 13:50:19.089152: step 18387, loss = 0.37210 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:50:20.051464 ops/training.py:65 2019-01-16 13:50:20.051362: step 18388, loss = 0.29260 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:50:21.014425 ops/training.py:65 2019-01-16 13:50:21.014335: step 18389, loss = 0.22137 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:50:21.975343 ops/training.py:65 2019-01-16 13:50:21.975271: step 18390, loss = 0.32732 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:50:22.936539 ops/training.py:65 2019-01-16 13:50:22.936438: step 18391, loss = 0.29213 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:50:23.898635 ops/training.py:65 2019-01-16 13:50:23.898538: step 18392, loss = 0.32783 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:50:24.859913 ops/training.py:65 2019-01-16 13:50:24.859821: step 18393, loss = 0.29944 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:50:25.822826 ops/training.py:65 2019-01-16 13:50:25.822745: step 18394, loss = 0.28876 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:50:26.786299 ops/training.py:65 2019-01-16 13:50:26.786199: step 18395, loss = 0.21462 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:50:27.749167 ops/training.py:65 2019-01-16 13:50:27.749069: step 18396, loss = 0.31199 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:50:28.711779 ops/training.py:65 2019-01-16 13:50:28.711665: step 18397, loss = 0.24505 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:50:29.675434 ops/training.py:65 2019-01-16 13:50:29.675340: step 18398, loss = 0.27412 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:50:30.637802 ops/training.py:65 2019-01-16 13:50:30.637705: step 18399, loss = 0.40556 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:50:31.600573 ops/training.py:65 2019-01-16 13:50:31.600470: step 18400, loss = 0.41432 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:50:32.565122 ops/training.py:65 2019-01-16 13:50:32.565045: step 18401, loss = 0.39556 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:50:33.531825 ops/training.py:65 2019-01-16 13:50:33.531725: step 18402, loss = 0.40118 (33.1 examples/sec; 0.965 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:50:34.495587 ops/training.py:65 2019-01-16 13:50:34.495487: step 18403, loss = 0.26775 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:50:35.457456 ops/training.py:65 2019-01-16 13:50:35.457358: step 18404, loss = 0.28866 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:50:36.419382 ops/training.py:65 2019-01-16 13:50:36.419288: step 18405, loss = 0.26932 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:50:37.381675 ops/training.py:65 2019-01-16 13:50:37.381575: step 18406, loss = 0.40316 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:50:38.344420 ops/training.py:65 2019-01-16 13:50:38.344319: step 18407, loss = 0.35126 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:50:39.307827 ops/training.py:65 2019-01-16 13:50:39.307731: step 18408, loss = 0.32358 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:50:40.269755 ops/training.py:65 2019-01-16 13:50:40.269655: step 18409, loss = 0.23182 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:50:41.234474 ops/training.py:65 2019-01-16 13:50:41.234379: step 18410, loss = 0.35571 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:50:42.196297 ops/training.py:65 2019-01-16 13:50:42.196217: step 18411, loss = 0.34387 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:50:43.158442 ops/training.py:65 2019-01-16 13:50:43.158344: step 18412, loss = 0.31866 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:50:44.121318 ops/training.py:65 2019-01-16 13:50:44.121236: step 18413, loss = 0.44330 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:50:45.083357 ops/training.py:65 2019-01-16 13:50:45.083263: step 18414, loss = 0.29328 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:50:46.044373 ops/training.py:65 2019-01-16 13:50:46.044275: step 18415, loss = 0.34375 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:50:47.005950 ops/training.py:65 2019-01-16 13:50:47.005862: step 18416, loss = 0.26116 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:50:47.967781 ops/training.py:65 2019-01-16 13:50:47.967711: step 18417, loss = 0.21431 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:50:48.929623 ops/training.py:65 2019-01-16 13:50:48.929550: step 18418, loss = 0.39289 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:50:49.891152 ops/training.py:65 2019-01-16 13:50:49.891090: step 18419, loss = 0.55085 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:50:50.853119 ops/training.py:65 2019-01-16 13:50:50.853011: step 18420, loss = 0.32772 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:50:51.815822 ops/training.py:65 2019-01-16 13:50:51.815726: step 18421, loss = 0.49366 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:50:52.777695 ops/training.py:65 2019-01-16 13:50:52.777611: step 18422, loss = 0.46161 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:50:53.740345 ops/training.py:65 2019-01-16 13:50:53.740269: step 18423, loss = 0.46786 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:50:54.702334 ops/training.py:65 2019-01-16 13:50:54.702234: step 18424, loss = 0.26781 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:50:55.667228 ops/training.py:65 2019-01-16 13:50:55.667129: step 18425, loss = 0.40627 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:50:56.630279 ops/training.py:65 2019-01-16 13:50:56.630182: step 18426, loss = 0.39556 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:50:57.592322 ops/training.py:65 2019-01-16 13:50:57.592226: step 18427, loss = 0.33678 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:50:58.557608 ops/training.py:65 2019-01-16 13:50:58.557493: step 18428, loss = 0.35452 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:50:59.521243 ops/training.py:65 2019-01-16 13:50:59.521148: step 18429, loss = 0.26185 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:51:00.486879 ops/training.py:65 2019-01-16 13:51:00.486803: step 18430, loss = 0.44596 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:51:01.451933 ops/training.py:65 2019-01-16 13:51:01.451825: step 18431, loss = 0.31250 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:51:02.413920 ops/training.py:65 2019-01-16 13:51:02.413834: step 18432, loss = 0.40452 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:51:03.376190 ops/training.py:65 2019-01-16 13:51:03.376092: step 18433, loss = 0.14310 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:51:04.338663 ops/training.py:65 2019-01-16 13:51:04.338559: step 18434, loss = 0.22286 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:51:05.300847 ops/training.py:65 2019-01-16 13:51:05.300736: step 18435, loss = 0.25179 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:51:06.263636 ops/training.py:65 2019-01-16 13:51:06.263520: step 18436, loss = 0.29751 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:51:07.225790 ops/training.py:65 2019-01-16 13:51:07.225687: step 18437, loss = 0.28168 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:51:08.187393 ops/training.py:65 2019-01-16 13:51:08.187296: step 18438, loss = 0.25378 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:51:09.150962 ops/training.py:65 2019-01-16 13:51:09.150844: step 18439, loss = 0.43899 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:51:10.112850 ops/training.py:65 2019-01-16 13:51:10.112755: step 18440, loss = 0.36388 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:51:11.076161 ops/training.py:65 2019-01-16 13:51:11.076040: step 18441, loss = 0.21959 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:51:12.040909 ops/training.py:65 2019-01-16 13:51:12.040806: step 18442, loss = 0.31339 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:51:13.002229 ops/training.py:65 2019-01-16 13:51:13.002131: step 18443, loss = 0.28377 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:51:13.963037 ops/training.py:65 2019-01-16 13:51:13.962963: step 18444, loss = 0.34091 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:51:14.923600 ops/training.py:65 2019-01-16 13:51:14.923509: step 18445, loss = 0.28250 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:51:15.888585 ops/training.py:65 2019-01-16 13:51:15.888516: step 18446, loss = 0.28918 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:51:16.850459 ops/training.py:65 2019-01-16 13:51:16.850361: step 18447, loss = 0.20109 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:51:17.812266 ops/training.py:65 2019-01-16 13:51:17.812191: step 18448, loss = 0.21009 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:51:18.773411 ops/training.py:65 2019-01-16 13:51:18.773321: step 18449, loss = 0.26485 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:51:19.736182 ops/training.py:65 2019-01-16 13:51:19.736083: step 18450, loss = 0.31214 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:51:20.697819 ops/training.py:65 2019-01-16 13:51:20.697715: step 18451, loss = 0.23116 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:51:21.659885 ops/training.py:65 2019-01-16 13:51:21.659775: step 18452, loss = 0.33266 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:51:22.623255 ops/training.py:65 2019-01-16 13:51:22.623176: step 18453, loss = 0.27337 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:51:23.585975 ops/training.py:65 2019-01-16 13:51:23.585881: step 18454, loss = 0.24779 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:51:24.551541 ops/training.py:65 2019-01-16 13:51:24.551469: step 18455, loss = 0.25497 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:51:25.513178 ops/training.py:65 2019-01-16 13:51:25.513131: step 18456, loss = 0.29619 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:51:26.475263 ops/training.py:65 2019-01-16 13:51:26.475172: step 18457, loss = 0.35383 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:51:27.435417 ops/training.py:65 2019-01-16 13:51:27.435351: step 18458, loss = 0.34223 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:51:28.393793 ops/training.py:65 2019-01-16 13:51:28.393736: step 18459, loss = 0.26591 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:51:29.355494 ops/training.py:65 2019-01-16 13:51:29.355454: step 18460, loss = 0.26525 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:51:30.317557 ops/training.py:65 2019-01-16 13:51:30.317520: step 18461, loss = 0.32623 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:51:31.278542 ops/training.py:65 2019-01-16 13:51:31.278487: step 18462, loss = 0.29825 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:51:32.239444 ops/training.py:65 2019-01-16 13:51:32.239412: step 18463, loss = 0.24174 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:51:33.200650 ops/training.py:65 2019-01-16 13:51:33.200618: step 18464, loss = 0.30802 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:51:34.161121 ops/training.py:65 2019-01-16 13:51:34.161064: step 18465, loss = 0.29264 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:51:35.123560 ops/training.py:65 2019-01-16 13:51:35.123524: step 18466, loss = 0.32173 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:51:36.085622 ops/training.py:65 2019-01-16 13:51:36.085584: step 18467, loss = 0.22408 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:51:37.047028 ops/training.py:65 2019-01-16 13:51:37.046931: step 18468, loss = 0.35256 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:51:38.008697 ops/training.py:65 2019-01-16 13:51:38.008597: step 18469, loss = 0.24318 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:51:38.973860 ops/training.py:65 2019-01-16 13:51:38.973759: step 18470, loss = 0.24364 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:51:39.936626 ops/training.py:65 2019-01-16 13:51:39.936514: step 18471, loss = 0.27597 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:51:40.899389 ops/training.py:65 2019-01-16 13:51:40.899324: step 18472, loss = 0.23589 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:51:41.861415 ops/training.py:65 2019-01-16 13:51:41.861315: step 18473, loss = 0.35151 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:51:42.824810 ops/training.py:65 2019-01-16 13:51:42.824711: step 18474, loss = 0.40888 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:51:43.786894 ops/training.py:65 2019-01-16 13:51:43.786820: step 18475, loss = 0.25150 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:51:44.749269 ops/training.py:65 2019-01-16 13:51:44.749182: step 18476, loss = 0.32394 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:51:45.711114 ops/training.py:65 2019-01-16 13:51:45.711042: step 18477, loss = 0.35511 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:51:46.672109 ops/training.py:65 2019-01-16 13:51:46.672067: step 18478, loss = 0.23011 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:51:47.633991 ops/training.py:65 2019-01-16 13:51:47.633949: step 18479, loss = 0.31207 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:51:48.597293 ops/training.py:65 2019-01-16 13:51:48.597261: step 18480, loss = 0.20667 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:51:49.559348 ops/training.py:65 2019-01-16 13:51:49.559267: step 18481, loss = 0.24906 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:51:50.522098 ops/training.py:65 2019-01-16 13:51:50.522001: step 18482, loss = 0.29035 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:51:51.484877 ops/training.py:65 2019-01-16 13:51:51.484781: step 18483, loss = 0.31297 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:51:52.447922 ops/training.py:65 2019-01-16 13:51:52.447826: step 18484, loss = 0.38863 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:51:53.410722 ops/training.py:65 2019-01-16 13:51:53.410629: step 18485, loss = 0.32259 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:51:54.373579 ops/training.py:65 2019-01-16 13:51:54.373483: step 18486, loss = 0.35260 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:51:55.336253 ops/training.py:65 2019-01-16 13:51:55.336155: step 18487, loss = 0.32759 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:51:56.298584 ops/training.py:65 2019-01-16 13:51:56.298483: step 18488, loss = 0.21399 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:51:57.261370 ops/training.py:65 2019-01-16 13:51:57.261278: step 18489, loss = 0.23370 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:51:58.226196 ops/training.py:65 2019-01-16 13:51:58.226102: step 18490, loss = 0.35012 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:51:59.188753 ops/training.py:65 2019-01-16 13:51:59.188659: step 18491, loss = 0.23256 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:52:00.150938 ops/training.py:65 2019-01-16 13:52:00.150854: step 18492, loss = 0.34269 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:52:01.113230 ops/training.py:65 2019-01-16 13:52:01.113178: step 18493, loss = 0.40060 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:52:02.074353 ops/training.py:65 2019-01-16 13:52:02.074305: step 18494, loss = 0.29899 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:52:03.037558 ops/training.py:65 2019-01-16 13:52:03.037482: step 18495, loss = 0.32174 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:52:04.002073 ops/training.py:65 2019-01-16 13:52:04.001983: step 18496, loss = 0.30230 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:52:04.965807 ops/training.py:65 2019-01-16 13:52:04.965715: step 18497, loss = 0.20008 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:52:05.928380 ops/training.py:65 2019-01-16 13:52:05.928282: step 18498, loss = 0.40485 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:52:06.892453 ops/training.py:65 2019-01-16 13:52:06.892370: step 18499, loss = 0.38540 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:52:07.854884 ops/training.py:65 2019-01-16 13:52:07.854790: step 18500, loss = 0.34433 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:52:08.818454 ops/training.py:65 2019-01-16 13:52:08.818354: step 18501, loss = 0.29772 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:52:09.781207 ops/training.py:65 2019-01-16 13:52:09.781118: step 18502, loss = 0.25583 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:52:10.745105 ops/training.py:65 2019-01-16 13:52:10.745011: step 18503, loss = 0.22742 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:52:11.707754 ops/training.py:65 2019-01-16 13:52:11.707658: step 18504, loss = 0.39932 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:52:12.670618 ops/training.py:65 2019-01-16 13:52:12.670522: step 18505, loss = 0.22949 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:52:13.633175 ops/training.py:65 2019-01-16 13:52:13.633082: step 18506, loss = 0.34516 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:52:14.595404 ops/training.py:65 2019-01-16 13:52:14.595325: step 18507, loss = 0.35734 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:52:15.558263 ops/training.py:65 2019-01-16 13:52:15.558188: step 18508, loss = 0.40239 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:52:16.521083 ops/training.py:65 2019-01-16 13:52:16.520982: step 18509, loss = 0.40889 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:52:17.485498 ops/training.py:65 2019-01-16 13:52:17.485430: step 18510, loss = 0.49117 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:52:18.447865 ops/training.py:65 2019-01-16 13:52:18.447777: step 18511, loss = 0.21665 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:52:19.409902 ops/training.py:65 2019-01-16 13:52:19.409852: step 18512, loss = 0.46518 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:52:20.372572 ops/training.py:65 2019-01-16 13:52:20.372480: step 18513, loss = 0.32799 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:52:21.334959 ops/training.py:65 2019-01-16 13:52:21.334872: step 18514, loss = 0.53521 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:52:22.297706 ops/training.py:65 2019-01-16 13:52:22.297604: step 18515, loss = 0.40380 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:52:23.260628 ops/training.py:65 2019-01-16 13:52:23.260527: step 18516, loss = 0.23664 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:52:24.223212 ops/training.py:65 2019-01-16 13:52:24.223115: step 18517, loss = 0.28719 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:52:25.184227 ops/training.py:65 2019-01-16 13:52:25.184129: step 18518, loss = 0.25581 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:52:26.145997 ops/training.py:65 2019-01-16 13:52:26.145903: step 18519, loss = 0.33165 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:52:27.106611 ops/training.py:65 2019-01-16 13:52:27.106523: step 18520, loss = 0.30029 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:52:28.067961 ops/training.py:65 2019-01-16 13:52:28.067874: step 18521, loss = 0.21718 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:52:29.029381 ops/training.py:65 2019-01-16 13:52:29.029284: step 18522, loss = 0.27009 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:52:29.990923 ops/training.py:65 2019-01-16 13:52:29.990864: step 18523, loss = 0.24977 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:52:30.953930 ops/training.py:65 2019-01-16 13:52:30.953872: step 18524, loss = 0.29729 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:52:31.917205 ops/training.py:65 2019-01-16 13:52:31.917113: step 18525, loss = 0.28010 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:52:32.879149 ops/training.py:65 2019-01-16 13:52:32.879078: step 18526, loss = 0.22379 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:52:33.842244 ops/training.py:65 2019-01-16 13:52:33.842159: step 18527, loss = 0.25772 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:52:34.805167 ops/training.py:65 2019-01-16 13:52:34.805073: step 18528, loss = 0.26833 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:52:35.767999 ops/training.py:65 2019-01-16 13:52:35.767903: step 18529, loss = 0.25703 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:52:36.730866 ops/training.py:65 2019-01-16 13:52:36.730766: step 18530, loss = 0.25858 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:52:37.692141 ops/training.py:65 2019-01-16 13:52:37.692078: step 18531, loss = 0.24865 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:52:38.652052 ops/training.py:65 2019-01-16 13:52:38.651953: step 18532, loss = 0.21774 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:52:39.613499 ops/training.py:65 2019-01-16 13:52:39.613403: step 18533, loss = 0.37352 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:52:40.576576 ops/training.py:65 2019-01-16 13:52:40.576472: step 18534, loss = 0.30732 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:52:41.542137 ops/training.py:65 2019-01-16 13:52:41.542039: step 18535, loss = 0.24480 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:52:42.505180 ops/training.py:65 2019-01-16 13:52:42.505080: step 18536, loss = 0.43184 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:52:43.467664 ops/training.py:65 2019-01-16 13:52:43.467564: step 18537, loss = 0.27313 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:52:44.431100 ops/training.py:65 2019-01-16 13:52:44.431017: step 18538, loss = 0.17362 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:52:45.394649 ops/training.py:65 2019-01-16 13:52:45.394550: step 18539, loss = 0.34929 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:52:46.357471 ops/training.py:65 2019-01-16 13:52:46.357370: step 18540, loss = 0.18420 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:52:47.320141 ops/training.py:65 2019-01-16 13:52:47.320045: step 18541, loss = 0.36272 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:52:48.283900 ops/training.py:65 2019-01-16 13:52:48.283802: step 18542, loss = 0.28422 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:52:49.246423 ops/training.py:65 2019-01-16 13:52:49.246327: step 18543, loss = 0.43866 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:52:50.208239 ops/training.py:65 2019-01-16 13:52:50.208143: step 18544, loss = 0.26645 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:52:51.170608 ops/training.py:65 2019-01-16 13:52:51.170510: step 18545, loss = 0.33829 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:52:52.133094 ops/training.py:65 2019-01-16 13:52:52.133005: step 18546, loss = 0.35658 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:52:53.095392 ops/training.py:65 2019-01-16 13:52:53.095298: step 18547, loss = 0.34188 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:52:54.058797 ops/training.py:65 2019-01-16 13:52:54.058715: step 18548, loss = 0.30484 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:52:55.021400 ops/training.py:65 2019-01-16 13:52:55.021304: step 18549, loss = 0.36297 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:52:55.985200 ops/training.py:65 2019-01-16 13:52:55.985095: step 18550, loss = 0.24838 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:52:56.948318 ops/training.py:65 2019-01-16 13:52:56.948226: step 18551, loss = 0.22915 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:52:57.911562 ops/training.py:65 2019-01-16 13:52:57.911464: step 18552, loss = 0.25986 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:52:58.873895 ops/training.py:65 2019-01-16 13:52:58.873796: step 18553, loss = 0.35561 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:52:59.836419 ops/training.py:65 2019-01-16 13:52:59.836330: step 18554, loss = 0.27194 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:53:00.798895 ops/training.py:65 2019-01-16 13:53:00.798799: step 18555, loss = 0.31747 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:53:01.762424 ops/training.py:65 2019-01-16 13:53:01.762335: step 18556, loss = 0.30544 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:53:02.724959 ops/training.py:65 2019-01-16 13:53:02.724862: step 18557, loss = 0.18825 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:53:03.687154 ops/training.py:65 2019-01-16 13:53:03.687060: step 18558, loss = 0.20229 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:53:04.650895 ops/training.py:65 2019-01-16 13:53:04.650796: step 18559, loss = 0.31870 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:53:05.612675 ops/training.py:65 2019-01-16 13:53:05.612585: step 18560, loss = 0.37851 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:53:06.574489 ops/training.py:65 2019-01-16 13:53:06.574394: step 18561, loss = 0.41493 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:53:07.534812 ops/training.py:65 2019-01-16 13:53:07.534738: step 18562, loss = 0.43000 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:53:08.495402 ops/training.py:65 2019-01-16 13:53:08.495339: step 18563, loss = 0.38745 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:53:09.454768 ops/training.py:65 2019-01-16 13:53:09.454679: step 18564, loss = 0.43474 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:53:10.419250 ops/training.py:65 2019-01-16 13:53:10.419150: step 18565, loss = 0.23144 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:53:11.380768 ops/training.py:65 2019-01-16 13:53:11.380671: step 18566, loss = 0.21986 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:53:12.345470 ops/training.py:65 2019-01-16 13:53:12.345368: step 18567, loss = 0.21766 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:53:13.307780 ops/training.py:65 2019-01-16 13:53:13.307710: step 18568, loss = 0.60423 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:53:14.269479 ops/training.py:65 2019-01-16 13:53:14.269405: step 18569, loss = 0.38790 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:53:15.229107 ops/training.py:65 2019-01-16 13:53:15.228994: step 18570, loss = 0.26130 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:53:16.190420 ops/training.py:65 2019-01-16 13:53:16.190316: step 18571, loss = 0.27375 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:53:17.150965 ops/training.py:65 2019-01-16 13:53:17.150885: step 18572, loss = 0.26239 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:53:18.114254 ops/training.py:65 2019-01-16 13:53:18.114157: step 18573, loss = 0.32651 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:53:19.077281 ops/training.py:65 2019-01-16 13:53:19.077206: step 18574, loss = 0.36495 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:53:20.041063 ops/training.py:65 2019-01-16 13:53:20.040987: step 18575, loss = 0.27687 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:53:21.003793 ops/training.py:65 2019-01-16 13:53:21.003736: step 18576, loss = 0.37893 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:53:21.965678 ops/training.py:65 2019-01-16 13:53:21.965581: step 18577, loss = 0.40440 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:53:22.927267 ops/training.py:65 2019-01-16 13:53:22.927169: step 18578, loss = 0.54103 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:53:23.888631 ops/training.py:65 2019-01-16 13:53:23.888534: step 18579, loss = 0.20703 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:53:24.851724 ops/training.py:65 2019-01-16 13:53:24.851671: step 18580, loss = 0.23277 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:53:25.816465 ops/training.py:65 2019-01-16 13:53:25.816432: step 18581, loss = 0.28444 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:53:26.778182 ops/training.py:65 2019-01-16 13:53:26.778148: step 18582, loss = 0.32718 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:53:27.740497 ops/training.py:65 2019-01-16 13:53:27.740463: step 18583, loss = 0.17531 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:53:28.702643 ops/training.py:65 2019-01-16 13:53:28.702612: step 18584, loss = 0.33802 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:53:29.664279 ops/training.py:65 2019-01-16 13:53:29.664184: step 18585, loss = 0.25349 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:53:30.627827 ops/training.py:65 2019-01-16 13:53:30.627782: step 18586, loss = 0.28655 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:53:31.589677 ops/training.py:65 2019-01-16 13:53:31.589644: step 18587, loss = 0.29701 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:53:32.551183 ops/training.py:65 2019-01-16 13:53:32.551088: step 18588, loss = 0.41893 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:53:33.513123 ops/training.py:65 2019-01-16 13:53:33.513041: step 18589, loss = 0.33872 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:53:34.475229 ops/training.py:65 2019-01-16 13:53:34.475132: step 18590, loss = 0.34748 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:53:35.437301 ops/training.py:65 2019-01-16 13:53:35.437212: step 18591, loss = 0.23850 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:53:36.399652 ops/training.py:65 2019-01-16 13:53:36.399562: step 18592, loss = 0.35854 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:53:37.362019 ops/training.py:65 2019-01-16 13:53:37.361925: step 18593, loss = 0.24173 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:53:38.324881 ops/training.py:65 2019-01-16 13:53:38.324783: step 18594, loss = 0.30426 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:53:39.289993 ops/training.py:65 2019-01-16 13:53:39.289887: step 18595, loss = 0.21640 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:53:40.253435 ops/training.py:65 2019-01-16 13:53:40.253341: step 18596, loss = 0.22801 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:53:41.217106 ops/training.py:65 2019-01-16 13:53:41.217006: step 18597, loss = 0.28886 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:53:42.179245 ops/training.py:65 2019-01-16 13:53:42.179141: step 18598, loss = 0.45300 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:53:43.142429 ops/training.py:65 2019-01-16 13:53:43.142323: step 18599, loss = 0.25724 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:53:44.107162 ops/training.py:65 2019-01-16 13:53:44.107082: step 18600, loss = 0.53422 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:53:45.069327 ops/training.py:65 2019-01-16 13:53:45.069226: step 18601, loss = 0.31699 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:53:46.031134 ops/training.py:65 2019-01-16 13:53:46.031040: step 18602, loss = 0.27942 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:53:46.998416 ops/training.py:65 2019-01-16 13:53:46.998314: step 18603, loss = 0.39521 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:53:47.961102 ops/training.py:65 2019-01-16 13:53:47.961012: step 18604, loss = 0.50713 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:53:48.922761 ops/training.py:65 2019-01-16 13:53:48.922683: step 18605, loss = 0.22802 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:53:49.883753 ops/training.py:65 2019-01-16 13:53:49.883678: step 18606, loss = 0.29945 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:53:50.844314 ops/training.py:65 2019-01-16 13:53:50.844235: step 18607, loss = 0.49442 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:53:51.807460 ops/training.py:65 2019-01-16 13:53:51.807375: step 18608, loss = 0.31261 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:53:52.770507 ops/training.py:65 2019-01-16 13:53:52.770414: step 18609, loss = 0.45912 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:53:53.732794 ops/training.py:65 2019-01-16 13:53:53.732672: step 18610, loss = 0.32578 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:53:54.697238 ops/training.py:65 2019-01-16 13:53:54.697138: step 18611, loss = 0.39402 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:53:55.658949 ops/training.py:65 2019-01-16 13:53:55.658853: step 18612, loss = 0.18662 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:53:56.622381 ops/training.py:65 2019-01-16 13:53:56.622284: step 18613, loss = 0.29550 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:53:57.586381 ops/training.py:65 2019-01-16 13:53:57.586284: step 18614, loss = 0.30020 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:53:58.549181 ops/training.py:65 2019-01-16 13:53:58.549082: step 18615, loss = 0.26836 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:53:59.511331 ops/training.py:65 2019-01-16 13:53:59.511242: step 18616, loss = 0.38015 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:54:00.474345 ops/training.py:65 2019-01-16 13:54:00.474247: step 18617, loss = 0.20955 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:54:01.436535 ops/training.py:65 2019-01-16 13:54:01.436452: step 18618, loss = 0.25073 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:54:02.399100 ops/training.py:65 2019-01-16 13:54:02.399006: step 18619, loss = 0.35630 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:54:03.360436 ops/training.py:65 2019-01-16 13:54:03.360378: step 18620, loss = 0.32900 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:54:04.320607 ops/training.py:65 2019-01-16 13:54:04.320538: step 18621, loss = 0.34668 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:54:05.281554 ops/training.py:65 2019-01-16 13:54:05.281494: step 18622, loss = 0.30107 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:54:06.242141 ops/training.py:65 2019-01-16 13:54:06.242062: step 18623, loss = 0.24979 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:54:07.203673 ops/training.py:65 2019-01-16 13:54:07.203596: step 18624, loss = 0.29892 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:54:08.164110 ops/training.py:65 2019-01-16 13:54:08.164027: step 18625, loss = 0.32225 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:54:09.127456 ops/training.py:65 2019-01-16 13:54:09.127377: step 18626, loss = 0.41897 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:54:10.090017 ops/training.py:65 2019-01-16 13:54:10.089922: step 18627, loss = 0.36538 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:54:11.052489 ops/training.py:65 2019-01-16 13:54:11.052392: step 18628, loss = 0.23387 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:54:12.015476 ops/training.py:65 2019-01-16 13:54:12.015375: step 18629, loss = 0.27463 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:54:12.978165 ops/training.py:65 2019-01-16 13:54:12.978073: step 18630, loss = 0.29517 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:54:13.940076 ops/training.py:65 2019-01-16 13:54:13.940004: step 18631, loss = 0.27532 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:54:14.901716 ops/training.py:65 2019-01-16 13:54:14.901622: step 18632, loss = 0.28308 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:54:15.864229 ops/training.py:65 2019-01-16 13:54:15.864153: step 18633, loss = 0.37204 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:54:16.826184 ops/training.py:65 2019-01-16 13:54:16.826090: step 18634, loss = 0.24125 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:54:17.789240 ops/training.py:65 2019-01-16 13:54:17.789169: step 18635, loss = 0.23271 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:54:18.751603 ops/training.py:65 2019-01-16 13:54:18.751506: step 18636, loss = 0.37773 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:54:19.713948 ops/training.py:65 2019-01-16 13:54:19.713861: step 18637, loss = 0.40568 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:54:20.676109 ops/training.py:65 2019-01-16 13:54:20.676018: step 18638, loss = 0.21807 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:54:21.637941 ops/training.py:65 2019-01-16 13:54:21.637850: step 18639, loss = 0.39603 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:54:22.600674 ops/training.py:65 2019-01-16 13:54:22.600587: step 18640, loss = 0.38343 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:54:23.562637 ops/training.py:65 2019-01-16 13:54:23.562538: step 18641, loss = 0.34703 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:54:24.525067 ops/training.py:65 2019-01-16 13:54:24.524974: step 18642, loss = 0.20802 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:54:25.487353 ops/training.py:65 2019-01-16 13:54:25.487261: step 18643, loss = 0.39325 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:54:26.448952 ops/training.py:65 2019-01-16 13:54:26.448858: step 18644, loss = 0.36175 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:54:27.413168 ops/training.py:65 2019-01-16 13:54:27.413096: step 18645, loss = 0.21885 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:54:28.375167 ops/training.py:65 2019-01-16 13:54:28.375068: step 18646, loss = 0.35808 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:54:29.337050 ops/training.py:65 2019-01-16 13:54:29.336964: step 18647, loss = 0.28552 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:54:30.298403 ops/training.py:65 2019-01-16 13:54:30.298312: step 18648, loss = 0.35573 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:54:31.260495 ops/training.py:65 2019-01-16 13:54:31.260416: step 18649, loss = 0.28545 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:54:32.225053 ops/training.py:65 2019-01-16 13:54:32.224952: step 18650, loss = 0.31413 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:54:33.187733 ops/training.py:65 2019-01-16 13:54:33.187655: step 18651, loss = 0.36927 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:54:34.149855 ops/training.py:65 2019-01-16 13:54:34.149765: step 18652, loss = 0.41346 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:54:35.111894 ops/training.py:65 2019-01-16 13:54:35.111801: step 18653, loss = 0.25285 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:54:36.074601 ops/training.py:65 2019-01-16 13:54:36.074505: step 18654, loss = 0.29497 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:54:37.036914 ops/training.py:65 2019-01-16 13:54:37.036814: step 18655, loss = 0.28998 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:54:38.001608 ops/training.py:65 2019-01-16 13:54:38.001510: step 18656, loss = 0.42030 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:54:38.964112 ops/training.py:65 2019-01-16 13:54:38.964014: step 18657, loss = 0.26912 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:54:39.927476 ops/training.py:65 2019-01-16 13:54:39.927388: step 18658, loss = 0.32363 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:54:40.889217 ops/training.py:65 2019-01-16 13:54:40.889119: step 18659, loss = 0.18219 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:54:41.853117 ops/training.py:65 2019-01-16 13:54:41.853025: step 18660, loss = 0.38704 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:54:42.815551 ops/training.py:65 2019-01-16 13:54:42.815452: step 18661, loss = 0.35907 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:54:43.781363 ops/training.py:65 2019-01-16 13:54:43.781265: step 18662, loss = 0.25940 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:54:44.743398 ops/training.py:65 2019-01-16 13:54:44.743318: step 18663, loss = 0.26260 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:54:45.705665 ops/training.py:65 2019-01-16 13:54:45.705590: step 18664, loss = 0.26786 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:54:46.667372 ops/training.py:65 2019-01-16 13:54:46.667271: step 18665, loss = 0.30918 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:54:47.631201 ops/training.py:65 2019-01-16 13:54:47.631102: step 18666, loss = 0.35504 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:54:48.593270 ops/training.py:65 2019-01-16 13:54:48.593197: step 18667, loss = 0.25156 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:54:49.556386 ops/training.py:65 2019-01-16 13:54:49.556292: step 18668, loss = 0.40440 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:54:50.521021 ops/training.py:65 2019-01-16 13:54:50.520892: step 18669, loss = 0.37968 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:54:51.483895 ops/training.py:65 2019-01-16 13:54:51.483801: step 18670, loss = 0.13591 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 13:54:52.446296 ops/training.py:65 2019-01-16 13:54:52.446164: step 18671, loss = 0.29543 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:54:53.408494 ops/training.py:65 2019-01-16 13:54:53.408395: step 18672, loss = 0.30190 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:54:54.371579 ops/training.py:65 2019-01-16 13:54:54.371481: step 18673, loss = 0.33018 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:54:55.333414 ops/training.py:65 2019-01-16 13:54:55.333294: step 18674, loss = 0.27206 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:54:56.296419 ops/training.py:65 2019-01-16 13:54:56.296322: step 18675, loss = 0.30583 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:54:57.258262 ops/training.py:65 2019-01-16 13:54:57.258136: step 18676, loss = 0.34955 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:54:58.220054 ops/training.py:65 2019-01-16 13:54:58.219922: step 18677, loss = 0.31710 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:54:59.183470 ops/training.py:65 2019-01-16 13:54:59.183375: step 18678, loss = 0.50664 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:55:00.147010 ops/training.py:65 2019-01-16 13:55:00.146927: step 18679, loss = 0.44432 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:55:01.110040 ops/training.py:65 2019-01-16 13:55:01.109948: step 18680, loss = 0.39400 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:55:02.075353 ops/training.py:65 2019-01-16 13:55:02.075259: step 18681, loss = 0.27044 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:55:03.037544 ops/training.py:65 2019-01-16 13:55:03.037467: step 18682, loss = 0.37551 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:55:04.000806 ops/training.py:65 2019-01-16 13:55:04.000706: step 18683, loss = 0.30192 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:55:04.962950 ops/training.py:65 2019-01-16 13:55:04.962853: step 18684, loss = 0.30697 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:55:05.925797 ops/training.py:65 2019-01-16 13:55:05.925697: step 18685, loss = 0.50853 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:55:06.890718 ops/training.py:65 2019-01-16 13:55:06.890625: step 18686, loss = 0.26757 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:55:07.853177 ops/training.py:65 2019-01-16 13:55:07.853078: step 18687, loss = 0.33652 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:55:08.816448 ops/training.py:65 2019-01-16 13:55:08.816356: step 18688, loss = 0.28762 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:55:09.779016 ops/training.py:65 2019-01-16 13:55:09.778930: step 18689, loss = 0.28125 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:55:10.741676 ops/training.py:65 2019-01-16 13:55:10.741581: step 18690, loss = 0.37091 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:55:11.703860 ops/training.py:65 2019-01-16 13:55:11.703759: step 18691, loss = 0.28920 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:55:12.666923 ops/training.py:65 2019-01-16 13:55:12.666824: step 18692, loss = 0.46847 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:55:13.629816 ops/training.py:65 2019-01-16 13:55:13.629720: step 18693, loss = 0.29361 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:55:14.592202 ops/training.py:65 2019-01-16 13:55:14.592116: step 18694, loss = 0.36960 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:55:15.554402 ops/training.py:65 2019-01-16 13:55:15.554302: step 18695, loss = 0.31409 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:55:16.516531 ops/training.py:65 2019-01-16 13:55:16.516458: step 18696, loss = 0.34228 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:55:17.478497 ops/training.py:65 2019-01-16 13:55:17.478408: step 18697, loss = 0.24989 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:55:18.441037 ops/training.py:65 2019-01-16 13:55:18.440962: step 18698, loss = 0.23178 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:55:19.403340 ops/training.py:65 2019-01-16 13:55:19.403256: step 18699, loss = 0.25743 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:55:20.365368 ops/training.py:65 2019-01-16 13:55:20.365277: step 18700, loss = 0.24402 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:55:21.325931 ops/training.py:65 2019-01-16 13:55:21.325869: step 18701, loss = 0.19421 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:55:22.284992 ops/training.py:65 2019-01-16 13:55:22.284913: step 18702, loss = 0.39255 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:55:23.245319 ops/training.py:65 2019-01-16 13:55:23.245229: step 18703, loss = 0.37502 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:55:24.206987 ops/training.py:65 2019-01-16 13:55:24.206890: step 18704, loss = 0.47900 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:55:25.167659 ops/training.py:65 2019-01-16 13:55:25.167565: step 18705, loss = 0.34883 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:55:26.128916 ops/training.py:65 2019-01-16 13:55:26.128819: step 18706, loss = 0.31360 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:55:27.090490 ops/training.py:65 2019-01-16 13:55:27.090391: step 18707, loss = 0.25141 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:55:28.052124 ops/training.py:65 2019-01-16 13:55:28.052033: step 18708, loss = 0.28403 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:55:29.013264 ops/training.py:65 2019-01-16 13:55:29.013168: step 18709, loss = 0.30876 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:55:29.974876 ops/training.py:65 2019-01-16 13:55:29.974783: step 18710, loss = 0.34349 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:55:30.939183 ops/training.py:65 2019-01-16 13:55:30.939128: step 18711, loss = 0.27069 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:55:31.900298 ops/training.py:65 2019-01-16 13:55:31.900204: step 18712, loss = 0.27436 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:55:32.860908 ops/training.py:65 2019-01-16 13:55:32.860833: step 18713, loss = 0.29170 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:55:33.822275 ops/training.py:65 2019-01-16 13:55:33.822175: step 18714, loss = 0.20310 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:55:34.783555 ops/training.py:65 2019-01-16 13:55:34.783460: step 18715, loss = 0.33965 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:55:35.745722 ops/training.py:65 2019-01-16 13:55:35.745618: step 18716, loss = 0.31052 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:55:36.707678 ops/training.py:65 2019-01-16 13:55:36.707582: step 18717, loss = 0.60459 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.65625
I0832 2019-01-16 13:55:37.671096 ops/training.py:65 2019-01-16 13:55:37.670998: step 18718, loss = 0.26019 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:55:38.633970 ops/training.py:65 2019-01-16 13:55:38.633891: step 18719, loss = 0.24786 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:55:39.596186 ops/training.py:65 2019-01-16 13:55:39.596101: step 18720, loss = 0.35331 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:55:40.557943 ops/training.py:65 2019-01-16 13:55:40.557845: step 18721, loss = 0.37367 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:55:41.519603 ops/training.py:65 2019-01-16 13:55:41.519500: step 18722, loss = 0.24570 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:55:42.481241 ops/training.py:65 2019-01-16 13:55:42.481150: step 18723, loss = 0.25376 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:55:43.443173 ops/training.py:65 2019-01-16 13:55:43.443045: step 18724, loss = 0.29223 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:55:44.404795 ops/training.py:65 2019-01-16 13:55:44.404712: step 18725, loss = 0.22013 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:55:45.366614 ops/training.py:65 2019-01-16 13:55:45.366519: step 18726, loss = 0.37907 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:55:46.329032 ops/training.py:65 2019-01-16 13:55:46.328926: step 18727, loss = 0.32693 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:55:47.290389 ops/training.py:65 2019-01-16 13:55:47.290291: step 18728, loss = 0.42850 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:55:48.251232 ops/training.py:65 2019-01-16 13:55:48.251148: step 18729, loss = 0.30449 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:55:49.211946 ops/training.py:65 2019-01-16 13:55:49.211860: step 18730, loss = 0.47464 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:55:50.173529 ops/training.py:65 2019-01-16 13:55:50.173438: step 18731, loss = 0.35084 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:55:51.135075 ops/training.py:65 2019-01-16 13:55:51.134979: step 18732, loss = 0.19944 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:55:52.097154 ops/training.py:65 2019-01-16 13:55:52.097059: step 18733, loss = 0.41327 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:55:53.058290 ops/training.py:65 2019-01-16 13:55:53.058193: step 18734, loss = 0.26403 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:55:54.020312 ops/training.py:65 2019-01-16 13:55:54.020233: step 18735, loss = 0.24495 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:55:54.982202 ops/training.py:65 2019-01-16 13:55:54.982122: step 18736, loss = 0.24161 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:55:55.943870 ops/training.py:65 2019-01-16 13:55:55.943796: step 18737, loss = 0.17364 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:55:56.906850 ops/training.py:65 2019-01-16 13:55:56.906752: step 18738, loss = 0.34214 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:55:57.870494 ops/training.py:65 2019-01-16 13:55:57.870394: step 18739, loss = 0.38827 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:55:58.832189 ops/training.py:65 2019-01-16 13:55:58.832095: step 18740, loss = 0.33054 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:55:59.794831 ops/training.py:65 2019-01-16 13:55:59.794738: step 18741, loss = 0.42104 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:56:00.755827 ops/training.py:65 2019-01-16 13:56:00.755733: step 18742, loss = 0.42402 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:56:01.720055 ops/training.py:65 2019-01-16 13:56:01.719993: step 18743, loss = 0.38594 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:56:02.684096 ops/training.py:65 2019-01-16 13:56:02.683999: step 18744, loss = 0.37858 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:56:03.647384 ops/training.py:65 2019-01-16 13:56:03.647309: step 18745, loss = 0.27487 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:56:04.609237 ops/training.py:65 2019-01-16 13:56:04.609137: step 18746, loss = 0.22684 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:56:05.571520 ops/training.py:65 2019-01-16 13:56:05.571421: step 18747, loss = 0.47934 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:56:06.534815 ops/training.py:65 2019-01-16 13:56:06.534714: step 18748, loss = 0.42668 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:56:07.497371 ops/training.py:65 2019-01-16 13:56:07.497268: step 18749, loss = 0.34921 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:56:08.460737 ops/training.py:65 2019-01-16 13:56:08.460636: step 18750, loss = 0.32174 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:56:09.427596 ops/training.py:65 2019-01-16 13:56:09.427511: step 18751, loss = 0.35264 (33.1 examples/sec; 0.966 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:56:10.392558 ops/training.py:65 2019-01-16 13:56:10.392456: step 18752, loss = 0.28375 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:56:11.354285 ops/training.py:65 2019-01-16 13:56:11.354179: step 18753, loss = 0.45177 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:56:12.316424 ops/training.py:65 2019-01-16 13:56:12.316341: step 18754, loss = 0.36726 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:56:13.281654 ops/training.py:65 2019-01-16 13:56:13.281583: step 18755, loss = 0.31486 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:56:14.243857 ops/training.py:65 2019-01-16 13:56:14.243788: step 18756, loss = 0.28039 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:56:15.206179 ops/training.py:65 2019-01-16 13:56:15.206132: step 18757, loss = 0.20582 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:56:16.167193 ops/training.py:65 2019-01-16 13:56:16.167127: step 18758, loss = 0.31832 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:56:17.128072 ops/training.py:65 2019-01-16 13:56:17.127979: step 18759, loss = 0.29377 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:56:18.089607 ops/training.py:65 2019-01-16 13:56:18.089530: step 18760, loss = 0.28335 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:56:19.052271 ops/training.py:65 2019-01-16 13:56:19.052170: step 18761, loss = 0.26657 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:56:20.015455 ops/training.py:65 2019-01-16 13:56:20.015354: step 18762, loss = 0.45119 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:56:20.978324 ops/training.py:65 2019-01-16 13:56:20.978242: step 18763, loss = 0.27336 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:56:21.942688 ops/training.py:65 2019-01-16 13:56:21.942607: step 18764, loss = 0.34004 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:56:22.905591 ops/training.py:65 2019-01-16 13:56:22.905499: step 18765, loss = 0.31035 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:56:23.871220 ops/training.py:65 2019-01-16 13:56:23.871127: step 18766, loss = 0.27377 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:56:24.833685 ops/training.py:65 2019-01-16 13:56:24.833593: step 18767, loss = 0.47611 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:56:25.799351 ops/training.py:65 2019-01-16 13:56:25.799257: step 18768, loss = 0.21558 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:56:26.762504 ops/training.py:65 2019-01-16 13:56:26.762404: step 18769, loss = 0.41383 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:56:27.726307 ops/training.py:65 2019-01-16 13:56:27.726208: step 18770, loss = 0.38720 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:56:28.690385 ops/training.py:65 2019-01-16 13:56:28.690319: step 18771, loss = 0.34622 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:56:29.653197 ops/training.py:65 2019-01-16 13:56:29.653137: step 18772, loss = 0.26483 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:56:30.615480 ops/training.py:65 2019-01-16 13:56:30.615383: step 18773, loss = 0.25624 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:56:31.576868 ops/training.py:65 2019-01-16 13:56:31.576789: step 18774, loss = 0.19192 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:56:32.539916 ops/training.py:65 2019-01-16 13:56:32.539816: step 18775, loss = 0.45281 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:56:33.504318 ops/training.py:65 2019-01-16 13:56:33.504216: step 18776, loss = 0.21374 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:56:34.468775 ops/training.py:65 2019-01-16 13:56:34.468673: step 18777, loss = 0.13052 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:56:35.431751 ops/training.py:65 2019-01-16 13:56:35.431655: step 18778, loss = 0.50135 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 13:56:36.396037 ops/training.py:65 2019-01-16 13:56:36.395936: step 18779, loss = 0.33822 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:56:37.361491 ops/training.py:65 2019-01-16 13:56:37.361391: step 18780, loss = 0.22570 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:56:38.325590 ops/training.py:65 2019-01-16 13:56:38.325490: step 18781, loss = 0.28324 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:56:39.287575 ops/training.py:65 2019-01-16 13:56:39.287478: step 18782, loss = 0.24340 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:56:40.248846 ops/training.py:65 2019-01-16 13:56:40.248783: step 18783, loss = 0.26848 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:56:41.211831 ops/training.py:65 2019-01-16 13:56:41.211784: step 18784, loss = 0.34453 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:56:42.175722 ops/training.py:65 2019-01-16 13:56:42.175679: step 18785, loss = 0.24094 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:56:43.137765 ops/training.py:65 2019-01-16 13:56:43.137706: step 18786, loss = 0.23355 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:56:44.098987 ops/training.py:65 2019-01-16 13:56:44.098909: step 18787, loss = 0.26266 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:56:45.062840 ops/training.py:65 2019-01-16 13:56:45.062751: step 18788, loss = 0.25463 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:56:46.024435 ops/training.py:65 2019-01-16 13:56:46.024360: step 18789, loss = 0.31407 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:56:46.986457 ops/training.py:65 2019-01-16 13:56:46.986367: step 18790, loss = 0.25036 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:56:47.949824 ops/training.py:65 2019-01-16 13:56:47.949755: step 18791, loss = 0.26558 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:56:48.916895 ops/training.py:65 2019-01-16 13:56:48.916804: step 18792, loss = 0.42294 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:56:49.880762 ops/training.py:65 2019-01-16 13:56:49.880674: step 18793, loss = 0.25485 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:56:50.842315 ops/training.py:65 2019-01-16 13:56:50.842222: step 18794, loss = 0.23812 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:56:51.805009 ops/training.py:65 2019-01-16 13:56:51.804915: step 18795, loss = 0.18546 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:56:52.766530 ops/training.py:65 2019-01-16 13:56:52.766432: step 18796, loss = 0.44797 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:56:53.729345 ops/training.py:65 2019-01-16 13:56:53.729251: step 18797, loss = 0.22411 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:56:54.691749 ops/training.py:65 2019-01-16 13:56:54.691662: step 18798, loss = 0.31284 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:56:55.653556 ops/training.py:65 2019-01-16 13:56:55.653489: step 18799, loss = 0.59200 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:56:56.615754 ops/training.py:65 2019-01-16 13:56:56.615666: step 18800, loss = 0.32213 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:56:57.580368 ops/training.py:65 2019-01-16 13:56:57.580276: step 18801, loss = 0.27365 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:56:58.542293 ops/training.py:65 2019-01-16 13:56:58.542192: step 18802, loss = 0.41918 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:56:59.508071 ops/training.py:65 2019-01-16 13:56:59.508007: step 18803, loss = 0.19788 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:57:00.472250 ops/training.py:65 2019-01-16 13:57:00.472205: step 18804, loss = 0.21752 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:57:01.433676 ops/training.py:65 2019-01-16 13:57:01.433609: step 18805, loss = 0.51490 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:57:02.395863 ops/training.py:65 2019-01-16 13:57:02.395769: step 18806, loss = 0.30731 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:57:03.357496 ops/training.py:65 2019-01-16 13:57:03.357425: step 18807, loss = 0.27011 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:57:04.318260 ops/training.py:65 2019-01-16 13:57:04.318202: step 18808, loss = 0.37803 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:57:05.276900 ops/training.py:65 2019-01-16 13:57:05.276830: step 18809, loss = 0.21464 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:57:06.235410 ops/training.py:65 2019-01-16 13:57:06.235345: step 18810, loss = 0.30572 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:57:07.194479 ops/training.py:65 2019-01-16 13:57:07.194442: step 18811, loss = 0.29533 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:57:08.155079 ops/training.py:65 2019-01-16 13:57:08.154986: step 18812, loss = 0.28586 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:57:09.118996 ops/training.py:65 2019-01-16 13:57:09.118956: step 18813, loss = 0.19233 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:57:10.080616 ops/training.py:65 2019-01-16 13:57:10.080580: step 18814, loss = 0.35156 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:57:11.043011 ops/training.py:65 2019-01-16 13:57:11.042979: step 18815, loss = 0.45864 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:57:12.007907 ops/training.py:65 2019-01-16 13:57:12.007875: step 18816, loss = 0.30759 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:57:12.973274 ops/training.py:65 2019-01-16 13:57:12.973239: step 18817, loss = 0.38810 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:57:13.935757 ops/training.py:65 2019-01-16 13:57:13.935725: step 18818, loss = 0.21483 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:57:14.899955 ops/training.py:65 2019-01-16 13:57:14.899916: step 18819, loss = 0.39094 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:57:15.861914 ops/training.py:65 2019-01-16 13:57:15.861882: step 18820, loss = 0.38064 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:57:16.823229 ops/training.py:65 2019-01-16 13:57:16.823196: step 18821, loss = 0.29061 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:57:17.785186 ops/training.py:65 2019-01-16 13:57:17.785154: step 18822, loss = 0.22573 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:57:18.745946 ops/training.py:65 2019-01-16 13:57:18.745862: step 18823, loss = 0.20832 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:57:19.711665 ops/training.py:65 2019-01-16 13:57:19.711627: step 18824, loss = 0.18948 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:57:20.675298 ops/training.py:65 2019-01-16 13:57:20.675262: step 18825, loss = 0.36815 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:57:21.638406 ops/training.py:65 2019-01-16 13:57:21.638374: step 18826, loss = 0.25823 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:57:22.599932 ops/training.py:65 2019-01-16 13:57:22.599839: step 18827, loss = 0.32088 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:57:23.562031 ops/training.py:65 2019-01-16 13:57:23.561932: step 18828, loss = 0.30859 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:57:24.523688 ops/training.py:65 2019-01-16 13:57:24.523587: step 18829, loss = 0.41980 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:57:25.484821 ops/training.py:65 2019-01-16 13:57:25.484723: step 18830, loss = 0.44110 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:57:26.447198 ops/training.py:65 2019-01-16 13:57:26.447105: step 18831, loss = 0.34267 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:57:27.409787 ops/training.py:65 2019-01-16 13:57:27.409662: step 18832, loss = 0.23048 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:57:28.371501 ops/training.py:65 2019-01-16 13:57:28.371434: step 18833, loss = 0.34083 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:57:29.332112 ops/training.py:65 2019-01-16 13:57:29.332037: step 18834, loss = 0.29866 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:57:30.293522 ops/training.py:65 2019-01-16 13:57:30.293457: step 18835, loss = 0.46325 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:57:31.255442 ops/training.py:65 2019-01-16 13:57:31.255391: step 18836, loss = 0.30990 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:57:32.218176 ops/training.py:65 2019-01-16 13:57:32.218078: step 18837, loss = 0.53875 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:57:33.180270 ops/training.py:65 2019-01-16 13:57:33.180192: step 18838, loss = 0.38162 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:57:34.142289 ops/training.py:65 2019-01-16 13:57:34.142187: step 18839, loss = 0.33934 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:57:35.103707 ops/training.py:65 2019-01-16 13:57:35.103611: step 18840, loss = 0.27143 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:57:36.065942 ops/training.py:65 2019-01-16 13:57:36.065838: step 18841, loss = 0.28442 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:57:37.027762 ops/training.py:65 2019-01-16 13:57:37.027666: step 18842, loss = 0.41824 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:57:37.992903 ops/training.py:65 2019-01-16 13:57:37.992803: step 18843, loss = 0.19482 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:57:38.957017 ops/training.py:65 2019-01-16 13:57:38.956914: step 18844, loss = 0.29772 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:57:39.921321 ops/training.py:65 2019-01-16 13:57:39.921224: step 18845, loss = 0.34141 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:57:40.885159 ops/training.py:65 2019-01-16 13:57:40.885059: step 18846, loss = 0.33324 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:57:41.848799 ops/training.py:65 2019-01-16 13:57:41.848698: step 18847, loss = 0.34912 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:57:42.811598 ops/training.py:65 2019-01-16 13:57:42.811506: step 18848, loss = 0.39367 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:57:43.776417 ops/training.py:65 2019-01-16 13:57:43.776318: step 18849, loss = 0.29135 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:57:44.740493 ops/training.py:65 2019-01-16 13:57:44.740410: step 18850, loss = 0.31197 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:57:45.702099 ops/training.py:65 2019-01-16 13:57:45.702002: step 18851, loss = 0.32537 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:57:46.662571 ops/training.py:65 2019-01-16 13:57:46.662495: step 18852, loss = 0.31603 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:57:47.621564 ops/training.py:65 2019-01-16 13:57:47.621493: step 18853, loss = 0.34013 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:57:48.582644 ops/training.py:65 2019-01-16 13:57:48.582602: step 18854, loss = 0.39727 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:57:49.547537 ops/training.py:65 2019-01-16 13:57:49.547480: step 18855, loss = 0.14915 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:57:50.508575 ops/training.py:65 2019-01-16 13:57:50.508487: step 18856, loss = 0.34558 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:57:51.469134 ops/training.py:65 2019-01-16 13:57:51.469043: step 18857, loss = 0.34567 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:57:52.428908 ops/training.py:65 2019-01-16 13:57:52.428845: step 18858, loss = 0.32673 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:57:53.390086 ops/training.py:65 2019-01-16 13:57:53.390053: step 18859, loss = 0.29765 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:57:54.351694 ops/training.py:65 2019-01-16 13:57:54.351664: step 18860, loss = 0.39254 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:57:55.313596 ops/training.py:65 2019-01-16 13:57:55.313561: step 18861, loss = 0.32196 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:57:56.275861 ops/training.py:65 2019-01-16 13:57:56.275823: step 18862, loss = 0.22435 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:57:57.239762 ops/training.py:65 2019-01-16 13:57:57.239729: step 18863, loss = 0.49475 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:57:58.200907 ops/training.py:65 2019-01-16 13:57:58.200872: step 18864, loss = 0.32488 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:57:59.161704 ops/training.py:65 2019-01-16 13:57:59.161607: step 18865, loss = 0.31675 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:58:00.126765 ops/training.py:65 2019-01-16 13:58:00.126702: step 18866, loss = 0.39148 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:58:01.091445 ops/training.py:65 2019-01-16 13:58:01.091404: step 18867, loss = 0.25688 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:58:02.054425 ops/training.py:65 2019-01-16 13:58:02.054387: step 18868, loss = 0.22664 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:58:03.016585 ops/training.py:65 2019-01-16 13:58:03.016545: step 18869, loss = 0.31679 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:58:03.978911 ops/training.py:65 2019-01-16 13:58:03.978842: step 18870, loss = 0.31012 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:58:04.940869 ops/training.py:65 2019-01-16 13:58:04.940833: step 18871, loss = 0.23268 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:58:05.902030 ops/training.py:65 2019-01-16 13:58:05.901997: step 18872, loss = 0.31988 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:58:06.862636 ops/training.py:65 2019-01-16 13:58:06.862533: step 18873, loss = 0.21505 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:58:07.826368 ops/training.py:65 2019-01-16 13:58:07.826316: step 18874, loss = 0.31729 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:58:08.786537 ops/training.py:65 2019-01-16 13:58:08.786465: step 18875, loss = 0.30084 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:58:09.745023 ops/training.py:65 2019-01-16 13:58:09.744960: step 18876, loss = 0.19475 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:58:10.703694 ops/training.py:65 2019-01-16 13:58:10.703625: step 18877, loss = 0.25745 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:58:11.667981 ops/training.py:65 2019-01-16 13:58:11.667941: step 18878, loss = 0.24975 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:58:12.631233 ops/training.py:65 2019-01-16 13:58:12.631200: step 18879, loss = 0.32610 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:58:13.592918 ops/training.py:65 2019-01-16 13:58:13.592886: step 18880, loss = 0.44376 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:58:14.554298 ops/training.py:65 2019-01-16 13:58:14.554259: step 18881, loss = 0.25102 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:58:15.515329 ops/training.py:65 2019-01-16 13:58:15.515296: step 18882, loss = 0.33152 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:58:16.475781 ops/training.py:65 2019-01-16 13:58:16.475749: step 18883, loss = 0.29257 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:58:17.436835 ops/training.py:65 2019-01-16 13:58:17.436803: step 18884, loss = 0.37953 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:58:18.398148 ops/training.py:65 2019-01-16 13:58:18.398116: step 18885, loss = 0.31878 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:58:19.358397 ops/training.py:65 2019-01-16 13:58:19.358366: step 18886, loss = 0.26530 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:58:20.321987 ops/training.py:65 2019-01-16 13:58:20.321954: step 18887, loss = 0.28855 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:58:21.284675 ops/training.py:65 2019-01-16 13:58:21.284644: step 18888, loss = 0.23567 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:58:22.247801 ops/training.py:65 2019-01-16 13:58:22.247770: step 18889, loss = 0.41170 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:58:23.209839 ops/training.py:65 2019-01-16 13:58:23.209806: step 18890, loss = 0.22596 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:58:24.175869 ops/training.py:65 2019-01-16 13:58:24.175837: step 18891, loss = 0.24704 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:58:25.140389 ops/training.py:65 2019-01-16 13:58:25.140347: step 18892, loss = 0.16260 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:58:26.101841 ops/training.py:65 2019-01-16 13:58:26.101808: step 18893, loss = 0.48445 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:58:27.065188 ops/training.py:65 2019-01-16 13:58:27.065156: step 18894, loss = 0.26836 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:58:28.026861 ops/training.py:65 2019-01-16 13:58:28.026777: step 18895, loss = 0.38660 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:58:28.987828 ops/training.py:65 2019-01-16 13:58:28.987753: step 18896, loss = 0.37407 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:58:29.950624 ops/training.py:65 2019-01-16 13:58:29.950564: step 18897, loss = 0.35286 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:58:30.912166 ops/training.py:65 2019-01-16 13:58:30.912109: step 18898, loss = 0.21995 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:58:31.875987 ops/training.py:65 2019-01-16 13:58:31.875948: step 18899, loss = 0.29652 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:58:32.839275 ops/training.py:65 2019-01-16 13:58:32.839201: step 18900, loss = 0.18415 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:58:33.800546 ops/training.py:65 2019-01-16 13:58:33.800474: step 18901, loss = 0.45035 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:58:34.763735 ops/training.py:65 2019-01-16 13:58:34.763691: step 18902, loss = 0.20281 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:58:35.724553 ops/training.py:65 2019-01-16 13:58:35.724498: step 18903, loss = 0.18438 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:58:36.687437 ops/training.py:65 2019-01-16 13:58:36.687401: step 18904, loss = 0.41000 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:58:37.651175 ops/training.py:65 2019-01-16 13:58:37.651089: step 18905, loss = 0.41927 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:58:38.614595 ops/training.py:65 2019-01-16 13:58:38.614509: step 18906, loss = 0.35929 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:58:39.576671 ops/training.py:65 2019-01-16 13:58:39.576583: step 18907, loss = 0.29713 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:58:40.539296 ops/training.py:65 2019-01-16 13:58:40.539209: step 18908, loss = 0.28084 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:58:41.500997 ops/training.py:65 2019-01-16 13:58:41.500902: step 18909, loss = 0.30360 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:58:42.462421 ops/training.py:65 2019-01-16 13:58:42.462327: step 18910, loss = 0.26353 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:58:43.424306 ops/training.py:65 2019-01-16 13:58:43.424217: step 18911, loss = 0.33417 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:58:44.386320 ops/training.py:65 2019-01-16 13:58:44.386239: step 18912, loss = 0.28167 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:58:45.348567 ops/training.py:65 2019-01-16 13:58:45.348476: step 18913, loss = 0.40548 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:58:46.312753 ops/training.py:65 2019-01-16 13:58:46.312697: step 18914, loss = 0.25933 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:58:47.276779 ops/training.py:65 2019-01-16 13:58:47.276742: step 18915, loss = 0.32648 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:58:48.237983 ops/training.py:65 2019-01-16 13:58:48.237941: step 18916, loss = 0.29322 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:58:49.200625 ops/training.py:65 2019-01-16 13:58:49.200524: step 18917, loss = 0.49869 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:58:50.161765 ops/training.py:65 2019-01-16 13:58:50.161694: step 18918, loss = 0.30234 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:58:51.123859 ops/training.py:65 2019-01-16 13:58:51.123808: step 18919, loss = 0.22922 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:58:52.088307 ops/training.py:65 2019-01-16 13:58:52.088272: step 18920, loss = 0.17880 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:58:53.052423 ops/training.py:65 2019-01-16 13:58:53.052342: step 18921, loss = 0.38822 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:58:54.015148 ops/training.py:65 2019-01-16 13:58:54.015058: step 18922, loss = 0.19530 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:58:54.978046 ops/training.py:65 2019-01-16 13:58:54.977952: step 18923, loss = 0.37118 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:58:55.939794 ops/training.py:65 2019-01-16 13:58:55.939701: step 18924, loss = 0.30879 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:58:56.903058 ops/training.py:65 2019-01-16 13:58:56.902961: step 18925, loss = 0.32441 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:58:57.867111 ops/training.py:65 2019-01-16 13:58:57.867022: step 18926, loss = 0.35484 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:58:58.830378 ops/training.py:65 2019-01-16 13:58:58.830291: step 18927, loss = 0.31464 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:58:59.793343 ops/training.py:65 2019-01-16 13:58:59.793264: step 18928, loss = 0.41768 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:59:00.758052 ops/training.py:65 2019-01-16 13:59:00.757975: step 18929, loss = 0.46475 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:59:01.720174 ops/training.py:65 2019-01-16 13:59:01.720098: step 18930, loss = 0.37472 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:59:02.681743 ops/training.py:65 2019-01-16 13:59:02.681659: step 18931, loss = 0.23085 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:59:03.643006 ops/training.py:65 2019-01-16 13:59:03.642929: step 18932, loss = 0.30790 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:59:04.605178 ops/training.py:65 2019-01-16 13:59:04.605088: step 18933, loss = 0.20556 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:59:05.568639 ops/training.py:65 2019-01-16 13:59:05.568565: step 18934, loss = 0.27391 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:59:06.529929 ops/training.py:65 2019-01-16 13:59:06.529854: step 18935, loss = 0.17992 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:59:07.491738 ops/training.py:65 2019-01-16 13:59:07.491667: step 18936, loss = 0.53683 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 13:59:08.453201 ops/training.py:65 2019-01-16 13:59:08.453115: step 18937, loss = 0.41471 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:59:09.415904 ops/training.py:65 2019-01-16 13:59:09.415816: step 18938, loss = 0.29408 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:59:10.378307 ops/training.py:65 2019-01-16 13:59:10.378217: step 18939, loss = 0.36474 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:59:11.340971 ops/training.py:65 2019-01-16 13:59:11.340895: step 18940, loss = 0.39396 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:59:12.303658 ops/training.py:65 2019-01-16 13:59:12.303567: step 18941, loss = 0.44197 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:59:13.266425 ops/training.py:65 2019-01-16 13:59:13.266331: step 18942, loss = 0.39974 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:59:14.229024 ops/training.py:65 2019-01-16 13:59:14.228947: step 18943, loss = 0.43574 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:59:15.190788 ops/training.py:65 2019-01-16 13:59:15.190705: step 18944, loss = 0.30358 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:59:16.153638 ops/training.py:65 2019-01-16 13:59:16.153567: step 18945, loss = 0.31289 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:59:17.115577 ops/training.py:65 2019-01-16 13:59:17.115504: step 18946, loss = 0.29164 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:59:18.075523 ops/training.py:65 2019-01-16 13:59:18.075474: step 18947, loss = 0.28024 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:59:19.036620 ops/training.py:65 2019-01-16 13:59:19.036557: step 18948, loss = 0.33682 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:59:19.998118 ops/training.py:65 2019-01-16 13:59:19.998059: step 18949, loss = 0.39655 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:59:20.958758 ops/training.py:65 2019-01-16 13:59:20.958687: step 18950, loss = 0.33539 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:59:21.919724 ops/training.py:65 2019-01-16 13:59:21.919633: step 18951, loss = 0.25057 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:59:22.884510 ops/training.py:65 2019-01-16 13:59:22.884415: step 18952, loss = 0.27466 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:59:23.847465 ops/training.py:65 2019-01-16 13:59:23.847362: step 18953, loss = 0.47048 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 13:59:24.809282 ops/training.py:65 2019-01-16 13:59:24.809193: step 18954, loss = 0.33871 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:59:25.770719 ops/training.py:65 2019-01-16 13:59:25.770628: step 18955, loss = 0.48970 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:59:26.732224 ops/training.py:65 2019-01-16 13:59:26.732133: step 18956, loss = 0.43292 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 13:59:27.694095 ops/training.py:65 2019-01-16 13:59:27.694015: step 18957, loss = 0.25097 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:59:28.655861 ops/training.py:65 2019-01-16 13:59:28.655771: step 18958, loss = 0.24535 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:59:29.616973 ops/training.py:65 2019-01-16 13:59:29.616913: step 18959, loss = 0.29816 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:59:30.580352 ops/training.py:65 2019-01-16 13:59:30.580309: step 18960, loss = 0.24967 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:59:31.542249 ops/training.py:65 2019-01-16 13:59:31.542155: step 18961, loss = 0.26446 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:59:32.505954 ops/training.py:65 2019-01-16 13:59:32.505899: step 18962, loss = 0.26313 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:59:33.470946 ops/training.py:65 2019-01-16 13:59:33.470895: step 18963, loss = 0.25381 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:59:34.432464 ops/training.py:65 2019-01-16 13:59:34.432379: step 18964, loss = 0.27114 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:59:35.394574 ops/training.py:65 2019-01-16 13:59:35.394482: step 18965, loss = 0.44597 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:59:36.355463 ops/training.py:65 2019-01-16 13:59:36.355421: step 18966, loss = 0.23333 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 13:59:37.316145 ops/training.py:65 2019-01-16 13:59:37.316108: step 18967, loss = 0.31227 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:59:38.277171 ops/training.py:65 2019-01-16 13:59:38.277111: step 18968, loss = 0.32321 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:59:39.238725 ops/training.py:65 2019-01-16 13:59:39.238666: step 18969, loss = 0.28913 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:59:40.200723 ops/training.py:65 2019-01-16 13:59:40.200657: step 18970, loss = 0.25305 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:59:41.165261 ops/training.py:65 2019-01-16 13:59:41.165202: step 18971, loss = 0.31504 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:59:42.128754 ops/training.py:65 2019-01-16 13:59:42.128714: step 18972, loss = 0.28611 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:59:43.092362 ops/training.py:65 2019-01-16 13:59:43.092326: step 18973, loss = 0.27843 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:59:44.055733 ops/training.py:65 2019-01-16 13:59:44.055686: step 18974, loss = 0.29115 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:59:45.019932 ops/training.py:65 2019-01-16 13:59:45.019879: step 18975, loss = 0.24801 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:59:45.983042 ops/training.py:65 2019-01-16 13:59:45.982982: step 18976, loss = 0.38044 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 13:59:46.947162 ops/training.py:65 2019-01-16 13:59:46.947128: step 18977, loss = 0.36957 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:59:47.910207 ops/training.py:65 2019-01-16 13:59:47.910175: step 18978, loss = 0.34406 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:59:48.873668 ops/training.py:65 2019-01-16 13:59:48.873635: step 18979, loss = 0.31309 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:59:49.835084 ops/training.py:65 2019-01-16 13:59:49.835040: step 18980, loss = 0.20189 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:59:50.796349 ops/training.py:65 2019-01-16 13:59:50.796317: step 18981, loss = 0.22036 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:59:51.757932 ops/training.py:65 2019-01-16 13:59:51.757899: step 18982, loss = 0.29528 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:59:52.718530 ops/training.py:65 2019-01-16 13:59:52.718437: step 18983, loss = 0.21809 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:59:53.683610 ops/training.py:65 2019-01-16 13:59:53.683531: step 18984, loss = 0.35486 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:59:54.647951 ops/training.py:65 2019-01-16 13:59:54.647892: step 18985, loss = 0.24685 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 13:59:55.608728 ops/training.py:65 2019-01-16 13:59:55.608675: step 18986, loss = 0.29800 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:59:56.573285 ops/training.py:65 2019-01-16 13:59:56.573240: step 18987, loss = 0.34810 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 13:59:57.536546 ops/training.py:65 2019-01-16 13:59:57.536506: step 18988, loss = 0.25723 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 13:59:58.500224 ops/training.py:65 2019-01-16 13:59:58.500187: step 18989, loss = 0.24124 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 13:59:59.461058 ops/training.py:65 2019-01-16 13:59:59.461025: step 18990, loss = 0.43514 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:00:00.423505 ops/training.py:65 2019-01-16 14:00:00.423471: step 18991, loss = 0.32519 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:00:01.387172 ops/training.py:65 2019-01-16 14:00:01.387142: step 18992, loss = 0.37708 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:00:02.349115 ops/training.py:65 2019-01-16 14:00:02.349085: step 18993, loss = 0.24381 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:00:03.311035 ops/training.py:65 2019-01-16 14:00:03.311002: step 18994, loss = 0.26067 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:00:04.272712 ops/training.py:65 2019-01-16 14:00:04.272679: step 18995, loss = 0.23337 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:00:05.233970 ops/training.py:65 2019-01-16 14:00:05.233938: step 18996, loss = 0.23610 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:00:06.196174 ops/training.py:65 2019-01-16 14:00:06.196139: step 18997, loss = 0.19045 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:00:07.157287 ops/training.py:65 2019-01-16 14:00:07.157253: step 18998, loss = 0.34072 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:00:08.118426 ops/training.py:65 2019-01-16 14:00:08.118390: step 18999, loss = 0.26922 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:00:09.083673 ops/training.py:65 2019-01-16 14:00:09.083631: step 19000, loss = 0.22604 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:00:10.046409 ops/training.py:65 2019-01-16 14:00:10.046369: step 19001, loss = 0.24363 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:00:11.010026 ops/training.py:65 2019-01-16 14:00:11.009968: step 19002, loss = 0.43908 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:00:11.971962 ops/training.py:65 2019-01-16 14:00:11.971926: step 19003, loss = 0.43224 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 14:00:12.934560 ops/training.py:65 2019-01-16 14:00:12.934528: step 19004, loss = 0.34909 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:00:13.897899 ops/training.py:65 2019-01-16 14:00:13.897866: step 19005, loss = 0.36297 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:00:14.859310 ops/training.py:65 2019-01-16 14:00:14.859268: step 19006, loss = 0.32775 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:00:15.820858 ops/training.py:65 2019-01-16 14:00:15.820826: step 19007, loss = 0.24254 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:00:16.781934 ops/training.py:65 2019-01-16 14:00:16.781903: step 19008, loss = 0.21542 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:00:17.743347 ops/training.py:65 2019-01-16 14:00:17.743316: step 19009, loss = 0.17798 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:00:18.704432 ops/training.py:65 2019-01-16 14:00:18.704399: step 19010, loss = 0.27496 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:00:19.665632 ops/training.py:65 2019-01-16 14:00:19.665599: step 19011, loss = 0.26149 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:00:20.626723 ops/training.py:65 2019-01-16 14:00:20.626692: step 19012, loss = 0.31805 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:00:21.587273 ops/training.py:65 2019-01-16 14:00:21.587241: step 19013, loss = 0.14983 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:00:22.547786 ops/training.py:65 2019-01-16 14:00:22.547753: step 19014, loss = 0.31508 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:00:23.508738 ops/training.py:65 2019-01-16 14:00:23.508707: step 19015, loss = 0.27919 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:00:24.469950 ops/training.py:65 2019-01-16 14:00:24.469918: step 19016, loss = 0.35672 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:00:25.430866 ops/training.py:65 2019-01-16 14:00:25.430820: step 19017, loss = 0.32073 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:00:26.391944 ops/training.py:65 2019-01-16 14:00:26.391893: step 19018, loss = 0.24225 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:00:27.353315 ops/training.py:65 2019-01-16 14:00:27.353281: step 19019, loss = 0.32003 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:00:28.314315 ops/training.py:65 2019-01-16 14:00:28.314282: step 19020, loss = 0.22047 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:00:29.274979 ops/training.py:65 2019-01-16 14:00:29.274947: step 19021, loss = 0.48729 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:00:30.235477 ops/training.py:65 2019-01-16 14:00:30.235445: step 19022, loss = 0.32532 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:00:31.195287 ops/training.py:65 2019-01-16 14:00:31.195260: step 19023, loss = 0.24615 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:00:32.155918 ops/training.py:65 2019-01-16 14:00:32.155886: step 19024, loss = 0.36702 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:00:33.118683 ops/training.py:65 2019-01-16 14:00:33.118648: step 19025, loss = 0.39603 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:00:34.083810 ops/training.py:65 2019-01-16 14:00:34.083776: step 19026, loss = 0.28732 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:00:35.047082 ops/training.py:65 2019-01-16 14:00:35.047052: step 19027, loss = 0.21830 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:00:36.007594 ops/training.py:65 2019-01-16 14:00:36.007503: step 19028, loss = 0.33247 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:00:36.968418 ops/training.py:65 2019-01-16 14:00:36.968331: step 19029, loss = 0.30390 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:00:37.932670 ops/training.py:65 2019-01-16 14:00:37.932624: step 19030, loss = 0.23434 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:00:38.896110 ops/training.py:65 2019-01-16 14:00:38.896062: step 19031, loss = 0.21236 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:00:39.857221 ops/training.py:65 2019-01-16 14:00:39.857180: step 19032, loss = 0.46880 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 14:00:40.817524 ops/training.py:65 2019-01-16 14:00:40.817454: step 19033, loss = 0.38863 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:00:41.778255 ops/training.py:65 2019-01-16 14:00:41.778221: step 19034, loss = 0.40664 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:00:42.740064 ops/training.py:65 2019-01-16 14:00:42.740029: step 19035, loss = 0.54814 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:00:43.699927 ops/training.py:65 2019-01-16 14:00:43.699834: step 19036, loss = 0.20695 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:00:44.659418 ops/training.py:65 2019-01-16 14:00:44.659347: step 19037, loss = 0.37153 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:00:45.623090 ops/training.py:65 2019-01-16 14:00:45.623056: step 19038, loss = 0.31849 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:00:46.586544 ops/training.py:65 2019-01-16 14:00:46.586498: step 19039, loss = 0.18839 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:00:47.549532 ops/training.py:65 2019-01-16 14:00:47.549498: step 19040, loss = 0.34039 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:00:48.510033 ops/training.py:65 2019-01-16 14:00:48.510000: step 19041, loss = 0.33706 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:00:49.471299 ops/training.py:65 2019-01-16 14:00:49.471266: step 19042, loss = 0.42904 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:00:50.434432 ops/training.py:65 2019-01-16 14:00:50.434399: step 19043, loss = 0.31283 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:00:51.397543 ops/training.py:65 2019-01-16 14:00:51.397510: step 19044, loss = 0.24494 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:00:52.359207 ops/training.py:65 2019-01-16 14:00:52.359128: step 19045, loss = 0.26884 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:00:53.320598 ops/training.py:65 2019-01-16 14:00:53.320521: step 19046, loss = 0.25136 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:00:54.283912 ops/training.py:65 2019-01-16 14:00:54.283834: step 19047, loss = 0.17095 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:00:55.247293 ops/training.py:65 2019-01-16 14:00:55.247229: step 19048, loss = 0.24381 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:00:56.212623 ops/training.py:65 2019-01-16 14:00:56.212548: step 19049, loss = 0.38263 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:00:57.172194 ops/training.py:65 2019-01-16 14:00:57.172157: step 19050, loss = 0.20745 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:00:58.136843 ops/training.py:65 2019-01-16 14:00:58.136793: step 19051, loss = 0.32550 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:00:59.100351 ops/training.py:65 2019-01-16 14:00:59.100284: step 19052, loss = 0.42939 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:01:00.064165 ops/training.py:65 2019-01-16 14:01:00.064118: step 19053, loss = 0.34130 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:01:01.025312 ops/training.py:65 2019-01-16 14:01:01.025278: step 19054, loss = 0.40460 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:01:01.986489 ops/training.py:65 2019-01-16 14:01:01.986430: step 19055, loss = 0.40739 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:01:02.948257 ops/training.py:65 2019-01-16 14:01:02.948202: step 19056, loss = 0.21678 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:01:03.909071 ops/training.py:65 2019-01-16 14:01:03.909003: step 19057, loss = 0.25566 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:01:04.870441 ops/training.py:65 2019-01-16 14:01:04.870382: step 19058, loss = 0.34575 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:01:05.831239 ops/training.py:65 2019-01-16 14:01:05.831174: step 19059, loss = 0.34957 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:01:06.792542 ops/training.py:65 2019-01-16 14:01:06.792501: step 19060, loss = 0.20288 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:01:07.753965 ops/training.py:65 2019-01-16 14:01:07.753894: step 19061, loss = 0.31891 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:01:08.715511 ops/training.py:65 2019-01-16 14:01:08.715439: step 19062, loss = 0.32922 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:01:09.676319 ops/training.py:65 2019-01-16 14:01:09.676250: step 19063, loss = 0.25747 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:01:10.637664 ops/training.py:65 2019-01-16 14:01:10.637603: step 19064, loss = 0.45042 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:01:11.598769 ops/training.py:65 2019-01-16 14:01:11.598709: step 19065, loss = 0.34055 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:01:12.559838 ops/training.py:65 2019-01-16 14:01:12.559795: step 19066, loss = 0.25117 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:01:13.521420 ops/training.py:65 2019-01-16 14:01:13.521381: step 19067, loss = 0.22761 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:01:14.482641 ops/training.py:65 2019-01-16 14:01:14.482590: step 19068, loss = 0.27858 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:01:15.443995 ops/training.py:65 2019-01-16 14:01:15.443961: step 19069, loss = 0.20399 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:01:16.405573 ops/training.py:65 2019-01-16 14:01:16.405540: step 19070, loss = 0.30809 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:01:17.366690 ops/training.py:65 2019-01-16 14:01:17.366659: step 19071, loss = 0.29357 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:01:18.328974 ops/training.py:65 2019-01-16 14:01:18.328938: step 19072, loss = 0.17113 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:01:19.290425 ops/training.py:65 2019-01-16 14:01:19.290392: step 19073, loss = 0.23944 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:01:20.252405 ops/training.py:65 2019-01-16 14:01:20.252372: step 19074, loss = 0.29455 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:01:21.213792 ops/training.py:65 2019-01-16 14:01:21.213730: step 19075, loss = 0.27843 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:01:22.175750 ops/training.py:65 2019-01-16 14:01:22.175668: step 19076, loss = 0.23492 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:01:23.137276 ops/training.py:65 2019-01-16 14:01:23.137194: step 19077, loss = 0.29406 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:01:24.098840 ops/training.py:65 2019-01-16 14:01:24.098770: step 19078, loss = 0.21488 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:01:25.060646 ops/training.py:65 2019-01-16 14:01:25.060608: step 19079, loss = 0.25602 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:01:26.021740 ops/training.py:65 2019-01-16 14:01:26.021707: step 19080, loss = 0.26138 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:01:26.981995 ops/training.py:65 2019-01-16 14:01:26.981962: step 19081, loss = 0.36726 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:01:27.943372 ops/training.py:65 2019-01-16 14:01:27.943327: step 19082, loss = 0.34422 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:01:28.903960 ops/training.py:65 2019-01-16 14:01:28.903908: step 19083, loss = 0.33761 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:01:29.865051 ops/training.py:65 2019-01-16 14:01:29.864979: step 19084, loss = 0.38572 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:01:30.826523 ops/training.py:65 2019-01-16 14:01:30.826455: step 19085, loss = 0.25199 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:01:31.788869 ops/training.py:65 2019-01-16 14:01:31.788829: step 19086, loss = 0.34085 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:01:32.749766 ops/training.py:65 2019-01-16 14:01:32.749735: step 19087, loss = 0.22346 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:01:33.711346 ops/training.py:65 2019-01-16 14:01:33.711306: step 19088, loss = 0.25651 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:01:34.671980 ops/training.py:65 2019-01-16 14:01:34.671946: step 19089, loss = 0.21788 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:01:35.632914 ops/training.py:65 2019-01-16 14:01:35.632877: step 19090, loss = 0.27725 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:01:36.593040 ops/training.py:65 2019-01-16 14:01:36.592946: step 19091, loss = 0.22551 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:01:37.553820 ops/training.py:65 2019-01-16 14:01:37.553721: step 19092, loss = 0.24799 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:01:38.513835 ops/training.py:65 2019-01-16 14:01:38.513758: step 19093, loss = 0.20204 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:01:39.472173 ops/training.py:65 2019-01-16 14:01:39.472108: step 19094, loss = 0.25779 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:01:40.430189 ops/training.py:65 2019-01-16 14:01:40.430115: step 19095, loss = 0.24859 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:01:41.388678 ops/training.py:65 2019-01-16 14:01:41.388616: step 19096, loss = 0.22704 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:01:42.347036 ops/training.py:65 2019-01-16 14:01:42.346976: step 19097, loss = 0.24819 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:01:43.310177 ops/training.py:65 2019-01-16 14:01:43.310140: step 19098, loss = 0.15027 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:01:44.272762 ops/training.py:65 2019-01-16 14:01:44.272699: step 19099, loss = 0.37789 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:01:45.233376 ops/training.py:65 2019-01-16 14:01:45.233340: step 19100, loss = 0.37856 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:01:46.193487 ops/training.py:65 2019-01-16 14:01:46.193443: step 19101, loss = 0.27815 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:01:47.154508 ops/training.py:65 2019-01-16 14:01:47.154436: step 19102, loss = 0.29872 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:01:48.115301 ops/training.py:65 2019-01-16 14:01:48.115204: step 19103, loss = 0.24240 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:01:49.075548 ops/training.py:65 2019-01-16 14:01:49.075474: step 19104, loss = 0.20893 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:01:50.034477 ops/training.py:65 2019-01-16 14:01:50.034405: step 19105, loss = 0.18373 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:01:50.993938 ops/training.py:65 2019-01-16 14:01:50.993849: step 19106, loss = 0.24282 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:01:51.953437 ops/training.py:65 2019-01-16 14:01:51.953363: step 19107, loss = 0.24247 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:01:52.916698 ops/training.py:65 2019-01-16 14:01:52.916618: step 19108, loss = 0.30061 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:01:53.881484 ops/training.py:65 2019-01-16 14:01:53.881406: step 19109, loss = 0.35055 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:01:54.845108 ops/training.py:65 2019-01-16 14:01:54.845022: step 19110, loss = 0.31331 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:01:55.805486 ops/training.py:65 2019-01-16 14:01:55.805398: step 19111, loss = 0.37072 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:01:56.765709 ops/training.py:65 2019-01-16 14:01:56.765636: step 19112, loss = 0.32504 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:01:57.729648 ops/training.py:65 2019-01-16 14:01:57.729612: step 19113, loss = 0.23529 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:01:58.694559 ops/training.py:65 2019-01-16 14:01:58.694474: step 19114, loss = 0.47684 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:01:59.655970 ops/training.py:65 2019-01-16 14:01:59.655893: step 19115, loss = 0.27366 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:02:00.616685 ops/training.py:65 2019-01-16 14:02:00.616609: step 19116, loss = 0.41338 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:02:01.582507 ops/training.py:65 2019-01-16 14:02:01.582424: step 19117, loss = 0.22070 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:02:02.547128 ops/training.py:65 2019-01-16 14:02:02.547073: step 19118, loss = 0.27177 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:02:03.510414 ops/training.py:65 2019-01-16 14:02:03.510324: step 19119, loss = 0.43940 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:02:04.472511 ops/training.py:65 2019-01-16 14:02:04.472473: step 19120, loss = 0.27357 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:02:05.434275 ops/training.py:65 2019-01-16 14:02:05.434241: step 19121, loss = 0.24108 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:02:06.395447 ops/training.py:65 2019-01-16 14:02:06.395416: step 19122, loss = 0.36028 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:02:07.357525 ops/training.py:65 2019-01-16 14:02:07.357494: step 19123, loss = 0.25655 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:02:08.319038 ops/training.py:65 2019-01-16 14:02:08.319003: step 19124, loss = 0.32349 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:02:09.284591 ops/training.py:65 2019-01-16 14:02:09.284558: step 19125, loss = 0.23774 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:02:10.248862 ops/training.py:65 2019-01-16 14:02:10.248833: step 19126, loss = 0.37938 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:02:11.213028 ops/training.py:65 2019-01-16 14:02:11.212998: step 19127, loss = 0.34216 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:02:12.178771 ops/training.py:65 2019-01-16 14:02:12.178736: step 19128, loss = 0.27832 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:02:13.143145 ops/training.py:65 2019-01-16 14:02:13.143115: step 19129, loss = 0.42758 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:02:14.106338 ops/training.py:65 2019-01-16 14:02:14.106309: step 19130, loss = 0.26037 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:02:15.067759 ops/training.py:65 2019-01-16 14:02:15.067688: step 19131, loss = 0.16272 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:02:16.029444 ops/training.py:65 2019-01-16 14:02:16.029410: step 19132, loss = 0.24388 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:02:16.990887 ops/training.py:65 2019-01-16 14:02:16.990857: step 19133, loss = 0.28796 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:02:17.951416 ops/training.py:65 2019-01-16 14:02:17.951385: step 19134, loss = 0.37225 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:02:18.913045 ops/training.py:65 2019-01-16 14:02:18.913013: step 19135, loss = 0.26191 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:02:19.874876 ops/training.py:65 2019-01-16 14:02:19.874845: step 19136, loss = 0.24764 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:02:20.836269 ops/training.py:65 2019-01-16 14:02:20.836238: step 19137, loss = 0.29812 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:02:21.797491 ops/training.py:65 2019-01-16 14:02:21.797449: step 19138, loss = 0.29760 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:02:22.758880 ops/training.py:65 2019-01-16 14:02:22.758847: step 19139, loss = 0.30300 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:02:23.720769 ops/training.py:65 2019-01-16 14:02:23.720739: step 19140, loss = 0.34754 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:02:24.683143 ops/training.py:65 2019-01-16 14:02:24.683113: step 19141, loss = 0.44005 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:02:25.645429 ops/training.py:65 2019-01-16 14:02:25.645400: step 19142, loss = 0.33093 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:02:26.606754 ops/training.py:65 2019-01-16 14:02:26.606725: step 19143, loss = 0.34518 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:02:27.568091 ops/training.py:65 2019-01-16 14:02:27.568049: step 19144, loss = 0.16862 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:02:28.528684 ops/training.py:65 2019-01-16 14:02:28.528644: step 19145, loss = 0.33431 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:02:29.489755 ops/training.py:65 2019-01-16 14:02:29.489721: step 19146, loss = 0.48200 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:02:30.451771 ops/training.py:65 2019-01-16 14:02:30.451739: step 19147, loss = 0.39353 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:02:31.413796 ops/training.py:65 2019-01-16 14:02:31.413761: step 19148, loss = 0.23395 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:02:32.375057 ops/training.py:65 2019-01-16 14:02:32.375026: step 19149, loss = 0.35522 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:02:33.336976 ops/training.py:65 2019-01-16 14:02:33.336940: step 19150, loss = 0.44263 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:02:34.298194 ops/training.py:65 2019-01-16 14:02:34.298138: step 19151, loss = 0.19035 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:02:35.260968 ops/training.py:65 2019-01-16 14:02:35.260935: step 19152, loss = 0.20036 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:02:36.223001 ops/training.py:65 2019-01-16 14:02:36.222971: step 19153, loss = 0.37506 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:02:37.188251 ops/training.py:65 2019-01-16 14:02:37.188220: step 19154, loss = 0.32148 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:02:38.151116 ops/training.py:65 2019-01-16 14:02:38.151084: step 19155, loss = 0.33862 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:02:39.113242 ops/training.py:65 2019-01-16 14:02:39.113210: step 19156, loss = 0.18715 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:02:40.073667 ops/training.py:65 2019-01-16 14:02:40.073635: step 19157, loss = 0.31808 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:02:41.035341 ops/training.py:65 2019-01-16 14:02:41.035307: step 19158, loss = 0.33914 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:02:41.996386 ops/training.py:65 2019-01-16 14:02:41.996353: step 19159, loss = 0.26027 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:02:42.956835 ops/training.py:65 2019-01-16 14:02:42.956803: step 19160, loss = 0.32219 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:02:43.920621 ops/training.py:65 2019-01-16 14:02:43.920585: step 19161, loss = 0.33718 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:02:44.883366 ops/training.py:65 2019-01-16 14:02:44.883294: step 19162, loss = 0.25124 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:02:45.847406 ops/training.py:65 2019-01-16 14:02:45.847369: step 19163, loss = 0.25589 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:02:46.808396 ops/training.py:65 2019-01-16 14:02:46.808363: step 19164, loss = 0.18826 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:02:47.769751 ops/training.py:65 2019-01-16 14:02:47.769718: step 19165, loss = 0.31454 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:02:48.730051 ops/training.py:65 2019-01-16 14:02:48.730019: step 19166, loss = 0.24208 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:02:49.695699 ops/training.py:65 2019-01-16 14:02:49.695666: step 19167, loss = 0.39188 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:02:50.660737 ops/training.py:65 2019-01-16 14:02:50.660705: step 19168, loss = 0.28018 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:02:51.624317 ops/training.py:65 2019-01-16 14:02:51.624286: step 19169, loss = 0.37494 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:02:52.588248 ops/training.py:65 2019-01-16 14:02:52.588216: step 19170, loss = 0.35804 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:02:53.550273 ops/training.py:65 2019-01-16 14:02:53.550234: step 19171, loss = 0.20031 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:02:54.511703 ops/training.py:65 2019-01-16 14:02:54.511657: step 19172, loss = 0.30039 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:02:55.472929 ops/training.py:65 2019-01-16 14:02:55.472895: step 19173, loss = 0.32069 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:02:56.436041 ops/training.py:65 2019-01-16 14:02:56.436012: step 19174, loss = 0.29933 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:02:57.398266 ops/training.py:65 2019-01-16 14:02:57.398233: step 19175, loss = 0.29763 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:02:58.360273 ops/training.py:65 2019-01-16 14:02:58.360238: step 19176, loss = 0.39761 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:02:59.321532 ops/training.py:65 2019-01-16 14:02:59.321499: step 19177, loss = 0.21963 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:03:00.282738 ops/training.py:65 2019-01-16 14:03:00.282706: step 19178, loss = 0.24077 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:03:01.242955 ops/training.py:65 2019-01-16 14:03:01.242871: step 19179, loss = 0.18400 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:03:02.207656 ops/training.py:65 2019-01-16 14:03:02.207612: step 19180, loss = 0.43764 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:03:03.172533 ops/training.py:65 2019-01-16 14:03:03.172482: step 19181, loss = 0.19088 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:03:04.136227 ops/training.py:65 2019-01-16 14:03:04.136183: step 19182, loss = 0.23325 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:03:05.098701 ops/training.py:65 2019-01-16 14:03:05.098666: step 19183, loss = 0.27464 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:03:06.062013 ops/training.py:65 2019-01-16 14:03:06.061980: step 19184, loss = 0.37133 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:03:07.024260 ops/training.py:65 2019-01-16 14:03:07.024174: step 19185, loss = 0.22847 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:03:07.987343 ops/training.py:65 2019-01-16 14:03:07.987247: step 19186, loss = 0.27078 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:03:08.949836 ops/training.py:65 2019-01-16 14:03:08.949738: step 19187, loss = 0.38486 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:03:09.911610 ops/training.py:65 2019-01-16 14:03:09.911530: step 19188, loss = 0.28301 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:03:10.872546 ops/training.py:65 2019-01-16 14:03:10.872462: step 19189, loss = 0.41916 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:03:11.833708 ops/training.py:65 2019-01-16 14:03:11.833616: step 19190, loss = 0.30840 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:03:12.798397 ops/training.py:65 2019-01-16 14:03:12.798305: step 19191, loss = 0.24560 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:03:13.762081 ops/training.py:65 2019-01-16 14:03:13.762000: step 19192, loss = 0.27080 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:03:14.725103 ops/training.py:65 2019-01-16 14:03:14.725028: step 19193, loss = 0.31624 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:03:15.686528 ops/training.py:65 2019-01-16 14:03:15.686468: step 19194, loss = 0.38273 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:03:16.648105 ops/training.py:65 2019-01-16 14:03:16.648024: step 19195, loss = 0.37161 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:03:17.611366 ops/training.py:65 2019-01-16 14:03:17.611271: step 19196, loss = 0.47982 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:03:18.576778 ops/training.py:65 2019-01-16 14:03:18.576685: step 19197, loss = 0.45138 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:03:19.539075 ops/training.py:65 2019-01-16 14:03:19.538987: step 19198, loss = 0.33557 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:03:20.500577 ops/training.py:65 2019-01-16 14:03:20.500489: step 19199, loss = 0.33127 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:03:21.461966 ops/training.py:65 2019-01-16 14:03:21.461878: step 19200, loss = 0.37740 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:03:22.426126 ops/training.py:65 2019-01-16 14:03:22.426037: step 19201, loss = 0.38578 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:03:23.387973 ops/training.py:65 2019-01-16 14:03:23.387881: step 19202, loss = 0.24743 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:03:24.349686 ops/training.py:65 2019-01-16 14:03:24.349595: step 19203, loss = 0.23620 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:03:25.312993 ops/training.py:65 2019-01-16 14:03:25.312895: step 19204, loss = 0.23017 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:03:26.276191 ops/training.py:65 2019-01-16 14:03:26.276093: step 19205, loss = 0.27180 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:03:27.238396 ops/training.py:65 2019-01-16 14:03:27.238299: step 19206, loss = 0.20451 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:03:28.201354 ops/training.py:65 2019-01-16 14:03:28.201269: step 19207, loss = 0.32541 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:03:29.161769 ops/training.py:65 2019-01-16 14:03:29.161693: step 19208, loss = 0.16164 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:03:30.125558 ops/training.py:65 2019-01-16 14:03:30.125477: step 19209, loss = 0.35546 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:03:31.088809 ops/training.py:65 2019-01-16 14:03:31.088730: step 19210, loss = 0.25967 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:03:32.052192 ops/training.py:65 2019-01-16 14:03:32.052095: step 19211, loss = 0.23601 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:03:33.014983 ops/training.py:65 2019-01-16 14:03:33.014896: step 19212, loss = 0.20464 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:03:33.980508 ops/training.py:65 2019-01-16 14:03:33.980414: step 19213, loss = 0.30032 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:03:34.943946 ops/training.py:65 2019-01-16 14:03:34.943852: step 19214, loss = 0.28733 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:03:35.907562 ops/training.py:65 2019-01-16 14:03:35.907465: step 19215, loss = 0.24491 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:03:36.871954 ops/training.py:65 2019-01-16 14:03:36.871860: step 19216, loss = 0.33810 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:03:37.834707 ops/training.py:65 2019-01-16 14:03:37.834610: step 19217, loss = 0.41279 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:03:38.797708 ops/training.py:65 2019-01-16 14:03:38.797627: step 19218, loss = 0.18139 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:03:39.758776 ops/training.py:65 2019-01-16 14:03:39.758694: step 19219, loss = 0.33193 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:03:40.719685 ops/training.py:65 2019-01-16 14:03:40.719590: step 19220, loss = 0.36499 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:03:41.680583 ops/training.py:65 2019-01-16 14:03:41.680487: step 19221, loss = 0.36959 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:03:42.642606 ops/training.py:65 2019-01-16 14:03:42.642510: step 19222, loss = 0.35494 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:03:43.604422 ops/training.py:65 2019-01-16 14:03:43.604325: step 19223, loss = 0.19336 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:03:44.565525 ops/training.py:65 2019-01-16 14:03:44.565445: step 19224, loss = 0.23205 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:03:45.528018 ops/training.py:65 2019-01-16 14:03:45.527936: step 19225, loss = 0.32445 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:03:46.491192 ops/training.py:65 2019-01-16 14:03:46.491113: step 19226, loss = 0.20655 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:03:47.453157 ops/training.py:65 2019-01-16 14:03:47.453077: step 19227, loss = 0.27014 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:03:48.413527 ops/training.py:65 2019-01-16 14:03:48.413460: step 19228, loss = 0.37226 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:03:49.372857 ops/training.py:65 2019-01-16 14:03:49.372791: step 19229, loss = 0.41131 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:03:50.333233 ops/training.py:65 2019-01-16 14:03:50.333154: step 19230, loss = 0.17628 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:03:51.295112 ops/training.py:65 2019-01-16 14:03:51.295016: step 19231, loss = 0.33820 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:03:52.258045 ops/training.py:65 2019-01-16 14:03:52.257948: step 19232, loss = 0.25318 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:03:53.222155 ops/training.py:65 2019-01-16 14:03:53.222064: step 19233, loss = 0.32264 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:03:54.184894 ops/training.py:65 2019-01-16 14:03:54.184818: step 19234, loss = 0.23300 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:03:55.146704 ops/training.py:65 2019-01-16 14:03:55.146618: step 19235, loss = 0.36188 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:03:56.108921 ops/training.py:65 2019-01-16 14:03:56.108823: step 19236, loss = 0.54832 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:03:57.070888 ops/training.py:65 2019-01-16 14:03:57.070801: step 19237, loss = 0.49843 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 14:03:58.033501 ops/training.py:65 2019-01-16 14:03:58.033409: step 19238, loss = 0.31120 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:03:58.995323 ops/training.py:65 2019-01-16 14:03:58.995224: step 19239, loss = 0.24421 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:03:59.960462 ops/training.py:65 2019-01-16 14:03:59.960416: step 19240, loss = 0.42418 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:04:00.924226 ops/training.py:65 2019-01-16 14:04:00.924184: step 19241, loss = 0.39979 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:04:01.886333 ops/training.py:65 2019-01-16 14:04:01.886293: step 19242, loss = 0.18490 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:04:02.847372 ops/training.py:65 2019-01-16 14:04:02.847339: step 19243, loss = 0.34813 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:04:03.811477 ops/training.py:65 2019-01-16 14:04:03.811443: step 19244, loss = 0.43643 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:04:04.774414 ops/training.py:65 2019-01-16 14:04:04.774381: step 19245, loss = 0.43380 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:04:05.736572 ops/training.py:65 2019-01-16 14:04:05.736539: step 19246, loss = 0.35005 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:04:06.698800 ops/training.py:65 2019-01-16 14:04:06.698765: step 19247, loss = 0.31899 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:04:07.660652 ops/training.py:65 2019-01-16 14:04:07.660619: step 19248, loss = 0.23840 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:04:08.622470 ops/training.py:65 2019-01-16 14:04:08.622439: step 19249, loss = 0.33512 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:04:09.584963 ops/training.py:65 2019-01-16 14:04:09.584932: step 19250, loss = 0.43708 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:04:10.546691 ops/training.py:65 2019-01-16 14:04:10.546660: step 19251, loss = 0.36366 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:04:11.509435 ops/training.py:65 2019-01-16 14:04:11.509404: step 19252, loss = 0.36013 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:04:12.472061 ops/training.py:65 2019-01-16 14:04:12.471975: step 19253, loss = 0.20914 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:04:13.434070 ops/training.py:65 2019-01-16 14:04:13.433979: step 19254, loss = 0.29713 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:04:14.398796 ops/training.py:65 2019-01-16 14:04:14.398722: step 19255, loss = 0.31919 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:04:15.360150 ops/training.py:65 2019-01-16 14:04:15.360081: step 19256, loss = 0.15622 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:04:16.324998 ops/training.py:65 2019-01-16 14:04:16.324965: step 19257, loss = 0.32632 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:04:17.287474 ops/training.py:65 2019-01-16 14:04:17.287441: step 19258, loss = 0.21543 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:04:18.249809 ops/training.py:65 2019-01-16 14:04:18.249776: step 19259, loss = 0.37384 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:04:19.211089 ops/training.py:65 2019-01-16 14:04:19.211055: step 19260, loss = 0.36725 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:04:20.172754 ops/training.py:65 2019-01-16 14:04:20.172720: step 19261, loss = 0.33349 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:04:21.134954 ops/training.py:65 2019-01-16 14:04:21.134908: step 19262, loss = 0.37412 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:04:22.097470 ops/training.py:65 2019-01-16 14:04:22.097435: step 19263, loss = 0.30281 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:04:23.059399 ops/training.py:65 2019-01-16 14:04:23.059366: step 19264, loss = 0.19548 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:04:24.022307 ops/training.py:65 2019-01-16 14:04:24.022267: step 19265, loss = 0.42540 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:04:24.987925 ops/training.py:65 2019-01-16 14:04:24.987882: step 19266, loss = 0.44595 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:04:25.950121 ops/training.py:65 2019-01-16 14:04:25.950083: step 19267, loss = 0.31957 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:04:26.913326 ops/training.py:65 2019-01-16 14:04:26.913291: step 19268, loss = 0.22596 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:04:27.875951 ops/training.py:65 2019-01-16 14:04:27.875919: step 19269, loss = 0.22218 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:04:28.839204 ops/training.py:65 2019-01-16 14:04:28.839174: step 19270, loss = 0.29270 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:04:29.801253 ops/training.py:65 2019-01-16 14:04:29.801223: step 19271, loss = 0.20441 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:04:30.762790 ops/training.py:65 2019-01-16 14:04:30.762761: step 19272, loss = 0.37954 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:04:31.725166 ops/training.py:65 2019-01-16 14:04:31.725136: step 19273, loss = 0.19632 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:04:32.687339 ops/training.py:65 2019-01-16 14:04:32.687311: step 19274, loss = 0.29689 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:04:33.650774 ops/training.py:65 2019-01-16 14:04:33.650742: step 19275, loss = 0.24054 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:04:34.611688 ops/training.py:65 2019-01-16 14:04:34.611656: step 19276, loss = 0.18153 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:04:35.574753 ops/training.py:65 2019-01-16 14:04:35.574721: step 19277, loss = 0.39994 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:04:36.535044 ops/training.py:65 2019-01-16 14:04:36.535013: step 19278, loss = 0.26199 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:04:37.496556 ops/training.py:65 2019-01-16 14:04:37.496525: step 19279, loss = 0.52995 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 14:04:38.458172 ops/training.py:65 2019-01-16 14:04:38.458141: step 19280, loss = 0.32072 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:04:39.419965 ops/training.py:65 2019-01-16 14:04:39.419933: step 19281, loss = 0.25360 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:04:40.380329 ops/training.py:65 2019-01-16 14:04:40.380298: step 19282, loss = 0.13708 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:04:41.345533 ops/training.py:65 2019-01-16 14:04:41.345498: step 19283, loss = 0.40643 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:04:42.308358 ops/training.py:65 2019-01-16 14:04:42.308323: step 19284, loss = 0.37081 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:04:43.271084 ops/training.py:65 2019-01-16 14:04:43.271018: step 19285, loss = 0.31161 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:04:44.233046 ops/training.py:65 2019-01-16 14:04:44.233001: step 19286, loss = 0.32827 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:04:45.194447 ops/training.py:65 2019-01-16 14:04:45.194412: step 19287, loss = 0.22903 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:04:46.156449 ops/training.py:65 2019-01-16 14:04:46.156417: step 19288, loss = 0.28219 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:04:47.118222 ops/training.py:65 2019-01-16 14:04:47.118180: step 19289, loss = 0.25814 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:04:48.079886 ops/training.py:65 2019-01-16 14:04:48.079784: step 19290, loss = 0.27213 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:04:49.041420 ops/training.py:65 2019-01-16 14:04:49.041336: step 19291, loss = 0.32811 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:04:50.002357 ops/training.py:65 2019-01-16 14:04:50.002294: step 19292, loss = 0.21462 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:04:50.965237 ops/training.py:65 2019-01-16 14:04:50.965153: step 19293, loss = 0.20482 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:04:51.929223 ops/training.py:65 2019-01-16 14:04:51.929183: step 19294, loss = 0.37132 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:04:52.895485 ops/training.py:65 2019-01-16 14:04:52.895446: step 19295, loss = 0.19544 (33.1 examples/sec; 0.965 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:04:53.856228 ops/training.py:65 2019-01-16 14:04:53.856194: step 19296, loss = 0.34085 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:04:54.820495 ops/training.py:65 2019-01-16 14:04:54.820459: step 19297, loss = 0.28368 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:04:55.784242 ops/training.py:65 2019-01-16 14:04:55.784208: step 19298, loss = 0.25537 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:04:56.746347 ops/training.py:65 2019-01-16 14:04:56.746319: step 19299, loss = 0.35862 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:04:57.708175 ops/training.py:65 2019-01-16 14:04:57.708144: step 19300, loss = 0.20249 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:04:58.670092 ops/training.py:65 2019-01-16 14:04:58.670059: step 19301, loss = 0.23931 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:04:59.631743 ops/training.py:65 2019-01-16 14:04:59.631712: step 19302, loss = 0.29760 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:05:00.593732 ops/training.py:65 2019-01-16 14:05:00.593701: step 19303, loss = 0.23291 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:05:01.555519 ops/training.py:65 2019-01-16 14:05:01.555490: step 19304, loss = 0.22684 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:05:02.517219 ops/training.py:65 2019-01-16 14:05:02.517190: step 19305, loss = 0.20958 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:05:03.478452 ops/training.py:65 2019-01-16 14:05:03.478373: step 19306, loss = 0.52174 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:05:04.443378 ops/training.py:65 2019-01-16 14:05:04.443344: step 19307, loss = 0.22660 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:05:05.406768 ops/training.py:65 2019-01-16 14:05:05.406738: step 19308, loss = 0.37248 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:05:06.369358 ops/training.py:65 2019-01-16 14:05:06.369327: step 19309, loss = 0.28521 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:05:07.331008 ops/training.py:65 2019-01-16 14:05:07.330977: step 19310, loss = 0.23533 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:05:08.292787 ops/training.py:65 2019-01-16 14:05:08.292757: step 19311, loss = 0.23623 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:05:09.254906 ops/training.py:65 2019-01-16 14:05:09.254875: step 19312, loss = 0.25036 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:05:10.216766 ops/training.py:65 2019-01-16 14:05:10.216735: step 19313, loss = 0.36146 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:05:11.178403 ops/training.py:65 2019-01-16 14:05:11.178371: step 19314, loss = 0.23592 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:05:12.139898 ops/training.py:65 2019-01-16 14:05:12.139866: step 19315, loss = 0.30079 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:05:13.101308 ops/training.py:65 2019-01-16 14:05:13.101233: step 19316, loss = 0.25888 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:05:14.063420 ops/training.py:65 2019-01-16 14:05:14.063347: step 19317, loss = 0.19492 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:05:15.028232 ops/training.py:65 2019-01-16 14:05:15.028161: step 19318, loss = 0.44542 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:05:15.988929 ops/training.py:65 2019-01-16 14:05:15.988845: step 19319, loss = 0.18627 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:05:16.949042 ops/training.py:65 2019-01-16 14:05:16.948954: step 19320, loss = 0.30576 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:05:17.912925 ops/training.py:65 2019-01-16 14:05:17.912855: step 19321, loss = 0.22678 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:05:18.874251 ops/training.py:65 2019-01-16 14:05:18.874163: step 19322, loss = 0.46931 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:05:19.835056 ops/training.py:65 2019-01-16 14:05:19.834962: step 19323, loss = 0.14938 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:05:20.796123 ops/training.py:65 2019-01-16 14:05:20.796030: step 19324, loss = 0.26874 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:05:21.756415 ops/training.py:65 2019-01-16 14:05:21.756352: step 19325, loss = 0.17314 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:05:22.719764 ops/training.py:65 2019-01-16 14:05:22.719682: step 19326, loss = 0.19795 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:05:23.683433 ops/training.py:65 2019-01-16 14:05:23.683338: step 19327, loss = 0.30880 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:05:24.646785 ops/training.py:65 2019-01-16 14:05:24.646694: step 19328, loss = 0.31191 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:05:25.608770 ops/training.py:65 2019-01-16 14:05:25.608685: step 19329, loss = 0.20959 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:05:26.571418 ops/training.py:65 2019-01-16 14:05:26.571324: step 19330, loss = 0.25535 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:05:27.533463 ops/training.py:65 2019-01-16 14:05:27.533372: step 19331, loss = 0.25027 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:05:28.495836 ops/training.py:65 2019-01-16 14:05:28.495749: step 19332, loss = 0.20617 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:05:29.456387 ops/training.py:65 2019-01-16 14:05:29.456308: step 19333, loss = 0.21315 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:05:30.418010 ops/training.py:65 2019-01-16 14:05:30.417921: step 19334, loss = 0.32612 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:05:31.383820 ops/training.py:65 2019-01-16 14:05:31.383734: step 19335, loss = 0.19823 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:05:32.346817 ops/training.py:65 2019-01-16 14:05:32.346725: step 19336, loss = 0.29650 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:05:33.309230 ops/training.py:65 2019-01-16 14:05:33.309131: step 19337, loss = 0.40778 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:05:34.271212 ops/training.py:65 2019-01-16 14:05:34.271111: step 19338, loss = 0.21014 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:05:35.232835 ops/training.py:65 2019-01-16 14:05:35.232732: step 19339, loss = 0.21103 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:05:36.194931 ops/training.py:65 2019-01-16 14:05:36.194847: step 19340, loss = 0.36545 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:05:37.155469 ops/training.py:65 2019-01-16 14:05:37.155394: step 19341, loss = 0.24509 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:05:38.119726 ops/training.py:65 2019-01-16 14:05:38.119648: step 19342, loss = 0.25294 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:05:39.084067 ops/training.py:65 2019-01-16 14:05:39.083971: step 19343, loss = 0.22859 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:05:40.046371 ops/training.py:65 2019-01-16 14:05:40.046278: step 19344, loss = 0.43173 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:05:41.008105 ops/training.py:65 2019-01-16 14:05:41.008002: step 19345, loss = 0.21000 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:05:41.970017 ops/training.py:65 2019-01-16 14:05:41.969911: step 19346, loss = 0.39367 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:05:42.931727 ops/training.py:65 2019-01-16 14:05:42.931633: step 19347, loss = 0.26100 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:05:43.893627 ops/training.py:65 2019-01-16 14:05:43.893530: step 19348, loss = 0.37533 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:05:44.855674 ops/training.py:65 2019-01-16 14:05:44.855576: step 19349, loss = 0.22975 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:05:45.818802 ops/training.py:65 2019-01-16 14:05:45.818703: step 19350, loss = 0.13874 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:05:46.783065 ops/training.py:65 2019-01-16 14:05:46.782986: step 19351, loss = 0.28004 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:05:47.747442 ops/training.py:65 2019-01-16 14:05:47.747348: step 19352, loss = 0.24015 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:05:48.712065 ops/training.py:65 2019-01-16 14:05:48.711980: step 19353, loss = 0.19093 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:05:49.673066 ops/training.py:65 2019-01-16 14:05:49.673011: step 19354, loss = 0.25613 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:05:50.635199 ops/training.py:65 2019-01-16 14:05:50.635139: step 19355, loss = 0.29215 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:05:51.596760 ops/training.py:65 2019-01-16 14:05:51.596720: step 19356, loss = 0.33645 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:05:52.558352 ops/training.py:65 2019-01-16 14:05:52.558316: step 19357, loss = 0.24629 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:05:53.520097 ops/training.py:65 2019-01-16 14:05:53.520054: step 19358, loss = 0.14511 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:05:54.482007 ops/training.py:65 2019-01-16 14:05:54.481966: step 19359, loss = 0.48335 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:05:55.445107 ops/training.py:65 2019-01-16 14:05:55.445077: step 19360, loss = 0.22624 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:05:56.407010 ops/training.py:65 2019-01-16 14:05:56.406975: step 19361, loss = 0.32526 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:05:57.367916 ops/training.py:65 2019-01-16 14:05:57.367879: step 19362, loss = 0.40234 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:05:58.329874 ops/training.py:65 2019-01-16 14:05:58.329840: step 19363, loss = 0.21067 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:05:59.292594 ops/training.py:65 2019-01-16 14:05:59.292557: step 19364, loss = 0.38372 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:06:00.254094 ops/training.py:65 2019-01-16 14:06:00.254059: step 19365, loss = 0.31767 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:06:01.215763 ops/training.py:65 2019-01-16 14:06:01.215731: step 19366, loss = 0.23844 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:06:02.178149 ops/training.py:65 2019-01-16 14:06:02.178117: step 19367, loss = 0.33842 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:06:03.139950 ops/training.py:65 2019-01-16 14:06:03.139918: step 19368, loss = 0.28867 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:06:04.101910 ops/training.py:65 2019-01-16 14:06:04.101875: step 19369, loss = 0.38161 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:06:05.063822 ops/training.py:65 2019-01-16 14:06:05.063787: step 19370, loss = 0.17033 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:06:06.025676 ops/training.py:65 2019-01-16 14:06:06.025635: step 19371, loss = 0.28373 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:06:06.988745 ops/training.py:65 2019-01-16 14:06:06.988709: step 19372, loss = 0.37243 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:06:07.949456 ops/training.py:65 2019-01-16 14:06:07.949382: step 19373, loss = 0.20153 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:06:08.910780 ops/training.py:65 2019-01-16 14:06:08.910697: step 19374, loss = 0.40321 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:06:09.876487 ops/training.py:65 2019-01-16 14:06:09.876403: step 19375, loss = 0.26010 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:06:10.838527 ops/training.py:65 2019-01-16 14:06:10.838428: step 19376, loss = 0.44749 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:06:11.803822 ops/training.py:65 2019-01-16 14:06:11.803730: step 19377, loss = 0.18064 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:06:12.767703 ops/training.py:65 2019-01-16 14:06:12.767611: step 19378, loss = 0.39651 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:06:13.731024 ops/training.py:65 2019-01-16 14:06:13.730934: step 19379, loss = 0.28729 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:06:14.692621 ops/training.py:65 2019-01-16 14:06:14.692550: step 19380, loss = 0.32037 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:06:15.654406 ops/training.py:65 2019-01-16 14:06:15.654311: step 19381, loss = 0.40031 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:06:16.616552 ops/training.py:65 2019-01-16 14:06:16.616471: step 19382, loss = 0.38433 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:06:17.579358 ops/training.py:65 2019-01-16 14:06:17.579261: step 19383, loss = 0.28117 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:06:18.540992 ops/training.py:65 2019-01-16 14:06:18.540944: step 19384, loss = 0.25615 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:06:19.503032 ops/training.py:65 2019-01-16 14:06:19.502986: step 19385, loss = 0.29225 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:06:20.464548 ops/training.py:65 2019-01-16 14:06:20.464509: step 19386, loss = 0.25317 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:06:21.425135 ops/training.py:65 2019-01-16 14:06:21.425040: step 19387, loss = 0.24174 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:06:22.389104 ops/training.py:65 2019-01-16 14:06:22.389032: step 19388, loss = 0.25587 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:06:23.351245 ops/training.py:65 2019-01-16 14:06:23.351147: step 19389, loss = 0.25176 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:06:24.311169 ops/training.py:65 2019-01-16 14:06:24.311100: step 19390, loss = 0.43442 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:06:25.269918 ops/training.py:65 2019-01-16 14:06:25.269849: step 19391, loss = 0.17220 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:06:26.234484 ops/training.py:65 2019-01-16 14:06:26.234449: step 19392, loss = 0.32724 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:06:27.199104 ops/training.py:65 2019-01-16 14:06:27.199070: step 19393, loss = 0.24283 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:06:28.159611 ops/training.py:65 2019-01-16 14:06:28.159551: step 19394, loss = 0.36962 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:06:29.117685 ops/training.py:65 2019-01-16 14:06:29.117624: step 19395, loss = 0.33009 (33.4 examples/sec; 0.957 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:06:30.076225 ops/training.py:65 2019-01-16 14:06:30.076167: step 19396, loss = 0.45943 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:06:31.034848 ops/training.py:65 2019-01-16 14:06:31.034786: step 19397, loss = 0.27627 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:06:31.997221 ops/training.py:65 2019-01-16 14:06:31.997174: step 19398, loss = 0.27283 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:06:32.960687 ops/training.py:65 2019-01-16 14:06:32.960647: step 19399, loss = 0.34844 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:06:33.922529 ops/training.py:65 2019-01-16 14:06:33.922477: step 19400, loss = 0.44455 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:06:34.884315 ops/training.py:65 2019-01-16 14:06:34.884274: step 19401, loss = 0.31887 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:06:35.845836 ops/training.py:65 2019-01-16 14:06:35.845799: step 19402, loss = 0.26402 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:06:36.807501 ops/training.py:65 2019-01-16 14:06:36.807457: step 19403, loss = 0.25603 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:06:37.768980 ops/training.py:65 2019-01-16 14:06:37.768917: step 19404, loss = 0.20781 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:06:38.728353 ops/training.py:65 2019-01-16 14:06:38.728289: step 19405, loss = 0.27489 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:06:39.688298 ops/training.py:65 2019-01-16 14:06:39.688238: step 19406, loss = 0.27328 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:06:40.648923 ops/training.py:65 2019-01-16 14:06:40.648861: step 19407, loss = 0.38046 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:06:41.607965 ops/training.py:65 2019-01-16 14:06:41.607895: step 19408, loss = 0.41379 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:06:42.573119 ops/training.py:65 2019-01-16 14:06:42.573030: step 19409, loss = 0.20732 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:06:43.538225 ops/training.py:65 2019-01-16 14:06:43.538124: step 19410, loss = 0.43980 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:06:44.501606 ops/training.py:65 2019-01-16 14:06:44.501518: step 19411, loss = 0.23875 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:06:45.463455 ops/training.py:65 2019-01-16 14:06:45.463380: step 19412, loss = 0.24801 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:06:46.425525 ops/training.py:65 2019-01-16 14:06:46.425446: step 19413, loss = 0.38100 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:06:47.388061 ops/training.py:65 2019-01-16 14:06:47.387966: step 19414, loss = 0.39257 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:06:48.350212 ops/training.py:65 2019-01-16 14:06:48.350124: step 19415, loss = 0.25040 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:06:49.310957 ops/training.py:65 2019-01-16 14:06:49.310842: step 19416, loss = 0.16895 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:06:50.272395 ops/training.py:65 2019-01-16 14:06:50.272298: step 19417, loss = 0.27836 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:06:51.233739 ops/training.py:65 2019-01-16 14:06:51.233647: step 19418, loss = 0.37245 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:06:52.195605 ops/training.py:65 2019-01-16 14:06:52.195523: step 19419, loss = 0.44848 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:06:53.156821 ops/training.py:65 2019-01-16 14:06:53.156754: step 19420, loss = 0.31286 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:06:54.118191 ops/training.py:65 2019-01-16 14:06:54.118126: step 19421, loss = 0.30446 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:06:55.081539 ops/training.py:65 2019-01-16 14:06:55.081474: step 19422, loss = 0.22944 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:06:56.046529 ops/training.py:65 2019-01-16 14:06:56.046431: step 19423, loss = 0.28809 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:06:57.009614 ops/training.py:65 2019-01-16 14:06:57.009510: step 19424, loss = 0.29444 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:06:57.974927 ops/training.py:65 2019-01-16 14:06:57.974827: step 19425, loss = 0.43967 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:06:58.938613 ops/training.py:65 2019-01-16 14:06:58.938524: step 19426, loss = 0.34747 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:06:59.903656 ops/training.py:65 2019-01-16 14:06:59.903566: step 19427, loss = 0.35483 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:07:00.867163 ops/training.py:65 2019-01-16 14:07:00.867070: step 19428, loss = 0.22905 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:07:01.829105 ops/training.py:65 2019-01-16 14:07:01.829023: step 19429, loss = 0.28832 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:07:02.790434 ops/training.py:65 2019-01-16 14:07:02.790341: step 19430, loss = 0.16139 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:07:03.754027 ops/training.py:65 2019-01-16 14:07:03.753932: step 19431, loss = 0.27721 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:07:04.719938 ops/training.py:65 2019-01-16 14:07:04.719860: step 19432, loss = 0.18461 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:07:05.685219 ops/training.py:65 2019-01-16 14:07:05.685120: step 19433, loss = 0.53000 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:07:06.648000 ops/training.py:65 2019-01-16 14:07:06.647903: step 19434, loss = 0.41280 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:07:07.612855 ops/training.py:65 2019-01-16 14:07:07.612811: step 19435, loss = 0.45411 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:07:08.576599 ops/training.py:65 2019-01-16 14:07:08.576511: step 19436, loss = 0.45218 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:07:09.538766 ops/training.py:65 2019-01-16 14:07:09.538678: step 19437, loss = 0.24669 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:07:10.499845 ops/training.py:65 2019-01-16 14:07:10.499756: step 19438, loss = 0.23418 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:07:11.463102 ops/training.py:65 2019-01-16 14:07:11.463023: step 19439, loss = 0.31747 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:07:12.425532 ops/training.py:65 2019-01-16 14:07:12.425497: step 19440, loss = 0.44456 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 14:07:13.388972 ops/training.py:65 2019-01-16 14:07:13.388938: step 19441, loss = 0.23131 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:07:14.350828 ops/training.py:65 2019-01-16 14:07:14.350795: step 19442, loss = 0.32733 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:07:15.316288 ops/training.py:65 2019-01-16 14:07:15.316233: step 19443, loss = 0.23276 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:07:16.277245 ops/training.py:65 2019-01-16 14:07:16.277211: step 19444, loss = 0.25821 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:07:17.241494 ops/training.py:65 2019-01-16 14:07:17.241461: step 19445, loss = 0.22535 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:07:18.205136 ops/training.py:65 2019-01-16 14:07:18.205101: step 19446, loss = 0.37854 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:07:19.166958 ops/training.py:65 2019-01-16 14:07:19.166927: step 19447, loss = 0.24642 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:07:20.131385 ops/training.py:65 2019-01-16 14:07:20.131353: step 19448, loss = 0.26572 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:07:21.096482 ops/training.py:65 2019-01-16 14:07:21.096424: step 19449, loss = 0.18378 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:07:22.060668 ops/training.py:65 2019-01-16 14:07:22.060623: step 19450, loss = 0.21972 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:07:23.023892 ops/training.py:65 2019-01-16 14:07:23.023858: step 19451, loss = 0.19322 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:07:23.987502 ops/training.py:65 2019-01-16 14:07:23.987469: step 19452, loss = 0.32036 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:07:24.949394 ops/training.py:65 2019-01-16 14:07:24.949366: step 19453, loss = 0.34479 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:07:25.910505 ops/training.py:65 2019-01-16 14:07:25.910472: step 19454, loss = 0.30812 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:07:26.871281 ops/training.py:65 2019-01-16 14:07:26.871247: step 19455, loss = 0.40257 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:07:27.832866 ops/training.py:65 2019-01-16 14:07:27.832830: step 19456, loss = 0.22047 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:07:28.794858 ops/training.py:65 2019-01-16 14:07:28.794820: step 19457, loss = 0.37545 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:07:29.756406 ops/training.py:65 2019-01-16 14:07:29.756373: step 19458, loss = 0.20320 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:07:30.718568 ops/training.py:65 2019-01-16 14:07:30.718472: step 19459, loss = 0.53046 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:07:31.683292 ops/training.py:65 2019-01-16 14:07:31.683207: step 19460, loss = 0.34553 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:07:32.648055 ops/training.py:65 2019-01-16 14:07:32.648006: step 19461, loss = 0.23671 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:07:33.611038 ops/training.py:65 2019-01-16 14:07:33.610958: step 19462, loss = 0.24359 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:07:34.572532 ops/training.py:65 2019-01-16 14:07:34.572470: step 19463, loss = 0.21036 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:07:35.533019 ops/training.py:65 2019-01-16 14:07:35.532927: step 19464, loss = 0.40089 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:07:36.493205 ops/training.py:65 2019-01-16 14:07:36.493127: step 19465, loss = 0.25015 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:07:37.453316 ops/training.py:65 2019-01-16 14:07:37.453234: step 19466, loss = 0.22141 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:07:38.413536 ops/training.py:65 2019-01-16 14:07:38.413443: step 19467, loss = 0.23553 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:07:39.374099 ops/training.py:65 2019-01-16 14:07:39.374009: step 19468, loss = 0.24577 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:07:40.334275 ops/training.py:65 2019-01-16 14:07:40.334182: step 19469, loss = 0.31521 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:07:41.294541 ops/training.py:65 2019-01-16 14:07:41.294447: step 19470, loss = 0.32175 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:07:42.254805 ops/training.py:65 2019-01-16 14:07:42.254715: step 19471, loss = 0.30242 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:07:43.215109 ops/training.py:65 2019-01-16 14:07:43.215020: step 19472, loss = 0.32066 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:07:44.176723 ops/training.py:65 2019-01-16 14:07:44.176623: step 19473, loss = 0.23767 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:07:45.141094 ops/training.py:65 2019-01-16 14:07:45.141020: step 19474, loss = 0.36358 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:07:46.102071 ops/training.py:65 2019-01-16 14:07:46.101979: step 19475, loss = 0.11218 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:07:47.064406 ops/training.py:65 2019-01-16 14:07:47.064296: step 19476, loss = 0.35977 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:07:48.026068 ops/training.py:65 2019-01-16 14:07:48.025960: step 19477, loss = 0.34555 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:07:48.991811 ops/training.py:65 2019-01-16 14:07:48.991713: step 19478, loss = 0.31722 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:07:49.955411 ops/training.py:65 2019-01-16 14:07:49.955317: step 19479, loss = 0.20438 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:07:50.918337 ops/training.py:65 2019-01-16 14:07:50.918227: step 19480, loss = 0.25373 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:07:51.881490 ops/training.py:65 2019-01-16 14:07:51.881404: step 19481, loss = 0.30504 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:07:52.842511 ops/training.py:65 2019-01-16 14:07:52.842437: step 19482, loss = 0.22384 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:07:53.803451 ops/training.py:65 2019-01-16 14:07:53.803406: step 19483, loss = 0.30757 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:07:54.764572 ops/training.py:65 2019-01-16 14:07:54.764533: step 19484, loss = 0.19269 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:07:55.728709 ops/training.py:65 2019-01-16 14:07:55.728664: step 19485, loss = 0.22062 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:07:56.688131 ops/training.py:65 2019-01-16 14:07:56.688091: step 19486, loss = 0.28668 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:07:57.647180 ops/training.py:65 2019-01-16 14:07:57.647140: step 19487, loss = 0.24562 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:07:58.611081 ops/training.py:65 2019-01-16 14:07:58.611046: step 19488, loss = 0.34316 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:07:59.574286 ops/training.py:65 2019-01-16 14:07:59.574252: step 19489, loss = 0.28069 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:08:00.536813 ops/training.py:65 2019-01-16 14:08:00.536778: step 19490, loss = 0.25119 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:08:01.497498 ops/training.py:65 2019-01-16 14:08:01.497466: step 19491, loss = 0.16437 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:08:02.458575 ops/training.py:65 2019-01-16 14:08:02.458543: step 19492, loss = 0.16640 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:08:03.419329 ops/training.py:65 2019-01-16 14:08:03.419299: step 19493, loss = 0.22017 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:08:04.381643 ops/training.py:65 2019-01-16 14:08:04.381613: step 19494, loss = 0.35251 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:08:05.342746 ops/training.py:65 2019-01-16 14:08:05.342701: step 19495, loss = 0.25853 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:08:06.307543 ops/training.py:65 2019-01-16 14:08:06.307510: step 19496, loss = 0.24098 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:08:07.268889 ops/training.py:65 2019-01-16 14:08:07.268860: step 19497, loss = 0.23360 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:08:08.230232 ops/training.py:65 2019-01-16 14:08:08.230202: step 19498, loss = 0.21853 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:08:09.191321 ops/training.py:65 2019-01-16 14:08:09.191286: step 19499, loss = 0.30835 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:08:10.152967 ops/training.py:65 2019-01-16 14:08:10.152933: step 19500, loss = 0.13931 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:08:11.113547 ops/training.py:65 2019-01-16 14:08:11.113516: step 19501, loss = 0.42178 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:08:12.074798 ops/training.py:65 2019-01-16 14:08:12.074768: step 19502, loss = 0.20206 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:08:13.035595 ops/training.py:65 2019-01-16 14:08:13.035564: step 19503, loss = 0.42108 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:08:13.996720 ops/training.py:65 2019-01-16 14:08:13.996687: step 19504, loss = 0.18042 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:08:14.957446 ops/training.py:65 2019-01-16 14:08:14.957381: step 19505, loss = 0.24149 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:08:15.919243 ops/training.py:65 2019-01-16 14:08:15.919208: step 19506, loss = 0.19713 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:08:16.880603 ops/training.py:65 2019-01-16 14:08:16.880570: step 19507, loss = 0.40250 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:08:17.845547 ops/training.py:65 2019-01-16 14:08:17.845514: step 19508, loss = 0.25633 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:08:18.809074 ops/training.py:65 2019-01-16 14:08:18.809041: step 19509, loss = 0.25054 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:08:19.769979 ops/training.py:65 2019-01-16 14:08:19.769941: step 19510, loss = 0.21766 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:08:20.730775 ops/training.py:65 2019-01-16 14:08:20.730707: step 19511, loss = 0.19964 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:08:21.690866 ops/training.py:65 2019-01-16 14:08:21.690742: step 19512, loss = 0.35120 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:08:22.656917 ops/training.py:65 2019-01-16 14:08:22.656850: step 19513, loss = 0.23543 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:08:23.620603 ops/training.py:65 2019-01-16 14:08:23.620549: step 19514, loss = 0.33930 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:08:24.581901 ops/training.py:65 2019-01-16 14:08:24.581817: step 19515, loss = 0.27374 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:08:25.542225 ops/training.py:65 2019-01-16 14:08:25.542156: step 19516, loss = 0.17204 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:08:26.501863 ops/training.py:65 2019-01-16 14:08:26.501807: step 19517, loss = 0.37299 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:08:27.462113 ops/training.py:65 2019-01-16 14:08:27.462057: step 19518, loss = 0.24594 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:08:28.421468 ops/training.py:65 2019-01-16 14:08:28.421414: step 19519, loss = 0.12710 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:08:29.380149 ops/training.py:65 2019-01-16 14:08:29.380095: step 19520, loss = 0.29761 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:08:30.338901 ops/training.py:65 2019-01-16 14:08:30.338841: step 19521, loss = 0.24386 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:08:31.301808 ops/training.py:65 2019-01-16 14:08:31.301754: step 19522, loss = 0.14060 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:08:32.265459 ops/training.py:65 2019-01-16 14:08:32.265395: step 19523, loss = 0.24097 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:08:33.226398 ops/training.py:65 2019-01-16 14:08:33.226324: step 19524, loss = 0.33116 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:08:34.187167 ops/training.py:65 2019-01-16 14:08:34.187093: step 19525, loss = 0.16530 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:08:35.148284 ops/training.py:65 2019-01-16 14:08:35.148223: step 19526, loss = 0.27907 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:08:36.109453 ops/training.py:65 2019-01-16 14:08:36.109375: step 19527, loss = 0.29664 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:08:37.073116 ops/training.py:65 2019-01-16 14:08:37.073040: step 19528, loss = 0.25017 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:08:38.036472 ops/training.py:65 2019-01-16 14:08:38.036390: step 19529, loss = 0.26154 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:08:38.998607 ops/training.py:65 2019-01-16 14:08:38.998507: step 19530, loss = 0.23997 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:08:39.960752 ops/training.py:65 2019-01-16 14:08:39.960678: step 19531, loss = 0.31793 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:08:40.921831 ops/training.py:65 2019-01-16 14:08:40.921735: step 19532, loss = 0.19180 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:08:41.883334 ops/training.py:65 2019-01-16 14:08:41.883253: step 19533, loss = 0.22511 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:08:42.847313 ops/training.py:65 2019-01-16 14:08:42.847229: step 19534, loss = 0.38177 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:08:43.810905 ops/training.py:65 2019-01-16 14:08:43.810831: step 19535, loss = 0.26976 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:08:44.773294 ops/training.py:65 2019-01-16 14:08:44.773232: step 19536, loss = 0.16556 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:08:45.734119 ops/training.py:65 2019-01-16 14:08:45.734056: step 19537, loss = 0.26137 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:08:46.695627 ops/training.py:65 2019-01-16 14:08:46.695549: step 19538, loss = 0.33165 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:08:47.657382 ops/training.py:65 2019-01-16 14:08:47.657303: step 19539, loss = 0.33149 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:08:48.619513 ops/training.py:65 2019-01-16 14:08:48.619409: step 19540, loss = 0.27829 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:08:49.581082 ops/training.py:65 2019-01-16 14:08:49.581006: step 19541, loss = 0.23443 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:08:50.541951 ops/training.py:65 2019-01-16 14:08:50.541849: step 19542, loss = 0.15479 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:08:51.504104 ops/training.py:65 2019-01-16 14:08:51.504029: step 19543, loss = 0.23520 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:08:52.465707 ops/training.py:65 2019-01-16 14:08:52.465629: step 19544, loss = 0.35374 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:08:53.426961 ops/training.py:65 2019-01-16 14:08:53.426885: step 19545, loss = 0.31640 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:08:54.388307 ops/training.py:65 2019-01-16 14:08:54.388200: step 19546, loss = 0.18252 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:08:55.352426 ops/training.py:65 2019-01-16 14:08:55.352341: step 19547, loss = 0.27856 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:08:56.313888 ops/training.py:65 2019-01-16 14:08:56.313800: step 19548, loss = 0.51452 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:08:57.278371 ops/training.py:65 2019-01-16 14:08:57.278311: step 19549, loss = 0.39195 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:08:58.241336 ops/training.py:65 2019-01-16 14:08:58.241255: step 19550, loss = 0.29459 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:08:59.204762 ops/training.py:65 2019-01-16 14:08:59.204683: step 19551, loss = 0.33347 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:09:00.166237 ops/training.py:65 2019-01-16 14:09:00.166158: step 19552, loss = 0.32792 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:09:01.126609 ops/training.py:65 2019-01-16 14:09:01.126550: step 19553, loss = 0.28105 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:09:02.085444 ops/training.py:65 2019-01-16 14:09:02.085390: step 19554, loss = 0.30212 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:09:03.048012 ops/training.py:65 2019-01-16 14:09:03.047954: step 19555, loss = 0.26505 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:09:04.012114 ops/training.py:65 2019-01-16 14:09:04.012039: step 19556, loss = 0.14428 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:09:04.976415 ops/training.py:65 2019-01-16 14:09:04.976354: step 19557, loss = 0.28860 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:09:05.939454 ops/training.py:65 2019-01-16 14:09:05.939378: step 19558, loss = 0.47404 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 14:09:06.902738 ops/training.py:65 2019-01-16 14:09:06.902662: step 19559, loss = 0.31606 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:09:07.864785 ops/training.py:65 2019-01-16 14:09:07.864707: step 19560, loss = 0.15038 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:09:08.827406 ops/training.py:65 2019-01-16 14:09:08.827327: step 19561, loss = 0.15969 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:09:09.790522 ops/training.py:65 2019-01-16 14:09:09.790446: step 19562, loss = 0.28781 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:09:10.752098 ops/training.py:65 2019-01-16 14:09:10.751993: step 19563, loss = 0.36931 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:09:11.716470 ops/training.py:65 2019-01-16 14:09:11.716389: step 19564, loss = 0.24678 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:09:12.679031 ops/training.py:65 2019-01-16 14:09:12.678952: step 19565, loss = 0.17443 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:09:13.641445 ops/training.py:65 2019-01-16 14:09:13.641370: step 19566, loss = 0.32966 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:09:14.603818 ops/training.py:65 2019-01-16 14:09:14.603739: step 19567, loss = 0.31058 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:09:15.567439 ops/training.py:65 2019-01-16 14:09:15.567371: step 19568, loss = 0.32266 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:09:16.532581 ops/training.py:65 2019-01-16 14:09:16.532503: step 19569, loss = 0.23406 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:09:17.496502 ops/training.py:65 2019-01-16 14:09:17.496422: step 19570, loss = 0.29302 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:09:18.458802 ops/training.py:65 2019-01-16 14:09:18.458724: step 19571, loss = 0.28246 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:09:19.421571 ops/training.py:65 2019-01-16 14:09:19.421495: step 19572, loss = 0.34929 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:09:20.385480 ops/training.py:65 2019-01-16 14:09:20.385416: step 19573, loss = 0.33684 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:09:21.347678 ops/training.py:65 2019-01-16 14:09:21.347601: step 19574, loss = 0.39805 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:09:22.308476 ops/training.py:65 2019-01-16 14:09:22.308396: step 19575, loss = 0.26118 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:09:23.270116 ops/training.py:65 2019-01-16 14:09:23.270035: step 19576, loss = 0.23163 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:09:24.234840 ops/training.py:65 2019-01-16 14:09:24.234758: step 19577, loss = 0.28195 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:09:25.198269 ops/training.py:65 2019-01-16 14:09:25.198188: step 19578, loss = 0.25325 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:09:26.162927 ops/training.py:65 2019-01-16 14:09:26.162840: step 19579, loss = 0.31225 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:09:27.125755 ops/training.py:65 2019-01-16 14:09:27.125672: step 19580, loss = 0.17271 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:09:28.088058 ops/training.py:65 2019-01-16 14:09:28.087972: step 19581, loss = 0.58803 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:09:29.049612 ops/training.py:65 2019-01-16 14:09:29.049533: step 19582, loss = 0.28605 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:09:30.013836 ops/training.py:65 2019-01-16 14:09:30.013766: step 19583, loss = 0.15669 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:09:30.977960 ops/training.py:65 2019-01-16 14:09:30.977880: step 19584, loss = 0.31751 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:09:31.941700 ops/training.py:65 2019-01-16 14:09:31.941623: step 19585, loss = 0.27276 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:09:32.904477 ops/training.py:65 2019-01-16 14:09:32.904397: step 19586, loss = 0.35720 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:09:33.867563 ops/training.py:65 2019-01-16 14:09:33.867490: step 19587, loss = 0.36071 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:09:34.828164 ops/training.py:65 2019-01-16 14:09:34.828092: step 19588, loss = 0.21706 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:09:35.793414 ops/training.py:65 2019-01-16 14:09:35.793338: step 19589, loss = 0.48097 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:09:36.758382 ops/training.py:65 2019-01-16 14:09:36.758303: step 19590, loss = 0.15209 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:09:37.719942 ops/training.py:65 2019-01-16 14:09:37.719844: step 19591, loss = 0.20220 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:09:38.683876 ops/training.py:65 2019-01-16 14:09:38.683794: step 19592, loss = 0.17050 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:09:39.645988 ops/training.py:65 2019-01-16 14:09:39.645914: step 19593, loss = 0.40368 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:09:40.608959 ops/training.py:65 2019-01-16 14:09:40.608879: step 19594, loss = 0.29237 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:09:41.571169 ops/training.py:65 2019-01-16 14:09:41.571091: step 19595, loss = 0.20839 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:09:42.535521 ops/training.py:65 2019-01-16 14:09:42.535440: step 19596, loss = 0.23001 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:09:43.498792 ops/training.py:65 2019-01-16 14:09:43.498719: step 19597, loss = 0.30814 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:09:44.461086 ops/training.py:65 2019-01-16 14:09:44.461007: step 19598, loss = 0.25982 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:09:45.422024 ops/training.py:65 2019-01-16 14:09:45.421957: step 19599, loss = 0.22288 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:09:46.383208 ops/training.py:65 2019-01-16 14:09:46.383128: step 19600, loss = 0.28196 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:09:47.347758 ops/training.py:65 2019-01-16 14:09:47.347699: step 19601, loss = 0.29388 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:09:48.309526 ops/training.py:65 2019-01-16 14:09:48.309447: step 19602, loss = 0.36580 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:09:49.275416 ops/training.py:65 2019-01-16 14:09:49.275337: step 19603, loss = 0.24274 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:09:50.236663 ops/training.py:65 2019-01-16 14:09:50.236604: step 19604, loss = 0.20435 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:09:51.198369 ops/training.py:65 2019-01-16 14:09:51.198290: step 19605, loss = 0.42305 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:09:52.160702 ops/training.py:65 2019-01-16 14:09:52.160622: step 19606, loss = 0.22235 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:09:53.125561 ops/training.py:65 2019-01-16 14:09:53.125478: step 19607, loss = 0.32134 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:09:54.089891 ops/training.py:65 2019-01-16 14:09:54.089811: step 19608, loss = 0.33973 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:09:55.051872 ops/training.py:65 2019-01-16 14:09:55.051789: step 19609, loss = 0.42852 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:09:56.017687 ops/training.py:65 2019-01-16 14:09:56.017607: step 19610, loss = 0.44542 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:09:56.980245 ops/training.py:65 2019-01-16 14:09:56.980169: step 19611, loss = 0.26682 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:09:57.942694 ops/training.py:65 2019-01-16 14:09:57.942613: step 19612, loss = 0.27488 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:09:58.906133 ops/training.py:65 2019-01-16 14:09:58.906055: step 19613, loss = 0.35125 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:09:59.868487 ops/training.py:65 2019-01-16 14:09:59.868414: step 19614, loss = 0.22574 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:10:00.831283 ops/training.py:65 2019-01-16 14:10:00.831209: step 19615, loss = 0.35950 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:10:01.795753 ops/training.py:65 2019-01-16 14:10:01.795686: step 19616, loss = 0.29448 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:10:02.756687 ops/training.py:65 2019-01-16 14:10:02.756605: step 19617, loss = 0.24253 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:10:03.722435 ops/training.py:65 2019-01-16 14:10:03.722355: step 19618, loss = 0.16494 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:10:04.686272 ops/training.py:65 2019-01-16 14:10:04.686210: step 19619, loss = 0.26659 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:10:05.649342 ops/training.py:65 2019-01-16 14:10:05.649258: step 19620, loss = 0.37726 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:10:06.612584 ops/training.py:65 2019-01-16 14:10:06.612499: step 19621, loss = 0.32760 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:10:07.574865 ops/training.py:65 2019-01-16 14:10:07.574778: step 19622, loss = 0.34223 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:10:08.537896 ops/training.py:65 2019-01-16 14:10:08.537813: step 19623, loss = 0.22723 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:10:09.501892 ops/training.py:65 2019-01-16 14:10:09.501813: step 19624, loss = 0.45357 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:10:10.466096 ops/training.py:65 2019-01-16 14:10:10.466014: step 19625, loss = 0.44004 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:10:11.429632 ops/training.py:65 2019-01-16 14:10:11.429544: step 19626, loss = 0.35822 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:10:12.393184 ops/training.py:65 2019-01-16 14:10:12.393099: step 19627, loss = 0.24473 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:10:13.356538 ops/training.py:65 2019-01-16 14:10:13.356468: step 19628, loss = 0.32269 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:10:14.317996 ops/training.py:65 2019-01-16 14:10:14.317936: step 19629, loss = 0.34429 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:10:15.279269 ops/training.py:65 2019-01-16 14:10:15.279209: step 19630, loss = 0.30497 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:10:16.241816 ops/training.py:65 2019-01-16 14:10:16.241738: step 19631, loss = 0.33232 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:10:17.203720 ops/training.py:65 2019-01-16 14:10:17.203642: step 19632, loss = 0.29185 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:10:18.168245 ops/training.py:65 2019-01-16 14:10:18.168168: step 19633, loss = 0.36914 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:10:19.130114 ops/training.py:65 2019-01-16 14:10:19.130033: step 19634, loss = 0.19881 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:10:20.091989 ops/training.py:65 2019-01-16 14:10:20.091918: step 19635, loss = 0.21553 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:10:21.054767 ops/training.py:65 2019-01-16 14:10:21.054693: step 19636, loss = 0.28020 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:10:22.018007 ops/training.py:65 2019-01-16 14:10:22.017931: step 19637, loss = 0.19513 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:10:22.979810 ops/training.py:65 2019-01-16 14:10:22.979734: step 19638, loss = 0.28356 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:10:23.942229 ops/training.py:65 2019-01-16 14:10:23.942150: step 19639, loss = 0.35431 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:10:24.904889 ops/training.py:65 2019-01-16 14:10:24.904816: step 19640, loss = 0.25068 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:10:25.867280 ops/training.py:65 2019-01-16 14:10:25.867202: step 19641, loss = 0.17933 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:10:26.830148 ops/training.py:65 2019-01-16 14:10:26.830069: step 19642, loss = 0.36415 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:10:27.793970 ops/training.py:65 2019-01-16 14:10:27.793887: step 19643, loss = 0.26086 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:10:28.758735 ops/training.py:65 2019-01-16 14:10:28.758654: step 19644, loss = 0.32062 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:10:29.721945 ops/training.py:65 2019-01-16 14:10:29.721876: step 19645, loss = 0.27320 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:10:30.683235 ops/training.py:65 2019-01-16 14:10:30.683156: step 19646, loss = 0.18391 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:10:31.645886 ops/training.py:65 2019-01-16 14:10:31.645808: step 19647, loss = 0.21920 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:10:32.610709 ops/training.py:65 2019-01-16 14:10:32.610633: step 19648, loss = 0.19099 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:10:33.573287 ops/training.py:65 2019-01-16 14:10:33.573211: step 19649, loss = 0.19561 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:10:34.535077 ops/training.py:65 2019-01-16 14:10:34.535001: step 19650, loss = 0.24316 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:10:35.496656 ops/training.py:65 2019-01-16 14:10:35.496597: step 19651, loss = 0.30767 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:10:36.457897 ops/training.py:65 2019-01-16 14:10:36.457816: step 19652, loss = 0.23952 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:10:37.418843 ops/training.py:65 2019-01-16 14:10:37.418764: step 19653, loss = 0.27217 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:10:38.380797 ops/training.py:65 2019-01-16 14:10:38.380734: step 19654, loss = 0.18058 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:10:39.344023 ops/training.py:65 2019-01-16 14:10:39.343949: step 19655, loss = 0.44796 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:10:40.305660 ops/training.py:65 2019-01-16 14:10:40.305581: step 19656, loss = 0.35403 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:10:41.267701 ops/training.py:65 2019-01-16 14:10:41.267619: step 19657, loss = 0.24553 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:10:42.229046 ops/training.py:65 2019-01-16 14:10:42.228967: step 19658, loss = 0.25163 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:10:43.190069 ops/training.py:65 2019-01-16 14:10:43.189997: step 19659, loss = 0.30275 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:10:44.151344 ops/training.py:65 2019-01-16 14:10:44.151268: step 19660, loss = 0.27622 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:10:45.112260 ops/training.py:65 2019-01-16 14:10:45.112200: step 19661, loss = 0.22874 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:10:46.073432 ops/training.py:65 2019-01-16 14:10:46.073363: step 19662, loss = 0.24016 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:10:47.035747 ops/training.py:65 2019-01-16 14:10:47.035668: step 19663, loss = 0.49044 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:10:48.000559 ops/training.py:65 2019-01-16 14:10:48.000480: step 19664, loss = 0.30305 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:10:48.964128 ops/training.py:65 2019-01-16 14:10:48.964046: step 19665, loss = 0.28187 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:10:49.926931 ops/training.py:65 2019-01-16 14:10:49.926857: step 19666, loss = 0.28655 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:10:50.888480 ops/training.py:65 2019-01-16 14:10:50.888400: step 19667, loss = 0.24057 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:10:51.853297 ops/training.py:65 2019-01-16 14:10:51.853219: step 19668, loss = 0.40299 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:10:52.817177 ops/training.py:65 2019-01-16 14:10:52.817105: step 19669, loss = 0.35145 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:10:53.779782 ops/training.py:65 2019-01-16 14:10:53.779703: step 19670, loss = 0.30889 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:10:54.743101 ops/training.py:65 2019-01-16 14:10:54.743023: step 19671, loss = 0.27328 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:10:55.706885 ops/training.py:65 2019-01-16 14:10:55.706806: step 19672, loss = 0.20458 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:10:56.669741 ops/training.py:65 2019-01-16 14:10:56.669663: step 19673, loss = 0.25718 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:10:57.631506 ops/training.py:65 2019-01-16 14:10:57.631430: step 19674, loss = 0.30148 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:10:58.595520 ops/training.py:65 2019-01-16 14:10:58.595440: step 19675, loss = 0.19789 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:10:59.558155 ops/training.py:65 2019-01-16 14:10:59.558082: step 19676, loss = 0.25877 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:11:00.522853 ops/training.py:65 2019-01-16 14:11:00.522793: step 19677, loss = 0.21214 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:11:01.484860 ops/training.py:65 2019-01-16 14:11:01.484786: step 19678, loss = 0.30250 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:11:02.445733 ops/training.py:65 2019-01-16 14:11:02.445656: step 19679, loss = 0.28821 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:11:03.407336 ops/training.py:65 2019-01-16 14:11:03.407229: step 19680, loss = 0.24776 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:11:04.370832 ops/training.py:65 2019-01-16 14:11:04.370749: step 19681, loss = 0.24648 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:11:05.333249 ops/training.py:65 2019-01-16 14:11:05.333184: step 19682, loss = 0.36029 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:11:06.295361 ops/training.py:65 2019-01-16 14:11:06.295282: step 19683, loss = 0.24211 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:11:07.256953 ops/training.py:65 2019-01-16 14:11:07.256873: step 19684, loss = 0.24205 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:11:08.218805 ops/training.py:65 2019-01-16 14:11:08.218727: step 19685, loss = 0.26404 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:11:09.179996 ops/training.py:65 2019-01-16 14:11:09.179907: step 19686, loss = 0.16439 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:11:10.142549 ops/training.py:65 2019-01-16 14:11:10.142478: step 19687, loss = 0.29769 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:11:11.105173 ops/training.py:65 2019-01-16 14:11:11.105092: step 19688, loss = 0.17260 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:11:12.067073 ops/training.py:65 2019-01-16 14:11:12.066995: step 19689, loss = 0.16431 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:11:13.029416 ops/training.py:65 2019-01-16 14:11:13.029355: step 19690, loss = 0.20378 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:11:13.990922 ops/training.py:65 2019-01-16 14:11:13.990870: step 19691, loss = 0.19892 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:11:14.953384 ops/training.py:65 2019-01-16 14:11:14.953324: step 19692, loss = 0.25777 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:11:15.915977 ops/training.py:65 2019-01-16 14:11:15.915906: step 19693, loss = 0.23512 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:11:16.877158 ops/training.py:65 2019-01-16 14:11:16.877080: step 19694, loss = 0.09971 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:11:17.838177 ops/training.py:65 2019-01-16 14:11:17.838092: step 19695, loss = 0.27262 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:11:18.800045 ops/training.py:65 2019-01-16 14:11:18.799960: step 19696, loss = 0.17228 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:11:19.761431 ops/training.py:65 2019-01-16 14:11:19.761371: step 19697, loss = 0.33822 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:11:20.723328 ops/training.py:65 2019-01-16 14:11:20.723253: step 19698, loss = 0.26483 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:11:21.684684 ops/training.py:65 2019-01-16 14:11:21.684610: step 19699, loss = 0.33711 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:11:22.648435 ops/training.py:65 2019-01-16 14:11:22.648351: step 19700, loss = 0.32325 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:11:23.612922 ops/training.py:65 2019-01-16 14:11:23.612841: step 19701, loss = 0.29339 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:11:24.576883 ops/training.py:65 2019-01-16 14:11:24.576804: step 19702, loss = 0.38932 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:11:25.540257 ops/training.py:65 2019-01-16 14:11:25.540180: step 19703, loss = 0.20430 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:11:26.502326 ops/training.py:65 2019-01-16 14:11:26.502244: step 19704, loss = 0.15694 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:11:27.467435 ops/training.py:65 2019-01-16 14:11:27.467353: step 19705, loss = 0.33323 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:11:28.429457 ops/training.py:65 2019-01-16 14:11:28.429381: step 19706, loss = 0.21320 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:11:29.392239 ops/training.py:65 2019-01-16 14:11:29.392156: step 19707, loss = 0.22252 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:11:30.355406 ops/training.py:65 2019-01-16 14:11:30.355332: step 19708, loss = 0.24001 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:11:31.319281 ops/training.py:65 2019-01-16 14:11:31.319215: step 19709, loss = 0.14950 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:11:32.280265 ops/training.py:65 2019-01-16 14:11:32.280163: step 19710, loss = 0.28106 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:11:33.242335 ops/training.py:65 2019-01-16 14:11:33.242256: step 19711, loss = 0.25015 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:11:34.203956 ops/training.py:65 2019-01-16 14:11:34.203876: step 19712, loss = 0.36062 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:11:35.165393 ops/training.py:65 2019-01-16 14:11:35.165331: step 19713, loss = 0.26769 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:11:36.128711 ops/training.py:65 2019-01-16 14:11:36.128630: step 19714, loss = 0.32668 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:11:37.091730 ops/training.py:65 2019-01-16 14:11:37.091651: step 19715, loss = 0.29687 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:11:38.056662 ops/training.py:65 2019-01-16 14:11:38.056590: step 19716, loss = 0.28642 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:11:39.020619 ops/training.py:65 2019-01-16 14:11:39.020540: step 19717, loss = 0.24109 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:11:39.984544 ops/training.py:65 2019-01-16 14:11:39.984470: step 19718, loss = 0.24621 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:11:40.947063 ops/training.py:65 2019-01-16 14:11:40.946986: step 19719, loss = 0.32937 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:11:41.908471 ops/training.py:65 2019-01-16 14:11:41.908391: step 19720, loss = 0.13739 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:11:42.872246 ops/training.py:65 2019-01-16 14:11:42.872163: step 19721, loss = 0.28686 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:11:43.836113 ops/training.py:65 2019-01-16 14:11:43.836033: step 19722, loss = 0.24748 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:11:44.799440 ops/training.py:65 2019-01-16 14:11:44.799361: step 19723, loss = 0.25378 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:11:45.760553 ops/training.py:65 2019-01-16 14:11:45.760481: step 19724, loss = 0.34770 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:11:46.720981 ops/training.py:65 2019-01-16 14:11:46.720899: step 19725, loss = 0.21569 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:11:47.684401 ops/training.py:65 2019-01-16 14:11:47.684321: step 19726, loss = 0.30656 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:11:48.646542 ops/training.py:65 2019-01-16 14:11:48.646460: step 19727, loss = 0.29325 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:11:49.608517 ops/training.py:65 2019-01-16 14:11:49.608441: step 19728, loss = 0.30981 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:11:50.569663 ops/training.py:65 2019-01-16 14:11:50.569600: step 19729, loss = 0.17658 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:11:51.531214 ops/training.py:65 2019-01-16 14:11:51.531151: step 19730, loss = 0.26735 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:11:52.493937 ops/training.py:65 2019-01-16 14:11:52.493876: step 19731, loss = 0.27346 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:11:53.458829 ops/training.py:65 2019-01-16 14:11:53.458766: step 19732, loss = 0.26602 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:11:54.419989 ops/training.py:65 2019-01-16 14:11:54.419910: step 19733, loss = 0.31812 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:11:55.380449 ops/training.py:65 2019-01-16 14:11:55.380368: step 19734, loss = 0.31948 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:11:56.342920 ops/training.py:65 2019-01-16 14:11:56.342839: step 19735, loss = 0.38223 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:11:57.308692 ops/training.py:65 2019-01-16 14:11:57.308612: step 19736, loss = 0.32906 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:11:58.270779 ops/training.py:65 2019-01-16 14:11:58.270696: step 19737, loss = 0.26183 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:11:59.236107 ops/training.py:65 2019-01-16 14:11:59.236024: step 19738, loss = 0.32176 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:12:00.197114 ops/training.py:65 2019-01-16 14:12:00.197039: step 19739, loss = 0.19073 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:12:01.158146 ops/training.py:65 2019-01-16 14:12:01.158071: step 19740, loss = 0.24877 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:12:02.118849 ops/training.py:65 2019-01-16 14:12:02.118778: step 19741, loss = 0.13011 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:12:03.081997 ops/training.py:65 2019-01-16 14:12:03.081919: step 19742, loss = 0.24177 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:12:04.043624 ops/training.py:65 2019-01-16 14:12:04.043547: step 19743, loss = 0.29626 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:12:05.008834 ops/training.py:65 2019-01-16 14:12:05.008774: step 19744, loss = 0.35965 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:12:05.971915 ops/training.py:65 2019-01-16 14:12:05.971836: step 19745, loss = 0.28651 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:12:06.933694 ops/training.py:65 2019-01-16 14:12:06.933620: step 19746, loss = 0.34151 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:12:07.895701 ops/training.py:65 2019-01-16 14:12:07.895619: step 19747, loss = 0.23512 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:12:08.856481 ops/training.py:65 2019-01-16 14:12:08.856403: step 19748, loss = 0.29340 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:12:09.819509 ops/training.py:65 2019-01-16 14:12:09.819434: step 19749, loss = 0.33347 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:12:10.781871 ops/training.py:65 2019-01-16 14:12:10.781789: step 19750, loss = 0.24180 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:12:11.743909 ops/training.py:65 2019-01-16 14:12:11.743828: step 19751, loss = 0.28870 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:12:12.705476 ops/training.py:65 2019-01-16 14:12:12.705418: step 19752, loss = 0.25296 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:12:13.666386 ops/training.py:65 2019-01-16 14:12:13.666321: step 19753, loss = 0.25622 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:12:14.628951 ops/training.py:65 2019-01-16 14:12:14.628892: step 19754, loss = 0.25340 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:12:15.591664 ops/training.py:65 2019-01-16 14:12:15.591595: step 19755, loss = 0.22879 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:12:16.554652 ops/training.py:65 2019-01-16 14:12:16.554572: step 19756, loss = 0.26493 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:12:17.518722 ops/training.py:65 2019-01-16 14:12:17.518644: step 19757, loss = 0.32741 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:12:18.482404 ops/training.py:65 2019-01-16 14:12:18.482322: step 19758, loss = 0.19195 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:12:19.445707 ops/training.py:65 2019-01-16 14:12:19.445635: step 19759, loss = 0.42787 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:12:20.408026 ops/training.py:65 2019-01-16 14:12:20.407963: step 19760, loss = 0.24707 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:12:21.369499 ops/training.py:65 2019-01-16 14:12:21.369421: step 19761, loss = 0.26984 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:12:22.330767 ops/training.py:65 2019-01-16 14:12:22.330663: step 19762, loss = 0.16255 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:12:23.293735 ops/training.py:65 2019-01-16 14:12:23.293657: step 19763, loss = 0.32600 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:12:24.258031 ops/training.py:65 2019-01-16 14:12:24.257961: step 19764, loss = 0.26729 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:12:25.220941 ops/training.py:65 2019-01-16 14:12:25.220862: step 19765, loss = 0.32199 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:12:26.183944 ops/training.py:65 2019-01-16 14:12:26.183864: step 19766, loss = 0.38675 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:12:27.146159 ops/training.py:65 2019-01-16 14:12:27.146057: step 19767, loss = 0.15842 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:12:28.108270 ops/training.py:65 2019-01-16 14:12:28.108188: step 19768, loss = 0.22335 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:12:29.070162 ops/training.py:65 2019-01-16 14:12:29.070080: step 19769, loss = 0.45891 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.6875
I0832 2019-01-16 14:12:30.032310 ops/training.py:65 2019-01-16 14:12:30.032213: step 19770, loss = 0.39000 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:12:30.994086 ops/training.py:65 2019-01-16 14:12:30.994003: step 19771, loss = 0.37385 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:12:31.956057 ops/training.py:65 2019-01-16 14:12:31.955992: step 19772, loss = 0.26625 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:12:32.916001 ops/training.py:65 2019-01-16 14:12:32.915925: step 19773, loss = 0.25952 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:12:33.876035 ops/training.py:65 2019-01-16 14:12:33.875965: step 19774, loss = 0.30211 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:12:34.835323 ops/training.py:65 2019-01-16 14:12:34.835274: step 19775, loss = 0.24568 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:12:35.795393 ops/training.py:65 2019-01-16 14:12:35.795327: step 19776, loss = 0.30903 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:12:36.755787 ops/training.py:65 2019-01-16 14:12:36.755732: step 19777, loss = 0.33796 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:12:37.720842 ops/training.py:65 2019-01-16 14:12:37.720775: step 19778, loss = 0.20336 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:12:38.683446 ops/training.py:65 2019-01-16 14:12:38.683341: step 19779, loss = 0.18803 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:12:39.645053 ops/training.py:65 2019-01-16 14:12:39.644980: step 19780, loss = 0.24184 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:12:40.607901 ops/training.py:65 2019-01-16 14:12:40.607826: step 19781, loss = 0.29100 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:12:41.570169 ops/training.py:65 2019-01-16 14:12:41.570089: step 19782, loss = 0.35465 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:12:42.532292 ops/training.py:65 2019-01-16 14:12:42.532213: step 19783, loss = 0.27025 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:12:43.494814 ops/training.py:65 2019-01-16 14:12:43.494734: step 19784, loss = 0.25630 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:12:44.460581 ops/training.py:65 2019-01-16 14:12:44.460517: step 19785, loss = 0.40736 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:12:45.421143 ops/training.py:65 2019-01-16 14:12:45.421075: step 19786, loss = 0.27466 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:12:46.382305 ops/training.py:65 2019-01-16 14:12:46.382229: step 19787, loss = 0.18997 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:12:47.343812 ops/training.py:65 2019-01-16 14:12:47.343741: step 19788, loss = 0.22252 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:12:48.306063 ops/training.py:65 2019-01-16 14:12:48.305981: step 19789, loss = 0.38188 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:12:49.270679 ops/training.py:65 2019-01-16 14:12:49.270595: step 19790, loss = 0.18978 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:12:50.233755 ops/training.py:65 2019-01-16 14:12:50.233680: step 19791, loss = 0.28320 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:12:51.196839 ops/training.py:65 2019-01-16 14:12:51.196756: step 19792, loss = 0.24609 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:12:52.157617 ops/training.py:65 2019-01-16 14:12:52.157541: step 19793, loss = 0.17456 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:12:53.118625 ops/training.py:65 2019-01-16 14:12:53.118546: step 19794, loss = 0.33104 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:12:54.079315 ops/training.py:65 2019-01-16 14:12:54.079236: step 19795, loss = 0.30984 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:12:55.040846 ops/training.py:65 2019-01-16 14:12:55.040739: step 19796, loss = 0.27862 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:12:56.004329 ops/training.py:65 2019-01-16 14:12:56.004246: step 19797, loss = 0.38093 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:12:56.968268 ops/training.py:65 2019-01-16 14:12:56.968189: step 19798, loss = 0.25015 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:12:57.930790 ops/training.py:65 2019-01-16 14:12:57.930711: step 19799, loss = 0.43533 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:12:58.893712 ops/training.py:65 2019-01-16 14:12:58.893634: step 19800, loss = 0.23938 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:12:59.856144 ops/training.py:65 2019-01-16 14:12:59.856071: step 19801, loss = 0.18250 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:13:00.818023 ops/training.py:65 2019-01-16 14:13:00.817947: step 19802, loss = 0.22432 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:13:01.779201 ops/training.py:65 2019-01-16 14:13:01.779148: step 19803, loss = 0.37895 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:13:02.738999 ops/training.py:65 2019-01-16 14:13:02.738943: step 19804, loss = 0.21408 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:13:03.699213 ops/training.py:65 2019-01-16 14:13:03.699156: step 19805, loss = 0.46722 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:13:04.659269 ops/training.py:65 2019-01-16 14:13:04.659208: step 19806, loss = 0.35050 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:13:05.619889 ops/training.py:65 2019-01-16 14:13:05.619832: step 19807, loss = 0.17687 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:13:06.582812 ops/training.py:65 2019-01-16 14:13:06.582746: step 19808, loss = 0.18983 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:13:07.546574 ops/training.py:65 2019-01-16 14:13:07.546496: step 19809, loss = 0.39132 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:13:08.509082 ops/training.py:65 2019-01-16 14:13:08.508981: step 19810, loss = 0.20237 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:13:09.471244 ops/training.py:65 2019-01-16 14:13:09.471164: step 19811, loss = 0.40236 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:13:10.433707 ops/training.py:65 2019-01-16 14:13:10.433583: step 19812, loss = 0.28655 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:13:11.399369 ops/training.py:65 2019-01-16 14:13:11.399270: step 19813, loss = 0.28731 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:13:12.360640 ops/training.py:65 2019-01-16 14:13:12.360547: step 19814, loss = 0.40264 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:13:13.322963 ops/training.py:65 2019-01-16 14:13:13.322862: step 19815, loss = 0.43605 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:13:14.288597 ops/training.py:65 2019-01-16 14:13:14.288503: step 19816, loss = 0.37429 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:13:15.251324 ops/training.py:65 2019-01-16 14:13:15.251244: step 19817, loss = 0.23453 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:13:16.213597 ops/training.py:65 2019-01-16 14:13:16.213506: step 19818, loss = 0.22005 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:13:17.178586 ops/training.py:65 2019-01-16 14:13:17.178488: step 19819, loss = 0.15669 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:13:18.140852 ops/training.py:65 2019-01-16 14:13:18.140750: step 19820, loss = 0.31923 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:13:19.103292 ops/training.py:65 2019-01-16 14:13:19.103193: step 19821, loss = 0.33053 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:13:20.064980 ops/training.py:65 2019-01-16 14:13:20.064885: step 19822, loss = 0.22999 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:13:21.026729 ops/training.py:65 2019-01-16 14:13:21.026631: step 19823, loss = 0.25409 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:13:21.989734 ops/training.py:65 2019-01-16 14:13:21.989636: step 19824, loss = 0.17715 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:13:22.951704 ops/training.py:65 2019-01-16 14:13:22.951616: step 19825, loss = 0.59195 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:13:23.913299 ops/training.py:65 2019-01-16 14:13:23.913213: step 19826, loss = 0.27275 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:13:24.874586 ops/training.py:65 2019-01-16 14:13:24.874494: step 19827, loss = 0.26538 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:13:25.835610 ops/training.py:65 2019-01-16 14:13:25.835521: step 19828, loss = 0.32761 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:13:26.797259 ops/training.py:65 2019-01-16 14:13:26.797153: step 19829, loss = 0.22977 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:13:27.758660 ops/training.py:65 2019-01-16 14:13:27.758560: step 19830, loss = 0.17597 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:13:28.719821 ops/training.py:65 2019-01-16 14:13:28.719727: step 19831, loss = 0.18514 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:13:29.681720 ops/training.py:65 2019-01-16 14:13:29.681624: step 19832, loss = 0.37421 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:13:30.643859 ops/training.py:65 2019-01-16 14:13:30.643804: step 19833, loss = 0.41977 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:13:31.605021 ops/training.py:65 2019-01-16 14:13:31.604921: step 19834, loss = 0.26820 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:13:32.567168 ops/training.py:65 2019-01-16 14:13:32.567070: step 19835, loss = 0.19083 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:13:33.528493 ops/training.py:65 2019-01-16 14:13:33.528384: step 19836, loss = 0.19255 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:13:34.490655 ops/training.py:65 2019-01-16 14:13:34.490571: step 19837, loss = 0.19355 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:13:35.451928 ops/training.py:65 2019-01-16 14:13:35.451866: step 19838, loss = 0.29447 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:13:36.413677 ops/training.py:65 2019-01-16 14:13:36.413608: step 19839, loss = 0.22822 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:13:37.375552 ops/training.py:65 2019-01-16 14:13:37.375450: step 19840, loss = 0.21940 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:13:38.336845 ops/training.py:65 2019-01-16 14:13:38.336775: step 19841, loss = 0.43237 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:13:39.298737 ops/training.py:65 2019-01-16 14:13:39.298639: step 19842, loss = 0.20909 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:13:40.262387 ops/training.py:65 2019-01-16 14:13:40.262292: step 19843, loss = 0.14905 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:13:41.225620 ops/training.py:65 2019-01-16 14:13:41.225508: step 19844, loss = 0.25095 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:13:42.189932 ops/training.py:65 2019-01-16 14:13:42.189834: step 19845, loss = 0.27440 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:13:43.151582 ops/training.py:65 2019-01-16 14:13:43.151478: step 19846, loss = 0.23241 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:13:44.117137 ops/training.py:65 2019-01-16 14:13:44.117041: step 19847, loss = 0.25111 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:13:45.082353 ops/training.py:65 2019-01-16 14:13:45.082271: step 19848, loss = 0.27928 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:13:46.045339 ops/training.py:65 2019-01-16 14:13:46.045253: step 19849, loss = 0.44180 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:13:47.005505 ops/training.py:65 2019-01-16 14:13:47.005409: step 19850, loss = 0.59014 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:13:47.969458 ops/training.py:65 2019-01-16 14:13:47.969359: step 19851, loss = 0.23925 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:13:48.932237 ops/training.py:65 2019-01-16 14:13:48.932140: step 19852, loss = 0.31856 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:13:49.893808 ops/training.py:65 2019-01-16 14:13:49.893725: step 19853, loss = 0.15147 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:13:50.855237 ops/training.py:65 2019-01-16 14:13:50.855144: step 19854, loss = 0.19182 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:13:51.816494 ops/training.py:65 2019-01-16 14:13:51.816381: step 19855, loss = 0.30600 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:13:52.779673 ops/training.py:65 2019-01-16 14:13:52.779556: step 19856, loss = 0.40018 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:13:53.742457 ops/training.py:65 2019-01-16 14:13:53.742365: step 19857, loss = 0.26324 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:13:54.704941 ops/training.py:65 2019-01-16 14:13:54.704845: step 19858, loss = 0.23866 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:13:55.667440 ops/training.py:65 2019-01-16 14:13:55.667291: step 19859, loss = 0.20921 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:13:56.630295 ops/training.py:65 2019-01-16 14:13:56.630192: step 19860, loss = 0.28045 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:13:57.592279 ops/training.py:65 2019-01-16 14:13:57.592164: step 19861, loss = 0.19662 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:13:58.554074 ops/training.py:65 2019-01-16 14:13:58.553977: step 19862, loss = 0.19540 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:13:59.514666 ops/training.py:65 2019-01-16 14:13:59.514572: step 19863, loss = 0.19695 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:14:00.475317 ops/training.py:65 2019-01-16 14:14:00.475220: step 19864, loss = 0.23783 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:14:01.439634 ops/training.py:65 2019-01-16 14:14:01.439547: step 19865, loss = 0.45532 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:14:02.402273 ops/training.py:65 2019-01-16 14:14:02.402173: step 19866, loss = 0.21251 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:14:03.365288 ops/training.py:65 2019-01-16 14:14:03.365226: step 19867, loss = 0.36204 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:14:04.328051 ops/training.py:65 2019-01-16 14:14:04.327944: step 19868, loss = 0.37699 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:14:05.290815 ops/training.py:65 2019-01-16 14:14:05.290706: step 19869, loss = 0.15701 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:14:06.252029 ops/training.py:65 2019-01-16 14:14:06.251930: step 19870, loss = 0.32684 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:14:07.212807 ops/training.py:65 2019-01-16 14:14:07.212706: step 19871, loss = 0.33919 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:14:08.175015 ops/training.py:65 2019-01-16 14:14:08.174900: step 19872, loss = 0.13839 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:14:09.136970 ops/training.py:65 2019-01-16 14:14:09.136856: step 19873, loss = 0.32560 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:14:10.099261 ops/training.py:65 2019-01-16 14:14:10.099169: step 19874, loss = 0.26146 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:14:11.060554 ops/training.py:65 2019-01-16 14:14:11.060462: step 19875, loss = 0.31239 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:14:12.021708 ops/training.py:65 2019-01-16 14:14:12.021608: step 19876, loss = 0.24462 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:14:12.983064 ops/training.py:65 2019-01-16 14:14:12.982952: step 19877, loss = 0.33516 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:14:13.945517 ops/training.py:65 2019-01-16 14:14:13.945423: step 19878, loss = 0.25847 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:14:14.907186 ops/training.py:65 2019-01-16 14:14:14.907078: step 19879, loss = 0.33743 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:14:15.870964 ops/training.py:65 2019-01-16 14:14:15.870883: step 19880, loss = 0.28958 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:14:16.833437 ops/training.py:65 2019-01-16 14:14:16.833342: step 19881, loss = 0.28447 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:14:17.795250 ops/training.py:65 2019-01-16 14:14:17.795151: step 19882, loss = 0.46283 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:14:18.757867 ops/training.py:65 2019-01-16 14:14:18.757798: step 19883, loss = 0.35879 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:14:19.717512 ops/training.py:65 2019-01-16 14:14:19.717419: step 19884, loss = 0.54566 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:14:20.678796 ops/training.py:65 2019-01-16 14:14:20.678700: step 19885, loss = 0.16454 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:14:21.642120 ops/training.py:65 2019-01-16 14:14:21.642020: step 19886, loss = 0.26781 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:14:22.605512 ops/training.py:65 2019-01-16 14:14:22.605414: step 19887, loss = 0.18469 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:14:23.567517 ops/training.py:65 2019-01-16 14:14:23.567409: step 19888, loss = 0.13929 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:14:24.530229 ops/training.py:65 2019-01-16 14:14:24.530039: step 19889, loss = 0.15365 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:14:25.491541 ops/training.py:65 2019-01-16 14:14:25.491489: step 19890, loss = 0.38657 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:14:26.454595 ops/training.py:65 2019-01-16 14:14:26.454496: step 19891, loss = 0.17739 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:14:27.416542 ops/training.py:65 2019-01-16 14:14:27.416439: step 19892, loss = 0.18474 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:14:28.378281 ops/training.py:65 2019-01-16 14:14:28.378177: step 19893, loss = 0.23694 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:14:29.340283 ops/training.py:65 2019-01-16 14:14:29.340193: step 19894, loss = 0.33134 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:14:30.301871 ops/training.py:65 2019-01-16 14:14:30.301803: step 19895, loss = 0.18084 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:14:31.263720 ops/training.py:65 2019-01-16 14:14:31.263620: step 19896, loss = 0.46329 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:14:32.228772 ops/training.py:65 2019-01-16 14:14:32.228655: step 19897, loss = 0.27217 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:14:33.193927 ops/training.py:65 2019-01-16 14:14:33.193811: step 19898, loss = 0.37743 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:14:34.156714 ops/training.py:65 2019-01-16 14:14:34.156647: step 19899, loss = 0.15320 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:14:35.119285 ops/training.py:65 2019-01-16 14:14:35.119200: step 19900, loss = 0.24888 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:14:36.081014 ops/training.py:65 2019-01-16 14:14:36.080895: step 19901, loss = 0.36437 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:14:37.042932 ops/training.py:65 2019-01-16 14:14:37.042831: step 19902, loss = 0.30758 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:14:38.010989 ops/training.py:65 2019-01-16 14:14:38.010895: step 19903, loss = 0.28307 (33.1 examples/sec; 0.967 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:14:38.972743 ops/training.py:65 2019-01-16 14:14:38.972645: step 19904, loss = 0.37982 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:14:39.936204 ops/training.py:65 2019-01-16 14:14:39.936110: step 19905, loss = 0.30246 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:14:40.900177 ops/training.py:65 2019-01-16 14:14:40.900070: step 19906, loss = 0.26091 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:14:41.864389 ops/training.py:65 2019-01-16 14:14:41.864292: step 19907, loss = 0.28969 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:14:42.826211 ops/training.py:65 2019-01-16 14:14:42.826116: step 19908, loss = 0.24011 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:14:43.787649 ops/training.py:65 2019-01-16 14:14:43.787552: step 19909, loss = 0.27587 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:14:44.749943 ops/training.py:65 2019-01-16 14:14:44.749833: step 19910, loss = 0.29288 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:14:45.714021 ops/training.py:65 2019-01-16 14:14:45.713924: step 19911, loss = 0.16648 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:14:46.678818 ops/training.py:65 2019-01-16 14:14:46.678706: step 19912, loss = 0.20648 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:14:47.643471 ops/training.py:65 2019-01-16 14:14:47.643356: step 19913, loss = 0.28559 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:14:48.606825 ops/training.py:65 2019-01-16 14:14:48.606712: step 19914, loss = 0.23789 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:14:49.569904 ops/training.py:65 2019-01-16 14:14:49.569813: step 19915, loss = 0.20775 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:14:50.530808 ops/training.py:65 2019-01-16 14:14:50.530700: step 19916, loss = 0.28800 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:14:51.495041 ops/training.py:65 2019-01-16 14:14:51.494933: step 19917, loss = 0.19866 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:14:52.458460 ops/training.py:65 2019-01-16 14:14:52.458377: step 19918, loss = 0.31344 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:14:53.421249 ops/training.py:65 2019-01-16 14:14:53.421149: step 19919, loss = 0.27980 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:14:54.384647 ops/training.py:65 2019-01-16 14:14:54.384538: step 19920, loss = 0.38671 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:14:55.348695 ops/training.py:65 2019-01-16 14:14:55.348604: step 19921, loss = 0.42910 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:14:56.310961 ops/training.py:65 2019-01-16 14:14:56.310864: step 19922, loss = 0.30357 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:14:57.271974 ops/training.py:65 2019-01-16 14:14:57.271916: step 19923, loss = 0.53099 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:14:58.232942 ops/training.py:65 2019-01-16 14:14:58.232848: step 19924, loss = 0.20933 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:14:59.193933 ops/training.py:65 2019-01-16 14:14:59.193827: step 19925, loss = 0.29027 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:15:00.155840 ops/training.py:65 2019-01-16 14:15:00.155736: step 19926, loss = 0.33309 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:15:01.118116 ops/training.py:65 2019-01-16 14:15:01.118027: step 19927, loss = 0.29525 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:15:02.079950 ops/training.py:65 2019-01-16 14:15:02.079862: step 19928, loss = 0.17107 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:15:03.042674 ops/training.py:65 2019-01-16 14:15:03.042584: step 19929, loss = 0.34157 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:15:04.007288 ops/training.py:65 2019-01-16 14:15:04.007196: step 19930, loss = 0.38191 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:15:04.970424 ops/training.py:65 2019-01-16 14:15:04.970356: step 19931, loss = 0.14811 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:15:05.932844 ops/training.py:65 2019-01-16 14:15:05.932742: step 19932, loss = 0.25180 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:15:06.895463 ops/training.py:65 2019-01-16 14:15:06.895369: step 19933, loss = 0.30884 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:15:07.857731 ops/training.py:65 2019-01-16 14:15:07.857653: step 19934, loss = 0.21841 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:15:08.819670 ops/training.py:65 2019-01-16 14:15:08.819592: step 19935, loss = 0.28723 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:15:09.781482 ops/training.py:65 2019-01-16 14:15:09.781387: step 19936, loss = 0.21657 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:15:10.742803 ops/training.py:65 2019-01-16 14:15:10.742710: step 19937, loss = 0.33768 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:15:11.705074 ops/training.py:65 2019-01-16 14:15:11.704960: step 19938, loss = 0.31296 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:15:12.670829 ops/training.py:65 2019-01-16 14:15:12.670759: step 19939, loss = 0.21272 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:15:13.633819 ops/training.py:65 2019-01-16 14:15:13.633729: step 19940, loss = 0.30894 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:15:14.599540 ops/training.py:65 2019-01-16 14:15:14.599448: step 19941, loss = 0.25133 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:15:15.565196 ops/training.py:65 2019-01-16 14:15:15.565116: step 19942, loss = 0.40781 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:15:16.528690 ops/training.py:65 2019-01-16 14:15:16.528574: step 19943, loss = 0.38575 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:15:17.491309 ops/training.py:65 2019-01-16 14:15:17.491216: step 19944, loss = 0.29598 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:15:18.453140 ops/training.py:65 2019-01-16 14:15:18.453039: step 19945, loss = 0.28479 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:15:19.414760 ops/training.py:65 2019-01-16 14:15:19.414677: step 19946, loss = 0.20399 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:15:20.376673 ops/training.py:65 2019-01-16 14:15:20.376584: step 19947, loss = 0.20129 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:15:21.338631 ops/training.py:65 2019-01-16 14:15:21.338540: step 19948, loss = 0.22150 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:15:22.301319 ops/training.py:65 2019-01-16 14:15:22.301225: step 19949, loss = 0.29103 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:15:23.263364 ops/training.py:65 2019-01-16 14:15:23.263277: step 19950, loss = 0.31519 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:15:24.223996 ops/training.py:65 2019-01-16 14:15:24.223906: step 19951, loss = 0.21337 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:15:25.186310 ops/training.py:65 2019-01-16 14:15:25.186155: step 19952, loss = 0.42652 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:15:26.150085 ops/training.py:65 2019-01-16 14:15:26.149996: step 19953, loss = 0.29399 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:15:27.114191 ops/training.py:65 2019-01-16 14:15:27.114094: step 19954, loss = 0.22303 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:15:28.077294 ops/training.py:65 2019-01-16 14:15:28.077195: step 19955, loss = 0.35710 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:15:29.037542 ops/training.py:65 2019-01-16 14:15:29.037453: step 19956, loss = 0.21629 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:15:30.001669 ops/training.py:65 2019-01-16 14:15:30.001562: step 19957, loss = 0.29953 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:15:30.963584 ops/training.py:65 2019-01-16 14:15:30.963483: step 19958, loss = 0.19741 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:15:31.926248 ops/training.py:65 2019-01-16 14:15:31.926150: step 19959, loss = 0.32825 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:15:32.889480 ops/training.py:65 2019-01-16 14:15:32.889391: step 19960, loss = 0.23817 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:15:33.851921 ops/training.py:65 2019-01-16 14:15:33.851814: step 19961, loss = 0.19102 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:15:34.814196 ops/training.py:65 2019-01-16 14:15:34.814077: step 19962, loss = 0.17187 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:15:35.777267 ops/training.py:65 2019-01-16 14:15:35.777186: step 19963, loss = 0.29213 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:15:36.737348 ops/training.py:65 2019-01-16 14:15:36.737281: step 19964, loss = 0.22082 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:15:37.701661 ops/training.py:65 2019-01-16 14:15:37.701574: step 19965, loss = 0.25969 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:15:38.664035 ops/training.py:65 2019-01-16 14:15:38.663945: step 19966, loss = 0.22121 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:15:39.629831 ops/training.py:65 2019-01-16 14:15:39.629720: step 19967, loss = 0.23248 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:15:40.593365 ops/training.py:65 2019-01-16 14:15:40.593253: step 19968, loss = 0.17487 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:15:41.554992 ops/training.py:65 2019-01-16 14:15:41.554933: step 19969, loss = 0.35604 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:15:42.516068 ops/training.py:65 2019-01-16 14:15:42.515967: step 19970, loss = 0.27854 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:15:43.477616 ops/training.py:65 2019-01-16 14:15:43.477525: step 19971, loss = 0.13896 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:15:44.440838 ops/training.py:65 2019-01-16 14:15:44.440739: step 19972, loss = 0.19275 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:15:45.405324 ops/training.py:65 2019-01-16 14:15:45.405244: step 19973, loss = 0.36429 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:15:46.367189 ops/training.py:65 2019-01-16 14:15:46.367093: step 19974, loss = 0.18007 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:15:47.327967 ops/training.py:65 2019-01-16 14:15:47.327861: step 19975, loss = 0.24764 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:15:48.291906 ops/training.py:65 2019-01-16 14:15:48.291807: step 19976, loss = 0.14959 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:15:49.259740 ops/training.py:65 2019-01-16 14:15:49.259625: step 19977, loss = 0.31778 (33.1 examples/sec; 0.967 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:15:50.224951 ops/training.py:65 2019-01-16 14:15:50.224837: step 19978, loss = 0.15540 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:15:51.188526 ops/training.py:65 2019-01-16 14:15:51.188432: step 19979, loss = 0.27588 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:15:52.150176 ops/training.py:65 2019-01-16 14:15:52.150078: step 19980, loss = 0.18101 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:15:53.112855 ops/training.py:65 2019-01-16 14:15:53.112760: step 19981, loss = 0.20213 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:15:54.078502 ops/training.py:65 2019-01-16 14:15:54.078391: step 19982, loss = 0.25663 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:15:55.044171 ops/training.py:65 2019-01-16 14:15:55.044064: step 19983, loss = 0.20782 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:15:56.009067 ops/training.py:65 2019-01-16 14:15:56.008950: step 19984, loss = 0.40400 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:15:56.973295 ops/training.py:65 2019-01-16 14:15:56.973194: step 19985, loss = 0.31576 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:15:57.935125 ops/training.py:65 2019-01-16 14:15:57.935009: step 19986, loss = 0.24635 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:15:58.896382 ops/training.py:65 2019-01-16 14:15:58.896272: step 19987, loss = 0.27777 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:15:59.859542 ops/training.py:65 2019-01-16 14:15:59.859435: step 19988, loss = 0.22074 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:16:00.821521 ops/training.py:65 2019-01-16 14:16:00.821419: step 19989, loss = 0.15011 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:16:01.788505 ops/training.py:65 2019-01-16 14:16:01.788424: step 19990, loss = 0.26751 (33.1 examples/sec; 0.966 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:16:02.751453 ops/training.py:65 2019-01-16 14:16:02.751354: step 19991, loss = 0.16188 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:16:03.716845 ops/training.py:65 2019-01-16 14:16:03.716751: step 19992, loss = 0.23459 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:16:04.680677 ops/training.py:65 2019-01-16 14:16:04.680584: step 19993, loss = 0.22982 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:16:05.643641 ops/training.py:65 2019-01-16 14:16:05.643546: step 19994, loss = 0.36807 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:16:06.605677 ops/training.py:65 2019-01-16 14:16:06.605585: step 19995, loss = 0.28214 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:16:07.567874 ops/training.py:65 2019-01-16 14:16:07.567771: step 19996, loss = 0.34656 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:16:08.533680 ops/training.py:65 2019-01-16 14:16:08.533582: step 19997, loss = 0.17336 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:16:09.494508 ops/training.py:65 2019-01-16 14:16:09.494430: step 19998, loss = 0.21615 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:16:10.458260 ops/training.py:65 2019-01-16 14:16:10.458169: step 19999, loss = 0.30849 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:20:49.678291 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I0832 2019-01-16 14:20:49.679146 ops/training.py:41 2019-01-16 14:20:49.679094: step 20000, loss = 0.23 (0.1 examples/sec; 278.255 sec/batch) | Training accuracy = 0.90625 | Validation accuracy = 0.69155 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_08_07_39_512188
I0832 2019-01-16 14:20:50.641355 ops/training.py:65 2019-01-16 14:20:50.641260: step 20001, loss = 0.19297 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:20:51.602970 ops/training.py:65 2019-01-16 14:20:51.602880: step 20002, loss = 0.15973 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:20:52.563585 ops/training.py:65 2019-01-16 14:20:52.563514: step 20003, loss = 0.25666 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:20:53.527692 ops/training.py:65 2019-01-16 14:20:53.527625: step 20004, loss = 0.30293 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:20:54.490752 ops/training.py:65 2019-01-16 14:20:54.490701: step 20005, loss = 0.21527 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:20:55.452954 ops/training.py:65 2019-01-16 14:20:55.452880: step 20006, loss = 0.18478 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:20:56.415103 ops/training.py:65 2019-01-16 14:20:56.415011: step 20007, loss = 0.27400 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:20:57.378955 ops/training.py:65 2019-01-16 14:20:57.378879: step 20008, loss = 0.20395 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:20:58.341401 ops/training.py:65 2019-01-16 14:20:58.341322: step 20009, loss = 0.27470 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:20:59.303289 ops/training.py:65 2019-01-16 14:20:59.303184: step 20010, loss = 0.30555 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:21:00.265519 ops/training.py:65 2019-01-16 14:21:00.265413: step 20011, loss = 0.33530 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:21:01.227281 ops/training.py:65 2019-01-16 14:21:01.227208: step 20012, loss = 0.18806 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:21:02.187268 ops/training.py:65 2019-01-16 14:21:02.187195: step 20013, loss = 0.21132 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:21:03.147268 ops/training.py:65 2019-01-16 14:21:03.147193: step 20014, loss = 0.25022 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:21:04.107549 ops/training.py:65 2019-01-16 14:21:04.107482: step 20015, loss = 0.34981 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:21:05.068501 ops/training.py:65 2019-01-16 14:21:05.068396: step 20016, loss = 0.32534 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:21:06.030739 ops/training.py:65 2019-01-16 14:21:06.030629: step 20017, loss = 0.37565 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:21:06.993636 ops/training.py:65 2019-01-16 14:21:06.993514: step 20018, loss = 0.38822 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:21:07.956576 ops/training.py:65 2019-01-16 14:21:07.956487: step 20019, loss = 0.28476 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:21:08.919540 ops/training.py:65 2019-01-16 14:21:08.919468: step 20020, loss = 0.21967 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:21:09.881994 ops/training.py:65 2019-01-16 14:21:09.881932: step 20021, loss = 0.16925 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:21:10.843858 ops/training.py:65 2019-01-16 14:21:10.843800: step 20022, loss = 0.32990 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:21:11.805687 ops/training.py:65 2019-01-16 14:21:11.805582: step 20023, loss = 0.24280 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:21:12.769107 ops/training.py:65 2019-01-16 14:21:12.769005: step 20024, loss = 0.36569 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:21:13.731058 ops/training.py:65 2019-01-16 14:21:13.730961: step 20025, loss = 0.22246 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:21:14.691982 ops/training.py:65 2019-01-16 14:21:14.691886: step 20026, loss = 0.18363 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:21:15.653386 ops/training.py:65 2019-01-16 14:21:15.653307: step 20027, loss = 0.39625 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:21:16.615475 ops/training.py:65 2019-01-16 14:21:16.615388: step 20028, loss = 0.26994 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:21:17.580210 ops/training.py:65 2019-01-16 14:21:17.580163: step 20029, loss = 0.12978 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:21:18.542075 ops/training.py:65 2019-01-16 14:21:18.541993: step 20030, loss = 0.31110 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:21:19.502878 ops/training.py:65 2019-01-16 14:21:19.502826: step 20031, loss = 0.27171 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:21:20.466861 ops/training.py:65 2019-01-16 14:21:20.466784: step 20032, loss = 0.19753 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:21:21.429612 ops/training.py:65 2019-01-16 14:21:21.429517: step 20033, loss = 0.23182 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:21:22.391311 ops/training.py:65 2019-01-16 14:21:22.391217: step 20034, loss = 0.31817 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:21:23.353409 ops/training.py:65 2019-01-16 14:21:23.353310: step 20035, loss = 0.23537 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:21:24.316027 ops/training.py:65 2019-01-16 14:21:24.315929: step 20036, loss = 0.20555 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:21:25.277464 ops/training.py:65 2019-01-16 14:21:25.277374: step 20037, loss = 0.18983 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:21:26.239332 ops/training.py:65 2019-01-16 14:21:26.239236: step 20038, loss = 0.18349 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:21:27.201281 ops/training.py:65 2019-01-16 14:21:27.201183: step 20039, loss = 0.15556 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:21:28.164285 ops/training.py:65 2019-01-16 14:21:28.164187: step 20040, loss = 0.17368 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:21:29.126876 ops/training.py:65 2019-01-16 14:21:29.126777: step 20041, loss = 0.13395 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:21:30.091715 ops/training.py:65 2019-01-16 14:21:30.091625: step 20042, loss = 0.15971 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:21:31.056264 ops/training.py:65 2019-01-16 14:21:31.056196: step 20043, loss = 0.27555 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:21:32.019656 ops/training.py:65 2019-01-16 14:21:32.019576: step 20044, loss = 0.22391 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:21:32.982453 ops/training.py:65 2019-01-16 14:21:32.982395: step 20045, loss = 0.21001 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:21:33.944856 ops/training.py:65 2019-01-16 14:21:33.944805: step 20046, loss = 0.23255 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:21:34.908554 ops/training.py:65 2019-01-16 14:21:34.908503: step 20047, loss = 0.33577 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:21:35.870941 ops/training.py:65 2019-01-16 14:21:35.870912: step 20048, loss = 0.17913 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:21:36.832249 ops/training.py:65 2019-01-16 14:21:36.832189: step 20049, loss = 0.21612 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:21:37.792960 ops/training.py:65 2019-01-16 14:21:37.792858: step 20050, loss = 0.31535 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:21:38.759363 ops/training.py:65 2019-01-16 14:21:38.759296: step 20051, loss = 0.14682 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:21:39.723578 ops/training.py:65 2019-01-16 14:21:39.723519: step 20052, loss = 0.20917 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:21:40.687671 ops/training.py:65 2019-01-16 14:21:40.687630: step 20053, loss = 0.27298 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:21:41.648998 ops/training.py:65 2019-01-16 14:21:41.648956: step 20054, loss = 0.36916 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:21:42.611450 ops/training.py:65 2019-01-16 14:21:42.611355: step 20055, loss = 0.22565 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:21:43.574080 ops/training.py:65 2019-01-16 14:21:43.573981: step 20056, loss = 0.32294 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:21:44.536678 ops/training.py:65 2019-01-16 14:21:44.536584: step 20057, loss = 0.23545 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:21:45.498511 ops/training.py:65 2019-01-16 14:21:45.498431: step 20058, loss = 0.21543 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:21:46.464649 ops/training.py:65 2019-01-16 14:21:46.464568: step 20059, loss = 0.30602 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:21:47.426872 ops/training.py:65 2019-01-16 14:21:47.426778: step 20060, loss = 0.29061 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:21:48.388223 ops/training.py:65 2019-01-16 14:21:48.388136: step 20061, loss = 0.38407 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:21:49.351383 ops/training.py:65 2019-01-16 14:21:49.351318: step 20062, loss = 0.29857 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:21:50.313802 ops/training.py:65 2019-01-16 14:21:50.313708: step 20063, loss = 0.24926 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:21:51.274669 ops/training.py:65 2019-01-16 14:21:51.274588: step 20064, loss = 0.35244 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:21:52.234937 ops/training.py:65 2019-01-16 14:21:52.234862: step 20065, loss = 0.21075 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:21:53.197662 ops/training.py:65 2019-01-16 14:21:53.197575: step 20066, loss = 0.22722 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:21:54.160602 ops/training.py:65 2019-01-16 14:21:54.160534: step 20067, loss = 0.29374 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:21:55.123550 ops/training.py:65 2019-01-16 14:21:55.123461: step 20068, loss = 0.35263 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:21:56.084853 ops/training.py:65 2019-01-16 14:21:56.084759: step 20069, loss = 0.22807 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:21:57.047376 ops/training.py:65 2019-01-16 14:21:57.047286: step 20070, loss = 0.27800 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:21:58.008672 ops/training.py:65 2019-01-16 14:21:58.008579: step 20071, loss = 0.20311 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:21:58.970757 ops/training.py:65 2019-01-16 14:21:58.970665: step 20072, loss = 0.26929 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:21:59.932739 ops/training.py:65 2019-01-16 14:21:59.932655: step 20073, loss = 0.20440 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:22:00.894671 ops/training.py:65 2019-01-16 14:22:00.894575: step 20074, loss = 0.20056 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:22:01.857304 ops/training.py:65 2019-01-16 14:22:01.857219: step 20075, loss = 0.40799 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:22:02.818854 ops/training.py:65 2019-01-16 14:22:02.818763: step 20076, loss = 0.32578 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:22:03.784737 ops/training.py:65 2019-01-16 14:22:03.784639: step 20077, loss = 0.18714 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:22:04.747437 ops/training.py:65 2019-01-16 14:22:04.747363: step 20078, loss = 0.45411 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:22:05.710807 ops/training.py:65 2019-01-16 14:22:05.710715: step 20079, loss = 0.22453 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:22:06.672626 ops/training.py:65 2019-01-16 14:22:06.672527: step 20080, loss = 0.21982 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:22:07.638707 ops/training.py:65 2019-01-16 14:22:07.638611: step 20081, loss = 0.22531 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:22:08.601112 ops/training.py:65 2019-01-16 14:22:08.601034: step 20082, loss = 0.26783 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:22:09.563533 ops/training.py:65 2019-01-16 14:22:09.563445: step 20083, loss = 0.26333 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:22:10.525976 ops/training.py:65 2019-01-16 14:22:10.525878: step 20084, loss = 0.32270 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:22:11.492503 ops/training.py:65 2019-01-16 14:22:11.492408: step 20085, loss = 0.15232 (33.1 examples/sec; 0.965 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:22:12.455268 ops/training.py:65 2019-01-16 14:22:12.455177: step 20086, loss = 0.37123 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:22:13.417751 ops/training.py:65 2019-01-16 14:22:13.417657: step 20087, loss = 0.19795 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:22:14.380136 ops/training.py:65 2019-01-16 14:22:14.380046: step 20088, loss = 0.15933 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:22:15.341829 ops/training.py:65 2019-01-16 14:22:15.341740: step 20089, loss = 0.31161 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:22:16.303853 ops/training.py:65 2019-01-16 14:22:16.303784: step 20090, loss = 0.24251 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:22:17.265328 ops/training.py:65 2019-01-16 14:22:17.265238: step 20091, loss = 0.28282 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:22:18.227782 ops/training.py:65 2019-01-16 14:22:18.227678: step 20092, loss = 0.32332 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:22:19.190331 ops/training.py:65 2019-01-16 14:22:19.190230: step 20093, loss = 0.35855 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:22:20.151127 ops/training.py:65 2019-01-16 14:22:20.151043: step 20094, loss = 0.34430 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:22:21.111362 ops/training.py:65 2019-01-16 14:22:21.111294: step 20095, loss = 0.29980 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:22:22.070527 ops/training.py:65 2019-01-16 14:22:22.070444: step 20096, loss = 0.19090 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:22:23.030799 ops/training.py:65 2019-01-16 14:22:23.030727: step 20097, loss = 0.16743 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:22:23.994291 ops/training.py:65 2019-01-16 14:22:23.994217: step 20098, loss = 0.20580 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:22:24.957700 ops/training.py:65 2019-01-16 14:22:24.957610: step 20099, loss = 0.36989 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:22:25.920703 ops/training.py:65 2019-01-16 14:22:25.920611: step 20100, loss = 0.20475 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:22:26.883501 ops/training.py:65 2019-01-16 14:22:26.883400: step 20101, loss = 0.19200 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:22:27.849803 ops/training.py:65 2019-01-16 14:22:27.849705: step 20102, loss = 0.40345 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:22:28.812221 ops/training.py:65 2019-01-16 14:22:28.812121: step 20103, loss = 0.40497 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:22:29.775685 ops/training.py:65 2019-01-16 14:22:29.775596: step 20104, loss = 0.16896 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:22:30.740012 ops/training.py:65 2019-01-16 14:22:30.739907: step 20105, loss = 0.23473 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:22:31.702959 ops/training.py:65 2019-01-16 14:22:31.702872: step 20106, loss = 0.20866 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:22:32.667265 ops/training.py:65 2019-01-16 14:22:32.667168: step 20107, loss = 0.35784 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:22:33.631542 ops/training.py:65 2019-01-16 14:22:33.631445: step 20108, loss = 0.33782 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:22:34.595324 ops/training.py:65 2019-01-16 14:22:34.595257: step 20109, loss = 0.19521 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:22:35.558260 ops/training.py:65 2019-01-16 14:22:35.558159: step 20110, loss = 0.26169 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:22:36.519942 ops/training.py:65 2019-01-16 14:22:36.519847: step 20111, loss = 0.27045 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:22:37.481070 ops/training.py:65 2019-01-16 14:22:37.480996: step 20112, loss = 0.31285 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:22:38.442587 ops/training.py:65 2019-01-16 14:22:38.442529: step 20113, loss = 0.13281 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:22:39.404602 ops/training.py:65 2019-01-16 14:22:39.404523: step 20114, loss = 0.33625 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:22:40.365589 ops/training.py:65 2019-01-16 14:22:40.365493: step 20115, loss = 0.29053 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:22:41.326999 ops/training.py:65 2019-01-16 14:22:41.326900: step 20116, loss = 0.32445 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:22:42.292083 ops/training.py:65 2019-01-16 14:22:42.291980: step 20117, loss = 0.31258 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:22:43.257072 ops/training.py:65 2019-01-16 14:22:43.256976: step 20118, loss = 0.32588 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:22:44.221600 ops/training.py:65 2019-01-16 14:22:44.221507: step 20119, loss = 0.30264 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:22:45.183113 ops/training.py:65 2019-01-16 14:22:45.183012: step 20120, loss = 0.24025 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:22:46.147312 ops/training.py:65 2019-01-16 14:22:46.147235: step 20121, loss = 0.19316 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:22:47.108573 ops/training.py:65 2019-01-16 14:22:47.108491: step 20122, loss = 0.29186 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:22:48.070135 ops/training.py:65 2019-01-16 14:22:48.070043: step 20123, loss = 0.21450 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:22:49.031691 ops/training.py:65 2019-01-16 14:22:49.031595: step 20124, loss = 0.27897 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:22:49.994538 ops/training.py:65 2019-01-16 14:22:49.994458: step 20125, loss = 0.13933 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:22:50.955865 ops/training.py:65 2019-01-16 14:22:50.955764: step 20126, loss = 0.28821 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:22:51.917844 ops/training.py:65 2019-01-16 14:22:51.917746: step 20127, loss = 0.19129 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:22:52.879932 ops/training.py:65 2019-01-16 14:22:52.879847: step 20128, loss = 0.29892 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:22:53.841057 ops/training.py:65 2019-01-16 14:22:53.840983: step 20129, loss = 0.25775 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:22:54.801989 ops/training.py:65 2019-01-16 14:22:54.801925: step 20130, loss = 0.14651 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:22:55.765334 ops/training.py:65 2019-01-16 14:22:55.765258: step 20131, loss = 0.23030 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:22:56.728855 ops/training.py:65 2019-01-16 14:22:56.728758: step 20132, loss = 0.21687 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:22:57.691387 ops/training.py:65 2019-01-16 14:22:57.691290: step 20133, loss = 0.22547 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:22:58.653485 ops/training.py:65 2019-01-16 14:22:58.653384: step 20134, loss = 0.28430 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:22:59.616352 ops/training.py:65 2019-01-16 14:22:59.616255: step 20135, loss = 0.19271 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:23:00.579997 ops/training.py:65 2019-01-16 14:23:00.579890: step 20136, loss = 0.29733 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:23:01.542306 ops/training.py:65 2019-01-16 14:23:01.542218: step 20137, loss = 0.23968 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:23:02.504408 ops/training.py:65 2019-01-16 14:23:02.504315: step 20138, loss = 0.17999 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:23:03.465613 ops/training.py:65 2019-01-16 14:23:03.465541: step 20139, loss = 0.17356 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:23:04.426443 ops/training.py:65 2019-01-16 14:23:04.426395: step 20140, loss = 0.15944 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:23:05.387814 ops/training.py:65 2019-01-16 14:23:05.387743: step 20141, loss = 0.28202 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:23:06.348209 ops/training.py:65 2019-01-16 14:23:06.348143: step 20142, loss = 0.41165 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:23:07.308110 ops/training.py:65 2019-01-16 14:23:07.308043: step 20143, loss = 0.25413 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:23:08.268424 ops/training.py:65 2019-01-16 14:23:08.268356: step 20144, loss = 0.21619 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:23:09.231932 ops/training.py:65 2019-01-16 14:23:09.231874: step 20145, loss = 0.22468 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:23:10.194985 ops/training.py:65 2019-01-16 14:23:10.194895: step 20146, loss = 0.30759 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:23:11.156927 ops/training.py:65 2019-01-16 14:23:11.156836: step 20147, loss = 0.14670 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:23:12.119411 ops/training.py:65 2019-01-16 14:23:12.119314: step 20148, loss = 0.24252 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:23:13.082788 ops/training.py:65 2019-01-16 14:23:13.082680: step 20149, loss = 0.27607 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:23:14.046639 ops/training.py:65 2019-01-16 14:23:14.046534: step 20150, loss = 0.54160 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:23:15.009291 ops/training.py:65 2019-01-16 14:23:15.009195: step 20151, loss = 0.23935 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:23:15.974397 ops/training.py:65 2019-01-16 14:23:15.974324: step 20152, loss = 0.40754 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:23:16.936765 ops/training.py:65 2019-01-16 14:23:16.936691: step 20153, loss = 0.23641 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:23:17.898330 ops/training.py:65 2019-01-16 14:23:17.898239: step 20154, loss = 0.24738 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:23:18.860320 ops/training.py:65 2019-01-16 14:23:18.860224: step 20155, loss = 0.25681 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:23:19.823122 ops/training.py:65 2019-01-16 14:23:19.823047: step 20156, loss = 0.15566 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:23:20.785794 ops/training.py:65 2019-01-16 14:23:20.785696: step 20157, loss = 0.32349 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:23:21.747187 ops/training.py:65 2019-01-16 14:23:21.747083: step 20158, loss = 0.27144 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:23:22.708979 ops/training.py:65 2019-01-16 14:23:22.708877: step 20159, loss = 0.21981 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:23:23.671455 ops/training.py:65 2019-01-16 14:23:23.671355: step 20160, loss = 0.29901 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:23:24.632794 ops/training.py:65 2019-01-16 14:23:24.632733: step 20161, loss = 0.23260 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:23:25.593572 ops/training.py:65 2019-01-16 14:23:25.593503: step 20162, loss = 0.31582 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:23:26.554141 ops/training.py:65 2019-01-16 14:23:26.554075: step 20163, loss = 0.26392 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:23:27.514247 ops/training.py:65 2019-01-16 14:23:27.514179: step 20164, loss = 0.26787 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:23:28.475947 ops/training.py:65 2019-01-16 14:23:28.475873: step 20165, loss = 0.29571 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:23:29.436401 ops/training.py:65 2019-01-16 14:23:29.436326: step 20166, loss = 0.12852 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:23:30.397315 ops/training.py:65 2019-01-16 14:23:30.397246: step 20167, loss = 0.24798 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:23:31.358688 ops/training.py:65 2019-01-16 14:23:31.358627: step 20168, loss = 0.34746 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:23:32.318650 ops/training.py:65 2019-01-16 14:23:32.318582: step 20169, loss = 0.20515 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:23:33.278987 ops/training.py:65 2019-01-16 14:23:33.278917: step 20170, loss = 0.19861 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:23:34.243703 ops/training.py:65 2019-01-16 14:23:34.243629: step 20171, loss = 0.36926 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:23:35.206399 ops/training.py:65 2019-01-16 14:23:35.206324: step 20172, loss = 0.21494 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:23:36.169107 ops/training.py:65 2019-01-16 14:23:36.169005: step 20173, loss = 0.28692 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:23:37.131392 ops/training.py:65 2019-01-16 14:23:37.131296: step 20174, loss = 0.22382 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:23:38.093838 ops/training.py:65 2019-01-16 14:23:38.093744: step 20175, loss = 0.16309 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:23:39.056300 ops/training.py:65 2019-01-16 14:23:39.056200: step 20176, loss = 0.18075 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:23:40.019017 ops/training.py:65 2019-01-16 14:23:40.018923: step 20177, loss = 0.22756 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:23:40.981517 ops/training.py:65 2019-01-16 14:23:40.981416: step 20178, loss = 0.25629 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:23:41.943635 ops/training.py:65 2019-01-16 14:23:41.943535: step 20179, loss = 0.20675 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:23:42.905615 ops/training.py:65 2019-01-16 14:23:42.905516: step 20180, loss = 0.20143 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:23:43.866644 ops/training.py:65 2019-01-16 14:23:43.866541: step 20181, loss = 0.19831 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:23:44.828339 ops/training.py:65 2019-01-16 14:23:44.828235: step 20182, loss = 0.30710 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:23:45.789342 ops/training.py:65 2019-01-16 14:23:45.789268: step 20183, loss = 0.26532 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:23:46.753636 ops/training.py:65 2019-01-16 14:23:46.753565: step 20184, loss = 0.26832 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:23:47.715999 ops/training.py:65 2019-01-16 14:23:47.715895: step 20185, loss = 0.27615 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:23:48.678377 ops/training.py:65 2019-01-16 14:23:48.678275: step 20186, loss = 0.28992 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:23:49.641689 ops/training.py:65 2019-01-16 14:23:49.641609: step 20187, loss = 0.16220 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:23:50.604350 ops/training.py:65 2019-01-16 14:23:50.604276: step 20188, loss = 0.19129 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:23:51.566053 ops/training.py:65 2019-01-16 14:23:51.565970: step 20189, loss = 0.25802 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:23:52.530190 ops/training.py:65 2019-01-16 14:23:52.530108: step 20190, loss = 0.29467 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:23:53.494306 ops/training.py:65 2019-01-16 14:23:53.494223: step 20191, loss = 0.20533 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:23:54.458202 ops/training.py:65 2019-01-16 14:23:54.458106: step 20192, loss = 0.26519 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:23:55.419235 ops/training.py:65 2019-01-16 14:23:55.419139: step 20193, loss = 0.21080 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:23:56.380852 ops/training.py:65 2019-01-16 14:23:56.380749: step 20194, loss = 0.17610 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:23:57.342280 ops/training.py:65 2019-01-16 14:23:57.342185: step 20195, loss = 0.25099 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:23:58.304163 ops/training.py:65 2019-01-16 14:23:58.304061: step 20196, loss = 0.27052 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:23:59.265539 ops/training.py:65 2019-01-16 14:23:59.265462: step 20197, loss = 0.31280 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:24:00.227601 ops/training.py:65 2019-01-16 14:24:00.227523: step 20198, loss = 0.15296 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:24:01.190719 ops/training.py:65 2019-01-16 14:24:01.190619: step 20199, loss = 0.24625 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:24:02.152705 ops/training.py:65 2019-01-16 14:24:02.152620: step 20200, loss = 0.32501 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:24:03.113931 ops/training.py:65 2019-01-16 14:24:03.113876: step 20201, loss = 0.27619 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:24:04.073769 ops/training.py:65 2019-01-16 14:24:04.073702: step 20202, loss = 0.15384 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:24:05.033747 ops/training.py:65 2019-01-16 14:24:05.033690: step 20203, loss = 0.40399 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:24:05.993841 ops/training.py:65 2019-01-16 14:24:05.993769: step 20204, loss = 0.25039 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:24:06.954063 ops/training.py:65 2019-01-16 14:24:06.953993: step 20205, loss = 0.23478 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:24:07.913970 ops/training.py:65 2019-01-16 14:24:07.913900: step 20206, loss = 0.24796 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:24:08.874387 ops/training.py:65 2019-01-16 14:24:08.874320: step 20207, loss = 0.15009 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:24:09.837239 ops/training.py:65 2019-01-16 14:24:09.837188: step 20208, loss = 0.24918 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:24:10.801642 ops/training.py:65 2019-01-16 14:24:10.801586: step 20209, loss = 0.18911 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:24:11.763485 ops/training.py:65 2019-01-16 14:24:11.763397: step 20210, loss = 0.29565 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:24:12.724077 ops/training.py:65 2019-01-16 14:24:12.724011: step 20211, loss = 0.23203 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:24:13.684182 ops/training.py:65 2019-01-16 14:24:13.684109: step 20212, loss = 0.20985 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:24:14.648718 ops/training.py:65 2019-01-16 14:24:14.648665: step 20213, loss = 0.30446 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:24:15.612816 ops/training.py:65 2019-01-16 14:24:15.612746: step 20214, loss = 0.26484 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:24:16.574716 ops/training.py:65 2019-01-16 14:24:16.574636: step 20215, loss = 0.22344 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:24:17.536537 ops/training.py:65 2019-01-16 14:24:17.536494: step 20216, loss = 0.22129 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:24:18.496805 ops/training.py:65 2019-01-16 14:24:18.496732: step 20217, loss = 0.20559 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:24:19.461212 ops/training.py:65 2019-01-16 14:24:19.461157: step 20218, loss = 0.31862 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:24:20.424791 ops/training.py:65 2019-01-16 14:24:20.424753: step 20219, loss = 0.25013 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:24:21.386882 ops/training.py:65 2019-01-16 14:24:21.386848: step 20220, loss = 0.26852 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:24:22.351336 ops/training.py:65 2019-01-16 14:24:22.351305: step 20221, loss = 0.19805 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:24:23.313714 ops/training.py:65 2019-01-16 14:24:23.313683: step 20222, loss = 0.22627 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:24:24.274427 ops/training.py:65 2019-01-16 14:24:24.274395: step 20223, loss = 0.31220 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:24:25.235116 ops/training.py:65 2019-01-16 14:24:25.235075: step 20224, loss = 0.21866 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:24:26.196057 ops/training.py:65 2019-01-16 14:24:26.195983: step 20225, loss = 0.29796 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:24:27.156954 ops/training.py:65 2019-01-16 14:24:27.156914: step 20226, loss = 0.17934 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:24:28.121705 ops/training.py:65 2019-01-16 14:24:28.121663: step 20227, loss = 0.34629 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:24:29.083702 ops/training.py:65 2019-01-16 14:24:29.083662: step 20228, loss = 0.20374 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:24:30.044562 ops/training.py:65 2019-01-16 14:24:30.044528: step 20229, loss = 0.20346 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:24:31.005690 ops/training.py:65 2019-01-16 14:24:31.005652: step 20230, loss = 0.21920 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:24:31.966487 ops/training.py:65 2019-01-16 14:24:31.966442: step 20231, loss = 0.19090 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:24:32.928634 ops/training.py:65 2019-01-16 14:24:32.928572: step 20232, loss = 0.35168 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:24:33.890277 ops/training.py:65 2019-01-16 14:24:33.890241: step 20233, loss = 0.15966 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:24:34.852484 ops/training.py:65 2019-01-16 14:24:34.852446: step 20234, loss = 0.22936 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:24:35.814261 ops/training.py:65 2019-01-16 14:24:35.814210: step 20235, loss = 0.21975 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:24:36.775573 ops/training.py:65 2019-01-16 14:24:36.775493: step 20236, loss = 0.23003 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:24:37.739271 ops/training.py:65 2019-01-16 14:24:37.739167: step 20237, loss = 0.23978 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:24:38.702360 ops/training.py:65 2019-01-16 14:24:38.702253: step 20238, loss = 0.31191 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:24:39.665147 ops/training.py:65 2019-01-16 14:24:39.665052: step 20239, loss = 0.16728 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:24:40.627278 ops/training.py:65 2019-01-16 14:24:40.627203: step 20240, loss = 0.14908 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:24:41.587604 ops/training.py:65 2019-01-16 14:24:41.587525: step 20241, loss = 0.28482 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:24:42.547758 ops/training.py:65 2019-01-16 14:24:42.547683: step 20242, loss = 0.19338 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:24:43.510806 ops/training.py:65 2019-01-16 14:24:43.510725: step 20243, loss = 0.23578 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:24:44.473669 ops/training.py:65 2019-01-16 14:24:44.473570: step 20244, loss = 0.21581 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:24:45.436948 ops/training.py:65 2019-01-16 14:24:45.436851: step 20245, loss = 0.16674 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:24:46.399058 ops/training.py:65 2019-01-16 14:24:46.398968: step 20246, loss = 0.39407 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:24:47.359570 ops/training.py:65 2019-01-16 14:24:47.359468: step 20247, loss = 0.16176 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:24:48.321637 ops/training.py:65 2019-01-16 14:24:48.321529: step 20248, loss = 0.25401 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:24:49.282915 ops/training.py:65 2019-01-16 14:24:49.282817: step 20249, loss = 0.18369 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:24:50.248733 ops/training.py:65 2019-01-16 14:24:50.248647: step 20250, loss = 0.18551 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:24:51.210108 ops/training.py:65 2019-01-16 14:24:51.210012: step 20251, loss = 0.36039 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:24:52.174319 ops/training.py:65 2019-01-16 14:24:52.174219: step 20252, loss = 0.27108 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:24:53.137796 ops/training.py:65 2019-01-16 14:24:53.137695: step 20253, loss = 0.27583 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:24:54.100082 ops/training.py:65 2019-01-16 14:24:54.099978: step 20254, loss = 0.30243 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:24:55.064831 ops/training.py:65 2019-01-16 14:24:55.064729: step 20255, loss = 0.20126 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:24:56.027740 ops/training.py:65 2019-01-16 14:24:56.027645: step 20256, loss = 0.18826 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:24:56.991376 ops/training.py:65 2019-01-16 14:24:56.991276: step 20257, loss = 0.13971 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:24:57.953766 ops/training.py:65 2019-01-16 14:24:57.953669: step 20258, loss = 0.24008 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:24:58.916844 ops/training.py:65 2019-01-16 14:24:58.916743: step 20259, loss = 0.20783 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:24:59.881234 ops/training.py:65 2019-01-16 14:24:59.881135: step 20260, loss = 0.31220 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:25:00.845564 ops/training.py:65 2019-01-16 14:25:00.845464: step 20261, loss = 0.27626 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:25:01.806461 ops/training.py:65 2019-01-16 14:25:01.806367: step 20262, loss = 0.20341 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:25:02.767600 ops/training.py:65 2019-01-16 14:25:02.767531: step 20263, loss = 0.20765 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:25:03.730061 ops/training.py:65 2019-01-16 14:25:03.729999: step 20264, loss = 0.22294 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:25:04.693641 ops/training.py:65 2019-01-16 14:25:04.693577: step 20265, loss = 0.22580 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:25:05.656287 ops/training.py:65 2019-01-16 14:25:05.656187: step 20266, loss = 0.20771 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:25:06.619299 ops/training.py:65 2019-01-16 14:25:06.619199: step 20267, loss = 0.24435 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:25:07.580722 ops/training.py:65 2019-01-16 14:25:07.580649: step 20268, loss = 0.38671 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:25:08.544231 ops/training.py:65 2019-01-16 14:25:08.544151: step 20269, loss = 0.22586 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:25:09.506271 ops/training.py:65 2019-01-16 14:25:09.506177: step 20270, loss = 0.36211 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:25:10.467393 ops/training.py:65 2019-01-16 14:25:10.467302: step 20271, loss = 0.30159 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:25:11.430102 ops/training.py:65 2019-01-16 14:25:11.430001: step 20272, loss = 0.33815 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:25:12.391220 ops/training.py:65 2019-01-16 14:25:12.391115: step 20273, loss = 0.18794 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:25:13.353599 ops/training.py:65 2019-01-16 14:25:13.353494: step 20274, loss = 0.34400 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:25:14.316028 ops/training.py:65 2019-01-16 14:25:14.315952: step 20275, loss = 0.25351 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:25:15.276478 ops/training.py:65 2019-01-16 14:25:15.276402: step 20276, loss = 0.23786 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:25:16.236576 ops/training.py:65 2019-01-16 14:25:16.236499: step 20277, loss = 0.37945 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:25:17.201403 ops/training.py:65 2019-01-16 14:25:17.201319: step 20278, loss = 0.26199 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:25:18.164183 ops/training.py:65 2019-01-16 14:25:18.164080: step 20279, loss = 0.19760 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:25:19.126149 ops/training.py:65 2019-01-16 14:25:19.126071: step 20280, loss = 0.25055 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:25:20.089246 ops/training.py:65 2019-01-16 14:25:20.089162: step 20281, loss = 0.21695 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:25:21.052594 ops/training.py:65 2019-01-16 14:25:21.052489: step 20282, loss = 0.28106 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:25:22.015215 ops/training.py:65 2019-01-16 14:25:22.015115: step 20283, loss = 0.22044 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:25:22.977182 ops/training.py:65 2019-01-16 14:25:22.977098: step 20284, loss = 0.24697 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:25:23.940801 ops/training.py:65 2019-01-16 14:25:23.940757: step 20285, loss = 0.14295 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:25:24.903420 ops/training.py:65 2019-01-16 14:25:24.903377: step 20286, loss = 0.38247 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:25:25.864878 ops/training.py:65 2019-01-16 14:25:25.864802: step 20287, loss = 0.19588 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:25:26.825373 ops/training.py:65 2019-01-16 14:25:26.825277: step 20288, loss = 0.30144 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:25:27.786676 ops/training.py:65 2019-01-16 14:25:27.786576: step 20289, loss = 0.24158 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:25:28.747648 ops/training.py:65 2019-01-16 14:25:28.747545: step 20290, loss = 0.19648 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:25:29.708565 ops/training.py:65 2019-01-16 14:25:29.708473: step 20291, loss = 0.20842 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:25:30.671879 ops/training.py:65 2019-01-16 14:25:30.671783: step 20292, loss = 0.14746 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:25:31.633368 ops/training.py:65 2019-01-16 14:25:31.633266: step 20293, loss = 0.19709 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:25:32.596387 ops/training.py:65 2019-01-16 14:25:32.596252: step 20294, loss = 0.39373 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:25:33.558189 ops/training.py:65 2019-01-16 14:25:33.558088: step 20295, loss = 0.19735 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:25:34.522361 ops/training.py:65 2019-01-16 14:25:34.522233: step 20296, loss = 0.43475 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:25:35.487596 ops/training.py:65 2019-01-16 14:25:35.487530: step 20297, loss = 0.36166 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:25:36.451000 ops/training.py:65 2019-01-16 14:25:36.450900: step 20298, loss = 0.18808 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:25:37.412902 ops/training.py:65 2019-01-16 14:25:37.412802: step 20299, loss = 0.21550 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:25:38.374169 ops/training.py:65 2019-01-16 14:25:38.374088: step 20300, loss = 0.28627 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:25:39.336349 ops/training.py:65 2019-01-16 14:25:39.336249: step 20301, loss = 0.28114 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:25:40.299286 ops/training.py:65 2019-01-16 14:25:40.299188: step 20302, loss = 0.33859 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:25:41.262274 ops/training.py:65 2019-01-16 14:25:41.262173: step 20303, loss = 0.18570 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:25:42.225105 ops/training.py:65 2019-01-16 14:25:42.225000: step 20304, loss = 0.33356 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:25:43.190689 ops/training.py:65 2019-01-16 14:25:43.190598: step 20305, loss = 0.27217 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:25:44.155455 ops/training.py:65 2019-01-16 14:25:44.155353: step 20306, loss = 0.18584 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:25:45.117233 ops/training.py:65 2019-01-16 14:25:45.117134: step 20307, loss = 0.23852 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:25:46.078384 ops/training.py:65 2019-01-16 14:25:46.078304: step 20308, loss = 0.38653 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:25:47.039150 ops/training.py:65 2019-01-16 14:25:47.039047: step 20309, loss = 0.19969 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:25:47.999561 ops/training.py:65 2019-01-16 14:25:47.999478: step 20310, loss = 0.42257 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:25:48.960311 ops/training.py:65 2019-01-16 14:25:48.960243: step 20311, loss = 0.47519 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:25:49.920996 ops/training.py:65 2019-01-16 14:25:49.920925: step 20312, loss = 0.24155 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:25:50.882081 ops/training.py:65 2019-01-16 14:25:50.881990: step 20313, loss = 0.24541 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:25:51.843932 ops/training.py:65 2019-01-16 14:25:51.843862: step 20314, loss = 0.34669 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:25:52.805867 ops/training.py:65 2019-01-16 14:25:52.805779: step 20315, loss = 0.29334 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:25:53.769725 ops/training.py:65 2019-01-16 14:25:53.769638: step 20316, loss = 0.38605 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:25:54.733129 ops/training.py:65 2019-01-16 14:25:54.733038: step 20317, loss = 0.27940 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:25:55.695899 ops/training.py:65 2019-01-16 14:25:55.695800: step 20318, loss = 0.19052 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:25:56.659992 ops/training.py:65 2019-01-16 14:25:56.659902: step 20319, loss = 0.25102 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:25:57.622278 ops/training.py:65 2019-01-16 14:25:57.622180: step 20320, loss = 0.17022 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:25:58.584107 ops/training.py:65 2019-01-16 14:25:58.584008: step 20321, loss = 0.20437 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:25:59.545563 ops/training.py:65 2019-01-16 14:25:59.545470: step 20322, loss = 0.23769 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:26:00.507293 ops/training.py:65 2019-01-16 14:26:00.507192: step 20323, loss = 0.25022 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:26:01.468680 ops/training.py:65 2019-01-16 14:26:01.468592: step 20324, loss = 0.18799 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:26:02.429920 ops/training.py:65 2019-01-16 14:26:02.429830: step 20325, loss = 0.26811 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:26:03.392042 ops/training.py:65 2019-01-16 14:26:03.391949: step 20326, loss = 0.15218 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:26:04.356874 ops/training.py:65 2019-01-16 14:26:04.356794: step 20327, loss = 0.35042 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:26:05.321805 ops/training.py:65 2019-01-16 14:26:05.321728: step 20328, loss = 0.42567 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:26:06.285834 ops/training.py:65 2019-01-16 14:26:06.285757: step 20329, loss = 0.24710 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:26:07.248226 ops/training.py:65 2019-01-16 14:26:07.248128: step 20330, loss = 0.25142 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:26:08.210608 ops/training.py:65 2019-01-16 14:26:08.210520: step 20331, loss = 0.19604 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:26:09.172384 ops/training.py:65 2019-01-16 14:26:09.172311: step 20332, loss = 0.26553 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:26:10.132119 ops/training.py:65 2019-01-16 14:26:10.132047: step 20333, loss = 0.12150 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:26:11.092715 ops/training.py:65 2019-01-16 14:26:11.092604: step 20334, loss = 0.14585 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:26:12.054256 ops/training.py:65 2019-01-16 14:26:12.054181: step 20335, loss = 0.22783 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:26:13.015940 ops/training.py:65 2019-01-16 14:26:13.015872: step 20336, loss = 0.19213 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:26:13.978320 ops/training.py:65 2019-01-16 14:26:13.978228: step 20337, loss = 0.32190 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:26:14.941396 ops/training.py:65 2019-01-16 14:26:14.941303: step 20338, loss = 0.30698 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:26:15.903157 ops/training.py:65 2019-01-16 14:26:15.903078: step 20339, loss = 0.31689 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:26:16.864926 ops/training.py:65 2019-01-16 14:26:16.864834: step 20340, loss = 0.20706 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:26:17.827343 ops/training.py:65 2019-01-16 14:26:17.827249: step 20341, loss = 0.27269 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:26:18.789571 ops/training.py:65 2019-01-16 14:26:18.789495: step 20342, loss = 0.18185 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:26:19.751337 ops/training.py:65 2019-01-16 14:26:19.751256: step 20343, loss = 0.20652 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:26:20.712911 ops/training.py:65 2019-01-16 14:26:20.712818: step 20344, loss = 0.32658 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:26:21.674987 ops/training.py:65 2019-01-16 14:26:21.674885: step 20345, loss = 0.12794 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:26:22.637418 ops/training.py:65 2019-01-16 14:26:22.637324: step 20346, loss = 0.37738 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:26:23.599899 ops/training.py:65 2019-01-16 14:26:23.599798: step 20347, loss = 0.17062 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:26:24.561371 ops/training.py:65 2019-01-16 14:26:24.561274: step 20348, loss = 0.15640 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:26:25.523155 ops/training.py:65 2019-01-16 14:26:25.523058: step 20349, loss = 0.40561 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:26:26.485676 ops/training.py:65 2019-01-16 14:26:26.485584: step 20350, loss = 0.20508 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:26:27.449421 ops/training.py:65 2019-01-16 14:26:27.449318: step 20351, loss = 0.17711 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:26:28.410724 ops/training.py:65 2019-01-16 14:26:28.410620: step 20352, loss = 0.22028 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:26:29.372142 ops/training.py:65 2019-01-16 14:26:29.372043: step 20353, loss = 0.35375 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:26:30.333369 ops/training.py:65 2019-01-16 14:26:30.333274: step 20354, loss = 0.29909 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:26:31.294881 ops/training.py:65 2019-01-16 14:26:31.294779: step 20355, loss = 0.17364 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:26:32.255529 ops/training.py:65 2019-01-16 14:26:32.255434: step 20356, loss = 0.26327 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:26:33.218217 ops/training.py:65 2019-01-16 14:26:33.218114: step 20357, loss = 0.26423 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:26:34.180864 ops/training.py:65 2019-01-16 14:26:34.180780: step 20358, loss = 0.27360 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:26:35.142728 ops/training.py:65 2019-01-16 14:26:35.142649: step 20359, loss = 0.25552 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:26:36.105480 ops/training.py:65 2019-01-16 14:26:36.105407: step 20360, loss = 0.08462 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:26:37.070337 ops/training.py:65 2019-01-16 14:26:37.070232: step 20361, loss = 0.41985 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:26:38.033855 ops/training.py:65 2019-01-16 14:26:38.033760: step 20362, loss = 0.33033 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:26:38.998579 ops/training.py:65 2019-01-16 14:26:38.998493: step 20363, loss = 0.37773 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:26:39.961205 ops/training.py:65 2019-01-16 14:26:39.961109: step 20364, loss = 0.36843 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:26:40.923298 ops/training.py:65 2019-01-16 14:26:40.923199: step 20365, loss = 0.28523 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:26:41.885199 ops/training.py:65 2019-01-16 14:26:41.885105: step 20366, loss = 0.14475 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:26:42.846034 ops/training.py:65 2019-01-16 14:26:42.845932: step 20367, loss = 0.22453 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:26:43.811770 ops/training.py:65 2019-01-16 14:26:43.811670: step 20368, loss = 0.18665 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:26:44.776048 ops/training.py:65 2019-01-16 14:26:44.775950: step 20369, loss = 0.18465 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:26:45.736926 ops/training.py:65 2019-01-16 14:26:45.736843: step 20370, loss = 0.12263 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:26:46.699425 ops/training.py:65 2019-01-16 14:26:46.699324: step 20371, loss = 0.18454 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:26:47.660023 ops/training.py:65 2019-01-16 14:26:47.659916: step 20372, loss = 0.25342 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:26:48.624177 ops/training.py:65 2019-01-16 14:26:48.624080: step 20373, loss = 0.20934 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:26:49.587988 ops/training.py:65 2019-01-16 14:26:49.587898: step 20374, loss = 0.28915 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:26:50.551360 ops/training.py:65 2019-01-16 14:26:50.551270: step 20375, loss = 0.16037 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:26:51.512674 ops/training.py:65 2019-01-16 14:26:51.512572: step 20376, loss = 0.26746 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:26:52.474059 ops/training.py:65 2019-01-16 14:26:52.473963: step 20377, loss = 0.31744 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:26:53.437498 ops/training.py:65 2019-01-16 14:26:53.437393: step 20378, loss = 0.26953 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:26:54.402864 ops/training.py:65 2019-01-16 14:26:54.402762: step 20379, loss = 0.40902 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:26:55.368494 ops/training.py:65 2019-01-16 14:26:55.368394: step 20380, loss = 0.20300 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:26:56.332280 ops/training.py:65 2019-01-16 14:26:56.332175: step 20381, loss = 0.20852 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:26:57.295147 ops/training.py:65 2019-01-16 14:26:57.295049: step 20382, loss = 0.19551 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:26:58.258391 ops/training.py:65 2019-01-16 14:26:58.258325: step 20383, loss = 0.17960 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:26:59.220481 ops/training.py:65 2019-01-16 14:26:59.220396: step 20384, loss = 0.37062 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:27:00.183237 ops/training.py:65 2019-01-16 14:27:00.183160: step 20385, loss = 0.17193 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:27:01.144490 ops/training.py:65 2019-01-16 14:27:01.144409: step 20386, loss = 0.29653 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:27:02.104842 ops/training.py:65 2019-01-16 14:27:02.104765: step 20387, loss = 0.18946 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:27:03.066378 ops/training.py:65 2019-01-16 14:27:03.066298: step 20388, loss = 0.13360 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:27:04.028061 ops/training.py:65 2019-01-16 14:27:04.027994: step 20389, loss = 0.29253 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:27:04.990872 ops/training.py:65 2019-01-16 14:27:04.990778: step 20390, loss = 0.30538 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:27:05.954230 ops/training.py:65 2019-01-16 14:27:05.954133: step 20391, loss = 0.22809 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:27:06.917047 ops/training.py:65 2019-01-16 14:27:06.916962: step 20392, loss = 0.22073 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:27:07.882461 ops/training.py:65 2019-01-16 14:27:07.882370: step 20393, loss = 0.41492 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:27:08.846091 ops/training.py:65 2019-01-16 14:27:08.845987: step 20394, loss = 0.18705 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:27:09.812536 ops/training.py:65 2019-01-16 14:27:09.812441: step 20395, loss = 0.15906 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:27:10.773440 ops/training.py:65 2019-01-16 14:27:10.773346: step 20396, loss = 0.25944 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:27:11.739256 ops/training.py:65 2019-01-16 14:27:11.739155: step 20397, loss = 0.20729 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:27:12.701259 ops/training.py:65 2019-01-16 14:27:12.701161: step 20398, loss = 0.21070 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:27:13.665398 ops/training.py:65 2019-01-16 14:27:13.665293: step 20399, loss = 0.23812 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:27:14.631001 ops/training.py:65 2019-01-16 14:27:14.630904: step 20400, loss = 0.29360 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:27:15.594490 ops/training.py:65 2019-01-16 14:27:15.594393: step 20401, loss = 0.34644 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:27:16.557080 ops/training.py:65 2019-01-16 14:27:16.556994: step 20402, loss = 0.25832 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:27:17.523527 ops/training.py:65 2019-01-16 14:27:17.523461: step 20403, loss = 0.10684 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:27:18.487051 ops/training.py:65 2019-01-16 14:27:18.487012: step 20404, loss = 0.20585 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:27:19.449944 ops/training.py:65 2019-01-16 14:27:19.449905: step 20405, loss = 0.19682 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:27:20.412737 ops/training.py:65 2019-01-16 14:27:20.412694: step 20406, loss = 0.24335 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:27:21.373925 ops/training.py:65 2019-01-16 14:27:21.373874: step 20407, loss = 0.23440 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:27:22.336908 ops/training.py:65 2019-01-16 14:27:22.336866: step 20408, loss = 0.17996 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:27:23.298712 ops/training.py:65 2019-01-16 14:27:23.298674: step 20409, loss = 0.30822 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:27:24.260975 ops/training.py:65 2019-01-16 14:27:24.260938: step 20410, loss = 0.24708 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:27:25.222617 ops/training.py:65 2019-01-16 14:27:25.222561: step 20411, loss = 0.46135 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:27:26.183742 ops/training.py:65 2019-01-16 14:27:26.183683: step 20412, loss = 0.17065 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:27:27.145322 ops/training.py:65 2019-01-16 14:27:27.145251: step 20413, loss = 0.26650 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:27:28.106356 ops/training.py:65 2019-01-16 14:27:28.106309: step 20414, loss = 0.14654 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:27:29.068121 ops/training.py:65 2019-01-16 14:27:29.068082: step 20415, loss = 0.11886 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:27:30.029153 ops/training.py:65 2019-01-16 14:27:30.029116: step 20416, loss = 0.16895 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:27:30.990883 ops/training.py:65 2019-01-16 14:27:30.990838: step 20417, loss = 0.10002 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:27:31.952811 ops/training.py:65 2019-01-16 14:27:31.952770: step 20418, loss = 0.19447 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:27:32.914839 ops/training.py:65 2019-01-16 14:27:32.914773: step 20419, loss = 0.28186 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:27:33.875971 ops/training.py:65 2019-01-16 14:27:33.875870: step 20420, loss = 0.22670 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:27:34.840204 ops/training.py:65 2019-01-16 14:27:34.840128: step 20421, loss = 0.37234 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:27:35.803213 ops/training.py:65 2019-01-16 14:27:35.803144: step 20422, loss = 0.15463 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:27:36.765415 ops/training.py:65 2019-01-16 14:27:36.765353: step 20423, loss = 0.26728 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:27:37.727959 ops/training.py:65 2019-01-16 14:27:37.727869: step 20424, loss = 0.38806 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:27:38.690523 ops/training.py:65 2019-01-16 14:27:38.690430: step 20425, loss = 0.16639 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:27:39.652226 ops/training.py:65 2019-01-16 14:27:39.652155: step 20426, loss = 0.23126 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:27:40.612984 ops/training.py:65 2019-01-16 14:27:40.612902: step 20427, loss = 0.33949 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:27:41.576125 ops/training.py:65 2019-01-16 14:27:41.576062: step 20428, loss = 0.18782 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:27:42.539708 ops/training.py:65 2019-01-16 14:27:42.539611: step 20429, loss = 0.29230 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:27:43.503663 ops/training.py:65 2019-01-16 14:27:43.503560: step 20430, loss = 0.16674 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:27:44.465943 ops/training.py:65 2019-01-16 14:27:44.465846: step 20431, loss = 0.21506 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:27:45.427838 ops/training.py:65 2019-01-16 14:27:45.427748: step 20432, loss = 0.20385 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:27:46.388501 ops/training.py:65 2019-01-16 14:27:46.388421: step 20433, loss = 0.27048 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:27:47.349748 ops/training.py:65 2019-01-16 14:27:47.349647: step 20434, loss = 0.30094 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:27:48.311245 ops/training.py:65 2019-01-16 14:27:48.311143: step 20435, loss = 0.21247 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:27:49.273717 ops/training.py:65 2019-01-16 14:27:49.273624: step 20436, loss = 0.27123 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:27:50.235567 ops/training.py:65 2019-01-16 14:27:50.235481: step 20437, loss = 0.15797 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:27:51.198340 ops/training.py:65 2019-01-16 14:27:51.198282: step 20438, loss = 0.18359 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:27:52.159562 ops/training.py:65 2019-01-16 14:27:52.159467: step 20439, loss = 0.22788 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:27:53.122091 ops/training.py:65 2019-01-16 14:27:53.122016: step 20440, loss = 0.33064 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:27:54.086196 ops/training.py:65 2019-01-16 14:27:54.086148: step 20441, loss = 0.20712 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:27:55.050554 ops/training.py:65 2019-01-16 14:27:55.050502: step 20442, loss = 0.26301 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:27:56.013468 ops/training.py:65 2019-01-16 14:27:56.013409: step 20443, loss = 0.23673 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:27:56.974701 ops/training.py:65 2019-01-16 14:27:56.974657: step 20444, loss = 0.34774 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:27:57.935524 ops/training.py:65 2019-01-16 14:27:57.935489: step 20445, loss = 0.26046 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:27:58.896960 ops/training.py:65 2019-01-16 14:27:58.896926: step 20446, loss = 0.17750 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:27:59.861103 ops/training.py:65 2019-01-16 14:27:59.861070: step 20447, loss = 0.31880 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:28:00.823094 ops/training.py:65 2019-01-16 14:28:00.823060: step 20448, loss = 0.25389 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:28:01.784921 ops/training.py:65 2019-01-16 14:28:01.784888: step 20449, loss = 0.27242 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:28:02.745173 ops/training.py:65 2019-01-16 14:28:02.745088: step 20450, loss = 0.24615 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:28:03.710402 ops/training.py:65 2019-01-16 14:28:03.710322: step 20451, loss = 0.30687 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:28:04.677076 ops/training.py:65 2019-01-16 14:28:04.677038: step 20452, loss = 0.33483 (33.1 examples/sec; 0.966 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:28:05.636335 ops/training.py:65 2019-01-16 14:28:05.636301: step 20453, loss = 0.31466 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:28:06.600202 ops/training.py:65 2019-01-16 14:28:06.600168: step 20454, loss = 0.24907 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:28:07.563542 ops/training.py:65 2019-01-16 14:28:07.563507: step 20455, loss = 0.23569 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:28:08.525878 ops/training.py:65 2019-01-16 14:28:08.525785: step 20456, loss = 0.23032 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:28:09.489112 ops/training.py:65 2019-01-16 14:28:09.489036: step 20457, loss = 0.23808 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:28:10.453428 ops/training.py:65 2019-01-16 14:28:10.453340: step 20458, loss = 0.13874 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:28:11.416502 ops/training.py:65 2019-01-16 14:28:11.416402: step 20459, loss = 0.32847 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:28:12.377736 ops/training.py:65 2019-01-16 14:28:12.377602: step 20460, loss = 0.18942 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:28:13.339565 ops/training.py:65 2019-01-16 14:28:13.339459: step 20461, loss = 0.25720 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:28:14.301447 ops/training.py:65 2019-01-16 14:28:14.301367: step 20462, loss = 0.28367 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:28:15.263933 ops/training.py:65 2019-01-16 14:28:15.263843: step 20463, loss = 0.23246 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:28:16.225928 ops/training.py:65 2019-01-16 14:28:16.225853: step 20464, loss = 0.13382 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:28:17.186316 ops/training.py:65 2019-01-16 14:28:17.186215: step 20465, loss = 0.13477 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:28:18.150470 ops/training.py:65 2019-01-16 14:28:18.150375: step 20466, loss = 0.23772 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:28:19.112349 ops/training.py:65 2019-01-16 14:28:19.112255: step 20467, loss = 0.28201 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:28:20.077689 ops/training.py:65 2019-01-16 14:28:20.077617: step 20468, loss = 0.34355 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:28:21.040059 ops/training.py:65 2019-01-16 14:28:21.039956: step 20469, loss = 0.14303 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:28:22.001631 ops/training.py:65 2019-01-16 14:28:22.001535: step 20470, loss = 0.19749 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:28:22.965352 ops/training.py:65 2019-01-16 14:28:22.965258: step 20471, loss = 0.12704 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:28:23.928644 ops/training.py:65 2019-01-16 14:28:23.928541: step 20472, loss = 0.33029 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:28:24.890873 ops/training.py:65 2019-01-16 14:28:24.890775: step 20473, loss = 0.16162 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:28:25.852324 ops/training.py:65 2019-01-16 14:28:25.852231: step 20474, loss = 0.20665 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:28:26.814333 ops/training.py:65 2019-01-16 14:28:26.814239: step 20475, loss = 0.35476 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:28:27.776391 ops/training.py:65 2019-01-16 14:28:27.776291: step 20476, loss = 0.24743 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:28:28.739408 ops/training.py:65 2019-01-16 14:28:28.739305: step 20477, loss = 0.24008 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:28:29.700997 ops/training.py:65 2019-01-16 14:28:29.700900: step 20478, loss = 0.23811 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:28:30.663119 ops/training.py:65 2019-01-16 14:28:30.663020: step 20479, loss = 0.15903 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:28:31.625386 ops/training.py:65 2019-01-16 14:28:31.625286: step 20480, loss = 0.16224 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:28:32.587770 ops/training.py:65 2019-01-16 14:28:32.587667: step 20481, loss = 0.33915 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:28:33.549895 ops/training.py:65 2019-01-16 14:28:33.549793: step 20482, loss = 0.21356 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:28:34.512760 ops/training.py:65 2019-01-16 14:28:34.512680: step 20483, loss = 0.19818 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:28:35.474325 ops/training.py:65 2019-01-16 14:28:35.474244: step 20484, loss = 0.41661 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:28:36.435251 ops/training.py:65 2019-01-16 14:28:36.435150: step 20485, loss = 0.19024 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:28:37.397196 ops/training.py:65 2019-01-16 14:28:37.397099: step 20486, loss = 0.29388 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:28:38.358946 ops/training.py:65 2019-01-16 14:28:38.358862: step 20487, loss = 0.19371 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:28:39.320448 ops/training.py:65 2019-01-16 14:28:39.320347: step 20488, loss = 0.22532 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:28:40.282601 ops/training.py:65 2019-01-16 14:28:40.282508: step 20489, loss = 0.20332 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:28:41.244838 ops/training.py:65 2019-01-16 14:28:41.244734: step 20490, loss = 0.17865 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:28:42.207231 ops/training.py:65 2019-01-16 14:28:42.207127: step 20491, loss = 0.21053 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:28:43.172207 ops/training.py:65 2019-01-16 14:28:43.172125: step 20492, loss = 0.16069 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:28:44.137722 ops/training.py:65 2019-01-16 14:28:44.137632: step 20493, loss = 0.16504 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:28:45.100145 ops/training.py:65 2019-01-16 14:28:45.100033: step 20494, loss = 0.20249 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:28:46.061558 ops/training.py:65 2019-01-16 14:28:46.061483: step 20495, loss = 0.20051 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:28:47.022554 ops/training.py:65 2019-01-16 14:28:47.022466: step 20496, loss = 0.22823 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:28:47.984450 ops/training.py:65 2019-01-16 14:28:47.984351: step 20497, loss = 0.36747 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:28:48.945626 ops/training.py:65 2019-01-16 14:28:48.945552: step 20498, loss = 0.24805 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:28:49.906191 ops/training.py:65 2019-01-16 14:28:49.906126: step 20499, loss = 0.11917 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:28:50.867142 ops/training.py:65 2019-01-16 14:28:50.867043: step 20500, loss = 0.32683 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:28:51.830140 ops/training.py:65 2019-01-16 14:28:51.830034: step 20501, loss = 0.23197 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:28:52.795209 ops/training.py:65 2019-01-16 14:28:52.795135: step 20502, loss = 0.32745 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:28:53.758367 ops/training.py:65 2019-01-16 14:28:53.758282: step 20503, loss = 0.20799 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:28:54.722510 ops/training.py:65 2019-01-16 14:28:54.722421: step 20504, loss = 0.24140 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:28:55.685008 ops/training.py:65 2019-01-16 14:28:55.684912: step 20505, loss = 0.29163 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:28:56.646566 ops/training.py:65 2019-01-16 14:28:56.646448: step 20506, loss = 0.38669 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:28:57.607869 ops/training.py:65 2019-01-16 14:28:57.607751: step 20507, loss = 0.20806 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:28:58.571947 ops/training.py:65 2019-01-16 14:28:58.571849: step 20508, loss = 0.32164 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:28:59.536914 ops/training.py:65 2019-01-16 14:28:59.536817: step 20509, loss = 0.26489 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:29:00.500535 ops/training.py:65 2019-01-16 14:29:00.500437: step 20510, loss = 0.23327 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:29:01.465359 ops/training.py:65 2019-01-16 14:29:01.465272: step 20511, loss = 0.38433 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:29:02.427830 ops/training.py:65 2019-01-16 14:29:02.427738: step 20512, loss = 0.32970 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:29:03.390638 ops/training.py:65 2019-01-16 14:29:03.390547: step 20513, loss = 0.25472 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:29:04.352027 ops/training.py:65 2019-01-16 14:29:04.351958: step 20514, loss = 0.30287 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:29:05.313070 ops/training.py:65 2019-01-16 14:29:05.312994: step 20515, loss = 0.20612 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:29:06.273671 ops/training.py:65 2019-01-16 14:29:06.273574: step 20516, loss = 0.13999 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:29:07.236315 ops/training.py:65 2019-01-16 14:29:07.236215: step 20517, loss = 0.24739 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:29:08.200152 ops/training.py:65 2019-01-16 14:29:08.200055: step 20518, loss = 0.26430 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:29:09.164852 ops/training.py:65 2019-01-16 14:29:09.164781: step 20519, loss = 0.15463 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:29:10.127932 ops/training.py:65 2019-01-16 14:29:10.127853: step 20520, loss = 0.29511 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:29:11.090607 ops/training.py:65 2019-01-16 14:29:11.090517: step 20521, loss = 0.25529 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:29:12.052217 ops/training.py:65 2019-01-16 14:29:12.052117: step 20522, loss = 0.35013 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:29:13.017208 ops/training.py:65 2019-01-16 14:29:13.017111: step 20523, loss = 0.41595 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:29:13.978510 ops/training.py:65 2019-01-16 14:29:13.978406: step 20524, loss = 0.14409 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:29:14.940092 ops/training.py:65 2019-01-16 14:29:14.939999: step 20525, loss = 0.22922 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:29:15.905724 ops/training.py:65 2019-01-16 14:29:15.905646: step 20526, loss = 0.21256 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:29:16.867730 ops/training.py:65 2019-01-16 14:29:16.867640: step 20527, loss = 0.32294 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:29:17.832324 ops/training.py:65 2019-01-16 14:29:17.832199: step 20528, loss = 0.39094 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:29:18.794800 ops/training.py:65 2019-01-16 14:29:18.794723: step 20529, loss = 0.26544 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:29:19.757024 ops/training.py:65 2019-01-16 14:29:19.756948: step 20530, loss = 0.20060 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:29:20.718394 ops/training.py:65 2019-01-16 14:29:20.718327: step 20531, loss = 0.14896 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:29:21.681415 ops/training.py:65 2019-01-16 14:29:21.681351: step 20532, loss = 0.30998 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:29:22.644090 ops/training.py:65 2019-01-16 14:29:22.643989: step 20533, loss = 0.12738 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:29:23.606182 ops/training.py:65 2019-01-16 14:29:23.606108: step 20534, loss = 0.14423 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:29:24.565744 ops/training.py:65 2019-01-16 14:29:24.565677: step 20535, loss = 0.14743 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:29:25.529878 ops/training.py:65 2019-01-16 14:29:25.529807: step 20536, loss = 0.25929 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:29:26.493607 ops/training.py:65 2019-01-16 14:29:26.493506: step 20537, loss = 0.19821 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:29:27.455442 ops/training.py:65 2019-01-16 14:29:27.455337: step 20538, loss = 0.22438 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:29:28.418801 ops/training.py:65 2019-01-16 14:29:28.418697: step 20539, loss = 0.15803 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:29:29.381119 ops/training.py:65 2019-01-16 14:29:29.381053: step 20540, loss = 0.17350 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:29:30.344704 ops/training.py:65 2019-01-16 14:29:30.344642: step 20541, loss = 0.23055 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:29:31.306272 ops/training.py:65 2019-01-16 14:29:31.306174: step 20542, loss = 0.12970 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:29:32.268106 ops/training.py:65 2019-01-16 14:29:32.268006: step 20543, loss = 0.12526 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:29:33.231348 ops/training.py:65 2019-01-16 14:29:33.231246: step 20544, loss = 0.28138 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:29:34.196837 ops/training.py:65 2019-01-16 14:29:34.196751: step 20545, loss = 0.18988 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:29:35.159657 ops/training.py:65 2019-01-16 14:29:35.159562: step 20546, loss = 0.29248 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:29:36.125837 ops/training.py:65 2019-01-16 14:29:36.125734: step 20547, loss = 0.21279 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:29:37.088179 ops/training.py:65 2019-01-16 14:29:37.088084: step 20548, loss = 0.33156 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:29:38.050777 ops/training.py:65 2019-01-16 14:29:38.050678: step 20549, loss = 0.19459 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:29:39.013050 ops/training.py:65 2019-01-16 14:29:39.012961: step 20550, loss = 0.26001 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:29:39.974600 ops/training.py:65 2019-01-16 14:29:39.974538: step 20551, loss = 0.22614 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:29:40.935931 ops/training.py:65 2019-01-16 14:29:40.935864: step 20552, loss = 0.28933 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:29:41.899501 ops/training.py:65 2019-01-16 14:29:41.899439: step 20553, loss = 0.28847 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:29:42.862785 ops/training.py:65 2019-01-16 14:29:42.862689: step 20554, loss = 0.37369 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:29:43.824526 ops/training.py:65 2019-01-16 14:29:43.824428: step 20555, loss = 0.23118 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:29:44.787708 ops/training.py:65 2019-01-16 14:29:44.787606: step 20556, loss = 0.15210 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:29:45.750612 ops/training.py:65 2019-01-16 14:29:45.750510: step 20557, loss = 0.25807 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:29:46.712742 ops/training.py:65 2019-01-16 14:29:46.712660: step 20558, loss = 0.18269 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:29:47.675066 ops/training.py:65 2019-01-16 14:29:47.674972: step 20559, loss = 0.33455 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:29:48.637559 ops/training.py:65 2019-01-16 14:29:48.637483: step 20560, loss = 0.10824 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:29:49.600202 ops/training.py:65 2019-01-16 14:29:49.600124: step 20561, loss = 0.16552 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:29:50.562253 ops/training.py:65 2019-01-16 14:29:50.562172: step 20562, loss = 0.20415 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:29:51.524406 ops/training.py:65 2019-01-16 14:29:51.524331: step 20563, loss = 0.22127 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:29:52.487918 ops/training.py:65 2019-01-16 14:29:52.487834: step 20564, loss = 0.13009 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:29:53.450236 ops/training.py:65 2019-01-16 14:29:53.450134: step 20565, loss = 0.26832 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:29:54.412163 ops/training.py:65 2019-01-16 14:29:54.412060: step 20566, loss = 0.31859 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:29:55.375543 ops/training.py:65 2019-01-16 14:29:55.375449: step 20567, loss = 0.37539 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:29:56.340004 ops/training.py:65 2019-01-16 14:29:56.339901: step 20568, loss = 0.19781 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:29:57.302602 ops/training.py:65 2019-01-16 14:29:57.302510: step 20569, loss = 0.23164 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:29:58.265969 ops/training.py:65 2019-01-16 14:29:58.265876: step 20570, loss = 0.29663 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:29:59.227810 ops/training.py:65 2019-01-16 14:29:59.227742: step 20571, loss = 0.23359 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:30:00.188000 ops/training.py:65 2019-01-16 14:30:00.187937: step 20572, loss = 0.14939 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:30:01.147495 ops/training.py:65 2019-01-16 14:30:01.147432: step 20573, loss = 0.26157 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:30:02.107779 ops/training.py:65 2019-01-16 14:30:02.107702: step 20574, loss = 0.21484 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:30:03.068435 ops/training.py:65 2019-01-16 14:30:03.068370: step 20575, loss = 0.30121 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:30:04.030081 ops/training.py:65 2019-01-16 14:30:04.030018: step 20576, loss = 0.24969 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:30:04.991222 ops/training.py:65 2019-01-16 14:30:04.991169: step 20577, loss = 0.21544 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:30:05.952476 ops/training.py:65 2019-01-16 14:30:05.952404: step 20578, loss = 0.28115 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:30:06.912838 ops/training.py:65 2019-01-16 14:30:06.912764: step 20579, loss = 0.14738 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:30:07.873135 ops/training.py:65 2019-01-16 14:30:07.873071: step 20580, loss = 0.30176 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:30:08.833801 ops/training.py:65 2019-01-16 14:30:08.833736: step 20581, loss = 0.16740 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:30:09.795420 ops/training.py:65 2019-01-16 14:30:09.795355: step 20582, loss = 0.17965 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:30:10.756757 ops/training.py:65 2019-01-16 14:30:10.756691: step 20583, loss = 0.20401 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:30:11.719546 ops/training.py:65 2019-01-16 14:30:11.719480: step 20584, loss = 0.23227 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:30:12.683892 ops/training.py:65 2019-01-16 14:30:12.683787: step 20585, loss = 0.21022 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:30:13.646077 ops/training.py:65 2019-01-16 14:30:13.646006: step 20586, loss = 0.15011 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:30:14.606358 ops/training.py:65 2019-01-16 14:30:14.606292: step 20587, loss = 0.16339 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:30:15.566943 ops/training.py:65 2019-01-16 14:30:15.566872: step 20588, loss = 0.22979 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:30:16.528213 ops/training.py:65 2019-01-16 14:30:16.528120: step 20589, loss = 0.16366 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:30:17.490244 ops/training.py:65 2019-01-16 14:30:17.490141: step 20590, loss = 0.24565 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:30:18.454800 ops/training.py:65 2019-01-16 14:30:18.454718: step 20591, loss = 0.25801 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:30:19.416038 ops/training.py:65 2019-01-16 14:30:19.415960: step 20592, loss = 0.18883 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:30:20.379312 ops/training.py:65 2019-01-16 14:30:20.379215: step 20593, loss = 0.11252 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:30:21.344607 ops/training.py:65 2019-01-16 14:30:21.344514: step 20594, loss = 0.21147 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:30:22.306786 ops/training.py:65 2019-01-16 14:30:22.306690: step 20595, loss = 0.14315 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:30:23.269634 ops/training.py:65 2019-01-16 14:30:23.269538: step 20596, loss = 0.18623 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:30:24.233528 ops/training.py:65 2019-01-16 14:30:24.233429: step 20597, loss = 0.16390 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:30:25.196747 ops/training.py:65 2019-01-16 14:30:25.196652: step 20598, loss = 0.25878 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:30:26.159459 ops/training.py:65 2019-01-16 14:30:26.159360: step 20599, loss = 0.15212 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:30:27.120915 ops/training.py:65 2019-01-16 14:30:27.120814: step 20600, loss = 0.21348 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:30:28.083389 ops/training.py:65 2019-01-16 14:30:28.083288: step 20601, loss = 0.29759 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:30:29.045504 ops/training.py:65 2019-01-16 14:30:29.045404: step 20602, loss = 0.20584 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:30:30.007778 ops/training.py:65 2019-01-16 14:30:30.007682: step 20603, loss = 0.32650 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:30:30.972054 ops/training.py:65 2019-01-16 14:30:30.971956: step 20604, loss = 0.16134 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:30:31.936019 ops/training.py:65 2019-01-16 14:30:31.935916: step 20605, loss = 0.38220 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:30:32.899740 ops/training.py:65 2019-01-16 14:30:32.899640: step 20606, loss = 0.23604 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:30:33.862848 ops/training.py:65 2019-01-16 14:30:33.862769: step 20607, loss = 0.17861 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:30:34.824772 ops/training.py:65 2019-01-16 14:30:34.824675: step 20608, loss = 0.17068 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:30:35.786724 ops/training.py:65 2019-01-16 14:30:35.786630: step 20609, loss = 0.27746 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:30:36.748792 ops/training.py:65 2019-01-16 14:30:36.748695: step 20610, loss = 0.19682 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:30:37.710193 ops/training.py:65 2019-01-16 14:30:37.710095: step 20611, loss = 0.12811 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:30:38.671808 ops/training.py:65 2019-01-16 14:30:38.671708: step 20612, loss = 0.12115 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:30:39.633752 ops/training.py:65 2019-01-16 14:30:39.633656: step 20613, loss = 0.22518 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:30:40.595150 ops/training.py:65 2019-01-16 14:30:40.595054: step 20614, loss = 0.18169 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:30:41.557363 ops/training.py:65 2019-01-16 14:30:41.557283: step 20615, loss = 0.25142 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:30:42.519893 ops/training.py:65 2019-01-16 14:30:42.519791: step 20616, loss = 0.19620 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:30:43.481856 ops/training.py:65 2019-01-16 14:30:43.481756: step 20617, loss = 0.23262 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:30:44.444396 ops/training.py:65 2019-01-16 14:30:44.444287: step 20618, loss = 0.31261 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:30:45.409219 ops/training.py:65 2019-01-16 14:30:45.409117: step 20619, loss = 0.24001 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:30:46.371554 ops/training.py:65 2019-01-16 14:30:46.371476: step 20620, loss = 0.27298 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:30:47.336287 ops/training.py:65 2019-01-16 14:30:47.336191: step 20621, loss = 0.18344 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:30:48.300513 ops/training.py:65 2019-01-16 14:30:48.300412: step 20622, loss = 0.22953 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:30:49.263779 ops/training.py:65 2019-01-16 14:30:49.263697: step 20623, loss = 0.17162 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:30:50.227006 ops/training.py:65 2019-01-16 14:30:50.226916: step 20624, loss = 0.11053 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:30:51.189246 ops/training.py:65 2019-01-16 14:30:51.189143: step 20625, loss = 0.34505 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:30:52.152067 ops/training.py:65 2019-01-16 14:30:52.151991: step 20626, loss = 0.17118 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:30:53.116290 ops/training.py:65 2019-01-16 14:30:53.116207: step 20627, loss = 0.24957 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:30:54.079823 ops/training.py:65 2019-01-16 14:30:54.079726: step 20628, loss = 0.34943 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:30:55.041651 ops/training.py:65 2019-01-16 14:30:55.041546: step 20629, loss = 0.37285 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:30:56.003385 ops/training.py:65 2019-01-16 14:30:56.003283: step 20630, loss = 0.15360 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:30:56.964116 ops/training.py:65 2019-01-16 14:30:56.964017: step 20631, loss = 0.17564 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:30:57.925613 ops/training.py:65 2019-01-16 14:30:57.925512: step 20632, loss = 0.14661 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:30:58.889888 ops/training.py:65 2019-01-16 14:30:58.889785: step 20633, loss = 0.24373 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:30:59.855311 ops/training.py:65 2019-01-16 14:30:59.855217: step 20634, loss = 0.31932 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:31:00.819867 ops/training.py:65 2019-01-16 14:31:00.819768: step 20635, loss = 0.15310 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:31:01.780672 ops/training.py:65 2019-01-16 14:31:01.780578: step 20636, loss = 0.13884 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:31:02.741909 ops/training.py:65 2019-01-16 14:31:02.741813: step 20637, loss = 0.29175 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:31:03.705790 ops/training.py:65 2019-01-16 14:31:03.705691: step 20638, loss = 0.30076 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:31:04.668862 ops/training.py:65 2019-01-16 14:31:04.668781: step 20639, loss = 0.27538 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:31:05.631571 ops/training.py:65 2019-01-16 14:31:05.631490: step 20640, loss = 0.36834 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:31:06.592903 ops/training.py:65 2019-01-16 14:31:06.592809: step 20641, loss = 0.21485 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:31:07.554383 ops/training.py:65 2019-01-16 14:31:07.554285: step 20642, loss = 0.24462 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:31:08.515263 ops/training.py:65 2019-01-16 14:31:08.515167: step 20643, loss = 0.18042 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:31:09.476988 ops/training.py:65 2019-01-16 14:31:09.476907: step 20644, loss = 0.22546 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:31:10.437493 ops/training.py:65 2019-01-16 14:31:10.437426: step 20645, loss = 0.17311 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:31:11.399598 ops/training.py:65 2019-01-16 14:31:11.399520: step 20646, loss = 0.20447 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:31:12.362615 ops/training.py:65 2019-01-16 14:31:12.362508: step 20647, loss = 0.14956 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:31:13.325604 ops/training.py:65 2019-01-16 14:31:13.325511: step 20648, loss = 0.21084 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:31:14.286813 ops/training.py:65 2019-01-16 14:31:14.286710: step 20649, loss = 0.22901 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:31:15.247845 ops/training.py:65 2019-01-16 14:31:15.247746: step 20650, loss = 0.21672 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:31:16.210440 ops/training.py:65 2019-01-16 14:31:16.210363: step 20651, loss = 0.19632 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:31:17.172354 ops/training.py:65 2019-01-16 14:31:17.172259: step 20652, loss = 0.25368 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:31:18.134320 ops/training.py:65 2019-01-16 14:31:18.134221: step 20653, loss = 0.14828 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:31:19.095235 ops/training.py:65 2019-01-16 14:31:19.095152: step 20654, loss = 0.24174 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:31:20.055902 ops/training.py:65 2019-01-16 14:31:20.055839: step 20655, loss = 0.28549 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:31:21.015964 ops/training.py:65 2019-01-16 14:31:21.015887: step 20656, loss = 0.29099 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:31:21.975401 ops/training.py:65 2019-01-16 14:31:21.975331: step 20657, loss = 0.38061 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:31:22.940355 ops/training.py:65 2019-01-16 14:31:22.940275: step 20658, loss = 0.12196 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:31:23.904229 ops/training.py:65 2019-01-16 14:31:23.904130: step 20659, loss = 0.11688 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:31:24.867231 ops/training.py:65 2019-01-16 14:31:24.867137: step 20660, loss = 0.19204 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:31:25.829061 ops/training.py:65 2019-01-16 14:31:25.828955: step 20661, loss = 0.28871 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:31:26.790016 ops/training.py:65 2019-01-16 14:31:26.789876: step 20662, loss = 0.27242 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:31:27.751485 ops/training.py:65 2019-01-16 14:31:27.751386: step 20663, loss = 0.22583 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:31:28.713867 ops/training.py:65 2019-01-16 14:31:28.713761: step 20664, loss = 0.13696 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:31:29.675723 ops/training.py:65 2019-01-16 14:31:29.675630: step 20665, loss = 0.25842 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:31:30.637428 ops/training.py:65 2019-01-16 14:31:30.637327: step 20666, loss = 0.39688 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:31:31.603938 ops/training.py:65 2019-01-16 14:31:31.603841: step 20667, loss = 0.16745 (33.1 examples/sec; 0.965 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:31:32.568826 ops/training.py:65 2019-01-16 14:31:32.568727: step 20668, loss = 0.15035 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:31:33.533016 ops/training.py:65 2019-01-16 14:31:33.532917: step 20669, loss = 0.50819 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:31:34.494469 ops/training.py:65 2019-01-16 14:31:34.494381: step 20670, loss = 0.20847 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:31:35.455977 ops/training.py:65 2019-01-16 14:31:35.455891: step 20671, loss = 0.20848 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:31:36.416988 ops/training.py:65 2019-01-16 14:31:36.416895: step 20672, loss = 0.25553 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:31:37.379415 ops/training.py:65 2019-01-16 14:31:37.379317: step 20673, loss = 0.20179 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:31:38.342955 ops/training.py:65 2019-01-16 14:31:38.342857: step 20674, loss = 0.20163 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:31:39.308498 ops/training.py:65 2019-01-16 14:31:39.308400: step 20675, loss = 0.19455 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:31:40.273109 ops/training.py:65 2019-01-16 14:31:40.273018: step 20676, loss = 0.20635 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:31:41.236767 ops/training.py:65 2019-01-16 14:31:41.236671: step 20677, loss = 0.38550 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:31:42.198194 ops/training.py:65 2019-01-16 14:31:42.198113: step 20678, loss = 0.20467 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:31:43.159943 ops/training.py:65 2019-01-16 14:31:43.159844: step 20679, loss = 0.26969 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:31:44.121358 ops/training.py:65 2019-01-16 14:31:44.121250: step 20680, loss = 0.24359 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:31:45.085860 ops/training.py:65 2019-01-16 14:31:45.085759: step 20681, loss = 0.27428 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:31:46.050399 ops/training.py:65 2019-01-16 14:31:46.050315: step 20682, loss = 0.20159 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:31:47.014197 ops/training.py:65 2019-01-16 14:31:47.014114: step 20683, loss = 0.16255 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:31:47.975905 ops/training.py:65 2019-01-16 14:31:47.975801: step 20684, loss = 0.26823 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:31:48.938128 ops/training.py:65 2019-01-16 14:31:48.938048: step 20685, loss = 0.28123 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:31:49.900033 ops/training.py:65 2019-01-16 14:31:49.899937: step 20686, loss = 0.28633 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:31:50.861202 ops/training.py:65 2019-01-16 14:31:50.861118: step 20687, loss = 0.24173 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:31:51.824232 ops/training.py:65 2019-01-16 14:31:51.824141: step 20688, loss = 0.27569 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:31:52.785754 ops/training.py:65 2019-01-16 14:31:52.785662: step 20689, loss = 0.17517 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:31:53.747631 ops/training.py:65 2019-01-16 14:31:53.747514: step 20690, loss = 0.17390 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:31:54.709703 ops/training.py:65 2019-01-16 14:31:54.709607: step 20691, loss = 0.32977 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:31:55.672146 ops/training.py:65 2019-01-16 14:31:55.672043: step 20692, loss = 0.37810 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:31:56.633796 ops/training.py:65 2019-01-16 14:31:56.633695: step 20693, loss = 0.26680 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:31:57.595266 ops/training.py:65 2019-01-16 14:31:57.595172: step 20694, loss = 0.23039 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:31:58.556791 ops/training.py:65 2019-01-16 14:31:58.556699: step 20695, loss = 0.26879 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:31:59.519399 ops/training.py:65 2019-01-16 14:31:59.519292: step 20696, loss = 0.38099 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:32:00.484197 ops/training.py:65 2019-01-16 14:32:00.484104: step 20697, loss = 0.22240 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:32:01.448581 ops/training.py:65 2019-01-16 14:32:01.448492: step 20698, loss = 0.21495 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:32:02.412573 ops/training.py:65 2019-01-16 14:32:02.412494: step 20699, loss = 0.21400 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:32:03.376113 ops/training.py:65 2019-01-16 14:32:03.376018: step 20700, loss = 0.13597 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:32:04.338351 ops/training.py:65 2019-01-16 14:32:04.338270: step 20701, loss = 0.25225 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:32:05.299951 ops/training.py:65 2019-01-16 14:32:05.299872: step 20702, loss = 0.21312 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:32:06.262299 ops/training.py:65 2019-01-16 14:32:06.262203: step 20703, loss = 0.24118 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:32:07.223144 ops/training.py:65 2019-01-16 14:32:07.223052: step 20704, loss = 0.27614 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:32:08.185451 ops/training.py:65 2019-01-16 14:32:08.185354: step 20705, loss = 0.19746 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:32:09.147234 ops/training.py:65 2019-01-16 14:32:09.147136: step 20706, loss = 0.15263 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:32:10.107878 ops/training.py:65 2019-01-16 14:32:10.107789: step 20707, loss = 0.27420 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:32:11.068720 ops/training.py:65 2019-01-16 14:32:11.068623: step 20708, loss = 0.22670 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:32:12.029714 ops/training.py:65 2019-01-16 14:32:12.029581: step 20709, loss = 0.20546 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:32:12.991022 ops/training.py:65 2019-01-16 14:32:12.990911: step 20710, loss = 0.16814 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:32:13.952873 ops/training.py:65 2019-01-16 14:32:13.952779: step 20711, loss = 0.18412 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:32:14.914295 ops/training.py:65 2019-01-16 14:32:14.914198: step 20712, loss = 0.13232 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:32:15.876323 ops/training.py:65 2019-01-16 14:32:15.876225: step 20713, loss = 0.28615 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:32:16.837078 ops/training.py:65 2019-01-16 14:32:16.836975: step 20714, loss = 0.26745 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:32:17.798311 ops/training.py:65 2019-01-16 14:32:17.798212: step 20715, loss = 0.31996 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:32:18.759610 ops/training.py:65 2019-01-16 14:32:18.759510: step 20716, loss = 0.24291 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:32:19.720838 ops/training.py:65 2019-01-16 14:32:19.720762: step 20717, loss = 0.22230 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:32:20.681826 ops/training.py:65 2019-01-16 14:32:20.681726: step 20718, loss = 0.33097 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:32:21.643484 ops/training.py:65 2019-01-16 14:32:21.643401: step 20719, loss = 0.24529 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:32:22.604775 ops/training.py:65 2019-01-16 14:32:22.604710: step 20720, loss = 0.20712 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:32:23.567479 ops/training.py:65 2019-01-16 14:32:23.567401: step 20721, loss = 0.24338 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:32:24.530470 ops/training.py:65 2019-01-16 14:32:24.530368: step 20722, loss = 0.18819 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:32:25.493585 ops/training.py:65 2019-01-16 14:32:25.493482: step 20723, loss = 0.32615 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:32:26.455880 ops/training.py:65 2019-01-16 14:32:26.455778: step 20724, loss = 0.21567 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:32:27.416877 ops/training.py:65 2019-01-16 14:32:27.416770: step 20725, loss = 0.25152 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:32:28.378033 ops/training.py:65 2019-01-16 14:32:28.377959: step 20726, loss = 0.17430 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:32:29.337075 ops/training.py:65 2019-01-16 14:32:29.336998: step 20727, loss = 0.20775 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:32:30.299356 ops/training.py:65 2019-01-16 14:32:30.299278: step 20728, loss = 0.22643 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:32:31.263486 ops/training.py:65 2019-01-16 14:32:31.263387: step 20729, loss = 0.33480 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:32:32.226756 ops/training.py:65 2019-01-16 14:32:32.226651: step 20730, loss = 0.35766 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:32:33.189391 ops/training.py:65 2019-01-16 14:32:33.189292: step 20731, loss = 0.30252 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:32:34.151800 ops/training.py:65 2019-01-16 14:32:34.151724: step 20732, loss = 0.25086 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:32:35.113800 ops/training.py:65 2019-01-16 14:32:35.113720: step 20733, loss = 0.20207 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:32:36.076298 ops/training.py:65 2019-01-16 14:32:36.076197: step 20734, loss = 0.19636 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:32:37.038755 ops/training.py:65 2019-01-16 14:32:37.038654: step 20735, loss = 0.16957 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:32:38.001123 ops/training.py:65 2019-01-16 14:32:38.001025: step 20736, loss = 0.14145 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:32:38.964840 ops/training.py:65 2019-01-16 14:32:38.964739: step 20737, loss = 0.19815 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:32:39.929660 ops/training.py:65 2019-01-16 14:32:39.929565: step 20738, loss = 0.40156 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:32:40.891922 ops/training.py:65 2019-01-16 14:32:40.891825: step 20739, loss = 0.27540 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:32:41.855847 ops/training.py:65 2019-01-16 14:32:41.855750: step 20740, loss = 0.19757 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:32:42.818783 ops/training.py:65 2019-01-16 14:32:42.818695: step 20741, loss = 0.22510 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:32:43.781628 ops/training.py:65 2019-01-16 14:32:43.781534: step 20742, loss = 0.27023 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:32:44.745667 ops/training.py:65 2019-01-16 14:32:44.745570: step 20743, loss = 0.11144 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:32:45.707383 ops/training.py:65 2019-01-16 14:32:45.707282: step 20744, loss = 0.44845 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:32:46.671384 ops/training.py:65 2019-01-16 14:32:46.671306: step 20745, loss = 0.15303 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:32:47.635224 ops/training.py:65 2019-01-16 14:32:47.635134: step 20746, loss = 0.17913 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:32:48.599214 ops/training.py:65 2019-01-16 14:32:48.599111: step 20747, loss = 0.13104 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:32:49.561103 ops/training.py:65 2019-01-16 14:32:49.561022: step 20748, loss = 0.16102 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:32:50.521732 ops/training.py:65 2019-01-16 14:32:50.521655: step 20749, loss = 0.31095 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:32:51.483503 ops/training.py:65 2019-01-16 14:32:51.483404: step 20750, loss = 0.10869 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:32:52.445272 ops/training.py:65 2019-01-16 14:32:52.445178: step 20751, loss = 0.22012 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:32:53.407565 ops/training.py:65 2019-01-16 14:32:53.407466: step 20752, loss = 0.31980 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:32:54.369043 ops/training.py:65 2019-01-16 14:32:54.368943: step 20753, loss = 0.29367 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:32:55.331227 ops/training.py:65 2019-01-16 14:32:55.331125: step 20754, loss = 0.20225 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:32:56.293816 ops/training.py:65 2019-01-16 14:32:56.293714: step 20755, loss = 0.21411 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:32:57.256059 ops/training.py:65 2019-01-16 14:32:57.255967: step 20756, loss = 0.41391 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:32:58.218005 ops/training.py:65 2019-01-16 14:32:58.217902: step 20757, loss = 0.26982 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:32:59.179699 ops/training.py:65 2019-01-16 14:32:59.179603: step 20758, loss = 0.42893 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:33:00.141171 ops/training.py:65 2019-01-16 14:33:00.141077: step 20759, loss = 0.21917 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:33:01.102968 ops/training.py:65 2019-01-16 14:33:01.102864: step 20760, loss = 0.12502 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:33:02.064386 ops/training.py:65 2019-01-16 14:33:02.064300: step 20761, loss = 0.24479 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:33:03.026814 ops/training.py:65 2019-01-16 14:33:03.026721: step 20762, loss = 0.19417 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:33:03.988120 ops/training.py:65 2019-01-16 14:33:03.988027: step 20763, loss = 0.21998 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:33:04.949914 ops/training.py:65 2019-01-16 14:33:04.949815: step 20764, loss = 0.14511 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:33:05.911377 ops/training.py:65 2019-01-16 14:33:05.911293: step 20765, loss = 0.21223 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:33:06.872414 ops/training.py:65 2019-01-16 14:33:06.872317: step 20766, loss = 0.31801 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:33:07.834246 ops/training.py:65 2019-01-16 14:33:07.834155: step 20767, loss = 0.19471 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:33:08.796688 ops/training.py:65 2019-01-16 14:33:08.796588: step 20768, loss = 0.20309 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:33:09.758556 ops/training.py:65 2019-01-16 14:33:09.758462: step 20769, loss = 0.20357 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:33:10.720110 ops/training.py:65 2019-01-16 14:33:10.720018: step 20770, loss = 0.36355 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:33:11.681657 ops/training.py:65 2019-01-16 14:33:11.681558: step 20771, loss = 0.26973 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:33:12.642190 ops/training.py:65 2019-01-16 14:33:12.642098: step 20772, loss = 0.10428 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:33:13.604304 ops/training.py:65 2019-01-16 14:33:13.604222: step 20773, loss = 0.19464 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:33:14.567555 ops/training.py:65 2019-01-16 14:33:14.567482: step 20774, loss = 0.14365 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:33:15.530861 ops/training.py:65 2019-01-16 14:33:15.530773: step 20775, loss = 0.21138 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:33:16.493425 ops/training.py:65 2019-01-16 14:33:16.493348: step 20776, loss = 0.13833 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:33:17.454745 ops/training.py:65 2019-01-16 14:33:17.454654: step 20777, loss = 0.17475 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:33:18.418418 ops/training.py:65 2019-01-16 14:33:18.418324: step 20778, loss = 0.19965 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:33:19.381117 ops/training.py:65 2019-01-16 14:33:19.381017: step 20779, loss = 0.13706 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:33:20.343399 ops/training.py:65 2019-01-16 14:33:20.343315: step 20780, loss = 0.23372 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:33:21.307529 ops/training.py:65 2019-01-16 14:33:21.307438: step 20781, loss = 0.23387 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:33:22.271231 ops/training.py:65 2019-01-16 14:33:22.271127: step 20782, loss = 0.28116 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:33:23.234817 ops/training.py:65 2019-01-16 14:33:23.234717: step 20783, loss = 0.15196 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:33:24.196160 ops/training.py:65 2019-01-16 14:33:24.196069: step 20784, loss = 0.14660 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:33:25.158065 ops/training.py:65 2019-01-16 14:33:25.157971: step 20785, loss = 0.21350 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:33:26.119901 ops/training.py:65 2019-01-16 14:33:26.119802: step 20786, loss = 0.24455 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:33:27.081941 ops/training.py:65 2019-01-16 14:33:27.081846: step 20787, loss = 0.29898 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:33:28.044377 ops/training.py:65 2019-01-16 14:33:28.044274: step 20788, loss = 0.22400 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:33:29.006128 ops/training.py:65 2019-01-16 14:33:29.006033: step 20789, loss = 0.18579 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:33:29.968743 ops/training.py:65 2019-01-16 14:33:29.968658: step 20790, loss = 0.29149 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:33:30.930137 ops/training.py:65 2019-01-16 14:33:30.930049: step 20791, loss = 0.22141 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:33:31.892788 ops/training.py:65 2019-01-16 14:33:31.892683: step 20792, loss = 0.26392 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:33:32.854974 ops/training.py:65 2019-01-16 14:33:32.854874: step 20793, loss = 0.23578 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:33:33.820755 ops/training.py:65 2019-01-16 14:33:33.820666: step 20794, loss = 0.22270 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:33:34.783517 ops/training.py:65 2019-01-16 14:33:34.783419: step 20795, loss = 0.22261 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:33:35.746608 ops/training.py:65 2019-01-16 14:33:35.746509: step 20796, loss = 0.20768 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:33:36.708578 ops/training.py:65 2019-01-16 14:33:36.708480: step 20797, loss = 0.18443 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:33:37.673765 ops/training.py:65 2019-01-16 14:33:37.673667: step 20798, loss = 0.12911 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:33:38.636878 ops/training.py:65 2019-01-16 14:33:38.636781: step 20799, loss = 0.25380 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:33:39.599250 ops/training.py:65 2019-01-16 14:33:39.599161: step 20800, loss = 0.21197 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:33:40.561514 ops/training.py:65 2019-01-16 14:33:40.561421: step 20801, loss = 0.21397 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:33:41.524415 ops/training.py:65 2019-01-16 14:33:41.524313: step 20802, loss = 0.32501 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:33:42.487350 ops/training.py:65 2019-01-16 14:33:42.487272: step 20803, loss = 0.21861 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:33:43.448917 ops/training.py:65 2019-01-16 14:33:43.448844: step 20804, loss = 0.18745 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:33:44.409232 ops/training.py:65 2019-01-16 14:33:44.409166: step 20805, loss = 0.13697 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:33:45.373000 ops/training.py:65 2019-01-16 14:33:45.372935: step 20806, loss = 0.32973 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:33:46.336781 ops/training.py:65 2019-01-16 14:33:46.336703: step 20807, loss = 0.09391 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:33:47.299850 ops/training.py:65 2019-01-16 14:33:47.299765: step 20808, loss = 0.14339 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:33:48.264615 ops/training.py:65 2019-01-16 14:33:48.264528: step 20809, loss = 0.25014 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:33:49.226212 ops/training.py:65 2019-01-16 14:33:49.226109: step 20810, loss = 0.15933 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:33:50.187612 ops/training.py:65 2019-01-16 14:33:50.187552: step 20811, loss = 0.22091 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:33:51.148454 ops/training.py:65 2019-01-16 14:33:51.148377: step 20812, loss = 0.22134 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:33:52.110899 ops/training.py:65 2019-01-16 14:33:52.110823: step 20813, loss = 0.15333 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:33:53.072704 ops/training.py:65 2019-01-16 14:33:53.072607: step 20814, loss = 0.10835 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:33:54.035083 ops/training.py:65 2019-01-16 14:33:54.034986: step 20815, loss = 0.28930 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:33:54.999469 ops/training.py:65 2019-01-16 14:33:54.999387: step 20816, loss = 0.12541 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:33:55.961936 ops/training.py:65 2019-01-16 14:33:55.961845: step 20817, loss = 0.31800 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:33:56.924140 ops/training.py:65 2019-01-16 14:33:56.924047: step 20818, loss = 0.21232 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:33:57.885522 ops/training.py:65 2019-01-16 14:33:57.885429: step 20819, loss = 0.23063 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:33:58.849589 ops/training.py:65 2019-01-16 14:33:58.849483: step 20820, loss = 0.26515 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:33:59.814705 ops/training.py:65 2019-01-16 14:33:59.814609: step 20821, loss = 0.29019 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:34:00.778514 ops/training.py:65 2019-01-16 14:34:00.778413: step 20822, loss = 0.14356 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:34:01.742634 ops/training.py:65 2019-01-16 14:34:01.742537: step 20823, loss = 0.38497 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:34:02.709804 ops/training.py:65 2019-01-16 14:34:02.709705: step 20824, loss = 0.22463 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:34:03.674443 ops/training.py:65 2019-01-16 14:34:03.674361: step 20825, loss = 0.11667 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:34:04.638064 ops/training.py:65 2019-01-16 14:34:04.637967: step 20826, loss = 0.24987 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:34:05.599043 ops/training.py:65 2019-01-16 14:34:05.598943: step 20827, loss = 0.17450 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:34:06.560492 ops/training.py:65 2019-01-16 14:34:06.560392: step 20828, loss = 0.34741 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:34:07.521606 ops/training.py:65 2019-01-16 14:34:07.521505: step 20829, loss = 0.13724 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:34:08.486282 ops/training.py:65 2019-01-16 14:34:08.486188: step 20830, loss = 0.32910 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:34:09.450606 ops/training.py:65 2019-01-16 14:34:09.450511: step 20831, loss = 0.20530 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:34:10.414331 ops/training.py:65 2019-01-16 14:34:10.414235: step 20832, loss = 0.17191 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:34:11.376086 ops/training.py:65 2019-01-16 14:34:11.375984: step 20833, loss = 0.27538 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:34:12.338204 ops/training.py:65 2019-01-16 14:34:12.338102: step 20834, loss = 0.16213 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:34:13.300274 ops/training.py:65 2019-01-16 14:34:13.300175: step 20835, loss = 0.21353 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:34:14.262029 ops/training.py:65 2019-01-16 14:34:14.261895: step 20836, loss = 0.23103 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:34:15.224031 ops/training.py:65 2019-01-16 14:34:15.223933: step 20837, loss = 0.29950 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:34:16.185050 ops/training.py:65 2019-01-16 14:34:16.184946: step 20838, loss = 0.32294 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:34:17.146665 ops/training.py:65 2019-01-16 14:34:17.146595: step 20839, loss = 0.14770 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:34:18.107892 ops/training.py:65 2019-01-16 14:34:18.107820: step 20840, loss = 0.19179 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:34:19.071324 ops/training.py:65 2019-01-16 14:34:19.071215: step 20841, loss = 0.31180 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:34:20.036814 ops/training.py:65 2019-01-16 14:34:20.036715: step 20842, loss = 0.34241 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:34:21.001767 ops/training.py:65 2019-01-16 14:34:21.001676: step 20843, loss = 0.21244 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:34:21.965256 ops/training.py:65 2019-01-16 14:34:21.965158: step 20844, loss = 0.17332 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:34:22.926691 ops/training.py:65 2019-01-16 14:34:22.926564: step 20845, loss = 0.15640 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:34:23.889204 ops/training.py:65 2019-01-16 14:34:23.889099: step 20846, loss = 0.13308 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:34:24.852158 ops/training.py:65 2019-01-16 14:34:24.852054: step 20847, loss = 0.15558 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:34:25.813638 ops/training.py:65 2019-01-16 14:34:25.813539: step 20848, loss = 0.27318 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:34:26.775086 ops/training.py:65 2019-01-16 14:34:26.774982: step 20849, loss = 0.20139 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:34:27.737964 ops/training.py:65 2019-01-16 14:34:27.737862: step 20850, loss = 0.20629 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:34:28.700403 ops/training.py:65 2019-01-16 14:34:28.700299: step 20851, loss = 0.22096 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:34:29.662447 ops/training.py:65 2019-01-16 14:34:29.662350: step 20852, loss = 0.26616 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:34:30.623894 ops/training.py:65 2019-01-16 14:34:30.623798: step 20853, loss = 0.45222 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:34:31.586137 ops/training.py:65 2019-01-16 14:34:31.586033: step 20854, loss = 0.13383 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:34:32.549394 ops/training.py:65 2019-01-16 14:34:32.549255: step 20855, loss = 0.17218 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:34:33.514469 ops/training.py:65 2019-01-16 14:34:33.514397: step 20856, loss = 0.33017 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:34:34.478575 ops/training.py:65 2019-01-16 14:34:34.478476: step 20857, loss = 0.14610 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:34:35.441873 ops/training.py:65 2019-01-16 14:34:35.441790: step 20858, loss = 0.26505 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:34:36.403594 ops/training.py:65 2019-01-16 14:34:36.403494: step 20859, loss = 0.34189 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:34:37.365511 ops/training.py:65 2019-01-16 14:34:37.365408: step 20860, loss = 0.21435 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:34:38.328084 ops/training.py:65 2019-01-16 14:34:38.327984: step 20861, loss = 0.18414 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:34:39.290176 ops/training.py:65 2019-01-16 14:34:39.289912: step 20862, loss = 0.18337 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:34:40.251968 ops/training.py:65 2019-01-16 14:34:40.251870: step 20863, loss = 0.21326 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:34:41.213503 ops/training.py:65 2019-01-16 14:34:41.213404: step 20864, loss = 0.20675 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:34:42.176379 ops/training.py:65 2019-01-16 14:34:42.176283: step 20865, loss = 0.26181 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:34:43.139091 ops/training.py:65 2019-01-16 14:34:43.139018: step 20866, loss = 0.30931 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:34:44.099162 ops/training.py:65 2019-01-16 14:34:44.099089: step 20867, loss = 0.28215 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:34:45.059426 ops/training.py:65 2019-01-16 14:34:45.059358: step 20868, loss = 0.25712 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:34:46.020417 ops/training.py:65 2019-01-16 14:34:46.020337: step 20869, loss = 0.16953 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:34:46.980350 ops/training.py:65 2019-01-16 14:34:46.980272: step 20870, loss = 0.17231 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:34:47.941271 ops/training.py:65 2019-01-16 14:34:47.941164: step 20871, loss = 0.42819 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:34:48.908124 ops/training.py:65 2019-01-16 14:34:48.908045: step 20872, loss = 0.23355 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:34:49.872014 ops/training.py:65 2019-01-16 14:34:49.871914: step 20873, loss = 0.29145 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:34:50.835945 ops/training.py:65 2019-01-16 14:34:50.835864: step 20874, loss = 0.17136 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:34:51.798398 ops/training.py:65 2019-01-16 14:34:51.798298: step 20875, loss = 0.18022 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:34:52.761282 ops/training.py:65 2019-01-16 14:34:52.761183: step 20876, loss = 0.27065 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:34:53.724167 ops/training.py:65 2019-01-16 14:34:53.724063: step 20877, loss = 0.12492 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:34:54.686332 ops/training.py:65 2019-01-16 14:34:54.686232: step 20878, loss = 0.27377 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:34:55.648388 ops/training.py:65 2019-01-16 14:34:55.648283: step 20879, loss = 0.25602 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:34:56.610376 ops/training.py:65 2019-01-16 14:34:56.610272: step 20880, loss = 0.15658 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:34:57.574453 ops/training.py:65 2019-01-16 14:34:57.574357: step 20881, loss = 0.19451 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:34:58.538284 ops/training.py:65 2019-01-16 14:34:58.538185: step 20882, loss = 0.29147 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:34:59.501191 ops/training.py:65 2019-01-16 14:34:59.501086: step 20883, loss = 0.23264 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:35:00.463632 ops/training.py:65 2019-01-16 14:35:00.463537: step 20884, loss = 0.15609 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:35:01.426202 ops/training.py:65 2019-01-16 14:35:01.426109: step 20885, loss = 0.31052 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:35:02.391221 ops/training.py:65 2019-01-16 14:35:02.391146: step 20886, loss = 0.22717 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:35:03.355057 ops/training.py:65 2019-01-16 14:35:03.354977: step 20887, loss = 0.20945 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:35:04.318249 ops/training.py:65 2019-01-16 14:35:04.318155: step 20888, loss = 0.30951 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:35:05.280512 ops/training.py:65 2019-01-16 14:35:05.280437: step 20889, loss = 0.17689 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:35:06.242341 ops/training.py:65 2019-01-16 14:35:06.242238: step 20890, loss = 0.19840 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:35:07.206888 ops/training.py:65 2019-01-16 14:35:07.206808: step 20891, loss = 0.26818 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:35:08.170990 ops/training.py:65 2019-01-16 14:35:08.170900: step 20892, loss = 0.13895 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:35:09.133166 ops/training.py:65 2019-01-16 14:35:09.133070: step 20893, loss = 0.28610 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:35:10.094787 ops/training.py:65 2019-01-16 14:35:10.094690: step 20894, loss = 0.34133 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:35:11.057184 ops/training.py:65 2019-01-16 14:35:11.057086: step 20895, loss = 0.27553 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:35:12.018615 ops/training.py:65 2019-01-16 14:35:12.018515: step 20896, loss = 0.20195 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:35:12.980094 ops/training.py:65 2019-01-16 14:35:12.979996: step 20897, loss = 0.27244 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:35:13.943609 ops/training.py:65 2019-01-16 14:35:13.943509: step 20898, loss = 0.33932 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:35:14.906822 ops/training.py:65 2019-01-16 14:35:14.906721: step 20899, loss = 0.22799 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:35:15.869249 ops/training.py:65 2019-01-16 14:35:15.869169: step 20900, loss = 0.19664 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:35:16.833989 ops/training.py:65 2019-01-16 14:35:16.833914: step 20901, loss = 0.23590 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:35:17.797124 ops/training.py:65 2019-01-16 14:35:17.797031: step 20902, loss = 0.23551 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:35:18.759293 ops/training.py:65 2019-01-16 14:35:18.759198: step 20903, loss = 0.35820 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:35:19.724519 ops/training.py:65 2019-01-16 14:35:19.724418: step 20904, loss = 0.23457 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:35:20.687822 ops/training.py:65 2019-01-16 14:35:20.687748: step 20905, loss = 0.16433 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:35:21.651099 ops/training.py:65 2019-01-16 14:35:21.651002: step 20906, loss = 0.26230 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:35:22.612638 ops/training.py:65 2019-01-16 14:35:22.612543: step 20907, loss = 0.21172 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:35:23.574629 ops/training.py:65 2019-01-16 14:35:23.574528: step 20908, loss = 0.17922 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:35:24.537263 ops/training.py:65 2019-01-16 14:35:24.537171: step 20909, loss = 0.29220 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:35:25.498691 ops/training.py:65 2019-01-16 14:35:25.498597: step 20910, loss = 0.24141 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:35:26.460142 ops/training.py:65 2019-01-16 14:35:26.460039: step 20911, loss = 0.23959 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:35:27.421594 ops/training.py:65 2019-01-16 14:35:27.421491: step 20912, loss = 0.15046 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:35:28.383818 ops/training.py:65 2019-01-16 14:35:28.383713: step 20913, loss = 0.24654 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:35:29.344802 ops/training.py:65 2019-01-16 14:35:29.344706: step 20914, loss = 0.16011 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:35:30.306422 ops/training.py:65 2019-01-16 14:35:30.306330: step 20915, loss = 0.16131 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:35:31.269419 ops/training.py:65 2019-01-16 14:35:31.269317: step 20916, loss = 0.20870 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:35:32.231072 ops/training.py:65 2019-01-16 14:35:32.230978: step 20917, loss = 0.23849 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:35:33.193792 ops/training.py:65 2019-01-16 14:35:33.193716: step 20918, loss = 0.20992 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:35:34.160001 ops/training.py:65 2019-01-16 14:35:34.159900: step 20919, loss = 0.18139 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:35:35.124753 ops/training.py:65 2019-01-16 14:35:35.124660: step 20920, loss = 0.14503 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:35:36.088147 ops/training.py:65 2019-01-16 14:35:36.088048: step 20921, loss = 0.31508 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:35:37.049712 ops/training.py:65 2019-01-16 14:35:37.049619: step 20922, loss = 0.23960 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:35:38.011304 ops/training.py:65 2019-01-16 14:35:38.011208: step 20923, loss = 0.24772 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:35:38.973869 ops/training.py:65 2019-01-16 14:35:38.973773: step 20924, loss = 0.17564 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:35:39.938115 ops/training.py:65 2019-01-16 14:35:39.938021: step 20925, loss = 0.32507 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:35:40.902976 ops/training.py:65 2019-01-16 14:35:40.902874: step 20926, loss = 0.25959 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:35:41.866896 ops/training.py:65 2019-01-16 14:35:41.866798: step 20927, loss = 0.31981 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:35:42.828710 ops/training.py:65 2019-01-16 14:35:42.828614: step 20928, loss = 0.26104 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:35:43.791320 ops/training.py:65 2019-01-16 14:35:43.791215: step 20929, loss = 0.14855 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:35:44.754047 ops/training.py:65 2019-01-16 14:35:44.753950: step 20930, loss = 0.20583 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:35:45.716819 ops/training.py:65 2019-01-16 14:35:45.716742: step 20931, loss = 0.21828 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:35:46.680830 ops/training.py:65 2019-01-16 14:35:46.680765: step 20932, loss = 0.21398 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:35:47.644327 ops/training.py:65 2019-01-16 14:35:47.644228: step 20933, loss = 0.30206 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:35:48.606817 ops/training.py:65 2019-01-16 14:35:48.606741: step 20934, loss = 0.21054 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:35:49.570222 ops/training.py:65 2019-01-16 14:35:49.570155: step 20935, loss = 0.29473 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:35:50.531903 ops/training.py:65 2019-01-16 14:35:50.531832: step 20936, loss = 0.16290 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:35:51.493137 ops/training.py:65 2019-01-16 14:35:51.493058: step 20937, loss = 0.28139 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:35:52.454865 ops/training.py:65 2019-01-16 14:35:52.454780: step 20938, loss = 0.17176 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:35:53.416245 ops/training.py:65 2019-01-16 14:35:53.416146: step 20939, loss = 0.21542 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:35:54.377983 ops/training.py:65 2019-01-16 14:35:54.377890: step 20940, loss = 0.19820 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:35:55.339775 ops/training.py:65 2019-01-16 14:35:55.339669: step 20941, loss = 0.24545 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:35:56.301883 ops/training.py:65 2019-01-16 14:35:56.301784: step 20942, loss = 0.18223 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:35:57.266028 ops/training.py:65 2019-01-16 14:35:57.265933: step 20943, loss = 0.29032 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:35:58.229281 ops/training.py:65 2019-01-16 14:35:58.229181: step 20944, loss = 0.20981 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:35:59.191150 ops/training.py:65 2019-01-16 14:35:59.191051: step 20945, loss = 0.23638 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:36:00.152753 ops/training.py:65 2019-01-16 14:36:00.152660: step 20946, loss = 0.12306 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:36:01.113656 ops/training.py:65 2019-01-16 14:36:01.113580: step 20947, loss = 0.23544 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:36:02.076373 ops/training.py:65 2019-01-16 14:36:02.076305: step 20948, loss = 0.17854 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:36:03.040131 ops/training.py:65 2019-01-16 14:36:03.040046: step 20949, loss = 0.23843 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:36:04.003843 ops/training.py:65 2019-01-16 14:36:04.003758: step 20950, loss = 0.14412 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:36:04.965266 ops/training.py:65 2019-01-16 14:36:04.965171: step 20951, loss = 0.30934 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:36:05.927536 ops/training.py:65 2019-01-16 14:36:05.927449: step 20952, loss = 0.28076 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:36:06.889518 ops/training.py:65 2019-01-16 14:36:06.889425: step 20953, loss = 0.12906 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:36:07.850712 ops/training.py:65 2019-01-16 14:36:07.850613: step 20954, loss = 0.15748 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:36:08.812355 ops/training.py:65 2019-01-16 14:36:08.812255: step 20955, loss = 0.26853 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:36:09.775829 ops/training.py:65 2019-01-16 14:36:09.775739: step 20956, loss = 0.40400 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:36:10.738257 ops/training.py:65 2019-01-16 14:36:10.738165: step 20957, loss = 0.22246 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:36:11.700765 ops/training.py:65 2019-01-16 14:36:11.700670: step 20958, loss = 0.19134 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:36:12.662050 ops/training.py:65 2019-01-16 14:36:12.661957: step 20959, loss = 0.43370 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:36:13.624244 ops/training.py:65 2019-01-16 14:36:13.624147: step 20960, loss = 0.20161 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:36:14.586574 ops/training.py:65 2019-01-16 14:36:14.586478: step 20961, loss = 0.22323 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:36:15.552071 ops/training.py:65 2019-01-16 14:36:15.551972: step 20962, loss = 0.23413 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:36:16.516425 ops/training.py:65 2019-01-16 14:36:16.516348: step 20963, loss = 0.23838 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:36:17.478828 ops/training.py:65 2019-01-16 14:36:17.478764: step 20964, loss = 0.17144 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:36:18.441376 ops/training.py:65 2019-01-16 14:36:18.441296: step 20965, loss = 0.31931 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:36:19.405874 ops/training.py:65 2019-01-16 14:36:19.405775: step 20966, loss = 0.18057 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:36:20.367380 ops/training.py:65 2019-01-16 14:36:20.367306: step 20967, loss = 0.25147 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:36:21.328429 ops/training.py:65 2019-01-16 14:36:21.328331: step 20968, loss = 0.32132 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:36:22.289526 ops/training.py:65 2019-01-16 14:36:22.289429: step 20969, loss = 0.31484 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:36:23.251401 ops/training.py:65 2019-01-16 14:36:23.251301: step 20970, loss = 0.16111 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:36:24.214212 ops/training.py:65 2019-01-16 14:36:24.214122: step 20971, loss = 0.27309 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:36:25.175529 ops/training.py:65 2019-01-16 14:36:25.175433: step 20972, loss = 0.35236 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:36:26.137970 ops/training.py:65 2019-01-16 14:36:26.137866: step 20973, loss = 0.19863 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:36:27.102201 ops/training.py:65 2019-01-16 14:36:27.102067: step 20974, loss = 0.16046 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:36:28.067520 ops/training.py:65 2019-01-16 14:36:28.067417: step 20975, loss = 0.22262 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:36:29.030573 ops/training.py:65 2019-01-16 14:36:29.030473: step 20976, loss = 0.15262 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:36:29.996583 ops/training.py:65 2019-01-16 14:36:29.996489: step 20977, loss = 0.25014 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:36:30.961471 ops/training.py:65 2019-01-16 14:36:30.961384: step 20978, loss = 0.17748 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:36:31.924140 ops/training.py:65 2019-01-16 14:36:31.924036: step 20979, loss = 0.41355 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:36:32.886851 ops/training.py:65 2019-01-16 14:36:32.886755: step 20980, loss = 0.44738 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:36:33.847476 ops/training.py:65 2019-01-16 14:36:33.847409: step 20981, loss = 0.19705 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:36:34.807381 ops/training.py:65 2019-01-16 14:36:34.807314: step 20982, loss = 0.22792 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:36:35.767769 ops/training.py:65 2019-01-16 14:36:35.767701: step 20983, loss = 0.23701 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:36:36.727175 ops/training.py:65 2019-01-16 14:36:36.727108: step 20984, loss = 0.23953 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:36:37.686436 ops/training.py:65 2019-01-16 14:36:37.686372: step 20985, loss = 0.26056 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:36:38.648862 ops/training.py:65 2019-01-16 14:36:38.648790: step 20986, loss = 0.19876 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:36:39.611550 ops/training.py:65 2019-01-16 14:36:39.611459: step 20987, loss = 0.49559 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:36:40.573551 ops/training.py:65 2019-01-16 14:36:40.573451: step 20988, loss = 0.34340 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:36:41.535445 ops/training.py:65 2019-01-16 14:36:41.535343: step 20989, loss = 0.28661 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:36:42.497034 ops/training.py:65 2019-01-16 14:36:42.496927: step 20990, loss = 0.16918 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:36:43.458555 ops/training.py:65 2019-01-16 14:36:43.458454: step 20991, loss = 0.23182 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:36:44.420555 ops/training.py:65 2019-01-16 14:36:44.420452: step 20992, loss = 0.12254 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:36:45.382217 ops/training.py:65 2019-01-16 14:36:45.382127: step 20993, loss = 0.24229 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:36:46.343817 ops/training.py:65 2019-01-16 14:36:46.343741: step 20994, loss = 0.11931 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:36:47.307032 ops/training.py:65 2019-01-16 14:36:47.306969: step 20995, loss = 0.24669 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:36:48.268622 ops/training.py:65 2019-01-16 14:36:48.268541: step 20996, loss = 0.23314 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:36:49.229988 ops/training.py:65 2019-01-16 14:36:49.229888: step 20997, loss = 0.25091 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:36:50.191033 ops/training.py:65 2019-01-16 14:36:50.190945: step 20998, loss = 0.21325 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:36:51.153875 ops/training.py:65 2019-01-16 14:36:51.153789: step 20999, loss = 0.23094 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:36:52.116555 ops/training.py:65 2019-01-16 14:36:52.116457: step 21000, loss = 0.33805 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:36:53.078226 ops/training.py:65 2019-01-16 14:36:53.078126: step 21001, loss = 0.24904 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:36:54.039663 ops/training.py:65 2019-01-16 14:36:54.039560: step 21002, loss = 0.17007 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:36:55.004741 ops/training.py:65 2019-01-16 14:36:55.004645: step 21003, loss = 0.20624 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:36:55.968583 ops/training.py:65 2019-01-16 14:36:55.968486: step 21004, loss = 0.23694 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:36:56.931757 ops/training.py:65 2019-01-16 14:36:56.931630: step 21005, loss = 0.34111 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:36:57.893208 ops/training.py:65 2019-01-16 14:36:57.893086: step 21006, loss = 0.21532 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:36:58.854905 ops/training.py:65 2019-01-16 14:36:58.854805: step 21007, loss = 0.34100 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:36:59.816407 ops/training.py:65 2019-01-16 14:36:59.816313: step 21008, loss = 0.25180 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:37:00.778551 ops/training.py:65 2019-01-16 14:37:00.778453: step 21009, loss = 0.26074 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:37:01.741030 ops/training.py:65 2019-01-16 14:37:01.740946: step 21010, loss = 0.10072 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:37:02.703080 ops/training.py:65 2019-01-16 14:37:02.702980: step 21011, loss = 0.13720 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:37:03.665072 ops/training.py:65 2019-01-16 14:37:03.664991: step 21012, loss = 0.16278 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:37:04.627175 ops/training.py:65 2019-01-16 14:37:04.627072: step 21013, loss = 0.32279 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:37:05.589462 ops/training.py:65 2019-01-16 14:37:05.589387: step 21014, loss = 0.14953 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:37:06.551566 ops/training.py:65 2019-01-16 14:37:06.551464: step 21015, loss = 0.31266 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:37:07.513159 ops/training.py:65 2019-01-16 14:37:07.513060: step 21016, loss = 0.30394 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:37:08.475361 ops/training.py:65 2019-01-16 14:37:08.475262: step 21017, loss = 0.18361 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:37:09.438162 ops/training.py:65 2019-01-16 14:37:09.438069: step 21018, loss = 0.11790 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:37:10.398962 ops/training.py:65 2019-01-16 14:37:10.398876: step 21019, loss = 0.12492 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:37:11.361067 ops/training.py:65 2019-01-16 14:37:11.360974: step 21020, loss = 0.38825 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:37:12.322465 ops/training.py:65 2019-01-16 14:37:12.322372: step 21021, loss = 0.22433 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:37:13.284428 ops/training.py:65 2019-01-16 14:37:13.284330: step 21022, loss = 0.12928 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:37:14.245867 ops/training.py:65 2019-01-16 14:37:14.245767: step 21023, loss = 0.24082 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:37:15.207956 ops/training.py:65 2019-01-16 14:37:15.207859: step 21024, loss = 0.20460 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:37:16.170314 ops/training.py:65 2019-01-16 14:37:16.170221: step 21025, loss = 0.19304 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:37:17.130953 ops/training.py:65 2019-01-16 14:37:17.130896: step 21026, loss = 0.15448 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:37:18.092888 ops/training.py:65 2019-01-16 14:37:18.092787: step 21027, loss = 0.20677 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:37:19.054964 ops/training.py:65 2019-01-16 14:37:19.054892: step 21028, loss = 0.16777 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:37:20.016313 ops/training.py:65 2019-01-16 14:37:20.016214: step 21029, loss = 0.13479 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:37:20.978471 ops/training.py:65 2019-01-16 14:37:20.978376: step 21030, loss = 0.18877 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:37:21.939512 ops/training.py:65 2019-01-16 14:37:21.939437: step 21031, loss = 0.16186 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:37:22.898505 ops/training.py:65 2019-01-16 14:37:22.898429: step 21032, loss = 0.17111 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:37:23.858467 ops/training.py:65 2019-01-16 14:37:23.858394: step 21033, loss = 0.24894 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:37:24.818020 ops/training.py:65 2019-01-16 14:37:24.817953: step 21034, loss = 0.09359 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:37:25.779375 ops/training.py:65 2019-01-16 14:37:25.779318: step 21035, loss = 0.20087 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:37:26.742854 ops/training.py:65 2019-01-16 14:37:26.742751: step 21036, loss = 0.25278 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:37:27.707464 ops/training.py:65 2019-01-16 14:37:27.707366: step 21037, loss = 0.27875 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:37:28.670036 ops/training.py:65 2019-01-16 14:37:28.669930: step 21038, loss = 0.24203 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:37:29.633079 ops/training.py:65 2019-01-16 14:37:29.632984: step 21039, loss = 0.20547 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:37:30.595529 ops/training.py:65 2019-01-16 14:37:30.595427: step 21040, loss = 0.20623 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:37:31.557689 ops/training.py:65 2019-01-16 14:37:31.557589: step 21041, loss = 0.14603 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:37:32.519181 ops/training.py:65 2019-01-16 14:37:32.519114: step 21042, loss = 0.16356 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:37:33.481908 ops/training.py:65 2019-01-16 14:37:33.481856: step 21043, loss = 0.29176 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:37:34.444546 ops/training.py:65 2019-01-16 14:37:34.444452: step 21044, loss = 0.22050 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:37:35.406641 ops/training.py:65 2019-01-16 14:37:35.406564: step 21045, loss = 0.16843 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:37:36.368391 ops/training.py:65 2019-01-16 14:37:36.368296: step 21046, loss = 0.21711 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:37:37.329514 ops/training.py:65 2019-01-16 14:37:37.329418: step 21047, loss = 0.24913 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:37:38.291605 ops/training.py:65 2019-01-16 14:37:38.291503: step 21048, loss = 0.24910 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:37:39.254051 ops/training.py:65 2019-01-16 14:37:39.253956: step 21049, loss = 0.23209 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:37:40.216040 ops/training.py:65 2019-01-16 14:37:40.215943: step 21050, loss = 0.13754 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:37:41.177817 ops/training.py:65 2019-01-16 14:37:41.177718: step 21051, loss = 0.19007 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:37:42.139955 ops/training.py:65 2019-01-16 14:37:42.139853: step 21052, loss = 0.25518 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:37:43.102581 ops/training.py:65 2019-01-16 14:37:43.102484: step 21053, loss = 0.08425 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:37:44.064020 ops/training.py:65 2019-01-16 14:37:44.063928: step 21054, loss = 0.23787 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:37:45.025763 ops/training.py:65 2019-01-16 14:37:45.025669: step 21055, loss = 0.21804 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:37:45.986922 ops/training.py:65 2019-01-16 14:37:45.986841: step 21056, loss = 0.13389 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:37:46.947918 ops/training.py:65 2019-01-16 14:37:46.947838: step 21057, loss = 0.27523 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:37:47.910435 ops/training.py:65 2019-01-16 14:37:47.910344: step 21058, loss = 0.24957 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:37:48.871334 ops/training.py:65 2019-01-16 14:37:48.871259: step 21059, loss = 0.25503 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:37:49.832072 ops/training.py:65 2019-01-16 14:37:49.831978: step 21060, loss = 0.42683 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:37:50.797333 ops/training.py:65 2019-01-16 14:37:50.797258: step 21061, loss = 0.33773 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:37:51.761528 ops/training.py:65 2019-01-16 14:37:51.761424: step 21062, loss = 0.13278 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:37:52.725805 ops/training.py:65 2019-01-16 14:37:52.725716: step 21063, loss = 0.27687 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:37:53.687866 ops/training.py:65 2019-01-16 14:37:53.687766: step 21064, loss = 0.19337 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:37:54.650140 ops/training.py:65 2019-01-16 14:37:54.650041: step 21065, loss = 0.21145 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:37:55.612729 ops/training.py:65 2019-01-16 14:37:55.612622: step 21066, loss = 0.18241 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:37:56.575951 ops/training.py:65 2019-01-16 14:37:56.575853: step 21067, loss = 0.17781 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:37:57.541501 ops/training.py:65 2019-01-16 14:37:57.541401: step 21068, loss = 0.10775 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:37:58.505819 ops/training.py:65 2019-01-16 14:37:58.505718: step 21069, loss = 0.26996 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:37:59.469830 ops/training.py:65 2019-01-16 14:37:59.469728: step 21070, loss = 0.18271 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:38:00.432135 ops/training.py:65 2019-01-16 14:38:00.432038: step 21071, loss = 0.25985 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:38:01.394390 ops/training.py:65 2019-01-16 14:38:01.394299: step 21072, loss = 0.21964 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:38:02.355938 ops/training.py:65 2019-01-16 14:38:02.355846: step 21073, loss = 0.13396 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:38:03.317704 ops/training.py:65 2019-01-16 14:38:03.317627: step 21074, loss = 0.22288 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:38:04.279233 ops/training.py:65 2019-01-16 14:38:04.279107: step 21075, loss = 0.18770 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:38:05.240223 ops/training.py:65 2019-01-16 14:38:05.240133: step 21076, loss = 0.28863 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:38:06.201903 ops/training.py:65 2019-01-16 14:38:06.201815: step 21077, loss = 0.37809 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:38:07.164012 ops/training.py:65 2019-01-16 14:38:07.163916: step 21078, loss = 0.31478 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:38:08.125759 ops/training.py:65 2019-01-16 14:38:08.125664: step 21079, loss = 0.13990 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:38:09.088223 ops/training.py:65 2019-01-16 14:38:09.088132: step 21080, loss = 0.29636 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:38:10.050555 ops/training.py:65 2019-01-16 14:38:10.050463: step 21081, loss = 0.29752 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:38:11.012189 ops/training.py:65 2019-01-16 14:38:11.012087: step 21082, loss = 0.18792 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:38:11.974364 ops/training.py:65 2019-01-16 14:38:11.974264: step 21083, loss = 0.19132 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:38:12.936066 ops/training.py:65 2019-01-16 14:38:12.935972: step 21084, loss = 0.22730 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:38:13.897837 ops/training.py:65 2019-01-16 14:38:13.897737: step 21085, loss = 0.19301 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:38:14.859193 ops/training.py:65 2019-01-16 14:38:14.859099: step 21086, loss = 0.20193 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:38:15.820518 ops/training.py:65 2019-01-16 14:38:15.820426: step 21087, loss = 0.16581 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:38:16.782280 ops/training.py:65 2019-01-16 14:38:16.782218: step 21088, loss = 0.39097 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:38:17.743622 ops/training.py:65 2019-01-16 14:38:17.743524: step 21089, loss = 0.10153 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:38:18.705142 ops/training.py:65 2019-01-16 14:38:18.705063: step 21090, loss = 0.39291 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:38:19.666606 ops/training.py:65 2019-01-16 14:38:19.666507: step 21091, loss = 0.21343 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:38:20.628246 ops/training.py:65 2019-01-16 14:38:20.628167: step 21092, loss = 0.18883 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:38:21.590520 ops/training.py:65 2019-01-16 14:38:21.590419: step 21093, loss = 0.17360 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:38:22.551695 ops/training.py:65 2019-01-16 14:38:22.551591: step 21094, loss = 0.32171 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:38:23.516688 ops/training.py:65 2019-01-16 14:38:23.516592: step 21095, loss = 0.37523 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:38:24.481497 ops/training.py:65 2019-01-16 14:38:24.481394: step 21096, loss = 0.28972 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:38:25.445349 ops/training.py:65 2019-01-16 14:38:25.445245: step 21097, loss = 0.17129 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:38:26.407372 ops/training.py:65 2019-01-16 14:38:26.407270: step 21098, loss = 0.24949 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:38:27.369649 ops/training.py:65 2019-01-16 14:38:27.369550: step 21099, loss = 0.13590 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:38:28.331804 ops/training.py:65 2019-01-16 14:38:28.331702: step 21100, loss = 0.20149 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:38:29.292943 ops/training.py:65 2019-01-16 14:38:29.292842: step 21101, loss = 0.11989 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:38:30.254580 ops/training.py:65 2019-01-16 14:38:30.254485: step 21102, loss = 0.29075 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:38:31.215725 ops/training.py:65 2019-01-16 14:38:31.215628: step 21103, loss = 0.24814 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:38:32.177634 ops/training.py:65 2019-01-16 14:38:32.177536: step 21104, loss = 0.11842 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:38:33.139218 ops/training.py:65 2019-01-16 14:38:33.139119: step 21105, loss = 0.28457 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:38:34.101404 ops/training.py:65 2019-01-16 14:38:34.101317: step 21106, loss = 0.25181 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:38:35.064234 ops/training.py:65 2019-01-16 14:38:35.064131: step 21107, loss = 0.22601 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:38:36.026455 ops/training.py:65 2019-01-16 14:38:36.026364: step 21108, loss = 0.16358 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:38:36.987760 ops/training.py:65 2019-01-16 14:38:36.987626: step 21109, loss = 0.30398 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:38:37.950900 ops/training.py:65 2019-01-16 14:38:37.950806: step 21110, loss = 0.25512 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:38:38.912604 ops/training.py:65 2019-01-16 14:38:38.912511: step 21111, loss = 0.26593 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:38:39.875235 ops/training.py:65 2019-01-16 14:38:39.875136: step 21112, loss = 0.10819 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:38:40.837336 ops/training.py:65 2019-01-16 14:38:40.837242: step 21113, loss = 0.13286 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:38:41.799610 ops/training.py:65 2019-01-16 14:38:41.799510: step 21114, loss = 0.16794 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:38:42.760729 ops/training.py:65 2019-01-16 14:38:42.760631: step 21115, loss = 0.20130 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:38:43.721816 ops/training.py:65 2019-01-16 14:38:43.721739: step 21116, loss = 0.27778 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:38:44.685900 ops/training.py:65 2019-01-16 14:38:44.685826: step 21117, loss = 0.19075 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:38:45.649563 ops/training.py:65 2019-01-16 14:38:45.649465: step 21118, loss = 0.31913 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:38:46.612427 ops/training.py:65 2019-01-16 14:38:46.612345: step 21119, loss = 0.14443 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:38:47.574203 ops/training.py:65 2019-01-16 14:38:47.574110: step 21120, loss = 0.33789 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:38:48.536108 ops/training.py:65 2019-01-16 14:38:48.536030: step 21121, loss = 0.22677 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:38:49.497402 ops/training.py:65 2019-01-16 14:38:49.497263: step 21122, loss = 0.12008 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:38:50.462777 ops/training.py:65 2019-01-16 14:38:50.462678: step 21123, loss = 0.18133 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:38:51.427428 ops/training.py:65 2019-01-16 14:38:51.427321: step 21124, loss = 0.11890 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:38:52.390911 ops/training.py:65 2019-01-16 14:38:52.390805: step 21125, loss = 0.13488 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:38:53.353229 ops/training.py:65 2019-01-16 14:38:53.353134: step 21126, loss = 0.16431 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:38:54.314933 ops/training.py:65 2019-01-16 14:38:54.314826: step 21127, loss = 0.30948 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:38:55.276485 ops/training.py:65 2019-01-16 14:38:55.276380: step 21128, loss = 0.17387 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:38:56.239508 ops/training.py:65 2019-01-16 14:38:56.239409: step 21129, loss = 0.20790 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:38:57.203588 ops/training.py:65 2019-01-16 14:38:57.203491: step 21130, loss = 0.26354 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:38:58.167550 ops/training.py:65 2019-01-16 14:38:58.167453: step 21131, loss = 0.13419 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:38:59.130181 ops/training.py:65 2019-01-16 14:38:59.130086: step 21132, loss = 0.22422 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:39:00.093799 ops/training.py:65 2019-01-16 14:39:00.093705: step 21133, loss = 0.29116 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:39:01.055718 ops/training.py:65 2019-01-16 14:39:01.055622: step 21134, loss = 0.06992 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:39:02.017802 ops/training.py:65 2019-01-16 14:39:02.017714: step 21135, loss = 0.23767 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:39:02.979101 ops/training.py:65 2019-01-16 14:39:02.979007: step 21136, loss = 0.17070 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:39:03.941592 ops/training.py:65 2019-01-16 14:39:03.941506: step 21137, loss = 0.17090 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:39:04.902905 ops/training.py:65 2019-01-16 14:39:04.902808: step 21138, loss = 0.21394 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:39:05.864463 ops/training.py:65 2019-01-16 14:39:05.864383: step 21139, loss = 0.21370 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:39:06.825786 ops/training.py:65 2019-01-16 14:39:06.825687: step 21140, loss = 0.13830 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:39:07.788073 ops/training.py:65 2019-01-16 14:39:07.787974: step 21141, loss = 0.37548 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:39:08.750174 ops/training.py:65 2019-01-16 14:39:08.750075: step 21142, loss = 0.22343 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:39:09.710836 ops/training.py:65 2019-01-16 14:39:09.710747: step 21143, loss = 0.26195 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:39:10.671635 ops/training.py:65 2019-01-16 14:39:10.671539: step 21144, loss = 0.35973 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:39:11.633403 ops/training.py:65 2019-01-16 14:39:11.633301: step 21145, loss = 0.17653 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:39:12.596062 ops/training.py:65 2019-01-16 14:39:12.595969: step 21146, loss = 0.15842 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:39:13.558245 ops/training.py:65 2019-01-16 14:39:13.558143: step 21147, loss = 0.16186 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:39:14.520005 ops/training.py:65 2019-01-16 14:39:14.519901: step 21148, loss = 0.16924 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:39:15.481805 ops/training.py:65 2019-01-16 14:39:15.481728: step 21149, loss = 0.17977 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:39:16.444753 ops/training.py:65 2019-01-16 14:39:16.444650: step 21150, loss = 0.19201 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:39:17.409649 ops/training.py:65 2019-01-16 14:39:17.409574: step 21151, loss = 0.10794 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:39:18.371713 ops/training.py:65 2019-01-16 14:39:18.371610: step 21152, loss = 0.32098 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:39:19.333195 ops/training.py:65 2019-01-16 14:39:19.333089: step 21153, loss = 0.23730 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:39:20.298271 ops/training.py:65 2019-01-16 14:39:20.298193: step 21154, loss = 0.25065 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:39:21.262168 ops/training.py:65 2019-01-16 14:39:21.262073: step 21155, loss = 0.26711 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:39:22.227035 ops/training.py:65 2019-01-16 14:39:22.226945: step 21156, loss = 0.31005 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:39:23.189491 ops/training.py:65 2019-01-16 14:39:23.189388: step 21157, loss = 0.19921 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:39:24.155082 ops/training.py:65 2019-01-16 14:39:24.154980: step 21158, loss = 0.37248 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:39:25.118139 ops/training.py:65 2019-01-16 14:39:25.118045: step 21159, loss = 0.15287 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:39:26.081446 ops/training.py:65 2019-01-16 14:39:26.081344: step 21160, loss = 0.29758 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:39:27.043416 ops/training.py:65 2019-01-16 14:39:27.043315: step 21161, loss = 0.14029 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:39:28.005397 ops/training.py:65 2019-01-16 14:39:28.005290: step 21162, loss = 0.33881 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:39:28.970580 ops/training.py:65 2019-01-16 14:39:28.970476: step 21163, loss = 0.21484 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:39:29.934868 ops/training.py:65 2019-01-16 14:39:29.934773: step 21164, loss = 0.17916 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:39:30.899111 ops/training.py:65 2019-01-16 14:39:30.899008: step 21165, loss = 0.10021 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:39:31.861341 ops/training.py:65 2019-01-16 14:39:31.861239: step 21166, loss = 0.21116 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:39:32.823030 ops/training.py:65 2019-01-16 14:39:32.822934: step 21167, loss = 0.18929 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:39:33.785422 ops/training.py:65 2019-01-16 14:39:33.785343: step 21168, loss = 0.28137 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:39:34.747437 ops/training.py:65 2019-01-16 14:39:34.747338: step 21169, loss = 0.25842 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:39:35.709334 ops/training.py:65 2019-01-16 14:39:35.709256: step 21170, loss = 0.20644 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:39:36.671852 ops/training.py:65 2019-01-16 14:39:36.671748: step 21171, loss = 0.22087 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:39:37.633720 ops/training.py:65 2019-01-16 14:39:37.633623: step 21172, loss = 0.20905 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:39:38.594993 ops/training.py:65 2019-01-16 14:39:38.594899: step 21173, loss = 0.18869 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:39:39.556859 ops/training.py:65 2019-01-16 14:39:39.556755: step 21174, loss = 0.23735 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:39:40.519629 ops/training.py:65 2019-01-16 14:39:40.519535: step 21175, loss = 0.26124 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:39:41.482381 ops/training.py:65 2019-01-16 14:39:41.482278: step 21176, loss = 0.20003 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:39:42.444247 ops/training.py:65 2019-01-16 14:39:42.444151: step 21177, loss = 0.12310 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:39:43.406476 ops/training.py:65 2019-01-16 14:39:43.406374: step 21178, loss = 0.16083 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:39:44.367788 ops/training.py:65 2019-01-16 14:39:44.367690: step 21179, loss = 0.24069 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:39:45.329406 ops/training.py:65 2019-01-16 14:39:45.329319: step 21180, loss = 0.36092 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:39:46.291124 ops/training.py:65 2019-01-16 14:39:46.291036: step 21181, loss = 0.15333 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:39:47.252239 ops/training.py:65 2019-01-16 14:39:47.252159: step 21182, loss = 0.25894 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:39:48.214631 ops/training.py:65 2019-01-16 14:39:48.214526: step 21183, loss = 0.18460 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:39:49.177150 ops/training.py:65 2019-01-16 14:39:49.177047: step 21184, loss = 0.25736 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:39:50.139014 ops/training.py:65 2019-01-16 14:39:50.138920: step 21185, loss = 0.14740 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:39:51.101609 ops/training.py:65 2019-01-16 14:39:51.101511: step 21186, loss = 0.20516 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:39:52.063525 ops/training.py:65 2019-01-16 14:39:52.063441: step 21187, loss = 0.17532 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:39:53.025555 ops/training.py:65 2019-01-16 14:39:53.025460: step 21188, loss = 0.40758 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:39:53.988127 ops/training.py:65 2019-01-16 14:39:53.988025: step 21189, loss = 0.24375 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:39:54.949852 ops/training.py:65 2019-01-16 14:39:54.949754: step 21190, loss = 0.19730 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:39:55.911351 ops/training.py:65 2019-01-16 14:39:55.911253: step 21191, loss = 0.28018 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:39:56.875292 ops/training.py:65 2019-01-16 14:39:56.875200: step 21192, loss = 0.35350 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:39:57.839731 ops/training.py:65 2019-01-16 14:39:57.839637: step 21193, loss = 0.19285 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:39:58.803678 ops/training.py:65 2019-01-16 14:39:58.803574: step 21194, loss = 0.17623 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:39:59.767042 ops/training.py:65 2019-01-16 14:39:59.766947: step 21195, loss = 0.29181 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:40:00.729671 ops/training.py:65 2019-01-16 14:40:00.729571: step 21196, loss = 0.14883 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:40:01.689868 ops/training.py:65 2019-01-16 14:40:01.689784: step 21197, loss = 0.11154 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:40:02.654896 ops/training.py:65 2019-01-16 14:40:02.654799: step 21198, loss = 0.19224 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:40:03.620023 ops/training.py:65 2019-01-16 14:40:03.619933: step 21199, loss = 0.14184 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:40:04.584072 ops/training.py:65 2019-01-16 14:40:04.583969: step 21200, loss = 0.18557 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:40:05.547022 ops/training.py:65 2019-01-16 14:40:05.546943: step 21201, loss = 0.16793 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:40:06.511828 ops/training.py:65 2019-01-16 14:40:06.511728: step 21202, loss = 0.16983 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:40:07.476051 ops/training.py:65 2019-01-16 14:40:07.475949: step 21203, loss = 0.37447 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:40:08.439871 ops/training.py:65 2019-01-16 14:40:08.439771: step 21204, loss = 0.28890 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:40:09.402670 ops/training.py:65 2019-01-16 14:40:09.402567: step 21205, loss = 0.17436 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:40:10.364776 ops/training.py:65 2019-01-16 14:40:10.364679: step 21206, loss = 0.23657 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:40:11.328078 ops/training.py:65 2019-01-16 14:40:11.327977: step 21207, loss = 0.12970 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:40:12.293086 ops/training.py:65 2019-01-16 14:40:12.292991: step 21208, loss = 0.10166 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:40:13.258566 ops/training.py:65 2019-01-16 14:40:13.258468: step 21209, loss = 0.14909 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:40:14.222597 ops/training.py:65 2019-01-16 14:40:14.222493: step 21210, loss = 0.12094 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:40:15.185778 ops/training.py:65 2019-01-16 14:40:15.185676: step 21211, loss = 0.16384 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:40:16.149057 ops/training.py:65 2019-01-16 14:40:16.148970: step 21212, loss = 0.24817 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:40:17.111545 ops/training.py:65 2019-01-16 14:40:17.111461: step 21213, loss = 0.19992 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:40:18.072848 ops/training.py:65 2019-01-16 14:40:18.072753: step 21214, loss = 0.20580 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:40:19.034507 ops/training.py:65 2019-01-16 14:40:19.034411: step 21215, loss = 0.09995 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:40:19.997653 ops/training.py:65 2019-01-16 14:40:19.997581: step 21216, loss = 0.12814 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:40:20.960965 ops/training.py:65 2019-01-16 14:40:20.960899: step 21217, loss = 0.18135 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:40:21.923559 ops/training.py:65 2019-01-16 14:40:21.923464: step 21218, loss = 0.24970 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:40:22.885379 ops/training.py:65 2019-01-16 14:40:22.885260: step 21219, loss = 0.12628 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:40:23.847101 ops/training.py:65 2019-01-16 14:40:23.847000: step 21220, loss = 0.11760 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:40:24.808902 ops/training.py:65 2019-01-16 14:40:24.808808: step 21221, loss = 0.16875 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:40:25.770942 ops/training.py:65 2019-01-16 14:40:25.770843: step 21222, loss = 0.19725 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:40:26.732668 ops/training.py:65 2019-01-16 14:40:26.732570: step 21223, loss = 0.22998 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:40:27.693707 ops/training.py:65 2019-01-16 14:40:27.693607: step 21224, loss = 0.18711 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:40:28.655511 ops/training.py:65 2019-01-16 14:40:28.655408: step 21225, loss = 0.17634 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:40:29.616461 ops/training.py:65 2019-01-16 14:40:29.616366: step 21226, loss = 0.24447 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:40:30.577425 ops/training.py:65 2019-01-16 14:40:30.577334: step 21227, loss = 0.18098 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:40:31.540102 ops/training.py:65 2019-01-16 14:40:31.540002: step 21228, loss = 0.20772 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:40:32.501459 ops/training.py:65 2019-01-16 14:40:32.501364: step 21229, loss = 0.17546 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:40:33.464288 ops/training.py:65 2019-01-16 14:40:33.464211: step 21230, loss = 0.23836 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:40:34.429893 ops/training.py:65 2019-01-16 14:40:34.429800: step 21231, loss = 0.34327 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:40:35.394175 ops/training.py:65 2019-01-16 14:40:35.394071: step 21232, loss = 0.27431 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:40:36.357234 ops/training.py:65 2019-01-16 14:40:36.357147: step 21233, loss = 0.10545 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:40:37.318640 ops/training.py:65 2019-01-16 14:40:37.318549: step 21234, loss = 0.11243 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:40:38.280957 ops/training.py:65 2019-01-16 14:40:38.280874: step 21235, loss = 0.32884 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:40:39.241790 ops/training.py:65 2019-01-16 14:40:39.241696: step 21236, loss = 0.16786 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:40:40.204407 ops/training.py:65 2019-01-16 14:40:40.204318: step 21237, loss = 0.18069 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:40:41.166173 ops/training.py:65 2019-01-16 14:40:41.166079: step 21238, loss = 0.25788 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:40:42.130241 ops/training.py:65 2019-01-16 14:40:42.130147: step 21239, loss = 0.15923 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:40:43.092631 ops/training.py:65 2019-01-16 14:40:43.092539: step 21240, loss = 0.15512 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:40:44.056676 ops/training.py:65 2019-01-16 14:40:44.056582: step 21241, loss = 0.13926 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:40:45.020329 ops/training.py:65 2019-01-16 14:40:45.020236: step 21242, loss = 0.43386 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:40:45.982844 ops/training.py:65 2019-01-16 14:40:45.982749: step 21243, loss = 0.15518 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:40:46.945443 ops/training.py:65 2019-01-16 14:40:46.945366: step 21244, loss = 0.37081 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:40:47.906711 ops/training.py:65 2019-01-16 14:40:47.906632: step 21245, loss = 0.25270 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:40:48.868083 ops/training.py:65 2019-01-16 14:40:48.868013: step 21246, loss = 0.16828 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:40:49.829248 ops/training.py:65 2019-01-16 14:40:49.829150: step 21247, loss = 0.21321 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:40:50.790851 ops/training.py:65 2019-01-16 14:40:50.790779: step 21248, loss = 0.17723 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:40:51.754130 ops/training.py:65 2019-01-16 14:40:51.754026: step 21249, loss = 0.16067 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:40:52.718837 ops/training.py:65 2019-01-16 14:40:52.718743: step 21250, loss = 0.10425 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:40:53.683556 ops/training.py:65 2019-01-16 14:40:53.683454: step 21251, loss = 0.20580 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:40:54.647192 ops/training.py:65 2019-01-16 14:40:54.647094: step 21252, loss = 0.13868 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:40:55.610997 ops/training.py:65 2019-01-16 14:40:55.610889: step 21253, loss = 0.19769 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:40:56.574681 ops/training.py:65 2019-01-16 14:40:56.574579: step 21254, loss = 0.29286 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:40:57.536988 ops/training.py:65 2019-01-16 14:40:57.536885: step 21255, loss = 0.13545 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:40:58.499663 ops/training.py:65 2019-01-16 14:40:58.499558: step 21256, loss = 0.19220 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:40:59.461948 ops/training.py:65 2019-01-16 14:40:59.461847: step 21257, loss = 0.22957 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:41:00.424362 ops/training.py:65 2019-01-16 14:41:00.424267: step 21258, loss = 0.10442 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:41:01.389344 ops/training.py:65 2019-01-16 14:41:01.389258: step 21259, loss = 0.14920 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:41:02.353247 ops/training.py:65 2019-01-16 14:41:02.353151: step 21260, loss = 0.25621 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:41:03.316051 ops/training.py:65 2019-01-16 14:41:03.315953: step 21261, loss = 0.12482 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:41:04.280620 ops/training.py:65 2019-01-16 14:41:04.280542: step 21262, loss = 0.09442 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:41:05.243713 ops/training.py:65 2019-01-16 14:41:05.243619: step 21263, loss = 0.35485 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:41:06.206644 ops/training.py:65 2019-01-16 14:41:06.206564: step 21264, loss = 0.23137 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:41:07.168992 ops/training.py:65 2019-01-16 14:41:07.168897: step 21265, loss = 0.22470 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:41:08.130591 ops/training.py:65 2019-01-16 14:41:08.130492: step 21266, loss = 0.24657 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:41:09.092555 ops/training.py:65 2019-01-16 14:41:09.092460: step 21267, loss = 0.27354 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:41:10.053938 ops/training.py:65 2019-01-16 14:41:10.053848: step 21268, loss = 0.15672 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:41:11.015771 ops/training.py:65 2019-01-16 14:41:11.015679: step 21269, loss = 0.33161 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:41:11.976912 ops/training.py:65 2019-01-16 14:41:11.976814: step 21270, loss = 0.24642 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:41:12.938991 ops/training.py:65 2019-01-16 14:41:12.938863: step 21271, loss = 0.32274 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:41:13.900490 ops/training.py:65 2019-01-16 14:41:13.900357: step 21272, loss = 0.19580 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:41:14.861694 ops/training.py:65 2019-01-16 14:41:14.861563: step 21273, loss = 0.29464 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:41:15.824078 ops/training.py:65 2019-01-16 14:41:15.823980: step 21274, loss = 0.14184 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:41:16.785904 ops/training.py:65 2019-01-16 14:41:16.785802: step 21275, loss = 0.17806 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:41:17.747208 ops/training.py:65 2019-01-16 14:41:17.747116: step 21276, loss = 0.21611 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:41:18.708467 ops/training.py:65 2019-01-16 14:41:18.708397: step 21277, loss = 0.28179 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:41:19.669461 ops/training.py:65 2019-01-16 14:41:19.669362: step 21278, loss = 0.34679 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:41:20.633431 ops/training.py:65 2019-01-16 14:41:20.633359: step 21279, loss = 0.29631 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:41:21.598380 ops/training.py:65 2019-01-16 14:41:21.598280: step 21280, loss = 0.37471 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:41:22.561527 ops/training.py:65 2019-01-16 14:41:22.561429: step 21281, loss = 0.09822 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:41:23.523369 ops/training.py:65 2019-01-16 14:41:23.523274: step 21282, loss = 0.16301 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:41:24.486059 ops/training.py:65 2019-01-16 14:41:24.485961: step 21283, loss = 0.14916 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:41:25.448106 ops/training.py:65 2019-01-16 14:41:25.448010: step 21284, loss = 0.25227 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:41:26.410378 ops/training.py:65 2019-01-16 14:41:26.410273: step 21285, loss = 0.22576 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:41:27.373947 ops/training.py:65 2019-01-16 14:41:27.373848: step 21286, loss = 0.13447 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:41:28.335277 ops/training.py:65 2019-01-16 14:41:28.335176: step 21287, loss = 0.18632 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:41:29.296745 ops/training.py:65 2019-01-16 14:41:29.296649: step 21288, loss = 0.13876 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:41:30.258358 ops/training.py:65 2019-01-16 14:41:30.258266: step 21289, loss = 0.11561 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:41:31.220426 ops/training.py:65 2019-01-16 14:41:31.220330: step 21290, loss = 0.24342 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:41:32.182445 ops/training.py:65 2019-01-16 14:41:32.182350: step 21291, loss = 0.21894 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:41:33.144542 ops/training.py:65 2019-01-16 14:41:33.144440: step 21292, loss = 0.29569 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:41:34.106241 ops/training.py:65 2019-01-16 14:41:34.106149: step 21293, loss = 0.17637 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:41:35.067413 ops/training.py:65 2019-01-16 14:41:35.067335: step 21294, loss = 0.15421 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:41:36.030847 ops/training.py:65 2019-01-16 14:41:36.030782: step 21295, loss = 0.20154 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:41:36.993598 ops/training.py:65 2019-01-16 14:41:36.993501: step 21296, loss = 0.30052 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:41:37.954978 ops/training.py:65 2019-01-16 14:41:37.954882: step 21297, loss = 0.30513 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:41:38.916224 ops/training.py:65 2019-01-16 14:41:38.916127: step 21298, loss = 0.20566 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:41:39.878537 ops/training.py:65 2019-01-16 14:41:39.878441: step 21299, loss = 0.14198 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:41:40.840079 ops/training.py:65 2019-01-16 14:41:40.839983: step 21300, loss = 0.18185 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:41:41.802665 ops/training.py:65 2019-01-16 14:41:41.802564: step 21301, loss = 0.18033 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:41:42.764858 ops/training.py:65 2019-01-16 14:41:42.764761: step 21302, loss = 0.30731 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:41:43.726369 ops/training.py:65 2019-01-16 14:41:43.726269: step 21303, loss = 0.15722 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:41:44.688018 ops/training.py:65 2019-01-16 14:41:44.687921: step 21304, loss = 0.29929 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:41:45.652311 ops/training.py:65 2019-01-16 14:41:45.652214: step 21305, loss = 0.11522 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:41:46.615993 ops/training.py:65 2019-01-16 14:41:46.615914: step 21306, loss = 0.27315 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:41:47.578634 ops/training.py:65 2019-01-16 14:41:47.578559: step 21307, loss = 0.10078 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:41:48.544158 ops/training.py:65 2019-01-16 14:41:48.544085: step 21308, loss = 0.33369 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:41:49.506732 ops/training.py:65 2019-01-16 14:41:49.506640: step 21309, loss = 0.15153 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:41:50.467934 ops/training.py:65 2019-01-16 14:41:50.467847: step 21310, loss = 0.26024 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:41:51.429015 ops/training.py:65 2019-01-16 14:41:51.428939: step 21311, loss = 0.22986 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:41:52.389947 ops/training.py:65 2019-01-16 14:41:52.389861: step 21312, loss = 0.18315 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:41:53.352783 ops/training.py:65 2019-01-16 14:41:53.352684: step 21313, loss = 0.21313 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:41:54.315282 ops/training.py:65 2019-01-16 14:41:54.315186: step 21314, loss = 0.24824 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:41:55.276589 ops/training.py:65 2019-01-16 14:41:55.276492: step 21315, loss = 0.14759 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:41:56.238596 ops/training.py:65 2019-01-16 14:41:56.238492: step 21316, loss = 0.12451 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:41:57.199839 ops/training.py:65 2019-01-16 14:41:57.199718: step 21317, loss = 0.23335 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:41:58.161931 ops/training.py:65 2019-01-16 14:41:58.161825: step 21318, loss = 0.15133 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:41:59.123202 ops/training.py:65 2019-01-16 14:41:59.123103: step 21319, loss = 0.28365 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:42:00.085811 ops/training.py:65 2019-01-16 14:42:00.085742: step 21320, loss = 0.28691 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:42:01.047725 ops/training.py:65 2019-01-16 14:42:01.047601: step 21321, loss = 0.12338 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:42:02.013331 ops/training.py:65 2019-01-16 14:42:02.013258: step 21322, loss = 0.15716 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:42:02.973775 ops/training.py:65 2019-01-16 14:42:02.973704: step 21323, loss = 0.24913 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:42:03.934566 ops/training.py:65 2019-01-16 14:42:03.934474: step 21324, loss = 0.11725 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:42:04.899703 ops/training.py:65 2019-01-16 14:42:04.899611: step 21325, loss = 0.21416 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:42:05.863463 ops/training.py:65 2019-01-16 14:42:05.863365: step 21326, loss = 0.12889 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:42:06.828154 ops/training.py:65 2019-01-16 14:42:06.828081: step 21327, loss = 0.20408 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:42:07.791094 ops/training.py:65 2019-01-16 14:42:07.791001: step 21328, loss = 0.21942 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:42:08.753875 ops/training.py:65 2019-01-16 14:42:08.753778: step 21329, loss = 0.17570 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:42:09.715152 ops/training.py:65 2019-01-16 14:42:09.715062: step 21330, loss = 0.31080 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:42:10.676554 ops/training.py:65 2019-01-16 14:42:10.676448: step 21331, loss = 0.19392 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:42:11.638214 ops/training.py:65 2019-01-16 14:42:11.638129: step 21332, loss = 0.12480 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:42:12.599542 ops/training.py:65 2019-01-16 14:42:12.599443: step 21333, loss = 0.20935 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:42:13.560683 ops/training.py:65 2019-01-16 14:42:13.560597: step 21334, loss = 0.22225 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:42:14.523108 ops/training.py:65 2019-01-16 14:42:14.523030: step 21335, loss = 0.22858 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:42:15.483793 ops/training.py:65 2019-01-16 14:42:15.483716: step 21336, loss = 0.14908 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:42:16.444690 ops/training.py:65 2019-01-16 14:42:16.444607: step 21337, loss = 0.13624 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:42:17.406073 ops/training.py:65 2019-01-16 14:42:17.405983: step 21338, loss = 0.19288 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:42:18.370430 ops/training.py:65 2019-01-16 14:42:18.370341: step 21339, loss = 0.18504 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:42:19.333763 ops/training.py:65 2019-01-16 14:42:19.333700: step 21340, loss = 0.11029 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:42:20.296575 ops/training.py:65 2019-01-16 14:42:20.296478: step 21341, loss = 0.15835 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:42:21.258405 ops/training.py:65 2019-01-16 14:42:21.258305: step 21342, loss = 0.16388 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:42:22.222610 ops/training.py:65 2019-01-16 14:42:22.222517: step 21343, loss = 0.16365 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:42:23.186578 ops/training.py:65 2019-01-16 14:42:23.186484: step 21344, loss = 0.16844 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:42:24.149212 ops/training.py:65 2019-01-16 14:42:24.149115: step 21345, loss = 0.16531 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:42:25.111697 ops/training.py:65 2019-01-16 14:42:25.111597: step 21346, loss = 0.20855 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:42:26.074363 ops/training.py:65 2019-01-16 14:42:26.074266: step 21347, loss = 0.12131 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:42:27.036690 ops/training.py:65 2019-01-16 14:42:27.036602: step 21348, loss = 0.19033 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:42:28.000083 ops/training.py:65 2019-01-16 14:42:28.000009: step 21349, loss = 0.20519 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:42:28.963125 ops/training.py:65 2019-01-16 14:42:28.963019: step 21350, loss = 0.24008 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:42:29.925463 ops/training.py:65 2019-01-16 14:42:29.925393: step 21351, loss = 0.26948 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:42:30.888474 ops/training.py:65 2019-01-16 14:42:30.888401: step 21352, loss = 0.31574 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:42:31.852707 ops/training.py:65 2019-01-16 14:42:31.852606: step 21353, loss = 0.14098 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:42:32.814547 ops/training.py:65 2019-01-16 14:42:32.814441: step 21354, loss = 0.21027 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:42:33.776432 ops/training.py:65 2019-01-16 14:42:33.776345: step 21355, loss = 0.14905 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:42:34.737197 ops/training.py:65 2019-01-16 14:42:34.737088: step 21356, loss = 0.24726 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:42:35.701525 ops/training.py:65 2019-01-16 14:42:35.701446: step 21357, loss = 0.20109 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:42:36.664575 ops/training.py:65 2019-01-16 14:42:36.664476: step 21358, loss = 0.12600 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:42:37.625638 ops/training.py:65 2019-01-16 14:42:37.625545: step 21359, loss = 0.19053 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:42:38.586540 ops/training.py:65 2019-01-16 14:42:38.586439: step 21360, loss = 0.38879 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:42:39.547792 ops/training.py:65 2019-01-16 14:42:39.547689: step 21361, loss = 0.31984 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:42:40.510992 ops/training.py:65 2019-01-16 14:42:40.510896: step 21362, loss = 0.16187 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:42:41.472569 ops/training.py:65 2019-01-16 14:42:41.472475: step 21363, loss = 0.30963 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:42:42.434207 ops/training.py:65 2019-01-16 14:42:42.434117: step 21364, loss = 0.35975 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:42:43.399497 ops/training.py:65 2019-01-16 14:42:43.399401: step 21365, loss = 0.14848 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:42:44.364636 ops/training.py:65 2019-01-16 14:42:44.364539: step 21366, loss = 0.16653 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:42:45.327463 ops/training.py:65 2019-01-16 14:42:45.327364: step 21367, loss = 0.30595 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:42:46.289876 ops/training.py:65 2019-01-16 14:42:46.289778: step 21368, loss = 0.45587 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 14:42:47.250860 ops/training.py:65 2019-01-16 14:42:47.250779: step 21369, loss = 0.19077 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:42:48.214622 ops/training.py:65 2019-01-16 14:42:48.214525: step 21370, loss = 0.20615 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:42:49.177647 ops/training.py:65 2019-01-16 14:42:49.177562: step 21371, loss = 0.23224 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:42:50.141725 ops/training.py:65 2019-01-16 14:42:50.141634: step 21372, loss = 0.23860 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:42:51.103260 ops/training.py:65 2019-01-16 14:42:51.103185: step 21373, loss = 0.17459 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:42:52.065133 ops/training.py:65 2019-01-16 14:42:52.065028: step 21374, loss = 0.34622 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:42:53.027995 ops/training.py:65 2019-01-16 14:42:53.027894: step 21375, loss = 0.27944 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:42:53.989006 ops/training.py:65 2019-01-16 14:42:53.988913: step 21376, loss = 0.24922 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:42:54.951026 ops/training.py:65 2019-01-16 14:42:54.950926: step 21377, loss = 0.15824 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:42:55.912518 ops/training.py:65 2019-01-16 14:42:55.912435: step 21378, loss = 0.18115 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:42:56.874312 ops/training.py:65 2019-01-16 14:42:56.874249: step 21379, loss = 0.23832 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:42:57.838372 ops/training.py:65 2019-01-16 14:42:57.838282: step 21380, loss = 0.22397 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:42:58.801806 ops/training.py:65 2019-01-16 14:42:58.801702: step 21381, loss = 0.18647 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:42:59.763898 ops/training.py:65 2019-01-16 14:42:59.763802: step 21382, loss = 0.14459 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:43:00.729037 ops/training.py:65 2019-01-16 14:43:00.728939: step 21383, loss = 0.27090 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:43:01.692539 ops/training.py:65 2019-01-16 14:43:01.692451: step 21384, loss = 0.21338 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:43:02.655766 ops/training.py:65 2019-01-16 14:43:02.655667: step 21385, loss = 0.20919 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:43:03.617351 ops/training.py:65 2019-01-16 14:43:03.617260: step 21386, loss = 0.20805 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:43:04.582850 ops/training.py:65 2019-01-16 14:43:04.582743: step 21387, loss = 0.25952 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:43:05.545449 ops/training.py:65 2019-01-16 14:43:05.545353: step 21388, loss = 0.20201 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:43:06.509979 ops/training.py:65 2019-01-16 14:43:06.509879: step 21389, loss = 0.20432 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:43:07.472658 ops/training.py:65 2019-01-16 14:43:07.472557: step 21390, loss = 0.30782 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:43:08.436098 ops/training.py:65 2019-01-16 14:43:08.436011: step 21391, loss = 0.27746 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:43:09.398315 ops/training.py:65 2019-01-16 14:43:09.398228: step 21392, loss = 0.49934 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:43:10.361901 ops/training.py:65 2019-01-16 14:43:10.361817: step 21393, loss = 0.19529 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:43:11.323822 ops/training.py:65 2019-01-16 14:43:11.323727: step 21394, loss = 0.35607 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:43:12.285734 ops/training.py:65 2019-01-16 14:43:12.285649: step 21395, loss = 0.24851 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:43:13.248068 ops/training.py:65 2019-01-16 14:43:13.247978: step 21396, loss = 0.27486 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:43:14.210904 ops/training.py:65 2019-01-16 14:43:14.210821: step 21397, loss = 0.18473 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:43:15.172290 ops/training.py:65 2019-01-16 14:43:15.172186: step 21398, loss = 0.10853 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:43:16.133867 ops/training.py:65 2019-01-16 14:43:16.133749: step 21399, loss = 0.25807 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:43:17.095861 ops/training.py:65 2019-01-16 14:43:17.095759: step 21400, loss = 0.23550 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:43:18.058609 ops/training.py:65 2019-01-16 14:43:18.058512: step 21401, loss = 0.26862 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:43:19.019883 ops/training.py:65 2019-01-16 14:43:19.019769: step 21402, loss = 0.25552 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:43:19.981311 ops/training.py:65 2019-01-16 14:43:19.981227: step 21403, loss = 0.20065 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:43:20.943080 ops/training.py:65 2019-01-16 14:43:20.943032: step 21404, loss = 0.28675 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:43:21.905381 ops/training.py:65 2019-01-16 14:43:21.905273: step 21405, loss = 0.27647 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:43:22.867183 ops/training.py:65 2019-01-16 14:43:22.867103: step 21406, loss = 0.20464 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:43:23.828374 ops/training.py:65 2019-01-16 14:43:23.828281: step 21407, loss = 0.15661 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:43:24.793101 ops/training.py:65 2019-01-16 14:43:24.792996: step 21408, loss = 0.16409 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:43:25.757536 ops/training.py:65 2019-01-16 14:43:25.757455: step 21409, loss = 0.13894 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:43:26.720803 ops/training.py:65 2019-01-16 14:43:26.720709: step 21410, loss = 0.21709 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:43:27.683027 ops/training.py:65 2019-01-16 14:43:27.682936: step 21411, loss = 0.15300 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:43:28.646943 ops/training.py:65 2019-01-16 14:43:28.646847: step 21412, loss = 0.12738 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:43:29.610741 ops/training.py:65 2019-01-16 14:43:29.610653: step 21413, loss = 0.20156 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:43:30.573359 ops/training.py:65 2019-01-16 14:43:30.573288: step 21414, loss = 0.21066 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:43:31.538000 ops/training.py:65 2019-01-16 14:43:31.537894: step 21415, loss = 0.16356 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:43:32.502995 ops/training.py:65 2019-01-16 14:43:32.502930: step 21416, loss = 0.31137 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:43:33.464885 ops/training.py:65 2019-01-16 14:43:33.464784: step 21417, loss = 0.26199 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:43:34.425945 ops/training.py:65 2019-01-16 14:43:34.425851: step 21418, loss = 0.30049 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:43:35.387887 ops/training.py:65 2019-01-16 14:43:35.387789: step 21419, loss = 0.16248 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:43:36.349737 ops/training.py:65 2019-01-16 14:43:36.349645: step 21420, loss = 0.14285 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:43:37.311050 ops/training.py:65 2019-01-16 14:43:37.310956: step 21421, loss = 0.17289 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:43:38.272671 ops/training.py:65 2019-01-16 14:43:38.272572: step 21422, loss = 0.39818 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:43:39.235094 ops/training.py:65 2019-01-16 14:43:39.234973: step 21423, loss = 0.25707 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:43:40.200069 ops/training.py:65 2019-01-16 14:43:40.199997: step 21424, loss = 0.28458 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:43:41.163605 ops/training.py:65 2019-01-16 14:43:41.163508: step 21425, loss = 0.14513 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:43:42.128731 ops/training.py:65 2019-01-16 14:43:42.128627: step 21426, loss = 0.13245 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:43:43.092128 ops/training.py:65 2019-01-16 14:43:43.092026: step 21427, loss = 0.21774 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:43:44.053565 ops/training.py:65 2019-01-16 14:43:44.053449: step 21428, loss = 0.35514 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:43:45.016951 ops/training.py:65 2019-01-16 14:43:45.016806: step 21429, loss = 0.23913 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:43:45.982001 ops/training.py:65 2019-01-16 14:43:45.981935: step 21430, loss = 0.16336 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:43:46.945916 ops/training.py:65 2019-01-16 14:43:46.945836: step 21431, loss = 0.20097 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:43:47.909109 ops/training.py:65 2019-01-16 14:43:47.909009: step 21432, loss = 0.17711 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:43:48.871860 ops/training.py:65 2019-01-16 14:43:48.871742: step 21433, loss = 0.28023 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:43:49.839752 ops/training.py:65 2019-01-16 14:43:49.839652: step 21434, loss = 0.25468 (33.1 examples/sec; 0.966 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:43:50.804649 ops/training.py:65 2019-01-16 14:43:50.804549: step 21435, loss = 0.17749 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:43:51.768439 ops/training.py:65 2019-01-16 14:43:51.768344: step 21436, loss = 0.29290 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:43:52.730578 ops/training.py:65 2019-01-16 14:43:52.730497: step 21437, loss = 0.51952 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:43:53.692512 ops/training.py:65 2019-01-16 14:43:53.692431: step 21438, loss = 0.17836 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:43:54.655590 ops/training.py:65 2019-01-16 14:43:54.655497: step 21439, loss = 0.25380 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:43:55.617480 ops/training.py:65 2019-01-16 14:43:55.617385: step 21440, loss = 0.24440 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:43:56.579313 ops/training.py:65 2019-01-16 14:43:56.579212: step 21441, loss = 0.17855 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:43:57.540810 ops/training.py:65 2019-01-16 14:43:57.540714: step 21442, loss = 0.13335 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:43:58.502969 ops/training.py:65 2019-01-16 14:43:58.502849: step 21443, loss = 0.10901 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:43:59.465304 ops/training.py:65 2019-01-16 14:43:59.465198: step 21444, loss = 0.20216 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:44:00.427010 ops/training.py:65 2019-01-16 14:44:00.426937: step 21445, loss = 0.22326 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:44:01.387889 ops/training.py:65 2019-01-16 14:44:01.387810: step 21446, loss = 0.13911 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:44:02.349101 ops/training.py:65 2019-01-16 14:44:02.349021: step 21447, loss = 0.17969 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:44:03.314697 ops/training.py:65 2019-01-16 14:44:03.314597: step 21448, loss = 0.17930 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:44:04.279064 ops/training.py:65 2019-01-16 14:44:04.278951: step 21449, loss = 0.14872 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:44:05.243773 ops/training.py:65 2019-01-16 14:44:05.243677: step 21450, loss = 0.26754 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:44:06.207242 ops/training.py:65 2019-01-16 14:44:06.207155: step 21451, loss = 0.28055 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:44:07.169437 ops/training.py:65 2019-01-16 14:44:07.169375: step 21452, loss = 0.13326 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:44:08.135408 ops/training.py:65 2019-01-16 14:44:08.135336: step 21453, loss = 0.27605 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:44:09.098725 ops/training.py:65 2019-01-16 14:44:09.098690: step 21454, loss = 0.30956 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:44:10.062630 ops/training.py:65 2019-01-16 14:44:10.062592: step 21455, loss = 0.14606 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:44:11.026405 ops/training.py:65 2019-01-16 14:44:11.026352: step 21456, loss = 0.15118 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:44:11.988643 ops/training.py:65 2019-01-16 14:44:11.988580: step 21457, loss = 0.19803 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:44:12.950239 ops/training.py:65 2019-01-16 14:44:12.950186: step 21458, loss = 0.25175 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:44:13.911653 ops/training.py:65 2019-01-16 14:44:13.911597: step 21459, loss = 0.17424 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:44:14.872809 ops/training.py:65 2019-01-16 14:44:14.872770: step 21460, loss = 0.21578 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:44:15.833032 ops/training.py:65 2019-01-16 14:44:15.832997: step 21461, loss = 0.08993 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:44:16.794254 ops/training.py:65 2019-01-16 14:44:16.794219: step 21462, loss = 0.31856 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:44:17.755475 ops/training.py:65 2019-01-16 14:44:17.755418: step 21463, loss = 0.16234 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:44:18.716713 ops/training.py:65 2019-01-16 14:44:18.716679: step 21464, loss = 0.27910 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:44:19.679035 ops/training.py:65 2019-01-16 14:44:19.679002: step 21465, loss = 0.21845 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:44:20.641467 ops/training.py:65 2019-01-16 14:44:20.641428: step 21466, loss = 0.18382 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:44:21.602557 ops/training.py:65 2019-01-16 14:44:21.602524: step 21467, loss = 0.13349 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:44:22.564447 ops/training.py:65 2019-01-16 14:44:22.564391: step 21468, loss = 0.22435 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:44:23.525916 ops/training.py:65 2019-01-16 14:44:23.525876: step 21469, loss = 0.15198 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:44:24.487030 ops/training.py:65 2019-01-16 14:44:24.486995: step 21470, loss = 0.15372 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:44:25.448150 ops/training.py:65 2019-01-16 14:44:25.448112: step 21471, loss = 0.29776 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:44:26.409493 ops/training.py:65 2019-01-16 14:44:26.409456: step 21472, loss = 0.25823 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:44:27.370342 ops/training.py:65 2019-01-16 14:44:27.370303: step 21473, loss = 0.17175 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:44:28.330874 ops/training.py:65 2019-01-16 14:44:28.330836: step 21474, loss = 0.26134 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:44:29.291055 ops/training.py:65 2019-01-16 14:44:29.291013: step 21475, loss = 0.21339 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:44:30.251300 ops/training.py:65 2019-01-16 14:44:30.251262: step 21476, loss = 0.20904 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:44:31.212465 ops/training.py:65 2019-01-16 14:44:31.212429: step 21477, loss = 0.25414 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:44:32.173643 ops/training.py:65 2019-01-16 14:44:32.173608: step 21478, loss = 0.19533 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:44:33.134018 ops/training.py:65 2019-01-16 14:44:33.133984: step 21479, loss = 0.14892 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:44:34.096188 ops/training.py:65 2019-01-16 14:44:34.096157: step 21480, loss = 0.12393 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:44:35.057947 ops/training.py:65 2019-01-16 14:44:35.057916: step 21481, loss = 0.27699 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:44:36.019252 ops/training.py:65 2019-01-16 14:44:36.019221: step 21482, loss = 0.21972 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:44:36.979499 ops/training.py:65 2019-01-16 14:44:36.979464: step 21483, loss = 0.21567 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:44:37.940373 ops/training.py:65 2019-01-16 14:44:37.940329: step 21484, loss = 0.15192 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:44:38.902955 ops/training.py:65 2019-01-16 14:44:38.902910: step 21485, loss = 0.23980 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:44:39.864363 ops/training.py:65 2019-01-16 14:44:39.864318: step 21486, loss = 0.18302 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:44:40.825873 ops/training.py:65 2019-01-16 14:44:40.825834: step 21487, loss = 0.18894 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:44:41.786674 ops/training.py:65 2019-01-16 14:44:41.786641: step 21488, loss = 0.18752 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:44:42.747991 ops/training.py:65 2019-01-16 14:44:42.747958: step 21489, loss = 0.19326 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:44:43.709579 ops/training.py:65 2019-01-16 14:44:43.709546: step 21490, loss = 0.16423 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:44:44.670789 ops/training.py:65 2019-01-16 14:44:44.670756: step 21491, loss = 0.28695 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:44:45.631819 ops/training.py:65 2019-01-16 14:44:45.631772: step 21492, loss = 0.43596 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:44:46.592848 ops/training.py:65 2019-01-16 14:44:46.592799: step 21493, loss = 0.17586 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:44:47.554247 ops/training.py:65 2019-01-16 14:44:47.554165: step 21494, loss = 0.12817 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:44:48.515350 ops/training.py:65 2019-01-16 14:44:48.515310: step 21495, loss = 0.11875 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:44:49.476126 ops/training.py:65 2019-01-16 14:44:49.476090: step 21496, loss = 0.19401 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:44:50.436758 ops/training.py:65 2019-01-16 14:44:50.436731: step 21497, loss = 0.16102 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:44:51.397673 ops/training.py:65 2019-01-16 14:44:51.397641: step 21498, loss = 0.13004 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:44:52.358410 ops/training.py:65 2019-01-16 14:44:52.358376: step 21499, loss = 0.27334 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:44:53.319697 ops/training.py:65 2019-01-16 14:44:53.319663: step 21500, loss = 0.15163 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:44:54.280886 ops/training.py:65 2019-01-16 14:44:54.280854: step 21501, loss = 0.26147 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:44:55.242363 ops/training.py:65 2019-01-16 14:44:55.242330: step 21502, loss = 0.22588 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:44:56.204057 ops/training.py:65 2019-01-16 14:44:56.204024: step 21503, loss = 0.09097 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:44:57.164785 ops/training.py:65 2019-01-16 14:44:57.164753: step 21504, loss = 0.23837 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:44:58.126087 ops/training.py:65 2019-01-16 14:44:58.126055: step 21505, loss = 0.16375 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:44:59.087504 ops/training.py:65 2019-01-16 14:44:59.087472: step 21506, loss = 0.14937 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:45:00.049189 ops/training.py:65 2019-01-16 14:45:00.049156: step 21507, loss = 0.23584 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:45:01.010071 ops/training.py:65 2019-01-16 14:45:01.010036: step 21508, loss = 0.07856 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:45:01.972175 ops/training.py:65 2019-01-16 14:45:01.972142: step 21509, loss = 0.21814 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:45:02.933711 ops/training.py:65 2019-01-16 14:45:02.933654: step 21510, loss = 0.13556 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:45:03.896382 ops/training.py:65 2019-01-16 14:45:03.896343: step 21511, loss = 0.25865 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:45:04.856823 ops/training.py:65 2019-01-16 14:45:04.856784: step 21512, loss = 0.15106 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:45:05.818295 ops/training.py:65 2019-01-16 14:45:05.818236: step 21513, loss = 0.10391 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:45:06.779969 ops/training.py:65 2019-01-16 14:45:06.779913: step 21514, loss = 0.21738 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:45:07.741356 ops/training.py:65 2019-01-16 14:45:07.741297: step 21515, loss = 0.18156 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:45:08.702701 ops/training.py:65 2019-01-16 14:45:08.702640: step 21516, loss = 0.25556 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:45:09.663326 ops/training.py:65 2019-01-16 14:45:09.663291: step 21517, loss = 0.25817 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:45:10.623731 ops/training.py:65 2019-01-16 14:45:10.623697: step 21518, loss = 0.16049 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:45:11.585932 ops/training.py:65 2019-01-16 14:45:11.585878: step 21519, loss = 0.35748 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:45:12.547183 ops/training.py:65 2019-01-16 14:45:12.547134: step 21520, loss = 0.12833 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:45:13.509065 ops/training.py:65 2019-01-16 14:45:13.509019: step 21521, loss = 0.26074 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:45:14.469868 ops/training.py:65 2019-01-16 14:45:14.469821: step 21522, loss = 0.21012 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:45:15.430707 ops/training.py:65 2019-01-16 14:45:15.430653: step 21523, loss = 0.28582 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:45:16.391937 ops/training.py:65 2019-01-16 14:45:16.391883: step 21524, loss = 0.19896 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:45:17.352118 ops/training.py:65 2019-01-16 14:45:17.352040: step 21525, loss = 0.29670 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:45:18.313164 ops/training.py:65 2019-01-16 14:45:18.313136: step 21526, loss = 0.15389 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:45:19.274153 ops/training.py:65 2019-01-16 14:45:19.274090: step 21527, loss = 0.16706 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:45:20.235536 ops/training.py:65 2019-01-16 14:45:20.235500: step 21528, loss = 0.18449 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:45:21.196989 ops/training.py:65 2019-01-16 14:45:21.196958: step 21529, loss = 0.20973 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:45:22.158420 ops/training.py:65 2019-01-16 14:45:22.158386: step 21530, loss = 0.24977 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:45:23.119558 ops/training.py:65 2019-01-16 14:45:23.119524: step 21531, loss = 0.26693 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:45:24.081396 ops/training.py:65 2019-01-16 14:45:24.081363: step 21532, loss = 0.24916 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:45:25.042628 ops/training.py:65 2019-01-16 14:45:25.042594: step 21533, loss = 0.28039 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:45:26.003571 ops/training.py:65 2019-01-16 14:45:26.003537: step 21534, loss = 0.18376 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:45:26.964563 ops/training.py:65 2019-01-16 14:45:26.964531: step 21535, loss = 0.14726 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:45:27.925531 ops/training.py:65 2019-01-16 14:45:27.925497: step 21536, loss = 0.28676 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:45:28.889994 ops/training.py:65 2019-01-16 14:45:28.889895: step 21537, loss = 0.12783 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:45:29.853139 ops/training.py:65 2019-01-16 14:45:29.853086: step 21538, loss = 0.14055 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:45:30.816947 ops/training.py:65 2019-01-16 14:45:30.816908: step 21539, loss = 0.12996 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:45:31.779214 ops/training.py:65 2019-01-16 14:45:31.779176: step 21540, loss = 0.12700 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:45:32.740542 ops/training.py:65 2019-01-16 14:45:32.740495: step 21541, loss = 0.18052 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:45:33.701561 ops/training.py:65 2019-01-16 14:45:33.701492: step 21542, loss = 0.26368 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:45:34.662515 ops/training.py:65 2019-01-16 14:45:34.662476: step 21543, loss = 0.18170 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:45:35.622792 ops/training.py:65 2019-01-16 14:45:35.622755: step 21544, loss = 0.25168 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:45:36.584648 ops/training.py:65 2019-01-16 14:45:36.584553: step 21545, loss = 0.25316 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:45:37.548101 ops/training.py:65 2019-01-16 14:45:37.548061: step 21546, loss = 0.34502 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:45:38.509196 ops/training.py:65 2019-01-16 14:45:38.509155: step 21547, loss = 0.30611 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:45:39.468220 ops/training.py:65 2019-01-16 14:45:39.468183: step 21548, loss = 0.42450 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.71875
I0832 2019-01-16 14:45:40.433024 ops/training.py:65 2019-01-16 14:45:40.432984: step 21549, loss = 0.27216 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:45:41.396723 ops/training.py:65 2019-01-16 14:45:41.396660: step 21550, loss = 0.17230 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:45:42.359296 ops/training.py:65 2019-01-16 14:45:42.359257: step 21551, loss = 0.19631 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:45:43.320406 ops/training.py:65 2019-01-16 14:45:43.320356: step 21552, loss = 0.24958 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:45:44.281171 ops/training.py:65 2019-01-16 14:45:44.281136: step 21553, loss = 0.14770 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:45:45.241985 ops/training.py:65 2019-01-16 14:45:45.241930: step 21554, loss = 0.23913 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:45:46.203861 ops/training.py:65 2019-01-16 14:45:46.203805: step 21555, loss = 0.06838 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:45:47.165550 ops/training.py:65 2019-01-16 14:45:47.165479: step 21556, loss = 0.19785 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:45:48.126547 ops/training.py:65 2019-01-16 14:45:48.126510: step 21557, loss = 0.37047 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:45:49.091149 ops/training.py:65 2019-01-16 14:45:49.091068: step 21558, loss = 0.22866 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:45:50.055761 ops/training.py:65 2019-01-16 14:45:50.055717: step 21559, loss = 0.20812 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:45:51.020103 ops/training.py:65 2019-01-16 14:45:51.020071: step 21560, loss = 0.22473 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:45:51.984221 ops/training.py:65 2019-01-16 14:45:51.984163: step 21561, loss = 0.16918 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:45:52.945902 ops/training.py:65 2019-01-16 14:45:52.945862: step 21562, loss = 0.13676 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:45:53.907079 ops/training.py:65 2019-01-16 14:45:53.907046: step 21563, loss = 0.23055 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:45:54.868028 ops/training.py:65 2019-01-16 14:45:54.867995: step 21564, loss = 0.23588 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:45:55.828848 ops/training.py:65 2019-01-16 14:45:55.828814: step 21565, loss = 0.11760 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:45:56.789801 ops/training.py:65 2019-01-16 14:45:56.789765: step 21566, loss = 0.33358 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:45:57.755330 ops/training.py:65 2019-01-16 14:45:57.755240: step 21567, loss = 0.21543 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:45:58.715484 ops/training.py:65 2019-01-16 14:45:58.715380: step 21568, loss = 0.25747 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:45:59.679892 ops/training.py:65 2019-01-16 14:45:59.679847: step 21569, loss = 0.28518 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:46:00.643016 ops/training.py:65 2019-01-16 14:46:00.642946: step 21570, loss = 0.35155 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:46:01.605468 ops/training.py:65 2019-01-16 14:46:01.605431: step 21571, loss = 0.31392 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:46:02.567369 ops/training.py:65 2019-01-16 14:46:02.567334: step 21572, loss = 0.21868 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:46:03.528100 ops/training.py:65 2019-01-16 14:46:03.528023: step 21573, loss = 0.18308 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:46:04.492505 ops/training.py:65 2019-01-16 14:46:04.492461: step 21574, loss = 0.07190 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:46:05.455979 ops/training.py:65 2019-01-16 14:46:05.455934: step 21575, loss = 0.29314 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:46:06.418882 ops/training.py:65 2019-01-16 14:46:06.418845: step 21576, loss = 0.17920 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:46:07.380839 ops/training.py:65 2019-01-16 14:46:07.380795: step 21577, loss = 0.23895 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:46:08.341557 ops/training.py:65 2019-01-16 14:46:08.341516: step 21578, loss = 0.22656 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:46:09.302540 ops/training.py:65 2019-01-16 14:46:09.302506: step 21579, loss = 0.21441 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:46:10.262522 ops/training.py:65 2019-01-16 14:46:10.262489: step 21580, loss = 0.17641 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:46:11.223771 ops/training.py:65 2019-01-16 14:46:11.223737: step 21581, loss = 0.17012 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:46:12.185035 ops/training.py:65 2019-01-16 14:46:12.185003: step 21582, loss = 0.06175 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:46:13.145670 ops/training.py:65 2019-01-16 14:46:13.145637: step 21583, loss = 0.23771 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:46:14.110555 ops/training.py:65 2019-01-16 14:46:14.110522: step 21584, loss = 0.18837 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:46:15.074712 ops/training.py:65 2019-01-16 14:46:15.074675: step 21585, loss = 0.08008 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:46:16.037128 ops/training.py:65 2019-01-16 14:46:16.037084: step 21586, loss = 0.16485 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:46:16.999732 ops/training.py:65 2019-01-16 14:46:16.999666: step 21587, loss = 0.22016 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:46:17.961736 ops/training.py:65 2019-01-16 14:46:17.961701: step 21588, loss = 0.15489 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:46:18.923506 ops/training.py:65 2019-01-16 14:46:18.923478: step 21589, loss = 0.26191 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:46:19.885158 ops/training.py:65 2019-01-16 14:46:19.885129: step 21590, loss = 0.24448 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:46:20.846837 ops/training.py:65 2019-01-16 14:46:20.846793: step 21591, loss = 0.22757 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:46:21.808529 ops/training.py:65 2019-01-16 14:46:21.808444: step 21592, loss = 0.20769 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:46:22.773363 ops/training.py:65 2019-01-16 14:46:22.773322: step 21593, loss = 0.29115 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:46:23.735186 ops/training.py:65 2019-01-16 14:46:23.735141: step 21594, loss = 0.24081 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:46:24.698060 ops/training.py:65 2019-01-16 14:46:24.697978: step 21595, loss = 0.34294 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:46:25.658622 ops/training.py:65 2019-01-16 14:46:25.658534: step 21596, loss = 0.18345 (33.4 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:46:26.622591 ops/training.py:65 2019-01-16 14:46:26.622510: step 21597, loss = 0.09943 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:46:27.586600 ops/training.py:65 2019-01-16 14:46:27.586516: step 21598, loss = 0.13048 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:46:28.549901 ops/training.py:65 2019-01-16 14:46:28.549822: step 21599, loss = 0.21712 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:46:29.511361 ops/training.py:65 2019-01-16 14:46:29.511283: step 21600, loss = 0.30066 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:46:30.472904 ops/training.py:65 2019-01-16 14:46:30.472823: step 21601, loss = 0.22314 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:46:31.434735 ops/training.py:65 2019-01-16 14:46:31.434650: step 21602, loss = 0.12193 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:46:32.396534 ops/training.py:65 2019-01-16 14:46:32.396455: step 21603, loss = 0.27419 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:46:33.361229 ops/training.py:65 2019-01-16 14:46:33.361165: step 21604, loss = 0.30236 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:46:34.322094 ops/training.py:65 2019-01-16 14:46:34.322035: step 21605, loss = 0.09897 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:46:35.283616 ops/training.py:65 2019-01-16 14:46:35.283536: step 21606, loss = 0.23268 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:46:36.243857 ops/training.py:65 2019-01-16 14:46:36.243797: step 21607, loss = 0.22002 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:46:37.204425 ops/training.py:65 2019-01-16 14:46:37.204351: step 21608, loss = 0.26328 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:46:38.165863 ops/training.py:65 2019-01-16 14:46:38.165776: step 21609, loss = 0.30314 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:46:39.126271 ops/training.py:65 2019-01-16 14:46:39.126194: step 21610, loss = 0.30086 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:46:40.087626 ops/training.py:65 2019-01-16 14:46:40.087552: step 21611, loss = 0.33840 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:46:41.048907 ops/training.py:65 2019-01-16 14:46:41.048835: step 21612, loss = 0.17621 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:46:42.010967 ops/training.py:65 2019-01-16 14:46:42.010889: step 21613, loss = 0.22634 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:46:42.976630 ops/training.py:65 2019-01-16 14:46:42.976545: step 21614, loss = 0.25472 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:46:43.940142 ops/training.py:65 2019-01-16 14:46:43.940063: step 21615, loss = 0.19733 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:46:44.902307 ops/training.py:65 2019-01-16 14:46:44.902230: step 21616, loss = 0.21237 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:46:45.863842 ops/training.py:65 2019-01-16 14:46:45.863766: step 21617, loss = 0.31276 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:46:46.825101 ops/training.py:65 2019-01-16 14:46:46.825022: step 21618, loss = 0.23096 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:46:47.786560 ops/training.py:65 2019-01-16 14:46:47.786495: step 21619, loss = 0.14833 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:46:48.748641 ops/training.py:65 2019-01-16 14:46:48.748568: step 21620, loss = 0.15820 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:46:49.709903 ops/training.py:65 2019-01-16 14:46:49.709839: step 21621, loss = 0.19100 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:46:50.672034 ops/training.py:65 2019-01-16 14:46:50.671958: step 21622, loss = 0.22907 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:46:51.634086 ops/training.py:65 2019-01-16 14:46:51.634025: step 21623, loss = 0.23804 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:46:52.595691 ops/training.py:65 2019-01-16 14:46:52.595619: step 21624, loss = 0.17105 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:46:53.557773 ops/training.py:65 2019-01-16 14:46:53.557694: step 21625, loss = 0.29134 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:46:54.519316 ops/training.py:65 2019-01-16 14:46:54.519237: step 21626, loss = 0.30207 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:46:55.481191 ops/training.py:65 2019-01-16 14:46:55.481108: step 21627, loss = 0.12304 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:46:56.442630 ops/training.py:65 2019-01-16 14:46:56.442552: step 21628, loss = 0.20771 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:46:57.408345 ops/training.py:65 2019-01-16 14:46:57.408267: step 21629, loss = 0.13244 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:46:58.373482 ops/training.py:65 2019-01-16 14:46:58.373407: step 21630, loss = 0.14418 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:46:59.339026 ops/training.py:65 2019-01-16 14:46:59.338943: step 21631, loss = 0.13907 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:47:00.301745 ops/training.py:65 2019-01-16 14:47:00.301674: step 21632, loss = 0.20909 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:47:01.263244 ops/training.py:65 2019-01-16 14:47:01.263161: step 21633, loss = 0.22408 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:47:02.227928 ops/training.py:65 2019-01-16 14:47:02.227863: step 21634, loss = 0.20862 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:47:03.192198 ops/training.py:65 2019-01-16 14:47:03.192112: step 21635, loss = 0.20934 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:47:04.156603 ops/training.py:65 2019-01-16 14:47:04.156543: step 21636, loss = 0.12340 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:47:05.118712 ops/training.py:65 2019-01-16 14:47:05.118634: step 21637, loss = 0.07048 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:47:06.082159 ops/training.py:65 2019-01-16 14:47:06.082099: step 21638, loss = 0.13226 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:47:07.043776 ops/training.py:65 2019-01-16 14:47:07.043704: step 21639, loss = 0.25056 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:47:08.005899 ops/training.py:65 2019-01-16 14:47:08.005822: step 21640, loss = 0.16702 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:47:08.968030 ops/training.py:65 2019-01-16 14:47:08.967948: step 21641, loss = 0.21335 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:47:09.929548 ops/training.py:65 2019-01-16 14:47:09.929476: step 21642, loss = 0.15568 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:47:10.891677 ops/training.py:65 2019-01-16 14:47:10.891602: step 21643, loss = 0.11434 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:47:11.853144 ops/training.py:65 2019-01-16 14:47:11.853063: step 21644, loss = 0.26074 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:47:12.815151 ops/training.py:65 2019-01-16 14:47:12.815075: step 21645, loss = 0.09727 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:47:13.776463 ops/training.py:65 2019-01-16 14:47:13.776369: step 21646, loss = 0.09981 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:47:14.739369 ops/training.py:65 2019-01-16 14:47:14.739277: step 21647, loss = 0.20170 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:47:15.702293 ops/training.py:65 2019-01-16 14:47:15.702213: step 21648, loss = 0.09160 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:47:16.664365 ops/training.py:65 2019-01-16 14:47:16.664289: step 21649, loss = 0.23066 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:47:17.626339 ops/training.py:65 2019-01-16 14:47:17.626275: step 21650, loss = 0.14961 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:47:18.587629 ops/training.py:65 2019-01-16 14:47:18.587555: step 21651, loss = 0.17506 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:47:19.549817 ops/training.py:65 2019-01-16 14:47:19.549742: step 21652, loss = 0.25468 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:47:20.513507 ops/training.py:65 2019-01-16 14:47:20.513432: step 21653, loss = 0.23266 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:47:21.476782 ops/training.py:65 2019-01-16 14:47:21.476722: step 21654, loss = 0.15985 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:47:22.440778 ops/training.py:65 2019-01-16 14:47:22.440707: step 21655, loss = 0.10146 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:47:23.402295 ops/training.py:65 2019-01-16 14:47:23.402221: step 21656, loss = 0.18506 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:47:24.363925 ops/training.py:65 2019-01-16 14:47:24.363847: step 21657, loss = 0.30556 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:47:25.326140 ops/training.py:65 2019-01-16 14:47:25.326062: step 21658, loss = 0.10125 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:47:26.288540 ops/training.py:65 2019-01-16 14:47:26.288469: step 21659, loss = 0.16972 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:47:27.250458 ops/training.py:65 2019-01-16 14:47:27.250386: step 21660, loss = 0.20823 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:47:28.212284 ops/training.py:65 2019-01-16 14:47:28.212205: step 21661, loss = 0.16677 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:47:29.173988 ops/training.py:65 2019-01-16 14:47:29.173909: step 21662, loss = 0.34072 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:47:30.135371 ops/training.py:65 2019-01-16 14:47:30.135291: step 21663, loss = 0.19927 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:47:31.098583 ops/training.py:65 2019-01-16 14:47:31.098525: step 21664, loss = 0.25234 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:47:32.060463 ops/training.py:65 2019-01-16 14:47:32.060388: step 21665, loss = 0.14715 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:47:33.022405 ops/training.py:65 2019-01-16 14:47:33.022325: step 21666, loss = 0.19354 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:47:33.983569 ops/training.py:65 2019-01-16 14:47:33.983511: step 21667, loss = 0.08982 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:47:34.945791 ops/training.py:65 2019-01-16 14:47:34.945703: step 21668, loss = 0.38065 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:47:35.907743 ops/training.py:65 2019-01-16 14:47:35.907683: step 21669, loss = 0.25731 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:47:36.869482 ops/training.py:65 2019-01-16 14:47:36.869404: step 21670, loss = 0.37161 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:47:37.831696 ops/training.py:65 2019-01-16 14:47:37.831617: step 21671, loss = 0.24747 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:47:38.794029 ops/training.py:65 2019-01-16 14:47:38.793952: step 21672, loss = 0.17744 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:47:39.756216 ops/training.py:65 2019-01-16 14:47:39.756144: step 21673, loss = 0.17862 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:47:40.717762 ops/training.py:65 2019-01-16 14:47:40.717690: step 21674, loss = 0.29439 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:47:41.679231 ops/training.py:65 2019-01-16 14:47:41.679155: step 21675, loss = 0.17165 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:47:42.641353 ops/training.py:65 2019-01-16 14:47:42.641280: step 21676, loss = 0.19418 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:47:43.603307 ops/training.py:65 2019-01-16 14:47:43.603235: step 21677, loss = 0.14707 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:47:44.564953 ops/training.py:65 2019-01-16 14:47:44.564880: step 21678, loss = 0.15486 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:47:45.527305 ops/training.py:65 2019-01-16 14:47:45.527226: step 21679, loss = 0.19194 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:47:46.489810 ops/training.py:65 2019-01-16 14:47:46.489738: step 21680, loss = 0.26277 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:47:47.451493 ops/training.py:65 2019-01-16 14:47:47.451426: step 21681, loss = 0.13496 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:47:48.413632 ops/training.py:65 2019-01-16 14:47:48.413554: step 21682, loss = 0.19766 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:47:49.375017 ops/training.py:65 2019-01-16 14:47:49.374957: step 21683, loss = 0.09219 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:47:50.337516 ops/training.py:65 2019-01-16 14:47:50.337448: step 21684, loss = 0.15125 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:47:51.299865 ops/training.py:65 2019-01-16 14:47:51.299802: step 21685, loss = 0.31150 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:47:52.263107 ops/training.py:65 2019-01-16 14:47:52.263028: step 21686, loss = 0.27002 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:47:53.224555 ops/training.py:65 2019-01-16 14:47:53.224486: step 21687, loss = 0.15081 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:47:54.188851 ops/training.py:65 2019-01-16 14:47:54.188774: step 21688, loss = 0.21029 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:47:55.151715 ops/training.py:65 2019-01-16 14:47:55.151639: step 21689, loss = 0.31625 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:47:56.114528 ops/training.py:65 2019-01-16 14:47:56.114454: step 21690, loss = 0.23948 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:47:57.076436 ops/training.py:65 2019-01-16 14:47:57.076362: step 21691, loss = 0.25664 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:47:58.037931 ops/training.py:65 2019-01-16 14:47:58.037852: step 21692, loss = 0.16113 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:47:58.999189 ops/training.py:65 2019-01-16 14:47:58.999119: step 21693, loss = 0.11811 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:47:59.960843 ops/training.py:65 2019-01-16 14:47:59.960769: step 21694, loss = 0.25006 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:48:00.922003 ops/training.py:65 2019-01-16 14:48:00.921901: step 21695, loss = 0.26072 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:48:01.884207 ops/training.py:65 2019-01-16 14:48:01.884107: step 21696, loss = 0.18959 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:48:02.846535 ops/training.py:65 2019-01-16 14:48:02.846454: step 21697, loss = 0.19584 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:48:03.808278 ops/training.py:65 2019-01-16 14:48:03.808194: step 21698, loss = 0.30012 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:48:04.773286 ops/training.py:65 2019-01-16 14:48:04.773228: step 21699, loss = 0.19384 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:48:05.734590 ops/training.py:65 2019-01-16 14:48:05.734560: step 21700, loss = 0.18505 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:48:06.695947 ops/training.py:65 2019-01-16 14:48:06.695916: step 21701, loss = 0.10878 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:48:07.656803 ops/training.py:65 2019-01-16 14:48:07.656766: step 21702, loss = 0.17690 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:48:08.616884 ops/training.py:65 2019-01-16 14:48:08.616806: step 21703, loss = 0.27495 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:48:09.582736 ops/training.py:65 2019-01-16 14:48:09.582691: step 21704, loss = 0.12583 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:48:10.546150 ops/training.py:65 2019-01-16 14:48:10.546119: step 21705, loss = 0.22176 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:48:11.509050 ops/training.py:65 2019-01-16 14:48:11.508969: step 21706, loss = 0.20584 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:48:12.470604 ops/training.py:65 2019-01-16 14:48:12.470526: step 21707, loss = 0.13618 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:48:13.435576 ops/training.py:65 2019-01-16 14:48:13.435489: step 21708, loss = 0.29440 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:48:14.398158 ops/training.py:65 2019-01-16 14:48:14.398077: step 21709, loss = 0.30824 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:48:15.360795 ops/training.py:65 2019-01-16 14:48:15.360721: step 21710, loss = 0.18204 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:48:16.321947 ops/training.py:65 2019-01-16 14:48:16.321874: step 21711, loss = 0.11574 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:48:17.283259 ops/training.py:65 2019-01-16 14:48:17.283196: step 21712, loss = 0.20724 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:48:18.244585 ops/training.py:65 2019-01-16 14:48:18.244524: step 21713, loss = 0.21065 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:48:19.205557 ops/training.py:65 2019-01-16 14:48:19.205496: step 21714, loss = 0.12377 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:48:20.167260 ops/training.py:65 2019-01-16 14:48:20.167190: step 21715, loss = 0.64667 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:48:21.128185 ops/training.py:65 2019-01-16 14:48:21.128127: step 21716, loss = 0.21645 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:48:22.089172 ops/training.py:65 2019-01-16 14:48:22.089097: step 21717, loss = 0.08658 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:48:23.051007 ops/training.py:65 2019-01-16 14:48:23.050926: step 21718, loss = 0.06946 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:48:24.013457 ops/training.py:65 2019-01-16 14:48:24.013384: step 21719, loss = 0.11161 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:48:24.974991 ops/training.py:65 2019-01-16 14:48:24.974918: step 21720, loss = 0.27492 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:48:25.936229 ops/training.py:65 2019-01-16 14:48:25.936156: step 21721, loss = 0.33576 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:48:26.898953 ops/training.py:65 2019-01-16 14:48:26.898871: step 21722, loss = 0.22573 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:48:27.863514 ops/training.py:65 2019-01-16 14:48:27.863430: step 21723, loss = 0.21540 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:48:28.825098 ops/training.py:65 2019-01-16 14:48:28.825015: step 21724, loss = 0.21322 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:48:29.789110 ops/training.py:65 2019-01-16 14:48:29.789043: step 21725, loss = 0.08880 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:48:30.752590 ops/training.py:65 2019-01-16 14:48:30.752514: step 21726, loss = 0.17536 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:48:31.716041 ops/training.py:65 2019-01-16 14:48:31.715961: step 21727, loss = 0.21453 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:48:32.677663 ops/training.py:65 2019-01-16 14:48:32.677589: step 21728, loss = 0.20180 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:48:33.639697 ops/training.py:65 2019-01-16 14:48:33.639629: step 21729, loss = 0.21896 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:48:34.601372 ops/training.py:65 2019-01-16 14:48:34.601309: step 21730, loss = 0.25883 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:48:35.563253 ops/training.py:65 2019-01-16 14:48:35.563174: step 21731, loss = 0.19307 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:48:36.524547 ops/training.py:65 2019-01-16 14:48:36.524490: step 21732, loss = 0.17502 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:48:37.487382 ops/training.py:65 2019-01-16 14:48:37.487307: step 21733, loss = 0.31892 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:48:38.450535 ops/training.py:65 2019-01-16 14:48:38.450462: step 21734, loss = 0.15548 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:48:39.412900 ops/training.py:65 2019-01-16 14:48:39.412819: step 21735, loss = 0.14071 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:48:40.374125 ops/training.py:65 2019-01-16 14:48:40.374054: step 21736, loss = 0.14483 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:48:41.334958 ops/training.py:65 2019-01-16 14:48:41.334874: step 21737, loss = 0.17498 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:48:42.299317 ops/training.py:65 2019-01-16 14:48:42.299241: step 21738, loss = 0.11539 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:48:43.263846 ops/training.py:65 2019-01-16 14:48:43.263773: step 21739, loss = 0.23699 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:48:44.226791 ops/training.py:65 2019-01-16 14:48:44.226709: step 21740, loss = 0.32768 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:48:45.187530 ops/training.py:65 2019-01-16 14:48:45.187454: step 21741, loss = 0.18394 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:48:46.149672 ops/training.py:65 2019-01-16 14:48:46.149592: step 21742, loss = 0.24982 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:48:47.112521 ops/training.py:65 2019-01-16 14:48:47.112459: step 21743, loss = 0.14765 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:48:48.075050 ops/training.py:65 2019-01-16 14:48:48.074980: step 21744, loss = 0.30373 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:48:49.037396 ops/training.py:65 2019-01-16 14:48:49.037337: step 21745, loss = 0.20349 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:48:50.001733 ops/training.py:65 2019-01-16 14:48:50.001655: step 21746, loss = 0.32551 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:48:50.963824 ops/training.py:65 2019-01-16 14:48:50.963762: step 21747, loss = 0.24836 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:48:51.926900 ops/training.py:65 2019-01-16 14:48:51.926832: step 21748, loss = 0.27224 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:48:52.889664 ops/training.py:65 2019-01-16 14:48:52.889583: step 21749, loss = 0.13950 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:48:53.852684 ops/training.py:65 2019-01-16 14:48:53.852609: step 21750, loss = 0.17637 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:48:54.814938 ops/training.py:65 2019-01-16 14:48:54.814856: step 21751, loss = 0.10374 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:48:55.777979 ops/training.py:65 2019-01-16 14:48:55.777905: step 21752, loss = 0.29837 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:48:56.739364 ops/training.py:65 2019-01-16 14:48:56.739279: step 21753, loss = 0.40120 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:48:57.700114 ops/training.py:65 2019-01-16 14:48:57.700033: step 21754, loss = 0.15767 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:48:58.661362 ops/training.py:65 2019-01-16 14:48:58.661285: step 21755, loss = 0.15144 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:48:59.625209 ops/training.py:65 2019-01-16 14:48:59.625135: step 21756, loss = 0.19662 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:49:00.587461 ops/training.py:65 2019-01-16 14:49:00.587389: step 21757, loss = 0.20366 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:49:01.550282 ops/training.py:65 2019-01-16 14:49:01.550216: step 21758, loss = 0.19173 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:49:02.513548 ops/training.py:65 2019-01-16 14:49:02.513472: step 21759, loss = 0.15974 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:49:03.475306 ops/training.py:65 2019-01-16 14:49:03.475233: step 21760, loss = 0.18135 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:49:04.437086 ops/training.py:65 2019-01-16 14:49:04.437025: step 21761, loss = 0.23064 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:49:05.398056 ops/training.py:65 2019-01-16 14:49:05.397979: step 21762, loss = 0.36402 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:49:06.359217 ops/training.py:65 2019-01-16 14:49:06.359156: step 21763, loss = 0.11358 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:49:07.321816 ops/training.py:65 2019-01-16 14:49:07.321741: step 21764, loss = 0.17293 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:49:08.284364 ops/training.py:65 2019-01-16 14:49:08.284293: step 21765, loss = 0.16596 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:49:09.245745 ops/training.py:65 2019-01-16 14:49:09.245662: step 21766, loss = 0.31848 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:49:10.207035 ops/training.py:65 2019-01-16 14:49:10.206965: step 21767, loss = 0.36917 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:49:11.170023 ops/training.py:65 2019-01-16 14:49:11.169937: step 21768, loss = 0.14908 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:49:12.133157 ops/training.py:65 2019-01-16 14:49:12.133082: step 21769, loss = 0.20198 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:49:13.097377 ops/training.py:65 2019-01-16 14:49:13.097291: step 21770, loss = 0.28408 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:49:14.060216 ops/training.py:65 2019-01-16 14:49:14.060134: step 21771, loss = 0.10683 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:49:15.021657 ops/training.py:65 2019-01-16 14:49:15.021577: step 21772, loss = 0.19090 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:49:15.983595 ops/training.py:65 2019-01-16 14:49:15.983524: step 21773, loss = 0.18360 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:49:16.944320 ops/training.py:65 2019-01-16 14:49:16.944262: step 21774, loss = 0.26988 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:49:17.903726 ops/training.py:65 2019-01-16 14:49:17.903662: step 21775, loss = 0.13607 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:49:18.866320 ops/training.py:65 2019-01-16 14:49:18.866238: step 21776, loss = 0.19151 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:49:19.830847 ops/training.py:65 2019-01-16 14:49:19.830803: step 21777, loss = 0.11047 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:49:20.792858 ops/training.py:65 2019-01-16 14:49:20.792802: step 21778, loss = 0.17962 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:49:21.756289 ops/training.py:65 2019-01-16 14:49:21.756240: step 21779, loss = 0.17094 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:49:22.720567 ops/training.py:65 2019-01-16 14:49:22.720488: step 21780, loss = 0.16275 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:49:23.683261 ops/training.py:65 2019-01-16 14:49:23.683184: step 21781, loss = 0.28786 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:49:24.645369 ops/training.py:65 2019-01-16 14:49:24.645293: step 21782, loss = 0.11286 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:49:25.607585 ops/training.py:65 2019-01-16 14:49:25.607500: step 21783, loss = 0.18201 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:49:26.572619 ops/training.py:65 2019-01-16 14:49:26.572544: step 21784, loss = 0.25808 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:49:27.537098 ops/training.py:65 2019-01-16 14:49:27.537024: step 21785, loss = 0.20932 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:49:28.500069 ops/training.py:65 2019-01-16 14:49:28.499988: step 21786, loss = 0.10413 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:49:29.464277 ops/training.py:65 2019-01-16 14:49:29.464198: step 21787, loss = 0.14596 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:49:30.425903 ops/training.py:65 2019-01-16 14:49:30.425832: step 21788, loss = 0.27210 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:49:31.387750 ops/training.py:65 2019-01-16 14:49:31.387669: step 21789, loss = 0.18394 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:49:32.351485 ops/training.py:65 2019-01-16 14:49:32.351410: step 21790, loss = 0.25288 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:49:33.314916 ops/training.py:65 2019-01-16 14:49:33.314841: step 21791, loss = 0.17728 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:49:34.276134 ops/training.py:65 2019-01-16 14:49:34.276063: step 21792, loss = 0.13061 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:49:35.236842 ops/training.py:65 2019-01-16 14:49:35.236777: step 21793, loss = 0.18027 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:49:36.197911 ops/training.py:65 2019-01-16 14:49:36.197848: step 21794, loss = 0.16184 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:49:37.157296 ops/training.py:65 2019-01-16 14:49:37.157221: step 21795, loss = 0.16065 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:49:38.117916 ops/training.py:65 2019-01-16 14:49:38.117857: step 21796, loss = 0.07467 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:49:39.077102 ops/training.py:65 2019-01-16 14:49:39.077040: step 21797, loss = 0.19754 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:49:40.040723 ops/training.py:65 2019-01-16 14:49:40.040661: step 21798, loss = 0.16663 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:49:41.003402 ops/training.py:65 2019-01-16 14:49:41.003329: step 21799, loss = 0.18554 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:49:41.964136 ops/training.py:65 2019-01-16 14:49:41.964058: step 21800, loss = 0.09824 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:49:42.924953 ops/training.py:65 2019-01-16 14:49:42.924874: step 21801, loss = 0.21066 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:49:43.885712 ops/training.py:65 2019-01-16 14:49:43.885639: step 21802, loss = 0.19970 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:49:44.846938 ops/training.py:65 2019-01-16 14:49:44.846862: step 21803, loss = 0.25276 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:49:45.808719 ops/training.py:65 2019-01-16 14:49:45.808643: step 21804, loss = 0.19179 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:49:46.770294 ops/training.py:65 2019-01-16 14:49:46.770214: step 21805, loss = 0.11195 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:49:47.732213 ops/training.py:65 2019-01-16 14:49:47.732145: step 21806, loss = 0.19138 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:49:48.692989 ops/training.py:65 2019-01-16 14:49:48.692915: step 21807, loss = 0.19566 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:49:49.654421 ops/training.py:65 2019-01-16 14:49:49.654343: step 21808, loss = 0.29107 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:49:50.617473 ops/training.py:65 2019-01-16 14:49:50.617393: step 21809, loss = 0.24620 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:49:51.579758 ops/training.py:65 2019-01-16 14:49:51.579679: step 21810, loss = 0.06117 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:49:52.540986 ops/training.py:65 2019-01-16 14:49:52.540928: step 21811, loss = 0.06433 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:49:53.502725 ops/training.py:65 2019-01-16 14:49:53.502670: step 21812, loss = 0.21999 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:49:54.463362 ops/training.py:65 2019-01-16 14:49:54.463299: step 21813, loss = 0.33031 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:49:55.424336 ops/training.py:65 2019-01-16 14:49:55.424273: step 21814, loss = 0.17643 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:49:56.386433 ops/training.py:65 2019-01-16 14:49:56.386376: step 21815, loss = 0.42265 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:49:57.350752 ops/training.py:65 2019-01-16 14:49:57.350693: step 21816, loss = 0.14977 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:49:58.312559 ops/training.py:65 2019-01-16 14:49:58.312481: step 21817, loss = 0.18222 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:49:59.278632 ops/training.py:65 2019-01-16 14:49:59.278550: step 21818, loss = 0.28125 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:50:00.241040 ops/training.py:65 2019-01-16 14:50:00.240968: step 21819, loss = 0.13917 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:50:01.203461 ops/training.py:65 2019-01-16 14:50:01.203385: step 21820, loss = 0.25887 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:50:02.164471 ops/training.py:65 2019-01-16 14:50:02.164403: step 21821, loss = 0.15070 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:50:03.126112 ops/training.py:65 2019-01-16 14:50:03.126024: step 21822, loss = 0.29351 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:50:04.087049 ops/training.py:65 2019-01-16 14:50:04.086988: step 21823, loss = 0.20418 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:50:05.047537 ops/training.py:65 2019-01-16 14:50:05.047489: step 21824, loss = 0.12213 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:50:06.006692 ops/training.py:65 2019-01-16 14:50:06.006631: step 21825, loss = 0.17613 (33.4 examples/sec; 0.958 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:50:06.966644 ops/training.py:65 2019-01-16 14:50:06.966589: step 21826, loss = 0.24272 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:50:07.926840 ops/training.py:65 2019-01-16 14:50:07.926780: step 21827, loss = 0.14530 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:50:08.890697 ops/training.py:65 2019-01-16 14:50:08.890641: step 21828, loss = 0.29501 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:50:09.853816 ops/training.py:65 2019-01-16 14:50:09.853738: step 21829, loss = 0.28858 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:50:10.816409 ops/training.py:65 2019-01-16 14:50:10.816335: step 21830, loss = 0.24863 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:50:11.777794 ops/training.py:65 2019-01-16 14:50:11.777709: step 21831, loss = 0.25918 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:50:12.739813 ops/training.py:65 2019-01-16 14:50:12.739736: step 21832, loss = 0.20078 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:50:13.700825 ops/training.py:65 2019-01-16 14:50:13.700747: step 21833, loss = 0.30064 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:50:14.662378 ops/training.py:65 2019-01-16 14:50:14.662303: step 21834, loss = 0.16084 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:50:15.624250 ops/training.py:65 2019-01-16 14:50:15.624165: step 21835, loss = 0.21000 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:50:16.587512 ops/training.py:65 2019-01-16 14:50:16.587435: step 21836, loss = 0.38143 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:50:17.551183 ops/training.py:65 2019-01-16 14:50:17.551116: step 21837, loss = 0.35585 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:50:18.514874 ops/training.py:65 2019-01-16 14:50:18.514802: step 21838, loss = 0.27712 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:50:19.477681 ops/training.py:65 2019-01-16 14:50:19.477608: step 21839, loss = 0.18090 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:50:20.439473 ops/training.py:65 2019-01-16 14:50:20.439407: step 21840, loss = 0.17107 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:50:21.400685 ops/training.py:65 2019-01-16 14:50:21.400623: step 21841, loss = 0.38174 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:50:22.362064 ops/training.py:65 2019-01-16 14:50:22.362001: step 21842, loss = 0.14772 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:50:23.324400 ops/training.py:65 2019-01-16 14:50:23.324342: step 21843, loss = 0.09585 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:50:24.287138 ops/training.py:65 2019-01-16 14:50:24.287061: step 21844, loss = 0.27131 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:50:25.248644 ops/training.py:65 2019-01-16 14:50:25.248571: step 21845, loss = 0.20769 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:50:26.209186 ops/training.py:65 2019-01-16 14:50:26.209107: step 21846, loss = 0.20707 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:50:27.169957 ops/training.py:65 2019-01-16 14:50:27.169880: step 21847, loss = 0.27745 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:50:28.131843 ops/training.py:65 2019-01-16 14:50:28.131758: step 21848, loss = 0.13357 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:50:29.093782 ops/training.py:65 2019-01-16 14:50:29.093696: step 21849, loss = 0.27177 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:50:30.057478 ops/training.py:65 2019-01-16 14:50:30.057409: step 21850, loss = 0.16694 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:50:31.020798 ops/training.py:65 2019-01-16 14:50:31.020721: step 21851, loss = 0.15268 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:50:31.984099 ops/training.py:65 2019-01-16 14:50:31.984023: step 21852, loss = 0.07884 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:50:32.946176 ops/training.py:65 2019-01-16 14:50:32.946091: step 21853, loss = 0.08710 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:50:33.907436 ops/training.py:65 2019-01-16 14:50:33.907359: step 21854, loss = 0.23978 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:50:34.869082 ops/training.py:65 2019-01-16 14:50:34.869019: step 21855, loss = 0.27879 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:50:35.831065 ops/training.py:65 2019-01-16 14:50:35.831001: step 21856, loss = 0.13726 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:50:36.791747 ops/training.py:65 2019-01-16 14:50:36.791672: step 21857, loss = 0.08171 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:50:37.753813 ops/training.py:65 2019-01-16 14:50:37.753733: step 21858, loss = 0.35814 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:50:38.717878 ops/training.py:65 2019-01-16 14:50:38.717800: step 21859, loss = 0.18036 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:50:39.681387 ops/training.py:65 2019-01-16 14:50:39.681308: step 21860, loss = 0.12392 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:50:40.645559 ops/training.py:65 2019-01-16 14:50:40.645483: step 21861, loss = 0.14891 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:50:41.606707 ops/training.py:65 2019-01-16 14:50:41.606624: step 21862, loss = 0.38128 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:50:42.570889 ops/training.py:65 2019-01-16 14:50:42.570810: step 21863, loss = 0.25832 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:50:43.535045 ops/training.py:65 2019-01-16 14:50:43.534966: step 21864, loss = 0.15882 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:50:44.500280 ops/training.py:65 2019-01-16 14:50:44.500203: step 21865, loss = 0.12349 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:50:45.462949 ops/training.py:65 2019-01-16 14:50:45.462868: step 21866, loss = 0.11546 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:50:46.426013 ops/training.py:65 2019-01-16 14:50:46.425939: step 21867, loss = 0.24843 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:50:47.387355 ops/training.py:65 2019-01-16 14:50:47.387290: step 21868, loss = 0.16544 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:50:48.349241 ops/training.py:65 2019-01-16 14:50:48.349172: step 21869, loss = 0.21403 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:50:49.311263 ops/training.py:65 2019-01-16 14:50:49.311199: step 21870, loss = 0.17418 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:50:50.273202 ops/training.py:65 2019-01-16 14:50:50.273143: step 21871, loss = 0.21893 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:50:51.235777 ops/training.py:65 2019-01-16 14:50:51.235700: step 21872, loss = 0.19340 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:50:52.197511 ops/training.py:65 2019-01-16 14:50:52.197435: step 21873, loss = 0.14668 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:50:53.158384 ops/training.py:65 2019-01-16 14:50:53.158307: step 21874, loss = 0.26171 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:50:54.120606 ops/training.py:65 2019-01-16 14:50:54.120531: step 21875, loss = 0.21167 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:50:55.082221 ops/training.py:65 2019-01-16 14:50:55.082140: step 21876, loss = 0.18869 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:50:56.047375 ops/training.py:65 2019-01-16 14:50:56.047299: step 21877, loss = 0.24422 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:50:57.010914 ops/training.py:65 2019-01-16 14:50:57.010836: step 21878, loss = 0.24829 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:50:57.976085 ops/training.py:65 2019-01-16 14:50:57.976004: step 21879, loss = 0.09717 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:50:58.941185 ops/training.py:65 2019-01-16 14:50:58.941106: step 21880, loss = 0.16091 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:50:59.903633 ops/training.py:65 2019-01-16 14:50:59.903558: step 21881, loss = 0.19006 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:51:00.866421 ops/training.py:65 2019-01-16 14:51:00.866344: step 21882, loss = 0.24300 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:51:01.829389 ops/training.py:65 2019-01-16 14:51:01.829320: step 21883, loss = 0.31034 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:51:02.791140 ops/training.py:65 2019-01-16 14:51:02.791064: step 21884, loss = 0.15648 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:51:03.753698 ops/training.py:65 2019-01-16 14:51:03.753624: step 21885, loss = 0.18258 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:51:04.716091 ops/training.py:65 2019-01-16 14:51:04.716030: step 21886, loss = 0.18441 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:51:05.677966 ops/training.py:65 2019-01-16 14:51:05.677880: step 21887, loss = 0.23881 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:51:06.639950 ops/training.py:65 2019-01-16 14:51:06.639852: step 21888, loss = 0.13698 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:51:07.601969 ops/training.py:65 2019-01-16 14:51:07.601869: step 21889, loss = 0.34383 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:51:08.563925 ops/training.py:65 2019-01-16 14:51:08.563830: step 21890, loss = 0.30564 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:51:09.525594 ops/training.py:65 2019-01-16 14:51:09.525501: step 21891, loss = 0.08992 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:51:10.488851 ops/training.py:65 2019-01-16 14:51:10.488756: step 21892, loss = 0.22663 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:51:11.451056 ops/training.py:65 2019-01-16 14:51:11.450960: step 21893, loss = 0.16303 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:51:12.414827 ops/training.py:65 2019-01-16 14:51:12.414758: step 21894, loss = 0.20863 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:51:13.378646 ops/training.py:65 2019-01-16 14:51:13.378551: step 21895, loss = 0.31418 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:51:14.341418 ops/training.py:65 2019-01-16 14:51:14.341320: step 21896, loss = 0.12617 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:51:15.302923 ops/training.py:65 2019-01-16 14:51:15.302826: step 21897, loss = 0.40506 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:51:16.265207 ops/training.py:65 2019-01-16 14:51:16.265115: step 21898, loss = 0.23624 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:51:17.225946 ops/training.py:65 2019-01-16 14:51:17.225878: step 21899, loss = 0.28534 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:51:18.189250 ops/training.py:65 2019-01-16 14:51:18.189173: step 21900, loss = 0.20510 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:51:19.152184 ops/training.py:65 2019-01-16 14:51:19.152112: step 21901, loss = 0.13723 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:51:20.113444 ops/training.py:65 2019-01-16 14:51:20.113361: step 21902, loss = 0.13828 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:51:21.073606 ops/training.py:65 2019-01-16 14:51:21.073526: step 21903, loss = 0.17307 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:51:22.033240 ops/training.py:65 2019-01-16 14:51:22.033156: step 21904, loss = 0.14874 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:51:22.998443 ops/training.py:65 2019-01-16 14:51:22.998360: step 21905, loss = 0.11521 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:51:23.961418 ops/training.py:65 2019-01-16 14:51:23.961323: step 21906, loss = 0.13111 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:51:24.923274 ops/training.py:65 2019-01-16 14:51:24.923182: step 21907, loss = 0.20121 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:51:25.883582 ops/training.py:65 2019-01-16 14:51:25.883487: step 21908, loss = 0.13298 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:51:26.849222 ops/training.py:65 2019-01-16 14:51:26.849127: step 21909, loss = 0.11967 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:51:27.814433 ops/training.py:65 2019-01-16 14:51:27.814335: step 21910, loss = 0.13413 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:51:28.777894 ops/training.py:65 2019-01-16 14:51:28.777794: step 21911, loss = 0.12883 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:51:29.739127 ops/training.py:65 2019-01-16 14:51:29.739037: step 21912, loss = 0.13485 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:51:30.700340 ops/training.py:65 2019-01-16 14:51:30.700243: step 21913, loss = 0.10580 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:51:31.661514 ops/training.py:65 2019-01-16 14:51:31.661432: step 21914, loss = 0.14391 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:51:32.622839 ops/training.py:65 2019-01-16 14:51:32.622753: step 21915, loss = 0.19381 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:51:33.585086 ops/training.py:65 2019-01-16 14:51:33.584994: step 21916, loss = 0.16742 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:51:34.547001 ops/training.py:65 2019-01-16 14:51:34.546927: step 21917, loss = 0.10222 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:51:35.509005 ops/training.py:65 2019-01-16 14:51:35.508926: step 21918, loss = 0.11835 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:51:36.471119 ops/training.py:65 2019-01-16 14:51:36.471023: step 21919, loss = 0.16613 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:51:37.432855 ops/training.py:65 2019-01-16 14:51:37.432760: step 21920, loss = 0.13302 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:51:38.394525 ops/training.py:65 2019-01-16 14:51:38.394436: step 21921, loss = 0.08491 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:51:39.356978 ops/training.py:65 2019-01-16 14:51:39.356879: step 21922, loss = 0.11739 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:51:40.321117 ops/training.py:65 2019-01-16 14:51:40.321024: step 21923, loss = 0.21226 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:51:41.285088 ops/training.py:65 2019-01-16 14:51:41.284990: step 21924, loss = 0.09273 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:51:42.248262 ops/training.py:65 2019-01-16 14:51:42.248170: step 21925, loss = 0.19222 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:51:43.212233 ops/training.py:65 2019-01-16 14:51:43.212130: step 21926, loss = 0.11775 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:51:44.176575 ops/training.py:65 2019-01-16 14:51:44.176475: step 21927, loss = 0.28172 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:51:45.139606 ops/training.py:65 2019-01-16 14:51:45.139511: step 21928, loss = 0.20610 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:51:46.101404 ops/training.py:65 2019-01-16 14:51:46.101340: step 21929, loss = 0.26138 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:51:47.061158 ops/training.py:65 2019-01-16 14:51:47.061096: step 21930, loss = 0.18195 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:51:48.024710 ops/training.py:65 2019-01-16 14:51:48.024638: step 21931, loss = 0.31454 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:51:48.988219 ops/training.py:65 2019-01-16 14:51:48.988129: step 21932, loss = 0.19245 (33.2 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:51:49.953280 ops/training.py:65 2019-01-16 14:51:49.953184: step 21933, loss = 0.17917 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:51:50.916343 ops/training.py:65 2019-01-16 14:51:50.916248: step 21934, loss = 0.13634 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:51:51.878789 ops/training.py:65 2019-01-16 14:51:51.878692: step 21935, loss = 0.14207 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:51:52.841376 ops/training.py:65 2019-01-16 14:51:52.841271: step 21936, loss = 0.24209 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:51:53.805506 ops/training.py:65 2019-01-16 14:51:53.805435: step 21937, loss = 0.17647 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:51:54.768837 ops/training.py:65 2019-01-16 14:51:54.768745: step 21938, loss = 0.15313 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:51:55.732004 ops/training.py:65 2019-01-16 14:51:55.731910: step 21939, loss = 0.24246 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:51:56.693804 ops/training.py:65 2019-01-16 14:51:56.693707: step 21940, loss = 0.23900 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:51:57.656209 ops/training.py:65 2019-01-16 14:51:57.656113: step 21941, loss = 0.10905 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:51:58.618383 ops/training.py:65 2019-01-16 14:51:58.618291: step 21942, loss = 0.22880 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:51:59.580268 ops/training.py:65 2019-01-16 14:51:59.580172: step 21943, loss = 0.22500 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:52:00.542210 ops/training.py:65 2019-01-16 14:52:00.542117: step 21944, loss = 0.31530 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:52:01.504641 ops/training.py:65 2019-01-16 14:52:01.504565: step 21945, loss = 0.13120 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:52:02.466919 ops/training.py:65 2019-01-16 14:52:02.466825: step 21946, loss = 0.11688 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:52:03.430291 ops/training.py:65 2019-01-16 14:52:03.430192: step 21947, loss = 0.12457 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:52:04.392691 ops/training.py:65 2019-01-16 14:52:04.392604: step 21948, loss = 0.21523 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:52:05.357848 ops/training.py:65 2019-01-16 14:52:05.357768: step 21949, loss = 0.17725 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:52:06.321364 ops/training.py:65 2019-01-16 14:52:06.321243: step 21950, loss = 0.22303 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:52:07.284098 ops/training.py:65 2019-01-16 14:52:07.284006: step 21951, loss = 0.16791 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:52:08.246597 ops/training.py:65 2019-01-16 14:52:08.246503: step 21952, loss = 0.09530 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:52:09.211835 ops/training.py:65 2019-01-16 14:52:09.211736: step 21953, loss = 0.16871 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:52:10.174529 ops/training.py:65 2019-01-16 14:52:10.174441: step 21954, loss = 0.21635 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:52:11.137845 ops/training.py:65 2019-01-16 14:52:11.137753: step 21955, loss = 0.09652 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:52:12.099502 ops/training.py:65 2019-01-16 14:52:12.099408: step 21956, loss = 0.12216 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:52:13.061996 ops/training.py:65 2019-01-16 14:52:13.061897: step 21957, loss = 0.24511 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:52:14.025121 ops/training.py:65 2019-01-16 14:52:14.025022: step 21958, loss = 0.17756 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:52:14.988053 ops/training.py:65 2019-01-16 14:52:14.987958: step 21959, loss = 0.25798 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:52:15.951536 ops/training.py:65 2019-01-16 14:52:15.951472: step 21960, loss = 0.18921 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:52:16.914547 ops/training.py:65 2019-01-16 14:52:16.914449: step 21961, loss = 0.20737 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:52:17.876925 ops/training.py:65 2019-01-16 14:52:17.876854: step 21962, loss = 0.09911 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:52:18.838463 ops/training.py:65 2019-01-16 14:52:18.838383: step 21963, loss = 0.16117 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:52:19.800695 ops/training.py:65 2019-01-16 14:52:19.800614: step 21964, loss = 0.16666 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:52:20.761516 ops/training.py:65 2019-01-16 14:52:20.761440: step 21965, loss = 0.14894 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:52:21.723295 ops/training.py:65 2019-01-16 14:52:21.723197: step 21966, loss = 0.21583 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:52:22.684200 ops/training.py:65 2019-01-16 14:52:22.684105: step 21967, loss = 0.27364 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:52:23.645408 ops/training.py:65 2019-01-16 14:52:23.645312: step 21968, loss = 0.12733 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:52:24.607726 ops/training.py:65 2019-01-16 14:52:24.607630: step 21969, loss = 0.20151 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:52:25.573385 ops/training.py:65 2019-01-16 14:52:25.573289: step 21970, loss = 0.14558 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:52:26.535299 ops/training.py:65 2019-01-16 14:52:26.535195: step 21971, loss = 0.15762 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:52:27.500864 ops/training.py:65 2019-01-16 14:52:27.500768: step 21972, loss = 0.12022 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:52:28.464269 ops/training.py:65 2019-01-16 14:52:28.464170: step 21973, loss = 0.23494 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:52:29.428322 ops/training.py:65 2019-01-16 14:52:29.428223: step 21974, loss = 0.12897 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:52:30.391372 ops/training.py:65 2019-01-16 14:52:30.391273: step 21975, loss = 0.37342 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:52:31.354510 ops/training.py:65 2019-01-16 14:52:31.354407: step 21976, loss = 0.20152 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:52:32.319706 ops/training.py:65 2019-01-16 14:52:32.319610: step 21977, loss = 0.18667 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:52:33.284457 ops/training.py:65 2019-01-16 14:52:33.284359: step 21978, loss = 0.22078 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:52:34.249059 ops/training.py:65 2019-01-16 14:52:34.248981: step 21979, loss = 0.18536 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:52:35.212987 ops/training.py:65 2019-01-16 14:52:35.212925: step 21980, loss = 0.23424 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:52:36.175793 ops/training.py:65 2019-01-16 14:52:36.175700: step 21981, loss = 0.25783 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:52:37.138931 ops/training.py:65 2019-01-16 14:52:37.138844: step 21982, loss = 0.28067 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:52:38.102868 ops/training.py:65 2019-01-16 14:52:38.102740: step 21983, loss = 0.12127 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:52:39.066278 ops/training.py:65 2019-01-16 14:52:39.066215: step 21984, loss = 0.26527 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:52:40.028610 ops/training.py:65 2019-01-16 14:52:40.028517: step 21985, loss = 0.14236 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:52:40.990946 ops/training.py:65 2019-01-16 14:52:40.990850: step 21986, loss = 0.11124 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:52:41.953887 ops/training.py:65 2019-01-16 14:52:41.953797: step 21987, loss = 0.16403 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:52:42.915902 ops/training.py:65 2019-01-16 14:52:42.915799: step 21988, loss = 0.24107 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:52:43.880753 ops/training.py:65 2019-01-16 14:52:43.880658: step 21989, loss = 0.36455 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:52:44.844488 ops/training.py:65 2019-01-16 14:52:44.844390: step 21990, loss = 0.11801 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:52:45.808523 ops/training.py:65 2019-01-16 14:52:45.808426: step 21991, loss = 0.40646 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.75
I0832 2019-01-16 14:52:46.770626 ops/training.py:65 2019-01-16 14:52:46.770530: step 21992, loss = 0.15189 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:52:47.732179 ops/training.py:65 2019-01-16 14:52:47.732093: step 21993, loss = 0.25047 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:52:48.695206 ops/training.py:65 2019-01-16 14:52:48.695128: step 21994, loss = 0.25679 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:52:49.658216 ops/training.py:65 2019-01-16 14:52:49.658129: step 21995, loss = 0.15138 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:52:50.621924 ops/training.py:65 2019-01-16 14:52:50.621854: step 21996, loss = 0.16690 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:52:51.586193 ops/training.py:65 2019-01-16 14:52:51.586094: step 21997, loss = 0.19371 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:52:52.548372 ops/training.py:65 2019-01-16 14:52:52.548274: step 21998, loss = 0.21463 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:52:53.511215 ops/training.py:65 2019-01-16 14:52:53.511081: step 21999, loss = 0.33151 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:57:32.257228 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I0832 2019-01-16 14:57:32.258175 ops/training.py:41 2019-01-16 14:57:32.258120: step 22000, loss = 0.09 (0.1 examples/sec; 277.784 sec/batch) | Training accuracy = 0.96875 | Validation accuracy = 0.67165 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_08_07_39_512188
I0832 2019-01-16 14:57:33.222256 ops/training.py:65 2019-01-16 14:57:33.222213: step 22001, loss = 0.15415 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:57:34.184112 ops/training.py:65 2019-01-16 14:57:34.184014: step 22002, loss = 0.15528 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:57:35.146894 ops/training.py:65 2019-01-16 14:57:35.146804: step 22003, loss = 0.22828 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:57:36.109119 ops/training.py:65 2019-01-16 14:57:36.109033: step 22004, loss = 0.14670 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:57:37.069686 ops/training.py:65 2019-01-16 14:57:37.069595: step 22005, loss = 0.15537 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:57:38.031836 ops/training.py:65 2019-01-16 14:57:38.031737: step 22006, loss = 0.21310 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:57:38.992438 ops/training.py:65 2019-01-16 14:57:38.992343: step 22007, loss = 0.31716 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:57:39.954417 ops/training.py:65 2019-01-16 14:57:39.954332: step 22008, loss = 0.16198 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:57:40.916015 ops/training.py:65 2019-01-16 14:57:40.915927: step 22009, loss = 0.21825 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:57:41.877615 ops/training.py:65 2019-01-16 14:57:41.877515: step 22010, loss = 0.13970 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:57:42.839752 ops/training.py:65 2019-01-16 14:57:42.839653: step 22011, loss = 0.09062 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:57:43.800912 ops/training.py:65 2019-01-16 14:57:43.800813: step 22012, loss = 0.12248 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:57:44.762631 ops/training.py:65 2019-01-16 14:57:44.762530: step 22013, loss = 0.14539 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:57:45.724505 ops/training.py:65 2019-01-16 14:57:45.724405: step 22014, loss = 0.15819 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:57:46.686029 ops/training.py:65 2019-01-16 14:57:46.685935: step 22015, loss = 0.10344 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:57:47.647103 ops/training.py:65 2019-01-16 14:57:47.647002: step 22016, loss = 0.19458 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:57:48.612326 ops/training.py:65 2019-01-16 14:57:48.612238: step 22017, loss = 0.08863 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:57:49.577487 ops/training.py:65 2019-01-16 14:57:49.577410: step 22018, loss = 0.22625 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:57:50.539701 ops/training.py:65 2019-01-16 14:57:50.539596: step 22019, loss = 0.10807 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:57:51.504836 ops/training.py:65 2019-01-16 14:57:51.504748: step 22020, loss = 0.43559 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.78125
I0832 2019-01-16 14:57:52.470222 ops/training.py:65 2019-01-16 14:57:52.470140: step 22021, loss = 0.28544 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:57:53.432645 ops/training.py:65 2019-01-16 14:57:53.432567: step 22022, loss = 0.18879 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:57:54.397228 ops/training.py:65 2019-01-16 14:57:54.397129: step 22023, loss = 0.13438 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:57:55.360110 ops/training.py:65 2019-01-16 14:57:55.360010: step 22024, loss = 0.12835 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:57:56.322202 ops/training.py:65 2019-01-16 14:57:56.322114: step 22025, loss = 0.09442 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:57:57.284103 ops/training.py:65 2019-01-16 14:57:57.284029: step 22026, loss = 0.15397 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:57:58.247264 ops/training.py:65 2019-01-16 14:57:58.247190: step 22027, loss = 0.21316 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:57:59.209256 ops/training.py:65 2019-01-16 14:57:59.209164: step 22028, loss = 0.10692 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:58:00.170643 ops/training.py:65 2019-01-16 14:58:00.170555: step 22029, loss = 0.18401 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:58:01.131324 ops/training.py:65 2019-01-16 14:58:01.131228: step 22030, loss = 0.15743 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:58:02.091779 ops/training.py:65 2019-01-16 14:58:02.091689: step 22031, loss = 0.12296 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:58:03.052675 ops/training.py:65 2019-01-16 14:58:03.052579: step 22032, loss = 0.33745 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:58:04.013989 ops/training.py:65 2019-01-16 14:58:04.013894: step 22033, loss = 0.14055 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:58:04.975192 ops/training.py:65 2019-01-16 14:58:04.975113: step 22034, loss = 0.14920 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:58:05.936522 ops/training.py:65 2019-01-16 14:58:05.936457: step 22035, loss = 0.15806 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:58:06.898618 ops/training.py:65 2019-01-16 14:58:06.898522: step 22036, loss = 0.21420 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:58:07.860717 ops/training.py:65 2019-01-16 14:58:07.860615: step 22037, loss = 0.07809 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:58:08.822195 ops/training.py:65 2019-01-16 14:58:08.822106: step 22038, loss = 0.13631 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:58:09.783758 ops/training.py:65 2019-01-16 14:58:09.783676: step 22039, loss = 0.12916 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:58:10.745507 ops/training.py:65 2019-01-16 14:58:10.745413: step 22040, loss = 0.24623 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:58:11.707017 ops/training.py:65 2019-01-16 14:58:11.706920: step 22041, loss = 0.27755 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:58:12.669061 ops/training.py:65 2019-01-16 14:58:12.668965: step 22042, loss = 0.15227 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:58:13.631729 ops/training.py:65 2019-01-16 14:58:13.631632: step 22043, loss = 0.11143 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:58:14.593095 ops/training.py:65 2019-01-16 14:58:14.592998: step 22044, loss = 0.22381 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:58:15.555833 ops/training.py:65 2019-01-16 14:58:15.555730: step 22045, loss = 0.27508 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:58:16.518502 ops/training.py:65 2019-01-16 14:58:16.518401: step 22046, loss = 0.22181 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:58:17.481525 ops/training.py:65 2019-01-16 14:58:17.481449: step 22047, loss = 0.08631 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:58:18.442809 ops/training.py:65 2019-01-16 14:58:18.442714: step 22048, loss = 0.28550 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:58:19.405251 ops/training.py:65 2019-01-16 14:58:19.405146: step 22049, loss = 0.20259 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:58:20.367389 ops/training.py:65 2019-01-16 14:58:20.367292: step 22050, loss = 0.10721 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:58:21.332180 ops/training.py:65 2019-01-16 14:58:21.332120: step 22051, loss = 0.14513 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:58:22.295503 ops/training.py:65 2019-01-16 14:58:22.295410: step 22052, loss = 0.16495 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:58:23.259485 ops/training.py:65 2019-01-16 14:58:23.259384: step 22053, loss = 0.16856 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:58:24.222025 ops/training.py:65 2019-01-16 14:58:24.221923: step 22054, loss = 0.23258 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:58:25.183421 ops/training.py:65 2019-01-16 14:58:25.183318: step 22055, loss = 0.14671 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:58:26.144758 ops/training.py:65 2019-01-16 14:58:26.144655: step 22056, loss = 0.17315 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:58:27.108574 ops/training.py:65 2019-01-16 14:58:27.108493: step 22057, loss = 0.13025 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:58:28.071327 ops/training.py:65 2019-01-16 14:58:28.071238: step 22058, loss = 0.15916 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:58:29.036053 ops/training.py:65 2019-01-16 14:58:29.035955: step 22059, loss = 0.10495 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:58:29.998227 ops/training.py:65 2019-01-16 14:58:29.998138: step 22060, loss = 0.22891 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:58:30.960292 ops/training.py:65 2019-01-16 14:58:30.960191: step 22061, loss = 0.08210 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:58:31.922254 ops/training.py:65 2019-01-16 14:58:31.922153: step 22062, loss = 0.14349 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:58:32.884482 ops/training.py:65 2019-01-16 14:58:32.884380: step 22063, loss = 0.14498 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:58:33.845699 ops/training.py:65 2019-01-16 14:58:33.845600: step 22064, loss = 0.22497 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:58:34.807396 ops/training.py:65 2019-01-16 14:58:34.807315: step 22065, loss = 0.22279 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:58:35.769326 ops/training.py:65 2019-01-16 14:58:35.769264: step 22066, loss = 0.15185 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:58:36.730410 ops/training.py:65 2019-01-16 14:58:36.730311: step 22067, loss = 0.25634 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:58:37.691703 ops/training.py:65 2019-01-16 14:58:37.691599: step 22068, loss = 0.10404 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:58:38.653614 ops/training.py:65 2019-01-16 14:58:38.653513: step 22069, loss = 0.10042 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:58:39.615131 ops/training.py:65 2019-01-16 14:58:39.615031: step 22070, loss = 0.23146 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:58:40.577363 ops/training.py:65 2019-01-16 14:58:40.577274: step 22071, loss = 0.06280 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:58:41.540139 ops/training.py:65 2019-01-16 14:58:41.540040: step 22072, loss = 0.11949 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:58:42.501818 ops/training.py:65 2019-01-16 14:58:42.501719: step 22073, loss = 0.09239 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:58:43.463926 ops/training.py:65 2019-01-16 14:58:43.463826: step 22074, loss = 0.22632 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:58:44.426030 ops/training.py:65 2019-01-16 14:58:44.425926: step 22075, loss = 0.13425 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:58:45.388684 ops/training.py:65 2019-01-16 14:58:45.388577: step 22076, loss = 0.17831 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:58:46.352181 ops/training.py:65 2019-01-16 14:58:46.352117: step 22077, loss = 0.19512 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:58:47.315378 ops/training.py:65 2019-01-16 14:58:47.315300: step 22078, loss = 0.22378 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:58:48.276649 ops/training.py:65 2019-01-16 14:58:48.276579: step 22079, loss = 0.17425 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:58:49.238241 ops/training.py:65 2019-01-16 14:58:49.238148: step 22080, loss = 0.20456 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:58:50.199094 ops/training.py:65 2019-01-16 14:58:50.199017: step 22081, loss = 0.15027 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:58:51.160443 ops/training.py:65 2019-01-16 14:58:51.160363: step 22082, loss = 0.16518 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:58:52.121698 ops/training.py:65 2019-01-16 14:58:52.121600: step 22083, loss = 0.15896 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:58:53.083894 ops/training.py:65 2019-01-16 14:58:53.083794: step 22084, loss = 0.26862 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:58:54.045848 ops/training.py:65 2019-01-16 14:58:54.045748: step 22085, loss = 0.13671 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:58:55.007901 ops/training.py:65 2019-01-16 14:58:55.007806: step 22086, loss = 0.21724 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:58:55.970891 ops/training.py:65 2019-01-16 14:58:55.970789: step 22087, loss = 0.28272 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:58:56.932850 ops/training.py:65 2019-01-16 14:58:56.932744: step 22088, loss = 0.14454 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:58:57.895720 ops/training.py:65 2019-01-16 14:58:57.895619: step 22089, loss = 0.11422 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:58:58.859017 ops/training.py:65 2019-01-16 14:58:58.858916: step 22090, loss = 0.21032 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:58:59.822389 ops/training.py:65 2019-01-16 14:58:59.822295: step 22091, loss = 0.23737 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:59:00.783674 ops/training.py:65 2019-01-16 14:59:00.783575: step 22092, loss = 0.14639 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:59:01.745203 ops/training.py:65 2019-01-16 14:59:01.745109: step 22093, loss = 0.38605 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 14:59:02.707038 ops/training.py:65 2019-01-16 14:59:02.706941: step 22094, loss = 0.23916 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:59:03.668971 ops/training.py:65 2019-01-16 14:59:03.668876: step 22095, loss = 0.13054 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:59:04.631199 ops/training.py:65 2019-01-16 14:59:04.631111: step 22096, loss = 0.18177 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:59:05.593961 ops/training.py:65 2019-01-16 14:59:05.593890: step 22097, loss = 0.14823 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:59:06.556473 ops/training.py:65 2019-01-16 14:59:06.556395: step 22098, loss = 0.26607 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:59:07.518440 ops/training.py:65 2019-01-16 14:59:07.518347: step 22099, loss = 0.32368 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:59:08.481260 ops/training.py:65 2019-01-16 14:59:08.481160: step 22100, loss = 0.15246 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:59:09.446650 ops/training.py:65 2019-01-16 14:59:09.446569: step 22101, loss = 0.31367 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:59:10.410382 ops/training.py:65 2019-01-16 14:59:10.410302: step 22102, loss = 0.18083 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:59:11.372257 ops/training.py:65 2019-01-16 14:59:11.372178: step 22103, loss = 0.17651 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:59:12.333606 ops/training.py:65 2019-01-16 14:59:12.333512: step 22104, loss = 0.23393 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:59:13.295669 ops/training.py:65 2019-01-16 14:59:13.295580: step 22105, loss = 0.15019 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:59:14.258376 ops/training.py:65 2019-01-16 14:59:14.258273: step 22106, loss = 0.24644 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:59:15.219866 ops/training.py:65 2019-01-16 14:59:15.219771: step 22107, loss = 0.10370 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:59:16.182792 ops/training.py:65 2019-01-16 14:59:16.182693: step 22108, loss = 0.10717 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:59:17.145723 ops/training.py:65 2019-01-16 14:59:17.145622: step 22109, loss = 0.17753 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:59:18.110244 ops/training.py:65 2019-01-16 14:59:18.110180: step 22110, loss = 0.26279 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:59:19.074712 ops/training.py:65 2019-01-16 14:59:19.074626: step 22111, loss = 0.09563 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:59:20.037540 ops/training.py:65 2019-01-16 14:59:20.037473: step 22112, loss = 0.18360 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:59:20.999693 ops/training.py:65 2019-01-16 14:59:20.999621: step 22113, loss = 0.18782 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:59:21.962408 ops/training.py:65 2019-01-16 14:59:21.962307: step 22114, loss = 0.27759 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:59:22.926888 ops/training.py:65 2019-01-16 14:59:22.926793: step 22115, loss = 0.11622 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:59:23.891865 ops/training.py:65 2019-01-16 14:59:23.891765: step 22116, loss = 0.20121 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:59:24.855190 ops/training.py:65 2019-01-16 14:59:24.855090: step 22117, loss = 0.19627 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:59:25.816906 ops/training.py:65 2019-01-16 14:59:25.816807: step 22118, loss = 0.17133 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:59:26.778172 ops/training.py:65 2019-01-16 14:59:26.778077: step 22119, loss = 0.30973 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 14:59:27.740535 ops/training.py:65 2019-01-16 14:59:27.740435: step 22120, loss = 0.29969 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:59:28.703860 ops/training.py:65 2019-01-16 14:59:28.703757: step 22121, loss = 0.15600 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:59:29.666870 ops/training.py:65 2019-01-16 14:59:29.666769: step 22122, loss = 0.18788 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:59:30.628846 ops/training.py:65 2019-01-16 14:59:30.628756: step 22123, loss = 0.13366 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:59:31.590186 ops/training.py:65 2019-01-16 14:59:31.590086: step 22124, loss = 0.14739 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:59:32.551498 ops/training.py:65 2019-01-16 14:59:32.551400: step 22125, loss = 0.12416 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:59:33.514521 ops/training.py:65 2019-01-16 14:59:33.514422: step 22126, loss = 0.18680 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:59:34.476036 ops/training.py:65 2019-01-16 14:59:34.475938: step 22127, loss = 0.10996 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:59:35.437625 ops/training.py:65 2019-01-16 14:59:35.437552: step 22128, loss = 0.22391 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:59:36.399468 ops/training.py:65 2019-01-16 14:59:36.399396: step 22129, loss = 0.24437 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:59:37.360863 ops/training.py:65 2019-01-16 14:59:37.360771: step 22130, loss = 0.24416 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:59:38.323162 ops/training.py:65 2019-01-16 14:59:38.323061: step 22131, loss = 0.14272 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:59:39.285763 ops/training.py:65 2019-01-16 14:59:39.285663: step 22132, loss = 0.16836 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:59:40.248165 ops/training.py:65 2019-01-16 14:59:40.248066: step 22133, loss = 0.17099 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:59:41.210492 ops/training.py:65 2019-01-16 14:59:41.210389: step 22134, loss = 0.10595 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:59:42.171990 ops/training.py:65 2019-01-16 14:59:42.171917: step 22135, loss = 0.09675 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:59:43.135910 ops/training.py:65 2019-01-16 14:59:43.135841: step 22136, loss = 0.19776 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:59:44.099978 ops/training.py:65 2019-01-16 14:59:44.099882: step 22137, loss = 0.14451 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:59:45.062143 ops/training.py:65 2019-01-16 14:59:45.062055: step 22138, loss = 0.24594 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:59:46.023203 ops/training.py:65 2019-01-16 14:59:46.023110: step 22139, loss = 0.16913 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:59:46.983828 ops/training.py:65 2019-01-16 14:59:46.983732: step 22140, loss = 0.19471 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:59:47.944870 ops/training.py:65 2019-01-16 14:59:47.944790: step 22141, loss = 0.15747 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:59:48.905888 ops/training.py:65 2019-01-16 14:59:48.905792: step 22142, loss = 0.14962 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:59:49.866123 ops/training.py:65 2019-01-16 14:59:49.866028: step 22143, loss = 0.07758 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:59:50.826390 ops/training.py:65 2019-01-16 14:59:50.826318: step 22144, loss = 0.11181 (33.4 examples/sec; 0.959 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 14:59:51.787462 ops/training.py:65 2019-01-16 14:59:51.787372: step 22145, loss = 0.21982 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:59:52.751214 ops/training.py:65 2019-01-16 14:59:52.751136: step 22146, loss = 0.17412 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 14:59:53.714876 ops/training.py:65 2019-01-16 14:59:53.714776: step 22147, loss = 0.17222 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:59:54.680420 ops/training.py:65 2019-01-16 14:59:54.680324: step 22148, loss = 0.10458 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:59:55.643003 ops/training.py:65 2019-01-16 14:59:55.642901: step 22149, loss = 0.12421 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:59:56.607025 ops/training.py:65 2019-01-16 14:59:56.606925: step 22150, loss = 0.17264 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 14:59:57.569423 ops/training.py:65 2019-01-16 14:59:57.569326: step 22151, loss = 0.19708 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 14:59:58.532264 ops/training.py:65 2019-01-16 14:59:58.532164: step 22152, loss = 0.11584 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 14:59:59.496963 ops/training.py:65 2019-01-16 14:59:59.496871: step 22153, loss = 0.15423 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:00:00.460397 ops/training.py:65 2019-01-16 15:00:00.460302: step 22154, loss = 0.08564 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 15:00:01.422301 ops/training.py:65 2019-01-16 15:00:01.422223: step 22155, loss = 0.17452 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 15:00:02.384004 ops/training.py:65 2019-01-16 15:00:02.383915: step 22156, loss = 0.12887 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:00:03.345568 ops/training.py:65 2019-01-16 15:00:03.345471: step 22157, loss = 0.28958 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 15:00:04.309756 ops/training.py:65 2019-01-16 15:00:04.309657: step 22158, loss = 0.17554 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:00:05.273534 ops/training.py:65 2019-01-16 15:00:05.273461: step 22159, loss = 0.11158 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:00:06.235978 ops/training.py:65 2019-01-16 15:00:06.235900: step 22160, loss = 0.23356 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 15:00:07.198626 ops/training.py:65 2019-01-16 15:00:07.198526: step 22161, loss = 0.23788 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 15:00:08.160631 ops/training.py:65 2019-01-16 15:00:08.160532: step 22162, loss = 0.09286 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:00:09.122267 ops/training.py:65 2019-01-16 15:00:09.122165: step 22163, loss = 0.11448 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:00:10.083908 ops/training.py:65 2019-01-16 15:00:10.083820: step 22164, loss = 0.10851 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:00:11.044827 ops/training.py:65 2019-01-16 15:00:11.044732: step 22165, loss = 0.19543 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 15:00:12.006124 ops/training.py:65 2019-01-16 15:00:12.006023: step 22166, loss = 0.14527 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:00:12.967359 ops/training.py:65 2019-01-16 15:00:12.967262: step 22167, loss = 0.17734 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 15:00:13.929354 ops/training.py:65 2019-01-16 15:00:13.929253: step 22168, loss = 0.16407 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 15:00:14.891965 ops/training.py:65 2019-01-16 15:00:14.891865: step 22169, loss = 0.12384 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 15:00:15.853300 ops/training.py:65 2019-01-16 15:00:15.853201: step 22170, loss = 0.26473 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 15:00:16.815672 ops/training.py:65 2019-01-16 15:00:16.815575: step 22171, loss = 0.10809 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:00:17.777825 ops/training.py:65 2019-01-16 15:00:17.777724: step 22172, loss = 0.12433 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 15:00:18.739816 ops/training.py:65 2019-01-16 15:00:18.739735: step 22173, loss = 0.18905 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 15:00:19.702658 ops/training.py:65 2019-01-16 15:00:19.702558: step 22174, loss = 0.11597 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 15:00:20.663917 ops/training.py:65 2019-01-16 15:00:20.663815: step 22175, loss = 0.12106 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:00:21.624938 ops/training.py:65 2019-01-16 15:00:21.624852: step 22176, loss = 0.11571 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:00:22.588463 ops/training.py:65 2019-01-16 15:00:22.588389: step 22177, loss = 0.11600 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:00:23.550554 ops/training.py:65 2019-01-16 15:00:23.550458: step 22178, loss = 0.30292 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 15:00:24.512218 ops/training.py:65 2019-01-16 15:00:24.512130: step 22179, loss = 0.23459 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 15:00:25.474467 ops/training.py:65 2019-01-16 15:00:25.474367: step 22180, loss = 0.16899 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 15:00:26.436131 ops/training.py:65 2019-01-16 15:00:26.436037: step 22181, loss = 0.06219 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 15:00:27.397636 ops/training.py:65 2019-01-16 15:00:27.397537: step 22182, loss = 0.15977 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 15:00:28.360291 ops/training.py:65 2019-01-16 15:00:28.360192: step 22183, loss = 0.20967 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 15:00:29.321752 ops/training.py:65 2019-01-16 15:00:29.321655: step 22184, loss = 0.13079 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 15:00:30.284169 ops/training.py:65 2019-01-16 15:00:30.284076: step 22185, loss = 0.24933 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 15:00:31.245758 ops/training.py:65 2019-01-16 15:00:31.245660: step 22186, loss = 0.18348 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 15:00:32.206838 ops/training.py:65 2019-01-16 15:00:32.206739: step 22187, loss = 0.38614 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.8125
I0832 2019-01-16 15:00:33.168822 ops/training.py:65 2019-01-16 15:00:33.168724: step 22188, loss = 0.09655 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:00:34.133950 ops/training.py:65 2019-01-16 15:00:34.133861: step 22189, loss = 0.09645 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:00:35.097921 ops/training.py:65 2019-01-16 15:00:35.097848: step 22190, loss = 0.25655 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 15:00:36.062204 ops/training.py:65 2019-01-16 15:00:36.062124: step 22191, loss = 0.16651 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 15:00:37.024239 ops/training.py:65 2019-01-16 15:00:37.024143: step 22192, loss = 0.11887 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 15:00:37.988149 ops/training.py:65 2019-01-16 15:00:37.988049: step 22193, loss = 0.35120 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 15:00:38.950370 ops/training.py:65 2019-01-16 15:00:38.950271: step 22194, loss = 0.43094 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 15:00:39.913013 ops/training.py:65 2019-01-16 15:00:39.912922: step 22195, loss = 0.22532 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 15:00:40.874829 ops/training.py:65 2019-01-16 15:00:40.874730: step 22196, loss = 0.10676 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:00:41.836584 ops/training.py:65 2019-01-16 15:00:41.836485: step 22197, loss = 0.13877 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:00:42.798210 ops/training.py:65 2019-01-16 15:00:42.798115: step 22198, loss = 0.12805 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 15:00:43.760019 ops/training.py:65 2019-01-16 15:00:43.759914: step 22199, loss = 0.22145 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 15:00:44.722352 ops/training.py:65 2019-01-16 15:00:44.722253: step 22200, loss = 0.30895 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 15:00:45.684986 ops/training.py:65 2019-01-16 15:00:45.684892: step 22201, loss = 0.19046 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 15:00:46.647192 ops/training.py:65 2019-01-16 15:00:46.647094: step 22202, loss = 0.13409 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 15:00:47.609545 ops/training.py:65 2019-01-16 15:00:47.609446: step 22203, loss = 0.07662 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 15:00:48.571424 ops/training.py:65 2019-01-16 15:00:48.571334: step 22204, loss = 0.16877 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 15:00:49.534166 ops/training.py:65 2019-01-16 15:00:49.534075: step 22205, loss = 0.27517 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 15:00:50.496075 ops/training.py:65 2019-01-16 15:00:50.495999: step 22206, loss = 0.24962 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 15:00:51.457435 ops/training.py:65 2019-01-16 15:00:51.457355: step 22207, loss = 0.11383 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:00:52.419940 ops/training.py:65 2019-01-16 15:00:52.419807: step 22208, loss = 0.17771 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 15:00:53.386487 ops/training.py:65 2019-01-16 15:00:53.386389: step 22209, loss = 0.20068 (33.2 examples/sec; 0.965 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 15:00:54.349771 ops/training.py:65 2019-01-16 15:00:54.349677: step 22210, loss = 0.25117 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 15:00:55.313207 ops/training.py:65 2019-01-16 15:00:55.313105: step 22211, loss = 0.26694 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 15:00:56.275430 ops/training.py:65 2019-01-16 15:00:56.275328: step 22212, loss = 0.17373 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 15:00:57.236353 ops/training.py:65 2019-01-16 15:00:57.236253: step 22213, loss = 0.22769 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 15:00:58.198015 ops/training.py:65 2019-01-16 15:00:58.197915: step 22214, loss = 0.09113 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 15:00:59.160600 ops/training.py:65 2019-01-16 15:00:59.160498: step 22215, loss = 0.12127 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 15:01:00.122704 ops/training.py:65 2019-01-16 15:01:00.122611: step 22216, loss = 0.13413 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 15:01:01.085351 ops/training.py:65 2019-01-16 15:01:01.085248: step 22217, loss = 0.21712 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 15:01:02.046443 ops/training.py:65 2019-01-16 15:01:02.046362: step 22218, loss = 0.23450 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 15:01:03.010915 ops/training.py:65 2019-01-16 15:01:03.010819: step 22219, loss = 0.10540 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 15:01:03.976431 ops/training.py:65 2019-01-16 15:01:03.976331: step 22220, loss = 0.18610 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 15:01:04.938123 ops/training.py:65 2019-01-16 15:01:04.938066: step 22221, loss = 0.24890 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 15:01:05.903385 ops/training.py:65 2019-01-16 15:01:05.903307: step 22222, loss = 0.15829 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 15:01:06.865558 ops/training.py:65 2019-01-16 15:01:06.865469: step 22223, loss = 0.23510 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 15:01:07.830313 ops/training.py:65 2019-01-16 15:01:07.830215: step 22224, loss = 0.31381 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 15:01:08.794180 ops/training.py:65 2019-01-16 15:01:08.794082: step 22225, loss = 0.09655 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:01:09.756698 ops/training.py:65 2019-01-16 15:01:09.756612: step 22226, loss = 0.24552 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 15:01:10.718952 ops/training.py:65 2019-01-16 15:01:10.718853: step 22227, loss = 0.09162 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 15:01:11.681175 ops/training.py:65 2019-01-16 15:01:11.681071: step 22228, loss = 0.34168 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 15:01:12.645116 ops/training.py:65 2019-01-16 15:01:12.645021: step 22229, loss = 0.09286 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 15:01:13.609031 ops/training.py:65 2019-01-16 15:01:13.608948: step 22230, loss = 0.21443 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 15:01:14.571976 ops/training.py:65 2019-01-16 15:01:14.571885: step 22231, loss = 0.12082 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:01:15.533403 ops/training.py:65 2019-01-16 15:01:15.533306: step 22232, loss = 0.14014 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 15:01:16.494960 ops/training.py:65 2019-01-16 15:01:16.494862: step 22233, loss = 0.16614 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 15:01:17.455660 ops/training.py:65 2019-01-16 15:01:17.455567: step 22234, loss = 0.15812 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:01:18.417977 ops/training.py:65 2019-01-16 15:01:18.417894: step 22235, loss = 0.11198 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:01:19.380070 ops/training.py:65 2019-01-16 15:01:19.379964: step 22236, loss = 0.33085 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 15:01:20.342742 ops/training.py:65 2019-01-16 15:01:20.342667: step 22237, loss = 0.15062 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:01:21.303874 ops/training.py:65 2019-01-16 15:01:21.303792: step 22238, loss = 0.29165 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.84375
I0832 2019-01-16 15:01:22.264925 ops/training.py:65 2019-01-16 15:01:22.264830: step 22239, loss = 0.23816 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 15:01:23.225844 ops/training.py:65 2019-01-16 15:01:23.225747: step 22240, loss = 0.12403 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:01:24.188121 ops/training.py:65 2019-01-16 15:01:24.188029: step 22241, loss = 0.10719 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 15:01:25.150857 ops/training.py:65 2019-01-16 15:01:25.150756: step 22242, loss = 0.19892 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 15:01:26.112736 ops/training.py:65 2019-01-16 15:01:26.112640: step 22243, loss = 0.28016 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 15:01:27.074423 ops/training.py:65 2019-01-16 15:01:27.074328: step 22244, loss = 0.19545 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:01:28.036030 ops/training.py:65 2019-01-16 15:01:28.035929: step 22245, loss = 0.25787 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 15:01:28.997921 ops/training.py:65 2019-01-16 15:01:28.997822: step 22246, loss = 0.12964 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:01:29.959933 ops/training.py:65 2019-01-16 15:01:29.959840: step 22247, loss = 0.07879 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 1.0
I0832 2019-01-16 15:01:30.921697 ops/training.py:65 2019-01-16 15:01:30.921601: step 22248, loss = 0.22918 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 15:01:31.883491 ops/training.py:65 2019-01-16 15:01:31.883400: step 22249, loss = 0.22467 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 15:01:32.844791 ops/training.py:65 2019-01-16 15:01:32.844717: step 22250, loss = 0.12277 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:01:33.808973 ops/training.py:65 2019-01-16 15:01:33.808889: step 22251, loss = 0.13530 (33.2 examples/sec; 0.963 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:01:34.771863 ops/training.py:65 2019-01-16 15:01:34.771769: step 22252, loss = 0.29967 (33.3 examples/sec; 0.962 sec/batch) | Training accuracy = 0.90625
I0832 2019-01-16 15:01:35.734468 ops/training.py:65 2019-01-16 15:01:35.734365: step 22253, loss = 0.21696 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 15:01:36.699421 ops/training.py:65 2019-01-16 15:01:36.699346: step 22254, loss = 0.11784 (33.2 examples/sec; 0.964 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:01:37.660824 ops/training.py:65 2019-01-16 15:01:37.660748: step 22255, loss = 0.16452 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:01:38.623077 ops/training.py:65 2019-01-16 15:01:38.623000: step 22256, loss = 0.17817 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.96875
I0832 2019-01-16 15:01:39.584606 ops/training.py:65 2019-01-16 15:01:39.584509: step 22257, loss = 0.19543 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.875
I0832 2019-01-16 15:01:40.546016 ops/training.py:65 2019-01-16 15:01:40.545927: step 22258, loss = 0.28701 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 15:01:41.506795 ops/training.py:65 2019-01-16 15:01:41.506702: step 22259, loss = 0.21482 (33.3 examples/sec; 0.960 sec/batch) | Training accuracy = 0.9375
I0832 2019-01-16 15:01:42.468933 ops/training.py:65 2019-01-16 15:01:42.468840: step 22260, loss = 0.15739 (33.3 examples/sec; 0.961 sec/batch) | Training accuracy = 0.90625
