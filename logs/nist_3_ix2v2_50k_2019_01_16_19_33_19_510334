I2992 2019-01-16 19:34:03.536443 ops/training.py:229 Log written to /gpfs_home/dlinsley/cluttered_nist_experiments/logs/nist_3_ix2v2_50k_2019_01_16_19_33_19_510334
I2992 2019-01-16 19:38:41.355245 ops/training.py:396 Failed to save checkpoint: global name 'db' is not defined
I2992 2019-01-16 19:38:41.356285 ops/training.py:41 2019-01-16 19:38:41.356229: step 0, loss = 0.88 (0.1 examples/sec; 260.477 sec/batch) | Training accuracy = 0.5625 | Validation accuracy = 0.49865 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_19_33_19_510334
I2992 2019-01-16 19:38:42.247069 ops/training.py:65 2019-01-16 19:38:42.246994: step 1, loss = 1.01383 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:38:43.136597 ops/training.py:65 2019-01-16 19:38:43.136521: step 2, loss = 0.91390 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:38:44.026066 ops/training.py:65 2019-01-16 19:38:44.025981: step 3, loss = 1.20595 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:38:44.915104 ops/training.py:65 2019-01-16 19:38:44.915036: step 4, loss = 1.53191 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.25
I2992 2019-01-16 19:38:45.803359 ops/training.py:65 2019-01-16 19:38:45.803295: step 5, loss = 0.88984 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:38:46.693334 ops/training.py:65 2019-01-16 19:38:46.693282: step 6, loss = 1.06064 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:38:47.583392 ops/training.py:65 2019-01-16 19:38:47.583342: step 7, loss = 0.84741 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:38:48.472229 ops/training.py:65 2019-01-16 19:38:48.472148: step 8, loss = 0.99914 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:38:49.361252 ops/training.py:65 2019-01-16 19:38:49.361191: step 9, loss = 0.77071 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:38:50.250018 ops/training.py:65 2019-01-16 19:38:50.249934: step 10, loss = 1.33074 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:38:51.138888 ops/training.py:65 2019-01-16 19:38:51.138813: step 11, loss = 0.95997 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:38:52.028996 ops/training.py:65 2019-01-16 19:38:52.028919: step 12, loss = 1.21020 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:38:52.919633 ops/training.py:65 2019-01-16 19:38:52.919559: step 13, loss = 1.04131 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:38:53.809180 ops/training.py:65 2019-01-16 19:38:53.809135: step 14, loss = 0.95567 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:38:54.698013 ops/training.py:65 2019-01-16 19:38:54.697921: step 15, loss = 1.21667 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:38:55.587034 ops/training.py:65 2019-01-16 19:38:55.586940: step 16, loss = 1.11264 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:38:56.476421 ops/training.py:65 2019-01-16 19:38:56.476361: step 17, loss = 0.88240 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:38:57.366775 ops/training.py:65 2019-01-16 19:38:57.366708: step 18, loss = 1.08445 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:38:58.256597 ops/training.py:65 2019-01-16 19:38:58.256505: step 19, loss = 1.01066 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:38:59.147336 ops/training.py:65 2019-01-16 19:38:59.147266: step 20, loss = 0.89297 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:39:00.038302 ops/training.py:65 2019-01-16 19:39:00.038229: step 21, loss = 1.06209 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:39:00.929015 ops/training.py:65 2019-01-16 19:39:00.928948: step 22, loss = 1.04493 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:39:01.819548 ops/training.py:65 2019-01-16 19:39:01.819477: step 23, loss = 1.09928 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:39:02.708535 ops/training.py:65 2019-01-16 19:39:02.708463: step 24, loss = 1.22710 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:39:03.600848 ops/training.py:65 2019-01-16 19:39:03.600768: step 25, loss = 1.08191 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:39:04.491573 ops/training.py:65 2019-01-16 19:39:04.491502: step 26, loss = 1.13360 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:39:05.380762 ops/training.py:65 2019-01-16 19:39:05.380692: step 27, loss = 0.77340 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:39:06.270425 ops/training.py:65 2019-01-16 19:39:06.270353: step 28, loss = 1.11744 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:39:07.161112 ops/training.py:65 2019-01-16 19:39:07.161037: step 29, loss = 0.92390 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:39:08.052888 ops/training.py:65 2019-01-16 19:39:08.052814: step 30, loss = 0.84929 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:39:08.943652 ops/training.py:65 2019-01-16 19:39:08.943584: step 31, loss = 0.76648 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:39:09.833570 ops/training.py:65 2019-01-16 19:39:09.833494: step 32, loss = 1.16448 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:39:10.723975 ops/training.py:65 2019-01-16 19:39:10.723902: step 33, loss = 1.22452 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:39:11.615423 ops/training.py:65 2019-01-16 19:39:11.615348: step 34, loss = 0.80229 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:39:12.505839 ops/training.py:65 2019-01-16 19:39:12.505756: step 35, loss = 1.06683 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:39:13.395617 ops/training.py:65 2019-01-16 19:39:13.395537: step 36, loss = 0.85895 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:39:14.284687 ops/training.py:65 2019-01-16 19:39:14.284611: step 37, loss = 1.03616 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:39:15.175083 ops/training.py:65 2019-01-16 19:39:15.175015: step 38, loss = 1.04292 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:39:16.064531 ops/training.py:65 2019-01-16 19:39:16.064464: step 39, loss = 0.97579 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:39:16.954673 ops/training.py:65 2019-01-16 19:39:16.954618: step 40, loss = 1.15421 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:39:17.844642 ops/training.py:65 2019-01-16 19:39:17.844603: step 41, loss = 1.26416 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:39:18.735278 ops/training.py:65 2019-01-16 19:39:18.735222: step 42, loss = 0.82961 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:39:19.625802 ops/training.py:65 2019-01-16 19:39:19.625725: step 43, loss = 0.98264 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:39:20.515303 ops/training.py:65 2019-01-16 19:39:20.515232: step 44, loss = 0.85678 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:39:21.406086 ops/training.py:65 2019-01-16 19:39:21.406012: step 45, loss = 0.84644 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:39:22.295753 ops/training.py:65 2019-01-16 19:39:22.295684: step 46, loss = 0.86901 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:39:23.186474 ops/training.py:65 2019-01-16 19:39:23.186378: step 47, loss = 0.90614 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:39:24.076967 ops/training.py:65 2019-01-16 19:39:24.076894: step 48, loss = 0.82772 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:39:24.966451 ops/training.py:65 2019-01-16 19:39:24.966372: step 49, loss = 0.82796 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:39:25.855988 ops/training.py:65 2019-01-16 19:39:25.855911: step 50, loss = 0.91952 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:39:26.745166 ops/training.py:65 2019-01-16 19:39:26.745095: step 51, loss = 0.89759 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:39:27.634875 ops/training.py:65 2019-01-16 19:39:27.634790: step 52, loss = 1.00198 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:39:28.524422 ops/training.py:65 2019-01-16 19:39:28.524339: step 53, loss = 0.86774 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:39:29.413782 ops/training.py:65 2019-01-16 19:39:29.413693: step 54, loss = 0.91211 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:39:30.302320 ops/training.py:65 2019-01-16 19:39:30.302226: step 55, loss = 0.69154 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:39:31.191831 ops/training.py:65 2019-01-16 19:39:31.191735: step 56, loss = 1.02506 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:39:32.082392 ops/training.py:65 2019-01-16 19:39:32.082326: step 57, loss = 0.79996 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:39:32.971800 ops/training.py:65 2019-01-16 19:39:32.971722: step 58, loss = 0.90212 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:39:33.861286 ops/training.py:65 2019-01-16 19:39:33.861214: step 59, loss = 0.95983 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:39:34.752648 ops/training.py:65 2019-01-16 19:39:34.752573: step 60, loss = 0.86385 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:39:35.642346 ops/training.py:65 2019-01-16 19:39:35.642264: step 61, loss = 0.82328 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:39:36.533417 ops/training.py:65 2019-01-16 19:39:36.533338: step 62, loss = 0.81317 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:39:37.424537 ops/training.py:65 2019-01-16 19:39:37.424463: step 63, loss = 0.61689 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:39:38.315838 ops/training.py:65 2019-01-16 19:39:38.315763: step 64, loss = 0.75369 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:39:39.205627 ops/training.py:65 2019-01-16 19:39:39.205546: step 65, loss = 0.96419 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:39:40.095397 ops/training.py:65 2019-01-16 19:39:40.095323: step 66, loss = 0.72771 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 19:39:40.984665 ops/training.py:65 2019-01-16 19:39:40.984587: step 67, loss = 0.85572 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:39:41.876063 ops/training.py:65 2019-01-16 19:39:41.875985: step 68, loss = 0.76424 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:39:42.766797 ops/training.py:65 2019-01-16 19:39:42.766719: step 69, loss = 0.97357 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:39:43.657927 ops/training.py:65 2019-01-16 19:39:43.657845: step 70, loss = 0.87606 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:39:44.547963 ops/training.py:65 2019-01-16 19:39:44.547892: step 71, loss = 1.01025 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:39:45.436974 ops/training.py:65 2019-01-16 19:39:45.436908: step 72, loss = 0.88293 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:39:46.326644 ops/training.py:65 2019-01-16 19:39:46.326573: step 73, loss = 0.69184 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:39:47.217619 ops/training.py:65 2019-01-16 19:39:47.217541: step 74, loss = 0.80664 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:39:48.108171 ops/training.py:65 2019-01-16 19:39:48.108101: step 75, loss = 0.85875 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:39:48.998818 ops/training.py:65 2019-01-16 19:39:48.998740: step 76, loss = 0.89063 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:39:49.890063 ops/training.py:65 2019-01-16 19:39:49.889988: step 77, loss = 0.92450 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:39:50.779687 ops/training.py:65 2019-01-16 19:39:50.779589: step 78, loss = 1.14560 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:39:51.670330 ops/training.py:65 2019-01-16 19:39:51.670256: step 79, loss = 0.82876 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:39:52.560961 ops/training.py:65 2019-01-16 19:39:52.560883: step 80, loss = 0.74819 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:39:53.452112 ops/training.py:65 2019-01-16 19:39:53.452035: step 81, loss = 1.16465 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:39:54.341543 ops/training.py:65 2019-01-16 19:39:54.341471: step 82, loss = 0.79620 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:39:55.231620 ops/training.py:65 2019-01-16 19:39:55.231527: step 83, loss = 0.92727 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:39:56.120514 ops/training.py:65 2019-01-16 19:39:56.120419: step 84, loss = 0.85072 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:39:57.008950 ops/training.py:65 2019-01-16 19:39:57.008850: step 85, loss = 1.05444 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:39:57.899118 ops/training.py:65 2019-01-16 19:39:57.899013: step 86, loss = 0.69111 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:39:58.787381 ops/training.py:65 2019-01-16 19:39:58.787281: step 87, loss = 1.09318 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:39:59.675833 ops/training.py:65 2019-01-16 19:39:59.675736: step 88, loss = 0.94255 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:40:00.565604 ops/training.py:65 2019-01-16 19:40:00.565535: step 89, loss = 0.87217 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:40:01.455855 ops/training.py:65 2019-01-16 19:40:01.455773: step 90, loss = 0.93263 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:40:02.346262 ops/training.py:65 2019-01-16 19:40:02.346190: step 91, loss = 1.10857 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:40:03.236527 ops/training.py:65 2019-01-16 19:40:03.236446: step 92, loss = 0.80772 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:40:04.126825 ops/training.py:65 2019-01-16 19:40:04.126744: step 93, loss = 1.04743 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:40:05.016242 ops/training.py:65 2019-01-16 19:40:05.016163: step 94, loss = 0.71328 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:40:05.908234 ops/training.py:65 2019-01-16 19:40:05.908146: step 95, loss = 0.88332 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:40:06.798212 ops/training.py:65 2019-01-16 19:40:06.798133: step 96, loss = 0.95248 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:40:07.687325 ops/training.py:65 2019-01-16 19:40:07.687245: step 97, loss = 1.16933 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:40:08.577607 ops/training.py:65 2019-01-16 19:40:08.577572: step 98, loss = 1.08250 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:40:09.467824 ops/training.py:65 2019-01-16 19:40:09.467791: step 99, loss = 1.07706 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:40:10.358788 ops/training.py:65 2019-01-16 19:40:10.358732: step 100, loss = 1.01031 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:40:11.248968 ops/training.py:65 2019-01-16 19:40:11.248889: step 101, loss = 0.80333 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:40:12.139644 ops/training.py:65 2019-01-16 19:40:12.139563: step 102, loss = 0.91046 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:40:13.030755 ops/training.py:65 2019-01-16 19:40:13.030676: step 103, loss = 1.03376 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:40:13.921298 ops/training.py:65 2019-01-16 19:40:13.921223: step 104, loss = 1.12013 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:40:14.810784 ops/training.py:65 2019-01-16 19:40:14.810711: step 105, loss = 0.93507 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:40:15.700867 ops/training.py:65 2019-01-16 19:40:15.700792: step 106, loss = 0.80108 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:40:16.590362 ops/training.py:65 2019-01-16 19:40:16.590285: step 107, loss = 0.85770 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:40:17.480331 ops/training.py:65 2019-01-16 19:40:17.480292: step 108, loss = 0.92673 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:40:18.370407 ops/training.py:65 2019-01-16 19:40:18.370332: step 109, loss = 0.94726 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:40:19.260132 ops/training.py:65 2019-01-16 19:40:19.260056: step 110, loss = 0.77240 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:40:20.149578 ops/training.py:65 2019-01-16 19:40:20.149506: step 111, loss = 0.96759 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:40:21.038720 ops/training.py:65 2019-01-16 19:40:21.038640: step 112, loss = 1.01216 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:40:21.928137 ops/training.py:65 2019-01-16 19:40:21.928053: step 113, loss = 0.86639 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:40:22.818180 ops/training.py:65 2019-01-16 19:40:22.818097: step 114, loss = 1.01800 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:40:23.708205 ops/training.py:65 2019-01-16 19:40:23.708133: step 115, loss = 0.83050 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:40:24.598058 ops/training.py:65 2019-01-16 19:40:24.597970: step 116, loss = 0.80063 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:40:25.487845 ops/training.py:65 2019-01-16 19:40:25.487761: step 117, loss = 0.87005 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:40:26.377152 ops/training.py:65 2019-01-16 19:40:26.377069: step 118, loss = 0.94522 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:40:27.265440 ops/training.py:65 2019-01-16 19:40:27.265367: step 119, loss = 0.95029 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:40:28.155956 ops/training.py:65 2019-01-16 19:40:28.155916: step 120, loss = 0.99837 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:40:29.045565 ops/training.py:65 2019-01-16 19:40:29.045510: step 121, loss = 0.95679 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:40:29.934028 ops/training.py:65 2019-01-16 19:40:29.933962: step 122, loss = 1.03638 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:40:30.821906 ops/training.py:65 2019-01-16 19:40:30.821849: step 123, loss = 0.77448 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:40:31.709920 ops/training.py:65 2019-01-16 19:40:31.709848: step 124, loss = 0.86054 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:40:32.598179 ops/training.py:65 2019-01-16 19:40:32.598113: step 125, loss = 0.72381 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:40:33.486991 ops/training.py:65 2019-01-16 19:40:33.486921: step 126, loss = 0.72973 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:40:34.375084 ops/training.py:65 2019-01-16 19:40:34.375018: step 127, loss = 0.93666 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:40:35.264500 ops/training.py:65 2019-01-16 19:40:35.264422: step 128, loss = 0.83461 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:40:36.153798 ops/training.py:65 2019-01-16 19:40:36.153706: step 129, loss = 0.67865 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:40:37.045064 ops/training.py:65 2019-01-16 19:40:37.044982: step 130, loss = 0.68943 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:40:37.935033 ops/training.py:65 2019-01-16 19:40:37.934926: step 131, loss = 0.89341 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:40:38.825867 ops/training.py:65 2019-01-16 19:40:38.825782: step 132, loss = 0.99990 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:40:39.717023 ops/training.py:65 2019-01-16 19:40:39.716942: step 133, loss = 0.93484 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:40:40.606366 ops/training.py:65 2019-01-16 19:40:40.606298: step 134, loss = 0.93825 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:40:41.495538 ops/training.py:65 2019-01-16 19:40:41.495469: step 135, loss = 1.18196 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 19:40:42.386314 ops/training.py:65 2019-01-16 19:40:42.386242: step 136, loss = 0.82042 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:40:43.277088 ops/training.py:65 2019-01-16 19:40:43.277013: step 137, loss = 0.70339 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:40:44.168444 ops/training.py:65 2019-01-16 19:40:44.168371: step 138, loss = 0.99067 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:40:45.059189 ops/training.py:65 2019-01-16 19:40:45.059120: step 139, loss = 1.01722 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 19:40:45.948424 ops/training.py:65 2019-01-16 19:40:45.948349: step 140, loss = 0.88413 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:40:46.838575 ops/training.py:65 2019-01-16 19:40:46.838497: step 141, loss = 1.39590 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 19:40:47.729378 ops/training.py:65 2019-01-16 19:40:47.729304: step 142, loss = 0.88267 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:40:48.621154 ops/training.py:65 2019-01-16 19:40:48.621076: step 143, loss = 1.07953 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:40:49.511918 ops/training.py:65 2019-01-16 19:40:49.511841: step 144, loss = 1.03531 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:40:50.403220 ops/training.py:65 2019-01-16 19:40:50.403146: step 145, loss = 0.86080 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:40:51.293502 ops/training.py:65 2019-01-16 19:40:51.293424: step 146, loss = 0.74567 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:40:52.183445 ops/training.py:65 2019-01-16 19:40:52.183374: step 147, loss = 0.94064 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:40:53.074684 ops/training.py:65 2019-01-16 19:40:53.074603: step 148, loss = 0.74512 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:40:53.966501 ops/training.py:65 2019-01-16 19:40:53.966423: step 149, loss = 0.96652 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:40:54.857156 ops/training.py:65 2019-01-16 19:40:54.857088: step 150, loss = 0.76914 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 19:40:55.748453 ops/training.py:65 2019-01-16 19:40:55.748373: step 151, loss = 1.00019 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:40:56.639761 ops/training.py:65 2019-01-16 19:40:56.639689: step 152, loss = 1.09621 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:40:57.529455 ops/training.py:65 2019-01-16 19:40:57.529378: step 153, loss = 0.76183 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:40:58.419515 ops/training.py:65 2019-01-16 19:40:58.419441: step 154, loss = 0.89344 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:40:59.310404 ops/training.py:65 2019-01-16 19:40:59.310330: step 155, loss = 0.93182 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:41:00.200695 ops/training.py:65 2019-01-16 19:41:00.200622: step 156, loss = 1.04419 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:41:01.090941 ops/training.py:65 2019-01-16 19:41:01.090870: step 157, loss = 0.74060 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:41:01.982225 ops/training.py:65 2019-01-16 19:41:01.982151: step 158, loss = 0.95459 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:41:02.874816 ops/training.py:65 2019-01-16 19:41:02.874744: step 159, loss = 0.80934 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:41:03.764745 ops/training.py:65 2019-01-16 19:41:03.764671: step 160, loss = 1.00954 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:41:04.655313 ops/training.py:65 2019-01-16 19:41:04.655237: step 161, loss = 0.83082 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:41:05.546690 ops/training.py:65 2019-01-16 19:41:05.546614: step 162, loss = 0.74616 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:41:06.437965 ops/training.py:65 2019-01-16 19:41:06.437884: step 163, loss = 0.87043 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:41:07.328197 ops/training.py:65 2019-01-16 19:41:07.328102: step 164, loss = 0.96028 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:41:08.218249 ops/training.py:65 2019-01-16 19:41:08.218179: step 165, loss = 0.75714 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:41:09.107730 ops/training.py:65 2019-01-16 19:41:09.107654: step 166, loss = 0.69078 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:41:09.998056 ops/training.py:65 2019-01-16 19:41:09.997985: step 167, loss = 1.08270 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:41:10.887979 ops/training.py:65 2019-01-16 19:41:10.887902: step 168, loss = 0.88287 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:41:11.779393 ops/training.py:65 2019-01-16 19:41:11.779315: step 169, loss = 0.86913 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:41:12.669607 ops/training.py:65 2019-01-16 19:41:12.669525: step 170, loss = 0.99273 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:41:13.561416 ops/training.py:65 2019-01-16 19:41:13.561340: step 171, loss = 0.91344 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:41:14.451793 ops/training.py:65 2019-01-16 19:41:14.451718: step 172, loss = 0.96675 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:41:15.343277 ops/training.py:65 2019-01-16 19:41:15.343200: step 173, loss = 1.05170 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:41:16.233495 ops/training.py:65 2019-01-16 19:41:16.233421: step 174, loss = 0.88307 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:41:17.124638 ops/training.py:65 2019-01-16 19:41:17.124564: step 175, loss = 0.88331 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:41:18.015729 ops/training.py:65 2019-01-16 19:41:18.015654: step 176, loss = 0.81328 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:41:18.907139 ops/training.py:65 2019-01-16 19:41:18.907066: step 177, loss = 0.79484 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:41:19.796616 ops/training.py:65 2019-01-16 19:41:19.796538: step 178, loss = 0.83827 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:41:20.687725 ops/training.py:65 2019-01-16 19:41:20.687649: step 179, loss = 0.99023 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:41:21.578956 ops/training.py:65 2019-01-16 19:41:21.578882: step 180, loss = 0.74493 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:41:22.468811 ops/training.py:65 2019-01-16 19:41:22.468735: step 181, loss = 0.58035 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:41:23.358865 ops/training.py:65 2019-01-16 19:41:23.358781: step 182, loss = 0.94601 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:41:24.249133 ops/training.py:65 2019-01-16 19:41:24.249057: step 183, loss = 1.08765 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:41:25.139620 ops/training.py:65 2019-01-16 19:41:25.139546: step 184, loss = 0.83114 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:41:26.029858 ops/training.py:65 2019-01-16 19:41:26.029786: step 185, loss = 1.00126 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:41:26.918910 ops/training.py:65 2019-01-16 19:41:26.918840: step 186, loss = 0.73554 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:41:27.809526 ops/training.py:65 2019-01-16 19:41:27.809450: step 187, loss = 0.58198 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 19:41:28.699633 ops/training.py:65 2019-01-16 19:41:28.699560: step 188, loss = 0.84878 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:41:29.590621 ops/training.py:65 2019-01-16 19:41:29.590548: step 189, loss = 0.78645 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:41:30.483400 ops/training.py:65 2019-01-16 19:41:30.483327: step 190, loss = 1.02527 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:41:31.374563 ops/training.py:65 2019-01-16 19:41:31.374488: step 191, loss = 0.87132 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:41:32.264263 ops/training.py:65 2019-01-16 19:41:32.264189: step 192, loss = 0.92681 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:41:33.153809 ops/training.py:65 2019-01-16 19:41:33.153729: step 193, loss = 0.75676 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:41:34.043850 ops/training.py:65 2019-01-16 19:41:34.043772: step 194, loss = 0.95437 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:41:34.933124 ops/training.py:65 2019-01-16 19:41:34.933053: step 195, loss = 1.25336 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:41:35.823438 ops/training.py:65 2019-01-16 19:41:35.823357: step 196, loss = 0.99415 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:41:36.714614 ops/training.py:65 2019-01-16 19:41:36.714534: step 197, loss = 0.87682 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:41:37.603581 ops/training.py:65 2019-01-16 19:41:37.603504: step 198, loss = 0.86177 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:41:38.493503 ops/training.py:65 2019-01-16 19:41:38.493426: step 199, loss = 0.93467 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:41:39.383023 ops/training.py:65 2019-01-16 19:41:39.382947: step 200, loss = 0.91173 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:41:40.273254 ops/training.py:65 2019-01-16 19:41:40.273173: step 201, loss = 0.81795 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:41:41.163574 ops/training.py:65 2019-01-16 19:41:41.163496: step 202, loss = 0.84509 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:41:42.054498 ops/training.py:65 2019-01-16 19:41:42.054401: step 203, loss = 0.73864 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:41:42.944200 ops/training.py:65 2019-01-16 19:41:42.944127: step 204, loss = 0.92765 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:41:43.834724 ops/training.py:65 2019-01-16 19:41:43.834648: step 205, loss = 0.98336 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:41:44.726226 ops/training.py:65 2019-01-16 19:41:44.726156: step 206, loss = 1.04053 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:41:45.615687 ops/training.py:65 2019-01-16 19:41:45.615611: step 207, loss = 0.80861 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:41:46.505026 ops/training.py:65 2019-01-16 19:41:46.504951: step 208, loss = 0.75815 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:41:47.396101 ops/training.py:65 2019-01-16 19:41:47.396030: step 209, loss = 0.80792 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:41:48.285807 ops/training.py:65 2019-01-16 19:41:48.285738: step 210, loss = 0.78451 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:41:49.175235 ops/training.py:65 2019-01-16 19:41:49.175165: step 211, loss = 0.68174 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:41:50.065945 ops/training.py:65 2019-01-16 19:41:50.065872: step 212, loss = 0.84884 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:41:50.955392 ops/training.py:65 2019-01-16 19:41:50.955320: step 213, loss = 0.88605 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:41:51.846220 ops/training.py:65 2019-01-16 19:41:51.846141: step 214, loss = 0.77589 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:41:52.736412 ops/training.py:65 2019-01-16 19:41:52.736334: step 215, loss = 0.75644 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:41:53.626248 ops/training.py:65 2019-01-16 19:41:53.626174: step 216, loss = 0.67269 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:41:54.516270 ops/training.py:65 2019-01-16 19:41:54.516195: step 217, loss = 0.74358 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:41:55.406407 ops/training.py:65 2019-01-16 19:41:55.406328: step 218, loss = 0.79906 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:41:56.296960 ops/training.py:65 2019-01-16 19:41:56.296889: step 219, loss = 0.90457 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:41:57.187735 ops/training.py:65 2019-01-16 19:41:57.187661: step 220, loss = 0.89381 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:41:58.077815 ops/training.py:65 2019-01-16 19:41:58.077739: step 221, loss = 0.88991 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:41:58.967706 ops/training.py:65 2019-01-16 19:41:58.967629: step 222, loss = 0.83687 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:41:59.856805 ops/training.py:65 2019-01-16 19:41:59.856730: step 223, loss = 0.93683 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:42:00.747360 ops/training.py:65 2019-01-16 19:42:00.747281: step 224, loss = 0.66719 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:42:01.636964 ops/training.py:65 2019-01-16 19:42:01.636890: step 225, loss = 0.78063 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:42:02.526074 ops/training.py:65 2019-01-16 19:42:02.525991: step 226, loss = 0.83331 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:42:03.417035 ops/training.py:65 2019-01-16 19:42:03.416955: step 227, loss = 0.63662 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.75
I2992 2019-01-16 19:42:04.307555 ops/training.py:65 2019-01-16 19:42:04.307470: step 228, loss = 1.04236 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:42:05.196894 ops/training.py:65 2019-01-16 19:42:05.196816: step 229, loss = 0.54245 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.75
I2992 2019-01-16 19:42:06.087691 ops/training.py:65 2019-01-16 19:42:06.087615: step 230, loss = 0.84680 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:42:06.978776 ops/training.py:65 2019-01-16 19:42:06.978698: step 231, loss = 0.90184 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:42:07.869756 ops/training.py:65 2019-01-16 19:42:07.869674: step 232, loss = 0.68008 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:42:08.760772 ops/training.py:65 2019-01-16 19:42:08.760692: step 233, loss = 0.95663 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:42:09.651631 ops/training.py:65 2019-01-16 19:42:09.651558: step 234, loss = 0.73213 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 19:42:10.541793 ops/training.py:65 2019-01-16 19:42:10.541715: step 235, loss = 0.85450 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:42:11.433036 ops/training.py:65 2019-01-16 19:42:11.432967: step 236, loss = 0.76095 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:42:12.324556 ops/training.py:65 2019-01-16 19:42:12.324483: step 237, loss = 0.95243 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:42:13.215772 ops/training.py:65 2019-01-16 19:42:13.215688: step 238, loss = 0.74026 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:42:14.107296 ops/training.py:65 2019-01-16 19:42:14.107237: step 239, loss = 0.78448 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:42:14.996580 ops/training.py:65 2019-01-16 19:42:14.996506: step 240, loss = 0.69920 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:42:15.887024 ops/training.py:65 2019-01-16 19:42:15.886954: step 241, loss = 0.97997 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:42:16.778314 ops/training.py:65 2019-01-16 19:42:16.778242: step 242, loss = 0.99173 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:42:17.667906 ops/training.py:65 2019-01-16 19:42:17.667832: step 243, loss = 0.96885 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:42:18.557910 ops/training.py:65 2019-01-16 19:42:18.557841: step 244, loss = 0.65174 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:42:19.448300 ops/training.py:65 2019-01-16 19:42:19.448221: step 245, loss = 0.92255 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:42:20.339346 ops/training.py:65 2019-01-16 19:42:20.339272: step 246, loss = 0.82554 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:42:21.229733 ops/training.py:65 2019-01-16 19:42:21.229661: step 247, loss = 0.70103 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:42:22.118925 ops/training.py:65 2019-01-16 19:42:22.118860: step 248, loss = 0.86069 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:42:23.008284 ops/training.py:65 2019-01-16 19:42:23.008220: step 249, loss = 0.75543 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:42:23.898074 ops/training.py:65 2019-01-16 19:42:23.897982: step 250, loss = 0.77616 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:42:24.788491 ops/training.py:65 2019-01-16 19:42:24.788426: step 251, loss = 0.77503 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:42:25.677268 ops/training.py:65 2019-01-16 19:42:25.677207: step 252, loss = 0.83210 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:42:26.566805 ops/training.py:65 2019-01-16 19:42:26.566739: step 253, loss = 0.84452 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:42:27.456821 ops/training.py:65 2019-01-16 19:42:27.456737: step 254, loss = 0.69537 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:42:28.348680 ops/training.py:65 2019-01-16 19:42:28.348595: step 255, loss = 0.80387 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:42:29.238036 ops/training.py:65 2019-01-16 19:42:29.237964: step 256, loss = 0.74578 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:42:30.129510 ops/training.py:65 2019-01-16 19:42:30.129433: step 257, loss = 0.76463 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:42:31.019890 ops/training.py:65 2019-01-16 19:42:31.019818: step 258, loss = 0.72142 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:42:31.909616 ops/training.py:65 2019-01-16 19:42:31.909537: step 259, loss = 0.85341 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:42:32.801068 ops/training.py:65 2019-01-16 19:42:32.800991: step 260, loss = 0.82559 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:42:33.690514 ops/training.py:65 2019-01-16 19:42:33.690439: step 261, loss = 0.91624 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 19:42:34.581402 ops/training.py:65 2019-01-16 19:42:34.581323: step 262, loss = 0.72364 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:42:35.472306 ops/training.py:65 2019-01-16 19:42:35.472225: step 263, loss = 0.86121 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:42:36.362089 ops/training.py:65 2019-01-16 19:42:36.362011: step 264, loss = 0.79174 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:42:37.251708 ops/training.py:65 2019-01-16 19:42:37.251634: step 265, loss = 0.85381 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:42:38.141740 ops/training.py:65 2019-01-16 19:42:38.141664: step 266, loss = 0.76728 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:42:39.031375 ops/training.py:65 2019-01-16 19:42:39.031299: step 267, loss = 0.75593 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:42:39.921737 ops/training.py:65 2019-01-16 19:42:39.921662: step 268, loss = 0.79516 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:42:40.812870 ops/training.py:65 2019-01-16 19:42:40.812795: step 269, loss = 0.61458 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 19:42:41.703354 ops/training.py:65 2019-01-16 19:42:41.703278: step 270, loss = 0.85420 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:42:42.594232 ops/training.py:65 2019-01-16 19:42:42.594159: step 271, loss = 0.79196 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:42:43.485261 ops/training.py:65 2019-01-16 19:42:43.485180: step 272, loss = 0.80536 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:42:44.374672 ops/training.py:65 2019-01-16 19:42:44.374591: step 273, loss = 0.78464 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:42:45.265029 ops/training.py:65 2019-01-16 19:42:45.264960: step 274, loss = 0.62217 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:42:46.155657 ops/training.py:65 2019-01-16 19:42:46.155579: step 275, loss = 0.78338 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:42:47.045952 ops/training.py:65 2019-01-16 19:42:47.045876: step 276, loss = 0.85596 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:42:47.935366 ops/training.py:65 2019-01-16 19:42:47.935287: step 277, loss = 0.84819 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:42:48.825440 ops/training.py:65 2019-01-16 19:42:48.825361: step 278, loss = 0.76062 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:42:49.714996 ops/training.py:65 2019-01-16 19:42:49.714921: step 279, loss = 0.82181 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:42:50.605902 ops/training.py:65 2019-01-16 19:42:50.605830: step 280, loss = 0.73134 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:42:51.497120 ops/training.py:65 2019-01-16 19:42:51.497042: step 281, loss = 0.79680 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:42:52.386866 ops/training.py:65 2019-01-16 19:42:52.386791: step 282, loss = 0.73937 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:42:53.277933 ops/training.py:65 2019-01-16 19:42:53.277854: step 283, loss = 0.66389 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:42:54.168868 ops/training.py:65 2019-01-16 19:42:54.168793: step 284, loss = 0.72121 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:42:55.059591 ops/training.py:65 2019-01-16 19:42:55.059514: step 285, loss = 0.88617 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:42:55.952716 ops/training.py:65 2019-01-16 19:42:55.952636: step 286, loss = 0.78802 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:42:56.842892 ops/training.py:65 2019-01-16 19:42:56.842809: step 287, loss = 0.82866 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:42:57.733103 ops/training.py:65 2019-01-16 19:42:57.733033: step 288, loss = 0.68968 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:42:58.622873 ops/training.py:65 2019-01-16 19:42:58.622799: step 289, loss = 0.78750 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:42:59.513171 ops/training.py:65 2019-01-16 19:42:59.513096: step 290, loss = 0.80267 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:43:00.403429 ops/training.py:65 2019-01-16 19:43:00.403355: step 291, loss = 0.76552 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:43:01.294696 ops/training.py:65 2019-01-16 19:43:01.294619: step 292, loss = 0.74923 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:43:02.185306 ops/training.py:65 2019-01-16 19:43:02.185231: step 293, loss = 0.80352 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:43:03.074879 ops/training.py:65 2019-01-16 19:43:03.074801: step 294, loss = 0.75519 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:43:03.965864 ops/training.py:65 2019-01-16 19:43:03.965786: step 295, loss = 0.80329 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:43:04.856817 ops/training.py:65 2019-01-16 19:43:04.856741: step 296, loss = 0.85520 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:43:05.747716 ops/training.py:65 2019-01-16 19:43:05.747637: step 297, loss = 0.75356 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:43:06.638648 ops/training.py:65 2019-01-16 19:43:06.638563: step 298, loss = 0.80422 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:43:07.529375 ops/training.py:65 2019-01-16 19:43:07.529294: step 299, loss = 0.85779 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:43:08.418832 ops/training.py:65 2019-01-16 19:43:08.418756: step 300, loss = 0.89138 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:43:09.309649 ops/training.py:65 2019-01-16 19:43:09.309570: step 301, loss = 0.76522 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:43:10.200101 ops/training.py:65 2019-01-16 19:43:10.200020: step 302, loss = 0.79911 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:43:11.090675 ops/training.py:65 2019-01-16 19:43:11.090595: step 303, loss = 0.89883 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:43:11.980707 ops/training.py:65 2019-01-16 19:43:11.980626: step 304, loss = 0.79922 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:43:12.870681 ops/training.py:65 2019-01-16 19:43:12.870599: step 305, loss = 0.75407 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:43:13.761919 ops/training.py:65 2019-01-16 19:43:13.761847: step 306, loss = 1.03920 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:43:14.651666 ops/training.py:65 2019-01-16 19:43:14.651594: step 307, loss = 0.83301 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:43:15.542620 ops/training.py:65 2019-01-16 19:43:15.542548: step 308, loss = 0.87376 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:43:16.434472 ops/training.py:65 2019-01-16 19:43:16.434395: step 309, loss = 0.77497 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:43:17.324710 ops/training.py:65 2019-01-16 19:43:17.324638: step 310, loss = 0.66908 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 19:43:18.215681 ops/training.py:65 2019-01-16 19:43:18.215607: step 311, loss = 0.97714 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:43:19.106540 ops/training.py:65 2019-01-16 19:43:19.106465: step 312, loss = 0.93632 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 19:43:19.996206 ops/training.py:65 2019-01-16 19:43:19.996130: step 313, loss = 0.70879 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:43:20.885578 ops/training.py:65 2019-01-16 19:43:20.885500: step 314, loss = 0.77898 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:43:21.775533 ops/training.py:65 2019-01-16 19:43:21.775465: step 315, loss = 0.85680 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:43:22.665558 ops/training.py:65 2019-01-16 19:43:22.665480: step 316, loss = 0.88755 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:43:23.555450 ops/training.py:65 2019-01-16 19:43:23.555375: step 317, loss = 0.77590 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:43:24.446244 ops/training.py:65 2019-01-16 19:43:24.446166: step 318, loss = 0.66326 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 19:43:25.337540 ops/training.py:65 2019-01-16 19:43:25.337463: step 319, loss = 0.76719 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:43:26.228602 ops/training.py:65 2019-01-16 19:43:26.228536: step 320, loss = 0.78244 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:43:27.118692 ops/training.py:65 2019-01-16 19:43:27.118618: step 321, loss = 0.62569 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:43:28.009146 ops/training.py:65 2019-01-16 19:43:28.009072: step 322, loss = 0.71820 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:43:28.899173 ops/training.py:65 2019-01-16 19:43:28.899103: step 323, loss = 0.77528 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:43:29.790127 ops/training.py:65 2019-01-16 19:43:29.790054: step 324, loss = 0.74653 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:43:30.679620 ops/training.py:65 2019-01-16 19:43:30.679541: step 325, loss = 0.69583 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:43:31.570473 ops/training.py:65 2019-01-16 19:43:31.570394: step 326, loss = 0.75047 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:43:32.460592 ops/training.py:65 2019-01-16 19:43:32.460517: step 327, loss = 0.71902 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:43:33.350244 ops/training.py:65 2019-01-16 19:43:33.350149: step 328, loss = 0.70061 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:43:34.240949 ops/training.py:65 2019-01-16 19:43:34.240868: step 329, loss = 0.74789 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:43:35.131292 ops/training.py:65 2019-01-16 19:43:35.131222: step 330, loss = 0.80448 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:43:36.022395 ops/training.py:65 2019-01-16 19:43:36.022318: step 331, loss = 0.80382 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:43:36.912679 ops/training.py:65 2019-01-16 19:43:36.912604: step 332, loss = 0.71350 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:43:37.803473 ops/training.py:65 2019-01-16 19:43:37.803397: step 333, loss = 0.70194 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:43:38.695262 ops/training.py:65 2019-01-16 19:43:38.695183: step 334, loss = 0.88263 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 19:43:39.587014 ops/training.py:65 2019-01-16 19:43:39.586939: step 335, loss = 0.72974 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:43:40.477648 ops/training.py:65 2019-01-16 19:43:40.477571: step 336, loss = 0.67690 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:43:41.367748 ops/training.py:65 2019-01-16 19:43:41.367678: step 337, loss = 0.75776 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:43:42.257082 ops/training.py:65 2019-01-16 19:43:42.257014: step 338, loss = 0.70095 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:43:43.147436 ops/training.py:65 2019-01-16 19:43:43.147366: step 339, loss = 0.75735 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:43:44.037851 ops/training.py:65 2019-01-16 19:43:44.037786: step 340, loss = 0.64705 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:43:44.928713 ops/training.py:65 2019-01-16 19:43:44.928623: step 341, loss = 0.73919 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:43:45.818214 ops/training.py:65 2019-01-16 19:43:45.818150: step 342, loss = 0.88479 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:43:46.708615 ops/training.py:65 2019-01-16 19:43:46.708541: step 343, loss = 0.68726 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:43:47.598170 ops/training.py:65 2019-01-16 19:43:47.598088: step 344, loss = 0.85288 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:43:48.490788 ops/training.py:65 2019-01-16 19:43:48.490707: step 345, loss = 0.70425 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:43:49.381316 ops/training.py:65 2019-01-16 19:43:49.381238: step 346, loss = 0.76749 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:43:50.270738 ops/training.py:65 2019-01-16 19:43:50.270665: step 347, loss = 0.78231 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:43:51.161894 ops/training.py:65 2019-01-16 19:43:51.161818: step 348, loss = 0.72597 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:43:52.051694 ops/training.py:65 2019-01-16 19:43:52.051630: step 349, loss = 0.74758 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:43:52.941145 ops/training.py:65 2019-01-16 19:43:52.941079: step 350, loss = 0.63284 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:43:53.830720 ops/training.py:65 2019-01-16 19:43:53.830652: step 351, loss = 0.74940 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:43:54.720266 ops/training.py:65 2019-01-16 19:43:54.720192: step 352, loss = 0.61920 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 19:43:55.611863 ops/training.py:65 2019-01-16 19:43:55.611785: step 353, loss = 0.67895 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:43:56.502312 ops/training.py:65 2019-01-16 19:43:56.502237: step 354, loss = 0.84183 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:43:57.393963 ops/training.py:65 2019-01-16 19:43:57.393892: step 355, loss = 0.73198 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:43:58.285317 ops/training.py:65 2019-01-16 19:43:58.285236: step 356, loss = 0.80759 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:43:59.175259 ops/training.py:65 2019-01-16 19:43:59.175186: step 357, loss = 0.73433 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:44:00.066457 ops/training.py:65 2019-01-16 19:44:00.066385: step 358, loss = 0.68034 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:44:00.955962 ops/training.py:65 2019-01-16 19:44:00.955893: step 359, loss = 0.68809 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:44:01.845883 ops/training.py:65 2019-01-16 19:44:01.845819: step 360, loss = 0.84894 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:44:02.736008 ops/training.py:65 2019-01-16 19:44:02.735936: step 361, loss = 0.65655 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:44:03.625875 ops/training.py:65 2019-01-16 19:44:03.625798: step 362, loss = 0.70172 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:44:04.515530 ops/training.py:65 2019-01-16 19:44:04.515458: step 363, loss = 0.84463 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:44:05.406086 ops/training.py:65 2019-01-16 19:44:05.406013: step 364, loss = 0.76221 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:44:06.295345 ops/training.py:65 2019-01-16 19:44:06.295267: step 365, loss = 0.73700 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:44:07.185647 ops/training.py:65 2019-01-16 19:44:07.185576: step 366, loss = 0.66449 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:44:08.076787 ops/training.py:65 2019-01-16 19:44:08.076711: step 367, loss = 0.66438 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:44:08.967307 ops/training.py:65 2019-01-16 19:44:08.967234: step 368, loss = 0.72533 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:44:09.857973 ops/training.py:65 2019-01-16 19:44:09.857903: step 369, loss = 0.71351 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:44:10.748009 ops/training.py:65 2019-01-16 19:44:10.747942: step 370, loss = 0.72047 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:44:11.638426 ops/training.py:65 2019-01-16 19:44:11.638356: step 371, loss = 0.75767 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:44:12.529049 ops/training.py:65 2019-01-16 19:44:12.528977: step 372, loss = 0.76247 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:44:13.419318 ops/training.py:65 2019-01-16 19:44:13.419238: step 373, loss = 0.80642 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:44:14.309848 ops/training.py:65 2019-01-16 19:44:14.309784: step 374, loss = 0.76528 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:44:15.201196 ops/training.py:65 2019-01-16 19:44:15.201125: step 375, loss = 0.75736 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:44:16.090820 ops/training.py:65 2019-01-16 19:44:16.090746: step 376, loss = 0.70288 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:44:16.980617 ops/training.py:65 2019-01-16 19:44:16.980545: step 377, loss = 0.70921 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:44:17.871504 ops/training.py:65 2019-01-16 19:44:17.871428: step 378, loss = 0.67325 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:44:18.760979 ops/training.py:65 2019-01-16 19:44:18.760900: step 379, loss = 0.76578 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:44:19.651119 ops/training.py:65 2019-01-16 19:44:19.651044: step 380, loss = 0.73209 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:44:20.541375 ops/training.py:65 2019-01-16 19:44:20.541300: step 381, loss = 0.76482 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:44:21.432304 ops/training.py:65 2019-01-16 19:44:21.432231: step 382, loss = 0.69551 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:44:22.323445 ops/training.py:65 2019-01-16 19:44:22.323367: step 383, loss = 0.66541 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:44:23.213913 ops/training.py:65 2019-01-16 19:44:23.213831: step 384, loss = 0.69732 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:44:24.103987 ops/training.py:65 2019-01-16 19:44:24.103922: step 385, loss = 0.71848 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:44:24.993358 ops/training.py:65 2019-01-16 19:44:24.993292: step 386, loss = 0.77442 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:44:25.883253 ops/training.py:65 2019-01-16 19:44:25.883180: step 387, loss = 0.72824 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:44:26.772991 ops/training.py:65 2019-01-16 19:44:26.772922: step 388, loss = 0.74242 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:44:27.663386 ops/training.py:65 2019-01-16 19:44:27.663294: step 389, loss = 0.75739 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:44:28.553880 ops/training.py:65 2019-01-16 19:44:28.553808: step 390, loss = 0.67335 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:44:29.443899 ops/training.py:65 2019-01-16 19:44:29.443832: step 391, loss = 0.74255 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:44:30.333282 ops/training.py:65 2019-01-16 19:44:30.333212: step 392, loss = 0.74836 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:44:31.221941 ops/training.py:65 2019-01-16 19:44:31.221866: step 393, loss = 0.77768 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:44:32.112176 ops/training.py:65 2019-01-16 19:44:32.112102: step 394, loss = 0.72696 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:44:33.003068 ops/training.py:65 2019-01-16 19:44:33.002991: step 395, loss = 0.71264 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:44:33.893398 ops/training.py:65 2019-01-16 19:44:33.893329: step 396, loss = 0.81758 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 19:44:34.782986 ops/training.py:65 2019-01-16 19:44:34.782884: step 397, loss = 0.74128 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:44:35.674976 ops/training.py:65 2019-01-16 19:44:35.674873: step 398, loss = 0.72349 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:44:36.565746 ops/training.py:65 2019-01-16 19:44:36.565666: step 399, loss = 0.68744 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:44:37.458292 ops/training.py:65 2019-01-16 19:44:37.458215: step 400, loss = 0.81114 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:44:38.347743 ops/training.py:65 2019-01-16 19:44:38.347663: step 401, loss = 0.65411 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:44:39.238553 ops/training.py:65 2019-01-16 19:44:39.238478: step 402, loss = 0.67423 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:44:40.128266 ops/training.py:65 2019-01-16 19:44:40.128185: step 403, loss = 0.74602 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:44:41.018154 ops/training.py:65 2019-01-16 19:44:41.018074: step 404, loss = 0.72462 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:44:41.908605 ops/training.py:65 2019-01-16 19:44:41.908536: step 405, loss = 0.75265 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:44:42.799467 ops/training.py:65 2019-01-16 19:44:42.799385: step 406, loss = 0.75551 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:44:43.689320 ops/training.py:65 2019-01-16 19:44:43.689247: step 407, loss = 0.64870 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:44:44.579629 ops/training.py:65 2019-01-16 19:44:44.579557: step 408, loss = 0.76058 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:44:45.469774 ops/training.py:65 2019-01-16 19:44:45.469703: step 409, loss = 0.72516 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:44:46.358768 ops/training.py:65 2019-01-16 19:44:46.358693: step 410, loss = 0.69263 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:44:47.248331 ops/training.py:65 2019-01-16 19:44:47.248248: step 411, loss = 0.69382 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:44:48.138196 ops/training.py:65 2019-01-16 19:44:48.138115: step 412, loss = 0.67679 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:44:49.029269 ops/training.py:65 2019-01-16 19:44:49.029190: step 413, loss = 0.69403 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:44:49.920781 ops/training.py:65 2019-01-16 19:44:49.920705: step 414, loss = 0.70293 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:44:50.811106 ops/training.py:65 2019-01-16 19:44:50.811034: step 415, loss = 0.66036 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:44:51.701966 ops/training.py:65 2019-01-16 19:44:51.701898: step 416, loss = 0.72315 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:44:52.592856 ops/training.py:65 2019-01-16 19:44:52.592785: step 417, loss = 0.72536 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:44:53.482835 ops/training.py:65 2019-01-16 19:44:53.482759: step 418, loss = 0.70281 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:44:54.372827 ops/training.py:65 2019-01-16 19:44:54.372757: step 419, loss = 0.71865 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:44:55.264221 ops/training.py:65 2019-01-16 19:44:55.264151: step 420, loss = 0.73554 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:44:56.154033 ops/training.py:65 2019-01-16 19:44:56.153965: step 421, loss = 0.74701 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:44:57.044289 ops/training.py:65 2019-01-16 19:44:57.044222: step 422, loss = 0.75386 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:44:57.934228 ops/training.py:65 2019-01-16 19:44:57.934155: step 423, loss = 0.64360 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:44:58.825396 ops/training.py:65 2019-01-16 19:44:58.825321: step 424, loss = 0.70354 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:44:59.715758 ops/training.py:65 2019-01-16 19:44:59.715690: step 425, loss = 0.76543 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:45:00.605414 ops/training.py:65 2019-01-16 19:45:00.605343: step 426, loss = 0.70378 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:45:01.495451 ops/training.py:65 2019-01-16 19:45:01.495378: step 427, loss = 0.70965 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:45:02.384557 ops/training.py:65 2019-01-16 19:45:02.384487: step 428, loss = 0.73181 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:45:03.274157 ops/training.py:65 2019-01-16 19:45:03.274082: step 429, loss = 0.79179 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:45:04.163771 ops/training.py:65 2019-01-16 19:45:04.163703: step 430, loss = 0.72302 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:45:05.052573 ops/training.py:65 2019-01-16 19:45:05.052505: step 431, loss = 0.74756 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:45:05.942799 ops/training.py:65 2019-01-16 19:45:05.942719: step 432, loss = 0.69044 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:45:06.834187 ops/training.py:65 2019-01-16 19:45:06.834109: step 433, loss = 0.76262 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:45:07.724288 ops/training.py:65 2019-01-16 19:45:07.724212: step 434, loss = 0.74664 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:45:08.615704 ops/training.py:65 2019-01-16 19:45:08.615629: step 435, loss = 0.74157 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:45:09.506456 ops/training.py:65 2019-01-16 19:45:09.506376: step 436, loss = 0.75005 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:45:10.396494 ops/training.py:65 2019-01-16 19:45:10.396421: step 437, loss = 0.68554 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:45:11.286925 ops/training.py:65 2019-01-16 19:45:11.286848: step 438, loss = 0.69382 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:45:12.178196 ops/training.py:65 2019-01-16 19:45:12.178102: step 439, loss = 0.71841 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:45:13.067897 ops/training.py:65 2019-01-16 19:45:13.067823: step 440, loss = 0.72940 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:45:13.960509 ops/training.py:65 2019-01-16 19:45:13.960430: step 441, loss = 0.74689 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:45:14.850609 ops/training.py:65 2019-01-16 19:45:14.850533: step 442, loss = 0.59214 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.75
I2992 2019-01-16 19:45:15.740174 ops/training.py:65 2019-01-16 19:45:15.740109: step 443, loss = 0.63196 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:45:16.631064 ops/training.py:65 2019-01-16 19:45:16.630987: step 444, loss = 0.71984 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:45:17.521754 ops/training.py:65 2019-01-16 19:45:17.521682: step 445, loss = 0.83633 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 19:45:18.413564 ops/training.py:65 2019-01-16 19:45:18.413487: step 446, loss = 0.67410 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:45:19.304285 ops/training.py:65 2019-01-16 19:45:19.304212: step 447, loss = 0.66639 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:45:20.195586 ops/training.py:65 2019-01-16 19:45:20.195516: step 448, loss = 0.71383 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:45:21.085033 ops/training.py:65 2019-01-16 19:45:21.084957: step 449, loss = 0.75293 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:45:21.975960 ops/training.py:65 2019-01-16 19:45:21.975889: step 450, loss = 0.72249 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:45:22.865441 ops/training.py:65 2019-01-16 19:45:22.865360: step 451, loss = 0.68454 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:45:23.756097 ops/training.py:65 2019-01-16 19:45:23.756021: step 452, loss = 0.78025 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:45:24.645847 ops/training.py:65 2019-01-16 19:45:24.645763: step 453, loss = 0.66678 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:45:25.535753 ops/training.py:65 2019-01-16 19:45:25.535675: step 454, loss = 0.69158 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:45:26.426062 ops/training.py:65 2019-01-16 19:45:26.425989: step 455, loss = 0.70850 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:45:27.315816 ops/training.py:65 2019-01-16 19:45:27.315740: step 456, loss = 0.73805 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:45:28.205849 ops/training.py:65 2019-01-16 19:45:28.205768: step 457, loss = 0.74354 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:45:29.094887 ops/training.py:65 2019-01-16 19:45:29.094811: step 458, loss = 0.74740 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:45:29.984768 ops/training.py:65 2019-01-16 19:45:29.984690: step 459, loss = 0.67264 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:45:30.875679 ops/training.py:65 2019-01-16 19:45:30.875605: step 460, loss = 0.80070 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 19:45:31.766034 ops/training.py:65 2019-01-16 19:45:31.765958: step 461, loss = 0.67868 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:45:32.657151 ops/training.py:65 2019-01-16 19:45:32.657074: step 462, loss = 0.81811 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.25
I2992 2019-01-16 19:45:33.546925 ops/training.py:65 2019-01-16 19:45:33.546849: step 463, loss = 0.80732 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:45:34.436354 ops/training.py:65 2019-01-16 19:45:34.436283: step 464, loss = 0.74549 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:45:35.325785 ops/training.py:65 2019-01-16 19:45:35.325706: step 465, loss = 0.62494 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 19:45:36.216173 ops/training.py:65 2019-01-16 19:45:36.216093: step 466, loss = 0.66608 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:45:37.105635 ops/training.py:65 2019-01-16 19:45:37.105556: step 467, loss = 0.67148 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:45:37.996439 ops/training.py:65 2019-01-16 19:45:37.996359: step 468, loss = 0.76766 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:45:38.887566 ops/training.py:65 2019-01-16 19:45:38.887485: step 469, loss = 0.66237 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:45:39.777288 ops/training.py:65 2019-01-16 19:45:39.777205: step 470, loss = 0.73097 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:45:40.666964 ops/training.py:65 2019-01-16 19:45:40.666893: step 471, loss = 0.71491 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:45:41.556528 ops/training.py:65 2019-01-16 19:45:41.556457: step 472, loss = 0.61538 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:45:42.447965 ops/training.py:65 2019-01-16 19:45:42.447891: step 473, loss = 0.73481 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:45:43.338116 ops/training.py:65 2019-01-16 19:45:43.338034: step 474, loss = 0.73100 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:45:44.229694 ops/training.py:65 2019-01-16 19:45:44.229620: step 475, loss = 0.70879 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:45:45.119491 ops/training.py:65 2019-01-16 19:45:45.119413: step 476, loss = 0.77458 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:45:46.010565 ops/training.py:65 2019-01-16 19:45:46.010490: step 477, loss = 0.76505 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:45:46.901700 ops/training.py:65 2019-01-16 19:45:46.901619: step 478, loss = 0.66131 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 19:45:47.792350 ops/training.py:65 2019-01-16 19:45:47.792273: step 479, loss = 0.73267 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:45:48.683259 ops/training.py:65 2019-01-16 19:45:48.683190: step 480, loss = 0.64189 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:45:49.573434 ops/training.py:65 2019-01-16 19:45:49.573360: step 481, loss = 0.78499 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:45:50.464015 ops/training.py:65 2019-01-16 19:45:50.463943: step 482, loss = 0.71619 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:45:51.354908 ops/training.py:65 2019-01-16 19:45:51.354831: step 483, loss = 0.68159 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:45:52.245201 ops/training.py:65 2019-01-16 19:45:52.245127: step 484, loss = 0.81475 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:45:53.135042 ops/training.py:65 2019-01-16 19:45:53.134966: step 485, loss = 0.79651 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:45:54.026201 ops/training.py:65 2019-01-16 19:45:54.026124: step 486, loss = 0.80681 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:45:54.916754 ops/training.py:65 2019-01-16 19:45:54.916685: step 487, loss = 0.79056 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:45:55.807760 ops/training.py:65 2019-01-16 19:45:55.807690: step 488, loss = 0.68755 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:45:56.699010 ops/training.py:65 2019-01-16 19:45:56.698939: step 489, loss = 0.70331 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:45:57.589518 ops/training.py:65 2019-01-16 19:45:57.589450: step 490, loss = 0.79678 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:45:58.479432 ops/training.py:65 2019-01-16 19:45:58.479359: step 491, loss = 0.65479 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:45:59.369524 ops/training.py:65 2019-01-16 19:45:59.369454: step 492, loss = 0.70874 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:46:00.259564 ops/training.py:65 2019-01-16 19:46:00.259493: step 493, loss = 0.70970 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:46:01.150129 ops/training.py:65 2019-01-16 19:46:01.150055: step 494, loss = 0.78805 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:46:02.039480 ops/training.py:65 2019-01-16 19:46:02.039408: step 495, loss = 0.58142 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.78125
I2992 2019-01-16 19:46:02.929727 ops/training.py:65 2019-01-16 19:46:02.929650: step 496, loss = 0.72906 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:46:03.819468 ops/training.py:65 2019-01-16 19:46:03.819398: step 497, loss = 0.71428 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:46:04.710463 ops/training.py:65 2019-01-16 19:46:04.710389: step 498, loss = 0.80582 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:46:05.600093 ops/training.py:65 2019-01-16 19:46:05.600017: step 499, loss = 0.85218 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:46:06.489835 ops/training.py:65 2019-01-16 19:46:06.489756: step 500, loss = 0.72488 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:46:07.379212 ops/training.py:65 2019-01-16 19:46:07.379135: step 501, loss = 0.65930 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:46:08.268056 ops/training.py:65 2019-01-16 19:46:08.267976: step 502, loss = 0.84578 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 19:46:09.158606 ops/training.py:65 2019-01-16 19:46:09.158529: step 503, loss = 0.70655 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:46:10.048835 ops/training.py:65 2019-01-16 19:46:10.048752: step 504, loss = 0.81303 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:46:10.939050 ops/training.py:65 2019-01-16 19:46:10.938973: step 505, loss = 0.75763 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:46:11.829851 ops/training.py:65 2019-01-16 19:46:11.829767: step 506, loss = 0.76127 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:46:12.721242 ops/training.py:65 2019-01-16 19:46:12.721162: step 507, loss = 0.77259 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:46:13.611328 ops/training.py:65 2019-01-16 19:46:13.611229: step 508, loss = 0.77571 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:46:14.501979 ops/training.py:65 2019-01-16 19:46:14.501897: step 509, loss = 0.73975 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:46:15.391754 ops/training.py:65 2019-01-16 19:46:15.391683: step 510, loss = 0.66470 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:46:16.282267 ops/training.py:65 2019-01-16 19:46:16.282199: step 511, loss = 0.68179 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:46:17.172051 ops/training.py:65 2019-01-16 19:46:17.171982: step 512, loss = 0.71232 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:46:18.062922 ops/training.py:65 2019-01-16 19:46:18.062849: step 513, loss = 0.77797 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:46:18.953382 ops/training.py:65 2019-01-16 19:46:18.953306: step 514, loss = 0.69729 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:46:19.844806 ops/training.py:65 2019-01-16 19:46:19.844733: step 515, loss = 0.66766 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:46:20.734759 ops/training.py:65 2019-01-16 19:46:20.734688: step 516, loss = 0.78896 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:46:21.625472 ops/training.py:65 2019-01-16 19:46:21.625400: step 517, loss = 0.68411 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:46:22.516020 ops/training.py:65 2019-01-16 19:46:22.515952: step 518, loss = 0.68268 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:46:23.405331 ops/training.py:65 2019-01-16 19:46:23.405260: step 519, loss = 0.71486 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:46:24.294524 ops/training.py:65 2019-01-16 19:46:24.294456: step 520, loss = 0.78115 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:46:25.183989 ops/training.py:65 2019-01-16 19:46:25.183909: step 521, loss = 0.70717 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:46:26.072596 ops/training.py:65 2019-01-16 19:46:26.072536: step 522, loss = 0.65205 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:46:26.961750 ops/training.py:65 2019-01-16 19:46:26.961680: step 523, loss = 0.77628 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:46:27.850787 ops/training.py:65 2019-01-16 19:46:27.850713: step 524, loss = 0.63226 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 19:46:28.739229 ops/training.py:65 2019-01-16 19:46:28.739163: step 525, loss = 0.70481 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:46:29.629460 ops/training.py:65 2019-01-16 19:46:29.629385: step 526, loss = 0.73718 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:46:30.519288 ops/training.py:65 2019-01-16 19:46:30.519215: step 527, loss = 0.67614 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:46:31.409119 ops/training.py:65 2019-01-16 19:46:31.409035: step 528, loss = 0.81154 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:46:32.298596 ops/training.py:65 2019-01-16 19:46:32.298517: step 529, loss = 0.64777 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:46:33.188270 ops/training.py:65 2019-01-16 19:46:33.188195: step 530, loss = 0.68084 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:46:34.079617 ops/training.py:65 2019-01-16 19:46:34.079538: step 531, loss = 0.69754 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:46:34.970169 ops/training.py:65 2019-01-16 19:46:34.970095: step 532, loss = 0.77755 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:46:35.859623 ops/training.py:65 2019-01-16 19:46:35.859548: step 533, loss = 0.76510 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:46:36.748921 ops/training.py:65 2019-01-16 19:46:36.748845: step 534, loss = 0.70832 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:46:37.639695 ops/training.py:65 2019-01-16 19:46:37.639620: step 535, loss = 0.78670 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:46:38.528728 ops/training.py:65 2019-01-16 19:46:38.528654: step 536, loss = 0.73827 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:46:39.418656 ops/training.py:65 2019-01-16 19:46:39.418589: step 537, loss = 0.71346 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:46:40.308584 ops/training.py:65 2019-01-16 19:46:40.308494: step 538, loss = 0.74378 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:46:41.198531 ops/training.py:65 2019-01-16 19:46:41.198467: step 539, loss = 0.72781 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:46:42.088906 ops/training.py:65 2019-01-16 19:46:42.088841: step 540, loss = 0.67360 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 19:46:42.980032 ops/training.py:65 2019-01-16 19:46:42.979954: step 541, loss = 0.81040 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 19:46:43.870344 ops/training.py:65 2019-01-16 19:46:43.870276: step 542, loss = 0.73332 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:46:44.760607 ops/training.py:65 2019-01-16 19:46:44.760536: step 543, loss = 0.76776 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:46:45.650481 ops/training.py:65 2019-01-16 19:46:45.650394: step 544, loss = 0.68039 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:46:46.540645 ops/training.py:65 2019-01-16 19:46:46.540569: step 545, loss = 0.75627 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:46:47.431796 ops/training.py:65 2019-01-16 19:46:47.431716: step 546, loss = 0.66264 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:46:48.321607 ops/training.py:65 2019-01-16 19:46:48.321531: step 547, loss = 0.64566 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 19:46:49.212443 ops/training.py:65 2019-01-16 19:46:49.212374: step 548, loss = 0.72988 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:46:50.102315 ops/training.py:65 2019-01-16 19:46:50.102252: step 549, loss = 0.68088 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:46:50.993215 ops/training.py:65 2019-01-16 19:46:50.993141: step 550, loss = 0.71430 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:46:51.882830 ops/training.py:65 2019-01-16 19:46:51.882761: step 551, loss = 0.67278 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:46:52.772552 ops/training.py:65 2019-01-16 19:46:52.772480: step 552, loss = 0.75672 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:46:53.663086 ops/training.py:65 2019-01-16 19:46:53.663016: step 553, loss = 0.68356 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 19:46:54.552495 ops/training.py:65 2019-01-16 19:46:54.552427: step 554, loss = 0.80758 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:46:55.442332 ops/training.py:65 2019-01-16 19:46:55.442262: step 555, loss = 0.72742 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:46:56.332207 ops/training.py:65 2019-01-16 19:46:56.332145: step 556, loss = 0.71366 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:46:57.222577 ops/training.py:65 2019-01-16 19:46:57.222499: step 557, loss = 0.74007 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:46:58.113117 ops/training.py:65 2019-01-16 19:46:58.113049: step 558, loss = 0.69282 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:46:59.003910 ops/training.py:65 2019-01-16 19:46:59.003839: step 559, loss = 0.77638 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:46:59.894552 ops/training.py:65 2019-01-16 19:46:59.894483: step 560, loss = 0.63884 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:47:00.785524 ops/training.py:65 2019-01-16 19:47:00.785447: step 561, loss = 0.67628 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:47:01.676237 ops/training.py:65 2019-01-16 19:47:01.676159: step 562, loss = 0.77630 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:47:02.566352 ops/training.py:65 2019-01-16 19:47:02.566282: step 563, loss = 0.68521 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:47:03.457798 ops/training.py:65 2019-01-16 19:47:03.457724: step 564, loss = 0.71205 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:47:04.346891 ops/training.py:65 2019-01-16 19:47:04.346816: step 565, loss = 0.71297 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:47:05.236393 ops/training.py:65 2019-01-16 19:47:05.236313: step 566, loss = 0.73535 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:47:06.127489 ops/training.py:65 2019-01-16 19:47:06.127408: step 567, loss = 0.65699 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:47:07.017888 ops/training.py:65 2019-01-16 19:47:07.017811: step 568, loss = 0.70176 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:47:07.908529 ops/training.py:65 2019-01-16 19:47:07.908427: step 569, loss = 0.74898 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:47:08.800165 ops/training.py:65 2019-01-16 19:47:08.800063: step 570, loss = 0.69602 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:47:09.690299 ops/training.py:65 2019-01-16 19:47:09.690211: step 571, loss = 0.67379 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 19:47:10.580851 ops/training.py:65 2019-01-16 19:47:10.580750: step 572, loss = 0.73644 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:47:11.470208 ops/training.py:65 2019-01-16 19:47:11.470133: step 573, loss = 0.66696 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:47:12.360928 ops/training.py:65 2019-01-16 19:47:12.360850: step 574, loss = 0.66891 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:47:13.251685 ops/training.py:65 2019-01-16 19:47:13.251606: step 575, loss = 0.68411 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:47:14.143430 ops/training.py:65 2019-01-16 19:47:14.143351: step 576, loss = 0.70196 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:47:15.033612 ops/training.py:65 2019-01-16 19:47:15.033533: step 577, loss = 0.77775 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:47:15.926415 ops/training.py:65 2019-01-16 19:47:15.926341: step 578, loss = 0.69923 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:47:16.817089 ops/training.py:65 2019-01-16 19:47:16.817015: step 579, loss = 0.70101 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:47:17.706549 ops/training.py:65 2019-01-16 19:47:17.706473: step 580, loss = 0.68846 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:47:18.596001 ops/training.py:65 2019-01-16 19:47:18.595926: step 581, loss = 0.72369 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:47:19.485588 ops/training.py:65 2019-01-16 19:47:19.485511: step 582, loss = 0.73075 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:47:20.375652 ops/training.py:65 2019-01-16 19:47:20.375579: step 583, loss = 0.78877 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:47:21.266150 ops/training.py:65 2019-01-16 19:47:21.266079: step 584, loss = 0.63443 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 19:47:22.156948 ops/training.py:65 2019-01-16 19:47:22.156870: step 585, loss = 0.73460 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:47:23.047530 ops/training.py:65 2019-01-16 19:47:23.047462: step 586, loss = 0.73132 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:47:23.938307 ops/training.py:65 2019-01-16 19:47:23.938238: step 587, loss = 0.69777 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:47:24.828761 ops/training.py:65 2019-01-16 19:47:24.828688: step 588, loss = 0.69660 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:47:25.719664 ops/training.py:65 2019-01-16 19:47:25.719594: step 589, loss = 0.76652 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:47:26.610851 ops/training.py:65 2019-01-16 19:47:26.610780: step 590, loss = 0.62207 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 19:47:27.501787 ops/training.py:65 2019-01-16 19:47:27.501713: step 591, loss = 0.70826 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:47:28.392000 ops/training.py:65 2019-01-16 19:47:28.391925: step 592, loss = 0.69938 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:47:29.284471 ops/training.py:65 2019-01-16 19:47:29.284393: step 593, loss = 0.72315 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:47:30.175318 ops/training.py:65 2019-01-16 19:47:30.175247: step 594, loss = 0.73514 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:47:31.065082 ops/training.py:65 2019-01-16 19:47:31.065008: step 595, loss = 0.73927 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:47:31.955199 ops/training.py:65 2019-01-16 19:47:31.955118: step 596, loss = 0.62512 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 19:47:32.846578 ops/training.py:65 2019-01-16 19:47:32.846500: step 597, loss = 0.74585 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:47:33.738214 ops/training.py:65 2019-01-16 19:47:33.738138: step 598, loss = 0.72639 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:47:34.627979 ops/training.py:65 2019-01-16 19:47:34.627905: step 599, loss = 0.70672 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:47:35.518508 ops/training.py:65 2019-01-16 19:47:35.518439: step 600, loss = 0.70712 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:47:36.409588 ops/training.py:65 2019-01-16 19:47:36.409509: step 601, loss = 0.71432 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:47:37.300137 ops/training.py:65 2019-01-16 19:47:37.300037: step 602, loss = 0.68383 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:47:38.192303 ops/training.py:65 2019-01-16 19:47:38.192223: step 603, loss = 0.75504 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 19:47:39.082889 ops/training.py:65 2019-01-16 19:47:39.082798: step 604, loss = 0.74030 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:47:39.973557 ops/training.py:65 2019-01-16 19:47:39.973492: step 605, loss = 0.74854 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:47:40.863549 ops/training.py:65 2019-01-16 19:47:40.863478: step 606, loss = 0.74748 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:47:41.753141 ops/training.py:65 2019-01-16 19:47:41.753068: step 607, loss = 0.71356 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:47:42.643504 ops/training.py:65 2019-01-16 19:47:42.643435: step 608, loss = 0.72361 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:47:43.533083 ops/training.py:65 2019-01-16 19:47:43.533009: step 609, loss = 0.73347 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:47:44.423096 ops/training.py:65 2019-01-16 19:47:44.423029: step 610, loss = 0.73227 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:47:45.312627 ops/training.py:65 2019-01-16 19:47:45.312556: step 611, loss = 0.70573 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:47:46.203128 ops/training.py:65 2019-01-16 19:47:46.203054: step 612, loss = 0.66820 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:47:47.096014 ops/training.py:65 2019-01-16 19:47:47.095945: step 613, loss = 0.73926 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:47:47.985809 ops/training.py:65 2019-01-16 19:47:47.985711: step 614, loss = 0.65391 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:47:48.877435 ops/training.py:65 2019-01-16 19:47:48.877331: step 615, loss = 0.71774 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:47:49.769255 ops/training.py:65 2019-01-16 19:47:49.769152: step 616, loss = 0.71440 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:47:50.658763 ops/training.py:65 2019-01-16 19:47:50.658660: step 617, loss = 0.76359 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:47:51.548597 ops/training.py:65 2019-01-16 19:47:51.548496: step 618, loss = 0.75087 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:47:52.437920 ops/training.py:65 2019-01-16 19:47:52.437855: step 619, loss = 0.79968 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:47:53.328156 ops/training.py:65 2019-01-16 19:47:53.328086: step 620, loss = 0.68622 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:47:54.218502 ops/training.py:65 2019-01-16 19:47:54.218430: step 621, loss = 0.66074 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:47:55.107606 ops/training.py:65 2019-01-16 19:47:55.107535: step 622, loss = 0.72174 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:47:55.998068 ops/training.py:65 2019-01-16 19:47:55.998002: step 623, loss = 0.71817 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:47:56.889156 ops/training.py:65 2019-01-16 19:47:56.889088: step 624, loss = 0.70771 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:47:57.779323 ops/training.py:65 2019-01-16 19:47:57.779252: step 625, loss = 0.74767 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:47:58.669905 ops/training.py:65 2019-01-16 19:47:58.669835: step 626, loss = 0.67043 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:47:59.560651 ops/training.py:65 2019-01-16 19:47:59.560593: step 627, loss = 0.71489 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:48:00.451989 ops/training.py:65 2019-01-16 19:48:00.451923: step 628, loss = 0.75349 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:48:01.342953 ops/training.py:65 2019-01-16 19:48:01.342883: step 629, loss = 0.74308 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:48:02.234190 ops/training.py:65 2019-01-16 19:48:02.234119: step 630, loss = 0.65576 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:48:03.125693 ops/training.py:65 2019-01-16 19:48:03.125620: step 631, loss = 0.71541 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:48:04.015707 ops/training.py:65 2019-01-16 19:48:04.015634: step 632, loss = 0.68671 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:48:04.905141 ops/training.py:65 2019-01-16 19:48:04.905065: step 633, loss = 0.69100 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:48:05.794593 ops/training.py:65 2019-01-16 19:48:05.794518: step 634, loss = 0.69628 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:48:06.685543 ops/training.py:65 2019-01-16 19:48:06.685475: step 635, loss = 0.66957 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:48:07.575318 ops/training.py:65 2019-01-16 19:48:07.575244: step 636, loss = 0.68196 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:48:08.465182 ops/training.py:65 2019-01-16 19:48:08.465112: step 637, loss = 0.64777 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:48:09.355377 ops/training.py:65 2019-01-16 19:48:09.355306: step 638, loss = 0.74686 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:48:10.244575 ops/training.py:65 2019-01-16 19:48:10.244506: step 639, loss = 0.73068 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:48:11.134216 ops/training.py:65 2019-01-16 19:48:11.134143: step 640, loss = 0.71759 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:48:12.023426 ops/training.py:65 2019-01-16 19:48:12.023329: step 641, loss = 0.74051 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:48:12.913119 ops/training.py:65 2019-01-16 19:48:12.913023: step 642, loss = 0.65450 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:48:13.801941 ops/training.py:65 2019-01-16 19:48:13.801846: step 643, loss = 0.75007 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:48:14.690114 ops/training.py:65 2019-01-16 19:48:14.690023: step 644, loss = 0.66673 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:48:15.578810 ops/training.py:65 2019-01-16 19:48:15.578715: step 645, loss = 0.66079 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:48:16.468390 ops/training.py:65 2019-01-16 19:48:16.468319: step 646, loss = 0.72359 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:48:17.358497 ops/training.py:65 2019-01-16 19:48:17.358411: step 647, loss = 0.70616 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:48:18.247835 ops/training.py:65 2019-01-16 19:48:18.247767: step 648, loss = 0.71927 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:48:19.137743 ops/training.py:65 2019-01-16 19:48:19.137673: step 649, loss = 0.72587 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:48:20.027382 ops/training.py:65 2019-01-16 19:48:20.027314: step 650, loss = 0.68729 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:48:20.915665 ops/training.py:65 2019-01-16 19:48:20.915592: step 651, loss = 0.68659 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:48:21.804369 ops/training.py:65 2019-01-16 19:48:21.804295: step 652, loss = 0.77288 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:48:22.694985 ops/training.py:65 2019-01-16 19:48:22.694912: step 653, loss = 0.69314 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:48:23.584939 ops/training.py:65 2019-01-16 19:48:23.584861: step 654, loss = 0.66047 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:48:24.474359 ops/training.py:65 2019-01-16 19:48:24.474293: step 655, loss = 0.71216 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:48:25.364106 ops/training.py:65 2019-01-16 19:48:25.364030: step 656, loss = 0.67813 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:48:26.253687 ops/training.py:65 2019-01-16 19:48:26.253610: step 657, loss = 0.67921 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:48:27.144287 ops/training.py:65 2019-01-16 19:48:27.144207: step 658, loss = 0.73541 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:48:28.034960 ops/training.py:65 2019-01-16 19:48:28.034889: step 659, loss = 0.74165 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:48:28.925656 ops/training.py:65 2019-01-16 19:48:28.925577: step 660, loss = 0.69898 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:48:29.816500 ops/training.py:65 2019-01-16 19:48:29.816420: step 661, loss = 0.77703 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:48:30.705533 ops/training.py:65 2019-01-16 19:48:30.705458: step 662, loss = 0.73254 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:48:31.596389 ops/training.py:65 2019-01-16 19:48:31.596315: step 663, loss = 0.71184 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:48:32.488577 ops/training.py:65 2019-01-16 19:48:32.488491: step 664, loss = 0.68516 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:48:33.378758 ops/training.py:65 2019-01-16 19:48:33.378673: step 665, loss = 0.64916 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:48:34.268792 ops/training.py:65 2019-01-16 19:48:34.268719: step 666, loss = 0.66420 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:48:35.157871 ops/training.py:65 2019-01-16 19:48:35.157799: step 667, loss = 0.74533 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:48:36.048673 ops/training.py:65 2019-01-16 19:48:36.048600: step 668, loss = 0.69441 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:48:36.939726 ops/training.py:65 2019-01-16 19:48:36.939645: step 669, loss = 0.68944 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:48:37.829628 ops/training.py:65 2019-01-16 19:48:37.829548: step 670, loss = 0.66538 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 19:48:38.719951 ops/training.py:65 2019-01-16 19:48:38.719880: step 671, loss = 0.73695 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:48:39.611471 ops/training.py:65 2019-01-16 19:48:39.611389: step 672, loss = 0.74006 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:48:40.502221 ops/training.py:65 2019-01-16 19:48:40.502146: step 673, loss = 0.67147 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:48:41.393062 ops/training.py:65 2019-01-16 19:48:41.392988: step 674, loss = 0.68620 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:48:42.282142 ops/training.py:65 2019-01-16 19:48:42.282066: step 675, loss = 0.70987 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:48:43.173286 ops/training.py:65 2019-01-16 19:48:43.173208: step 676, loss = 0.66024 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:48:44.064094 ops/training.py:65 2019-01-16 19:48:44.064013: step 677, loss = 0.74207 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:48:44.955058 ops/training.py:65 2019-01-16 19:48:44.954984: step 678, loss = 0.71637 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:48:45.846338 ops/training.py:65 2019-01-16 19:48:45.846270: step 679, loss = 0.75891 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:48:46.736292 ops/training.py:65 2019-01-16 19:48:46.736217: step 680, loss = 0.76659 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:48:47.626423 ops/training.py:65 2019-01-16 19:48:47.626350: step 681, loss = 0.67293 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:48:48.516295 ops/training.py:65 2019-01-16 19:48:48.516223: step 682, loss = 0.71278 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:48:49.407019 ops/training.py:65 2019-01-16 19:48:49.406948: step 683, loss = 0.71440 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:48:50.296446 ops/training.py:65 2019-01-16 19:48:50.296375: step 684, loss = 0.69009 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:48:51.186673 ops/training.py:65 2019-01-16 19:48:51.186600: step 685, loss = 0.75647 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:48:52.077753 ops/training.py:65 2019-01-16 19:48:52.077676: step 686, loss = 0.74401 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:48:52.968814 ops/training.py:65 2019-01-16 19:48:52.968738: step 687, loss = 0.66950 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:48:53.858610 ops/training.py:65 2019-01-16 19:48:53.858532: step 688, loss = 0.71542 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:48:54.748332 ops/training.py:65 2019-01-16 19:48:54.748262: step 689, loss = 0.69404 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:48:55.638311 ops/training.py:65 2019-01-16 19:48:55.638240: step 690, loss = 0.66532 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:48:56.529607 ops/training.py:65 2019-01-16 19:48:56.529525: step 691, loss = 0.70213 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:48:57.420506 ops/training.py:65 2019-01-16 19:48:57.420430: step 692, loss = 0.64730 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:48:58.311711 ops/training.py:65 2019-01-16 19:48:58.311617: step 693, loss = 0.74514 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:48:59.202125 ops/training.py:65 2019-01-16 19:48:59.202051: step 694, loss = 0.80069 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 19:49:00.092398 ops/training.py:65 2019-01-16 19:49:00.092322: step 695, loss = 0.69789 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:49:00.982951 ops/training.py:65 2019-01-16 19:49:00.982877: step 696, loss = 0.69372 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:49:01.872501 ops/training.py:65 2019-01-16 19:49:01.872433: step 697, loss = 0.67772 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:49:02.762548 ops/training.py:65 2019-01-16 19:49:02.762475: step 698, loss = 0.74606 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:49:03.652449 ops/training.py:65 2019-01-16 19:49:03.652379: step 699, loss = 0.71392 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:49:04.541896 ops/training.py:65 2019-01-16 19:49:04.541826: step 700, loss = 0.76411 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:49:05.431913 ops/training.py:65 2019-01-16 19:49:05.431843: step 701, loss = 0.68812 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:49:06.322642 ops/training.py:65 2019-01-16 19:49:06.322572: step 702, loss = 0.69816 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:49:07.211734 ops/training.py:65 2019-01-16 19:49:07.211667: step 703, loss = 0.73854 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:49:08.102387 ops/training.py:65 2019-01-16 19:49:08.102316: step 704, loss = 0.70299 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:49:08.992739 ops/training.py:65 2019-01-16 19:49:08.992674: step 705, loss = 0.70147 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:49:09.882609 ops/training.py:65 2019-01-16 19:49:09.882543: step 706, loss = 0.69007 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:49:10.771645 ops/training.py:65 2019-01-16 19:49:10.771581: step 707, loss = 0.67299 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:49:11.660992 ops/training.py:65 2019-01-16 19:49:11.660922: step 708, loss = 0.78430 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:49:12.551533 ops/training.py:65 2019-01-16 19:49:12.551460: step 709, loss = 0.71063 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:49:13.442394 ops/training.py:65 2019-01-16 19:49:13.442317: step 710, loss = 0.81498 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:49:14.333675 ops/training.py:65 2019-01-16 19:49:14.333607: step 711, loss = 0.68879 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:49:15.224394 ops/training.py:65 2019-01-16 19:49:15.224324: step 712, loss = 0.62869 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:49:16.115375 ops/training.py:65 2019-01-16 19:49:16.115307: step 713, loss = 0.78022 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:49:17.005520 ops/training.py:65 2019-01-16 19:49:17.005454: step 714, loss = 0.72881 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:49:17.896426 ops/training.py:65 2019-01-16 19:49:17.896362: step 715, loss = 0.80135 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:49:18.787418 ops/training.py:65 2019-01-16 19:49:18.787351: step 716, loss = 0.73379 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:49:19.678871 ops/training.py:65 2019-01-16 19:49:19.678801: step 717, loss = 0.71496 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:49:20.568615 ops/training.py:65 2019-01-16 19:49:20.568542: step 718, loss = 0.78030 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:49:21.458107 ops/training.py:65 2019-01-16 19:49:21.458041: step 719, loss = 0.70190 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:49:22.347326 ops/training.py:65 2019-01-16 19:49:22.347259: step 720, loss = 0.69196 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:49:23.237002 ops/training.py:65 2019-01-16 19:49:23.236928: step 721, loss = 0.69691 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:49:24.127971 ops/training.py:65 2019-01-16 19:49:24.127901: step 722, loss = 0.70116 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:49:25.017379 ops/training.py:65 2019-01-16 19:49:25.017312: step 723, loss = 0.73191 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:49:25.906640 ops/training.py:65 2019-01-16 19:49:25.906569: step 724, loss = 0.69337 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:49:26.795793 ops/training.py:65 2019-01-16 19:49:26.795718: step 725, loss = 0.76762 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:49:27.687114 ops/training.py:65 2019-01-16 19:49:27.687034: step 726, loss = 0.72236 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:49:28.578262 ops/training.py:65 2019-01-16 19:49:28.578188: step 727, loss = 0.67739 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:49:29.467584 ops/training.py:65 2019-01-16 19:49:29.467509: step 728, loss = 0.64918 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 19:49:30.357540 ops/training.py:65 2019-01-16 19:49:30.357465: step 729, loss = 0.70272 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:49:31.248996 ops/training.py:65 2019-01-16 19:49:31.248918: step 730, loss = 0.70421 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:49:32.138261 ops/training.py:65 2019-01-16 19:49:32.138185: step 731, loss = 0.72616 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:49:33.029453 ops/training.py:65 2019-01-16 19:49:33.029378: step 732, loss = 0.66732 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:49:33.920163 ops/training.py:65 2019-01-16 19:49:33.920080: step 733, loss = 0.75321 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:49:34.809522 ops/training.py:65 2019-01-16 19:49:34.809446: step 734, loss = 0.70648 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:49:35.701632 ops/training.py:65 2019-01-16 19:49:35.701554: step 735, loss = 0.68921 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:49:36.592173 ops/training.py:65 2019-01-16 19:49:36.592092: step 736, loss = 0.74384 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:49:37.482278 ops/training.py:65 2019-01-16 19:49:37.482195: step 737, loss = 0.72745 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:49:38.374130 ops/training.py:65 2019-01-16 19:49:38.374049: step 738, loss = 0.72138 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:49:39.264606 ops/training.py:65 2019-01-16 19:49:39.264533: step 739, loss = 0.72624 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:49:40.154625 ops/training.py:65 2019-01-16 19:49:40.154548: step 740, loss = 0.63729 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:49:41.045244 ops/training.py:65 2019-01-16 19:49:41.045173: step 741, loss = 0.65310 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:49:41.935188 ops/training.py:65 2019-01-16 19:49:41.935114: step 742, loss = 0.66538 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:49:42.824344 ops/training.py:65 2019-01-16 19:49:42.824273: step 743, loss = 0.72990 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:49:43.714727 ops/training.py:65 2019-01-16 19:49:43.714651: step 744, loss = 0.72847 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:49:44.605456 ops/training.py:65 2019-01-16 19:49:44.605383: step 745, loss = 0.71536 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:49:45.495735 ops/training.py:65 2019-01-16 19:49:45.495663: step 746, loss = 0.71405 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:49:46.384984 ops/training.py:65 2019-01-16 19:49:46.384907: step 747, loss = 0.75045 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:49:47.274227 ops/training.py:65 2019-01-16 19:49:47.274150: step 748, loss = 0.70469 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:49:48.163925 ops/training.py:65 2019-01-16 19:49:48.163852: step 749, loss = 0.64954 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:49:49.054181 ops/training.py:65 2019-01-16 19:49:49.054116: step 750, loss = 0.69215 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:49:49.944106 ops/training.py:65 2019-01-16 19:49:49.944007: step 751, loss = 0.67664 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 19:49:50.835001 ops/training.py:65 2019-01-16 19:49:50.834924: step 752, loss = 0.74004 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:49:51.726409 ops/training.py:65 2019-01-16 19:49:51.726335: step 753, loss = 0.74866 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:49:52.616592 ops/training.py:65 2019-01-16 19:49:52.616519: step 754, loss = 0.74098 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:49:53.506999 ops/training.py:65 2019-01-16 19:49:53.506930: step 755, loss = 0.69072 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:49:54.395889 ops/training.py:65 2019-01-16 19:49:54.395819: step 756, loss = 0.75532 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:49:55.286755 ops/training.py:65 2019-01-16 19:49:55.286677: step 757, loss = 0.71753 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:49:56.176605 ops/training.py:65 2019-01-16 19:49:56.176532: step 758, loss = 0.71887 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:49:57.067664 ops/training.py:65 2019-01-16 19:49:57.067589: step 759, loss = 0.72000 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:49:57.957677 ops/training.py:65 2019-01-16 19:49:57.957596: step 760, loss = 0.77794 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:49:58.848915 ops/training.py:65 2019-01-16 19:49:58.848834: step 761, loss = 0.63823 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:49:59.740206 ops/training.py:65 2019-01-16 19:49:59.740128: step 762, loss = 0.80067 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:50:00.628576 ops/training.py:65 2019-01-16 19:50:00.628500: step 763, loss = 0.77649 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:50:01.519373 ops/training.py:65 2019-01-16 19:50:01.519298: step 764, loss = 0.74269 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:50:02.411770 ops/training.py:65 2019-01-16 19:50:02.411686: step 765, loss = 0.68959 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:50:03.303067 ops/training.py:65 2019-01-16 19:50:03.302985: step 766, loss = 0.70224 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:50:04.193901 ops/training.py:65 2019-01-16 19:50:04.193825: step 767, loss = 0.79248 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:50:05.083587 ops/training.py:65 2019-01-16 19:50:05.083510: step 768, loss = 0.70636 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:50:05.973592 ops/training.py:65 2019-01-16 19:50:05.973516: step 769, loss = 0.73219 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:50:06.862506 ops/training.py:65 2019-01-16 19:50:06.862426: step 770, loss = 0.73214 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:50:07.754562 ops/training.py:65 2019-01-16 19:50:07.754483: step 771, loss = 0.68473 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:50:08.643330 ops/training.py:65 2019-01-16 19:50:08.643250: step 772, loss = 0.67955 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:50:09.531474 ops/training.py:65 2019-01-16 19:50:09.531376: step 773, loss = 0.71935 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:50:10.419680 ops/training.py:65 2019-01-16 19:50:10.419588: step 774, loss = 0.76201 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:50:11.311172 ops/training.py:65 2019-01-16 19:50:11.311066: step 775, loss = 0.68327 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:50:12.203093 ops/training.py:65 2019-01-16 19:50:12.203016: step 776, loss = 0.77007 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:50:13.094139 ops/training.py:65 2019-01-16 19:50:13.094067: step 777, loss = 0.74307 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:50:13.983993 ops/training.py:65 2019-01-16 19:50:13.983920: step 778, loss = 0.64867 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:50:14.874891 ops/training.py:65 2019-01-16 19:50:14.874814: step 779, loss = 0.79966 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:50:15.765149 ops/training.py:65 2019-01-16 19:50:15.765077: step 780, loss = 0.72135 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:50:16.654938 ops/training.py:65 2019-01-16 19:50:16.654853: step 781, loss = 0.62902 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.75
I2992 2019-01-16 19:50:17.545147 ops/training.py:65 2019-01-16 19:50:17.545068: step 782, loss = 0.74329 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:50:18.435656 ops/training.py:65 2019-01-16 19:50:18.435581: step 783, loss = 0.68260 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:50:19.326192 ops/training.py:65 2019-01-16 19:50:19.326112: step 784, loss = 0.72743 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:50:20.217022 ops/training.py:65 2019-01-16 19:50:20.216946: step 785, loss = 0.71179 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:50:21.108090 ops/training.py:65 2019-01-16 19:50:21.108019: step 786, loss = 0.73619 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:50:21.999171 ops/training.py:65 2019-01-16 19:50:21.999095: step 787, loss = 0.72314 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:50:22.890132 ops/training.py:65 2019-01-16 19:50:22.890059: step 788, loss = 0.73759 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:50:23.781375 ops/training.py:65 2019-01-16 19:50:23.781301: step 789, loss = 0.75208 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 19:50:24.672646 ops/training.py:65 2019-01-16 19:50:24.672580: step 790, loss = 0.67718 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:50:25.562840 ops/training.py:65 2019-01-16 19:50:25.562769: step 791, loss = 0.68814 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:50:26.452975 ops/training.py:65 2019-01-16 19:50:26.452906: step 792, loss = 0.72641 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:50:27.344527 ops/training.py:65 2019-01-16 19:50:27.344447: step 793, loss = 0.71406 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:50:28.234602 ops/training.py:65 2019-01-16 19:50:28.234522: step 794, loss = 0.71224 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:50:29.124494 ops/training.py:65 2019-01-16 19:50:29.124418: step 795, loss = 0.69287 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:50:30.014224 ops/training.py:65 2019-01-16 19:50:30.014149: step 796, loss = 0.74350 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:50:30.903049 ops/training.py:65 2019-01-16 19:50:30.902988: step 797, loss = 0.72128 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:50:31.794271 ops/training.py:65 2019-01-16 19:50:31.794216: step 798, loss = 0.67093 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:50:32.685484 ops/training.py:65 2019-01-16 19:50:32.685411: step 799, loss = 0.74676 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:50:33.576512 ops/training.py:65 2019-01-16 19:50:33.576431: step 800, loss = 0.67130 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:50:34.466701 ops/training.py:65 2019-01-16 19:50:34.466625: step 801, loss = 0.70857 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:50:35.357549 ops/training.py:65 2019-01-16 19:50:35.357468: step 802, loss = 0.69251 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:50:36.246576 ops/training.py:65 2019-01-16 19:50:36.246495: step 803, loss = 0.68996 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:50:37.135473 ops/training.py:65 2019-01-16 19:50:37.135380: step 804, loss = 0.70633 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:50:38.025258 ops/training.py:65 2019-01-16 19:50:38.025174: step 805, loss = 0.70385 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:50:38.914208 ops/training.py:65 2019-01-16 19:50:38.914115: step 806, loss = 0.71081 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:50:39.802568 ops/training.py:65 2019-01-16 19:50:39.802474: step 807, loss = 0.76318 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:50:40.691827 ops/training.py:65 2019-01-16 19:50:40.691727: step 808, loss = 0.73307 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:50:41.581313 ops/training.py:65 2019-01-16 19:50:41.581212: step 809, loss = 0.68662 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:50:42.471312 ops/training.py:65 2019-01-16 19:50:42.471241: step 810, loss = 0.67696 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:50:43.360412 ops/training.py:65 2019-01-16 19:50:43.360294: step 811, loss = 0.72531 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:50:44.251336 ops/training.py:65 2019-01-16 19:50:44.251238: step 812, loss = 0.71762 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:50:45.142313 ops/training.py:65 2019-01-16 19:50:45.142217: step 813, loss = 0.72107 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:50:46.031531 ops/training.py:65 2019-01-16 19:50:46.031440: step 814, loss = 0.68816 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:50:46.919585 ops/training.py:65 2019-01-16 19:50:46.919454: step 815, loss = 0.71475 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:50:47.811432 ops/training.py:65 2019-01-16 19:50:47.811326: step 816, loss = 0.70165 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:50:48.702138 ops/training.py:65 2019-01-16 19:50:48.702059: step 817, loss = 0.72192 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:50:49.591217 ops/training.py:65 2019-01-16 19:50:49.591127: step 818, loss = 0.70728 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:50:50.481196 ops/training.py:65 2019-01-16 19:50:50.481123: step 819, loss = 0.65893 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 19:50:51.370993 ops/training.py:65 2019-01-16 19:50:51.370925: step 820, loss = 0.67048 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:50:52.262107 ops/training.py:65 2019-01-16 19:50:52.262034: step 821, loss = 0.67170 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:50:53.153514 ops/training.py:65 2019-01-16 19:50:53.153457: step 822, loss = 0.68670 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:50:54.043713 ops/training.py:65 2019-01-16 19:50:54.043635: step 823, loss = 0.69721 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:50:54.933034 ops/training.py:65 2019-01-16 19:50:54.932956: step 824, loss = 0.68050 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:50:55.822841 ops/training.py:65 2019-01-16 19:50:55.822773: step 825, loss = 0.69169 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:50:56.712810 ops/training.py:65 2019-01-16 19:50:56.712723: step 826, loss = 0.67230 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:50:57.602604 ops/training.py:65 2019-01-16 19:50:57.602516: step 827, loss = 0.67505 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:50:58.493635 ops/training.py:65 2019-01-16 19:50:58.493555: step 828, loss = 0.74605 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:50:59.382656 ops/training.py:65 2019-01-16 19:50:59.382582: step 829, loss = 0.69685 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:51:00.272874 ops/training.py:65 2019-01-16 19:51:00.272792: step 830, loss = 0.66993 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:51:01.163950 ops/training.py:65 2019-01-16 19:51:01.163876: step 831, loss = 0.70299 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:51:02.054179 ops/training.py:65 2019-01-16 19:51:02.054111: step 832, loss = 0.66552 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:51:02.943725 ops/training.py:65 2019-01-16 19:51:02.943644: step 833, loss = 0.68953 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:51:03.832588 ops/training.py:65 2019-01-16 19:51:03.832517: step 834, loss = 0.74274 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:51:04.721555 ops/training.py:65 2019-01-16 19:51:04.721484: step 835, loss = 0.73099 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:51:05.610392 ops/training.py:65 2019-01-16 19:51:05.610312: step 836, loss = 0.71974 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:51:06.499588 ops/training.py:65 2019-01-16 19:51:06.499515: step 837, loss = 0.66110 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:51:07.387581 ops/training.py:65 2019-01-16 19:51:07.387525: step 838, loss = 0.69919 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:51:08.276729 ops/training.py:65 2019-01-16 19:51:08.276655: step 839, loss = 0.70446 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:51:09.166721 ops/training.py:65 2019-01-16 19:51:09.166686: step 840, loss = 0.69624 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:51:10.055339 ops/training.py:65 2019-01-16 19:51:10.055259: step 841, loss = 0.69376 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:51:10.945744 ops/training.py:65 2019-01-16 19:51:10.945676: step 842, loss = 0.71480 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:51:11.835715 ops/training.py:65 2019-01-16 19:51:11.835638: step 843, loss = 0.67912 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:51:12.725459 ops/training.py:65 2019-01-16 19:51:12.725388: step 844, loss = 0.69093 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:51:13.615493 ops/training.py:65 2019-01-16 19:51:13.615415: step 845, loss = 0.73366 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:51:14.506728 ops/training.py:65 2019-01-16 19:51:14.506652: step 846, loss = 0.71828 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:51:15.396542 ops/training.py:65 2019-01-16 19:51:15.396467: step 847, loss = 0.72018 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:51:16.286480 ops/training.py:65 2019-01-16 19:51:16.286401: step 848, loss = 0.70144 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:51:17.174970 ops/training.py:65 2019-01-16 19:51:17.174904: step 849, loss = 0.70369 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:51:18.064930 ops/training.py:65 2019-01-16 19:51:18.064857: step 850, loss = 0.69347 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:51:18.955079 ops/training.py:65 2019-01-16 19:51:18.955012: step 851, loss = 0.74446 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:51:19.844555 ops/training.py:65 2019-01-16 19:51:19.844468: step 852, loss = 0.74044 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:51:20.734198 ops/training.py:65 2019-01-16 19:51:20.734106: step 853, loss = 0.73544 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:51:21.623402 ops/training.py:65 2019-01-16 19:51:21.623351: step 854, loss = 0.64603 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:51:22.513400 ops/training.py:65 2019-01-16 19:51:22.513332: step 855, loss = 0.69865 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:51:23.403058 ops/training.py:65 2019-01-16 19:51:23.402964: step 856, loss = 0.68963 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:51:24.293368 ops/training.py:65 2019-01-16 19:51:24.293298: step 857, loss = 0.69607 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:51:25.183085 ops/training.py:65 2019-01-16 19:51:25.183025: step 858, loss = 0.71356 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:51:26.072505 ops/training.py:65 2019-01-16 19:51:26.072443: step 859, loss = 0.73373 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:51:26.962762 ops/training.py:65 2019-01-16 19:51:26.962726: step 860, loss = 0.72142 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:51:27.854183 ops/training.py:65 2019-01-16 19:51:27.854149: step 861, loss = 0.75063 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:51:28.745428 ops/training.py:65 2019-01-16 19:51:28.745394: step 862, loss = 0.69704 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:51:29.634232 ops/training.py:65 2019-01-16 19:51:29.634171: step 863, loss = 0.66381 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 19:51:30.523194 ops/training.py:65 2019-01-16 19:51:30.523113: step 864, loss = 0.65398 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:51:31.412005 ops/training.py:65 2019-01-16 19:51:31.411942: step 865, loss = 0.75964 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:51:32.301494 ops/training.py:65 2019-01-16 19:51:32.301423: step 866, loss = 0.68139 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:51:33.191415 ops/training.py:65 2019-01-16 19:51:33.191344: step 867, loss = 0.68604 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:51:34.081189 ops/training.py:65 2019-01-16 19:51:34.081120: step 868, loss = 0.71064 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:51:34.972087 ops/training.py:65 2019-01-16 19:51:34.972012: step 869, loss = 0.68121 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:51:35.861091 ops/training.py:65 2019-01-16 19:51:35.861012: step 870, loss = 0.66871 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:51:36.752164 ops/training.py:65 2019-01-16 19:51:36.752087: step 871, loss = 0.70261 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:51:37.643138 ops/training.py:65 2019-01-16 19:51:37.643054: step 872, loss = 0.66987 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:51:38.533001 ops/training.py:65 2019-01-16 19:51:38.532922: step 873, loss = 0.75148 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:51:39.422205 ops/training.py:65 2019-01-16 19:51:39.422128: step 874, loss = 0.73216 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:51:40.311357 ops/training.py:65 2019-01-16 19:51:40.311280: step 875, loss = 0.72582 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:51:41.199891 ops/training.py:65 2019-01-16 19:51:41.199818: step 876, loss = 0.74517 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:51:42.089094 ops/training.py:65 2019-01-16 19:51:42.088991: step 877, loss = 0.72332 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:51:42.979495 ops/training.py:65 2019-01-16 19:51:42.979419: step 878, loss = 0.67596 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:51:43.870048 ops/training.py:65 2019-01-16 19:51:43.869978: step 879, loss = 0.71887 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:51:44.759664 ops/training.py:65 2019-01-16 19:51:44.759581: step 880, loss = 0.68900 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:51:45.648895 ops/training.py:65 2019-01-16 19:51:45.648808: step 881, loss = 0.70787 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:51:46.538193 ops/training.py:65 2019-01-16 19:51:46.538082: step 882, loss = 0.71744 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:51:47.427350 ops/training.py:65 2019-01-16 19:51:47.427280: step 883, loss = 0.69973 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:51:48.316727 ops/training.py:65 2019-01-16 19:51:48.316644: step 884, loss = 0.71336 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:51:49.207010 ops/training.py:65 2019-01-16 19:51:49.206939: step 885, loss = 0.68896 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:51:50.096783 ops/training.py:65 2019-01-16 19:51:50.096708: step 886, loss = 0.69874 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:51:50.987308 ops/training.py:65 2019-01-16 19:51:50.987222: step 887, loss = 0.67144 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:51:51.876857 ops/training.py:65 2019-01-16 19:51:51.876778: step 888, loss = 0.74818 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 19:51:52.767023 ops/training.py:65 2019-01-16 19:51:52.766947: step 889, loss = 0.70374 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:51:53.656174 ops/training.py:65 2019-01-16 19:51:53.656097: step 890, loss = 0.68768 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:51:54.546161 ops/training.py:65 2019-01-16 19:51:54.546087: step 891, loss = 0.69447 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:51:55.434984 ops/training.py:65 2019-01-16 19:51:55.434911: step 892, loss = 0.71740 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:51:56.323959 ops/training.py:65 2019-01-16 19:51:56.323890: step 893, loss = 0.67811 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:51:57.213142 ops/training.py:65 2019-01-16 19:51:57.213069: step 894, loss = 0.67703 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:51:58.103077 ops/training.py:65 2019-01-16 19:51:58.103000: step 895, loss = 0.70353 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:51:58.994887 ops/training.py:65 2019-01-16 19:51:58.994813: step 896, loss = 0.73516 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:51:59.885123 ops/training.py:65 2019-01-16 19:51:59.885039: step 897, loss = 0.71985 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:52:00.774630 ops/training.py:65 2019-01-16 19:52:00.774554: step 898, loss = 0.71548 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:52:01.664093 ops/training.py:65 2019-01-16 19:52:01.664012: step 899, loss = 0.70107 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:52:02.554931 ops/training.py:65 2019-01-16 19:52:02.554859: step 900, loss = 0.68496 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:52:03.445466 ops/training.py:65 2019-01-16 19:52:03.445391: step 901, loss = 0.70491 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:52:04.336346 ops/training.py:65 2019-01-16 19:52:04.336275: step 902, loss = 0.72231 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:52:05.227366 ops/training.py:65 2019-01-16 19:52:05.227293: step 903, loss = 0.70739 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:52:06.117251 ops/training.py:65 2019-01-16 19:52:06.117175: step 904, loss = 0.73486 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:52:07.007303 ops/training.py:65 2019-01-16 19:52:07.007223: step 905, loss = 0.70057 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:52:07.897919 ops/training.py:65 2019-01-16 19:52:07.897841: step 906, loss = 0.72420 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 19:52:08.788395 ops/training.py:65 2019-01-16 19:52:08.788305: step 907, loss = 0.74696 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:52:09.679123 ops/training.py:65 2019-01-16 19:52:09.679044: step 908, loss = 0.67118 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:52:10.570318 ops/training.py:65 2019-01-16 19:52:10.570245: step 909, loss = 0.73189 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:52:11.461501 ops/training.py:65 2019-01-16 19:52:11.461419: step 910, loss = 0.70103 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:52:12.351204 ops/training.py:65 2019-01-16 19:52:12.351125: step 911, loss = 0.76314 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:52:13.240780 ops/training.py:65 2019-01-16 19:52:13.240702: step 912, loss = 0.70625 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:52:14.130725 ops/training.py:65 2019-01-16 19:52:14.130650: step 913, loss = 0.76059 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 19:52:15.019620 ops/training.py:65 2019-01-16 19:52:15.019551: step 914, loss = 0.68453 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:52:15.911280 ops/training.py:65 2019-01-16 19:52:15.911207: step 915, loss = 0.70083 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:52:16.802238 ops/training.py:65 2019-01-16 19:52:16.802163: step 916, loss = 0.73155 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:52:17.692604 ops/training.py:65 2019-01-16 19:52:17.692528: step 917, loss = 0.71321 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:52:18.584327 ops/training.py:65 2019-01-16 19:52:18.584245: step 918, loss = 0.72418 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:52:19.475797 ops/training.py:65 2019-01-16 19:52:19.475717: step 919, loss = 0.67202 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:52:20.365865 ops/training.py:65 2019-01-16 19:52:20.365796: step 920, loss = 0.77422 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 19:52:21.255801 ops/training.py:65 2019-01-16 19:52:21.255716: step 921, loss = 0.67733 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:52:22.146508 ops/training.py:65 2019-01-16 19:52:22.146436: step 922, loss = 0.68636 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:52:23.037481 ops/training.py:65 2019-01-16 19:52:23.037403: step 923, loss = 0.73753 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:52:23.928919 ops/training.py:65 2019-01-16 19:52:23.928819: step 924, loss = 0.72359 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:52:24.820069 ops/training.py:65 2019-01-16 19:52:24.819993: step 925, loss = 0.73671 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:52:25.714134 ops/training.py:65 2019-01-16 19:52:25.714056: step 926, loss = 0.70164 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:52:26.604778 ops/training.py:65 2019-01-16 19:52:26.604710: step 927, loss = 0.67634 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:52:27.496625 ops/training.py:65 2019-01-16 19:52:27.496545: step 928, loss = 0.69186 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:52:28.386764 ops/training.py:65 2019-01-16 19:52:28.386688: step 929, loss = 0.72920 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:52:29.276361 ops/training.py:65 2019-01-16 19:52:29.276285: step 930, loss = 0.70672 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:52:30.168073 ops/training.py:65 2019-01-16 19:52:30.167997: step 931, loss = 0.70957 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:52:31.059870 ops/training.py:65 2019-01-16 19:52:31.059804: step 932, loss = 0.70401 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:52:31.951535 ops/training.py:65 2019-01-16 19:52:31.951458: step 933, loss = 0.67317 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:52:32.841907 ops/training.py:65 2019-01-16 19:52:32.841835: step 934, loss = 0.70807 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:52:33.730930 ops/training.py:65 2019-01-16 19:52:33.730856: step 935, loss = 0.71494 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:52:34.621617 ops/training.py:65 2019-01-16 19:52:34.621545: step 936, loss = 0.71084 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:52:35.511909 ops/training.py:65 2019-01-16 19:52:35.511830: step 937, loss = 0.74870 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:52:36.403413 ops/training.py:65 2019-01-16 19:52:36.403338: step 938, loss = 0.70371 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:52:37.294819 ops/training.py:65 2019-01-16 19:52:37.294740: step 939, loss = 0.68689 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:52:38.186475 ops/training.py:65 2019-01-16 19:52:38.186391: step 940, loss = 0.73745 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:52:39.076777 ops/training.py:65 2019-01-16 19:52:39.076695: step 941, loss = 0.71659 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:52:39.966090 ops/training.py:65 2019-01-16 19:52:39.966012: step 942, loss = 0.71414 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:52:40.856501 ops/training.py:65 2019-01-16 19:52:40.856423: step 943, loss = 0.73366 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:52:41.746535 ops/training.py:65 2019-01-16 19:52:41.746461: step 944, loss = 0.70704 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:52:42.635941 ops/training.py:65 2019-01-16 19:52:42.635864: step 945, loss = 0.71719 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:52:43.527399 ops/training.py:65 2019-01-16 19:52:43.527322: step 946, loss = 0.70092 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:52:44.418171 ops/training.py:65 2019-01-16 19:52:44.418095: step 947, loss = 0.69536 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:52:45.309998 ops/training.py:65 2019-01-16 19:52:45.309912: step 948, loss = 0.69559 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:52:46.200168 ops/training.py:65 2019-01-16 19:52:46.200095: step 949, loss = 0.72853 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:52:47.091529 ops/training.py:65 2019-01-16 19:52:47.091450: step 950, loss = 0.72039 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:52:47.983010 ops/training.py:65 2019-01-16 19:52:47.982928: step 951, loss = 0.67690 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:52:48.873009 ops/training.py:65 2019-01-16 19:52:48.872940: step 952, loss = 0.70583 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:52:49.763431 ops/training.py:65 2019-01-16 19:52:49.763329: step 953, loss = 0.70904 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:52:50.654796 ops/training.py:65 2019-01-16 19:52:50.654694: step 954, loss = 0.69667 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:52:51.546786 ops/training.py:65 2019-01-16 19:52:51.546680: step 955, loss = 0.70459 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:52:52.438200 ops/training.py:65 2019-01-16 19:52:52.438099: step 956, loss = 0.71796 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:52:53.330030 ops/training.py:65 2019-01-16 19:52:53.329936: step 957, loss = 0.69783 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:52:54.221639 ops/training.py:65 2019-01-16 19:52:54.221532: step 958, loss = 0.71643 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:52:55.113181 ops/training.py:65 2019-01-16 19:52:55.113082: step 959, loss = 0.70993 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:52:56.004675 ops/training.py:65 2019-01-16 19:52:56.004601: step 960, loss = 0.70297 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:52:56.896462 ops/training.py:65 2019-01-16 19:52:56.896388: step 961, loss = 0.72330 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:52:57.786862 ops/training.py:65 2019-01-16 19:52:57.786785: step 962, loss = 0.70655 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:52:58.678204 ops/training.py:65 2019-01-16 19:52:58.678136: step 963, loss = 0.70630 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:52:59.568374 ops/training.py:65 2019-01-16 19:52:59.568277: step 964, loss = 0.65811 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 19:53:00.459968 ops/training.py:65 2019-01-16 19:53:00.459865: step 965, loss = 0.71474 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:53:01.351744 ops/training.py:65 2019-01-16 19:53:01.351655: step 966, loss = 0.71705 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:53:02.242364 ops/training.py:65 2019-01-16 19:53:02.242289: step 967, loss = 0.67747 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:53:03.133417 ops/training.py:65 2019-01-16 19:53:03.133343: step 968, loss = 0.72390 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:53:04.025296 ops/training.py:65 2019-01-16 19:53:04.025227: step 969, loss = 0.69388 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:53:04.916771 ops/training.py:65 2019-01-16 19:53:04.916698: step 970, loss = 0.64090 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 19:53:05.807292 ops/training.py:65 2019-01-16 19:53:05.807217: step 971, loss = 0.73253 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:53:06.697436 ops/training.py:65 2019-01-16 19:53:06.697363: step 972, loss = 0.64059 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:53:07.587979 ops/training.py:65 2019-01-16 19:53:07.587898: step 973, loss = 0.70584 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:53:08.477874 ops/training.py:65 2019-01-16 19:53:08.477803: step 974, loss = 0.81190 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 19:53:09.368202 ops/training.py:65 2019-01-16 19:53:09.368135: step 975, loss = 0.75571 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:53:10.257814 ops/training.py:65 2019-01-16 19:53:10.257747: step 976, loss = 0.63327 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:53:11.147752 ops/training.py:65 2019-01-16 19:53:11.147676: step 977, loss = 0.73289 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:53:12.037674 ops/training.py:65 2019-01-16 19:53:12.037596: step 978, loss = 0.78535 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:53:12.927711 ops/training.py:65 2019-01-16 19:53:12.927631: step 979, loss = 0.73404 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:53:13.817335 ops/training.py:65 2019-01-16 19:53:13.817240: step 980, loss = 0.80092 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:53:14.706932 ops/training.py:65 2019-01-16 19:53:14.706859: step 981, loss = 0.69021 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:53:15.598662 ops/training.py:65 2019-01-16 19:53:15.598586: step 982, loss = 0.70689 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:53:16.488517 ops/training.py:65 2019-01-16 19:53:16.488439: step 983, loss = 0.70691 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:53:17.378677 ops/training.py:65 2019-01-16 19:53:17.378606: step 984, loss = 0.69974 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:53:18.268558 ops/training.py:65 2019-01-16 19:53:18.268482: step 985, loss = 0.72084 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:53:19.159056 ops/training.py:65 2019-01-16 19:53:19.158981: step 986, loss = 0.64447 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:53:20.049046 ops/training.py:65 2019-01-16 19:53:20.048972: step 987, loss = 0.67758 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:53:20.938699 ops/training.py:65 2019-01-16 19:53:20.938623: step 988, loss = 0.69836 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:53:21.830246 ops/training.py:65 2019-01-16 19:53:21.830169: step 989, loss = 0.69559 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:53:22.721811 ops/training.py:65 2019-01-16 19:53:22.721739: step 990, loss = 0.67385 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:53:23.613048 ops/training.py:65 2019-01-16 19:53:23.612975: step 991, loss = 0.72674 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:53:24.503564 ops/training.py:65 2019-01-16 19:53:24.503492: step 992, loss = 0.76182 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.25
I2992 2019-01-16 19:53:25.394004 ops/training.py:65 2019-01-16 19:53:25.393933: step 993, loss = 0.71349 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:53:26.284441 ops/training.py:65 2019-01-16 19:53:26.284366: step 994, loss = 0.75084 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:53:27.175941 ops/training.py:65 2019-01-16 19:53:27.175863: step 995, loss = 0.64217 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:53:28.067429 ops/training.py:65 2019-01-16 19:53:28.067355: step 996, loss = 0.64246 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:53:28.956416 ops/training.py:65 2019-01-16 19:53:28.956337: step 997, loss = 0.72408 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:53:29.845763 ops/training.py:65 2019-01-16 19:53:29.845698: step 998, loss = 0.70904 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:53:30.735529 ops/training.py:65 2019-01-16 19:53:30.735444: step 999, loss = 0.73040 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:53:31.626229 ops/training.py:65 2019-01-16 19:53:31.626165: step 1000, loss = 0.69580 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:53:32.515757 ops/training.py:65 2019-01-16 19:53:32.515697: step 1001, loss = 0.76398 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:53:33.405194 ops/training.py:65 2019-01-16 19:53:33.405125: step 1002, loss = 0.72675 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:53:34.294921 ops/training.py:65 2019-01-16 19:53:34.294853: step 1003, loss = 0.74890 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:53:35.184367 ops/training.py:65 2019-01-16 19:53:35.184302: step 1004, loss = 0.68743 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:53:36.075362 ops/training.py:65 2019-01-16 19:53:36.075287: step 1005, loss = 0.70724 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:53:36.965570 ops/training.py:65 2019-01-16 19:53:36.965503: step 1006, loss = 0.69976 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:53:37.855653 ops/training.py:65 2019-01-16 19:53:37.855587: step 1007, loss = 0.68445 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:53:38.744414 ops/training.py:65 2019-01-16 19:53:38.744351: step 1008, loss = 0.66195 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:53:39.633415 ops/training.py:65 2019-01-16 19:53:39.633347: step 1009, loss = 0.68862 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:53:40.522889 ops/training.py:65 2019-01-16 19:53:40.522825: step 1010, loss = 0.73340 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:53:41.413108 ops/training.py:65 2019-01-16 19:53:41.413043: step 1011, loss = 0.65593 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 19:53:42.303138 ops/training.py:65 2019-01-16 19:53:42.303080: step 1012, loss = 0.72782 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:53:43.193059 ops/training.py:65 2019-01-16 19:53:43.192986: step 1013, loss = 0.71631 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:53:44.083256 ops/training.py:65 2019-01-16 19:53:44.083188: step 1014, loss = 0.70460 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:53:44.973091 ops/training.py:65 2019-01-16 19:53:44.973028: step 1015, loss = 0.70782 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:53:45.862091 ops/training.py:65 2019-01-16 19:53:45.862021: step 1016, loss = 0.72484 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:53:46.751659 ops/training.py:65 2019-01-16 19:53:46.751596: step 1017, loss = 0.68124 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:53:47.641187 ops/training.py:65 2019-01-16 19:53:47.641118: step 1018, loss = 0.74305 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:53:48.530614 ops/training.py:65 2019-01-16 19:53:48.530551: step 1019, loss = 0.75279 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:53:49.420296 ops/training.py:65 2019-01-16 19:53:49.420231: step 1020, loss = 0.76111 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:53:50.309289 ops/training.py:65 2019-01-16 19:53:50.309228: step 1021, loss = 0.74499 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:53:51.200120 ops/training.py:65 2019-01-16 19:53:51.200061: step 1022, loss = 0.64591 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:53:52.090945 ops/training.py:65 2019-01-16 19:53:52.090878: step 1023, loss = 0.68991 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:53:52.980489 ops/training.py:65 2019-01-16 19:53:52.980427: step 1024, loss = 0.69437 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:53:53.870011 ops/training.py:65 2019-01-16 19:53:53.869934: step 1025, loss = 0.77245 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:53:54.760132 ops/training.py:65 2019-01-16 19:53:54.760067: step 1026, loss = 0.68874 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:53:55.649712 ops/training.py:65 2019-01-16 19:53:55.649644: step 1027, loss = 0.74196 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:53:56.538934 ops/training.py:65 2019-01-16 19:53:56.538863: step 1028, loss = 0.71470 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:53:57.428799 ops/training.py:65 2019-01-16 19:53:57.428729: step 1029, loss = 0.70373 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:53:58.318761 ops/training.py:65 2019-01-16 19:53:58.318689: step 1030, loss = 0.71506 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:53:59.208649 ops/training.py:65 2019-01-16 19:53:59.208580: step 1031, loss = 0.71987 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:54:00.099679 ops/training.py:65 2019-01-16 19:54:00.099604: step 1032, loss = 0.72703 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:54:00.989014 ops/training.py:65 2019-01-16 19:54:00.988948: step 1033, loss = 0.66677 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:54:01.879046 ops/training.py:65 2019-01-16 19:54:01.878979: step 1034, loss = 0.75927 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:54:02.768507 ops/training.py:65 2019-01-16 19:54:02.768437: step 1035, loss = 0.70780 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:54:03.658629 ops/training.py:65 2019-01-16 19:54:03.658559: step 1036, loss = 0.69596 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:54:04.548305 ops/training.py:65 2019-01-16 19:54:04.548244: step 1037, loss = 0.68971 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:54:05.438115 ops/training.py:65 2019-01-16 19:54:05.438050: step 1038, loss = 0.65998 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:54:06.327015 ops/training.py:65 2019-01-16 19:54:06.326949: step 1039, loss = 0.69995 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:54:07.217701 ops/training.py:65 2019-01-16 19:54:07.217636: step 1040, loss = 0.72106 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:54:08.107429 ops/training.py:65 2019-01-16 19:54:08.107361: step 1041, loss = 0.70933 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:54:08.996626 ops/training.py:65 2019-01-16 19:54:08.996558: step 1042, loss = 0.71983 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:54:09.886137 ops/training.py:65 2019-01-16 19:54:09.886073: step 1043, loss = 0.69578 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:54:10.775651 ops/training.py:65 2019-01-16 19:54:10.775581: step 1044, loss = 0.73091 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:54:11.665771 ops/training.py:65 2019-01-16 19:54:11.665705: step 1045, loss = 0.72222 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:54:12.554471 ops/training.py:65 2019-01-16 19:54:12.554405: step 1046, loss = 0.75787 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:54:13.443662 ops/training.py:65 2019-01-16 19:54:13.443596: step 1047, loss = 0.73725 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:54:14.334020 ops/training.py:65 2019-01-16 19:54:14.333949: step 1048, loss = 0.68187 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:54:15.224303 ops/training.py:65 2019-01-16 19:54:15.224220: step 1049, loss = 0.69593 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:54:16.114311 ops/training.py:65 2019-01-16 19:54:16.114224: step 1050, loss = 0.67782 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:54:17.005172 ops/training.py:65 2019-01-16 19:54:17.005078: step 1051, loss = 0.69852 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:54:17.895069 ops/training.py:65 2019-01-16 19:54:17.894973: step 1052, loss = 0.70963 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:54:18.786034 ops/training.py:65 2019-01-16 19:54:18.785894: step 1053, loss = 0.68653 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:54:19.675952 ops/training.py:65 2019-01-16 19:54:19.675877: step 1054, loss = 0.75694 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:54:20.565769 ops/training.py:65 2019-01-16 19:54:20.565695: step 1055, loss = 0.67284 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:54:21.456075 ops/training.py:65 2019-01-16 19:54:21.455991: step 1056, loss = 0.75916 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 19:54:22.346022 ops/training.py:65 2019-01-16 19:54:22.345944: step 1057, loss = 0.67489 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:54:23.235458 ops/training.py:65 2019-01-16 19:54:23.235384: step 1058, loss = 0.67770 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:54:24.125738 ops/training.py:65 2019-01-16 19:54:24.125668: step 1059, loss = 0.68735 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:54:25.014970 ops/training.py:65 2019-01-16 19:54:25.014897: step 1060, loss = 0.67854 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:54:25.904765 ops/training.py:65 2019-01-16 19:54:25.904690: step 1061, loss = 0.73157 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:54:26.794869 ops/training.py:65 2019-01-16 19:54:26.794797: step 1062, loss = 0.69185 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:54:27.684885 ops/training.py:65 2019-01-16 19:54:27.684793: step 1063, loss = 0.72641 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:54:28.575676 ops/training.py:65 2019-01-16 19:54:28.575573: step 1064, loss = 0.71281 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:54:29.466185 ops/training.py:65 2019-01-16 19:54:29.466081: step 1065, loss = 0.74485 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.25
I2992 2019-01-16 19:54:30.355534 ops/training.py:65 2019-01-16 19:54:30.355460: step 1066, loss = 0.72067 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:54:31.245106 ops/training.py:65 2019-01-16 19:54:31.245032: step 1067, loss = 0.65536 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:54:32.134573 ops/training.py:65 2019-01-16 19:54:32.134474: step 1068, loss = 0.76456 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:54:33.025025 ops/training.py:65 2019-01-16 19:54:33.024947: step 1069, loss = 0.68512 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:54:33.915493 ops/training.py:65 2019-01-16 19:54:33.915397: step 1070, loss = 0.73132 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:54:34.806310 ops/training.py:65 2019-01-16 19:54:34.806211: step 1071, loss = 0.66726 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:54:35.696841 ops/training.py:65 2019-01-16 19:54:35.696767: step 1072, loss = 0.72187 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:54:36.587411 ops/training.py:65 2019-01-16 19:54:36.587344: step 1073, loss = 0.66482 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:54:37.478437 ops/training.py:65 2019-01-16 19:54:37.478363: step 1074, loss = 0.67546 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:54:38.368596 ops/training.py:65 2019-01-16 19:54:38.368523: step 1075, loss = 0.70357 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:54:39.258074 ops/training.py:65 2019-01-16 19:54:39.258007: step 1076, loss = 0.70061 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:54:40.149013 ops/training.py:65 2019-01-16 19:54:40.148939: step 1077, loss = 0.71727 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:54:41.038097 ops/training.py:65 2019-01-16 19:54:41.038022: step 1078, loss = 0.74833 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:54:41.927691 ops/training.py:65 2019-01-16 19:54:41.927618: step 1079, loss = 0.68218 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:54:42.816738 ops/training.py:65 2019-01-16 19:54:42.816663: step 1080, loss = 0.72571 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:54:43.705317 ops/training.py:65 2019-01-16 19:54:43.705232: step 1081, loss = 0.71265 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:54:44.595785 ops/training.py:65 2019-01-16 19:54:44.595687: step 1082, loss = 0.67390 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:54:45.486577 ops/training.py:65 2019-01-16 19:54:45.486506: step 1083, loss = 0.71823 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:54:46.375964 ops/training.py:65 2019-01-16 19:54:46.375904: step 1084, loss = 0.67879 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:54:47.264911 ops/training.py:65 2019-01-16 19:54:47.264855: step 1085, loss = 0.71621 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:54:48.154304 ops/training.py:65 2019-01-16 19:54:48.154247: step 1086, loss = 0.70082 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:54:49.043985 ops/training.py:65 2019-01-16 19:54:49.043893: step 1087, loss = 0.71647 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:54:49.934688 ops/training.py:65 2019-01-16 19:54:49.934587: step 1088, loss = 0.70696 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:54:50.823878 ops/training.py:65 2019-01-16 19:54:50.823742: step 1089, loss = 0.73102 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 19:54:51.714063 ops/training.py:65 2019-01-16 19:54:51.713976: step 1090, loss = 0.72387 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:54:52.604310 ops/training.py:65 2019-01-16 19:54:52.604226: step 1091, loss = 0.68778 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:54:53.493749 ops/training.py:65 2019-01-16 19:54:53.493649: step 1092, loss = 0.72200 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:54:54.385265 ops/training.py:65 2019-01-16 19:54:54.385186: step 1093, loss = 0.69229 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:54:55.273631 ops/training.py:65 2019-01-16 19:54:55.273560: step 1094, loss = 0.69544 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:54:56.162778 ops/training.py:65 2019-01-16 19:54:56.162696: step 1095, loss = 0.67535 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:54:57.052224 ops/training.py:65 2019-01-16 19:54:57.052153: step 1096, loss = 0.68139 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:54:57.942705 ops/training.py:65 2019-01-16 19:54:57.942629: step 1097, loss = 0.67432 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:54:58.832437 ops/training.py:65 2019-01-16 19:54:58.832371: step 1098, loss = 0.67086 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:54:59.722419 ops/training.py:65 2019-01-16 19:54:59.722349: step 1099, loss = 0.67473 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:55:00.612689 ops/training.py:65 2019-01-16 19:55:00.612618: step 1100, loss = 0.73564 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:55:01.502567 ops/training.py:65 2019-01-16 19:55:01.502493: step 1101, loss = 0.70057 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:55:02.393929 ops/training.py:65 2019-01-16 19:55:02.393861: step 1102, loss = 0.66251 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:55:03.282926 ops/training.py:65 2019-01-16 19:55:03.282856: step 1103, loss = 0.75008 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:55:04.172607 ops/training.py:65 2019-01-16 19:55:04.172551: step 1104, loss = 0.69750 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:55:05.061532 ops/training.py:65 2019-01-16 19:55:05.061475: step 1105, loss = 0.66887 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:55:05.950715 ops/training.py:65 2019-01-16 19:55:05.950651: step 1106, loss = 0.72184 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:55:06.840119 ops/training.py:65 2019-01-16 19:55:06.840049: step 1107, loss = 0.71575 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:55:07.729243 ops/training.py:65 2019-01-16 19:55:07.729180: step 1108, loss = 0.65451 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:55:08.619595 ops/training.py:65 2019-01-16 19:55:08.619537: step 1109, loss = 0.74830 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:55:09.508718 ops/training.py:65 2019-01-16 19:55:09.508657: step 1110, loss = 0.74673 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:55:10.398082 ops/training.py:65 2019-01-16 19:55:10.398024: step 1111, loss = 0.73085 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:55:11.288203 ops/training.py:65 2019-01-16 19:55:11.288137: step 1112, loss = 0.66669 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:55:12.178839 ops/training.py:65 2019-01-16 19:55:12.178771: step 1113, loss = 0.60910 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 19:55:13.068625 ops/training.py:65 2019-01-16 19:55:13.068563: step 1114, loss = 0.74948 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:55:13.957853 ops/training.py:65 2019-01-16 19:55:13.957788: step 1115, loss = 0.71561 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:55:14.847091 ops/training.py:65 2019-01-16 19:55:14.847033: step 1116, loss = 0.69026 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:55:15.736593 ops/training.py:65 2019-01-16 19:55:15.736532: step 1117, loss = 0.75342 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:55:16.626192 ops/training.py:65 2019-01-16 19:55:16.626126: step 1118, loss = 0.73851 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:55:17.515532 ops/training.py:65 2019-01-16 19:55:17.515470: step 1119, loss = 0.74495 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:55:18.405523 ops/training.py:65 2019-01-16 19:55:18.405457: step 1120, loss = 0.71182 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:55:19.295584 ops/training.py:65 2019-01-16 19:55:19.295519: step 1121, loss = 0.72419 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:55:20.185476 ops/training.py:65 2019-01-16 19:55:20.185405: step 1122, loss = 0.64290 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 19:55:21.077162 ops/training.py:65 2019-01-16 19:55:21.077089: step 1123, loss = 0.68617 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:55:21.967948 ops/training.py:65 2019-01-16 19:55:21.967848: step 1124, loss = 0.65367 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 19:55:22.861680 ops/training.py:65 2019-01-16 19:55:22.861574: step 1125, loss = 0.65055 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:55:23.754899 ops/training.py:65 2019-01-16 19:55:23.754799: step 1126, loss = 0.69005 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:55:24.646644 ops/training.py:65 2019-01-16 19:55:24.646586: step 1127, loss = 0.68177 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:55:25.536371 ops/training.py:65 2019-01-16 19:55:25.536308: step 1128, loss = 0.67983 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:55:26.427042 ops/training.py:65 2019-01-16 19:55:26.426976: step 1129, loss = 0.69343 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:55:27.317880 ops/training.py:65 2019-01-16 19:55:27.317820: step 1130, loss = 0.65705 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:55:28.207810 ops/training.py:65 2019-01-16 19:55:28.207749: step 1131, loss = 0.66264 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:55:29.097926 ops/training.py:65 2019-01-16 19:55:29.097866: step 1132, loss = 0.67844 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:55:29.987308 ops/training.py:65 2019-01-16 19:55:29.987243: step 1133, loss = 0.72869 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:55:30.875752 ops/training.py:65 2019-01-16 19:55:30.875692: step 1134, loss = 0.68471 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:55:31.765631 ops/training.py:65 2019-01-16 19:55:31.765573: step 1135, loss = 0.68689 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:55:32.655348 ops/training.py:65 2019-01-16 19:55:32.655292: step 1136, loss = 0.71308 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:55:33.544180 ops/training.py:65 2019-01-16 19:55:33.544097: step 1137, loss = 0.71708 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:55:34.433490 ops/training.py:65 2019-01-16 19:55:34.433424: step 1138, loss = 0.66817 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:55:35.323544 ops/training.py:65 2019-01-16 19:55:35.323479: step 1139, loss = 0.68747 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:55:36.212611 ops/training.py:65 2019-01-16 19:55:36.212549: step 1140, loss = 0.70438 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:55:37.101545 ops/training.py:65 2019-01-16 19:55:37.101481: step 1141, loss = 0.71462 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:55:37.990669 ops/training.py:65 2019-01-16 19:55:37.990604: step 1142, loss = 0.71232 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:55:38.881682 ops/training.py:65 2019-01-16 19:55:38.881627: step 1143, loss = 0.65999 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:55:39.772492 ops/training.py:65 2019-01-16 19:55:39.772410: step 1144, loss = 0.69488 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:55:40.664681 ops/training.py:65 2019-01-16 19:55:40.664597: step 1145, loss = 0.69707 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:55:41.557117 ops/training.py:65 2019-01-16 19:55:41.557017: step 1146, loss = 0.72532 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:55:42.449084 ops/training.py:65 2019-01-16 19:55:42.448992: step 1147, loss = 0.66079 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 19:55:43.340946 ops/training.py:65 2019-01-16 19:55:43.340882: step 1148, loss = 0.71724 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:55:44.230353 ops/training.py:65 2019-01-16 19:55:44.230296: step 1149, loss = 0.68937 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:55:45.120244 ops/training.py:65 2019-01-16 19:55:45.120185: step 1150, loss = 0.70336 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:55:46.010345 ops/training.py:65 2019-01-16 19:55:46.010285: step 1151, loss = 0.73603 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:55:46.899416 ops/training.py:65 2019-01-16 19:55:46.899353: step 1152, loss = 0.69920 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:55:47.789512 ops/training.py:65 2019-01-16 19:55:47.789447: step 1153, loss = 0.73091 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:55:48.680307 ops/training.py:65 2019-01-16 19:55:48.680177: step 1154, loss = 0.73169 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:55:49.573148 ops/training.py:65 2019-01-16 19:55:49.573048: step 1155, loss = 0.65869 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:55:50.464364 ops/training.py:65 2019-01-16 19:55:50.464261: step 1156, loss = 0.69538 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:55:51.358028 ops/training.py:65 2019-01-16 19:55:51.357924: step 1157, loss = 0.69470 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:55:52.248264 ops/training.py:65 2019-01-16 19:55:52.248194: step 1158, loss = 0.69293 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:55:53.140979 ops/training.py:65 2019-01-16 19:55:53.140883: step 1159, loss = 0.67984 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:55:54.033474 ops/training.py:65 2019-01-16 19:55:54.033375: step 1160, loss = 0.69756 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:55:54.924982 ops/training.py:65 2019-01-16 19:55:54.924923: step 1161, loss = 0.69046 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:55:55.815217 ops/training.py:65 2019-01-16 19:55:55.815159: step 1162, loss = 0.73507 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 19:55:56.706297 ops/training.py:65 2019-01-16 19:55:56.706238: step 1163, loss = 0.66510 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:55:57.596491 ops/training.py:65 2019-01-16 19:55:57.596427: step 1164, loss = 0.77580 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:55:58.486337 ops/training.py:65 2019-01-16 19:55:58.486270: step 1165, loss = 0.67124 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:55:59.377512 ops/training.py:65 2019-01-16 19:55:59.377413: step 1166, loss = 0.70228 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:56:00.268663 ops/training.py:65 2019-01-16 19:56:00.268556: step 1167, loss = 0.73839 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:56:01.159270 ops/training.py:65 2019-01-16 19:56:01.159188: step 1168, loss = 0.66525 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:56:02.050121 ops/training.py:65 2019-01-16 19:56:02.050023: step 1169, loss = 0.63535 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 19:56:02.944833 ops/training.py:65 2019-01-16 19:56:02.944733: step 1170, loss = 0.68841 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:56:03.836185 ops/training.py:65 2019-01-16 19:56:03.836088: step 1171, loss = 0.69020 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:56:04.727403 ops/training.py:65 2019-01-16 19:56:04.727316: step 1172, loss = 0.75035 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:56:05.619695 ops/training.py:65 2019-01-16 19:56:05.619586: step 1173, loss = 0.68105 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:56:06.513118 ops/training.py:65 2019-01-16 19:56:06.512986: step 1174, loss = 0.74166 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:56:07.404611 ops/training.py:65 2019-01-16 19:56:07.404557: step 1175, loss = 0.66998 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:56:08.295065 ops/training.py:65 2019-01-16 19:56:08.295001: step 1176, loss = 0.65534 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:56:09.185599 ops/training.py:65 2019-01-16 19:56:09.185538: step 1177, loss = 0.65084 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:56:10.074564 ops/training.py:65 2019-01-16 19:56:10.074484: step 1178, loss = 0.75692 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:56:10.964067 ops/training.py:65 2019-01-16 19:56:10.964000: step 1179, loss = 0.66185 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:56:11.853569 ops/training.py:65 2019-01-16 19:56:11.853509: step 1180, loss = 0.68846 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:56:12.743083 ops/training.py:65 2019-01-16 19:56:12.743018: step 1181, loss = 0.70482 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:56:13.632340 ops/training.py:65 2019-01-16 19:56:13.632259: step 1182, loss = 0.73400 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:56:14.521635 ops/training.py:65 2019-01-16 19:56:14.521575: step 1183, loss = 0.70424 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:56:15.411737 ops/training.py:65 2019-01-16 19:56:15.411681: step 1184, loss = 0.71447 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:56:16.301394 ops/training.py:65 2019-01-16 19:56:16.301335: step 1185, loss = 0.70985 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:56:17.190746 ops/training.py:65 2019-01-16 19:56:17.190687: step 1186, loss = 0.67260 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:56:18.079926 ops/training.py:65 2019-01-16 19:56:18.079864: step 1187, loss = 0.68061 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:56:18.969471 ops/training.py:65 2019-01-16 19:56:18.969401: step 1188, loss = 0.70596 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:56:19.858416 ops/training.py:65 2019-01-16 19:56:19.858356: step 1189, loss = 0.65854 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 19:56:20.748145 ops/training.py:65 2019-01-16 19:56:20.748083: step 1190, loss = 0.68915 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:56:21.637363 ops/training.py:65 2019-01-16 19:56:21.637302: step 1191, loss = 0.73199 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:56:22.526996 ops/training.py:65 2019-01-16 19:56:22.526940: step 1192, loss = 0.68413 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:56:23.416254 ops/training.py:65 2019-01-16 19:56:23.416185: step 1193, loss = 0.68456 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:56:24.305762 ops/training.py:65 2019-01-16 19:56:24.305701: step 1194, loss = 0.69420 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:56:25.195027 ops/training.py:65 2019-01-16 19:56:25.194964: step 1195, loss = 0.67235 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:56:26.084155 ops/training.py:65 2019-01-16 19:56:26.084094: step 1196, loss = 0.69187 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:56:26.973085 ops/training.py:65 2019-01-16 19:56:26.973017: step 1197, loss = 0.66313 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 19:56:27.862589 ops/training.py:65 2019-01-16 19:56:27.862528: step 1198, loss = 0.71503 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:56:28.751349 ops/training.py:65 2019-01-16 19:56:28.751285: step 1199, loss = 0.71111 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:56:29.640960 ops/training.py:65 2019-01-16 19:56:29.640897: step 1200, loss = 0.67700 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:56:30.531894 ops/training.py:65 2019-01-16 19:56:30.531799: step 1201, loss = 0.73462 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:56:31.424167 ops/training.py:65 2019-01-16 19:56:31.424069: step 1202, loss = 0.71112 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:56:32.315709 ops/training.py:65 2019-01-16 19:56:32.315613: step 1203, loss = 0.69240 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:56:33.206611 ops/training.py:65 2019-01-16 19:56:33.206526: step 1204, loss = 0.69534 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:56:34.096623 ops/training.py:65 2019-01-16 19:56:34.096561: step 1205, loss = 0.70729 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:56:34.986276 ops/training.py:65 2019-01-16 19:56:34.986214: step 1206, loss = 0.68704 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:56:35.875686 ops/training.py:65 2019-01-16 19:56:35.875620: step 1207, loss = 0.68447 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:56:36.764360 ops/training.py:65 2019-01-16 19:56:36.764300: step 1208, loss = 0.68337 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:56:37.653037 ops/training.py:65 2019-01-16 19:56:37.652971: step 1209, loss = 0.65960 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:56:38.541946 ops/training.py:65 2019-01-16 19:56:38.541888: step 1210, loss = 0.70912 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:56:39.430827 ops/training.py:65 2019-01-16 19:56:39.430773: step 1211, loss = 0.73491 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:56:40.321235 ops/training.py:65 2019-01-16 19:56:40.321176: step 1212, loss = 0.71306 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:56:41.214031 ops/training.py:65 2019-01-16 19:56:41.213933: step 1213, loss = 0.73317 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:56:42.106171 ops/training.py:65 2019-01-16 19:56:42.106063: step 1214, loss = 0.70682 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:56:42.997312 ops/training.py:65 2019-01-16 19:56:42.997254: step 1215, loss = 0.70161 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:56:43.887133 ops/training.py:65 2019-01-16 19:56:43.887072: step 1216, loss = 0.69536 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:56:44.776616 ops/training.py:65 2019-01-16 19:56:44.776556: step 1217, loss = 0.69480 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:56:45.666343 ops/training.py:65 2019-01-16 19:56:45.666276: step 1218, loss = 0.67604 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:56:46.555528 ops/training.py:65 2019-01-16 19:56:46.555472: step 1219, loss = 0.70281 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:56:47.445435 ops/training.py:65 2019-01-16 19:56:47.445375: step 1220, loss = 0.71691 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:56:48.335872 ops/training.py:65 2019-01-16 19:56:48.335806: step 1221, loss = 0.71687 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:56:49.225314 ops/training.py:65 2019-01-16 19:56:49.225257: step 1222, loss = 0.72238 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:56:50.114903 ops/training.py:65 2019-01-16 19:56:50.114841: step 1223, loss = 0.72239 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:56:51.004113 ops/training.py:65 2019-01-16 19:56:51.004050: step 1224, loss = 0.68947 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:56:51.893858 ops/training.py:65 2019-01-16 19:56:51.893797: step 1225, loss = 0.68691 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:56:52.783931 ops/training.py:65 2019-01-16 19:56:52.783851: step 1226, loss = 0.76092 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:56:53.672965 ops/training.py:65 2019-01-16 19:56:53.672896: step 1227, loss = 0.66480 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:56:54.563136 ops/training.py:65 2019-01-16 19:56:54.563072: step 1228, loss = 0.70304 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:56:55.455477 ops/training.py:65 2019-01-16 19:56:55.455371: step 1229, loss = 0.75235 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 19:56:56.347826 ops/training.py:65 2019-01-16 19:56:56.347714: step 1230, loss = 0.70333 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:56:57.238726 ops/training.py:65 2019-01-16 19:56:57.238668: step 1231, loss = 0.68425 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:56:58.128801 ops/training.py:65 2019-01-16 19:56:58.128738: step 1232, loss = 0.73897 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:56:59.018010 ops/training.py:65 2019-01-16 19:56:59.017950: step 1233, loss = 0.71772 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:56:59.906884 ops/training.py:65 2019-01-16 19:56:59.906824: step 1234, loss = 0.68869 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:57:00.796613 ops/training.py:65 2019-01-16 19:57:00.796549: step 1235, loss = 0.72831 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:57:01.685720 ops/training.py:65 2019-01-16 19:57:01.685658: step 1236, loss = 0.68895 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:57:02.574735 ops/training.py:65 2019-01-16 19:57:02.574679: step 1237, loss = 0.72727 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:57:03.465009 ops/training.py:65 2019-01-16 19:57:03.464948: step 1238, loss = 0.69545 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:57:04.356214 ops/training.py:65 2019-01-16 19:57:04.356152: step 1239, loss = 0.68581 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:57:05.246398 ops/training.py:65 2019-01-16 19:57:05.246338: step 1240, loss = 0.66331 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:57:06.136161 ops/training.py:65 2019-01-16 19:57:06.136103: step 1241, loss = 0.74349 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:57:07.025543 ops/training.py:65 2019-01-16 19:57:07.025479: step 1242, loss = 0.71531 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:57:07.914791 ops/training.py:65 2019-01-16 19:57:07.914734: step 1243, loss = 0.72391 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:57:08.804212 ops/training.py:65 2019-01-16 19:57:08.804152: step 1244, loss = 0.72799 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:57:09.693548 ops/training.py:65 2019-01-16 19:57:09.693486: step 1245, loss = 0.72334 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:57:10.583197 ops/training.py:65 2019-01-16 19:57:10.583134: step 1246, loss = 0.70976 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:57:11.473172 ops/training.py:65 2019-01-16 19:57:11.473105: step 1247, loss = 0.68727 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:57:12.362508 ops/training.py:65 2019-01-16 19:57:12.362444: step 1248, loss = 0.72268 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:57:13.251665 ops/training.py:65 2019-01-16 19:57:13.251588: step 1249, loss = 0.67910 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:57:14.141650 ops/training.py:65 2019-01-16 19:57:14.141588: step 1250, loss = 0.71419 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:57:15.031202 ops/training.py:65 2019-01-16 19:57:15.031137: step 1251, loss = 0.67570 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:57:15.921457 ops/training.py:65 2019-01-16 19:57:15.921396: step 1252, loss = 0.74823 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:57:16.811076 ops/training.py:65 2019-01-16 19:57:16.811016: step 1253, loss = 0.73144 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:57:17.700959 ops/training.py:65 2019-01-16 19:57:17.700898: step 1254, loss = 0.70619 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:57:18.590131 ops/training.py:65 2019-01-16 19:57:18.590070: step 1255, loss = 0.69332 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:57:19.479721 ops/training.py:65 2019-01-16 19:57:19.479658: step 1256, loss = 0.69426 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:57:20.368979 ops/training.py:65 2019-01-16 19:57:20.368904: step 1257, loss = 0.68588 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:57:21.257944 ops/training.py:65 2019-01-16 19:57:21.257885: step 1258, loss = 0.69357 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:57:22.148207 ops/training.py:65 2019-01-16 19:57:22.148162: step 1259, loss = 0.68581 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:57:23.042400 ops/training.py:65 2019-01-16 19:57:23.042305: step 1260, loss = 0.70557 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:57:23.934247 ops/training.py:65 2019-01-16 19:57:23.934173: step 1261, loss = 0.73204 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:57:24.826574 ops/training.py:65 2019-01-16 19:57:24.826477: step 1262, loss = 0.65890 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 19:57:25.717928 ops/training.py:65 2019-01-16 19:57:25.717866: step 1263, loss = 0.68482 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:57:26.607956 ops/training.py:65 2019-01-16 19:57:26.607898: step 1264, loss = 0.70560 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:57:27.497604 ops/training.py:65 2019-01-16 19:57:27.497537: step 1265, loss = 0.71790 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:57:28.386944 ops/training.py:65 2019-01-16 19:57:28.386884: step 1266, loss = 0.68861 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:57:29.275896 ops/training.py:65 2019-01-16 19:57:29.275838: step 1267, loss = 0.67971 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:57:30.164433 ops/training.py:65 2019-01-16 19:57:30.164382: step 1268, loss = 0.67594 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:57:31.054805 ops/training.py:65 2019-01-16 19:57:31.054734: step 1269, loss = 0.68498 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:57:31.946634 ops/training.py:65 2019-01-16 19:57:31.946539: step 1270, loss = 0.74115 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:57:32.840412 ops/training.py:65 2019-01-16 19:57:32.840306: step 1271, loss = 0.70217 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:57:33.732124 ops/training.py:65 2019-01-16 19:57:33.732034: step 1272, loss = 0.68325 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:57:34.624004 ops/training.py:65 2019-01-16 19:57:34.623946: step 1273, loss = 0.69862 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:57:35.515816 ops/training.py:65 2019-01-16 19:57:35.515732: step 1274, loss = 0.67207 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:57:36.407341 ops/training.py:65 2019-01-16 19:57:36.407252: step 1275, loss = 0.70639 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:57:37.299089 ops/training.py:65 2019-01-16 19:57:37.298993: step 1276, loss = 0.65175 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:57:38.190598 ops/training.py:65 2019-01-16 19:57:38.190504: step 1277, loss = 0.70008 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:57:39.081896 ops/training.py:65 2019-01-16 19:57:39.081755: step 1278, loss = 0.69604 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:57:39.974494 ops/training.py:65 2019-01-16 19:57:39.974393: step 1279, loss = 0.72326 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:57:40.867722 ops/training.py:65 2019-01-16 19:57:40.867622: step 1280, loss = 0.70941 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:57:41.757556 ops/training.py:65 2019-01-16 19:57:41.757455: step 1281, loss = 0.72051 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:57:42.647358 ops/training.py:65 2019-01-16 19:57:42.647298: step 1282, loss = 0.69834 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:57:43.537664 ops/training.py:65 2019-01-16 19:57:43.537597: step 1283, loss = 0.72524 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:57:44.427218 ops/training.py:65 2019-01-16 19:57:44.427157: step 1284, loss = 0.70631 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:57:45.315667 ops/training.py:65 2019-01-16 19:57:45.315605: step 1285, loss = 0.68994 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:57:46.204958 ops/training.py:65 2019-01-16 19:57:46.204897: step 1286, loss = 0.71965 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:57:47.094746 ops/training.py:65 2019-01-16 19:57:47.094684: step 1287, loss = 0.73048 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:57:47.983993 ops/training.py:65 2019-01-16 19:57:47.983933: step 1288, loss = 0.65956 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:57:48.874037 ops/training.py:65 2019-01-16 19:57:48.873982: step 1289, loss = 0.66382 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:57:49.766768 ops/training.py:65 2019-01-16 19:57:49.766661: step 1290, loss = 0.65125 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:57:50.661410 ops/training.py:65 2019-01-16 19:57:50.661315: step 1291, loss = 0.69795 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:57:51.553532 ops/training.py:65 2019-01-16 19:57:51.553430: step 1292, loss = 0.76109 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 19:57:52.444449 ops/training.py:65 2019-01-16 19:57:52.444388: step 1293, loss = 0.80230 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:57:53.334292 ops/training.py:65 2019-01-16 19:57:53.334231: step 1294, loss = 0.70698 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:57:54.224114 ops/training.py:65 2019-01-16 19:57:54.224058: step 1295, loss = 0.67383 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:57:55.113105 ops/training.py:65 2019-01-16 19:57:55.113041: step 1296, loss = 0.67624 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:57:56.002316 ops/training.py:65 2019-01-16 19:57:56.002253: step 1297, loss = 0.67910 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:57:56.891773 ops/training.py:65 2019-01-16 19:57:56.891712: step 1298, loss = 0.72200 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:57:57.781356 ops/training.py:65 2019-01-16 19:57:57.781302: step 1299, loss = 0.82965 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.25
I2992 2019-01-16 19:57:58.670259 ops/training.py:65 2019-01-16 19:57:58.670209: step 1300, loss = 0.65076 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:57:59.560231 ops/training.py:65 2019-01-16 19:57:59.560175: step 1301, loss = 0.69920 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:58:00.449903 ops/training.py:65 2019-01-16 19:58:00.449836: step 1302, loss = 0.79231 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:58:01.339491 ops/training.py:65 2019-01-16 19:58:01.339429: step 1303, loss = 0.78505 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:58:02.229860 ops/training.py:65 2019-01-16 19:58:02.229782: step 1304, loss = 0.66848 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:58:03.123017 ops/training.py:65 2019-01-16 19:58:03.122918: step 1305, loss = 0.66750 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:58:04.016282 ops/training.py:65 2019-01-16 19:58:04.016182: step 1306, loss = 0.75408 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:58:04.906138 ops/training.py:65 2019-01-16 19:58:04.906081: step 1307, loss = 0.67904 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:58:05.795564 ops/training.py:65 2019-01-16 19:58:05.795509: step 1308, loss = 0.76680 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:58:06.683466 ops/training.py:65 2019-01-16 19:58:06.683410: step 1309, loss = 0.69872 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:58:07.572931 ops/training.py:65 2019-01-16 19:58:07.572874: step 1310, loss = 0.74075 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:58:08.462176 ops/training.py:65 2019-01-16 19:58:08.462116: step 1311, loss = 0.67284 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:58:09.351249 ops/training.py:65 2019-01-16 19:58:09.351196: step 1312, loss = 0.76131 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:58:10.240023 ops/training.py:65 2019-01-16 19:58:10.239952: step 1313, loss = 0.70073 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:58:11.129810 ops/training.py:65 2019-01-16 19:58:11.129749: step 1314, loss = 0.70343 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:58:12.018882 ops/training.py:65 2019-01-16 19:58:12.018817: step 1315, loss = 0.69212 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:58:12.909086 ops/training.py:65 2019-01-16 19:58:12.909024: step 1316, loss = 0.70482 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:58:13.801804 ops/training.py:65 2019-01-16 19:58:13.801722: step 1317, loss = 0.69274 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:58:14.693972 ops/training.py:65 2019-01-16 19:58:14.693885: step 1318, loss = 0.67625 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:58:15.587144 ops/training.py:65 2019-01-16 19:58:15.587040: step 1319, loss = 0.66912 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:58:16.478142 ops/training.py:65 2019-01-16 19:58:16.478080: step 1320, loss = 0.71982 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:58:17.370324 ops/training.py:65 2019-01-16 19:58:17.370270: step 1321, loss = 0.72407 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:58:18.262119 ops/training.py:65 2019-01-16 19:58:18.262020: step 1322, loss = 0.71106 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:58:19.154899 ops/training.py:65 2019-01-16 19:58:19.154809: step 1323, loss = 0.68706 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:58:20.045600 ops/training.py:65 2019-01-16 19:58:20.045539: step 1324, loss = 0.71808 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:58:20.935701 ops/training.py:65 2019-01-16 19:58:20.935641: step 1325, loss = 0.70904 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:58:21.826162 ops/training.py:65 2019-01-16 19:58:21.826106: step 1326, loss = 0.75313 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:58:22.716944 ops/training.py:65 2019-01-16 19:58:22.716884: step 1327, loss = 0.73668 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:58:23.607212 ops/training.py:65 2019-01-16 19:58:23.607147: step 1328, loss = 0.73768 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:58:24.496547 ops/training.py:65 2019-01-16 19:58:24.496485: step 1329, loss = 0.70794 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:58:25.387332 ops/training.py:65 2019-01-16 19:58:25.387268: step 1330, loss = 0.70878 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:58:26.277236 ops/training.py:65 2019-01-16 19:58:26.277177: step 1331, loss = 0.70802 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:58:27.166790 ops/training.py:65 2019-01-16 19:58:27.166727: step 1332, loss = 0.69452 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:58:28.056450 ops/training.py:65 2019-01-16 19:58:28.056383: step 1333, loss = 0.67256 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:58:28.945837 ops/training.py:65 2019-01-16 19:58:28.945776: step 1334, loss = 0.71050 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:58:29.834355 ops/training.py:65 2019-01-16 19:58:29.834299: step 1335, loss = 0.72110 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:58:30.723240 ops/training.py:65 2019-01-16 19:58:30.723178: step 1336, loss = 0.69519 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:58:31.613027 ops/training.py:65 2019-01-16 19:58:31.612960: step 1337, loss = 0.70287 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:58:32.503851 ops/training.py:65 2019-01-16 19:58:32.503756: step 1338, loss = 0.68758 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:58:33.397501 ops/training.py:65 2019-01-16 19:58:33.397408: step 1339, loss = 0.69193 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:58:34.289434 ops/training.py:65 2019-01-16 19:58:34.289330: step 1340, loss = 0.71913 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:58:35.180809 ops/training.py:65 2019-01-16 19:58:35.180750: step 1341, loss = 0.66137 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 19:58:36.069696 ops/training.py:65 2019-01-16 19:58:36.069634: step 1342, loss = 0.67928 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:58:36.959622 ops/training.py:65 2019-01-16 19:58:36.959561: step 1343, loss = 0.71279 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:58:37.850306 ops/training.py:65 2019-01-16 19:58:37.850236: step 1344, loss = 0.71185 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:58:38.742616 ops/training.py:65 2019-01-16 19:58:38.742526: step 1345, loss = 0.69362 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:58:39.635791 ops/training.py:65 2019-01-16 19:58:39.635686: step 1346, loss = 0.72298 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:58:40.528042 ops/training.py:65 2019-01-16 19:58:40.527954: step 1347, loss = 0.70632 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:58:41.418295 ops/training.py:65 2019-01-16 19:58:41.418233: step 1348, loss = 0.67811 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:58:42.307054 ops/training.py:65 2019-01-16 19:58:42.306995: step 1349, loss = 0.69948 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:58:43.196360 ops/training.py:65 2019-01-16 19:58:43.196297: step 1350, loss = 0.71073 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:58:44.087903 ops/training.py:65 2019-01-16 19:58:44.087836: step 1351, loss = 0.67403 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:58:44.980681 ops/training.py:65 2019-01-16 19:58:44.980583: step 1352, loss = 0.68354 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:58:45.872226 ops/training.py:65 2019-01-16 19:58:45.872167: step 1353, loss = 0.72136 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:58:46.760668 ops/training.py:65 2019-01-16 19:58:46.760605: step 1354, loss = 0.74429 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:58:47.650312 ops/training.py:65 2019-01-16 19:58:47.650252: step 1355, loss = 0.72344 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:58:48.539715 ops/training.py:65 2019-01-16 19:58:48.539662: step 1356, loss = 0.74495 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:58:49.428418 ops/training.py:65 2019-01-16 19:58:49.428359: step 1357, loss = 0.71467 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:58:50.317536 ops/training.py:65 2019-01-16 19:58:50.317479: step 1358, loss = 0.68224 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:58:51.206569 ops/training.py:65 2019-01-16 19:58:51.206510: step 1359, loss = 0.68653 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:58:52.096138 ops/training.py:65 2019-01-16 19:58:52.096070: step 1360, loss = 0.70227 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:58:52.984700 ops/training.py:65 2019-01-16 19:58:52.984629: step 1361, loss = 0.66786 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:58:53.873884 ops/training.py:65 2019-01-16 19:58:53.873822: step 1362, loss = 0.73566 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:58:54.763899 ops/training.py:65 2019-01-16 19:58:54.763835: step 1363, loss = 0.70389 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:58:55.653332 ops/training.py:65 2019-01-16 19:58:55.653271: step 1364, loss = 0.69143 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:58:56.544194 ops/training.py:65 2019-01-16 19:58:56.544136: step 1365, loss = 0.71415 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:58:57.436993 ops/training.py:65 2019-01-16 19:58:57.436886: step 1366, loss = 0.75709 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 19:58:58.329449 ops/training.py:65 2019-01-16 19:58:58.329361: step 1367, loss = 0.68193 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:58:59.219474 ops/training.py:65 2019-01-16 19:58:59.219409: step 1368, loss = 0.70533 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:59:00.108658 ops/training.py:65 2019-01-16 19:59:00.108590: step 1369, loss = 0.74232 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 19:59:00.997642 ops/training.py:65 2019-01-16 19:59:00.997581: step 1370, loss = 0.70499 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:59:01.887945 ops/training.py:65 2019-01-16 19:59:01.887873: step 1371, loss = 0.67033 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:59:02.780714 ops/training.py:65 2019-01-16 19:59:02.780607: step 1372, loss = 0.68894 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:59:03.672714 ops/training.py:65 2019-01-16 19:59:03.672621: step 1373, loss = 0.70763 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:59:04.565980 ops/training.py:65 2019-01-16 19:59:04.565841: step 1374, loss = 0.70807 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:59:05.457587 ops/training.py:65 2019-01-16 19:59:05.457521: step 1375, loss = 0.72312 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:59:06.346738 ops/training.py:65 2019-01-16 19:59:06.346673: step 1376, loss = 0.73046 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:59:07.236710 ops/training.py:65 2019-01-16 19:59:07.236645: step 1377, loss = 0.70001 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:59:08.126221 ops/training.py:65 2019-01-16 19:59:08.126157: step 1378, loss = 0.70012 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:59:09.016094 ops/training.py:65 2019-01-16 19:59:09.016028: step 1379, loss = 0.68424 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:59:09.905772 ops/training.py:65 2019-01-16 19:59:09.905715: step 1380, loss = 0.71837 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:59:10.794825 ops/training.py:65 2019-01-16 19:59:10.794767: step 1381, loss = 0.69599 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:59:11.685607 ops/training.py:65 2019-01-16 19:59:11.685524: step 1382, loss = 0.69718 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:59:12.578160 ops/training.py:65 2019-01-16 19:59:12.578063: step 1383, loss = 0.71432 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:59:13.470891 ops/training.py:65 2019-01-16 19:59:13.470802: step 1384, loss = 0.69965 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:59:14.361723 ops/training.py:65 2019-01-16 19:59:14.361668: step 1385, loss = 0.69756 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:59:15.252790 ops/training.py:65 2019-01-16 19:59:15.252734: step 1386, loss = 0.68874 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:59:16.142318 ops/training.py:65 2019-01-16 19:59:16.142251: step 1387, loss = 0.67444 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 19:59:17.031491 ops/training.py:65 2019-01-16 19:59:17.031434: step 1388, loss = 0.65884 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:59:17.920890 ops/training.py:65 2019-01-16 19:59:17.920835: step 1389, loss = 0.68711 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:59:18.810043 ops/training.py:65 2019-01-16 19:59:18.809968: step 1390, loss = 0.69957 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:59:19.699095 ops/training.py:65 2019-01-16 19:59:19.699040: step 1391, loss = 0.70291 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:59:20.588302 ops/training.py:65 2019-01-16 19:59:20.588252: step 1392, loss = 0.71788 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:59:21.477946 ops/training.py:65 2019-01-16 19:59:21.477888: step 1393, loss = 0.70635 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:59:22.366576 ops/training.py:65 2019-01-16 19:59:22.366515: step 1394, loss = 0.73471 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:59:23.256358 ops/training.py:65 2019-01-16 19:59:23.256295: step 1395, loss = 0.78072 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:59:24.145920 ops/training.py:65 2019-01-16 19:59:24.145860: step 1396, loss = 0.72986 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:59:25.035648 ops/training.py:65 2019-01-16 19:59:25.035590: step 1397, loss = 0.70825 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:59:25.924926 ops/training.py:65 2019-01-16 19:59:25.924868: step 1398, loss = 0.71949 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:59:26.814782 ops/training.py:65 2019-01-16 19:59:26.814720: step 1399, loss = 0.73494 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:59:27.704725 ops/training.py:65 2019-01-16 19:59:27.704661: step 1400, loss = 0.67897 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:59:28.593935 ops/training.py:65 2019-01-16 19:59:28.593878: step 1401, loss = 0.68698 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:59:29.483902 ops/training.py:65 2019-01-16 19:59:29.483838: step 1402, loss = 0.71181 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:59:30.373212 ops/training.py:65 2019-01-16 19:59:30.373153: step 1403, loss = 0.69877 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 19:59:31.263618 ops/training.py:65 2019-01-16 19:59:31.263554: step 1404, loss = 0.71448 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:59:32.154888 ops/training.py:65 2019-01-16 19:59:32.154793: step 1405, loss = 0.69629 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:59:33.046281 ops/training.py:65 2019-01-16 19:59:33.046183: step 1406, loss = 0.70589 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:59:33.938795 ops/training.py:65 2019-01-16 19:59:33.938692: step 1407, loss = 0.68968 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:59:34.830532 ops/training.py:65 2019-01-16 19:59:34.830432: step 1408, loss = 0.72050 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:59:35.720871 ops/training.py:65 2019-01-16 19:59:35.720804: step 1409, loss = 0.69819 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:59:36.610113 ops/training.py:65 2019-01-16 19:59:36.610054: step 1410, loss = 0.72297 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:59:37.499494 ops/training.py:65 2019-01-16 19:59:37.499435: step 1411, loss = 0.71758 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:59:38.388587 ops/training.py:65 2019-01-16 19:59:38.388528: step 1412, loss = 0.68570 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:59:39.278842 ops/training.py:65 2019-01-16 19:59:39.278779: step 1413, loss = 0.70145 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:59:40.168494 ops/training.py:65 2019-01-16 19:59:40.168433: step 1414, loss = 0.71085 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:59:41.057914 ops/training.py:65 2019-01-16 19:59:41.057836: step 1415, loss = 0.69861 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:59:41.946596 ops/training.py:65 2019-01-16 19:59:41.946532: step 1416, loss = 0.70515 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:59:42.837802 ops/training.py:65 2019-01-16 19:59:42.837736: step 1417, loss = 0.67693 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 19:59:43.730665 ops/training.py:65 2019-01-16 19:59:43.730565: step 1418, loss = 0.69761 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:59:44.622396 ops/training.py:65 2019-01-16 19:59:44.622251: step 1419, loss = 0.68713 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:59:45.513959 ops/training.py:65 2019-01-16 19:59:45.513840: step 1420, loss = 0.70532 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:59:46.405431 ops/training.py:65 2019-01-16 19:59:46.405337: step 1421, loss = 0.64420 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 19:59:47.295177 ops/training.py:65 2019-01-16 19:59:47.295076: step 1422, loss = 0.67764 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:59:48.186284 ops/training.py:65 2019-01-16 19:59:48.186216: step 1423, loss = 0.72769 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 19:59:49.076670 ops/training.py:65 2019-01-16 19:59:49.076601: step 1424, loss = 0.68845 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:59:49.965667 ops/training.py:65 2019-01-16 19:59:49.965605: step 1425, loss = 0.68494 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:59:50.856112 ops/training.py:65 2019-01-16 19:59:50.856043: step 1426, loss = 0.70569 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 19:59:51.746342 ops/training.py:65 2019-01-16 19:59:51.746272: step 1427, loss = 0.69815 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:59:52.636298 ops/training.py:65 2019-01-16 19:59:52.636235: step 1428, loss = 0.73554 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 19:59:53.525738 ops/training.py:65 2019-01-16 19:59:53.525672: step 1429, loss = 0.69458 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 19:59:54.415300 ops/training.py:65 2019-01-16 19:59:54.415235: step 1430, loss = 0.66350 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 19:59:55.305597 ops/training.py:65 2019-01-16 19:59:55.305532: step 1431, loss = 0.74940 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:59:56.195010 ops/training.py:65 2019-01-16 19:59:56.194945: step 1432, loss = 0.74576 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 19:59:57.083841 ops/training.py:65 2019-01-16 19:59:57.083780: step 1433, loss = 0.72350 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 19:59:57.974079 ops/training.py:65 2019-01-16 19:59:57.974023: step 1434, loss = 0.74983 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 19:59:58.864389 ops/training.py:65 2019-01-16 19:59:58.864336: step 1435, loss = 0.68950 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 19:59:59.753261 ops/training.py:65 2019-01-16 19:59:59.753206: step 1436, loss = 0.69270 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:00:00.642398 ops/training.py:65 2019-01-16 20:00:00.642338: step 1437, loss = 0.66456 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:00:01.533915 ops/training.py:65 2019-01-16 20:00:01.533848: step 1438, loss = 0.69907 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:00:02.426478 ops/training.py:65 2019-01-16 20:00:02.426383: step 1439, loss = 0.69016 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:00:03.320616 ops/training.py:65 2019-01-16 20:00:03.320533: step 1440, loss = 0.67710 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:00:04.213276 ops/training.py:65 2019-01-16 20:00:04.213179: step 1441, loss = 0.68464 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:00:05.105865 ops/training.py:65 2019-01-16 20:00:05.105774: step 1442, loss = 0.75053 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:00:05.997612 ops/training.py:65 2019-01-16 20:00:05.997526: step 1443, loss = 0.68772 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:00:06.890539 ops/training.py:65 2019-01-16 20:00:06.890439: step 1444, loss = 0.68473 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:00:07.782551 ops/training.py:65 2019-01-16 20:00:07.782454: step 1445, loss = 0.72880 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:00:08.676958 ops/training.py:65 2019-01-16 20:00:08.676888: step 1446, loss = 0.71630 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:00:09.565847 ops/training.py:65 2019-01-16 20:00:09.565777: step 1447, loss = 0.71204 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:00:10.455191 ops/training.py:65 2019-01-16 20:00:10.455129: step 1448, loss = 0.72476 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:00:11.344354 ops/training.py:65 2019-01-16 20:00:11.344290: step 1449, loss = 0.70191 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:00:12.233816 ops/training.py:65 2019-01-16 20:00:12.233746: step 1450, loss = 0.69843 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:00:13.125347 ops/training.py:65 2019-01-16 20:00:13.125278: step 1451, loss = 0.68121 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:00:14.017955 ops/training.py:65 2019-01-16 20:00:14.017862: step 1452, loss = 0.68350 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:00:14.909028 ops/training.py:65 2019-01-16 20:00:14.908970: step 1453, loss = 0.68436 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:00:15.801346 ops/training.py:65 2019-01-16 20:00:15.801244: step 1454, loss = 0.71927 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:00:16.693716 ops/training.py:65 2019-01-16 20:00:16.693588: step 1455, loss = 0.73530 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:00:17.586024 ops/training.py:65 2019-01-16 20:00:17.585922: step 1456, loss = 0.74498 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:00:18.477307 ops/training.py:65 2019-01-16 20:00:18.477249: step 1457, loss = 0.68698 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:00:19.367535 ops/training.py:65 2019-01-16 20:00:19.367469: step 1458, loss = 0.68523 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:00:20.256842 ops/training.py:65 2019-01-16 20:00:20.256786: step 1459, loss = 0.72578 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:00:21.148512 ops/training.py:65 2019-01-16 20:00:21.148459: step 1460, loss = 0.70755 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:00:22.041084 ops/training.py:65 2019-01-16 20:00:22.040992: step 1461, loss = 0.73337 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:00:22.934518 ops/training.py:65 2019-01-16 20:00:22.934412: step 1462, loss = 0.69649 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:00:23.827021 ops/training.py:65 2019-01-16 20:00:23.826958: step 1463, loss = 0.67998 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:00:24.716355 ops/training.py:65 2019-01-16 20:00:24.716292: step 1464, loss = 0.73053 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:00:25.605600 ops/training.py:65 2019-01-16 20:00:25.605540: step 1465, loss = 0.74572 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:00:26.495289 ops/training.py:65 2019-01-16 20:00:26.495217: step 1466, loss = 0.73857 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:00:27.386968 ops/training.py:65 2019-01-16 20:00:27.386868: step 1467, loss = 0.69602 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:00:28.278431 ops/training.py:65 2019-01-16 20:00:28.278331: step 1468, loss = 0.72440 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:00:29.171507 ops/training.py:65 2019-01-16 20:00:29.171406: step 1469, loss = 0.64199 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:00:30.063879 ops/training.py:65 2019-01-16 20:00:30.063823: step 1470, loss = 0.68185 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:00:30.953945 ops/training.py:65 2019-01-16 20:00:30.953892: step 1471, loss = 0.69135 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:00:31.843241 ops/training.py:65 2019-01-16 20:00:31.843182: step 1472, loss = 0.68465 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:00:32.733245 ops/training.py:65 2019-01-16 20:00:32.733188: step 1473, loss = 0.75258 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:00:33.622710 ops/training.py:65 2019-01-16 20:00:33.622646: step 1474, loss = 0.75070 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:00:34.511929 ops/training.py:65 2019-01-16 20:00:34.511877: step 1475, loss = 0.66543 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:00:35.401424 ops/training.py:65 2019-01-16 20:00:35.401373: step 1476, loss = 0.72250 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:00:36.291321 ops/training.py:65 2019-01-16 20:00:36.291258: step 1477, loss = 0.72631 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:00:37.181383 ops/training.py:65 2019-01-16 20:00:37.181320: step 1478, loss = 0.68027 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:00:38.070916 ops/training.py:65 2019-01-16 20:00:38.070855: step 1479, loss = 0.71428 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:00:38.960038 ops/training.py:65 2019-01-16 20:00:38.959974: step 1480, loss = 0.71779 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:00:39.851074 ops/training.py:65 2019-01-16 20:00:39.851013: step 1481, loss = 0.71380 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:00:40.742410 ops/training.py:65 2019-01-16 20:00:40.742352: step 1482, loss = 0.68409 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:00:41.632308 ops/training.py:65 2019-01-16 20:00:41.632253: step 1483, loss = 0.69788 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:00:42.521768 ops/training.py:65 2019-01-16 20:00:42.521712: step 1484, loss = 0.72560 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:00:43.411581 ops/training.py:65 2019-01-16 20:00:43.411521: step 1485, loss = 0.72280 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:00:44.302138 ops/training.py:65 2019-01-16 20:00:44.302082: step 1486, loss = 0.66992 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:00:45.193078 ops/training.py:65 2019-01-16 20:00:45.193018: step 1487, loss = 0.71812 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:00:46.083586 ops/training.py:65 2019-01-16 20:00:46.083526: step 1488, loss = 0.70622 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:00:46.975084 ops/training.py:65 2019-01-16 20:00:46.974998: step 1489, loss = 0.71009 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:00:47.867690 ops/training.py:65 2019-01-16 20:00:47.867591: step 1490, loss = 0.69783 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:00:48.759647 ops/training.py:65 2019-01-16 20:00:48.759576: step 1491, loss = 0.68853 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:00:49.648896 ops/training.py:65 2019-01-16 20:00:49.648832: step 1492, loss = 0.71965 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:00:50.539470 ops/training.py:65 2019-01-16 20:00:50.539413: step 1493, loss = 0.69335 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:00:51.429923 ops/training.py:65 2019-01-16 20:00:51.429864: step 1494, loss = 0.74340 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:00:52.320106 ops/training.py:65 2019-01-16 20:00:52.320046: step 1495, loss = 0.68115 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:00:53.210567 ops/training.py:65 2019-01-16 20:00:53.210499: step 1496, loss = 0.71229 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:00:54.101210 ops/training.py:65 2019-01-16 20:00:54.101148: step 1497, loss = 0.67914 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:00:54.991716 ops/training.py:65 2019-01-16 20:00:54.991652: step 1498, loss = 0.67984 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:00:55.881924 ops/training.py:65 2019-01-16 20:00:55.881855: step 1499, loss = 0.68311 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:00:56.771836 ops/training.py:65 2019-01-16 20:00:56.771777: step 1500, loss = 0.67955 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:00:57.660748 ops/training.py:65 2019-01-16 20:00:57.660689: step 1501, loss = 0.70445 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:00:58.550551 ops/training.py:65 2019-01-16 20:00:58.550494: step 1502, loss = 0.71230 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:00:59.440566 ops/training.py:65 2019-01-16 20:00:59.440503: step 1503, loss = 0.68204 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:01:00.330844 ops/training.py:65 2019-01-16 20:01:00.330785: step 1504, loss = 0.70963 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:01:01.219747 ops/training.py:65 2019-01-16 20:01:01.219690: step 1505, loss = 0.65072 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.78125
I2992 2019-01-16 20:01:02.108432 ops/training.py:65 2019-01-16 20:01:02.108379: step 1506, loss = 0.68774 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:01:02.997760 ops/training.py:65 2019-01-16 20:01:02.997697: step 1507, loss = 0.69014 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:01:03.887471 ops/training.py:65 2019-01-16 20:01:03.887406: step 1508, loss = 0.68465 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:01:04.777440 ops/training.py:65 2019-01-16 20:01:04.777380: step 1509, loss = 0.67433 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:01:05.666262 ops/training.py:65 2019-01-16 20:01:05.666206: step 1510, loss = 0.69426 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:01:06.555301 ops/training.py:65 2019-01-16 20:01:06.555246: step 1511, loss = 0.69794 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:01:07.444665 ops/training.py:65 2019-01-16 20:01:07.444605: step 1512, loss = 0.72202 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:01:08.335298 ops/training.py:65 2019-01-16 20:01:08.335239: step 1513, loss = 0.66772 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:01:09.225560 ops/training.py:65 2019-01-16 20:01:09.225503: step 1514, loss = 0.69047 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:01:10.115067 ops/training.py:65 2019-01-16 20:01:10.115005: step 1515, loss = 0.69444 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:01:11.003677 ops/training.py:65 2019-01-16 20:01:11.003616: step 1516, loss = 0.70339 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:01:11.893312 ops/training.py:65 2019-01-16 20:01:11.893253: step 1517, loss = 0.71245 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:01:12.783930 ops/training.py:65 2019-01-16 20:01:12.783868: step 1518, loss = 0.67017 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:01:13.673474 ops/training.py:65 2019-01-16 20:01:13.673409: step 1519, loss = 0.68652 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:01:14.564228 ops/training.py:65 2019-01-16 20:01:14.564144: step 1520, loss = 0.73455 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:01:15.456263 ops/training.py:65 2019-01-16 20:01:15.456164: step 1521, loss = 0.69762 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:01:16.347441 ops/training.py:65 2019-01-16 20:01:16.347353: step 1522, loss = 0.68513 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:01:17.239638 ops/training.py:65 2019-01-16 20:01:17.239539: step 1523, loss = 0.69779 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:01:18.130481 ops/training.py:65 2019-01-16 20:01:18.130422: step 1524, loss = 0.68405 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:01:19.019370 ops/training.py:65 2019-01-16 20:01:19.019311: step 1525, loss = 0.66545 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:01:19.907966 ops/training.py:65 2019-01-16 20:01:19.907905: step 1526, loss = 0.75478 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:01:20.802634 ops/training.py:65 2019-01-16 20:01:20.802567: step 1527, loss = 0.67826 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:01:21.693448 ops/training.py:65 2019-01-16 20:01:21.693349: step 1528, loss = 0.70212 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:01:22.586984 ops/training.py:65 2019-01-16 20:01:22.586895: step 1529, loss = 0.69807 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:01:23.478727 ops/training.py:65 2019-01-16 20:01:23.478652: step 1530, loss = 0.69175 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:01:24.368462 ops/training.py:65 2019-01-16 20:01:24.368379: step 1531, loss = 0.71302 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:01:25.257989 ops/training.py:65 2019-01-16 20:01:25.257926: step 1532, loss = 0.70059 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:01:26.147403 ops/training.py:65 2019-01-16 20:01:26.147347: step 1533, loss = 0.69274 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:01:27.036355 ops/training.py:65 2019-01-16 20:01:27.036296: step 1534, loss = 0.65229 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:01:27.925794 ops/training.py:65 2019-01-16 20:01:27.925737: step 1535, loss = 0.68614 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:01:28.815273 ops/training.py:65 2019-01-16 20:01:28.815214: step 1536, loss = 0.70778 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:01:29.703973 ops/training.py:65 2019-01-16 20:01:29.703910: step 1537, loss = 0.67524 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:01:30.593062 ops/training.py:65 2019-01-16 20:01:30.593002: step 1538, loss = 0.68708 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:01:31.482920 ops/training.py:65 2019-01-16 20:01:31.482853: step 1539, loss = 0.68926 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:01:32.372041 ops/training.py:65 2019-01-16 20:01:32.371979: step 1540, loss = 0.68874 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:01:33.261255 ops/training.py:65 2019-01-16 20:01:33.261188: step 1541, loss = 0.70055 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:01:34.151276 ops/training.py:65 2019-01-16 20:01:34.151217: step 1542, loss = 0.68235 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:01:35.041272 ops/training.py:65 2019-01-16 20:01:35.041211: step 1543, loss = 0.71717 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:01:35.930693 ops/training.py:65 2019-01-16 20:01:35.930620: step 1544, loss = 0.70747 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:01:36.819830 ops/training.py:65 2019-01-16 20:01:36.819756: step 1545, loss = 0.66103 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:01:37.709499 ops/training.py:65 2019-01-16 20:01:37.709432: step 1546, loss = 0.72086 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:01:38.599268 ops/training.py:65 2019-01-16 20:01:38.599195: step 1547, loss = 0.68239 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:01:39.487883 ops/training.py:65 2019-01-16 20:01:39.487821: step 1548, loss = 0.75805 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 20:01:40.376613 ops/training.py:65 2019-01-16 20:01:40.376548: step 1549, loss = 0.67579 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:01:41.265566 ops/training.py:65 2019-01-16 20:01:41.265489: step 1550, loss = 0.78066 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:01:42.154940 ops/training.py:65 2019-01-16 20:01:42.154876: step 1551, loss = 0.73448 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:01:43.044956 ops/training.py:65 2019-01-16 20:01:43.044893: step 1552, loss = 0.70564 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:01:43.934420 ops/training.py:65 2019-01-16 20:01:43.934357: step 1553, loss = 0.69450 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:01:44.825159 ops/training.py:65 2019-01-16 20:01:44.825068: step 1554, loss = 0.68818 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:01:45.715877 ops/training.py:65 2019-01-16 20:01:45.715746: step 1555, loss = 0.68252 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:01:46.606495 ops/training.py:65 2019-01-16 20:01:46.606409: step 1556, loss = 0.70274 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:01:47.497694 ops/training.py:65 2019-01-16 20:01:47.497590: step 1557, loss = 0.69996 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:01:48.390076 ops/training.py:65 2019-01-16 20:01:48.389965: step 1558, loss = 0.74048 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:01:49.282718 ops/training.py:65 2019-01-16 20:01:49.282621: step 1559, loss = 0.71950 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:01:50.172980 ops/training.py:65 2019-01-16 20:01:50.172915: step 1560, loss = 0.67255 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:01:51.062345 ops/training.py:65 2019-01-16 20:01:51.062282: step 1561, loss = 0.66621 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:01:51.951538 ops/training.py:65 2019-01-16 20:01:51.951477: step 1562, loss = 0.67391 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:01:52.840550 ops/training.py:65 2019-01-16 20:01:52.840484: step 1563, loss = 0.69116 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:01:53.729360 ops/training.py:65 2019-01-16 20:01:53.729290: step 1564, loss = 0.72369 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:01:54.619613 ops/training.py:65 2019-01-16 20:01:54.619548: step 1565, loss = 0.70964 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:01:55.508559 ops/training.py:65 2019-01-16 20:01:55.508500: step 1566, loss = 0.68280 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:01:56.399535 ops/training.py:65 2019-01-16 20:01:56.399474: step 1567, loss = 0.72201 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:01:57.291163 ops/training.py:65 2019-01-16 20:01:57.291110: step 1568, loss = 0.69783 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:01:58.182960 ops/training.py:65 2019-01-16 20:01:58.182884: step 1569, loss = 0.69121 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:01:59.075147 ops/training.py:65 2019-01-16 20:01:59.075045: step 1570, loss = 0.67813 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:01:59.967931 ops/training.py:65 2019-01-16 20:01:59.967843: step 1571, loss = 0.67025 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:02:00.857549 ops/training.py:65 2019-01-16 20:02:00.857488: step 1572, loss = 0.70854 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:02:01.746778 ops/training.py:65 2019-01-16 20:02:01.746713: step 1573, loss = 0.69843 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:02:02.637241 ops/training.py:65 2019-01-16 20:02:02.637170: step 1574, loss = 0.71622 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:02:03.529857 ops/training.py:65 2019-01-16 20:02:03.529773: step 1575, loss = 0.71473 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:02:04.422399 ops/training.py:65 2019-01-16 20:02:04.422314: step 1576, loss = 0.67739 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:02:05.316085 ops/training.py:65 2019-01-16 20:02:05.315980: step 1577, loss = 0.72567 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:02:06.207267 ops/training.py:65 2019-01-16 20:02:06.207167: step 1578, loss = 0.65974 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:02:07.098800 ops/training.py:65 2019-01-16 20:02:07.098737: step 1579, loss = 0.72387 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:02:07.988119 ops/training.py:65 2019-01-16 20:02:07.988061: step 1580, loss = 0.68399 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:02:08.877315 ops/training.py:65 2019-01-16 20:02:08.877242: step 1581, loss = 0.68225 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:02:09.767392 ops/training.py:65 2019-01-16 20:02:09.767328: step 1582, loss = 0.70150 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:02:10.656699 ops/training.py:65 2019-01-16 20:02:10.656639: step 1583, loss = 0.65989 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:02:11.546275 ops/training.py:65 2019-01-16 20:02:11.546212: step 1584, loss = 0.68502 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:02:12.438093 ops/training.py:65 2019-01-16 20:02:12.438024: step 1585, loss = 0.70238 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:02:13.330854 ops/training.py:65 2019-01-16 20:02:13.330759: step 1586, loss = 0.71562 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:02:14.223042 ops/training.py:65 2019-01-16 20:02:14.222944: step 1587, loss = 0.64455 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.75
I2992 2019-01-16 20:02:15.114756 ops/training.py:65 2019-01-16 20:02:15.114695: step 1588, loss = 0.71522 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:02:16.005799 ops/training.py:65 2019-01-16 20:02:16.005742: step 1589, loss = 0.72950 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:02:16.896297 ops/training.py:65 2019-01-16 20:02:16.896242: step 1590, loss = 0.70595 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:02:17.787489 ops/training.py:65 2019-01-16 20:02:17.787425: step 1591, loss = 0.68063 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:02:18.679939 ops/training.py:65 2019-01-16 20:02:18.679837: step 1592, loss = 0.70278 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:02:19.572565 ops/training.py:65 2019-01-16 20:02:19.572465: step 1593, loss = 0.66813 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:02:20.463577 ops/training.py:65 2019-01-16 20:02:20.463509: step 1594, loss = 0.74452 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:02:21.352718 ops/training.py:65 2019-01-16 20:02:21.352658: step 1595, loss = 0.70805 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:02:22.242059 ops/training.py:65 2019-01-16 20:02:22.241997: step 1596, loss = 0.71658 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:02:23.131679 ops/training.py:65 2019-01-16 20:02:23.131615: step 1597, loss = 0.70362 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:02:24.020831 ops/training.py:65 2019-01-16 20:02:24.020769: step 1598, loss = 0.68624 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:02:24.910287 ops/training.py:65 2019-01-16 20:02:24.910221: step 1599, loss = 0.73548 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:02:25.799377 ops/training.py:65 2019-01-16 20:02:25.799310: step 1600, loss = 0.67257 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:02:26.689113 ops/training.py:65 2019-01-16 20:02:26.689031: step 1601, loss = 0.69339 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:02:27.582460 ops/training.py:65 2019-01-16 20:02:27.582350: step 1602, loss = 0.71454 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:02:28.475098 ops/training.py:65 2019-01-16 20:02:28.475003: step 1603, loss = 0.69233 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:02:29.367375 ops/training.py:65 2019-01-16 20:02:29.367274: step 1604, loss = 0.70856 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:02:30.258570 ops/training.py:65 2019-01-16 20:02:30.258507: step 1605, loss = 0.68842 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:02:31.147454 ops/training.py:65 2019-01-16 20:02:31.147398: step 1606, loss = 0.72696 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:02:32.035823 ops/training.py:65 2019-01-16 20:02:32.035764: step 1607, loss = 0.69439 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:02:32.924966 ops/training.py:65 2019-01-16 20:02:32.924900: step 1608, loss = 0.72121 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:02:33.814760 ops/training.py:65 2019-01-16 20:02:33.814686: step 1609, loss = 0.69793 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:02:34.705399 ops/training.py:65 2019-01-16 20:02:34.705316: step 1610, loss = 0.67774 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:02:35.597218 ops/training.py:65 2019-01-16 20:02:35.597118: step 1611, loss = 0.67707 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:02:36.490068 ops/training.py:65 2019-01-16 20:02:36.489969: step 1612, loss = 0.73259 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:02:37.382056 ops/training.py:65 2019-01-16 20:02:37.381958: step 1613, loss = 0.71632 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:02:38.273100 ops/training.py:65 2019-01-16 20:02:38.273032: step 1614, loss = 0.71822 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:02:39.162883 ops/training.py:65 2019-01-16 20:02:39.162824: step 1615, loss = 0.73004 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:02:40.053024 ops/training.py:65 2019-01-16 20:02:40.052961: step 1616, loss = 0.71994 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:02:40.942419 ops/training.py:65 2019-01-16 20:02:40.942361: step 1617, loss = 0.70053 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:02:41.831964 ops/training.py:65 2019-01-16 20:02:41.831901: step 1618, loss = 0.72617 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:02:42.721103 ops/training.py:65 2019-01-16 20:02:42.721039: step 1619, loss = 0.71296 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:02:43.611547 ops/training.py:65 2019-01-16 20:02:43.611481: step 1620, loss = 0.69066 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:02:44.501543 ops/training.py:65 2019-01-16 20:02:44.501481: step 1621, loss = 0.69247 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:02:45.392201 ops/training.py:65 2019-01-16 20:02:45.392105: step 1622, loss = 0.70154 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:02:46.282904 ops/training.py:65 2019-01-16 20:02:46.282815: step 1623, loss = 0.69668 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:02:47.176543 ops/training.py:65 2019-01-16 20:02:47.176447: step 1624, loss = 0.71788 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:02:48.068517 ops/training.py:65 2019-01-16 20:02:48.068422: step 1625, loss = 0.73325 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:02:48.959048 ops/training.py:65 2019-01-16 20:02:48.958986: step 1626, loss = 0.70694 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:02:49.849036 ops/training.py:65 2019-01-16 20:02:49.848971: step 1627, loss = 0.69227 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:02:50.738258 ops/training.py:65 2019-01-16 20:02:50.738194: step 1628, loss = 0.70723 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:02:51.627932 ops/training.py:65 2019-01-16 20:02:51.627870: step 1629, loss = 0.70744 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:02:52.518020 ops/training.py:65 2019-01-16 20:02:52.517956: step 1630, loss = 0.69182 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:02:53.410464 ops/training.py:65 2019-01-16 20:02:53.410332: step 1631, loss = 0.72198 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:02:54.303315 ops/training.py:65 2019-01-16 20:02:54.303218: step 1632, loss = 0.71485 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:02:55.193123 ops/training.py:65 2019-01-16 20:02:55.193065: step 1633, loss = 0.66894 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:02:56.083455 ops/training.py:65 2019-01-16 20:02:56.083396: step 1634, loss = 0.71630 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:02:56.972709 ops/training.py:65 2019-01-16 20:02:56.972654: step 1635, loss = 0.70120 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:02:57.862862 ops/training.py:65 2019-01-16 20:02:57.862807: step 1636, loss = 0.71869 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:02:58.754249 ops/training.py:65 2019-01-16 20:02:58.754151: step 1637, loss = 0.69807 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:02:59.646706 ops/training.py:65 2019-01-16 20:02:59.646605: step 1638, loss = 0.70549 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:03:00.537823 ops/training.py:65 2019-01-16 20:03:00.537763: step 1639, loss = 0.71601 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:03:01.428620 ops/training.py:65 2019-01-16 20:03:01.428535: step 1640, loss = 0.70979 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:03:02.319798 ops/training.py:65 2019-01-16 20:03:02.319697: step 1641, loss = 0.69001 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:03:03.212501 ops/training.py:65 2019-01-16 20:03:03.212404: step 1642, loss = 0.68140 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:03:04.103504 ops/training.py:65 2019-01-16 20:03:04.103442: step 1643, loss = 0.69485 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:03:04.993184 ops/training.py:65 2019-01-16 20:03:04.993125: step 1644, loss = 0.67710 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:03:05.882179 ops/training.py:65 2019-01-16 20:03:05.882115: step 1645, loss = 0.70752 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:03:06.772068 ops/training.py:65 2019-01-16 20:03:06.772007: step 1646, loss = 0.71937 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:03:07.662469 ops/training.py:65 2019-01-16 20:03:07.662407: step 1647, loss = 0.70434 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:03:08.552190 ops/training.py:65 2019-01-16 20:03:08.552128: step 1648, loss = 0.71911 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:03:09.441611 ops/training.py:65 2019-01-16 20:03:09.441551: step 1649, loss = 0.70378 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:03:10.331699 ops/training.py:65 2019-01-16 20:03:10.331639: step 1650, loss = 0.66652 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:03:11.221196 ops/training.py:65 2019-01-16 20:03:11.221133: step 1651, loss = 0.69266 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:03:12.110623 ops/training.py:65 2019-01-16 20:03:12.110563: step 1652, loss = 0.70472 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:03:13.001237 ops/training.py:65 2019-01-16 20:03:13.001179: step 1653, loss = 0.69581 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:03:13.894696 ops/training.py:65 2019-01-16 20:03:13.894629: step 1654, loss = 0.66577 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:03:14.785734 ops/training.py:65 2019-01-16 20:03:14.785629: step 1655, loss = 0.71271 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:03:15.677405 ops/training.py:65 2019-01-16 20:03:15.677307: step 1656, loss = 0.71985 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:03:16.572073 ops/training.py:65 2019-01-16 20:03:16.571988: step 1657, loss = 0.71770 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:03:17.464627 ops/training.py:65 2019-01-16 20:03:17.464521: step 1658, loss = 0.70487 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:03:18.356794 ops/training.py:65 2019-01-16 20:03:18.356701: step 1659, loss = 0.68313 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:03:19.246588 ops/training.py:65 2019-01-16 20:03:19.246518: step 1660, loss = 0.66670 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:03:20.136742 ops/training.py:65 2019-01-16 20:03:20.136678: step 1661, loss = 0.67092 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:03:21.026754 ops/training.py:65 2019-01-16 20:03:21.026687: step 1662, loss = 0.72595 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:03:21.916023 ops/training.py:65 2019-01-16 20:03:21.915959: step 1663, loss = 0.71523 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:03:22.805796 ops/training.py:65 2019-01-16 20:03:22.805734: step 1664, loss = 0.74613 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:03:23.695074 ops/training.py:65 2019-01-16 20:03:23.695005: step 1665, loss = 0.66104 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:03:24.584119 ops/training.py:65 2019-01-16 20:03:24.584061: step 1666, loss = 0.69096 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:03:25.473363 ops/training.py:65 2019-01-16 20:03:25.473303: step 1667, loss = 0.65887 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:03:26.362423 ops/training.py:65 2019-01-16 20:03:26.362366: step 1668, loss = 0.70578 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:03:27.251385 ops/training.py:65 2019-01-16 20:03:27.251324: step 1669, loss = 0.68069 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:03:28.141119 ops/training.py:65 2019-01-16 20:03:28.141061: step 1670, loss = 0.70442 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:03:29.034559 ops/training.py:65 2019-01-16 20:03:29.034491: step 1671, loss = 0.71893 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:03:29.927921 ops/training.py:65 2019-01-16 20:03:29.927819: step 1672, loss = 0.67513 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:03:30.819867 ops/training.py:65 2019-01-16 20:03:30.819776: step 1673, loss = 0.71128 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:03:31.709577 ops/training.py:65 2019-01-16 20:03:31.709517: step 1674, loss = 0.68504 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:03:32.599900 ops/training.py:65 2019-01-16 20:03:32.599841: step 1675, loss = 0.70860 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:03:33.489341 ops/training.py:65 2019-01-16 20:03:33.489275: step 1676, loss = 0.70679 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:03:34.378946 ops/training.py:65 2019-01-16 20:03:34.378882: step 1677, loss = 0.68235 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:03:35.268180 ops/training.py:65 2019-01-16 20:03:35.268116: step 1678, loss = 0.70329 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:03:36.157178 ops/training.py:65 2019-01-16 20:03:36.157117: step 1679, loss = 0.69108 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:03:37.046836 ops/training.py:65 2019-01-16 20:03:37.046772: step 1680, loss = 0.68129 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:03:37.936139 ops/training.py:65 2019-01-16 20:03:37.936080: step 1681, loss = 0.68587 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:03:38.825446 ops/training.py:65 2019-01-16 20:03:38.825386: step 1682, loss = 0.71241 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:03:39.714811 ops/training.py:65 2019-01-16 20:03:39.714747: step 1683, loss = 0.68410 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:03:40.604295 ops/training.py:65 2019-01-16 20:03:40.604235: step 1684, loss = 0.72556 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:03:41.493164 ops/training.py:65 2019-01-16 20:03:41.493101: step 1685, loss = 0.69289 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:03:42.382174 ops/training.py:65 2019-01-16 20:03:42.382110: step 1686, loss = 0.73282 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:03:43.271753 ops/training.py:65 2019-01-16 20:03:43.271688: step 1687, loss = 0.72037 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:03:44.161053 ops/training.py:65 2019-01-16 20:03:44.160990: step 1688, loss = 0.69091 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:03:45.050854 ops/training.py:65 2019-01-16 20:03:45.050793: step 1689, loss = 0.65695 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:03:45.940544 ops/training.py:65 2019-01-16 20:03:45.940479: step 1690, loss = 0.69329 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:03:46.829991 ops/training.py:65 2019-01-16 20:03:46.829925: step 1691, loss = 0.70432 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:03:47.720331 ops/training.py:65 2019-01-16 20:03:47.720269: step 1692, loss = 0.69874 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:03:48.609864 ops/training.py:65 2019-01-16 20:03:48.609795: step 1693, loss = 0.69054 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:03:49.498518 ops/training.py:65 2019-01-16 20:03:49.498457: step 1694, loss = 0.70811 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:03:50.387601 ops/training.py:65 2019-01-16 20:03:50.387538: step 1695, loss = 0.69595 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:03:51.276648 ops/training.py:65 2019-01-16 20:03:51.276588: step 1696, loss = 0.69639 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:03:52.168322 ops/training.py:65 2019-01-16 20:03:52.168257: step 1697, loss = 0.68401 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:03:53.061287 ops/training.py:65 2019-01-16 20:03:53.061185: step 1698, loss = 0.69551 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:03:53.953050 ops/training.py:65 2019-01-16 20:03:53.952942: step 1699, loss = 0.70511 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:03:54.843452 ops/training.py:65 2019-01-16 20:03:54.843372: step 1700, loss = 0.69538 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:03:55.732722 ops/training.py:65 2019-01-16 20:03:55.732653: step 1701, loss = 0.68786 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:03:56.621998 ops/training.py:65 2019-01-16 20:03:56.621939: step 1702, loss = 0.68984 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:03:57.513392 ops/training.py:65 2019-01-16 20:03:57.513346: step 1703, loss = 0.71597 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:03:58.405291 ops/training.py:65 2019-01-16 20:03:58.405188: step 1704, loss = 0.67975 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:03:59.298108 ops/training.py:65 2019-01-16 20:03:59.298011: step 1705, loss = 0.68567 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:04:00.188672 ops/training.py:65 2019-01-16 20:04:00.188572: step 1706, loss = 0.68744 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:04:01.080016 ops/training.py:65 2019-01-16 20:04:01.079897: step 1707, loss = 0.68568 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:04:01.971632 ops/training.py:65 2019-01-16 20:04:01.971568: step 1708, loss = 0.71779 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:04:02.861847 ops/training.py:65 2019-01-16 20:04:02.861782: step 1709, loss = 0.68891 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:04:03.751770 ops/training.py:65 2019-01-16 20:04:03.751697: step 1710, loss = 0.69524 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:04:04.641470 ops/training.py:65 2019-01-16 20:04:04.641404: step 1711, loss = 0.70522 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:04:05.531022 ops/training.py:65 2019-01-16 20:04:05.530962: step 1712, loss = 0.68429 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:04:06.423105 ops/training.py:65 2019-01-16 20:04:06.423047: step 1713, loss = 0.69893 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:04:07.316231 ops/training.py:65 2019-01-16 20:04:07.316123: step 1714, loss = 0.71232 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:04:08.209270 ops/training.py:65 2019-01-16 20:04:08.209165: step 1715, loss = 0.68517 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:04:09.099858 ops/training.py:65 2019-01-16 20:04:09.099797: step 1716, loss = 0.68143 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:04:09.988973 ops/training.py:65 2019-01-16 20:04:09.988909: step 1717, loss = 0.72977 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:04:10.879849 ops/training.py:65 2019-01-16 20:04:10.879785: step 1718, loss = 0.69569 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:04:11.772900 ops/training.py:65 2019-01-16 20:04:11.772799: step 1719, loss = 0.65984 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:04:12.667157 ops/training.py:65 2019-01-16 20:04:12.667058: step 1720, loss = 0.68489 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:04:13.557529 ops/training.py:65 2019-01-16 20:04:13.557465: step 1721, loss = 0.70550 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:04:14.446910 ops/training.py:65 2019-01-16 20:04:14.446849: step 1722, loss = 0.70070 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:04:15.336619 ops/training.py:65 2019-01-16 20:04:15.336550: step 1723, loss = 0.73797 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:04:16.226187 ops/training.py:65 2019-01-16 20:04:16.226122: step 1724, loss = 0.67649 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:04:17.115570 ops/training.py:65 2019-01-16 20:04:17.115506: step 1725, loss = 0.71261 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:04:18.005098 ops/training.py:65 2019-01-16 20:04:18.005034: step 1726, loss = 0.71662 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:04:18.895217 ops/training.py:65 2019-01-16 20:04:18.895153: step 1727, loss = 0.71250 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:04:19.784566 ops/training.py:65 2019-01-16 20:04:19.784500: step 1728, loss = 0.68049 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:04:20.674353 ops/training.py:65 2019-01-16 20:04:20.674284: step 1729, loss = 0.71469 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:04:21.564450 ops/training.py:65 2019-01-16 20:04:21.564376: step 1730, loss = 0.68335 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:04:22.454389 ops/training.py:65 2019-01-16 20:04:22.454317: step 1731, loss = 0.71742 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:04:23.345259 ops/training.py:65 2019-01-16 20:04:23.345177: step 1732, loss = 0.73864 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:04:24.238159 ops/training.py:65 2019-01-16 20:04:24.238053: step 1733, loss = 0.72851 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:04:25.129298 ops/training.py:65 2019-01-16 20:04:25.129225: step 1734, loss = 0.68369 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:04:26.020646 ops/training.py:65 2019-01-16 20:04:26.020552: step 1735, loss = 0.73149 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:04:26.913510 ops/training.py:65 2019-01-16 20:04:26.913404: step 1736, loss = 0.65745 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:04:27.804964 ops/training.py:65 2019-01-16 20:04:27.804854: step 1737, loss = 0.71192 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:04:28.694544 ops/training.py:65 2019-01-16 20:04:28.694481: step 1738, loss = 0.70412 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:04:29.582933 ops/training.py:65 2019-01-16 20:04:29.582880: step 1739, loss = 0.70667 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:04:30.472697 ops/training.py:65 2019-01-16 20:04:30.472637: step 1740, loss = 0.70551 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:04:31.365622 ops/training.py:65 2019-01-16 20:04:31.365542: step 1741, loss = 0.67305 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:04:32.256142 ops/training.py:65 2019-01-16 20:04:32.256050: step 1742, loss = 0.68697 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:04:33.148870 ops/training.py:65 2019-01-16 20:04:33.148770: step 1743, loss = 0.68292 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:04:34.040821 ops/training.py:65 2019-01-16 20:04:34.040730: step 1744, loss = 0.70749 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:04:34.931746 ops/training.py:65 2019-01-16 20:04:34.931687: step 1745, loss = 0.71772 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:04:35.824148 ops/training.py:65 2019-01-16 20:04:35.824083: step 1746, loss = 0.72679 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:04:36.716428 ops/training.py:65 2019-01-16 20:04:36.716329: step 1747, loss = 0.66744 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:04:37.608642 ops/training.py:65 2019-01-16 20:04:37.608538: step 1748, loss = 0.71019 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:04:38.501873 ops/training.py:65 2019-01-16 20:04:38.501766: step 1749, loss = 0.72776 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:04:39.393866 ops/training.py:65 2019-01-16 20:04:39.393769: step 1750, loss = 0.70667 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:04:40.285747 ops/training.py:65 2019-01-16 20:04:40.285656: step 1751, loss = 0.68840 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:04:41.177237 ops/training.py:65 2019-01-16 20:04:41.177133: step 1752, loss = 0.65340 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:04:42.069165 ops/training.py:65 2019-01-16 20:04:42.069057: step 1753, loss = 0.68863 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:04:42.961561 ops/training.py:65 2019-01-16 20:04:42.961423: step 1754, loss = 0.71988 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:04:43.853113 ops/training.py:65 2019-01-16 20:04:43.853044: step 1755, loss = 0.65441 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:04:44.742327 ops/training.py:65 2019-01-16 20:04:44.742255: step 1756, loss = 0.68365 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:04:45.635914 ops/training.py:65 2019-01-16 20:04:45.635838: step 1757, loss = 0.71735 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:04:46.529142 ops/training.py:65 2019-01-16 20:04:46.529043: step 1758, loss = 0.71806 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:04:47.421563 ops/training.py:65 2019-01-16 20:04:47.421464: step 1759, loss = 0.70068 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:04:48.311968 ops/training.py:65 2019-01-16 20:04:48.311907: step 1760, loss = 0.69312 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:04:49.201659 ops/training.py:65 2019-01-16 20:04:49.201594: step 1761, loss = 0.69244 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:04:50.092001 ops/training.py:65 2019-01-16 20:04:50.091934: step 1762, loss = 0.69486 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:04:50.981564 ops/training.py:65 2019-01-16 20:04:50.981480: step 1763, loss = 0.70309 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:04:51.871003 ops/training.py:65 2019-01-16 20:04:51.870946: step 1764, loss = 0.71361 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:04:52.760202 ops/training.py:65 2019-01-16 20:04:52.760141: step 1765, loss = 0.70321 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:04:53.649684 ops/training.py:65 2019-01-16 20:04:53.649619: step 1766, loss = 0.73189 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:04:54.541109 ops/training.py:65 2019-01-16 20:04:54.541044: step 1767, loss = 0.68939 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:04:55.432130 ops/training.py:65 2019-01-16 20:04:55.432060: step 1768, loss = 0.70739 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:04:56.323891 ops/training.py:65 2019-01-16 20:04:56.323825: step 1769, loss = 0.72906 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:04:57.217083 ops/training.py:65 2019-01-16 20:04:57.216974: step 1770, loss = 0.69048 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:04:58.109812 ops/training.py:65 2019-01-16 20:04:58.109714: step 1771, loss = 0.70000 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:04:59.002313 ops/training.py:65 2019-01-16 20:04:59.002266: step 1772, loss = 0.71537 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:04:59.894486 ops/training.py:65 2019-01-16 20:04:59.894433: step 1773, loss = 0.72038 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:05:00.785912 ops/training.py:65 2019-01-16 20:05:00.785806: step 1774, loss = 0.70500 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:05:01.678706 ops/training.py:65 2019-01-16 20:05:01.678607: step 1775, loss = 0.67514 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:05:02.569688 ops/training.py:65 2019-01-16 20:05:02.569627: step 1776, loss = 0.71509 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:05:03.459379 ops/training.py:65 2019-01-16 20:05:03.459307: step 1777, loss = 0.72219 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:05:04.351605 ops/training.py:65 2019-01-16 20:05:04.351498: step 1778, loss = 0.71188 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:05:05.246146 ops/training.py:65 2019-01-16 20:05:05.246007: step 1779, loss = 0.66720 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:05:06.138336 ops/training.py:65 2019-01-16 20:05:06.138270: step 1780, loss = 0.74888 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:05:07.027940 ops/training.py:65 2019-01-16 20:05:07.027885: step 1781, loss = 0.70069 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:05:07.919712 ops/training.py:65 2019-01-16 20:05:07.919674: step 1782, loss = 0.69153 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:05:08.810774 ops/training.py:65 2019-01-16 20:05:08.810709: step 1783, loss = 0.74802 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:05:09.702472 ops/training.py:65 2019-01-16 20:05:09.702393: step 1784, loss = 0.69964 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:05:10.595331 ops/training.py:65 2019-01-16 20:05:10.595231: step 1785, loss = 0.70436 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:05:11.487550 ops/training.py:65 2019-01-16 20:05:11.487472: step 1786, loss = 0.67900 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:05:12.380416 ops/training.py:65 2019-01-16 20:05:12.380308: step 1787, loss = 0.70432 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:05:13.273295 ops/training.py:65 2019-01-16 20:05:13.273174: step 1788, loss = 0.67937 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:05:14.165918 ops/training.py:65 2019-01-16 20:05:14.165775: step 1789, loss = 0.70244 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:05:15.056323 ops/training.py:65 2019-01-16 20:05:15.056253: step 1790, loss = 0.77068 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:05:15.946998 ops/training.py:65 2019-01-16 20:05:15.946935: step 1791, loss = 0.67927 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:05:16.839728 ops/training.py:65 2019-01-16 20:05:16.839633: step 1792, loss = 0.70450 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:05:17.730787 ops/training.py:65 2019-01-16 20:05:17.730728: step 1793, loss = 0.73742 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:05:18.621771 ops/training.py:65 2019-01-16 20:05:18.621693: step 1794, loss = 0.71043 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:05:19.514969 ops/training.py:65 2019-01-16 20:05:19.514860: step 1795, loss = 0.69185 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:05:20.407386 ops/training.py:65 2019-01-16 20:05:20.407282: step 1796, loss = 0.70144 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:05:21.299853 ops/training.py:65 2019-01-16 20:05:21.299792: step 1797, loss = 0.67630 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:05:22.189425 ops/training.py:65 2019-01-16 20:05:22.189363: step 1798, loss = 0.70827 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:05:23.080784 ops/training.py:65 2019-01-16 20:05:23.080716: step 1799, loss = 0.70378 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:05:23.974042 ops/training.py:65 2019-01-16 20:05:23.973935: step 1800, loss = 0.69125 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:05:24.864717 ops/training.py:65 2019-01-16 20:05:24.864615: step 1801, loss = 0.68587 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:05:25.755897 ops/training.py:65 2019-01-16 20:05:25.755833: step 1802, loss = 0.67368 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:05:26.646228 ops/training.py:65 2019-01-16 20:05:26.646159: step 1803, loss = 0.70615 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:05:27.538173 ops/training.py:65 2019-01-16 20:05:27.538096: step 1804, loss = 0.72287 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:05:28.430785 ops/training.py:65 2019-01-16 20:05:28.430681: step 1805, loss = 0.71348 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:05:29.322468 ops/training.py:65 2019-01-16 20:05:29.322379: step 1806, loss = 0.71092 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:05:30.212575 ops/training.py:65 2019-01-16 20:05:30.212513: step 1807, loss = 0.70740 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:05:31.103805 ops/training.py:65 2019-01-16 20:05:31.103744: step 1808, loss = 0.69478 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:05:31.995273 ops/training.py:65 2019-01-16 20:05:31.995179: step 1809, loss = 0.68327 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:05:32.886563 ops/training.py:65 2019-01-16 20:05:32.886473: step 1810, loss = 0.70347 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:05:33.779770 ops/training.py:65 2019-01-16 20:05:33.779741: step 1811, loss = 0.70085 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:05:34.670982 ops/training.py:65 2019-01-16 20:05:34.670929: step 1812, loss = 0.67395 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:05:35.563076 ops/training.py:65 2019-01-16 20:05:35.562980: step 1813, loss = 0.71611 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:05:36.456279 ops/training.py:65 2019-01-16 20:05:36.456194: step 1814, loss = 0.68687 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:05:37.350634 ops/training.py:65 2019-01-16 20:05:37.350534: step 1815, loss = 0.69813 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:05:38.242397 ops/training.py:65 2019-01-16 20:05:38.242316: step 1816, loss = 0.69919 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:05:39.135141 ops/training.py:65 2019-01-16 20:05:39.135039: step 1817, loss = 0.73720 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:05:40.026513 ops/training.py:65 2019-01-16 20:05:40.026429: step 1818, loss = 0.70716 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:05:40.917808 ops/training.py:65 2019-01-16 20:05:40.917730: step 1819, loss = 0.69947 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:05:41.808907 ops/training.py:65 2019-01-16 20:05:41.808824: step 1820, loss = 0.69565 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:05:42.700771 ops/training.py:65 2019-01-16 20:05:42.700667: step 1821, loss = 0.67231 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:05:43.591223 ops/training.py:65 2019-01-16 20:05:43.591126: step 1822, loss = 0.67282 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 20:05:44.483516 ops/training.py:65 2019-01-16 20:05:44.483371: step 1823, loss = 0.70870 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:05:45.376832 ops/training.py:65 2019-01-16 20:05:45.376737: step 1824, loss = 0.71841 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:05:46.268754 ops/training.py:65 2019-01-16 20:05:46.268649: step 1825, loss = 0.72079 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:05:47.160343 ops/training.py:65 2019-01-16 20:05:47.160259: step 1826, loss = 0.71156 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:05:48.049991 ops/training.py:65 2019-01-16 20:05:48.049904: step 1827, loss = 0.65599 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:05:48.939790 ops/training.py:65 2019-01-16 20:05:48.939727: step 1828, loss = 0.73122 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:05:49.828520 ops/training.py:65 2019-01-16 20:05:49.828451: step 1829, loss = 0.70480 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:05:50.717188 ops/training.py:65 2019-01-16 20:05:50.717123: step 1830, loss = 0.71026 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:05:51.606075 ops/training.py:65 2019-01-16 20:05:51.606008: step 1831, loss = 0.69455 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:05:52.495057 ops/training.py:65 2019-01-16 20:05:52.495001: step 1832, loss = 0.70682 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:05:53.383921 ops/training.py:65 2019-01-16 20:05:53.383861: step 1833, loss = 0.72837 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:05:54.273084 ops/training.py:65 2019-01-16 20:05:54.273023: step 1834, loss = 0.64544 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:05:55.168503 ops/training.py:65 2019-01-16 20:05:55.168432: step 1835, loss = 0.71397 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:05:56.061330 ops/training.py:65 2019-01-16 20:05:56.061275: step 1836, loss = 0.71640 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:05:56.951535 ops/training.py:65 2019-01-16 20:05:56.951452: step 1837, loss = 0.70642 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:05:57.843854 ops/training.py:65 2019-01-16 20:05:57.843751: step 1838, loss = 0.67894 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:05:58.737013 ops/training.py:65 2019-01-16 20:05:58.736910: step 1839, loss = 0.67532 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:05:59.629917 ops/training.py:65 2019-01-16 20:05:59.629815: step 1840, loss = 0.70222 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:06:00.521526 ops/training.py:65 2019-01-16 20:06:00.521457: step 1841, loss = 0.75533 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:06:01.413381 ops/training.py:65 2019-01-16 20:06:01.413317: step 1842, loss = 0.73293 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:06:02.305102 ops/training.py:65 2019-01-16 20:06:02.305009: step 1843, loss = 0.67187 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:06:03.196667 ops/training.py:65 2019-01-16 20:06:03.196574: step 1844, loss = 0.74362 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:06:04.088529 ops/training.py:65 2019-01-16 20:06:04.088427: step 1845, loss = 0.64841 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:06:04.979586 ops/training.py:65 2019-01-16 20:06:04.979521: step 1846, loss = 0.68857 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:06:05.868000 ops/training.py:65 2019-01-16 20:06:05.867939: step 1847, loss = 0.75254 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:06:06.757109 ops/training.py:65 2019-01-16 20:06:06.757038: step 1848, loss = 0.63439 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:06:07.647492 ops/training.py:65 2019-01-16 20:06:07.647427: step 1849, loss = 0.74967 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:06:08.536102 ops/training.py:65 2019-01-16 20:06:08.536041: step 1850, loss = 0.71600 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:06:09.424643 ops/training.py:65 2019-01-16 20:06:09.424582: step 1851, loss = 0.72858 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:06:10.316157 ops/training.py:65 2019-01-16 20:06:10.316116: step 1852, loss = 0.74379 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:06:11.208505 ops/training.py:65 2019-01-16 20:06:11.208433: step 1853, loss = 0.68311 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:06:12.100949 ops/training.py:65 2019-01-16 20:06:12.100844: step 1854, loss = 0.67102 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:06:12.993565 ops/training.py:65 2019-01-16 20:06:12.993480: step 1855, loss = 0.66908 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:06:13.884766 ops/training.py:65 2019-01-16 20:06:13.884674: step 1856, loss = 0.65981 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:06:14.774959 ops/training.py:65 2019-01-16 20:06:14.774872: step 1857, loss = 0.71731 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:06:15.663748 ops/training.py:65 2019-01-16 20:06:15.663687: step 1858, loss = 0.74819 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:06:16.552959 ops/training.py:65 2019-01-16 20:06:16.552897: step 1859, loss = 0.67343 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:06:17.441695 ops/training.py:65 2019-01-16 20:06:17.441635: step 1860, loss = 0.73395 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:06:18.330623 ops/training.py:65 2019-01-16 20:06:18.330563: step 1861, loss = 0.71612 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:06:19.220861 ops/training.py:65 2019-01-16 20:06:19.220801: step 1862, loss = 0.71423 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:06:20.112180 ops/training.py:65 2019-01-16 20:06:20.112121: step 1863, loss = 0.72423 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:06:21.004506 ops/training.py:65 2019-01-16 20:06:21.004444: step 1864, loss = 0.69286 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:06:21.895815 ops/training.py:65 2019-01-16 20:06:21.895727: step 1865, loss = 0.72129 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:06:22.787892 ops/training.py:65 2019-01-16 20:06:22.787784: step 1866, loss = 0.74236 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:06:23.680016 ops/training.py:65 2019-01-16 20:06:23.679918: step 1867, loss = 0.71499 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:06:24.571440 ops/training.py:65 2019-01-16 20:06:24.571379: step 1868, loss = 0.80988 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:06:25.463378 ops/training.py:65 2019-01-16 20:06:25.463279: step 1869, loss = 0.69058 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:06:26.355869 ops/training.py:65 2019-01-16 20:06:26.355769: step 1870, loss = 0.66049 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:06:27.246916 ops/training.py:65 2019-01-16 20:06:27.246851: step 1871, loss = 0.68161 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:06:28.138013 ops/training.py:65 2019-01-16 20:06:28.137938: step 1872, loss = 0.73464 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:06:29.030338 ops/training.py:65 2019-01-16 20:06:29.030235: step 1873, loss = 0.69210 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:06:29.922317 ops/training.py:65 2019-01-16 20:06:29.922219: step 1874, loss = 0.72417 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:06:30.812816 ops/training.py:65 2019-01-16 20:06:30.812755: step 1875, loss = 0.69880 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:06:31.701501 ops/training.py:65 2019-01-16 20:06:31.701440: step 1876, loss = 0.68887 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:06:32.590846 ops/training.py:65 2019-01-16 20:06:32.590783: step 1877, loss = 0.69688 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:06:33.480865 ops/training.py:65 2019-01-16 20:06:33.480794: step 1878, loss = 0.69888 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:06:34.371874 ops/training.py:65 2019-01-16 20:06:34.371810: step 1879, loss = 0.70462 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:06:35.262620 ops/training.py:65 2019-01-16 20:06:35.262559: step 1880, loss = 0.68350 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:06:36.154242 ops/training.py:65 2019-01-16 20:06:36.154181: step 1881, loss = 0.67844 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:06:37.047205 ops/training.py:65 2019-01-16 20:06:37.047065: step 1882, loss = 0.70674 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:06:37.940702 ops/training.py:65 2019-01-16 20:06:37.940597: step 1883, loss = 0.72181 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:06:38.834710 ops/training.py:65 2019-01-16 20:06:38.834617: step 1884, loss = 0.70847 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:06:39.728704 ops/training.py:65 2019-01-16 20:06:39.728599: step 1885, loss = 0.74203 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:06:40.621019 ops/training.py:65 2019-01-16 20:06:40.620915: step 1886, loss = 0.67661 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:06:41.512918 ops/training.py:65 2019-01-16 20:06:41.512855: step 1887, loss = 0.68229 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:06:42.402193 ops/training.py:65 2019-01-16 20:06:42.402134: step 1888, loss = 0.74065 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:06:43.291798 ops/training.py:65 2019-01-16 20:06:43.291738: step 1889, loss = 0.68551 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:06:44.180424 ops/training.py:65 2019-01-16 20:06:44.180364: step 1890, loss = 0.67192 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:06:45.072141 ops/training.py:65 2019-01-16 20:06:45.072093: step 1891, loss = 0.73402 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:06:45.963742 ops/training.py:65 2019-01-16 20:06:45.963642: step 1892, loss = 0.75382 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:06:46.855558 ops/training.py:65 2019-01-16 20:06:46.855476: step 1893, loss = 0.72191 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:06:47.748206 ops/training.py:65 2019-01-16 20:06:47.748123: step 1894, loss = 0.71643 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:06:48.642211 ops/training.py:65 2019-01-16 20:06:48.642107: step 1895, loss = 0.67392 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:06:49.534202 ops/training.py:65 2019-01-16 20:06:49.534144: step 1896, loss = 0.68357 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:06:50.423266 ops/training.py:65 2019-01-16 20:06:50.423208: step 1897, loss = 0.69834 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:06:51.311755 ops/training.py:65 2019-01-16 20:06:51.311696: step 1898, loss = 0.68119 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:06:52.200005 ops/training.py:65 2019-01-16 20:06:52.199932: step 1899, loss = 0.72577 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:06:53.092140 ops/training.py:65 2019-01-16 20:06:53.092074: step 1900, loss = 0.70045 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:06:53.983439 ops/training.py:65 2019-01-16 20:06:53.983351: step 1901, loss = 0.70921 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:06:54.878950 ops/training.py:65 2019-01-16 20:06:54.878859: step 1902, loss = 0.67450 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:06:55.770591 ops/training.py:65 2019-01-16 20:06:55.770518: step 1903, loss = 0.66374 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:06:56.663178 ops/training.py:65 2019-01-16 20:06:56.663074: step 1904, loss = 0.71006 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:06:57.554703 ops/training.py:65 2019-01-16 20:06:57.554643: step 1905, loss = 0.69560 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:06:58.447963 ops/training.py:65 2019-01-16 20:06:58.447931: step 1906, loss = 0.67330 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:06:59.339606 ops/training.py:65 2019-01-16 20:06:59.339574: step 1907, loss = 0.71661 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:07:00.232337 ops/training.py:65 2019-01-16 20:07:00.232253: step 1908, loss = 0.74843 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:07:01.124049 ops/training.py:65 2019-01-16 20:07:01.123961: step 1909, loss = 0.67976 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:07:02.016771 ops/training.py:65 2019-01-16 20:07:02.016676: step 1910, loss = 0.70872 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:07:02.908467 ops/training.py:65 2019-01-16 20:07:02.908363: step 1911, loss = 0.67815 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:07:03.799889 ops/training.py:65 2019-01-16 20:07:03.799807: step 1912, loss = 0.71990 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:07:04.690468 ops/training.py:65 2019-01-16 20:07:04.690363: step 1913, loss = 0.71964 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:07:05.583579 ops/training.py:65 2019-01-16 20:07:05.583478: step 1914, loss = 0.65215 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:07:06.475877 ops/training.py:65 2019-01-16 20:07:06.475780: step 1915, loss = 0.66315 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:07:07.365316 ops/training.py:65 2019-01-16 20:07:07.365248: step 1916, loss = 0.69989 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:07:08.254734 ops/training.py:65 2019-01-16 20:07:08.254672: step 1917, loss = 0.67242 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:07:09.143170 ops/training.py:65 2019-01-16 20:07:09.143109: step 1918, loss = 0.71798 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:07:10.031750 ops/training.py:65 2019-01-16 20:07:10.031691: step 1919, loss = 0.65157 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:07:10.920821 ops/training.py:65 2019-01-16 20:07:10.920763: step 1920, loss = 0.67425 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:07:11.809132 ops/training.py:65 2019-01-16 20:07:11.809074: step 1921, loss = 0.72138 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:07:12.701247 ops/training.py:65 2019-01-16 20:07:12.701216: step 1922, loss = 0.87569 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.21875
I2992 2019-01-16 20:07:13.592738 ops/training.py:65 2019-01-16 20:07:13.592702: step 1923, loss = 0.70913 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:07:14.484177 ops/training.py:65 2019-01-16 20:07:14.484130: step 1924, loss = 0.69178 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:07:15.376459 ops/training.py:65 2019-01-16 20:07:15.376357: step 1925, loss = 0.74776 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:07:16.269677 ops/training.py:65 2019-01-16 20:07:16.269612: step 1926, loss = 0.70775 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:07:17.161749 ops/training.py:65 2019-01-16 20:07:17.161656: step 1927, loss = 0.74329 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:07:18.052132 ops/training.py:65 2019-01-16 20:07:18.052034: step 1928, loss = 0.69674 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:07:18.942088 ops/training.py:65 2019-01-16 20:07:18.942028: step 1929, loss = 0.72777 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:07:19.831931 ops/training.py:65 2019-01-16 20:07:19.831872: step 1930, loss = 0.72263 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:07:20.720729 ops/training.py:65 2019-01-16 20:07:20.720671: step 1931, loss = 0.71697 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:07:21.609931 ops/training.py:65 2019-01-16 20:07:21.609870: step 1932, loss = 0.69343 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:07:22.498844 ops/training.py:65 2019-01-16 20:07:22.498787: step 1933, loss = 0.66768 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:07:23.388881 ops/training.py:65 2019-01-16 20:07:23.388814: step 1934, loss = 0.69179 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:07:24.277530 ops/training.py:65 2019-01-16 20:07:24.277471: step 1935, loss = 0.70349 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:07:25.166669 ops/training.py:65 2019-01-16 20:07:25.166608: step 1936, loss = 0.71309 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:07:26.056099 ops/training.py:65 2019-01-16 20:07:26.056040: step 1937, loss = 0.68501 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:07:26.948138 ops/training.py:65 2019-01-16 20:07:26.948073: step 1938, loss = 0.71234 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:07:27.840075 ops/training.py:65 2019-01-16 20:07:27.839969: step 1939, loss = 0.65222 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:07:28.730862 ops/training.py:65 2019-01-16 20:07:28.730803: step 1940, loss = 0.67922 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:07:29.620001 ops/training.py:65 2019-01-16 20:07:29.619930: step 1941, loss = 0.70620 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:07:30.512375 ops/training.py:65 2019-01-16 20:07:30.512296: step 1942, loss = 0.69311 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:07:31.404833 ops/training.py:65 2019-01-16 20:07:31.404728: step 1943, loss = 0.68752 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:07:32.296977 ops/training.py:65 2019-01-16 20:07:32.296884: step 1944, loss = 0.70240 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:07:33.188758 ops/training.py:65 2019-01-16 20:07:33.188693: step 1945, loss = 0.70827 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:07:34.078413 ops/training.py:65 2019-01-16 20:07:34.078353: step 1946, loss = 0.67922 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:07:34.967980 ops/training.py:65 2019-01-16 20:07:34.967916: step 1947, loss = 0.76675 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 20:07:35.857987 ops/training.py:65 2019-01-16 20:07:35.857922: step 1948, loss = 0.67036 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:07:36.748127 ops/training.py:65 2019-01-16 20:07:36.748067: step 1949, loss = 0.73012 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:07:37.638053 ops/training.py:65 2019-01-16 20:07:37.637994: step 1950, loss = 0.71402 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:07:38.528473 ops/training.py:65 2019-01-16 20:07:38.528408: step 1951, loss = 0.70356 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:07:39.419121 ops/training.py:65 2019-01-16 20:07:39.419060: step 1952, loss = 0.66088 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:07:40.308173 ops/training.py:65 2019-01-16 20:07:40.308113: step 1953, loss = 0.67624 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:07:41.196995 ops/training.py:65 2019-01-16 20:07:41.196922: step 1954, loss = 0.73177 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:07:42.085888 ops/training.py:65 2019-01-16 20:07:42.085833: step 1955, loss = 0.69693 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:07:42.975348 ops/training.py:65 2019-01-16 20:07:42.975292: step 1956, loss = 0.75754 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:07:43.864597 ops/training.py:65 2019-01-16 20:07:43.864541: step 1957, loss = 0.71011 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:07:44.755377 ops/training.py:65 2019-01-16 20:07:44.755322: step 1958, loss = 0.70898 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:07:45.648853 ops/training.py:65 2019-01-16 20:07:45.648785: step 1959, loss = 0.74379 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:07:46.540457 ops/training.py:65 2019-01-16 20:07:46.540353: step 1960, loss = 0.68439 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:07:47.432358 ops/training.py:65 2019-01-16 20:07:47.432295: step 1961, loss = 0.69427 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:07:48.323380 ops/training.py:65 2019-01-16 20:07:48.323317: step 1962, loss = 0.71686 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:07:49.214574 ops/training.py:65 2019-01-16 20:07:49.214510: step 1963, loss = 0.68289 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:07:50.107863 ops/training.py:65 2019-01-16 20:07:50.107764: step 1964, loss = 0.69566 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:07:50.999079 ops/training.py:65 2019-01-16 20:07:50.998982: step 1965, loss = 0.66132 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:07:51.892580 ops/training.py:65 2019-01-16 20:07:51.892473: step 1966, loss = 0.69666 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:07:52.784584 ops/training.py:65 2019-01-16 20:07:52.784445: step 1967, loss = 0.66701 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:07:53.676588 ops/training.py:65 2019-01-16 20:07:53.676527: step 1968, loss = 0.71357 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:07:54.566314 ops/training.py:65 2019-01-16 20:07:54.566257: step 1969, loss = 0.72512 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:07:55.455692 ops/training.py:65 2019-01-16 20:07:55.455637: step 1970, loss = 0.68537 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:07:56.343605 ops/training.py:65 2019-01-16 20:07:56.343551: step 1971, loss = 0.70007 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:07:57.236170 ops/training.py:65 2019-01-16 20:07:57.236116: step 1972, loss = 0.71263 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:07:58.128088 ops/training.py:65 2019-01-16 20:07:58.127983: step 1973, loss = 0.66703 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:07:59.021433 ops/training.py:65 2019-01-16 20:07:59.021368: step 1974, loss = 0.74089 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:07:59.913763 ops/training.py:65 2019-01-16 20:07:59.913659: step 1975, loss = 0.67375 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:08:00.804541 ops/training.py:65 2019-01-16 20:08:00.804474: step 1976, loss = 0.69232 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:08:01.693585 ops/training.py:65 2019-01-16 20:08:01.693523: step 1977, loss = 0.69149 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:08:02.583421 ops/training.py:65 2019-01-16 20:08:02.583355: step 1978, loss = 0.70637 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:08:03.472344 ops/training.py:65 2019-01-16 20:08:03.472270: step 1979, loss = 0.69214 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:08:04.361166 ops/training.py:65 2019-01-16 20:08:04.361103: step 1980, loss = 0.72539 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:08:05.250173 ops/training.py:65 2019-01-16 20:08:05.250116: step 1981, loss = 0.72185 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:08:06.139669 ops/training.py:65 2019-01-16 20:08:06.139610: step 1982, loss = 0.71787 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:08:07.029707 ops/training.py:65 2019-01-16 20:08:07.029647: step 1983, loss = 0.69779 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:08:07.917700 ops/training.py:65 2019-01-16 20:08:07.917646: step 1984, loss = 0.75332 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:08:08.806616 ops/training.py:65 2019-01-16 20:08:08.806556: step 1985, loss = 0.67343 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:08:09.695858 ops/training.py:65 2019-01-16 20:08:09.695798: step 1986, loss = 0.68465 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:08:10.584523 ops/training.py:65 2019-01-16 20:08:10.584447: step 1987, loss = 0.70558 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:08:11.473831 ops/training.py:65 2019-01-16 20:08:11.473770: step 1988, loss = 0.68815 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:08:12.364162 ops/training.py:65 2019-01-16 20:08:12.364099: step 1989, loss = 0.72011 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:08:13.253449 ops/training.py:65 2019-01-16 20:08:13.253383: step 1990, loss = 0.74985 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:08:14.142850 ops/training.py:65 2019-01-16 20:08:14.142793: step 1991, loss = 0.68526 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:08:15.032049 ops/training.py:65 2019-01-16 20:08:15.031994: step 1992, loss = 0.69124 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:08:15.921104 ops/training.py:65 2019-01-16 20:08:15.921043: step 1993, loss = 0.70809 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:08:16.809477 ops/training.py:65 2019-01-16 20:08:16.809416: step 1994, loss = 0.65176 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:08:17.697806 ops/training.py:65 2019-01-16 20:08:17.697749: step 1995, loss = 0.72299 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:08:18.585925 ops/training.py:65 2019-01-16 20:08:18.585864: step 1996, loss = 0.71131 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:08:19.475212 ops/training.py:65 2019-01-16 20:08:19.475149: step 1997, loss = 0.71687 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:08:20.365081 ops/training.py:65 2019-01-16 20:08:20.365018: step 1998, loss = 0.69360 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:08:21.255202 ops/training.py:65 2019-01-16 20:08:21.255136: step 1999, loss = 0.67718 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:12:36.326362 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I2992 2019-01-16 20:12:36.327346 ops/training.py:41 2019-01-16 20:12:36.327289: step 2000, loss = 0.67 (0.1 examples/sec; 254.178 sec/batch) | Training accuracy = 0.5625 | Validation accuracy = 0.4983 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_19_33_19_510334
I2992 2019-01-16 20:12:37.218533 ops/training.py:65 2019-01-16 20:12:37.218467: step 2001, loss = 0.67657 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:12:38.106425 ops/training.py:65 2019-01-16 20:12:38.106363: step 2002, loss = 0.68768 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:12:38.994986 ops/training.py:65 2019-01-16 20:12:38.994924: step 2003, loss = 0.68156 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:12:39.885037 ops/training.py:65 2019-01-16 20:12:39.884972: step 2004, loss = 0.66751 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:12:40.774106 ops/training.py:65 2019-01-16 20:12:40.774048: step 2005, loss = 0.71034 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:12:41.663870 ops/training.py:65 2019-01-16 20:12:41.663812: step 2006, loss = 0.69551 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:12:42.554408 ops/training.py:65 2019-01-16 20:12:42.554340: step 2007, loss = 0.74888 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:12:43.443570 ops/training.py:65 2019-01-16 20:12:43.443506: step 2008, loss = 0.67066 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:12:44.332569 ops/training.py:65 2019-01-16 20:12:44.332505: step 2009, loss = 0.67798 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:12:45.221987 ops/training.py:65 2019-01-16 20:12:45.221920: step 2010, loss = 0.71458 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:12:46.110486 ops/training.py:65 2019-01-16 20:12:46.110411: step 2011, loss = 0.70219 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:12:46.999099 ops/training.py:65 2019-01-16 20:12:46.999035: step 2012, loss = 0.70888 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:12:47.887733 ops/training.py:65 2019-01-16 20:12:47.887670: step 2013, loss = 0.69762 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:12:48.778216 ops/training.py:65 2019-01-16 20:12:48.778150: step 2014, loss = 0.67475 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:12:49.667559 ops/training.py:65 2019-01-16 20:12:49.667495: step 2015, loss = 0.63633 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:12:50.555862 ops/training.py:65 2019-01-16 20:12:50.555793: step 2016, loss = 0.74788 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:12:51.445413 ops/training.py:65 2019-01-16 20:12:51.445346: step 2017, loss = 0.71585 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:12:52.335430 ops/training.py:65 2019-01-16 20:12:52.335365: step 2018, loss = 0.69312 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:12:53.224062 ops/training.py:65 2019-01-16 20:12:53.223996: step 2019, loss = 0.68733 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:12:54.113098 ops/training.py:65 2019-01-16 20:12:54.113028: step 2020, loss = 0.71815 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:12:55.001597 ops/training.py:65 2019-01-16 20:12:55.001532: step 2021, loss = 0.69006 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:12:55.892696 ops/training.py:65 2019-01-16 20:12:55.892631: step 2022, loss = 0.69597 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:12:56.784294 ops/training.py:65 2019-01-16 20:12:56.784192: step 2023, loss = 0.67228 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:12:57.675531 ops/training.py:65 2019-01-16 20:12:57.675438: step 2024, loss = 0.72595 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:12:58.566379 ops/training.py:65 2019-01-16 20:12:58.566285: step 2025, loss = 0.67304 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:12:59.458495 ops/training.py:65 2019-01-16 20:12:59.458405: step 2026, loss = 0.68630 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:13:00.350659 ops/training.py:65 2019-01-16 20:13:00.350560: step 2027, loss = 0.71472 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:13:01.241429 ops/training.py:65 2019-01-16 20:13:01.241330: step 2028, loss = 0.71501 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:13:02.131650 ops/training.py:65 2019-01-16 20:13:02.131585: step 2029, loss = 0.71044 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:13:03.020532 ops/training.py:65 2019-01-16 20:13:03.020466: step 2030, loss = 0.71161 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:13:03.910544 ops/training.py:65 2019-01-16 20:13:03.910460: step 2031, loss = 0.70185 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:13:04.802512 ops/training.py:65 2019-01-16 20:13:04.802412: step 2032, loss = 0.68026 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:13:05.694581 ops/training.py:65 2019-01-16 20:13:05.694481: step 2033, loss = 0.71603 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:13:06.585983 ops/training.py:65 2019-01-16 20:13:06.585891: step 2034, loss = 0.69798 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:13:07.475775 ops/training.py:65 2019-01-16 20:13:07.475709: step 2035, loss = 0.65093 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:13:08.365881 ops/training.py:65 2019-01-16 20:13:08.365813: step 2036, loss = 0.65028 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:13:09.255505 ops/training.py:65 2019-01-16 20:13:09.255443: step 2037, loss = 0.72416 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:13:10.143363 ops/training.py:65 2019-01-16 20:13:10.143304: step 2038, loss = 0.74664 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.25
I2992 2019-01-16 20:13:11.031939 ops/training.py:65 2019-01-16 20:13:11.031880: step 2039, loss = 0.70537 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:13:11.919908 ops/training.py:65 2019-01-16 20:13:11.919850: step 2040, loss = 0.67080 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:13:12.808361 ops/training.py:65 2019-01-16 20:13:12.808297: step 2041, loss = 0.70732 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:13:13.699889 ops/training.py:65 2019-01-16 20:13:13.699818: step 2042, loss = 0.72598 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:13:14.591994 ops/training.py:65 2019-01-16 20:13:14.591888: step 2043, loss = 0.67032 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:13:15.483048 ops/training.py:65 2019-01-16 20:13:15.482959: step 2044, loss = 0.72016 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:13:16.374117 ops/training.py:65 2019-01-16 20:13:16.374036: step 2045, loss = 0.68460 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:13:17.265341 ops/training.py:65 2019-01-16 20:13:17.265248: step 2046, loss = 0.67718 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:13:18.156558 ops/training.py:65 2019-01-16 20:13:18.156464: step 2047, loss = 0.68416 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:13:19.046854 ops/training.py:65 2019-01-16 20:13:19.046768: step 2048, loss = 0.66831 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:13:19.940732 ops/training.py:65 2019-01-16 20:13:19.940620: step 2049, loss = 0.72634 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:13:20.833424 ops/training.py:65 2019-01-16 20:13:20.833333: step 2050, loss = 0.69892 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:13:21.726281 ops/training.py:65 2019-01-16 20:13:21.726200: step 2051, loss = 0.70529 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:13:22.617564 ops/training.py:65 2019-01-16 20:13:22.617463: step 2052, loss = 0.69010 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:13:23.508905 ops/training.py:65 2019-01-16 20:13:23.508809: step 2053, loss = 0.67810 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:13:24.399156 ops/training.py:65 2019-01-16 20:13:24.399055: step 2054, loss = 0.72217 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:13:25.288610 ops/training.py:65 2019-01-16 20:13:25.288524: step 2055, loss = 0.68269 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:13:26.179765 ops/training.py:65 2019-01-16 20:13:26.179668: step 2056, loss = 0.65075 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:13:27.071255 ops/training.py:65 2019-01-16 20:13:27.071153: step 2057, loss = 0.67155 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:13:27.964267 ops/training.py:65 2019-01-16 20:13:27.964162: step 2058, loss = 0.70569 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:13:28.854087 ops/training.py:65 2019-01-16 20:13:28.854022: step 2059, loss = 0.65551 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:13:29.743030 ops/training.py:65 2019-01-16 20:13:29.742971: step 2060, loss = 0.65994 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:13:30.633001 ops/training.py:65 2019-01-16 20:13:30.632937: step 2061, loss = 0.71662 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:13:31.523154 ops/training.py:65 2019-01-16 20:13:31.523093: step 2062, loss = 0.69905 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:13:32.414477 ops/training.py:65 2019-01-16 20:13:32.414403: step 2063, loss = 0.70824 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:13:33.308374 ops/training.py:65 2019-01-16 20:13:33.308277: step 2064, loss = 0.68074 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:13:34.201161 ops/training.py:65 2019-01-16 20:13:34.201051: step 2065, loss = 0.72552 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:13:35.091441 ops/training.py:65 2019-01-16 20:13:35.091379: step 2066, loss = 0.71519 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:13:35.979976 ops/training.py:65 2019-01-16 20:13:35.979911: step 2067, loss = 0.73319 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 20:13:36.868587 ops/training.py:65 2019-01-16 20:13:36.868525: step 2068, loss = 0.70162 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:13:37.758000 ops/training.py:65 2019-01-16 20:13:37.757939: step 2069, loss = 0.69589 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:13:38.647257 ops/training.py:65 2019-01-16 20:13:38.647188: step 2070, loss = 0.71138 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:13:39.536817 ops/training.py:65 2019-01-16 20:13:39.536755: step 2071, loss = 0.70598 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:13:40.426006 ops/training.py:65 2019-01-16 20:13:40.425947: step 2072, loss = 0.69265 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:13:41.314766 ops/training.py:65 2019-01-16 20:13:41.314708: step 2073, loss = 0.70122 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:13:42.203433 ops/training.py:65 2019-01-16 20:13:42.203372: step 2074, loss = 0.71778 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:13:43.091952 ops/training.py:65 2019-01-16 20:13:43.091887: step 2075, loss = 0.69356 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:13:43.981004 ops/training.py:65 2019-01-16 20:13:43.980940: step 2076, loss = 0.68161 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:13:44.874676 ops/training.py:65 2019-01-16 20:13:44.874605: step 2077, loss = 0.70706 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:13:45.764393 ops/training.py:65 2019-01-16 20:13:45.764303: step 2078, loss = 0.73674 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:13:46.656211 ops/training.py:65 2019-01-16 20:13:46.656105: step 2079, loss = 0.72695 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:13:47.548209 ops/training.py:65 2019-01-16 20:13:47.548112: step 2080, loss = 0.70423 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:13:48.439357 ops/training.py:65 2019-01-16 20:13:48.439296: step 2081, loss = 0.69991 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:13:49.332691 ops/training.py:65 2019-01-16 20:13:49.332583: step 2082, loss = 0.68112 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:13:50.223440 ops/training.py:65 2019-01-16 20:13:50.223359: step 2083, loss = 0.73025 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:13:51.113781 ops/training.py:65 2019-01-16 20:13:51.113718: step 2084, loss = 0.68584 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:13:52.002825 ops/training.py:65 2019-01-16 20:13:52.002766: step 2085, loss = 0.68780 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:13:52.891768 ops/training.py:65 2019-01-16 20:13:52.891706: step 2086, loss = 0.69220 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:13:53.782622 ops/training.py:65 2019-01-16 20:13:53.782550: step 2087, loss = 0.73712 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:13:54.674218 ops/training.py:65 2019-01-16 20:13:54.674111: step 2088, loss = 0.70362 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:13:55.565423 ops/training.py:65 2019-01-16 20:13:55.565326: step 2089, loss = 0.67314 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:13:56.454297 ops/training.py:65 2019-01-16 20:13:56.454234: step 2090, loss = 0.69529 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:13:57.342693 ops/training.py:65 2019-01-16 20:13:57.342624: step 2091, loss = 0.65835 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:13:58.231538 ops/training.py:65 2019-01-16 20:13:58.231463: step 2092, loss = 0.72679 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:13:59.121594 ops/training.py:65 2019-01-16 20:13:59.121514: step 2093, loss = 0.72476 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:14:00.010817 ops/training.py:65 2019-01-16 20:14:00.010743: step 2094, loss = 0.68118 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:14:00.899605 ops/training.py:65 2019-01-16 20:14:00.899531: step 2095, loss = 0.68244 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:14:01.788788 ops/training.py:65 2019-01-16 20:14:01.788721: step 2096, loss = 0.71510 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:14:02.678317 ops/training.py:65 2019-01-16 20:14:02.678250: step 2097, loss = 0.69163 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:14:03.567826 ops/training.py:65 2019-01-16 20:14:03.567759: step 2098, loss = 0.71679 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:14:04.459758 ops/training.py:65 2019-01-16 20:14:04.459693: step 2099, loss = 0.70681 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:14:05.348158 ops/training.py:65 2019-01-16 20:14:05.348097: step 2100, loss = 0.69264 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:14:06.237453 ops/training.py:65 2019-01-16 20:14:06.237390: step 2101, loss = 0.71070 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:14:07.129841 ops/training.py:65 2019-01-16 20:14:07.129761: step 2102, loss = 0.71545 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:14:08.022026 ops/training.py:65 2019-01-16 20:14:08.021916: step 2103, loss = 0.73274 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:14:08.912936 ops/training.py:65 2019-01-16 20:14:08.912875: step 2104, loss = 0.71493 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:14:09.803713 ops/training.py:65 2019-01-16 20:14:09.803650: step 2105, loss = 0.66844 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:14:10.693744 ops/training.py:65 2019-01-16 20:14:10.693680: step 2106, loss = 0.67806 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:14:11.583495 ops/training.py:65 2019-01-16 20:14:11.583430: step 2107, loss = 0.69941 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:14:12.472491 ops/training.py:65 2019-01-16 20:14:12.472419: step 2108, loss = 0.66306 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:14:13.361488 ops/training.py:65 2019-01-16 20:14:13.361413: step 2109, loss = 0.69776 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:14:14.250686 ops/training.py:65 2019-01-16 20:14:14.250624: step 2110, loss = 0.68417 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:14:15.140357 ops/training.py:65 2019-01-16 20:14:15.140295: step 2111, loss = 0.70298 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:14:16.030092 ops/training.py:65 2019-01-16 20:14:16.030033: step 2112, loss = 0.65736 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:14:16.919117 ops/training.py:65 2019-01-16 20:14:16.919045: step 2113, loss = 0.65363 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:14:17.808442 ops/training.py:65 2019-01-16 20:14:17.808378: step 2114, loss = 0.69512 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:14:18.696793 ops/training.py:65 2019-01-16 20:14:18.696726: step 2115, loss = 0.71662 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:14:19.586113 ops/training.py:65 2019-01-16 20:14:19.586046: step 2116, loss = 0.70034 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:14:20.475288 ops/training.py:65 2019-01-16 20:14:20.475219: step 2117, loss = 0.68382 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:14:21.364381 ops/training.py:65 2019-01-16 20:14:21.364317: step 2118, loss = 0.75133 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:14:22.253170 ops/training.py:65 2019-01-16 20:14:22.253107: step 2119, loss = 0.73780 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:14:23.142996 ops/training.py:65 2019-01-16 20:14:23.142904: step 2120, loss = 0.71919 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:14:24.031635 ops/training.py:65 2019-01-16 20:14:24.031568: step 2121, loss = 0.68268 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:14:24.920092 ops/training.py:65 2019-01-16 20:14:24.920030: step 2122, loss = 0.65886 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:14:25.809758 ops/training.py:65 2019-01-16 20:14:25.809691: step 2123, loss = 0.69000 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:14:26.698399 ops/training.py:65 2019-01-16 20:14:26.698334: step 2124, loss = 0.71455 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:14:27.586900 ops/training.py:65 2019-01-16 20:14:27.586833: step 2125, loss = 0.69839 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:14:28.475282 ops/training.py:65 2019-01-16 20:14:28.475223: step 2126, loss = 0.75870 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:14:29.363739 ops/training.py:65 2019-01-16 20:14:29.363683: step 2127, loss = 0.68519 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:14:30.251872 ops/training.py:65 2019-01-16 20:14:30.251812: step 2128, loss = 0.64016 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:14:31.140289 ops/training.py:65 2019-01-16 20:14:31.140219: step 2129, loss = 0.72208 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:14:32.028457 ops/training.py:65 2019-01-16 20:14:32.028392: step 2130, loss = 0.70909 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:14:32.918595 ops/training.py:65 2019-01-16 20:14:32.918536: step 2131, loss = 0.62772 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 20:14:33.810470 ops/training.py:65 2019-01-16 20:14:33.810394: step 2132, loss = 0.65764 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:14:34.702894 ops/training.py:65 2019-01-16 20:14:34.702789: step 2133, loss = 0.74688 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:14:35.594575 ops/training.py:65 2019-01-16 20:14:35.594517: step 2134, loss = 0.70815 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:14:36.483652 ops/training.py:65 2019-01-16 20:14:36.483588: step 2135, loss = 0.69144 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:14:37.373029 ops/training.py:65 2019-01-16 20:14:37.372966: step 2136, loss = 0.66625 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:14:38.261864 ops/training.py:65 2019-01-16 20:14:38.261787: step 2137, loss = 0.74023 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:14:39.151424 ops/training.py:65 2019-01-16 20:14:39.151354: step 2138, loss = 0.69354 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:14:40.040085 ops/training.py:65 2019-01-16 20:14:40.040010: step 2139, loss = 0.70330 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:14:40.928659 ops/training.py:65 2019-01-16 20:14:40.928602: step 2140, loss = 0.70177 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:14:41.818221 ops/training.py:65 2019-01-16 20:14:41.818154: step 2141, loss = 0.69275 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:14:42.707722 ops/training.py:65 2019-01-16 20:14:42.707656: step 2142, loss = 0.69110 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:14:43.598848 ops/training.py:65 2019-01-16 20:14:43.598784: step 2143, loss = 0.68566 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:14:44.489053 ops/training.py:65 2019-01-16 20:14:44.488994: step 2144, loss = 0.69975 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:14:45.380435 ops/training.py:65 2019-01-16 20:14:45.380375: step 2145, loss = 0.64746 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 20:14:46.272401 ops/training.py:65 2019-01-16 20:14:46.272324: step 2146, loss = 0.70654 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:14:47.166256 ops/training.py:65 2019-01-16 20:14:47.166160: step 2147, loss = 0.67535 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:14:48.057502 ops/training.py:65 2019-01-16 20:14:48.057412: step 2148, loss = 0.68300 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:14:48.947544 ops/training.py:65 2019-01-16 20:14:48.947484: step 2149, loss = 0.70543 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:14:49.836424 ops/training.py:65 2019-01-16 20:14:49.836361: step 2150, loss = 0.71954 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:14:50.725059 ops/training.py:65 2019-01-16 20:14:50.724997: step 2151, loss = 0.69873 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:14:51.613961 ops/training.py:65 2019-01-16 20:14:51.613900: step 2152, loss = 0.71280 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:14:52.502348 ops/training.py:65 2019-01-16 20:14:52.502293: step 2153, loss = 0.72635 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:14:53.390608 ops/training.py:65 2019-01-16 20:14:53.390541: step 2154, loss = 0.70682 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:14:54.280263 ops/training.py:65 2019-01-16 20:14:54.280201: step 2155, loss = 0.73393 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:14:55.168743 ops/training.py:65 2019-01-16 20:14:55.168680: step 2156, loss = 0.69908 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:14:56.057914 ops/training.py:65 2019-01-16 20:14:56.057855: step 2157, loss = 0.69582 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:14:56.946353 ops/training.py:65 2019-01-16 20:14:56.946294: step 2158, loss = 0.70602 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:14:57.836546 ops/training.py:65 2019-01-16 20:14:57.836483: step 2159, loss = 0.64574 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.78125
I2992 2019-01-16 20:14:58.726009 ops/training.py:65 2019-01-16 20:14:58.725945: step 2160, loss = 0.70865 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:14:59.615881 ops/training.py:65 2019-01-16 20:14:59.615816: step 2161, loss = 0.73357 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:15:00.504748 ops/training.py:65 2019-01-16 20:15:00.504684: step 2162, loss = 0.68730 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:15:01.393644 ops/training.py:65 2019-01-16 20:15:01.393583: step 2163, loss = 0.71341 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:15:02.282445 ops/training.py:65 2019-01-16 20:15:02.282388: step 2164, loss = 0.71172 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:15:03.171873 ops/training.py:65 2019-01-16 20:15:03.171805: step 2165, loss = 0.73064 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:15:04.062298 ops/training.py:65 2019-01-16 20:15:04.062237: step 2166, loss = 0.68580 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:15:04.952974 ops/training.py:65 2019-01-16 20:15:04.952902: step 2167, loss = 0.70739 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:15:05.845256 ops/training.py:65 2019-01-16 20:15:05.845149: step 2168, loss = 0.69697 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:15:06.737427 ops/training.py:65 2019-01-16 20:15:06.737322: step 2169, loss = 0.67569 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:15:07.629146 ops/training.py:65 2019-01-16 20:15:07.629083: step 2170, loss = 0.69187 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:15:08.520278 ops/training.py:65 2019-01-16 20:15:08.520219: step 2171, loss = 0.68709 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:15:09.409315 ops/training.py:65 2019-01-16 20:15:09.409253: step 2172, loss = 0.70728 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:15:10.298417 ops/training.py:65 2019-01-16 20:15:10.298351: step 2173, loss = 0.69987 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:15:11.187321 ops/training.py:65 2019-01-16 20:15:11.187259: step 2174, loss = 0.70577 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:15:12.076447 ops/training.py:65 2019-01-16 20:15:12.076383: step 2175, loss = 0.68684 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:15:12.965632 ops/training.py:65 2019-01-16 20:15:12.965572: step 2176, loss = 0.68623 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:15:13.854768 ops/training.py:65 2019-01-16 20:15:13.854705: step 2177, loss = 0.67240 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:15:14.744129 ops/training.py:65 2019-01-16 20:15:14.744062: step 2178, loss = 0.67689 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:15:15.633719 ops/training.py:65 2019-01-16 20:15:15.633656: step 2179, loss = 0.68106 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:15:16.522982 ops/training.py:65 2019-01-16 20:15:16.522918: step 2180, loss = 0.73489 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:15:17.412158 ops/training.py:65 2019-01-16 20:15:17.412097: step 2181, loss = 0.73627 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:15:18.301533 ops/training.py:65 2019-01-16 20:15:18.301468: step 2182, loss = 0.72041 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:15:19.191218 ops/training.py:65 2019-01-16 20:15:19.191154: step 2183, loss = 0.69086 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:15:20.080531 ops/training.py:65 2019-01-16 20:15:20.080458: step 2184, loss = 0.69561 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:15:20.972220 ops/training.py:65 2019-01-16 20:15:20.972109: step 2185, loss = 0.70303 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:15:21.863422 ops/training.py:65 2019-01-16 20:15:21.863362: step 2186, loss = 0.70975 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:15:22.752753 ops/training.py:65 2019-01-16 20:15:22.752690: step 2187, loss = 0.69614 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:15:23.642506 ops/training.py:65 2019-01-16 20:15:23.642439: step 2188, loss = 0.67614 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:15:24.531163 ops/training.py:65 2019-01-16 20:15:24.531106: step 2189, loss = 0.67503 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:15:25.419704 ops/training.py:65 2019-01-16 20:15:25.419641: step 2190, loss = 0.69475 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:15:26.308167 ops/training.py:65 2019-01-16 20:15:26.308104: step 2191, loss = 0.72369 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:15:27.197402 ops/training.py:65 2019-01-16 20:15:27.197339: step 2192, loss = 0.76547 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:15:28.086874 ops/training.py:65 2019-01-16 20:15:28.086809: step 2193, loss = 0.72254 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:15:28.977006 ops/training.py:65 2019-01-16 20:15:28.976945: step 2194, loss = 0.75067 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:15:29.865693 ops/training.py:65 2019-01-16 20:15:29.865631: step 2195, loss = 0.68117 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:15:30.754579 ops/training.py:65 2019-01-16 20:15:30.754519: step 2196, loss = 0.74708 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 20:15:31.643983 ops/training.py:65 2019-01-16 20:15:31.643921: step 2197, loss = 0.72778 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:15:32.532806 ops/training.py:65 2019-01-16 20:15:32.532746: step 2198, loss = 0.69864 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:15:33.422324 ops/training.py:65 2019-01-16 20:15:33.422254: step 2199, loss = 0.69296 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:15:34.311445 ops/training.py:65 2019-01-16 20:15:34.311379: step 2200, loss = 0.73223 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:15:35.202159 ops/training.py:65 2019-01-16 20:15:35.202093: step 2201, loss = 0.67151 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:15:36.092393 ops/training.py:65 2019-01-16 20:15:36.092317: step 2202, loss = 0.71341 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:15:36.981557 ops/training.py:65 2019-01-16 20:15:36.981457: step 2203, loss = 0.69891 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:15:37.872246 ops/training.py:65 2019-01-16 20:15:37.872144: step 2204, loss = 0.71841 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:15:38.762594 ops/training.py:65 2019-01-16 20:15:38.762487: step 2205, loss = 0.71311 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:15:39.654706 ops/training.py:65 2019-01-16 20:15:39.654599: step 2206, loss = 0.71491 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:15:40.544505 ops/training.py:65 2019-01-16 20:15:40.544404: step 2207, loss = 0.69583 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:15:41.434279 ops/training.py:65 2019-01-16 20:15:41.434221: step 2208, loss = 0.70412 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:15:42.322893 ops/training.py:65 2019-01-16 20:15:42.322832: step 2209, loss = 0.70572 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:15:43.212018 ops/training.py:65 2019-01-16 20:15:43.211953: step 2210, loss = 0.67346 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:15:44.101826 ops/training.py:65 2019-01-16 20:15:44.101763: step 2211, loss = 0.72740 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:15:44.991472 ops/training.py:65 2019-01-16 20:15:44.991399: step 2212, loss = 0.70659 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:15:45.880422 ops/training.py:65 2019-01-16 20:15:45.880359: step 2213, loss = 0.66520 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:15:46.769718 ops/training.py:65 2019-01-16 20:15:46.769657: step 2214, loss = 0.72591 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 20:15:47.658649 ops/training.py:65 2019-01-16 20:15:47.658589: step 2215, loss = 0.64663 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.75
I2992 2019-01-16 20:15:48.548471 ops/training.py:65 2019-01-16 20:15:48.548405: step 2216, loss = 0.71268 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:15:49.440062 ops/training.py:65 2019-01-16 20:15:49.439999: step 2217, loss = 0.70092 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:15:50.331481 ops/training.py:65 2019-01-16 20:15:50.331374: step 2218, loss = 0.70913 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:15:51.224348 ops/training.py:65 2019-01-16 20:15:51.224243: step 2219, loss = 0.65037 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:15:52.115859 ops/training.py:65 2019-01-16 20:15:52.115754: step 2220, loss = 0.73142 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:15:53.008449 ops/training.py:65 2019-01-16 20:15:53.008342: step 2221, loss = 0.67616 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:15:53.899680 ops/training.py:65 2019-01-16 20:15:53.899582: step 2222, loss = 0.70976 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:15:54.790764 ops/training.py:65 2019-01-16 20:15:54.790653: step 2223, loss = 0.69127 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:15:55.681112 ops/training.py:65 2019-01-16 20:15:55.681043: step 2224, loss = 0.70904 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:15:56.571110 ops/training.py:65 2019-01-16 20:15:56.571038: step 2225, loss = 0.69733 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:15:57.461246 ops/training.py:65 2019-01-16 20:15:57.461146: step 2226, loss = 0.67819 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:15:58.354153 ops/training.py:65 2019-01-16 20:15:58.354050: step 2227, loss = 0.73545 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:15:59.245482 ops/training.py:65 2019-01-16 20:15:59.245385: step 2228, loss = 0.67438 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:16:00.135360 ops/training.py:65 2019-01-16 20:16:00.135257: step 2229, loss = 0.69112 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:16:01.025646 ops/training.py:65 2019-01-16 20:16:01.025548: step 2230, loss = 0.71163 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:16:01.916561 ops/training.py:65 2019-01-16 20:16:01.916479: step 2231, loss = 0.69825 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:16:02.809925 ops/training.py:65 2019-01-16 20:16:02.809824: step 2232, loss = 0.72687 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:16:03.700980 ops/training.py:65 2019-01-16 20:16:03.700904: step 2233, loss = 0.70229 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:16:04.590773 ops/training.py:65 2019-01-16 20:16:04.590710: step 2234, loss = 0.70312 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:16:05.480244 ops/training.py:65 2019-01-16 20:16:05.480186: step 2235, loss = 0.71924 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:16:06.368876 ops/training.py:65 2019-01-16 20:16:06.368819: step 2236, loss = 0.67793 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:16:07.258185 ops/training.py:65 2019-01-16 20:16:07.258125: step 2237, loss = 0.71232 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:16:08.147637 ops/training.py:65 2019-01-16 20:16:08.147568: step 2238, loss = 0.70468 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:16:09.036565 ops/training.py:65 2019-01-16 20:16:09.036505: step 2239, loss = 0.67911 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:16:09.924775 ops/training.py:65 2019-01-16 20:16:09.924709: step 2240, loss = 0.75921 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:16:10.813012 ops/training.py:65 2019-01-16 20:16:10.812955: step 2241, loss = 0.73794 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:16:11.702389 ops/training.py:65 2019-01-16 20:16:11.702326: step 2242, loss = 0.70464 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:16:12.594985 ops/training.py:65 2019-01-16 20:16:12.594918: step 2243, loss = 0.65886 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:16:13.486093 ops/training.py:65 2019-01-16 20:16:13.485993: step 2244, loss = 0.72244 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:16:14.379222 ops/training.py:65 2019-01-16 20:16:14.379141: step 2245, loss = 0.71819 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:16:15.272826 ops/training.py:65 2019-01-16 20:16:15.272714: step 2246, loss = 0.69906 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:16:16.164466 ops/training.py:65 2019-01-16 20:16:16.164363: step 2247, loss = 0.69898 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:16:17.054907 ops/training.py:65 2019-01-16 20:16:17.054850: step 2248, loss = 0.73356 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:16:17.944896 ops/training.py:65 2019-01-16 20:16:17.944840: step 2249, loss = 0.70887 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:16:18.834386 ops/training.py:65 2019-01-16 20:16:18.834330: step 2250, loss = 0.71502 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:16:19.722681 ops/training.py:65 2019-01-16 20:16:19.722622: step 2251, loss = 0.68152 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:16:20.611582 ops/training.py:65 2019-01-16 20:16:20.611518: step 2252, loss = 0.70587 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:16:21.500959 ops/training.py:65 2019-01-16 20:16:21.500896: step 2253, loss = 0.72151 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:16:22.389290 ops/training.py:65 2019-01-16 20:16:22.389226: step 2254, loss = 0.70632 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:16:23.279722 ops/training.py:65 2019-01-16 20:16:23.279656: step 2255, loss = 0.73394 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:16:24.169326 ops/training.py:65 2019-01-16 20:16:24.169271: step 2256, loss = 0.71639 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:16:25.058021 ops/training.py:65 2019-01-16 20:16:25.057968: step 2257, loss = 0.71953 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:16:25.946526 ops/training.py:65 2019-01-16 20:16:25.946472: step 2258, loss = 0.70861 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:16:26.834542 ops/training.py:65 2019-01-16 20:16:26.834483: step 2259, loss = 0.72836 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:16:27.722884 ops/training.py:65 2019-01-16 20:16:27.722820: step 2260, loss = 0.71478 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:16:28.612650 ops/training.py:65 2019-01-16 20:16:28.612587: step 2261, loss = 0.68922 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:16:29.502254 ops/training.py:65 2019-01-16 20:16:29.502193: step 2262, loss = 0.70515 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:16:30.392632 ops/training.py:65 2019-01-16 20:16:30.392565: step 2263, loss = 0.70452 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:16:31.282339 ops/training.py:65 2019-01-16 20:16:31.282276: step 2264, loss = 0.70021 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:16:32.171017 ops/training.py:65 2019-01-16 20:16:32.170950: step 2265, loss = 0.71878 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:16:33.061349 ops/training.py:65 2019-01-16 20:16:33.061278: step 2266, loss = 0.69304 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:16:33.950839 ops/training.py:65 2019-01-16 20:16:33.950771: step 2267, loss = 0.72493 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:16:34.840160 ops/training.py:65 2019-01-16 20:16:34.840093: step 2268, loss = 0.71903 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:16:35.728828 ops/training.py:65 2019-01-16 20:16:35.728762: step 2269, loss = 0.66624 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:16:36.620094 ops/training.py:65 2019-01-16 20:16:36.620025: step 2270, loss = 0.70466 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:16:37.511961 ops/training.py:65 2019-01-16 20:16:37.511856: step 2271, loss = 0.67313 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:16:38.403631 ops/training.py:65 2019-01-16 20:16:38.403530: step 2272, loss = 0.67395 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:16:39.293411 ops/training.py:65 2019-01-16 20:16:39.293344: step 2273, loss = 0.68006 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:16:40.182348 ops/training.py:65 2019-01-16 20:16:40.182286: step 2274, loss = 0.68392 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:16:41.071836 ops/training.py:65 2019-01-16 20:16:41.071770: step 2275, loss = 0.69853 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:16:41.959860 ops/training.py:65 2019-01-16 20:16:41.959794: step 2276, loss = 0.69641 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:16:42.849712 ops/training.py:65 2019-01-16 20:16:42.849649: step 2277, loss = 0.69727 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:16:43.740141 ops/training.py:65 2019-01-16 20:16:43.740064: step 2278, loss = 0.72702 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:16:44.633050 ops/training.py:65 2019-01-16 20:16:44.632935: step 2279, loss = 0.68732 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:16:45.523755 ops/training.py:65 2019-01-16 20:16:45.523662: step 2280, loss = 0.70073 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:16:46.414555 ops/training.py:65 2019-01-16 20:16:46.414483: step 2281, loss = 0.70304 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:16:47.305542 ops/training.py:65 2019-01-16 20:16:47.305462: step 2282, loss = 0.69484 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:16:48.196694 ops/training.py:65 2019-01-16 20:16:48.196589: step 2283, loss = 0.71527 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:16:49.088359 ops/training.py:65 2019-01-16 20:16:49.088249: step 2284, loss = 0.75553 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:16:49.980219 ops/training.py:65 2019-01-16 20:16:49.980120: step 2285, loss = 0.67310 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:16:50.872977 ops/training.py:65 2019-01-16 20:16:50.872872: step 2286, loss = 0.73942 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:16:51.765887 ops/training.py:65 2019-01-16 20:16:51.765775: step 2287, loss = 0.75231 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:16:52.657039 ops/training.py:65 2019-01-16 20:16:52.656929: step 2288, loss = 0.71431 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:16:53.547085 ops/training.py:65 2019-01-16 20:16:53.547016: step 2289, loss = 0.66836 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:16:54.438334 ops/training.py:65 2019-01-16 20:16:54.438272: step 2290, loss = 0.72651 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:16:55.326985 ops/training.py:65 2019-01-16 20:16:55.326927: step 2291, loss = 0.68636 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:16:56.215845 ops/training.py:65 2019-01-16 20:16:56.215782: step 2292, loss = 0.68831 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:16:57.104228 ops/training.py:65 2019-01-16 20:16:57.104156: step 2293, loss = 0.70417 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:16:57.993737 ops/training.py:65 2019-01-16 20:16:57.993670: step 2294, loss = 0.70091 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:16:58.884723 ops/training.py:65 2019-01-16 20:16:58.884649: step 2295, loss = 0.70499 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:16:59.777198 ops/training.py:65 2019-01-16 20:16:59.777091: step 2296, loss = 0.67858 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:17:00.669776 ops/training.py:65 2019-01-16 20:17:00.669687: step 2297, loss = 0.70146 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:17:01.561368 ops/training.py:65 2019-01-16 20:17:01.561266: step 2298, loss = 0.71715 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:17:02.452356 ops/training.py:65 2019-01-16 20:17:02.452262: step 2299, loss = 0.69669 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:17:03.343494 ops/training.py:65 2019-01-16 20:17:03.343389: step 2300, loss = 0.70061 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:17:04.235243 ops/training.py:65 2019-01-16 20:17:04.235134: step 2301, loss = 0.70745 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:17:05.127020 ops/training.py:65 2019-01-16 20:17:05.126974: step 2302, loss = 0.70789 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:17:06.020304 ops/training.py:65 2019-01-16 20:17:06.020242: step 2303, loss = 0.71624 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:17:06.911862 ops/training.py:65 2019-01-16 20:17:06.911763: step 2304, loss = 0.68185 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:17:07.803282 ops/training.py:65 2019-01-16 20:17:07.803187: step 2305, loss = 0.70261 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:17:08.692834 ops/training.py:65 2019-01-16 20:17:08.692774: step 2306, loss = 0.67546 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:17:09.583614 ops/training.py:65 2019-01-16 20:17:09.583549: step 2307, loss = 0.72712 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:17:10.473969 ops/training.py:65 2019-01-16 20:17:10.473866: step 2308, loss = 0.71523 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:17:11.368285 ops/training.py:65 2019-01-16 20:17:11.368193: step 2309, loss = 0.73618 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:17:12.260422 ops/training.py:65 2019-01-16 20:17:12.260315: step 2310, loss = 0.73393 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:17:13.152864 ops/training.py:65 2019-01-16 20:17:13.152760: step 2311, loss = 0.69895 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:17:14.044526 ops/training.py:65 2019-01-16 20:17:14.044466: step 2312, loss = 0.69837 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:17:14.932368 ops/training.py:65 2019-01-16 20:17:14.932307: step 2313, loss = 0.75809 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:17:15.821631 ops/training.py:65 2019-01-16 20:17:15.821564: step 2314, loss = 0.72943 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:17:16.710511 ops/training.py:65 2019-01-16 20:17:16.710450: step 2315, loss = 0.67054 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:17:17.599204 ops/training.py:65 2019-01-16 20:17:17.599142: step 2316, loss = 0.68084 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:17:18.488206 ops/training.py:65 2019-01-16 20:17:18.488147: step 2317, loss = 0.70093 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:17:19.377538 ops/training.py:65 2019-01-16 20:17:19.377474: step 2318, loss = 0.71018 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:17:20.266763 ops/training.py:65 2019-01-16 20:17:20.266702: step 2319, loss = 0.70583 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:17:21.155465 ops/training.py:65 2019-01-16 20:17:21.155405: step 2320, loss = 0.69350 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:17:22.044699 ops/training.py:65 2019-01-16 20:17:22.044631: step 2321, loss = 0.66011 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:17:22.934003 ops/training.py:65 2019-01-16 20:17:22.933943: step 2322, loss = 0.70620 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:17:23.822004 ops/training.py:65 2019-01-16 20:17:23.821938: step 2323, loss = 0.71029 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:17:24.711918 ops/training.py:65 2019-01-16 20:17:24.711847: step 2324, loss = 0.68027 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:17:25.604866 ops/training.py:65 2019-01-16 20:17:25.604754: step 2325, loss = 0.73194 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:17:26.495221 ops/training.py:65 2019-01-16 20:17:26.495112: step 2326, loss = 0.70870 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:17:27.386351 ops/training.py:65 2019-01-16 20:17:27.386249: step 2327, loss = 0.70502 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:17:28.277298 ops/training.py:65 2019-01-16 20:17:28.277202: step 2328, loss = 0.70850 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:17:29.168709 ops/training.py:65 2019-01-16 20:17:29.168639: step 2329, loss = 0.71755 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:17:30.057825 ops/training.py:65 2019-01-16 20:17:30.057762: step 2330, loss = 0.68535 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:17:30.946566 ops/training.py:65 2019-01-16 20:17:30.946508: step 2331, loss = 0.70350 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:17:31.834936 ops/training.py:65 2019-01-16 20:17:31.834881: step 2332, loss = 0.67067 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:17:32.723822 ops/training.py:65 2019-01-16 20:17:32.723767: step 2333, loss = 0.65791 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:17:33.613907 ops/training.py:65 2019-01-16 20:17:33.613851: step 2334, loss = 0.70293 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:17:34.503527 ops/training.py:65 2019-01-16 20:17:34.503463: step 2335, loss = 0.70747 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:17:35.395587 ops/training.py:65 2019-01-16 20:17:35.395479: step 2336, loss = 0.69399 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:17:36.289107 ops/training.py:65 2019-01-16 20:17:36.289004: step 2337, loss = 0.65020 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:17:37.180134 ops/training.py:65 2019-01-16 20:17:37.180069: step 2338, loss = 0.74379 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:17:38.068956 ops/training.py:65 2019-01-16 20:17:38.068898: step 2339, loss = 0.72552 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:17:38.957460 ops/training.py:65 2019-01-16 20:17:38.957406: step 2340, loss = 0.70194 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:17:39.846319 ops/training.py:65 2019-01-16 20:17:39.846267: step 2341, loss = 0.73044 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:17:40.734812 ops/training.py:65 2019-01-16 20:17:40.734757: step 2342, loss = 0.73957 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:17:41.624149 ops/training.py:65 2019-01-16 20:17:41.624092: step 2343, loss = 0.71507 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:17:42.514219 ops/training.py:65 2019-01-16 20:17:42.514158: step 2344, loss = 0.70074 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:17:43.404784 ops/training.py:65 2019-01-16 20:17:43.404716: step 2345, loss = 0.71004 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:17:44.295664 ops/training.py:65 2019-01-16 20:17:44.295605: step 2346, loss = 0.72447 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:17:45.184402 ops/training.py:65 2019-01-16 20:17:45.184342: step 2347, loss = 0.74093 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:17:46.072611 ops/training.py:65 2019-01-16 20:17:46.072548: step 2348, loss = 0.67281 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:17:46.961125 ops/training.py:65 2019-01-16 20:17:46.961067: step 2349, loss = 0.68789 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:17:47.851288 ops/training.py:65 2019-01-16 20:17:47.851222: step 2350, loss = 0.75306 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:17:48.741221 ops/training.py:65 2019-01-16 20:17:48.741112: step 2351, loss = 0.72681 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:17:49.632430 ops/training.py:65 2019-01-16 20:17:49.632322: step 2352, loss = 0.72459 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:17:50.522342 ops/training.py:65 2019-01-16 20:17:50.522237: step 2353, loss = 0.71257 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:17:51.414261 ops/training.py:65 2019-01-16 20:17:51.414159: step 2354, loss = 0.68697 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:17:52.303728 ops/training.py:65 2019-01-16 20:17:52.303624: step 2355, loss = 0.72679 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:17:53.192887 ops/training.py:65 2019-01-16 20:17:53.192821: step 2356, loss = 0.71773 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:17:54.081384 ops/training.py:65 2019-01-16 20:17:54.081324: step 2357, loss = 0.75328 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:17:54.972030 ops/training.py:65 2019-01-16 20:17:54.971962: step 2358, loss = 0.72657 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:17:55.864290 ops/training.py:65 2019-01-16 20:17:55.864186: step 2359, loss = 0.72557 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:17:56.756595 ops/training.py:65 2019-01-16 20:17:56.756499: step 2360, loss = 0.67535 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:17:57.647653 ops/training.py:65 2019-01-16 20:17:57.647552: step 2361, loss = 0.67148 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:17:58.538427 ops/training.py:65 2019-01-16 20:17:58.538329: step 2362, loss = 0.72166 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:17:59.430284 ops/training.py:65 2019-01-16 20:17:59.430179: step 2363, loss = 0.68263 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:18:00.322183 ops/training.py:65 2019-01-16 20:18:00.322095: step 2364, loss = 0.73494 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:18:01.214778 ops/training.py:65 2019-01-16 20:18:01.214677: step 2365, loss = 0.67563 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:18:02.105082 ops/training.py:65 2019-01-16 20:18:02.104982: step 2366, loss = 0.68668 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:18:02.994973 ops/training.py:65 2019-01-16 20:18:02.994916: step 2367, loss = 0.70836 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:18:03.883390 ops/training.py:65 2019-01-16 20:18:03.883326: step 2368, loss = 0.70170 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:18:04.772254 ops/training.py:65 2019-01-16 20:18:04.772196: step 2369, loss = 0.69773 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:18:05.660902 ops/training.py:65 2019-01-16 20:18:05.660842: step 2370, loss = 0.71438 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:18:06.548974 ops/training.py:65 2019-01-16 20:18:06.548918: step 2371, loss = 0.70479 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:18:07.437757 ops/training.py:65 2019-01-16 20:18:07.437701: step 2372, loss = 0.69454 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:18:08.327097 ops/training.py:65 2019-01-16 20:18:08.327037: step 2373, loss = 0.68931 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:18:09.215941 ops/training.py:65 2019-01-16 20:18:09.215886: step 2374, loss = 0.66996 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:18:10.104432 ops/training.py:65 2019-01-16 20:18:10.104373: step 2375, loss = 0.72256 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:18:10.992791 ops/training.py:65 2019-01-16 20:18:10.992728: step 2376, loss = 0.77012 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:18:11.882684 ops/training.py:65 2019-01-16 20:18:11.882608: step 2377, loss = 0.69427 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:18:12.775216 ops/training.py:65 2019-01-16 20:18:12.775107: step 2378, loss = 0.66500 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:18:13.668368 ops/training.py:65 2019-01-16 20:18:13.668269: step 2379, loss = 0.68534 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:18:14.559026 ops/training.py:65 2019-01-16 20:18:14.558957: step 2380, loss = 0.69096 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:18:15.448450 ops/training.py:65 2019-01-16 20:18:15.448384: step 2381, loss = 0.71518 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:18:16.337069 ops/training.py:65 2019-01-16 20:18:16.337014: step 2382, loss = 0.74090 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:18:17.226309 ops/training.py:65 2019-01-16 20:18:17.226248: step 2383, loss = 0.69894 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:18:18.115145 ops/training.py:65 2019-01-16 20:18:18.115086: step 2384, loss = 0.67343 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:18:19.004357 ops/training.py:65 2019-01-16 20:18:19.004291: step 2385, loss = 0.73245 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:18:19.893064 ops/training.py:65 2019-01-16 20:18:19.893000: step 2386, loss = 0.75331 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:18:20.781622 ops/training.py:65 2019-01-16 20:18:20.781558: step 2387, loss = 0.69089 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:18:21.670406 ops/training.py:65 2019-01-16 20:18:21.670343: step 2388, loss = 0.72402 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:18:22.559096 ops/training.py:65 2019-01-16 20:18:22.559040: step 2389, loss = 0.68997 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:18:23.447705 ops/training.py:65 2019-01-16 20:18:23.447641: step 2390, loss = 0.66490 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:18:24.336829 ops/training.py:65 2019-01-16 20:18:24.336768: step 2391, loss = 0.68851 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:18:25.225146 ops/training.py:65 2019-01-16 20:18:25.225091: step 2392, loss = 0.70709 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:18:26.114031 ops/training.py:65 2019-01-16 20:18:26.113979: step 2393, loss = 0.75050 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:18:27.002598 ops/training.py:65 2019-01-16 20:18:27.002548: step 2394, loss = 0.70244 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:18:27.891184 ops/training.py:65 2019-01-16 20:18:27.891126: step 2395, loss = 0.68613 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:18:28.779101 ops/training.py:65 2019-01-16 20:18:28.779043: step 2396, loss = 0.66714 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:18:29.668036 ops/training.py:65 2019-01-16 20:18:29.667976: step 2397, loss = 0.67326 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:18:30.555909 ops/training.py:65 2019-01-16 20:18:30.555845: step 2398, loss = 0.71553 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:18:31.444360 ops/training.py:65 2019-01-16 20:18:31.444295: step 2399, loss = 0.68460 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:18:32.333090 ops/training.py:65 2019-01-16 20:18:32.333025: step 2400, loss = 0.69495 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:18:33.222188 ops/training.py:65 2019-01-16 20:18:33.222121: step 2401, loss = 0.68264 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:18:34.111176 ops/training.py:65 2019-01-16 20:18:34.111112: step 2402, loss = 0.71022 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:18:34.999470 ops/training.py:65 2019-01-16 20:18:34.999409: step 2403, loss = 0.70754 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:18:35.888764 ops/training.py:65 2019-01-16 20:18:35.888702: step 2404, loss = 0.68015 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:18:36.777813 ops/training.py:65 2019-01-16 20:18:36.777750: step 2405, loss = 0.74480 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:18:37.668825 ops/training.py:65 2019-01-16 20:18:37.668756: step 2406, loss = 0.69085 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:18:38.561031 ops/training.py:65 2019-01-16 20:18:38.560925: step 2407, loss = 0.71699 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:18:39.452563 ops/training.py:65 2019-01-16 20:18:39.452505: step 2408, loss = 0.70064 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:18:40.341126 ops/training.py:65 2019-01-16 20:18:40.341072: step 2409, loss = 0.72294 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:18:41.229998 ops/training.py:65 2019-01-16 20:18:41.229930: step 2410, loss = 0.69262 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:18:42.119134 ops/training.py:65 2019-01-16 20:18:42.119079: step 2411, loss = 0.69044 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:18:43.008707 ops/training.py:65 2019-01-16 20:18:43.008654: step 2412, loss = 0.71922 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:18:43.897237 ops/training.py:65 2019-01-16 20:18:43.897172: step 2413, loss = 0.67901 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:18:44.786847 ops/training.py:65 2019-01-16 20:18:44.786782: step 2414, loss = 0.71834 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:18:45.675713 ops/training.py:65 2019-01-16 20:18:45.675654: step 2415, loss = 0.66629 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:18:46.565259 ops/training.py:65 2019-01-16 20:18:46.565204: step 2416, loss = 0.67045 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:18:47.454051 ops/training.py:65 2019-01-16 20:18:47.453989: step 2417, loss = 0.71389 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:18:48.342883 ops/training.py:65 2019-01-16 20:18:48.342819: step 2418, loss = 0.73251 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:18:49.232040 ops/training.py:65 2019-01-16 20:18:49.231980: step 2419, loss = 0.73703 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 20:18:50.120846 ops/training.py:65 2019-01-16 20:18:50.120782: step 2420, loss = 0.68718 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:18:51.009767 ops/training.py:65 2019-01-16 20:18:51.009703: step 2421, loss = 0.72662 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:18:51.898382 ops/training.py:65 2019-01-16 20:18:51.898323: step 2422, loss = 0.66700 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:18:52.789131 ops/training.py:65 2019-01-16 20:18:52.789058: step 2423, loss = 0.71014 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:18:53.678315 ops/training.py:65 2019-01-16 20:18:53.678222: step 2424, loss = 0.69140 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:18:54.569877 ops/training.py:65 2019-01-16 20:18:54.569774: step 2425, loss = 0.71216 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:18:55.460761 ops/training.py:65 2019-01-16 20:18:55.460657: step 2426, loss = 0.71631 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:18:56.350919 ops/training.py:65 2019-01-16 20:18:56.350852: step 2427, loss = 0.66974 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:18:57.239616 ops/training.py:65 2019-01-16 20:18:57.239546: step 2428, loss = 0.67340 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:18:58.128019 ops/training.py:65 2019-01-16 20:18:58.127953: step 2429, loss = 0.73943 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 20:18:59.017576 ops/training.py:65 2019-01-16 20:18:59.017516: step 2430, loss = 0.72043 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:18:59.906252 ops/training.py:65 2019-01-16 20:18:59.906190: step 2431, loss = 0.70194 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:19:00.794692 ops/training.py:65 2019-01-16 20:19:00.794631: step 2432, loss = 0.67215 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:19:01.684107 ops/training.py:65 2019-01-16 20:19:01.684044: step 2433, loss = 0.72661 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:19:02.572495 ops/training.py:65 2019-01-16 20:19:02.572438: step 2434, loss = 0.66658 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:19:03.461172 ops/training.py:65 2019-01-16 20:19:03.461113: step 2435, loss = 0.68945 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:19:04.351651 ops/training.py:65 2019-01-16 20:19:04.351588: step 2436, loss = 0.68585 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:19:05.243271 ops/training.py:65 2019-01-16 20:19:05.243171: step 2437, loss = 0.66805 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:19:06.134842 ops/training.py:65 2019-01-16 20:19:06.134749: step 2438, loss = 0.71629 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:19:07.024734 ops/training.py:65 2019-01-16 20:19:07.024671: step 2439, loss = 0.69537 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:19:07.914023 ops/training.py:65 2019-01-16 20:19:07.913957: step 2440, loss = 0.75610 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:19:08.802802 ops/training.py:65 2019-01-16 20:19:08.802739: step 2441, loss = 0.69019 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:19:09.691913 ops/training.py:65 2019-01-16 20:19:09.691850: step 2442, loss = 0.67417 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:19:10.580372 ops/training.py:65 2019-01-16 20:19:10.580306: step 2443, loss = 0.69102 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:19:11.468803 ops/training.py:65 2019-01-16 20:19:11.468742: step 2444, loss = 0.74434 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:19:12.357469 ops/training.py:65 2019-01-16 20:19:12.357411: step 2445, loss = 0.71757 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:19:13.246759 ops/training.py:65 2019-01-16 20:19:13.246692: step 2446, loss = 0.66706 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:19:14.135940 ops/training.py:65 2019-01-16 20:19:14.135877: step 2447, loss = 0.72397 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:19:15.024850 ops/training.py:65 2019-01-16 20:19:15.024788: step 2448, loss = 0.70591 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:19:15.913775 ops/training.py:65 2019-01-16 20:19:15.913709: step 2449, loss = 0.64076 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:19:16.802222 ops/training.py:65 2019-01-16 20:19:16.802162: step 2450, loss = 0.71555 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:19:17.690615 ops/training.py:65 2019-01-16 20:19:17.690552: step 2451, loss = 0.70760 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:19:18.579847 ops/training.py:65 2019-01-16 20:19:18.579783: step 2452, loss = 0.69331 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:19:19.468792 ops/training.py:65 2019-01-16 20:19:19.468726: step 2453, loss = 0.68204 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:19:20.357004 ops/training.py:65 2019-01-16 20:19:20.356941: step 2454, loss = 0.68331 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:19:21.245387 ops/training.py:65 2019-01-16 20:19:21.245325: step 2455, loss = 0.68207 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:19:22.133793 ops/training.py:65 2019-01-16 20:19:22.133731: step 2456, loss = 0.73824 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:19:23.022812 ops/training.py:65 2019-01-16 20:19:23.022751: step 2457, loss = 0.69472 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:19:23.911655 ops/training.py:65 2019-01-16 20:19:23.911589: step 2458, loss = 0.75066 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:19:24.799900 ops/training.py:65 2019-01-16 20:19:24.799829: step 2459, loss = 0.65842 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:19:25.688041 ops/training.py:65 2019-01-16 20:19:25.687961: step 2460, loss = 0.69599 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:19:26.577602 ops/training.py:65 2019-01-16 20:19:26.577539: step 2461, loss = 0.70460 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:19:27.466157 ops/training.py:65 2019-01-16 20:19:27.466090: step 2462, loss = 0.71049 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:19:28.355320 ops/training.py:65 2019-01-16 20:19:28.355249: step 2463, loss = 0.71573 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:19:29.244228 ops/training.py:65 2019-01-16 20:19:29.244168: step 2464, loss = 0.68878 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:19:30.132117 ops/training.py:65 2019-01-16 20:19:30.132060: step 2465, loss = 0.68666 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:19:31.020069 ops/training.py:65 2019-01-16 20:19:31.020010: step 2466, loss = 0.70399 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:19:31.909303 ops/training.py:65 2019-01-16 20:19:31.909240: step 2467, loss = 0.70308 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:19:32.797966 ops/training.py:65 2019-01-16 20:19:32.797894: step 2468, loss = 0.71209 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:19:33.686102 ops/training.py:65 2019-01-16 20:19:33.686034: step 2469, loss = 0.70136 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:19:34.574854 ops/training.py:65 2019-01-16 20:19:34.574790: step 2470, loss = 0.70466 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:19:35.463822 ops/training.py:65 2019-01-16 20:19:35.463748: step 2471, loss = 0.67175 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:19:36.352722 ops/training.py:65 2019-01-16 20:19:36.352654: step 2472, loss = 0.71108 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:19:37.240848 ops/training.py:65 2019-01-16 20:19:37.240780: step 2473, loss = 0.68529 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:19:38.133735 ops/training.py:65 2019-01-16 20:19:38.133664: step 2474, loss = 0.73527 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:19:39.025288 ops/training.py:65 2019-01-16 20:19:39.025188: step 2475, loss = 0.70336 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:19:39.916537 ops/training.py:65 2019-01-16 20:19:39.916473: step 2476, loss = 0.70318 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:19:40.808303 ops/training.py:65 2019-01-16 20:19:40.808226: step 2477, loss = 0.71785 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:19:41.699757 ops/training.py:65 2019-01-16 20:19:41.699653: step 2478, loss = 0.69848 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:19:42.590149 ops/training.py:65 2019-01-16 20:19:42.590067: step 2479, loss = 0.72629 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:19:43.483041 ops/training.py:65 2019-01-16 20:19:43.482944: step 2480, loss = 0.75210 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:19:44.373869 ops/training.py:65 2019-01-16 20:19:44.373762: step 2481, loss = 0.71751 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:19:45.264711 ops/training.py:65 2019-01-16 20:19:45.264645: step 2482, loss = 0.69875 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:19:46.153419 ops/training.py:65 2019-01-16 20:19:46.153355: step 2483, loss = 0.69568 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:19:47.042667 ops/training.py:65 2019-01-16 20:19:47.042601: step 2484, loss = 0.68550 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:19:47.931260 ops/training.py:65 2019-01-16 20:19:47.931196: step 2485, loss = 0.69510 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:19:48.820052 ops/training.py:65 2019-01-16 20:19:48.819988: step 2486, loss = 0.69820 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:19:49.709428 ops/training.py:65 2019-01-16 20:19:49.709364: step 2487, loss = 0.70063 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:19:50.598561 ops/training.py:65 2019-01-16 20:19:50.598498: step 2488, loss = 0.68907 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:19:51.487212 ops/training.py:65 2019-01-16 20:19:51.487144: step 2489, loss = 0.70483 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:19:52.376077 ops/training.py:65 2019-01-16 20:19:52.376013: step 2490, loss = 0.69631 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:19:53.264618 ops/training.py:65 2019-01-16 20:19:53.264551: step 2491, loss = 0.69771 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:19:54.153720 ops/training.py:65 2019-01-16 20:19:54.153657: step 2492, loss = 0.70763 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:19:55.044156 ops/training.py:65 2019-01-16 20:19:55.044087: step 2493, loss = 0.67338 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:19:55.935741 ops/training.py:65 2019-01-16 20:19:55.935635: step 2494, loss = 0.70022 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:19:56.826572 ops/training.py:65 2019-01-16 20:19:56.826480: step 2495, loss = 0.69906 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:19:57.715176 ops/training.py:65 2019-01-16 20:19:57.715112: step 2496, loss = 0.69298 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:19:58.604067 ops/training.py:65 2019-01-16 20:19:58.604000: step 2497, loss = 0.71906 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:19:59.493255 ops/training.py:65 2019-01-16 20:19:59.493187: step 2498, loss = 0.71581 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:20:00.384579 ops/training.py:65 2019-01-16 20:20:00.384500: step 2499, loss = 0.68146 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:20:01.275274 ops/training.py:65 2019-01-16 20:20:01.275167: step 2500, loss = 0.71178 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:20:02.167382 ops/training.py:65 2019-01-16 20:20:02.167300: step 2501, loss = 0.68888 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:20:03.057199 ops/training.py:65 2019-01-16 20:20:03.057130: step 2502, loss = 0.71190 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:20:03.946694 ops/training.py:65 2019-01-16 20:20:03.946622: step 2503, loss = 0.72421 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:20:04.835864 ops/training.py:65 2019-01-16 20:20:04.835799: step 2504, loss = 0.67365 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:20:05.724189 ops/training.py:65 2019-01-16 20:20:05.724122: step 2505, loss = 0.68747 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:20:06.612218 ops/training.py:65 2019-01-16 20:20:06.612152: step 2506, loss = 0.72509 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:20:07.502577 ops/training.py:65 2019-01-16 20:20:07.502505: step 2507, loss = 0.69880 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:20:08.392256 ops/training.py:65 2019-01-16 20:20:08.392191: step 2508, loss = 0.68091 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:20:09.281406 ops/training.py:65 2019-01-16 20:20:09.281338: step 2509, loss = 0.69107 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:20:10.169917 ops/training.py:65 2019-01-16 20:20:10.169838: step 2510, loss = 0.71049 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:20:11.059153 ops/training.py:65 2019-01-16 20:20:11.059054: step 2511, loss = 0.68009 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:20:11.948627 ops/training.py:65 2019-01-16 20:20:11.948559: step 2512, loss = 0.67570 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:20:12.837611 ops/training.py:65 2019-01-16 20:20:12.837538: step 2513, loss = 0.70136 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:20:13.733978 ops/training.py:65 2019-01-16 20:20:13.733906: step 2514, loss = 0.70564 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:20:14.624300 ops/training.py:65 2019-01-16 20:20:14.624197: step 2515, loss = 0.69205 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:20:15.513777 ops/training.py:65 2019-01-16 20:20:15.513701: step 2516, loss = 0.70529 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:20:16.402924 ops/training.py:65 2019-01-16 20:20:16.402856: step 2517, loss = 0.70895 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:20:17.291859 ops/training.py:65 2019-01-16 20:20:17.291790: step 2518, loss = 0.69410 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:20:18.181291 ops/training.py:65 2019-01-16 20:20:18.181224: step 2519, loss = 0.70548 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:20:19.069761 ops/training.py:65 2019-01-16 20:20:19.069695: step 2520, loss = 0.67467 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:20:19.958523 ops/training.py:65 2019-01-16 20:20:19.958457: step 2521, loss = 0.72072 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:20:20.847184 ops/training.py:65 2019-01-16 20:20:20.847114: step 2522, loss = 0.70935 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:20:21.735576 ops/training.py:65 2019-01-16 20:20:21.735504: step 2523, loss = 0.68933 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:20:22.624007 ops/training.py:65 2019-01-16 20:20:22.623939: step 2524, loss = 0.72300 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:20:23.515899 ops/training.py:65 2019-01-16 20:20:23.515823: step 2525, loss = 0.67039 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:20:24.406717 ops/training.py:65 2019-01-16 20:20:24.406615: step 2526, loss = 0.67373 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:20:25.298070 ops/training.py:65 2019-01-16 20:20:25.297974: step 2527, loss = 0.69574 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:20:26.189183 ops/training.py:65 2019-01-16 20:20:26.189098: step 2528, loss = 0.68226 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:20:27.077822 ops/training.py:65 2019-01-16 20:20:27.077743: step 2529, loss = 0.67964 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:20:27.967500 ops/training.py:65 2019-01-16 20:20:27.967422: step 2530, loss = 0.69380 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:20:28.857045 ops/training.py:65 2019-01-16 20:20:28.856975: step 2531, loss = 0.70042 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:20:29.745770 ops/training.py:65 2019-01-16 20:20:29.745698: step 2532, loss = 0.71585 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 20:20:30.635173 ops/training.py:65 2019-01-16 20:20:30.635100: step 2533, loss = 0.66742 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:20:31.524713 ops/training.py:65 2019-01-16 20:20:31.524636: step 2534, loss = 0.68376 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:20:32.413782 ops/training.py:65 2019-01-16 20:20:32.413685: step 2535, loss = 0.70273 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:20:33.305557 ops/training.py:65 2019-01-16 20:20:33.305469: step 2536, loss = 0.71384 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:20:34.197412 ops/training.py:65 2019-01-16 20:20:34.197305: step 2537, loss = 0.71807 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:20:35.087501 ops/training.py:65 2019-01-16 20:20:35.087399: step 2538, loss = 0.72029 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:20:35.977309 ops/training.py:65 2019-01-16 20:20:35.977201: step 2539, loss = 0.69981 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:20:36.866239 ops/training.py:65 2019-01-16 20:20:36.866150: step 2540, loss = 0.68292 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:20:37.756358 ops/training.py:65 2019-01-16 20:20:37.756280: step 2541, loss = 0.69440 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:20:38.647521 ops/training.py:65 2019-01-16 20:20:38.647437: step 2542, loss = 0.75861 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 20:20:39.540242 ops/training.py:65 2019-01-16 20:20:39.540132: step 2543, loss = 0.71358 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:20:40.432872 ops/training.py:65 2019-01-16 20:20:40.432772: step 2544, loss = 0.72360 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:20:41.324047 ops/training.py:65 2019-01-16 20:20:41.323974: step 2545, loss = 0.69196 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:20:42.213183 ops/training.py:65 2019-01-16 20:20:42.213109: step 2546, loss = 0.69984 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:20:43.102725 ops/training.py:65 2019-01-16 20:20:43.102662: step 2547, loss = 0.69809 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:20:43.991733 ops/training.py:65 2019-01-16 20:20:43.991671: step 2548, loss = 0.68643 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:20:44.880615 ops/training.py:65 2019-01-16 20:20:44.880555: step 2549, loss = 0.68478 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:20:45.769303 ops/training.py:65 2019-01-16 20:20:45.769238: step 2550, loss = 0.67843 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:20:46.658684 ops/training.py:65 2019-01-16 20:20:46.658619: step 2551, loss = 0.66620 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:20:47.547071 ops/training.py:65 2019-01-16 20:20:47.547013: step 2552, loss = 0.70953 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:20:48.435136 ops/training.py:65 2019-01-16 20:20:48.435067: step 2553, loss = 0.68688 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:20:49.323715 ops/training.py:65 2019-01-16 20:20:49.323660: step 2554, loss = 0.72083 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:20:50.212500 ops/training.py:65 2019-01-16 20:20:50.212439: step 2555, loss = 0.70933 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:20:51.101041 ops/training.py:65 2019-01-16 20:20:51.100979: step 2556, loss = 0.69065 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:20:51.990053 ops/training.py:65 2019-01-16 20:20:51.989989: step 2557, loss = 0.71678 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:20:52.878575 ops/training.py:65 2019-01-16 20:20:52.878511: step 2558, loss = 0.67860 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:20:53.766101 ops/training.py:65 2019-01-16 20:20:53.766028: step 2559, loss = 0.67302 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:20:54.654932 ops/training.py:65 2019-01-16 20:20:54.654867: step 2560, loss = 0.72230 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:20:55.543921 ops/training.py:65 2019-01-16 20:20:55.543858: step 2561, loss = 0.73470 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.25
I2992 2019-01-16 20:20:56.432029 ops/training.py:65 2019-01-16 20:20:56.431966: step 2562, loss = 0.67673 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:20:57.320390 ops/training.py:65 2019-01-16 20:20:57.320330: step 2563, loss = 0.71471 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:20:58.208540 ops/training.py:65 2019-01-16 20:20:58.208490: step 2564, loss = 0.65564 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:20:59.096584 ops/training.py:65 2019-01-16 20:20:59.096522: step 2565, loss = 0.70684 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:20:59.985594 ops/training.py:65 2019-01-16 20:20:59.985531: step 2566, loss = 0.71111 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 20:21:00.874278 ops/training.py:65 2019-01-16 20:21:00.874204: step 2567, loss = 0.70345 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:21:01.763930 ops/training.py:65 2019-01-16 20:21:01.763863: step 2568, loss = 0.68785 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:21:02.652392 ops/training.py:65 2019-01-16 20:21:02.652332: step 2569, loss = 0.68844 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:21:03.541476 ops/training.py:65 2019-01-16 20:21:03.541408: step 2570, loss = 0.67395 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:21:04.429554 ops/training.py:65 2019-01-16 20:21:04.429491: step 2571, loss = 0.73607 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:21:05.318503 ops/training.py:65 2019-01-16 20:21:05.318442: step 2572, loss = 0.70544 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:21:06.206963 ops/training.py:65 2019-01-16 20:21:06.206901: step 2573, loss = 0.68533 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:21:07.095780 ops/training.py:65 2019-01-16 20:21:07.095718: step 2574, loss = 0.68801 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:21:07.984635 ops/training.py:65 2019-01-16 20:21:07.984570: step 2575, loss = 0.72578 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:21:08.875718 ops/training.py:65 2019-01-16 20:21:08.875654: step 2576, loss = 0.69147 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:21:09.767023 ops/training.py:65 2019-01-16 20:21:09.766921: step 2577, loss = 0.70471 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:21:10.657771 ops/training.py:65 2019-01-16 20:21:10.657707: step 2578, loss = 0.69705 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:21:11.547004 ops/training.py:65 2019-01-16 20:21:11.546940: step 2579, loss = 0.66630 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:21:12.436527 ops/training.py:65 2019-01-16 20:21:12.436436: step 2580, loss = 0.71980 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:21:13.325877 ops/training.py:65 2019-01-16 20:21:13.325789: step 2581, loss = 0.72520 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:21:14.214938 ops/training.py:65 2019-01-16 20:21:14.214848: step 2582, loss = 0.70866 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:21:15.103573 ops/training.py:65 2019-01-16 20:21:15.103477: step 2583, loss = 0.66725 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:21:15.994219 ops/training.py:65 2019-01-16 20:21:15.994116: step 2584, loss = 0.66375 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:21:16.885305 ops/training.py:65 2019-01-16 20:21:16.885241: step 2585, loss = 0.67549 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:21:17.773750 ops/training.py:65 2019-01-16 20:21:17.773690: step 2586, loss = 0.71223 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:21:18.661920 ops/training.py:65 2019-01-16 20:21:18.661856: step 2587, loss = 0.69509 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:21:19.551203 ops/training.py:65 2019-01-16 20:21:19.551146: step 2588, loss = 0.74825 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:21:20.440255 ops/training.py:65 2019-01-16 20:21:20.440196: step 2589, loss = 0.70882 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:21:21.328849 ops/training.py:65 2019-01-16 20:21:21.328787: step 2590, loss = 0.65517 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:21:22.216945 ops/training.py:65 2019-01-16 20:21:22.216880: step 2591, loss = 0.72609 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:21:23.105448 ops/training.py:65 2019-01-16 20:21:23.105381: step 2592, loss = 0.65748 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 20:21:23.993920 ops/training.py:65 2019-01-16 20:21:23.993855: step 2593, loss = 0.70782 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:21:24.882333 ops/training.py:65 2019-01-16 20:21:24.882275: step 2594, loss = 0.68685 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:21:25.772373 ops/training.py:65 2019-01-16 20:21:25.772315: step 2595, loss = 0.70131 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:21:26.661464 ops/training.py:65 2019-01-16 20:21:26.661400: step 2596, loss = 0.70242 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:21:27.550749 ops/training.py:65 2019-01-16 20:21:27.550689: step 2597, loss = 0.71428 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:21:28.439686 ops/training.py:65 2019-01-16 20:21:28.439627: step 2598, loss = 0.69128 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:21:29.330367 ops/training.py:65 2019-01-16 20:21:29.330295: step 2599, loss = 0.69280 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:21:30.220154 ops/training.py:65 2019-01-16 20:21:30.220063: step 2600, loss = 0.72450 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:21:31.109071 ops/training.py:65 2019-01-16 20:21:31.108973: step 2601, loss = 0.69704 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:21:32.000362 ops/training.py:65 2019-01-16 20:21:32.000260: step 2602, loss = 0.67600 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:21:32.891576 ops/training.py:65 2019-01-16 20:21:32.891490: step 2603, loss = 0.68139 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:21:33.781016 ops/training.py:65 2019-01-16 20:21:33.780954: step 2604, loss = 0.70245 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:21:34.669577 ops/training.py:65 2019-01-16 20:21:34.669511: step 2605, loss = 0.66835 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:21:35.557986 ops/training.py:65 2019-01-16 20:21:35.557925: step 2606, loss = 0.68496 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:21:36.446410 ops/training.py:65 2019-01-16 20:21:36.446349: step 2607, loss = 0.68844 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:21:37.335830 ops/training.py:65 2019-01-16 20:21:37.335768: step 2608, loss = 0.68336 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:21:38.224658 ops/training.py:65 2019-01-16 20:21:38.224594: step 2609, loss = 0.67650 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:21:39.114220 ops/training.py:65 2019-01-16 20:21:39.114160: step 2610, loss = 0.68043 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:21:40.003158 ops/training.py:65 2019-01-16 20:21:40.003100: step 2611, loss = 0.67214 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:21:40.891489 ops/training.py:65 2019-01-16 20:21:40.891430: step 2612, loss = 0.69200 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:21:41.779916 ops/training.py:65 2019-01-16 20:21:41.779851: step 2613, loss = 0.70113 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:21:42.673405 ops/training.py:65 2019-01-16 20:21:42.673318: step 2614, loss = 0.69629 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:21:43.564451 ops/training.py:65 2019-01-16 20:21:43.564353: step 2615, loss = 0.66650 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:21:44.455714 ops/training.py:65 2019-01-16 20:21:44.455608: step 2616, loss = 0.68285 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:21:45.346516 ops/training.py:65 2019-01-16 20:21:45.346452: step 2617, loss = 0.70846 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:21:46.236146 ops/training.py:65 2019-01-16 20:21:46.236088: step 2618, loss = 0.64470 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:21:47.125124 ops/training.py:65 2019-01-16 20:21:47.125064: step 2619, loss = 0.71665 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:21:48.013420 ops/training.py:65 2019-01-16 20:21:48.013358: step 2620, loss = 0.69378 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:21:48.902836 ops/training.py:65 2019-01-16 20:21:48.902775: step 2621, loss = 0.73406 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:21:49.791074 ops/training.py:65 2019-01-16 20:21:49.791013: step 2622, loss = 0.70338 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:21:50.680179 ops/training.py:65 2019-01-16 20:21:50.680113: step 2623, loss = 0.70262 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:21:51.568237 ops/training.py:65 2019-01-16 20:21:51.568174: step 2624, loss = 0.68438 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:21:52.456999 ops/training.py:65 2019-01-16 20:21:52.456940: step 2625, loss = 0.71644 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:21:53.346020 ops/training.py:65 2019-01-16 20:21:53.345958: step 2626, loss = 0.70083 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:21:54.234679 ops/training.py:65 2019-01-16 20:21:54.234614: step 2627, loss = 0.72090 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:21:55.122749 ops/training.py:65 2019-01-16 20:21:55.122683: step 2628, loss = 0.67682 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:21:56.011373 ops/training.py:65 2019-01-16 20:21:56.011302: step 2629, loss = 0.70179 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:21:56.899908 ops/training.py:65 2019-01-16 20:21:56.899839: step 2630, loss = 0.67213 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:21:57.788610 ops/training.py:65 2019-01-16 20:21:57.788547: step 2631, loss = 0.68957 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:21:58.676983 ops/training.py:65 2019-01-16 20:21:58.676921: step 2632, loss = 0.65107 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:21:59.565893 ops/training.py:65 2019-01-16 20:21:59.565833: step 2633, loss = 0.67157 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:22:00.455071 ops/training.py:65 2019-01-16 20:22:00.455007: step 2634, loss = 0.73299 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:22:01.343187 ops/training.py:65 2019-01-16 20:22:01.343126: step 2635, loss = 0.73409 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:22:02.232104 ops/training.py:65 2019-01-16 20:22:02.232040: step 2636, loss = 0.68513 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:22:03.121238 ops/training.py:65 2019-01-16 20:22:03.121173: step 2637, loss = 0.67978 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:22:04.010571 ops/training.py:65 2019-01-16 20:22:04.010512: step 2638, loss = 0.71051 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:22:04.898564 ops/training.py:65 2019-01-16 20:22:04.898504: step 2639, loss = 0.73052 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:22:05.786750 ops/training.py:65 2019-01-16 20:22:05.786691: step 2640, loss = 0.70641 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:22:06.675092 ops/training.py:65 2019-01-16 20:22:06.675030: step 2641, loss = 0.67321 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:22:07.564780 ops/training.py:65 2019-01-16 20:22:07.564716: step 2642, loss = 0.69562 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:22:08.453826 ops/training.py:65 2019-01-16 20:22:08.453765: step 2643, loss = 0.71442 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:22:09.341689 ops/training.py:65 2019-01-16 20:22:09.341629: step 2644, loss = 0.73480 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:22:10.230696 ops/training.py:65 2019-01-16 20:22:10.230633: step 2645, loss = 0.69708 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:22:11.119184 ops/training.py:65 2019-01-16 20:22:11.119120: step 2646, loss = 0.68138 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:22:12.008781 ops/training.py:65 2019-01-16 20:22:12.008720: step 2647, loss = 0.70622 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:22:12.897402 ops/training.py:65 2019-01-16 20:22:12.897340: step 2648, loss = 0.70801 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:22:13.785629 ops/training.py:65 2019-01-16 20:22:13.785560: step 2649, loss = 0.67969 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:22:14.673826 ops/training.py:65 2019-01-16 20:22:14.673755: step 2650, loss = 0.69697 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:22:15.562981 ops/training.py:65 2019-01-16 20:22:15.562918: step 2651, loss = 0.70157 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:22:16.451508 ops/training.py:65 2019-01-16 20:22:16.451442: step 2652, loss = 0.67914 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 20:22:17.339598 ops/training.py:65 2019-01-16 20:22:17.339529: step 2653, loss = 0.69736 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:22:18.228252 ops/training.py:65 2019-01-16 20:22:18.228187: step 2654, loss = 0.67712 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:22:19.116514 ops/training.py:65 2019-01-16 20:22:19.116451: step 2655, loss = 0.68920 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:22:20.005626 ops/training.py:65 2019-01-16 20:22:20.005558: step 2656, loss = 0.72073 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:22:20.893979 ops/training.py:65 2019-01-16 20:22:20.893910: step 2657, loss = 0.69398 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:22:21.781903 ops/training.py:65 2019-01-16 20:22:21.781836: step 2658, loss = 0.69316 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:22:22.669544 ops/training.py:65 2019-01-16 20:22:22.669476: step 2659, loss = 0.71917 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:22:23.557961 ops/training.py:65 2019-01-16 20:22:23.557885: step 2660, loss = 0.72027 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:22:24.446371 ops/training.py:65 2019-01-16 20:22:24.446302: step 2661, loss = 0.68305 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:22:25.335040 ops/training.py:65 2019-01-16 20:22:25.334966: step 2662, loss = 0.69529 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:22:26.228756 ops/training.py:65 2019-01-16 20:22:26.228705: step 2663, loss = 0.70722 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:22:27.119414 ops/training.py:65 2019-01-16 20:22:27.119327: step 2664, loss = 0.66876 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:22:28.011211 ops/training.py:65 2019-01-16 20:22:28.011109: step 2665, loss = 0.69334 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:22:28.903458 ops/training.py:65 2019-01-16 20:22:28.903349: step 2666, loss = 0.72793 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:22:29.794029 ops/training.py:65 2019-01-16 20:22:29.793961: step 2667, loss = 0.72434 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:22:30.682965 ops/training.py:65 2019-01-16 20:22:30.682895: step 2668, loss = 0.71427 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:22:31.573719 ops/training.py:65 2019-01-16 20:22:31.573649: step 2669, loss = 0.70514 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:22:32.465437 ops/training.py:65 2019-01-16 20:22:32.465330: step 2670, loss = 0.70143 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:22:33.359026 ops/training.py:65 2019-01-16 20:22:33.358939: step 2671, loss = 0.71690 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:22:34.248098 ops/training.py:65 2019-01-16 20:22:34.248025: step 2672, loss = 0.66831 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:22:35.135866 ops/training.py:65 2019-01-16 20:22:35.135800: step 2673, loss = 0.72860 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:22:36.024931 ops/training.py:65 2019-01-16 20:22:36.024853: step 2674, loss = 0.73394 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:22:36.913456 ops/training.py:65 2019-01-16 20:22:36.913382: step 2675, loss = 0.67899 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:22:37.802797 ops/training.py:65 2019-01-16 20:22:37.802728: step 2676, loss = 0.68693 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:22:38.691345 ops/training.py:65 2019-01-16 20:22:38.691276: step 2677, loss = 0.66951 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:22:39.579572 ops/training.py:65 2019-01-16 20:22:39.579501: step 2678, loss = 0.71601 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:22:40.468243 ops/training.py:65 2019-01-16 20:22:40.468170: step 2679, loss = 0.73183 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:22:41.357147 ops/training.py:65 2019-01-16 20:22:41.357085: step 2680, loss = 0.70179 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:22:42.245706 ops/training.py:65 2019-01-16 20:22:42.245635: step 2681, loss = 0.70509 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:22:43.134826 ops/training.py:65 2019-01-16 20:22:43.134753: step 2682, loss = 0.69090 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:22:44.022911 ops/training.py:65 2019-01-16 20:22:44.022836: step 2683, loss = 0.68342 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:22:44.912553 ops/training.py:65 2019-01-16 20:22:44.912481: step 2684, loss = 0.67845 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:22:45.801199 ops/training.py:65 2019-01-16 20:22:45.801131: step 2685, loss = 0.69754 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:22:46.689272 ops/training.py:65 2019-01-16 20:22:46.689211: step 2686, loss = 0.72093 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:22:47.578087 ops/training.py:65 2019-01-16 20:22:47.578021: step 2687, loss = 0.70564 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:22:48.466339 ops/training.py:65 2019-01-16 20:22:48.466278: step 2688, loss = 0.71678 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:22:49.355548 ops/training.py:65 2019-01-16 20:22:49.355486: step 2689, loss = 0.70511 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:22:50.243748 ops/training.py:65 2019-01-16 20:22:50.243680: step 2690, loss = 0.69722 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:22:51.132056 ops/training.py:65 2019-01-16 20:22:51.131988: step 2691, loss = 0.70930 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:22:52.020408 ops/training.py:65 2019-01-16 20:22:52.020343: step 2692, loss = 0.71999 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:22:52.909014 ops/training.py:65 2019-01-16 20:22:52.908949: step 2693, loss = 0.68656 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:22:53.799851 ops/training.py:65 2019-01-16 20:22:53.799769: step 2694, loss = 0.71006 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:22:54.692322 ops/training.py:65 2019-01-16 20:22:54.692219: step 2695, loss = 0.70978 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:22:55.583311 ops/training.py:65 2019-01-16 20:22:55.583239: step 2696, loss = 0.67280 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:22:56.471652 ops/training.py:65 2019-01-16 20:22:56.471586: step 2697, loss = 0.69895 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:22:57.364677 ops/training.py:65 2019-01-16 20:22:57.364605: step 2698, loss = 0.68840 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:22:58.255560 ops/training.py:65 2019-01-16 20:22:58.255449: step 2699, loss = 0.70025 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:22:59.146705 ops/training.py:65 2019-01-16 20:22:59.146635: step 2700, loss = 0.71181 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:23:00.035660 ops/training.py:65 2019-01-16 20:23:00.035595: step 2701, loss = 0.72859 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:23:00.925084 ops/training.py:65 2019-01-16 20:23:00.925022: step 2702, loss = 0.66371 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:23:01.812922 ops/training.py:65 2019-01-16 20:23:01.812857: step 2703, loss = 0.70011 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:23:02.701548 ops/training.py:65 2019-01-16 20:23:02.701486: step 2704, loss = 0.69018 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:23:03.590056 ops/training.py:65 2019-01-16 20:23:03.589991: step 2705, loss = 0.69616 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:23:04.478971 ops/training.py:65 2019-01-16 20:23:04.478913: step 2706, loss = 0.67418 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:23:05.367332 ops/training.py:65 2019-01-16 20:23:05.367267: step 2707, loss = 0.69381 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:23:06.255525 ops/training.py:65 2019-01-16 20:23:06.255458: step 2708, loss = 0.71158 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:23:07.143493 ops/training.py:65 2019-01-16 20:23:07.143420: step 2709, loss = 0.68751 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:23:08.031849 ops/training.py:65 2019-01-16 20:23:08.031777: step 2710, loss = 0.70821 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:23:08.920367 ops/training.py:65 2019-01-16 20:23:08.920303: step 2711, loss = 0.71630 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:23:09.808618 ops/training.py:65 2019-01-16 20:23:09.808556: step 2712, loss = 0.68896 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:23:10.696771 ops/training.py:65 2019-01-16 20:23:10.696714: step 2713, loss = 0.66742 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:23:11.585177 ops/training.py:65 2019-01-16 20:23:11.585118: step 2714, loss = 0.68177 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:23:12.472753 ops/training.py:65 2019-01-16 20:23:12.472696: step 2715, loss = 0.71336 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:23:13.360598 ops/training.py:65 2019-01-16 20:23:13.360536: step 2716, loss = 0.72051 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:23:14.249017 ops/training.py:65 2019-01-16 20:23:14.248948: step 2717, loss = 0.73085 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:23:15.141634 ops/training.py:65 2019-01-16 20:23:15.141566: step 2718, loss = 0.73926 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:23:16.032350 ops/training.py:65 2019-01-16 20:23:16.032243: step 2719, loss = 0.69570 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:23:16.922515 ops/training.py:65 2019-01-16 20:23:16.922449: step 2720, loss = 0.73302 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:23:17.810911 ops/training.py:65 2019-01-16 20:23:17.810846: step 2721, loss = 0.67987 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:23:18.699503 ops/training.py:65 2019-01-16 20:23:18.699434: step 2722, loss = 0.69427 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:23:19.588763 ops/training.py:65 2019-01-16 20:23:19.588692: step 2723, loss = 0.69648 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:23:20.482459 ops/training.py:65 2019-01-16 20:23:20.482395: step 2724, loss = 0.68184 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:23:21.374545 ops/training.py:65 2019-01-16 20:23:21.374434: step 2725, loss = 0.66824 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:23:22.264530 ops/training.py:65 2019-01-16 20:23:22.264468: step 2726, loss = 0.70684 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:23:23.152353 ops/training.py:65 2019-01-16 20:23:23.152281: step 2727, loss = 0.73713 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:23:24.040884 ops/training.py:65 2019-01-16 20:23:24.040826: step 2728, loss = 0.67643 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:23:24.928562 ops/training.py:65 2019-01-16 20:23:24.928508: step 2729, loss = 0.65264 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:23:25.816860 ops/training.py:65 2019-01-16 20:23:25.816806: step 2730, loss = 0.68958 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:23:26.704764 ops/training.py:65 2019-01-16 20:23:26.704712: step 2731, loss = 0.70324 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:23:27.592449 ops/training.py:65 2019-01-16 20:23:27.592388: step 2732, loss = 0.74273 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:23:28.480877 ops/training.py:65 2019-01-16 20:23:28.480820: step 2733, loss = 0.69012 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:23:29.369005 ops/training.py:65 2019-01-16 20:23:29.368944: step 2734, loss = 0.71142 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:23:30.256915 ops/training.py:65 2019-01-16 20:23:30.256857: step 2735, loss = 0.70163 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:23:31.145924 ops/training.py:65 2019-01-16 20:23:31.145863: step 2736, loss = 0.70838 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:23:32.034772 ops/training.py:65 2019-01-16 20:23:32.034707: step 2737, loss = 0.67145 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:23:32.922873 ops/training.py:65 2019-01-16 20:23:32.922808: step 2738, loss = 0.70444 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:23:33.816819 ops/training.py:65 2019-01-16 20:23:33.816752: step 2739, loss = 0.70080 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:23:34.708884 ops/training.py:65 2019-01-16 20:23:34.708782: step 2740, loss = 0.69823 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:23:35.600273 ops/training.py:65 2019-01-16 20:23:35.600160: step 2741, loss = 0.67248 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:23:36.492577 ops/training.py:65 2019-01-16 20:23:36.492514: step 2742, loss = 0.71438 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:23:37.383533 ops/training.py:65 2019-01-16 20:23:37.383432: step 2743, loss = 0.68550 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:23:38.275367 ops/training.py:65 2019-01-16 20:23:38.275262: step 2744, loss = 0.70050 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:23:39.164432 ops/training.py:65 2019-01-16 20:23:39.164366: step 2745, loss = 0.71888 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:23:40.052447 ops/training.py:65 2019-01-16 20:23:40.052376: step 2746, loss = 0.69804 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:23:40.940635 ops/training.py:65 2019-01-16 20:23:40.940564: step 2747, loss = 0.70432 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:23:41.828707 ops/training.py:65 2019-01-16 20:23:41.828644: step 2748, loss = 0.71251 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:23:42.718151 ops/training.py:65 2019-01-16 20:23:42.718081: step 2749, loss = 0.69054 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:23:43.606423 ops/training.py:65 2019-01-16 20:23:43.606353: step 2750, loss = 0.74338 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:23:44.501151 ops/training.py:65 2019-01-16 20:23:44.501075: step 2751, loss = 0.74647 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:23:45.392551 ops/training.py:65 2019-01-16 20:23:45.392447: step 2752, loss = 0.69511 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:23:46.283974 ops/training.py:65 2019-01-16 20:23:46.283876: step 2753, loss = 0.68831 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:23:47.175706 ops/training.py:65 2019-01-16 20:23:47.175597: step 2754, loss = 0.65223 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:23:48.066223 ops/training.py:65 2019-01-16 20:23:48.066154: step 2755, loss = 0.63516 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:23:48.957444 ops/training.py:65 2019-01-16 20:23:48.957336: step 2756, loss = 0.64679 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 20:23:49.847570 ops/training.py:65 2019-01-16 20:23:49.847504: step 2757, loss = 0.69876 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:23:50.736271 ops/training.py:65 2019-01-16 20:23:50.736189: step 2758, loss = 0.69243 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:23:51.624665 ops/training.py:65 2019-01-16 20:23:51.624586: step 2759, loss = 0.69714 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:23:52.512895 ops/training.py:65 2019-01-16 20:23:52.512825: step 2760, loss = 0.69804 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:23:53.401428 ops/training.py:65 2019-01-16 20:23:53.401356: step 2761, loss = 0.71616 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:23:54.289410 ops/training.py:65 2019-01-16 20:23:54.289347: step 2762, loss = 0.70059 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:23:55.177913 ops/training.py:65 2019-01-16 20:23:55.177851: step 2763, loss = 0.74391 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:23:56.065204 ops/training.py:65 2019-01-16 20:23:56.065138: step 2764, loss = 0.71375 (36.1 examples/sec; 0.886 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:23:56.952990 ops/training.py:65 2019-01-16 20:23:56.952925: step 2765, loss = 0.65494 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:23:57.843000 ops/training.py:65 2019-01-16 20:23:57.842943: step 2766, loss = 0.69817 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:23:58.734381 ops/training.py:65 2019-01-16 20:23:58.734303: step 2767, loss = 0.71576 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:23:59.626137 ops/training.py:65 2019-01-16 20:23:59.626026: step 2768, loss = 0.70415 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:24:00.516413 ops/training.py:65 2019-01-16 20:24:00.516307: step 2769, loss = 0.69138 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:24:01.406340 ops/training.py:65 2019-01-16 20:24:01.406276: step 2770, loss = 0.68425 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:24:02.295165 ops/training.py:65 2019-01-16 20:24:02.295098: step 2771, loss = 0.68487 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:24:03.184371 ops/training.py:65 2019-01-16 20:24:03.184306: step 2772, loss = 0.70279 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:24:04.073445 ops/training.py:65 2019-01-16 20:24:04.073390: step 2773, loss = 0.69616 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:24:04.962314 ops/training.py:65 2019-01-16 20:24:04.962247: step 2774, loss = 0.69735 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:24:05.850474 ops/training.py:65 2019-01-16 20:24:05.850409: step 2775, loss = 0.70498 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:24:06.738255 ops/training.py:65 2019-01-16 20:24:06.738193: step 2776, loss = 0.70067 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:24:07.626376 ops/training.py:65 2019-01-16 20:24:07.626308: step 2777, loss = 0.69572 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:24:08.515113 ops/training.py:65 2019-01-16 20:24:08.515038: step 2778, loss = 0.69040 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:24:09.404172 ops/training.py:65 2019-01-16 20:24:09.404104: step 2779, loss = 0.69801 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:24:10.292665 ops/training.py:65 2019-01-16 20:24:10.292595: step 2780, loss = 0.68537 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:24:11.185956 ops/training.py:65 2019-01-16 20:24:11.185878: step 2781, loss = 0.68382 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:24:12.081343 ops/training.py:65 2019-01-16 20:24:12.081241: step 2782, loss = 0.67959 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:24:12.974297 ops/training.py:65 2019-01-16 20:24:12.974188: step 2783, loss = 0.69680 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:24:13.866258 ops/training.py:65 2019-01-16 20:24:13.866171: step 2784, loss = 0.68551 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:24:14.760394 ops/training.py:65 2019-01-16 20:24:14.760304: step 2785, loss = 0.71699 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:24:15.652337 ops/training.py:65 2019-01-16 20:24:15.652200: step 2786, loss = 0.72716 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:24:16.543508 ops/training.py:65 2019-01-16 20:24:16.543442: step 2787, loss = 0.66835 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:24:17.431959 ops/training.py:65 2019-01-16 20:24:17.431895: step 2788, loss = 0.72925 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:24:18.320263 ops/training.py:65 2019-01-16 20:24:18.320204: step 2789, loss = 0.67691 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:24:19.213216 ops/training.py:65 2019-01-16 20:24:19.213155: step 2790, loss = 0.68172 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:24:20.103850 ops/training.py:65 2019-01-16 20:24:20.103702: step 2791, loss = 0.69048 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:24:20.994378 ops/training.py:65 2019-01-16 20:24:20.994245: step 2792, loss = 0.69543 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:24:21.886951 ops/training.py:65 2019-01-16 20:24:21.886805: step 2793, loss = 0.69121 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:24:22.777273 ops/training.py:65 2019-01-16 20:24:22.777201: step 2794, loss = 0.69269 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:24:23.666651 ops/training.py:65 2019-01-16 20:24:23.666581: step 2795, loss = 0.70139 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:24:24.556429 ops/training.py:65 2019-01-16 20:24:24.556369: step 2796, loss = 0.67303 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:24:25.446586 ops/training.py:65 2019-01-16 20:24:25.446482: step 2797, loss = 0.71192 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:24:26.338298 ops/training.py:65 2019-01-16 20:24:26.338192: step 2798, loss = 0.66357 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:24:27.228605 ops/training.py:65 2019-01-16 20:24:27.228543: step 2799, loss = 0.67203 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:24:28.117015 ops/training.py:65 2019-01-16 20:24:28.116956: step 2800, loss = 0.71008 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:24:29.005215 ops/training.py:65 2019-01-16 20:24:29.005151: step 2801, loss = 0.71292 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:24:29.896733 ops/training.py:65 2019-01-16 20:24:29.896685: step 2802, loss = 0.69198 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:24:30.789580 ops/training.py:65 2019-01-16 20:24:30.789479: step 2803, loss = 0.70202 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:24:31.681958 ops/training.py:65 2019-01-16 20:24:31.681847: step 2804, loss = 0.66522 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:24:32.572516 ops/training.py:65 2019-01-16 20:24:32.572433: step 2805, loss = 0.68922 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:24:33.462342 ops/training.py:65 2019-01-16 20:24:33.462279: step 2806, loss = 0.72837 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:24:34.353983 ops/training.py:65 2019-01-16 20:24:34.353908: step 2807, loss = 0.68121 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:24:35.245097 ops/training.py:65 2019-01-16 20:24:35.245034: step 2808, loss = 0.70107 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:24:36.137225 ops/training.py:65 2019-01-16 20:24:36.137122: step 2809, loss = 0.67226 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:24:37.028009 ops/training.py:65 2019-01-16 20:24:37.027906: step 2810, loss = 0.69376 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:24:37.918989 ops/training.py:65 2019-01-16 20:24:37.918924: step 2811, loss = 0.72523 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:24:38.807457 ops/training.py:65 2019-01-16 20:24:38.807393: step 2812, loss = 0.72247 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:24:39.696400 ops/training.py:65 2019-01-16 20:24:39.696338: step 2813, loss = 0.71055 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:24:40.586230 ops/training.py:65 2019-01-16 20:24:40.586174: step 2814, loss = 0.69054 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:24:41.474304 ops/training.py:65 2019-01-16 20:24:41.474242: step 2815, loss = 0.70403 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:24:42.362022 ops/training.py:65 2019-01-16 20:24:42.361969: step 2816, loss = 0.69485 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:24:43.250734 ops/training.py:65 2019-01-16 20:24:43.250666: step 2817, loss = 0.69614 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:24:44.139393 ops/training.py:65 2019-01-16 20:24:44.139331: step 2818, loss = 0.71076 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:24:45.028699 ops/training.py:65 2019-01-16 20:24:45.028640: step 2819, loss = 0.69424 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:24:45.917413 ops/training.py:65 2019-01-16 20:24:45.917348: step 2820, loss = 0.70169 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:24:46.808532 ops/training.py:65 2019-01-16 20:24:46.808456: step 2821, loss = 0.68077 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:24:47.701315 ops/training.py:65 2019-01-16 20:24:47.701208: step 2822, loss = 0.70451 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:24:48.592854 ops/training.py:65 2019-01-16 20:24:48.592789: step 2823, loss = 0.68382 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:24:49.481717 ops/training.py:65 2019-01-16 20:24:49.481654: step 2824, loss = 0.71245 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:24:50.369859 ops/training.py:65 2019-01-16 20:24:50.369792: step 2825, loss = 0.68970 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:24:51.258388 ops/training.py:65 2019-01-16 20:24:51.258325: step 2826, loss = 0.70814 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:24:52.148836 ops/training.py:65 2019-01-16 20:24:52.148769: step 2827, loss = 0.72477 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:24:53.040124 ops/training.py:65 2019-01-16 20:24:53.040020: step 2828, loss = 0.71001 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:24:53.930781 ops/training.py:65 2019-01-16 20:24:53.930712: step 2829, loss = 0.67625 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:24:54.819653 ops/training.py:65 2019-01-16 20:24:54.819573: step 2830, loss = 0.67782 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:24:55.708071 ops/training.py:65 2019-01-16 20:24:55.708005: step 2831, loss = 0.67589 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:24:56.596294 ops/training.py:65 2019-01-16 20:24:56.596229: step 2832, loss = 0.67896 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:24:57.484940 ops/training.py:65 2019-01-16 20:24:57.484874: step 2833, loss = 0.68047 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:24:58.374352 ops/training.py:65 2019-01-16 20:24:58.374291: step 2834, loss = 0.69421 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:24:59.262862 ops/training.py:65 2019-01-16 20:24:59.262797: step 2835, loss = 0.67103 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:25:00.151052 ops/training.py:65 2019-01-16 20:25:00.150987: step 2836, loss = 0.68948 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:25:01.039921 ops/training.py:65 2019-01-16 20:25:01.039851: step 2837, loss = 0.70572 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:25:01.928232 ops/training.py:65 2019-01-16 20:25:01.928164: step 2838, loss = 0.69354 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:25:02.816841 ops/training.py:65 2019-01-16 20:25:02.816775: step 2839, loss = 0.70274 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:25:03.705890 ops/training.py:65 2019-01-16 20:25:03.705821: step 2840, loss = 0.68921 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:25:04.594568 ops/training.py:65 2019-01-16 20:25:04.594500: step 2841, loss = 0.71778 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:25:05.482823 ops/training.py:65 2019-01-16 20:25:05.482758: step 2842, loss = 0.70516 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:25:06.371482 ops/training.py:65 2019-01-16 20:25:06.371416: step 2843, loss = 0.66514 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.75
I2992 2019-01-16 20:25:07.260704 ops/training.py:65 2019-01-16 20:25:07.260635: step 2844, loss = 0.69807 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:25:08.149930 ops/training.py:65 2019-01-16 20:25:08.149853: step 2845, loss = 0.70765 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:25:09.038874 ops/training.py:65 2019-01-16 20:25:09.038808: step 2846, loss = 0.70305 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:25:09.927340 ops/training.py:65 2019-01-16 20:25:09.927274: step 2847, loss = 0.69196 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:25:10.815874 ops/training.py:65 2019-01-16 20:25:10.815810: step 2848, loss = 0.71230 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:25:11.708352 ops/training.py:65 2019-01-16 20:25:11.708277: step 2849, loss = 0.69818 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:25:12.600681 ops/training.py:65 2019-01-16 20:25:12.600576: step 2850, loss = 0.71126 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:25:13.493055 ops/training.py:65 2019-01-16 20:25:13.492957: step 2851, loss = 0.69728 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:25:14.384018 ops/training.py:65 2019-01-16 20:25:14.383945: step 2852, loss = 0.68063 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:25:15.273578 ops/training.py:65 2019-01-16 20:25:15.273511: step 2853, loss = 0.69164 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:25:16.162571 ops/training.py:65 2019-01-16 20:25:16.162503: step 2854, loss = 0.69615 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:25:17.051908 ops/training.py:65 2019-01-16 20:25:17.051833: step 2855, loss = 0.68576 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:25:17.943436 ops/training.py:65 2019-01-16 20:25:17.943336: step 2856, loss = 0.69015 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:25:18.835285 ops/training.py:65 2019-01-16 20:25:18.835178: step 2857, loss = 0.71184 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:25:19.725597 ops/training.py:65 2019-01-16 20:25:19.725518: step 2858, loss = 0.71306 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:25:20.613758 ops/training.py:65 2019-01-16 20:25:20.613679: step 2859, loss = 0.68604 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:25:21.502913 ops/training.py:65 2019-01-16 20:25:21.502844: step 2860, loss = 0.69153 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:25:22.393397 ops/training.py:65 2019-01-16 20:25:22.393328: step 2861, loss = 0.69009 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:25:23.283096 ops/training.py:65 2019-01-16 20:25:23.283030: step 2862, loss = 0.71131 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:25:24.171835 ops/training.py:65 2019-01-16 20:25:24.171769: step 2863, loss = 0.69167 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:25:25.060350 ops/training.py:65 2019-01-16 20:25:25.060288: step 2864, loss = 0.67793 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:25:25.949439 ops/training.py:65 2019-01-16 20:25:25.949374: step 2865, loss = 0.73167 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:25:26.838007 ops/training.py:65 2019-01-16 20:25:26.837944: step 2866, loss = 0.68509 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:25:27.726296 ops/training.py:65 2019-01-16 20:25:27.726223: step 2867, loss = 0.70554 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:25:28.615263 ops/training.py:65 2019-01-16 20:25:28.615194: step 2868, loss = 0.70064 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:25:29.504011 ops/training.py:65 2019-01-16 20:25:29.503944: step 2869, loss = 0.72336 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:25:30.392079 ops/training.py:65 2019-01-16 20:25:30.392016: step 2870, loss = 0.72129 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:25:31.280418 ops/training.py:65 2019-01-16 20:25:31.280350: step 2871, loss = 0.70377 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:25:32.168340 ops/training.py:65 2019-01-16 20:25:32.168273: step 2872, loss = 0.68804 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:25:33.056848 ops/training.py:65 2019-01-16 20:25:33.056785: step 2873, loss = 0.67222 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:25:33.945278 ops/training.py:65 2019-01-16 20:25:33.945210: step 2874, loss = 0.66600 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:25:34.833604 ops/training.py:65 2019-01-16 20:25:34.833534: step 2875, loss = 0.70876 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:25:35.722830 ops/training.py:65 2019-01-16 20:25:35.722765: step 2876, loss = 0.66963 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:25:36.611176 ops/training.py:65 2019-01-16 20:25:36.611109: step 2877, loss = 0.70207 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:25:37.499554 ops/training.py:65 2019-01-16 20:25:37.499492: step 2878, loss = 0.69745 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:25:38.389003 ops/training.py:65 2019-01-16 20:25:38.388938: step 2879, loss = 0.69556 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:25:39.276731 ops/training.py:65 2019-01-16 20:25:39.276662: step 2880, loss = 0.67216 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:25:40.166033 ops/training.py:65 2019-01-16 20:25:40.165967: step 2881, loss = 0.75102 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:25:41.054629 ops/training.py:65 2019-01-16 20:25:41.054560: step 2882, loss = 0.69903 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:25:41.943404 ops/training.py:65 2019-01-16 20:25:41.943338: step 2883, loss = 0.71764 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:25:42.831776 ops/training.py:65 2019-01-16 20:25:42.831711: step 2884, loss = 0.72540 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:25:43.720136 ops/training.py:65 2019-01-16 20:25:43.720067: step 2885, loss = 0.69832 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:25:44.608683 ops/training.py:65 2019-01-16 20:25:44.608613: step 2886, loss = 0.68731 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:25:45.496335 ops/training.py:65 2019-01-16 20:25:45.496258: step 2887, loss = 0.69583 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:25:46.384191 ops/training.py:65 2019-01-16 20:25:46.384119: step 2888, loss = 0.67072 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.75
I2992 2019-01-16 20:25:47.272862 ops/training.py:65 2019-01-16 20:25:47.272797: step 2889, loss = 0.69586 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:25:48.162316 ops/training.py:65 2019-01-16 20:25:48.162253: step 2890, loss = 0.68504 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:25:49.051307 ops/training.py:65 2019-01-16 20:25:49.051246: step 2891, loss = 0.70603 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:25:49.944952 ops/training.py:65 2019-01-16 20:25:49.944886: step 2892, loss = 0.67831 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:25:50.836687 ops/training.py:65 2019-01-16 20:25:50.836578: step 2893, loss = 0.72635 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:25:51.727131 ops/training.py:65 2019-01-16 20:25:51.727029: step 2894, loss = 0.70227 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:25:52.617764 ops/training.py:65 2019-01-16 20:25:52.617704: step 2895, loss = 0.68670 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:25:53.506598 ops/training.py:65 2019-01-16 20:25:53.506535: step 2896, loss = 0.71587 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:25:54.394440 ops/training.py:65 2019-01-16 20:25:54.394380: step 2897, loss = 0.68681 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:25:55.281818 ops/training.py:65 2019-01-16 20:25:55.281765: step 2898, loss = 0.65842 (36.1 examples/sec; 0.886 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:25:56.169219 ops/training.py:65 2019-01-16 20:25:56.169156: step 2899, loss = 0.71606 (36.1 examples/sec; 0.886 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:25:57.058153 ops/training.py:65 2019-01-16 20:25:57.058090: step 2900, loss = 0.70835 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:25:57.946979 ops/training.py:65 2019-01-16 20:25:57.946913: step 2901, loss = 0.66172 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:25:58.835342 ops/training.py:65 2019-01-16 20:25:58.835276: step 2902, loss = 0.67128 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:25:59.723468 ops/training.py:65 2019-01-16 20:25:59.723406: step 2903, loss = 0.66659 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:26:00.611193 ops/training.py:65 2019-01-16 20:26:00.611132: step 2904, loss = 0.72521 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:26:01.500146 ops/training.py:65 2019-01-16 20:26:01.500082: step 2905, loss = 0.65486 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:26:02.388252 ops/training.py:65 2019-01-16 20:26:02.388190: step 2906, loss = 0.72322 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:26:03.276979 ops/training.py:65 2019-01-16 20:26:03.276904: step 2907, loss = 0.66158 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:26:04.165677 ops/training.py:65 2019-01-16 20:26:04.165612: step 2908, loss = 0.67065 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:26:05.056458 ops/training.py:65 2019-01-16 20:26:05.056389: step 2909, loss = 0.66186 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 20:26:05.945671 ops/training.py:65 2019-01-16 20:26:05.945605: step 2910, loss = 0.70730 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:26:06.833635 ops/training.py:65 2019-01-16 20:26:06.833550: step 2911, loss = 0.64663 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 20:26:07.722680 ops/training.py:65 2019-01-16 20:26:07.722616: step 2912, loss = 0.70659 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:26:08.611962 ops/training.py:65 2019-01-16 20:26:08.611891: step 2913, loss = 0.69805 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:26:09.500398 ops/training.py:65 2019-01-16 20:26:09.500331: step 2914, loss = 0.68541 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:26:10.388472 ops/training.py:65 2019-01-16 20:26:10.388410: step 2915, loss = 0.65072 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:26:11.276898 ops/training.py:65 2019-01-16 20:26:11.276838: step 2916, loss = 0.70087 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:26:12.165711 ops/training.py:65 2019-01-16 20:26:12.165644: step 2917, loss = 0.73466 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:26:13.055021 ops/training.py:65 2019-01-16 20:26:13.054951: step 2918, loss = 0.74578 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:26:13.948298 ops/training.py:65 2019-01-16 20:26:13.948221: step 2919, loss = 0.73494 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:26:14.839723 ops/training.py:65 2019-01-16 20:26:14.839619: step 2920, loss = 0.77173 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:26:15.730450 ops/training.py:65 2019-01-16 20:26:15.730357: step 2921, loss = 0.77848 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:26:16.620204 ops/training.py:65 2019-01-16 20:26:16.620144: step 2922, loss = 0.70227 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:26:17.509908 ops/training.py:65 2019-01-16 20:26:17.509850: step 2923, loss = 0.69442 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:26:18.398357 ops/training.py:65 2019-01-16 20:26:18.398299: step 2924, loss = 0.70284 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:26:19.287908 ops/training.py:65 2019-01-16 20:26:19.287851: step 2925, loss = 0.69575 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:26:20.175766 ops/training.py:65 2019-01-16 20:26:20.175712: step 2926, loss = 0.72510 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:26:21.063955 ops/training.py:65 2019-01-16 20:26:21.063904: step 2927, loss = 0.73064 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:26:21.952409 ops/training.py:65 2019-01-16 20:26:21.952348: step 2928, loss = 0.68299 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:26:22.844284 ops/training.py:65 2019-01-16 20:26:22.844214: step 2929, loss = 0.63785 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 20:26:23.735838 ops/training.py:65 2019-01-16 20:26:23.735736: step 2930, loss = 0.69720 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:26:24.629700 ops/training.py:65 2019-01-16 20:26:24.629631: step 2931, loss = 0.67485 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:26:25.522022 ops/training.py:65 2019-01-16 20:26:25.521921: step 2932, loss = 0.68966 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:26:26.414249 ops/training.py:65 2019-01-16 20:26:26.414144: step 2933, loss = 0.74665 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:26:27.304710 ops/training.py:65 2019-01-16 20:26:27.304614: step 2934, loss = 0.71265 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:26:28.194144 ops/training.py:65 2019-01-16 20:26:28.194072: step 2935, loss = 0.70590 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:26:29.082876 ops/training.py:65 2019-01-16 20:26:29.082809: step 2936, loss = 0.70531 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:26:29.971572 ops/training.py:65 2019-01-16 20:26:29.971511: step 2937, loss = 0.71383 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:26:30.862823 ops/training.py:65 2019-01-16 20:26:30.862747: step 2938, loss = 0.70267 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:26:31.754089 ops/training.py:65 2019-01-16 20:26:31.753979: step 2939, loss = 0.67555 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:26:32.645280 ops/training.py:65 2019-01-16 20:26:32.645194: step 2940, loss = 0.71871 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:26:33.538596 ops/training.py:65 2019-01-16 20:26:33.538539: step 2941, loss = 0.69312 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:26:34.429070 ops/training.py:65 2019-01-16 20:26:34.429008: step 2942, loss = 0.67421 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:26:35.321550 ops/training.py:65 2019-01-16 20:26:35.321476: step 2943, loss = 0.71169 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:26:36.212341 ops/training.py:65 2019-01-16 20:26:36.212236: step 2944, loss = 0.69135 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:26:37.102714 ops/training.py:65 2019-01-16 20:26:37.102646: step 2945, loss = 0.71575 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:26:37.991457 ops/training.py:65 2019-01-16 20:26:37.991391: step 2946, loss = 0.70540 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:26:38.881803 ops/training.py:65 2019-01-16 20:26:38.881745: step 2947, loss = 0.68272 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:26:39.772832 ops/training.py:65 2019-01-16 20:26:39.772756: step 2948, loss = 0.71900 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:26:40.664738 ops/training.py:65 2019-01-16 20:26:40.664640: step 2949, loss = 0.69028 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:26:41.557370 ops/training.py:65 2019-01-16 20:26:41.557261: step 2950, loss = 0.68560 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:26:42.447715 ops/training.py:65 2019-01-16 20:26:42.447646: step 2951, loss = 0.70105 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:26:43.336219 ops/training.py:65 2019-01-16 20:26:43.336146: step 2952, loss = 0.66613 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:26:44.224989 ops/training.py:65 2019-01-16 20:26:44.224924: step 2953, loss = 0.68992 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:26:45.113676 ops/training.py:65 2019-01-16 20:26:45.113592: step 2954, loss = 0.71180 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:26:46.003991 ops/training.py:65 2019-01-16 20:26:46.003925: step 2955, loss = 0.69380 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:26:46.892573 ops/training.py:65 2019-01-16 20:26:46.892500: step 2956, loss = 0.71656 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:26:47.782615 ops/training.py:65 2019-01-16 20:26:47.782541: step 2957, loss = 0.70241 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:26:48.671755 ops/training.py:65 2019-01-16 20:26:48.671689: step 2958, loss = 0.73665 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:26:49.560342 ops/training.py:65 2019-01-16 20:26:49.560273: step 2959, loss = 0.68212 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:26:50.448283 ops/training.py:65 2019-01-16 20:26:50.448219: step 2960, loss = 0.71821 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:26:51.336116 ops/training.py:65 2019-01-16 20:26:51.336050: step 2961, loss = 0.72488 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:26:52.224889 ops/training.py:65 2019-01-16 20:26:52.224820: step 2962, loss = 0.69080 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:26:53.113373 ops/training.py:65 2019-01-16 20:26:53.113309: step 2963, loss = 0.71510 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:26:54.001750 ops/training.py:65 2019-01-16 20:26:54.001689: step 2964, loss = 0.68361 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:26:54.889629 ops/training.py:65 2019-01-16 20:26:54.889574: step 2965, loss = 0.67441 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:26:55.779026 ops/training.py:65 2019-01-16 20:26:55.778961: step 2966, loss = 0.66868 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:26:56.667505 ops/training.py:65 2019-01-16 20:26:56.667442: step 2967, loss = 0.70790 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:26:57.555736 ops/training.py:65 2019-01-16 20:26:57.555677: step 2968, loss = 0.71200 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:26:58.449935 ops/training.py:65 2019-01-16 20:26:58.449893: step 2969, loss = 0.71467 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:26:59.341097 ops/training.py:65 2019-01-16 20:26:59.341000: step 2970, loss = 0.72458 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:27:00.232956 ops/training.py:65 2019-01-16 20:27:00.232868: step 2971, loss = 0.67677 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:27:01.125599 ops/training.py:65 2019-01-16 20:27:01.125500: step 2972, loss = 0.67183 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:27:02.017827 ops/training.py:65 2019-01-16 20:27:02.017741: step 2973, loss = 0.71390 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:27:02.907515 ops/training.py:65 2019-01-16 20:27:02.907451: step 2974, loss = 0.69389 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:27:03.797888 ops/training.py:65 2019-01-16 20:27:03.797816: step 2975, loss = 0.74931 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:27:04.689319 ops/training.py:65 2019-01-16 20:27:04.689264: step 2976, loss = 0.67057 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:27:05.580725 ops/training.py:65 2019-01-16 20:27:05.580623: step 2977, loss = 0.67061 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:27:06.471523 ops/training.py:65 2019-01-16 20:27:06.471467: step 2978, loss = 0.70600 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:27:07.360100 ops/training.py:65 2019-01-16 20:27:07.360048: step 2979, loss = 0.70636 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:27:08.248399 ops/training.py:65 2019-01-16 20:27:08.248343: step 2980, loss = 0.68998 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:27:09.136577 ops/training.py:65 2019-01-16 20:27:09.136522: step 2981, loss = 0.68434 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:27:10.024747 ops/training.py:65 2019-01-16 20:27:10.024696: step 2982, loss = 0.70074 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:27:10.912932 ops/training.py:65 2019-01-16 20:27:10.912882: step 2983, loss = 0.70268 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:27:11.800967 ops/training.py:65 2019-01-16 20:27:11.800910: step 2984, loss = 0.68878 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:27:12.689409 ops/training.py:65 2019-01-16 20:27:12.689343: step 2985, loss = 0.67276 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:27:13.578044 ops/training.py:65 2019-01-16 20:27:13.577981: step 2986, loss = 0.68837 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:27:14.466491 ops/training.py:65 2019-01-16 20:27:14.466435: step 2987, loss = 0.73359 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:27:15.354462 ops/training.py:65 2019-01-16 20:27:15.354412: step 2988, loss = 0.70232 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:27:16.243488 ops/training.py:65 2019-01-16 20:27:16.243434: step 2989, loss = 0.69002 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:27:17.133481 ops/training.py:65 2019-01-16 20:27:17.133429: step 2990, loss = 0.69849 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:27:18.021939 ops/training.py:65 2019-01-16 20:27:18.021889: step 2991, loss = 0.69351 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:27:18.910871 ops/training.py:65 2019-01-16 20:27:18.910818: step 2992, loss = 0.68470 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:27:19.799223 ops/training.py:65 2019-01-16 20:27:19.799159: step 2993, loss = 0.72751 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:27:20.688886 ops/training.py:65 2019-01-16 20:27:20.688820: step 2994, loss = 0.66438 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 20:27:21.577270 ops/training.py:65 2019-01-16 20:27:21.577212: step 2995, loss = 0.69840 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:27:22.469162 ops/training.py:65 2019-01-16 20:27:22.469096: step 2996, loss = 0.72432 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:27:23.361296 ops/training.py:65 2019-01-16 20:27:23.361201: step 2997, loss = 0.74929 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:27:24.253219 ops/training.py:65 2019-01-16 20:27:24.253128: step 2998, loss = 0.69522 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:27:25.145408 ops/training.py:65 2019-01-16 20:27:25.145308: step 2999, loss = 0.71437 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:27:26.036002 ops/training.py:65 2019-01-16 20:27:26.035947: step 3000, loss = 0.71726 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:27:26.925022 ops/training.py:65 2019-01-16 20:27:26.924964: step 3001, loss = 0.69339 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:27:27.813286 ops/training.py:65 2019-01-16 20:27:27.813230: step 3002, loss = 0.71898 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:27:28.705549 ops/training.py:65 2019-01-16 20:27:28.705482: step 3003, loss = 0.69440 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:27:29.598771 ops/training.py:65 2019-01-16 20:27:29.598667: step 3004, loss = 0.69226 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:27:30.490139 ops/training.py:65 2019-01-16 20:27:30.490078: step 3005, loss = 0.68463 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:27:31.379630 ops/training.py:65 2019-01-16 20:27:31.379572: step 3006, loss = 0.70358 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:27:32.268173 ops/training.py:65 2019-01-16 20:27:32.268124: step 3007, loss = 0.70021 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:27:33.155871 ops/training.py:65 2019-01-16 20:27:33.155806: step 3008, loss = 0.73040 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:27:34.043801 ops/training.py:65 2019-01-16 20:27:34.043746: step 3009, loss = 0.71884 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:27:34.937445 ops/training.py:65 2019-01-16 20:27:34.937383: step 3010, loss = 0.70681 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:27:35.827713 ops/training.py:65 2019-01-16 20:27:35.827625: step 3011, loss = 0.68569 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:27:36.720281 ops/training.py:65 2019-01-16 20:27:36.720186: step 3012, loss = 0.72137 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:27:37.611981 ops/training.py:65 2019-01-16 20:27:37.611877: step 3013, loss = 0.66624 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:27:38.502200 ops/training.py:65 2019-01-16 20:27:38.502144: step 3014, loss = 0.67326 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:27:39.391304 ops/training.py:65 2019-01-16 20:27:39.391248: step 3015, loss = 0.70292 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:27:40.280453 ops/training.py:65 2019-01-16 20:27:40.280399: step 3016, loss = 0.67187 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:27:41.169070 ops/training.py:65 2019-01-16 20:27:41.169005: step 3017, loss = 0.69824 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:27:42.057893 ops/training.py:65 2019-01-16 20:27:42.057831: step 3018, loss = 0.68434 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:27:42.945681 ops/training.py:65 2019-01-16 20:27:42.945628: step 3019, loss = 0.68644 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:27:43.833714 ops/training.py:65 2019-01-16 20:27:43.833654: step 3020, loss = 0.72219 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:27:44.722140 ops/training.py:65 2019-01-16 20:27:44.722086: step 3021, loss = 0.69342 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:27:45.610254 ops/training.py:65 2019-01-16 20:27:45.610203: step 3022, loss = 0.68144 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:27:46.498712 ops/training.py:65 2019-01-16 20:27:46.498656: step 3023, loss = 0.67328 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:27:47.388434 ops/training.py:65 2019-01-16 20:27:47.388375: step 3024, loss = 0.70770 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:27:48.279555 ops/training.py:65 2019-01-16 20:27:48.279497: step 3025, loss = 0.67759 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:27:49.171292 ops/training.py:65 2019-01-16 20:27:49.171194: step 3026, loss = 0.65940 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:27:50.062594 ops/training.py:65 2019-01-16 20:27:50.062531: step 3027, loss = 0.69294 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:27:50.954098 ops/training.py:65 2019-01-16 20:27:50.954046: step 3028, loss = 0.67218 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:27:51.845957 ops/training.py:65 2019-01-16 20:27:51.845842: step 3029, loss = 0.68624 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:27:52.735926 ops/training.py:65 2019-01-16 20:27:52.735870: step 3030, loss = 0.69007 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:27:53.624298 ops/training.py:65 2019-01-16 20:27:53.624232: step 3031, loss = 0.70717 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:27:54.513064 ops/training.py:65 2019-01-16 20:27:54.513006: step 3032, loss = 0.70196 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:27:55.401289 ops/training.py:65 2019-01-16 20:27:55.401236: step 3033, loss = 0.67597 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:27:56.289277 ops/training.py:65 2019-01-16 20:27:56.289227: step 3034, loss = 0.71830 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:27:57.177389 ops/training.py:65 2019-01-16 20:27:57.177330: step 3035, loss = 0.70015 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:27:58.065687 ops/training.py:65 2019-01-16 20:27:58.065632: step 3036, loss = 0.69494 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:27:58.956490 ops/training.py:65 2019-01-16 20:27:58.956450: step 3037, loss = 0.72611 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:27:59.848571 ops/training.py:65 2019-01-16 20:27:59.848508: step 3038, loss = 0.68255 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:28:00.739668 ops/training.py:65 2019-01-16 20:28:00.739566: step 3039, loss = 0.69070 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:28:01.630780 ops/training.py:65 2019-01-16 20:28:01.630719: step 3040, loss = 0.66804 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:28:02.518796 ops/training.py:65 2019-01-16 20:28:02.518733: step 3041, loss = 0.69292 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:28:03.407982 ops/training.py:65 2019-01-16 20:28:03.407917: step 3042, loss = 0.64977 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:28:04.296260 ops/training.py:65 2019-01-16 20:28:04.296202: step 3043, loss = 0.69876 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:28:05.184737 ops/training.py:65 2019-01-16 20:28:05.184675: step 3044, loss = 0.72188 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:28:06.073176 ops/training.py:65 2019-01-16 20:28:06.073122: step 3045, loss = 0.68519 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:28:06.964379 ops/training.py:65 2019-01-16 20:28:06.964318: step 3046, loss = 0.70509 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:28:07.856248 ops/training.py:65 2019-01-16 20:28:07.856139: step 3047, loss = 0.70137 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:28:08.747120 ops/training.py:65 2019-01-16 20:28:08.747058: step 3048, loss = 0.70260 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:28:09.635365 ops/training.py:65 2019-01-16 20:28:09.635314: step 3049, loss = 0.69898 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:28:10.523743 ops/training.py:65 2019-01-16 20:28:10.523692: step 3050, loss = 0.73763 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:28:11.411992 ops/training.py:65 2019-01-16 20:28:11.411936: step 3051, loss = 0.73068 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:28:12.301286 ops/training.py:65 2019-01-16 20:28:12.301228: step 3052, loss = 0.69257 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:28:13.193291 ops/training.py:65 2019-01-16 20:28:13.193261: step 3053, loss = 0.69525 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:28:14.085064 ops/training.py:65 2019-01-16 20:28:14.084990: step 3054, loss = 0.72345 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:28:14.976882 ops/training.py:65 2019-01-16 20:28:14.976784: step 3055, loss = 0.67740 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:28:15.867777 ops/training.py:65 2019-01-16 20:28:15.867716: step 3056, loss = 0.71479 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:28:16.759480 ops/training.py:65 2019-01-16 20:28:16.759433: step 3057, loss = 0.67140 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:28:17.651980 ops/training.py:65 2019-01-16 20:28:17.651903: step 3058, loss = 0.67853 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:28:18.545529 ops/training.py:65 2019-01-16 20:28:18.545456: step 3059, loss = 0.71331 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:28:19.437574 ops/training.py:65 2019-01-16 20:28:19.437482: step 3060, loss = 0.72599 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:28:20.329728 ops/training.py:65 2019-01-16 20:28:20.329630: step 3061, loss = 0.70794 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:28:21.222076 ops/training.py:65 2019-01-16 20:28:21.222001: step 3062, loss = 0.70966 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:28:22.113829 ops/training.py:65 2019-01-16 20:28:22.113732: step 3063, loss = 0.70789 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:28:23.005984 ops/training.py:65 2019-01-16 20:28:23.005881: step 3064, loss = 0.69494 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:28:23.897144 ops/training.py:65 2019-01-16 20:28:23.897064: step 3065, loss = 0.72407 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:28:24.785931 ops/training.py:65 2019-01-16 20:28:24.785874: step 3066, loss = 0.71174 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:28:25.673266 ops/training.py:65 2019-01-16 20:28:25.673213: step 3067, loss = 0.70318 (36.1 examples/sec; 0.886 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:28:26.560845 ops/training.py:65 2019-01-16 20:28:26.560786: step 3068, loss = 0.75360 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:28:27.448834 ops/training.py:65 2019-01-16 20:28:27.448767: step 3069, loss = 0.70617 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:28:28.337576 ops/training.py:65 2019-01-16 20:28:28.337525: step 3070, loss = 0.68769 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:28:29.226576 ops/training.py:65 2019-01-16 20:28:29.226526: step 3071, loss = 0.72907 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:28:30.116541 ops/training.py:65 2019-01-16 20:28:30.116496: step 3072, loss = 0.69503 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:28:31.007140 ops/training.py:65 2019-01-16 20:28:31.007053: step 3073, loss = 0.67050 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:28:31.898131 ops/training.py:65 2019-01-16 20:28:31.898043: step 3074, loss = 0.73634 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:28:32.788657 ops/training.py:65 2019-01-16 20:28:32.788556: step 3075, loss = 0.71090 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:28:33.680266 ops/training.py:65 2019-01-16 20:28:33.680190: step 3076, loss = 0.66859 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:28:34.568609 ops/training.py:65 2019-01-16 20:28:34.568561: step 3077, loss = 0.69461 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:28:35.457173 ops/training.py:65 2019-01-16 20:28:35.457124: step 3078, loss = 0.69945 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:28:36.344999 ops/training.py:65 2019-01-16 20:28:36.344950: step 3079, loss = 0.70393 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:28:37.233670 ops/training.py:65 2019-01-16 20:28:37.233622: step 3080, loss = 0.69229 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:28:38.122403 ops/training.py:65 2019-01-16 20:28:38.122352: step 3081, loss = 0.71399 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:28:39.010704 ops/training.py:65 2019-01-16 20:28:39.010653: step 3082, loss = 0.68924 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:28:39.898387 ops/training.py:65 2019-01-16 20:28:39.898337: step 3083, loss = 0.70565 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:28:40.788756 ops/training.py:65 2019-01-16 20:28:40.788699: step 3084, loss = 0.69558 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:28:41.679505 ops/training.py:65 2019-01-16 20:28:41.679398: step 3085, loss = 0.71100 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:28:42.570371 ops/training.py:65 2019-01-16 20:28:42.570323: step 3086, loss = 0.66845 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:28:43.458928 ops/training.py:65 2019-01-16 20:28:43.458871: step 3087, loss = 0.72518 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:28:44.351430 ops/training.py:65 2019-01-16 20:28:44.351372: step 3088, loss = 0.68741 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:28:45.245376 ops/training.py:65 2019-01-16 20:28:45.245313: step 3089, loss = 0.64680 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:28:46.137985 ops/training.py:65 2019-01-16 20:28:46.137919: step 3090, loss = 0.67669 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:28:47.029695 ops/training.py:65 2019-01-16 20:28:47.029596: step 3091, loss = 0.68579 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:28:47.920234 ops/training.py:65 2019-01-16 20:28:47.920172: step 3092, loss = 0.68297 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:28:48.814073 ops/training.py:65 2019-01-16 20:28:48.814033: step 3093, loss = 0.71639 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:28:49.704513 ops/training.py:65 2019-01-16 20:28:49.704419: step 3094, loss = 0.72596 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:28:50.594954 ops/training.py:65 2019-01-16 20:28:50.594885: step 3095, loss = 0.71216 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:28:51.483485 ops/training.py:65 2019-01-16 20:28:51.483423: step 3096, loss = 0.69616 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:28:52.373645 ops/training.py:65 2019-01-16 20:28:52.373577: step 3097, loss = 0.70853 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:28:53.264659 ops/training.py:65 2019-01-16 20:28:53.264524: step 3098, loss = 0.68898 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:28:54.155993 ops/training.py:65 2019-01-16 20:28:54.155916: step 3099, loss = 0.68739 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:28:55.048627 ops/training.py:65 2019-01-16 20:28:55.048523: step 3100, loss = 0.68290 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:28:55.938476 ops/training.py:65 2019-01-16 20:28:55.938415: step 3101, loss = 0.72117 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:28:56.832046 ops/training.py:65 2019-01-16 20:28:56.832003: step 3102, loss = 0.69551 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:28:57.723586 ops/training.py:65 2019-01-16 20:28:57.723542: step 3103, loss = 0.69373 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:28:58.614395 ops/training.py:65 2019-01-16 20:28:58.614294: step 3104, loss = 0.67808 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:28:59.506432 ops/training.py:65 2019-01-16 20:28:59.506388: step 3105, loss = 0.71396 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:29:00.399861 ops/training.py:65 2019-01-16 20:29:00.399779: step 3106, loss = 0.69859 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:29:01.292329 ops/training.py:65 2019-01-16 20:29:01.292224: step 3107, loss = 0.70687 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:29:02.182368 ops/training.py:65 2019-01-16 20:29:02.182315: step 3108, loss = 0.69420 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:29:03.070583 ops/training.py:65 2019-01-16 20:29:03.070519: step 3109, loss = 0.67331 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:29:03.959194 ops/training.py:65 2019-01-16 20:29:03.959132: step 3110, loss = 0.68689 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:29:04.847487 ops/training.py:65 2019-01-16 20:29:04.847423: step 3111, loss = 0.72384 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:29:05.736008 ops/training.py:65 2019-01-16 20:29:05.735946: step 3112, loss = 0.69030 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:29:06.624748 ops/training.py:65 2019-01-16 20:29:06.624685: step 3113, loss = 0.68703 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:29:07.513867 ops/training.py:65 2019-01-16 20:29:07.513812: step 3114, loss = 0.73707 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 20:29:08.402104 ops/training.py:65 2019-01-16 20:29:08.402050: step 3115, loss = 0.69302 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:29:09.289696 ops/training.py:65 2019-01-16 20:29:09.289641: step 3116, loss = 0.69678 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:29:10.181659 ops/training.py:65 2019-01-16 20:29:10.181626: step 3117, loss = 0.71879 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:29:11.072488 ops/training.py:65 2019-01-16 20:29:11.072438: step 3118, loss = 0.72685 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:29:11.963233 ops/training.py:65 2019-01-16 20:29:11.963186: step 3119, loss = 0.69556 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:29:12.855369 ops/training.py:65 2019-01-16 20:29:12.855299: step 3120, loss = 0.71401 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:29:13.745487 ops/training.py:65 2019-01-16 20:29:13.745384: step 3121, loss = 0.71113 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:29:14.637297 ops/training.py:65 2019-01-16 20:29:14.637204: step 3122, loss = 0.66166 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:29:15.526057 ops/training.py:65 2019-01-16 20:29:15.526001: step 3123, loss = 0.69336 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:29:16.413369 ops/training.py:65 2019-01-16 20:29:16.413315: step 3124, loss = 0.67528 (36.1 examples/sec; 0.886 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:29:17.301293 ops/training.py:65 2019-01-16 20:29:17.301239: step 3125, loss = 0.68128 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:29:18.189979 ops/training.py:65 2019-01-16 20:29:18.189921: step 3126, loss = 0.67062 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:29:19.079609 ops/training.py:65 2019-01-16 20:29:19.079551: step 3127, loss = 0.68853 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:29:19.968426 ops/training.py:65 2019-01-16 20:29:19.968369: step 3128, loss = 0.71079 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:29:20.856655 ops/training.py:65 2019-01-16 20:29:20.856602: step 3129, loss = 0.69377 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:29:21.744499 ops/training.py:65 2019-01-16 20:29:21.744444: step 3130, loss = 0.66795 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:29:22.633364 ops/training.py:65 2019-01-16 20:29:22.633314: step 3131, loss = 0.70658 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:29:23.522120 ops/training.py:65 2019-01-16 20:29:23.522049: step 3132, loss = 0.74076 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:29:24.411490 ops/training.py:65 2019-01-16 20:29:24.411433: step 3133, loss = 0.71276 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:29:25.300714 ops/training.py:65 2019-01-16 20:29:25.300659: step 3134, loss = 0.67675 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:29:26.188777 ops/training.py:65 2019-01-16 20:29:26.188722: step 3135, loss = 0.70247 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:29:27.080001 ops/training.py:65 2019-01-16 20:29:27.079930: step 3136, loss = 0.69163 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:29:27.972452 ops/training.py:65 2019-01-16 20:29:27.972342: step 3137, loss = 0.67882 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:29:28.863453 ops/training.py:65 2019-01-16 20:29:28.863397: step 3138, loss = 0.69860 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:29:29.751607 ops/training.py:65 2019-01-16 20:29:29.751557: step 3139, loss = 0.72140 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:29:30.639056 ops/training.py:65 2019-01-16 20:29:30.639001: step 3140, loss = 0.71859 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:29:31.526342 ops/training.py:65 2019-01-16 20:29:31.526288: step 3141, loss = 0.69539 (36.1 examples/sec; 0.886 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:29:32.417653 ops/training.py:65 2019-01-16 20:29:32.417616: step 3142, loss = 0.68692 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:29:33.309817 ops/training.py:65 2019-01-16 20:29:33.309775: step 3143, loss = 0.69289 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:29:34.200792 ops/training.py:65 2019-01-16 20:29:34.200697: step 3144, loss = 0.71517 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:29:35.092229 ops/training.py:65 2019-01-16 20:29:35.092170: step 3145, loss = 0.71280 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:29:35.983180 ops/training.py:65 2019-01-16 20:29:35.983114: step 3146, loss = 0.68068 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:29:36.875971 ops/training.py:65 2019-01-16 20:29:36.875901: step 3147, loss = 0.67625 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:29:37.766092 ops/training.py:65 2019-01-16 20:29:37.766013: step 3148, loss = 0.64588 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:29:38.657944 ops/training.py:65 2019-01-16 20:29:38.657840: step 3149, loss = 0.71479 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:29:39.548695 ops/training.py:65 2019-01-16 20:29:39.548544: step 3150, loss = 0.70400 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:29:40.439621 ops/training.py:65 2019-01-16 20:29:40.439558: step 3151, loss = 0.71262 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:29:41.327382 ops/training.py:65 2019-01-16 20:29:41.327320: step 3152, loss = 0.68233 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:29:42.215287 ops/training.py:65 2019-01-16 20:29:42.215226: step 3153, loss = 0.66840 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:29:43.103360 ops/training.py:65 2019-01-16 20:29:43.103295: step 3154, loss = 0.69929 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:29:43.992174 ops/training.py:65 2019-01-16 20:29:43.992119: step 3155, loss = 0.68696 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:29:44.885049 ops/training.py:65 2019-01-16 20:29:44.885007: step 3156, loss = 0.69135 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:29:45.779171 ops/training.py:65 2019-01-16 20:29:45.779117: step 3157, loss = 0.70164 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:29:46.668970 ops/training.py:65 2019-01-16 20:29:46.668893: step 3158, loss = 0.70671 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:29:47.562019 ops/training.py:65 2019-01-16 20:29:47.561940: step 3159, loss = 0.70769 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:29:48.453453 ops/training.py:65 2019-01-16 20:29:48.453355: step 3160, loss = 0.70617 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:29:49.344410 ops/training.py:65 2019-01-16 20:29:49.344345: step 3161, loss = 0.67097 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:29:50.232813 ops/training.py:65 2019-01-16 20:29:50.232750: step 3162, loss = 0.69459 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:29:51.121167 ops/training.py:65 2019-01-16 20:29:51.121098: step 3163, loss = 0.69775 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:29:52.010748 ops/training.py:65 2019-01-16 20:29:52.010683: step 3164, loss = 0.68103 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:29:52.900290 ops/training.py:65 2019-01-16 20:29:52.900232: step 3165, loss = 0.67120 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:29:53.789571 ops/training.py:65 2019-01-16 20:29:53.789514: step 3166, loss = 0.69491 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:29:54.682409 ops/training.py:65 2019-01-16 20:29:54.682352: step 3167, loss = 0.69675 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:29:55.574350 ops/training.py:65 2019-01-16 20:29:55.574246: step 3168, loss = 0.68847 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:29:56.465105 ops/training.py:65 2019-01-16 20:29:56.465041: step 3169, loss = 0.68296 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:29:57.358695 ops/training.py:65 2019-01-16 20:29:57.358628: step 3170, loss = 0.74056 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:29:58.248471 ops/training.py:65 2019-01-16 20:29:58.248384: step 3171, loss = 0.71800 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:29:59.138130 ops/training.py:65 2019-01-16 20:29:59.138058: step 3172, loss = 0.67781 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:30:00.026273 ops/training.py:65 2019-01-16 20:30:00.026189: step 3173, loss = 0.69895 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:30:00.916946 ops/training.py:65 2019-01-16 20:30:00.916840: step 3174, loss = 0.70205 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:30:01.807401 ops/training.py:65 2019-01-16 20:30:01.807339: step 3175, loss = 0.66270 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:30:02.696023 ops/training.py:65 2019-01-16 20:30:02.695964: step 3176, loss = 0.70079 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:30:03.583945 ops/training.py:65 2019-01-16 20:30:03.583871: step 3177, loss = 0.67979 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:30:04.472546 ops/training.py:65 2019-01-16 20:30:04.472477: step 3178, loss = 0.73113 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:30:05.360868 ops/training.py:65 2019-01-16 20:30:05.360800: step 3179, loss = 0.68494 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:30:06.251771 ops/training.py:65 2019-01-16 20:30:06.251729: step 3180, loss = 0.70073 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:30:07.144139 ops/training.py:65 2019-01-16 20:30:07.144037: step 3181, loss = 0.70172 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:30:08.037011 ops/training.py:65 2019-01-16 20:30:08.036941: step 3182, loss = 0.69196 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:30:08.929119 ops/training.py:65 2019-01-16 20:30:08.929022: step 3183, loss = 0.73358 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:30:09.821053 ops/training.py:65 2019-01-16 20:30:09.820946: step 3184, loss = 0.70581 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:30:10.715516 ops/training.py:65 2019-01-16 20:30:10.715433: step 3185, loss = 0.69628 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:30:11.607782 ops/training.py:65 2019-01-16 20:30:11.607679: step 3186, loss = 0.71830 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:30:12.499267 ops/training.py:65 2019-01-16 20:30:12.499207: step 3187, loss = 0.71024 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:30:13.388677 ops/training.py:65 2019-01-16 20:30:13.388614: step 3188, loss = 0.69575 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:30:14.280386 ops/training.py:65 2019-01-16 20:30:14.280328: step 3189, loss = 0.70765 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:30:15.172463 ops/training.py:65 2019-01-16 20:30:15.172358: step 3190, loss = 0.70279 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:30:16.063325 ops/training.py:65 2019-01-16 20:30:16.063260: step 3191, loss = 0.66787 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:30:16.952438 ops/training.py:65 2019-01-16 20:30:16.952372: step 3192, loss = 0.67699 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:30:17.841390 ops/training.py:65 2019-01-16 20:30:17.841309: step 3193, loss = 0.71525 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:30:18.729202 ops/training.py:65 2019-01-16 20:30:18.729142: step 3194, loss = 0.70910 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:30:19.617878 ops/training.py:65 2019-01-16 20:30:19.617805: step 3195, loss = 0.69472 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:30:20.506216 ops/training.py:65 2019-01-16 20:30:20.506156: step 3196, loss = 0.70976 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:30:21.393842 ops/training.py:65 2019-01-16 20:30:21.393786: step 3197, loss = 0.73096 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:30:22.281257 ops/training.py:65 2019-01-16 20:30:22.281193: step 3198, loss = 0.74975 (36.1 examples/sec; 0.886 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:30:23.170205 ops/training.py:65 2019-01-16 20:30:23.170140: step 3199, loss = 0.72771 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:30:24.058037 ops/training.py:65 2019-01-16 20:30:24.057980: step 3200, loss = 0.71335 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:30:24.945960 ops/training.py:65 2019-01-16 20:30:24.945905: step 3201, loss = 0.73758 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:30:25.837592 ops/training.py:65 2019-01-16 20:30:25.837543: step 3202, loss = 0.70563 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:30:26.727446 ops/training.py:65 2019-01-16 20:30:26.727401: step 3203, loss = 0.66999 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:30:27.617464 ops/training.py:65 2019-01-16 20:30:27.617399: step 3204, loss = 0.66318 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:30:28.505958 ops/training.py:65 2019-01-16 20:30:28.505898: step 3205, loss = 0.70152 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:30:29.394486 ops/training.py:65 2019-01-16 20:30:29.394399: step 3206, loss = 0.66928 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:30:30.287487 ops/training.py:65 2019-01-16 20:30:30.287396: step 3207, loss = 0.71344 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:30:31.178088 ops/training.py:65 2019-01-16 20:30:31.177986: step 3208, loss = 0.67842 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:30:32.068359 ops/training.py:65 2019-01-16 20:30:32.068261: step 3209, loss = 0.70422 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:30:32.959904 ops/training.py:65 2019-01-16 20:30:32.959802: step 3210, loss = 0.64228 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:30:33.850560 ops/training.py:65 2019-01-16 20:30:33.850493: step 3211, loss = 0.74909 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:30:34.742146 ops/training.py:65 2019-01-16 20:30:34.742074: step 3212, loss = 0.67871 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:30:35.634331 ops/training.py:65 2019-01-16 20:30:35.634222: step 3213, loss = 0.69511 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:30:36.526237 ops/training.py:65 2019-01-16 20:30:36.526140: step 3214, loss = 0.69069 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:30:37.416602 ops/training.py:65 2019-01-16 20:30:37.416539: step 3215, loss = 0.71637 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:30:38.305178 ops/training.py:65 2019-01-16 20:30:38.305099: step 3216, loss = 0.73117 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:30:39.194608 ops/training.py:65 2019-01-16 20:30:39.194528: step 3217, loss = 0.69517 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:30:40.084061 ops/training.py:65 2019-01-16 20:30:40.083979: step 3218, loss = 0.67973 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:30:40.974357 ops/training.py:65 2019-01-16 20:30:40.974288: step 3219, loss = 0.69451 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:30:41.862943 ops/training.py:65 2019-01-16 20:30:41.862876: step 3220, loss = 0.73123 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:30:42.751852 ops/training.py:65 2019-01-16 20:30:42.751785: step 3221, loss = 0.70617 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:30:43.645134 ops/training.py:65 2019-01-16 20:30:43.645066: step 3222, loss = 0.70323 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:30:44.535634 ops/training.py:65 2019-01-16 20:30:44.535540: step 3223, loss = 0.65771 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:30:45.427930 ops/training.py:65 2019-01-16 20:30:45.427824: step 3224, loss = 0.65923 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:30:46.317775 ops/training.py:65 2019-01-16 20:30:46.317707: step 3225, loss = 0.73732 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:30:47.207325 ops/training.py:65 2019-01-16 20:30:47.207259: step 3226, loss = 0.73749 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:30:48.095878 ops/training.py:65 2019-01-16 20:30:48.095811: step 3227, loss = 0.72868 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:30:48.984973 ops/training.py:65 2019-01-16 20:30:48.984915: step 3228, loss = 0.66934 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:30:49.873178 ops/training.py:65 2019-01-16 20:30:49.873120: step 3229, loss = 0.73394 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:30:50.761755 ops/training.py:65 2019-01-16 20:30:50.761688: step 3230, loss = 0.70665 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:30:51.650622 ops/training.py:65 2019-01-16 20:30:51.650551: step 3231, loss = 0.68706 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:30:52.540023 ops/training.py:65 2019-01-16 20:30:52.539954: step 3232, loss = 0.74835 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:30:53.428894 ops/training.py:65 2019-01-16 20:30:53.428830: step 3233, loss = 0.75154 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:30:54.317391 ops/training.py:65 2019-01-16 20:30:54.317324: step 3234, loss = 0.70420 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:30:55.206688 ops/training.py:65 2019-01-16 20:30:55.206621: step 3235, loss = 0.73471 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:30:56.095878 ops/training.py:65 2019-01-16 20:30:56.095815: step 3236, loss = 0.69500 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:30:56.984054 ops/training.py:65 2019-01-16 20:30:56.983992: step 3237, loss = 0.72569 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:30:57.872595 ops/training.py:65 2019-01-16 20:30:57.872534: step 3238, loss = 0.69818 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:30:58.762103 ops/training.py:65 2019-01-16 20:30:58.762040: step 3239, loss = 0.70953 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:30:59.651510 ops/training.py:65 2019-01-16 20:30:59.651447: step 3240, loss = 0.70872 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:31:00.541758 ops/training.py:65 2019-01-16 20:31:00.541703: step 3241, loss = 0.68975 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:31:01.430760 ops/training.py:65 2019-01-16 20:31:01.430703: step 3242, loss = 0.68682 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:31:02.324798 ops/training.py:65 2019-01-16 20:31:02.324748: step 3243, loss = 0.66958 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:31:03.215965 ops/training.py:65 2019-01-16 20:31:03.215932: step 3244, loss = 0.71073 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:31:04.109132 ops/training.py:65 2019-01-16 20:31:04.109052: step 3245, loss = 0.70048 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:31:05.001186 ops/training.py:65 2019-01-16 20:31:05.001082: step 3246, loss = 0.71643 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:31:05.895092 ops/training.py:65 2019-01-16 20:31:05.895026: step 3247, loss = 0.70430 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:31:06.787606 ops/training.py:65 2019-01-16 20:31:06.787496: step 3248, loss = 0.70516 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:31:07.678468 ops/training.py:65 2019-01-16 20:31:07.678376: step 3249, loss = 0.73051 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:31:08.567427 ops/training.py:65 2019-01-16 20:31:08.567362: step 3250, loss = 0.65391 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:31:09.455037 ops/training.py:65 2019-01-16 20:31:09.454977: step 3251, loss = 0.70275 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:31:10.342784 ops/training.py:65 2019-01-16 20:31:10.342728: step 3252, loss = 0.69528 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:31:11.235410 ops/training.py:65 2019-01-16 20:31:11.235354: step 3253, loss = 0.71927 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:31:12.127285 ops/training.py:65 2019-01-16 20:31:12.127176: step 3254, loss = 0.70837 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:31:13.018476 ops/training.py:65 2019-01-16 20:31:13.018419: step 3255, loss = 0.72101 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:31:13.907657 ops/training.py:65 2019-01-16 20:31:13.907597: step 3256, loss = 0.68590 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:31:14.796006 ops/training.py:65 2019-01-16 20:31:14.795950: step 3257, loss = 0.71352 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:31:15.684323 ops/training.py:65 2019-01-16 20:31:15.684273: step 3258, loss = 0.72342 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:31:16.571651 ops/training.py:65 2019-01-16 20:31:16.571600: step 3259, loss = 0.70306 (36.1 examples/sec; 0.886 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:31:17.463696 ops/training.py:65 2019-01-16 20:31:17.463664: step 3260, loss = 0.68668 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:31:18.355270 ops/training.py:65 2019-01-16 20:31:18.355179: step 3261, loss = 0.71474 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:31:19.247145 ops/training.py:65 2019-01-16 20:31:19.247057: step 3262, loss = 0.69272 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:31:20.136294 ops/training.py:65 2019-01-16 20:31:20.136233: step 3263, loss = 0.70709 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:31:21.024028 ops/training.py:65 2019-01-16 20:31:21.023955: step 3264, loss = 0.66773 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:31:21.912832 ops/training.py:65 2019-01-16 20:31:21.912744: step 3265, loss = 0.69629 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:31:22.801361 ops/training.py:65 2019-01-16 20:31:22.801275: step 3266, loss = 0.69961 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:31:23.690424 ops/training.py:65 2019-01-16 20:31:23.690359: step 3267, loss = 0.66080 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:31:24.585538 ops/training.py:65 2019-01-16 20:31:24.585474: step 3268, loss = 0.70065 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:31:25.476487 ops/training.py:65 2019-01-16 20:31:25.476378: step 3269, loss = 0.67861 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:31:26.367354 ops/training.py:65 2019-01-16 20:31:26.367260: step 3270, loss = 0.70655 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:31:27.259232 ops/training.py:65 2019-01-16 20:31:27.259183: step 3271, loss = 0.72459 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:31:28.149730 ops/training.py:65 2019-01-16 20:31:28.149645: step 3272, loss = 0.68154 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:31:29.039129 ops/training.py:65 2019-01-16 20:31:29.039067: step 3273, loss = 0.74150 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:31:29.929116 ops/training.py:65 2019-01-16 20:31:29.929046: step 3274, loss = 0.71719 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:31:30.820617 ops/training.py:65 2019-01-16 20:31:30.820513: step 3275, loss = 0.68157 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:31:31.711621 ops/training.py:65 2019-01-16 20:31:31.711552: step 3276, loss = 0.68694 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:31:32.600092 ops/training.py:65 2019-01-16 20:31:32.600034: step 3277, loss = 0.67414 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:31:33.488235 ops/training.py:65 2019-01-16 20:31:33.488164: step 3278, loss = 0.76546 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.25
I2992 2019-01-16 20:31:34.377849 ops/training.py:65 2019-01-16 20:31:34.377781: step 3279, loss = 0.70942 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:31:35.266765 ops/training.py:65 2019-01-16 20:31:35.266695: step 3280, loss = 0.66826 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:31:36.155739 ops/training.py:65 2019-01-16 20:31:36.155670: step 3281, loss = 0.71139 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:31:37.044336 ops/training.py:65 2019-01-16 20:31:37.044261: step 3282, loss = 0.70366 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:31:37.932550 ops/training.py:65 2019-01-16 20:31:37.932477: step 3283, loss = 0.70866 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:31:38.822040 ops/training.py:65 2019-01-16 20:31:38.821967: step 3284, loss = 0.70073 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:31:39.710523 ops/training.py:65 2019-01-16 20:31:39.710448: step 3285, loss = 0.69580 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:31:40.599268 ops/training.py:65 2019-01-16 20:31:40.599198: step 3286, loss = 0.66226 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:31:41.490855 ops/training.py:65 2019-01-16 20:31:41.490778: step 3287, loss = 0.69602 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:31:42.382786 ops/training.py:65 2019-01-16 20:31:42.382682: step 3288, loss = 0.71901 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:31:43.274317 ops/training.py:65 2019-01-16 20:31:43.274226: step 3289, loss = 0.67611 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:31:44.164586 ops/training.py:65 2019-01-16 20:31:44.164511: step 3290, loss = 0.69756 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:31:45.053864 ops/training.py:65 2019-01-16 20:31:45.053798: step 3291, loss = 0.70462 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:31:45.943185 ops/training.py:65 2019-01-16 20:31:45.943120: step 3292, loss = 0.71784 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:31:46.831328 ops/training.py:65 2019-01-16 20:31:46.831266: step 3293, loss = 0.69449 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:31:47.721166 ops/training.py:65 2019-01-16 20:31:47.721093: step 3294, loss = 0.75182 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.21875
I2992 2019-01-16 20:31:48.611870 ops/training.py:65 2019-01-16 20:31:48.611811: step 3295, loss = 0.71123 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:31:49.502271 ops/training.py:65 2019-01-16 20:31:49.502181: step 3296, loss = 0.68975 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:31:50.393330 ops/training.py:65 2019-01-16 20:31:50.393225: step 3297, loss = 0.68083 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:31:51.284812 ops/training.py:65 2019-01-16 20:31:51.284709: step 3298, loss = 0.70129 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:31:52.174877 ops/training.py:65 2019-01-16 20:31:52.174779: step 3299, loss = 0.69306 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:31:53.065505 ops/training.py:65 2019-01-16 20:31:53.065414: step 3300, loss = 0.68727 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:31:53.955080 ops/training.py:65 2019-01-16 20:31:53.954993: step 3301, loss = 0.69171 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:31:54.846783 ops/training.py:65 2019-01-16 20:31:54.846677: step 3302, loss = 0.69557 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:31:55.737650 ops/training.py:65 2019-01-16 20:31:55.737579: step 3303, loss = 0.72129 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:31:56.626843 ops/training.py:65 2019-01-16 20:31:56.626749: step 3304, loss = 0.68353 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:31:57.517524 ops/training.py:65 2019-01-16 20:31:57.517420: step 3305, loss = 0.67642 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:31:58.408476 ops/training.py:65 2019-01-16 20:31:58.408401: step 3306, loss = 0.69640 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:31:59.297652 ops/training.py:65 2019-01-16 20:31:59.297575: step 3307, loss = 0.69584 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:32:00.185869 ops/training.py:65 2019-01-16 20:32:00.185805: step 3308, loss = 0.68063 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:32:01.074344 ops/training.py:65 2019-01-16 20:32:01.074280: step 3309, loss = 0.69916 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:32:01.963099 ops/training.py:65 2019-01-16 20:32:01.963042: step 3310, loss = 0.70644 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:32:02.850971 ops/training.py:65 2019-01-16 20:32:02.850912: step 3311, loss = 0.69134 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:32:03.739162 ops/training.py:65 2019-01-16 20:32:03.739091: step 3312, loss = 0.71075 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:32:04.629276 ops/training.py:65 2019-01-16 20:32:04.629215: step 3313, loss = 0.65802 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 20:32:05.518069 ops/training.py:65 2019-01-16 20:32:05.518007: step 3314, loss = 0.69374 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:32:06.406581 ops/training.py:65 2019-01-16 20:32:06.406515: step 3315, loss = 0.71875 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:32:07.295648 ops/training.py:65 2019-01-16 20:32:07.295584: step 3316, loss = 0.71675 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:32:08.184984 ops/training.py:65 2019-01-16 20:32:08.184919: step 3317, loss = 0.70304 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:32:09.073132 ops/training.py:65 2019-01-16 20:32:09.073069: step 3318, loss = 0.69012 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:32:09.961432 ops/training.py:65 2019-01-16 20:32:09.961371: step 3319, loss = 0.67898 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:32:10.851310 ops/training.py:65 2019-01-16 20:32:10.851267: step 3320, loss = 0.68268 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:32:11.743100 ops/training.py:65 2019-01-16 20:32:11.743041: step 3321, loss = 0.70226 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:32:12.634513 ops/training.py:65 2019-01-16 20:32:12.634460: step 3322, loss = 0.71021 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:32:13.525881 ops/training.py:65 2019-01-16 20:32:13.525838: step 3323, loss = 0.68394 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:32:14.417897 ops/training.py:65 2019-01-16 20:32:14.417794: step 3324, loss = 0.71258 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:32:15.309539 ops/training.py:65 2019-01-16 20:32:15.309454: step 3325, loss = 0.70765 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:32:16.201711 ops/training.py:65 2019-01-16 20:32:16.201653: step 3326, loss = 0.69058 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:32:17.092880 ops/training.py:65 2019-01-16 20:32:17.092804: step 3327, loss = 0.71918 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:32:17.984958 ops/training.py:65 2019-01-16 20:32:17.984856: step 3328, loss = 0.71227 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:32:18.876642 ops/training.py:65 2019-01-16 20:32:18.876558: step 3329, loss = 0.71503 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:32:19.764852 ops/training.py:65 2019-01-16 20:32:19.764785: step 3330, loss = 0.71231 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:32:20.653910 ops/training.py:65 2019-01-16 20:32:20.653846: step 3331, loss = 0.72177 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:32:21.542539 ops/training.py:65 2019-01-16 20:32:21.542472: step 3332, loss = 0.67918 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:32:22.436511 ops/training.py:65 2019-01-16 20:32:22.436468: step 3333, loss = 0.67349 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:32:23.330437 ops/training.py:65 2019-01-16 20:32:23.330397: step 3334, loss = 0.70775 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:32:24.222436 ops/training.py:65 2019-01-16 20:32:24.222391: step 3335, loss = 0.68635 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:32:25.114357 ops/training.py:65 2019-01-16 20:32:25.114255: step 3336, loss = 0.69214 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:32:26.003979 ops/training.py:65 2019-01-16 20:32:26.003914: step 3337, loss = 0.68799 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:32:26.893114 ops/training.py:65 2019-01-16 20:32:26.893054: step 3338, loss = 0.70572 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:32:27.788310 ops/training.py:65 2019-01-16 20:32:27.788241: step 3339, loss = 0.69067 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:32:28.682689 ops/training.py:65 2019-01-16 20:32:28.682611: step 3340, loss = 0.71347 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:32:29.573052 ops/training.py:65 2019-01-16 20:32:29.572973: step 3341, loss = 0.70963 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:32:30.467097 ops/training.py:65 2019-01-16 20:32:30.466997: step 3342, loss = 0.71240 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:32:31.359066 ops/training.py:65 2019-01-16 20:32:31.358961: step 3343, loss = 0.70899 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:32:32.250262 ops/training.py:65 2019-01-16 20:32:32.250195: step 3344, loss = 0.70061 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:32:33.141693 ops/training.py:65 2019-01-16 20:32:33.141592: step 3345, loss = 0.72421 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:32:34.031866 ops/training.py:65 2019-01-16 20:32:34.031799: step 3346, loss = 0.70125 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:32:34.920338 ops/training.py:65 2019-01-16 20:32:34.920264: step 3347, loss = 0.71660 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:32:35.808700 ops/training.py:65 2019-01-16 20:32:35.808629: step 3348, loss = 0.67505 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:32:36.697387 ops/training.py:65 2019-01-16 20:32:36.697320: step 3349, loss = 0.70063 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:32:37.585693 ops/training.py:65 2019-01-16 20:32:37.585632: step 3350, loss = 0.67101 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:32:38.474305 ops/training.py:65 2019-01-16 20:32:38.474237: step 3351, loss = 0.68367 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:32:39.362605 ops/training.py:65 2019-01-16 20:32:39.362540: step 3352, loss = 0.68198 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:32:40.250993 ops/training.py:65 2019-01-16 20:32:40.250930: step 3353, loss = 0.67812 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:32:41.139574 ops/training.py:65 2019-01-16 20:32:41.139510: step 3354, loss = 0.70474 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:32:42.028106 ops/training.py:65 2019-01-16 20:32:42.028041: step 3355, loss = 0.69504 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:32:42.917468 ops/training.py:65 2019-01-16 20:32:42.917394: step 3356, loss = 0.70934 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:32:43.806496 ops/training.py:65 2019-01-16 20:32:43.806426: step 3357, loss = 0.67714 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:32:44.700305 ops/training.py:65 2019-01-16 20:32:44.700244: step 3358, loss = 0.70509 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:32:45.592588 ops/training.py:65 2019-01-16 20:32:45.592479: step 3359, loss = 0.68222 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:32:46.483514 ops/training.py:65 2019-01-16 20:32:46.483445: step 3360, loss = 0.68913 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:32:47.372262 ops/training.py:65 2019-01-16 20:32:47.372189: step 3361, loss = 0.70497 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:32:48.260660 ops/training.py:65 2019-01-16 20:32:48.260597: step 3362, loss = 0.69751 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:32:49.149207 ops/training.py:65 2019-01-16 20:32:49.149142: step 3363, loss = 0.68318 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 20:32:50.037536 ops/training.py:65 2019-01-16 20:32:50.037437: step 3364, loss = 0.69420 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:32:50.926376 ops/training.py:65 2019-01-16 20:32:50.926303: step 3365, loss = 0.72439 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:32:51.817685 ops/training.py:65 2019-01-16 20:32:51.817614: step 3366, loss = 0.68961 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:32:52.709633 ops/training.py:65 2019-01-16 20:32:52.709528: step 3367, loss = 0.68576 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:32:53.601112 ops/training.py:65 2019-01-16 20:32:53.601045: step 3368, loss = 0.66904 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:32:54.490397 ops/training.py:65 2019-01-16 20:32:54.490345: step 3369, loss = 0.68758 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:32:55.379099 ops/training.py:65 2019-01-16 20:32:55.379041: step 3370, loss = 0.71308 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:32:56.268290 ops/training.py:65 2019-01-16 20:32:56.268228: step 3371, loss = 0.73731 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:32:57.156897 ops/training.py:65 2019-01-16 20:32:57.156840: step 3372, loss = 0.70202 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:32:58.045587 ops/training.py:65 2019-01-16 20:32:58.045519: step 3373, loss = 0.69082 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:32:58.936244 ops/training.py:65 2019-01-16 20:32:58.936179: step 3374, loss = 0.68459 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:32:59.826523 ops/training.py:65 2019-01-16 20:32:59.826425: step 3375, loss = 0.71869 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:33:00.718918 ops/training.py:65 2019-01-16 20:33:00.718812: step 3376, loss = 0.68378 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:33:01.609938 ops/training.py:65 2019-01-16 20:33:01.609876: step 3377, loss = 0.68150 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:33:02.499009 ops/training.py:65 2019-01-16 20:33:02.498953: step 3378, loss = 0.71934 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:33:03.387242 ops/training.py:65 2019-01-16 20:33:03.387179: step 3379, loss = 0.72705 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:33:04.280813 ops/training.py:65 2019-01-16 20:33:04.280742: step 3380, loss = 0.68661 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:33:05.176030 ops/training.py:65 2019-01-16 20:33:05.175945: step 3381, loss = 0.70879 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:33:06.067948 ops/training.py:65 2019-01-16 20:33:06.067842: step 3382, loss = 0.68800 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:33:06.958898 ops/training.py:65 2019-01-16 20:33:06.958830: step 3383, loss = 0.69615 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:33:07.848726 ops/training.py:65 2019-01-16 20:33:07.848655: step 3384, loss = 0.72265 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:33:08.737527 ops/training.py:65 2019-01-16 20:33:08.737464: step 3385, loss = 0.70518 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:33:09.625842 ops/training.py:65 2019-01-16 20:33:09.625771: step 3386, loss = 0.71209 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:33:10.514851 ops/training.py:65 2019-01-16 20:33:10.514788: step 3387, loss = 0.70229 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:33:11.404321 ops/training.py:65 2019-01-16 20:33:11.404259: step 3388, loss = 0.69452 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:33:12.292716 ops/training.py:65 2019-01-16 20:33:12.292664: step 3389, loss = 0.66062 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:33:13.181313 ops/training.py:65 2019-01-16 20:33:13.181249: step 3390, loss = 0.71136 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:33:14.069779 ops/training.py:65 2019-01-16 20:33:14.069717: step 3391, loss = 0.69922 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:33:14.957880 ops/training.py:65 2019-01-16 20:33:14.957824: step 3392, loss = 0.69248 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:33:15.846609 ops/training.py:65 2019-01-16 20:33:15.846556: step 3393, loss = 0.67521 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 20:33:16.734676 ops/training.py:65 2019-01-16 20:33:16.734622: step 3394, loss = 0.69343 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:33:17.625695 ops/training.py:65 2019-01-16 20:33:17.625632: step 3395, loss = 0.69223 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:33:18.515795 ops/training.py:65 2019-01-16 20:33:18.515681: step 3396, loss = 0.68104 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:33:19.408511 ops/training.py:65 2019-01-16 20:33:19.408412: step 3397, loss = 0.71280 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:33:20.300689 ops/training.py:65 2019-01-16 20:33:20.300583: step 3398, loss = 0.68223 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:33:21.191754 ops/training.py:65 2019-01-16 20:33:21.191659: step 3399, loss = 0.69982 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:33:22.080550 ops/training.py:65 2019-01-16 20:33:22.080480: step 3400, loss = 0.69378 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:33:22.970337 ops/training.py:65 2019-01-16 20:33:22.970270: step 3401, loss = 0.71389 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:33:23.858542 ops/training.py:65 2019-01-16 20:33:23.858474: step 3402, loss = 0.67732 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:33:24.746920 ops/training.py:65 2019-01-16 20:33:24.746853: step 3403, loss = 0.68409 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:33:25.635097 ops/training.py:65 2019-01-16 20:33:25.635033: step 3404, loss = 0.68952 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:33:26.523041 ops/training.py:65 2019-01-16 20:33:26.522975: step 3405, loss = 0.67904 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:33:27.411746 ops/training.py:65 2019-01-16 20:33:27.411680: step 3406, loss = 0.72251 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:33:28.299817 ops/training.py:65 2019-01-16 20:33:28.299750: step 3407, loss = 0.72077 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:33:29.189986 ops/training.py:65 2019-01-16 20:33:29.189905: step 3408, loss = 0.69924 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:33:30.081493 ops/training.py:65 2019-01-16 20:33:30.081389: step 3409, loss = 0.70897 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:33:30.973723 ops/training.py:65 2019-01-16 20:33:30.973629: step 3410, loss = 0.69435 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:33:31.863171 ops/training.py:65 2019-01-16 20:33:31.863100: step 3411, loss = 0.69030 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:33:32.752090 ops/training.py:65 2019-01-16 20:33:32.752012: step 3412, loss = 0.69752 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:33:33.640337 ops/training.py:65 2019-01-16 20:33:33.640265: step 3413, loss = 0.67860 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:33:34.534650 ops/training.py:65 2019-01-16 20:33:34.534588: step 3414, loss = 0.76221 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:33:35.425897 ops/training.py:65 2019-01-16 20:33:35.425790: step 3415, loss = 0.68992 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:33:36.317722 ops/training.py:65 2019-01-16 20:33:36.317644: step 3416, loss = 0.70011 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:33:37.209433 ops/training.py:65 2019-01-16 20:33:37.209332: step 3417, loss = 0.69615 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:33:38.100052 ops/training.py:65 2019-01-16 20:33:38.099982: step 3418, loss = 0.66870 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:33:38.992214 ops/training.py:65 2019-01-16 20:33:38.992114: step 3419, loss = 0.72118 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:33:39.885367 ops/training.py:65 2019-01-16 20:33:39.885294: step 3420, loss = 0.71149 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:33:40.776931 ops/training.py:65 2019-01-16 20:33:40.776889: step 3421, loss = 0.68104 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:33:41.668939 ops/training.py:65 2019-01-16 20:33:41.668862: step 3422, loss = 0.70665 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:33:42.561010 ops/training.py:65 2019-01-16 20:33:42.560904: step 3423, loss = 0.67479 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:33:43.455416 ops/training.py:65 2019-01-16 20:33:43.455323: step 3424, loss = 0.69295 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:33:44.347593 ops/training.py:65 2019-01-16 20:33:44.347490: step 3425, loss = 0.67617 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:33:45.238501 ops/training.py:65 2019-01-16 20:33:45.238404: step 3426, loss = 0.70331 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:33:46.126666 ops/training.py:65 2019-01-16 20:33:46.126600: step 3427, loss = 0.69436 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:33:47.014778 ops/training.py:65 2019-01-16 20:33:47.014707: step 3428, loss = 0.70435 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:33:47.906302 ops/training.py:65 2019-01-16 20:33:47.906233: step 3429, loss = 0.74290 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:33:48.797767 ops/training.py:65 2019-01-16 20:33:48.797672: step 3430, loss = 0.70927 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:33:49.688958 ops/training.py:65 2019-01-16 20:33:49.688874: step 3431, loss = 0.70129 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:33:50.578016 ops/training.py:65 2019-01-16 20:33:50.577945: step 3432, loss = 0.68978 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:33:51.466895 ops/training.py:65 2019-01-16 20:33:51.466825: step 3433, loss = 0.70011 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:33:52.355516 ops/training.py:65 2019-01-16 20:33:52.355441: step 3434, loss = 0.68969 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:33:53.246569 ops/training.py:65 2019-01-16 20:33:53.246493: step 3435, loss = 0.69751 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:33:54.138309 ops/training.py:65 2019-01-16 20:33:54.138207: step 3436, loss = 0.68646 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:33:55.028829 ops/training.py:65 2019-01-16 20:33:55.028747: step 3437, loss = 0.69899 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:33:55.919180 ops/training.py:65 2019-01-16 20:33:55.919115: step 3438, loss = 0.72212 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:33:56.807552 ops/training.py:65 2019-01-16 20:33:56.807489: step 3439, loss = 0.69606 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:33:57.696392 ops/training.py:65 2019-01-16 20:33:57.696334: step 3440, loss = 0.68624 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:33:58.585149 ops/training.py:65 2019-01-16 20:33:58.585091: step 3441, loss = 0.70002 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:33:59.474106 ops/training.py:65 2019-01-16 20:33:59.474043: step 3442, loss = 0.65704 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:34:00.362215 ops/training.py:65 2019-01-16 20:34:00.362155: step 3443, loss = 0.72252 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:34:01.253023 ops/training.py:65 2019-01-16 20:34:01.252976: step 3444, loss = 0.67705 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:34:02.143733 ops/training.py:65 2019-01-16 20:34:02.143648: step 3445, loss = 0.70343 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:34:03.036651 ops/training.py:65 2019-01-16 20:34:03.036548: step 3446, loss = 0.68990 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:34:03.927411 ops/training.py:65 2019-01-16 20:34:03.927316: step 3447, loss = 0.69345 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:34:04.818884 ops/training.py:65 2019-01-16 20:34:04.818784: step 3448, loss = 0.72585 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:34:05.709201 ops/training.py:65 2019-01-16 20:34:05.709131: step 3449, loss = 0.67383 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:34:06.599438 ops/training.py:65 2019-01-16 20:34:06.599362: step 3450, loss = 0.73364 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:34:07.488345 ops/training.py:65 2019-01-16 20:34:07.488281: step 3451, loss = 0.75556 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:34:08.376105 ops/training.py:65 2019-01-16 20:34:08.376048: step 3452, loss = 0.75787 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:34:09.265133 ops/training.py:65 2019-01-16 20:34:09.265075: step 3453, loss = 0.72771 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:34:10.154307 ops/training.py:65 2019-01-16 20:34:10.154241: step 3454, loss = 0.68942 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:34:11.042887 ops/training.py:65 2019-01-16 20:34:11.042822: step 3455, loss = 0.72550 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:34:11.931048 ops/training.py:65 2019-01-16 20:34:11.930977: step 3456, loss = 0.73489 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:34:12.819525 ops/training.py:65 2019-01-16 20:34:12.819458: step 3457, loss = 0.69037 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:34:13.708756 ops/training.py:65 2019-01-16 20:34:13.708685: step 3458, loss = 0.69017 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:34:14.597816 ops/training.py:65 2019-01-16 20:34:14.597753: step 3459, loss = 0.67213 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:34:15.486667 ops/training.py:65 2019-01-16 20:34:15.486599: step 3460, loss = 0.75273 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:34:16.375759 ops/training.py:65 2019-01-16 20:34:16.375692: step 3461, loss = 0.73907 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:34:17.265020 ops/training.py:65 2019-01-16 20:34:17.264962: step 3462, loss = 0.71071 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:34:18.154112 ops/training.py:65 2019-01-16 20:34:18.154049: step 3463, loss = 0.71853 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:34:19.042964 ops/training.py:65 2019-01-16 20:34:19.042904: step 3464, loss = 0.63856 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:34:19.931218 ops/training.py:65 2019-01-16 20:34:19.931152: step 3465, loss = 0.77379 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:34:20.820115 ops/training.py:65 2019-01-16 20:34:20.820048: step 3466, loss = 0.72336 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:34:21.708660 ops/training.py:65 2019-01-16 20:34:21.708596: step 3467, loss = 0.68208 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:34:22.597508 ops/training.py:65 2019-01-16 20:34:22.597449: step 3468, loss = 0.74078 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:34:23.485765 ops/training.py:65 2019-01-16 20:34:23.485705: step 3469, loss = 0.70405 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:34:24.374221 ops/training.py:65 2019-01-16 20:34:24.374169: step 3470, loss = 0.67286 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:34:25.263006 ops/training.py:65 2019-01-16 20:34:25.262945: step 3471, loss = 0.71015 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:34:26.152154 ops/training.py:65 2019-01-16 20:34:26.152091: step 3472, loss = 0.68893 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:34:27.040386 ops/training.py:65 2019-01-16 20:34:27.040320: step 3473, loss = 0.82462 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:34:27.929211 ops/training.py:65 2019-01-16 20:34:27.929142: step 3474, loss = 0.69428 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:34:28.818110 ops/training.py:65 2019-01-16 20:34:28.818043: step 3475, loss = 0.69339 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:34:29.706388 ops/training.py:65 2019-01-16 20:34:29.706325: step 3476, loss = 0.67707 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:34:30.594779 ops/training.py:65 2019-01-16 20:34:30.594717: step 3477, loss = 0.73826 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:34:31.482862 ops/training.py:65 2019-01-16 20:34:31.482800: step 3478, loss = 0.72653 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:34:32.370598 ops/training.py:65 2019-01-16 20:34:32.370522: step 3479, loss = 0.75427 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:34:33.259483 ops/training.py:65 2019-01-16 20:34:33.259413: step 3480, loss = 0.69018 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:34:34.148078 ops/training.py:65 2019-01-16 20:34:34.148008: step 3481, loss = 0.64162 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:34:35.036653 ops/training.py:65 2019-01-16 20:34:35.036589: step 3482, loss = 0.71206 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:34:35.925083 ops/training.py:65 2019-01-16 20:34:35.925014: step 3483, loss = 0.79020 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.25
I2992 2019-01-16 20:34:36.813695 ops/training.py:65 2019-01-16 20:34:36.813623: step 3484, loss = 0.70714 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:34:37.702231 ops/training.py:65 2019-01-16 20:34:37.702158: step 3485, loss = 0.75878 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:34:38.593482 ops/training.py:65 2019-01-16 20:34:38.593411: step 3486, loss = 0.73579 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:34:39.484936 ops/training.py:65 2019-01-16 20:34:39.484831: step 3487, loss = 0.75009 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:34:40.377320 ops/training.py:65 2019-01-16 20:34:40.377214: step 3488, loss = 0.69095 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:34:41.267302 ops/training.py:65 2019-01-16 20:34:41.267240: step 3489, loss = 0.70535 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:34:42.155520 ops/training.py:65 2019-01-16 20:34:42.155458: step 3490, loss = 0.70622 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:34:43.045640 ops/training.py:65 2019-01-16 20:34:43.045569: step 3491, loss = 0.67446 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:34:43.937225 ops/training.py:65 2019-01-16 20:34:43.937121: step 3492, loss = 0.70265 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:34:44.828168 ops/training.py:65 2019-01-16 20:34:44.828071: step 3493, loss = 0.67836 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:34:45.716632 ops/training.py:65 2019-01-16 20:34:45.716564: step 3494, loss = 0.71721 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:34:46.604765 ops/training.py:65 2019-01-16 20:34:46.604704: step 3495, loss = 0.68643 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:34:47.493368 ops/training.py:65 2019-01-16 20:34:47.493303: step 3496, loss = 0.72806 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:34:48.381386 ops/training.py:65 2019-01-16 20:34:48.381327: step 3497, loss = 0.68128 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:34:49.269424 ops/training.py:65 2019-01-16 20:34:49.269359: step 3498, loss = 0.69840 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:34:50.157412 ops/training.py:65 2019-01-16 20:34:50.157352: step 3499, loss = 0.71682 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:34:51.045587 ops/training.py:65 2019-01-16 20:34:51.045526: step 3500, loss = 0.69660 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:34:51.934259 ops/training.py:65 2019-01-16 20:34:51.934193: step 3501, loss = 0.69618 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:34:52.824301 ops/training.py:65 2019-01-16 20:34:52.824237: step 3502, loss = 0.77943 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.25
I2992 2019-01-16 20:34:53.712833 ops/training.py:65 2019-01-16 20:34:53.712766: step 3503, loss = 0.68892 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:34:54.601243 ops/training.py:65 2019-01-16 20:34:54.601187: step 3504, loss = 0.69020 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:34:55.489915 ops/training.py:65 2019-01-16 20:34:55.489854: step 3505, loss = 0.67824 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:34:56.379479 ops/training.py:65 2019-01-16 20:34:56.379414: step 3506, loss = 0.68682 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:34:57.270082 ops/training.py:65 2019-01-16 20:34:57.269969: step 3507, loss = 0.70149 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:34:58.163165 ops/training.py:65 2019-01-16 20:34:58.163124: step 3508, loss = 0.70564 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:34:59.054288 ops/training.py:65 2019-01-16 20:34:59.054209: step 3509, loss = 0.71456 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:34:59.946627 ops/training.py:65 2019-01-16 20:34:59.946521: step 3510, loss = 0.70655 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:35:00.837050 ops/training.py:65 2019-01-16 20:35:00.836981: step 3511, loss = 0.67329 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:35:01.725578 ops/training.py:65 2019-01-16 20:35:01.725505: step 3512, loss = 0.69739 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:35:02.614619 ops/training.py:65 2019-01-16 20:35:02.614544: step 3513, loss = 0.66553 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:35:03.508617 ops/training.py:65 2019-01-16 20:35:03.508535: step 3514, loss = 0.71931 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:35:04.400990 ops/training.py:65 2019-01-16 20:35:04.400896: step 3515, loss = 0.71388 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:35:05.290788 ops/training.py:65 2019-01-16 20:35:05.290691: step 3516, loss = 0.67518 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:35:06.179593 ops/training.py:65 2019-01-16 20:35:06.179526: step 3517, loss = 0.70081 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:35:07.067873 ops/training.py:65 2019-01-16 20:35:07.067801: step 3518, loss = 0.75999 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:35:07.956594 ops/training.py:65 2019-01-16 20:35:07.956525: step 3519, loss = 0.70359 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:35:08.845785 ops/training.py:65 2019-01-16 20:35:08.845721: step 3520, loss = 0.67775 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:35:09.734411 ops/training.py:65 2019-01-16 20:35:09.734349: step 3521, loss = 0.63414 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:35:10.622074 ops/training.py:65 2019-01-16 20:35:10.622012: step 3522, loss = 0.71045 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:35:11.509686 ops/training.py:65 2019-01-16 20:35:11.509620: step 3523, loss = 0.70820 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:35:12.397717 ops/training.py:65 2019-01-16 20:35:12.397653: step 3524, loss = 0.70929 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:35:13.285577 ops/training.py:65 2019-01-16 20:35:13.285505: step 3525, loss = 0.71059 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:35:14.174212 ops/training.py:65 2019-01-16 20:35:14.174145: step 3526, loss = 0.73020 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:35:15.064516 ops/training.py:65 2019-01-16 20:35:15.064443: step 3527, loss = 0.69992 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:35:15.956964 ops/training.py:65 2019-01-16 20:35:15.956863: step 3528, loss = 0.74441 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:35:16.848097 ops/training.py:65 2019-01-16 20:35:16.848027: step 3529, loss = 0.73120 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:35:17.737287 ops/training.py:65 2019-01-16 20:35:17.737224: step 3530, loss = 0.72586 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:35:18.626075 ops/training.py:65 2019-01-16 20:35:18.626013: step 3531, loss = 0.70068 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:35:19.514981 ops/training.py:65 2019-01-16 20:35:19.514916: step 3532, loss = 0.67630 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:35:20.404362 ops/training.py:65 2019-01-16 20:35:20.404300: step 3533, loss = 0.66963 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:35:21.292710 ops/training.py:65 2019-01-16 20:35:21.292645: step 3534, loss = 0.65756 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:35:22.181250 ops/training.py:65 2019-01-16 20:35:22.181185: step 3535, loss = 0.76386 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:35:23.070143 ops/training.py:65 2019-01-16 20:35:23.070078: step 3536, loss = 0.71556 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:35:23.958271 ops/training.py:65 2019-01-16 20:35:23.958205: step 3537, loss = 0.79328 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:35:24.846984 ops/training.py:65 2019-01-16 20:35:24.846924: step 3538, loss = 0.77337 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:35:25.735432 ops/training.py:65 2019-01-16 20:35:25.735373: step 3539, loss = 0.66083 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:35:26.626737 ops/training.py:65 2019-01-16 20:35:26.626672: step 3540, loss = 0.65367 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:35:27.519254 ops/training.py:65 2019-01-16 20:35:27.519151: step 3541, loss = 0.68449 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:35:28.411932 ops/training.py:65 2019-01-16 20:35:28.411827: step 3542, loss = 0.71866 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:35:29.302689 ops/training.py:65 2019-01-16 20:35:29.302621: step 3543, loss = 0.76281 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:35:30.191482 ops/training.py:65 2019-01-16 20:35:30.191409: step 3544, loss = 0.69370 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:35:31.080594 ops/training.py:65 2019-01-16 20:35:31.080518: step 3545, loss = 0.82714 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:35:31.970836 ops/training.py:65 2019-01-16 20:35:31.970732: step 3546, loss = 0.72220 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:35:32.860381 ops/training.py:65 2019-01-16 20:35:32.860312: step 3547, loss = 0.72623 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:35:33.749266 ops/training.py:65 2019-01-16 20:35:33.749195: step 3548, loss = 0.73626 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:35:34.637349 ops/training.py:65 2019-01-16 20:35:34.637281: step 3549, loss = 0.70681 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:35:35.526097 ops/training.py:65 2019-01-16 20:35:35.526029: step 3550, loss = 0.66543 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:35:36.414594 ops/training.py:65 2019-01-16 20:35:36.414529: step 3551, loss = 0.66881 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:35:37.303463 ops/training.py:65 2019-01-16 20:35:37.303396: step 3552, loss = 0.78420 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:35:38.192020 ops/training.py:65 2019-01-16 20:35:38.191956: step 3553, loss = 0.66518 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:35:39.080103 ops/training.py:65 2019-01-16 20:35:39.080045: step 3554, loss = 0.75353 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:35:39.968438 ops/training.py:65 2019-01-16 20:35:39.968375: step 3555, loss = 0.65157 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:35:40.857337 ops/training.py:65 2019-01-16 20:35:40.857269: step 3556, loss = 0.74482 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:35:41.749342 ops/training.py:65 2019-01-16 20:35:41.749281: step 3557, loss = 0.70746 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:35:42.640639 ops/training.py:65 2019-01-16 20:35:42.640531: step 3558, loss = 0.69838 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:35:43.531906 ops/training.py:65 2019-01-16 20:35:43.531840: step 3559, loss = 0.70932 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:35:44.421920 ops/training.py:65 2019-01-16 20:35:44.421858: step 3560, loss = 0.71145 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:35:45.312252 ops/training.py:65 2019-01-16 20:35:45.312175: step 3561, loss = 0.72296 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:35:46.201859 ops/training.py:65 2019-01-16 20:35:46.201772: step 3562, loss = 0.71384 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:35:47.093740 ops/training.py:65 2019-01-16 20:35:47.093655: step 3563, loss = 0.68973 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:35:47.985515 ops/training.py:65 2019-01-16 20:35:47.985411: step 3564, loss = 0.71181 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:35:48.875378 ops/training.py:65 2019-01-16 20:35:48.875290: step 3565, loss = 0.69010 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:35:49.765778 ops/training.py:65 2019-01-16 20:35:49.765711: step 3566, loss = 0.68728 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:35:50.655362 ops/training.py:65 2019-01-16 20:35:50.655289: step 3567, loss = 0.70586 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:35:51.544652 ops/training.py:65 2019-01-16 20:35:51.544582: step 3568, loss = 0.66839 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:35:52.433679 ops/training.py:65 2019-01-16 20:35:52.433576: step 3569, loss = 0.72224 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:35:53.323974 ops/training.py:65 2019-01-16 20:35:53.323889: step 3570, loss = 0.68964 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:35:54.218270 ops/training.py:65 2019-01-16 20:35:54.218187: step 3571, loss = 0.74287 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:35:55.109683 ops/training.py:65 2019-01-16 20:35:55.109584: step 3572, loss = 0.70424 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:35:56.001049 ops/training.py:65 2019-01-16 20:35:56.000949: step 3573, loss = 0.72772 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:35:56.890694 ops/training.py:65 2019-01-16 20:35:56.890601: step 3574, loss = 0.72000 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:35:57.785734 ops/training.py:65 2019-01-16 20:35:57.785657: step 3575, loss = 0.67322 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:35:58.678289 ops/training.py:65 2019-01-16 20:35:58.678187: step 3576, loss = 0.71801 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:35:59.569594 ops/training.py:65 2019-01-16 20:35:59.569526: step 3577, loss = 0.70930 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:36:00.462004 ops/training.py:65 2019-01-16 20:36:00.461942: step 3578, loss = 0.70195 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:36:01.354065 ops/training.py:65 2019-01-16 20:36:01.353960: step 3579, loss = 0.71213 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:36:02.245535 ops/training.py:65 2019-01-16 20:36:02.245444: step 3580, loss = 0.68251 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:36:03.135322 ops/training.py:65 2019-01-16 20:36:03.135255: step 3581, loss = 0.69085 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:36:04.023918 ops/training.py:65 2019-01-16 20:36:04.023854: step 3582, loss = 0.68746 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:36:04.913159 ops/training.py:65 2019-01-16 20:36:04.913096: step 3583, loss = 0.69936 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:36:05.801412 ops/training.py:65 2019-01-16 20:36:05.801348: step 3584, loss = 0.70570 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:36:06.689030 ops/training.py:65 2019-01-16 20:36:06.688966: step 3585, loss = 0.68612 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:36:07.576741 ops/training.py:65 2019-01-16 20:36:07.576675: step 3586, loss = 0.72984 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:36:08.465415 ops/training.py:65 2019-01-16 20:36:08.465349: step 3587, loss = 0.70926 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:36:09.354493 ops/training.py:65 2019-01-16 20:36:09.354431: step 3588, loss = 0.67799 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:36:10.243456 ops/training.py:65 2019-01-16 20:36:10.243395: step 3589, loss = 0.68820 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:36:11.133098 ops/training.py:65 2019-01-16 20:36:11.133031: step 3590, loss = 0.67847 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:36:12.024608 ops/training.py:65 2019-01-16 20:36:12.024508: step 3591, loss = 0.69407 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:36:12.917136 ops/training.py:65 2019-01-16 20:36:12.917052: step 3592, loss = 0.72139 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:36:13.808905 ops/training.py:65 2019-01-16 20:36:13.808809: step 3593, loss = 0.69429 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:36:14.700713 ops/training.py:65 2019-01-16 20:36:14.700620: step 3594, loss = 0.70502 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:36:15.589381 ops/training.py:65 2019-01-16 20:36:15.589313: step 3595, loss = 0.70131 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:36:16.478375 ops/training.py:65 2019-01-16 20:36:16.478308: step 3596, loss = 0.71203 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:36:17.367177 ops/training.py:65 2019-01-16 20:36:17.367116: step 3597, loss = 0.71032 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:36:18.256393 ops/training.py:65 2019-01-16 20:36:18.256325: step 3598, loss = 0.71284 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:36:19.146149 ops/training.py:65 2019-01-16 20:36:19.146079: step 3599, loss = 0.70665 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:36:20.035227 ops/training.py:65 2019-01-16 20:36:20.035160: step 3600, loss = 0.71970 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:36:20.924515 ops/training.py:65 2019-01-16 20:36:20.924450: step 3601, loss = 0.70625 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:36:21.813380 ops/training.py:65 2019-01-16 20:36:21.813316: step 3602, loss = 0.71304 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:36:22.702007 ops/training.py:65 2019-01-16 20:36:22.701942: step 3603, loss = 0.69156 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:36:23.591057 ops/training.py:65 2019-01-16 20:36:23.590991: step 3604, loss = 0.68453 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:36:24.480537 ops/training.py:65 2019-01-16 20:36:24.480473: step 3605, loss = 0.67996 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:36:25.369312 ops/training.py:65 2019-01-16 20:36:25.369251: step 3606, loss = 0.72180 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:36:26.257353 ops/training.py:65 2019-01-16 20:36:26.257288: step 3607, loss = 0.69938 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:36:27.146364 ops/training.py:65 2019-01-16 20:36:27.146298: step 3608, loss = 0.72487 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:36:28.035862 ops/training.py:65 2019-01-16 20:36:28.035798: step 3609, loss = 0.69212 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:36:28.925879 ops/training.py:65 2019-01-16 20:36:28.925808: step 3610, loss = 0.67757 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:36:29.817900 ops/training.py:65 2019-01-16 20:36:29.817798: step 3611, loss = 0.71050 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:36:30.709580 ops/training.py:65 2019-01-16 20:36:30.709488: step 3612, loss = 0.67886 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:36:31.599126 ops/training.py:65 2019-01-16 20:36:31.599059: step 3613, loss = 0.71406 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:36:32.488081 ops/training.py:65 2019-01-16 20:36:32.488018: step 3614, loss = 0.71008 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:36:33.376702 ops/training.py:65 2019-01-16 20:36:33.376640: step 3615, loss = 0.68345 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:36:34.265795 ops/training.py:65 2019-01-16 20:36:34.265732: step 3616, loss = 0.65963 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 20:36:35.154444 ops/training.py:65 2019-01-16 20:36:35.154384: step 3617, loss = 0.73142 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:36:36.044409 ops/training.py:65 2019-01-16 20:36:36.044348: step 3618, loss = 0.66494 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:36:36.933418 ops/training.py:65 2019-01-16 20:36:36.933358: step 3619, loss = 0.71834 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:36:37.822173 ops/training.py:65 2019-01-16 20:36:37.822105: step 3620, loss = 0.71068 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:36:38.711331 ops/training.py:65 2019-01-16 20:36:38.711268: step 3621, loss = 0.74147 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 20:36:39.600410 ops/training.py:65 2019-01-16 20:36:39.600350: step 3622, loss = 0.70419 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:36:40.489790 ops/training.py:65 2019-01-16 20:36:40.489733: step 3623, loss = 0.68142 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:36:41.378930 ops/training.py:65 2019-01-16 20:36:41.378867: step 3624, loss = 0.70556 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:36:42.269958 ops/training.py:65 2019-01-16 20:36:42.269880: step 3625, loss = 0.74757 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:36:43.162616 ops/training.py:65 2019-01-16 20:36:43.162515: step 3626, loss = 0.67306 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:36:44.054863 ops/training.py:65 2019-01-16 20:36:44.054765: step 3627, loss = 0.69606 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:36:44.944621 ops/training.py:65 2019-01-16 20:36:44.944560: step 3628, loss = 0.74991 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:36:45.833196 ops/training.py:65 2019-01-16 20:36:45.833132: step 3629, loss = 0.71473 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:36:46.722276 ops/training.py:65 2019-01-16 20:36:46.722209: step 3630, loss = 0.71879 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:36:47.612508 ops/training.py:65 2019-01-16 20:36:47.612442: step 3631, loss = 0.71992 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:36:48.505128 ops/training.py:65 2019-01-16 20:36:48.505020: step 3632, loss = 0.70319 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:36:49.397131 ops/training.py:65 2019-01-16 20:36:49.397044: step 3633, loss = 0.69218 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:36:50.286242 ops/training.py:65 2019-01-16 20:36:50.286179: step 3634, loss = 0.74141 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:36:51.175780 ops/training.py:65 2019-01-16 20:36:51.175714: step 3635, loss = 0.67324 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:36:52.065072 ops/training.py:65 2019-01-16 20:36:52.065011: step 3636, loss = 0.71472 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:36:52.954466 ops/training.py:65 2019-01-16 20:36:52.954402: step 3637, loss = 0.66682 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:36:53.843509 ops/training.py:65 2019-01-16 20:36:53.843440: step 3638, loss = 0.68379 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:36:54.732310 ops/training.py:65 2019-01-16 20:36:54.732246: step 3639, loss = 0.69848 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:36:55.621927 ops/training.py:65 2019-01-16 20:36:55.621861: step 3640, loss = 0.71037 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:36:56.510723 ops/training.py:65 2019-01-16 20:36:56.510659: step 3641, loss = 0.69216 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:36:57.401918 ops/training.py:65 2019-01-16 20:36:57.401856: step 3642, loss = 0.74724 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.21875
I2992 2019-01-16 20:36:58.293577 ops/training.py:65 2019-01-16 20:36:58.293473: step 3643, loss = 0.67566 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:36:59.185748 ops/training.py:65 2019-01-16 20:36:59.185656: step 3644, loss = 0.69671 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:37:00.075946 ops/training.py:65 2019-01-16 20:37:00.075882: step 3645, loss = 0.70430 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:37:00.965661 ops/training.py:65 2019-01-16 20:37:00.965592: step 3646, loss = 0.73503 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:37:01.854411 ops/training.py:65 2019-01-16 20:37:01.854346: step 3647, loss = 0.68843 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:37:02.743331 ops/training.py:65 2019-01-16 20:37:02.743267: step 3648, loss = 0.71668 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:37:03.634591 ops/training.py:65 2019-01-16 20:37:03.634518: step 3649, loss = 0.70880 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:37:04.525733 ops/training.py:65 2019-01-16 20:37:04.525635: step 3650, loss = 0.68471 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:37:05.417460 ops/training.py:65 2019-01-16 20:37:05.417358: step 3651, loss = 0.72402 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:37:06.309727 ops/training.py:65 2019-01-16 20:37:06.309670: step 3652, loss = 0.71140 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:37:07.203024 ops/training.py:65 2019-01-16 20:37:07.202929: step 3653, loss = 0.69582 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:37:08.095054 ops/training.py:65 2019-01-16 20:37:08.094954: step 3654, loss = 0.71187 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:37:08.986821 ops/training.py:65 2019-01-16 20:37:08.986729: step 3655, loss = 0.67687 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:37:09.876567 ops/training.py:65 2019-01-16 20:37:09.876506: step 3656, loss = 0.71140 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:37:10.764430 ops/training.py:65 2019-01-16 20:37:10.764372: step 3657, loss = 0.74491 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:37:11.652124 ops/training.py:65 2019-01-16 20:37:11.652066: step 3658, loss = 0.69768 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:37:12.541520 ops/training.py:65 2019-01-16 20:37:12.541454: step 3659, loss = 0.67224 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:37:13.430102 ops/training.py:65 2019-01-16 20:37:13.430037: step 3660, loss = 0.68935 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:37:14.319248 ops/training.py:65 2019-01-16 20:37:14.319186: step 3661, loss = 0.70136 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:37:15.208859 ops/training.py:65 2019-01-16 20:37:15.208801: step 3662, loss = 0.68242 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:37:16.098372 ops/training.py:65 2019-01-16 20:37:16.098311: step 3663, loss = 0.70449 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:37:16.987821 ops/training.py:65 2019-01-16 20:37:16.987754: step 3664, loss = 0.72233 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:37:17.878040 ops/training.py:65 2019-01-16 20:37:17.877981: step 3665, loss = 0.70714 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:37:18.767105 ops/training.py:65 2019-01-16 20:37:18.767044: step 3666, loss = 0.70193 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:37:19.656623 ops/training.py:65 2019-01-16 20:37:19.656564: step 3667, loss = 0.69756 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:37:20.546410 ops/training.py:65 2019-01-16 20:37:20.546350: step 3668, loss = 0.71113 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:37:21.435528 ops/training.py:65 2019-01-16 20:37:21.435465: step 3669, loss = 0.68605 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:37:22.324528 ops/training.py:65 2019-01-16 20:37:22.324463: step 3670, loss = 0.69503 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:37:23.215915 ops/training.py:65 2019-01-16 20:37:23.215851: step 3671, loss = 0.68640 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:37:24.104953 ops/training.py:65 2019-01-16 20:37:24.104894: step 3672, loss = 0.69996 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:37:24.992990 ops/training.py:65 2019-01-16 20:37:24.992925: step 3673, loss = 0.70972 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:37:25.881936 ops/training.py:65 2019-01-16 20:37:25.881869: step 3674, loss = 0.71685 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:37:26.770740 ops/training.py:65 2019-01-16 20:37:26.770674: step 3675, loss = 0.68909 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:37:27.660039 ops/training.py:65 2019-01-16 20:37:27.659964: step 3676, loss = 0.69272 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:37:28.548440 ops/training.py:65 2019-01-16 20:37:28.548373: step 3677, loss = 0.71024 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:37:29.437344 ops/training.py:65 2019-01-16 20:37:29.437279: step 3678, loss = 0.72538 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:37:30.326200 ops/training.py:65 2019-01-16 20:37:30.326138: step 3679, loss = 0.71778 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:37:31.215015 ops/training.py:65 2019-01-16 20:37:31.214953: step 3680, loss = 0.68665 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:37:32.104802 ops/training.py:65 2019-01-16 20:37:32.104742: step 3681, loss = 0.70801 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:37:32.993383 ops/training.py:65 2019-01-16 20:37:32.993307: step 3682, loss = 0.71105 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:37:33.883201 ops/training.py:65 2019-01-16 20:37:33.883136: step 3683, loss = 0.67539 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:37:34.772242 ops/training.py:65 2019-01-16 20:37:34.772177: step 3684, loss = 0.69764 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:37:35.661712 ops/training.py:65 2019-01-16 20:37:35.661648: step 3685, loss = 0.71016 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:37:36.555137 ops/training.py:65 2019-01-16 20:37:36.555066: step 3686, loss = 0.68692 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:37:37.445728 ops/training.py:65 2019-01-16 20:37:37.445627: step 3687, loss = 0.68561 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:37:38.338134 ops/training.py:65 2019-01-16 20:37:38.338041: step 3688, loss = 0.70698 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:37:39.227958 ops/training.py:65 2019-01-16 20:37:39.227861: step 3689, loss = 0.68866 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:37:40.117177 ops/training.py:65 2019-01-16 20:37:40.117114: step 3690, loss = 0.71756 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:37:41.005861 ops/training.py:65 2019-01-16 20:37:41.005803: step 3691, loss = 0.71167 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:37:41.894370 ops/training.py:65 2019-01-16 20:37:41.894301: step 3692, loss = 0.73513 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.25
I2992 2019-01-16 20:37:42.783221 ops/training.py:65 2019-01-16 20:37:42.783154: step 3693, loss = 0.69233 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:37:43.672756 ops/training.py:65 2019-01-16 20:37:43.672691: step 3694, loss = 0.68776 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:37:44.566118 ops/training.py:65 2019-01-16 20:37:44.566045: step 3695, loss = 0.68539 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:37:45.458261 ops/training.py:65 2019-01-16 20:37:45.458154: step 3696, loss = 0.68705 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:37:46.349619 ops/training.py:65 2019-01-16 20:37:46.349522: step 3697, loss = 0.69400 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:37:47.240165 ops/training.py:65 2019-01-16 20:37:47.240100: step 3698, loss = 0.71604 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:37:48.134142 ops/training.py:65 2019-01-16 20:37:48.134072: step 3699, loss = 0.68356 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:37:49.026147 ops/training.py:65 2019-01-16 20:37:49.026055: step 3700, loss = 0.71949 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:37:49.917509 ops/training.py:65 2019-01-16 20:37:49.917382: step 3701, loss = 0.70401 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:37:50.806817 ops/training.py:65 2019-01-16 20:37:50.806754: step 3702, loss = 0.71819 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:37:51.695622 ops/training.py:65 2019-01-16 20:37:51.695555: step 3703, loss = 0.66579 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:37:52.586636 ops/training.py:65 2019-01-16 20:37:52.586573: step 3704, loss = 0.72077 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:37:53.478925 ops/training.py:65 2019-01-16 20:37:53.478826: step 3705, loss = 0.67494 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:37:54.370877 ops/training.py:65 2019-01-16 20:37:54.370772: step 3706, loss = 0.65433 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:37:55.262485 ops/training.py:65 2019-01-16 20:37:55.262414: step 3707, loss = 0.67424 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:37:56.151842 ops/training.py:65 2019-01-16 20:37:56.151780: step 3708, loss = 0.70060 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:37:57.040871 ops/training.py:65 2019-01-16 20:37:57.040776: step 3709, loss = 0.71602 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:37:57.930600 ops/training.py:65 2019-01-16 20:37:57.930492: step 3710, loss = 0.71487 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:37:58.821179 ops/training.py:65 2019-01-16 20:37:58.821108: step 3711, loss = 0.70039 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:37:59.714918 ops/training.py:65 2019-01-16 20:37:59.714822: step 3712, loss = 0.73779 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:38:00.607210 ops/training.py:65 2019-01-16 20:38:00.607104: step 3713, loss = 0.68599 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:38:01.496889 ops/training.py:65 2019-01-16 20:38:01.496800: step 3714, loss = 0.68182 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:38:02.385931 ops/training.py:65 2019-01-16 20:38:02.385865: step 3715, loss = 0.69841 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:38:03.275093 ops/training.py:65 2019-01-16 20:38:03.275024: step 3716, loss = 0.71148 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:38:04.163803 ops/training.py:65 2019-01-16 20:38:04.163739: step 3717, loss = 0.68447 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:38:05.052893 ops/training.py:65 2019-01-16 20:38:05.052832: step 3718, loss = 0.71276 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:38:05.941898 ops/training.py:65 2019-01-16 20:38:05.941838: step 3719, loss = 0.70131 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:38:06.830037 ops/training.py:65 2019-01-16 20:38:06.829966: step 3720, loss = 0.67949 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:38:07.719460 ops/training.py:65 2019-01-16 20:38:07.719394: step 3721, loss = 0.71424 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:38:08.608097 ops/training.py:65 2019-01-16 20:38:08.608033: step 3722, loss = 0.72313 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:38:09.496826 ops/training.py:65 2019-01-16 20:38:09.496761: step 3723, loss = 0.71135 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:38:10.385091 ops/training.py:65 2019-01-16 20:38:10.385028: step 3724, loss = 0.66876 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:38:11.273643 ops/training.py:65 2019-01-16 20:38:11.273579: step 3725, loss = 0.70590 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:38:12.162815 ops/training.py:65 2019-01-16 20:38:12.162754: step 3726, loss = 0.70476 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:38:13.053262 ops/training.py:65 2019-01-16 20:38:13.053197: step 3727, loss = 0.68002 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:38:13.943449 ops/training.py:65 2019-01-16 20:38:13.943383: step 3728, loss = 0.69792 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:38:14.832319 ops/training.py:65 2019-01-16 20:38:14.832250: step 3729, loss = 0.68525 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:38:15.720727 ops/training.py:65 2019-01-16 20:38:15.720661: step 3730, loss = 0.71473 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:38:16.609711 ops/training.py:65 2019-01-16 20:38:16.609642: step 3731, loss = 0.73453 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.25
I2992 2019-01-16 20:38:17.498454 ops/training.py:65 2019-01-16 20:38:17.498393: step 3732, loss = 0.68758 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:38:18.386889 ops/training.py:65 2019-01-16 20:38:18.386830: step 3733, loss = 0.68207 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:38:19.276822 ops/training.py:65 2019-01-16 20:38:19.276760: step 3734, loss = 0.68188 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:38:20.165750 ops/training.py:65 2019-01-16 20:38:20.165688: step 3735, loss = 0.70967 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:38:21.054866 ops/training.py:65 2019-01-16 20:38:21.054801: step 3736, loss = 0.68872 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:38:21.942648 ops/training.py:65 2019-01-16 20:38:21.942590: step 3737, loss = 0.69499 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:38:22.832610 ops/training.py:65 2019-01-16 20:38:22.832549: step 3738, loss = 0.70047 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:38:23.722643 ops/training.py:65 2019-01-16 20:38:23.722574: step 3739, loss = 0.66830 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:38:24.611486 ops/training.py:65 2019-01-16 20:38:24.611421: step 3740, loss = 0.65487 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:38:25.500828 ops/training.py:65 2019-01-16 20:38:25.500762: step 3741, loss = 0.71182 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:38:26.389107 ops/training.py:65 2019-01-16 20:38:26.389039: step 3742, loss = 0.67487 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:38:27.278639 ops/training.py:65 2019-01-16 20:38:27.278574: step 3743, loss = 0.68892 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:38:28.169821 ops/training.py:65 2019-01-16 20:38:28.169723: step 3744, loss = 0.69968 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:38:29.062562 ops/training.py:65 2019-01-16 20:38:29.062454: step 3745, loss = 0.68944 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:38:29.953497 ops/training.py:65 2019-01-16 20:38:29.953407: step 3746, loss = 0.69058 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:38:30.846027 ops/training.py:65 2019-01-16 20:38:30.845964: step 3747, loss = 0.70227 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:38:31.737018 ops/training.py:65 2019-01-16 20:38:31.736920: step 3748, loss = 0.71994 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:38:32.629387 ops/training.py:65 2019-01-16 20:38:32.629280: step 3749, loss = 0.67916 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:38:33.522463 ops/training.py:65 2019-01-16 20:38:33.522359: step 3750, loss = 0.70450 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:38:34.413406 ops/training.py:65 2019-01-16 20:38:34.413346: step 3751, loss = 0.68446 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:38:35.305038 ops/training.py:65 2019-01-16 20:38:35.304975: step 3752, loss = 0.67856 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:38:36.195635 ops/training.py:65 2019-01-16 20:38:36.195563: step 3753, loss = 0.68893 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:38:37.087206 ops/training.py:65 2019-01-16 20:38:37.087104: step 3754, loss = 0.69061 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:38:37.981090 ops/training.py:65 2019-01-16 20:38:37.980981: step 3755, loss = 0.69670 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:38:38.873316 ops/training.py:65 2019-01-16 20:38:38.873238: step 3756, loss = 0.68211 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:38:39.765445 ops/training.py:65 2019-01-16 20:38:39.765344: step 3757, loss = 0.71337 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:38:40.657198 ops/training.py:65 2019-01-16 20:38:40.657115: step 3758, loss = 0.70850 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:38:41.545582 ops/training.py:65 2019-01-16 20:38:41.545496: step 3759, loss = 0.69258 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:38:42.433904 ops/training.py:65 2019-01-16 20:38:42.433813: step 3760, loss = 0.69449 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:38:43.326473 ops/training.py:65 2019-01-16 20:38:43.326372: step 3761, loss = 0.71257 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:38:44.218068 ops/training.py:65 2019-01-16 20:38:44.217976: step 3762, loss = 0.70773 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:38:45.109594 ops/training.py:65 2019-01-16 20:38:45.109496: step 3763, loss = 0.69097 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:38:45.999671 ops/training.py:65 2019-01-16 20:38:45.999568: step 3764, loss = 0.69446 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:38:46.889943 ops/training.py:65 2019-01-16 20:38:46.889846: step 3765, loss = 0.72513 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:38:47.780304 ops/training.py:65 2019-01-16 20:38:47.780207: step 3766, loss = 0.68142 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:38:48.670416 ops/training.py:65 2019-01-16 20:38:48.670318: step 3767, loss = 0.72411 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:38:49.560476 ops/training.py:65 2019-01-16 20:38:49.560377: step 3768, loss = 0.68878 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:38:50.450055 ops/training.py:65 2019-01-16 20:38:50.449945: step 3769, loss = 0.66296 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:38:51.340491 ops/training.py:65 2019-01-16 20:38:51.340354: step 3770, loss = 0.69736 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:38:52.233074 ops/training.py:65 2019-01-16 20:38:52.232972: step 3771, loss = 0.70408 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:38:53.125041 ops/training.py:65 2019-01-16 20:38:53.124943: step 3772, loss = 0.66727 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:38:54.013825 ops/training.py:65 2019-01-16 20:38:54.013728: step 3773, loss = 0.66500 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:38:54.902652 ops/training.py:65 2019-01-16 20:38:54.902555: step 3774, loss = 0.69559 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:38:55.795433 ops/training.py:65 2019-01-16 20:38:55.795347: step 3775, loss = 0.70408 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:38:56.688022 ops/training.py:65 2019-01-16 20:38:56.687929: step 3776, loss = 0.71957 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:38:57.578497 ops/training.py:65 2019-01-16 20:38:57.578400: step 3777, loss = 0.69011 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:38:58.470691 ops/training.py:65 2019-01-16 20:38:58.470595: step 3778, loss = 0.67655 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:38:59.361777 ops/training.py:65 2019-01-16 20:38:59.361688: step 3779, loss = 0.71918 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:39:00.252376 ops/training.py:65 2019-01-16 20:39:00.252298: step 3780, loss = 0.68771 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:39:01.144218 ops/training.py:65 2019-01-16 20:39:01.144112: step 3781, loss = 0.68729 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:39:02.036055 ops/training.py:65 2019-01-16 20:39:02.035960: step 3782, loss = 0.71195 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:39:02.928458 ops/training.py:65 2019-01-16 20:39:02.928355: step 3783, loss = 0.69860 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:39:03.820007 ops/training.py:65 2019-01-16 20:39:03.819903: step 3784, loss = 0.67884 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:39:04.711036 ops/training.py:65 2019-01-16 20:39:04.710939: step 3785, loss = 0.72949 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:39:05.599991 ops/training.py:65 2019-01-16 20:39:05.599888: step 3786, loss = 0.72948 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:39:06.488529 ops/training.py:65 2019-01-16 20:39:06.488428: step 3787, loss = 0.71097 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:39:07.380588 ops/training.py:65 2019-01-16 20:39:07.380482: step 3788, loss = 0.69187 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:39:08.272608 ops/training.py:65 2019-01-16 20:39:08.272508: step 3789, loss = 0.69099 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:39:09.163104 ops/training.py:65 2019-01-16 20:39:09.163017: step 3790, loss = 0.69317 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:39:10.052951 ops/training.py:65 2019-01-16 20:39:10.052854: step 3791, loss = 0.70922 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:39:10.943642 ops/training.py:65 2019-01-16 20:39:10.943538: step 3792, loss = 0.69404 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:39:11.834927 ops/training.py:65 2019-01-16 20:39:11.834828: step 3793, loss = 0.72680 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:39:12.725544 ops/training.py:65 2019-01-16 20:39:12.725477: step 3794, loss = 0.70006 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:39:13.617353 ops/training.py:65 2019-01-16 20:39:13.617250: step 3795, loss = 0.71311 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:39:14.508310 ops/training.py:65 2019-01-16 20:39:14.508217: step 3796, loss = 0.69499 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:39:15.399418 ops/training.py:65 2019-01-16 20:39:15.399358: step 3797, loss = 0.70377 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:39:16.289194 ops/training.py:65 2019-01-16 20:39:16.289092: step 3798, loss = 0.71119 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:39:17.181219 ops/training.py:65 2019-01-16 20:39:17.181121: step 3799, loss = 0.71912 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:39:18.075241 ops/training.py:65 2019-01-16 20:39:18.075173: step 3800, loss = 0.70908 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:39:18.967206 ops/training.py:65 2019-01-16 20:39:18.967113: step 3801, loss = 0.68830 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:39:19.859877 ops/training.py:65 2019-01-16 20:39:19.859784: step 3802, loss = 0.67915 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:39:20.752010 ops/training.py:65 2019-01-16 20:39:20.751905: step 3803, loss = 0.69820 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:39:21.644568 ops/training.py:65 2019-01-16 20:39:21.644471: step 3804, loss = 0.69796 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:39:22.536243 ops/training.py:65 2019-01-16 20:39:22.536138: step 3805, loss = 0.69500 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:39:23.428906 ops/training.py:65 2019-01-16 20:39:23.428807: step 3806, loss = 0.70669 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:39:24.320927 ops/training.py:65 2019-01-16 20:39:24.320829: step 3807, loss = 0.69084 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:39:25.211002 ops/training.py:65 2019-01-16 20:39:25.210905: step 3808, loss = 0.71091 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:39:26.100649 ops/training.py:65 2019-01-16 20:39:26.100588: step 3809, loss = 0.70043 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:39:26.989335 ops/training.py:65 2019-01-16 20:39:26.989273: step 3810, loss = 0.72092 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:39:27.878775 ops/training.py:65 2019-01-16 20:39:27.878711: step 3811, loss = 0.68126 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:39:28.769482 ops/training.py:65 2019-01-16 20:39:28.769417: step 3812, loss = 0.67546 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:39:29.658099 ops/training.py:65 2019-01-16 20:39:29.658034: step 3813, loss = 0.73251 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:39:30.547754 ops/training.py:65 2019-01-16 20:39:30.547689: step 3814, loss = 0.68983 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:39:31.436083 ops/training.py:65 2019-01-16 20:39:31.436016: step 3815, loss = 0.70005 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:39:32.324126 ops/training.py:65 2019-01-16 20:39:32.324057: step 3816, loss = 0.69836 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:39:33.214001 ops/training.py:65 2019-01-16 20:39:33.213933: step 3817, loss = 0.69736 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:39:34.102301 ops/training.py:65 2019-01-16 20:39:34.102240: step 3818, loss = 0.68436 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:39:34.990301 ops/training.py:65 2019-01-16 20:39:34.990239: step 3819, loss = 0.68858 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:39:35.878316 ops/training.py:65 2019-01-16 20:39:35.878252: step 3820, loss = 0.71559 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:39:36.766466 ops/training.py:65 2019-01-16 20:39:36.766405: step 3821, loss = 0.69137 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:39:37.655031 ops/training.py:65 2019-01-16 20:39:37.654971: step 3822, loss = 0.67958 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:39:38.543766 ops/training.py:65 2019-01-16 20:39:38.543698: step 3823, loss = 0.68969 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:39:39.432093 ops/training.py:65 2019-01-16 20:39:39.432030: step 3824, loss = 0.69353 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:39:40.325407 ops/training.py:65 2019-01-16 20:39:40.325336: step 3825, loss = 0.68749 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:39:41.217399 ops/training.py:65 2019-01-16 20:39:41.217291: step 3826, loss = 0.66481 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:39:42.109945 ops/training.py:65 2019-01-16 20:39:42.109846: step 3827, loss = 0.69773 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:39:43.003830 ops/training.py:65 2019-01-16 20:39:43.003728: step 3828, loss = 0.67140 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:39:43.896067 ops/training.py:65 2019-01-16 20:39:43.895965: step 3829, loss = 0.68300 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:39:44.789348 ops/training.py:65 2019-01-16 20:39:44.789278: step 3830, loss = 0.69489 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:39:45.681302 ops/training.py:65 2019-01-16 20:39:45.681199: step 3831, loss = 0.69038 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:39:46.573674 ops/training.py:65 2019-01-16 20:39:46.573572: step 3832, loss = 0.69403 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:39:47.464694 ops/training.py:65 2019-01-16 20:39:47.464593: step 3833, loss = 0.69142 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:39:48.353349 ops/training.py:65 2019-01-16 20:39:48.353250: step 3834, loss = 0.70326 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:39:49.245766 ops/training.py:65 2019-01-16 20:39:49.245703: step 3835, loss = 0.69245 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:39:50.137389 ops/training.py:65 2019-01-16 20:39:50.137311: step 3836, loss = 0.69266 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:39:51.029831 ops/training.py:65 2019-01-16 20:39:51.029746: step 3837, loss = 0.67805 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:39:51.921792 ops/training.py:65 2019-01-16 20:39:51.921708: step 3838, loss = 0.69338 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:39:52.812571 ops/training.py:65 2019-01-16 20:39:52.812488: step 3839, loss = 0.69321 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:39:53.704263 ops/training.py:65 2019-01-16 20:39:53.704166: step 3840, loss = 0.72087 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:39:54.593739 ops/training.py:65 2019-01-16 20:39:54.593650: step 3841, loss = 0.69981 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:39:55.485667 ops/training.py:65 2019-01-16 20:39:55.485599: step 3842, loss = 0.68512 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:39:56.377934 ops/training.py:65 2019-01-16 20:39:56.377887: step 3843, loss = 0.69899 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:39:57.268647 ops/training.py:65 2019-01-16 20:39:57.268596: step 3844, loss = 0.69361 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:39:58.160118 ops/training.py:65 2019-01-16 20:39:58.160077: step 3845, loss = 0.68193 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:39:59.051157 ops/training.py:65 2019-01-16 20:39:59.051076: step 3846, loss = 0.69261 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:39:59.943140 ops/training.py:65 2019-01-16 20:39:59.943041: step 3847, loss = 0.69954 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:40:00.833961 ops/training.py:65 2019-01-16 20:40:00.833884: step 3848, loss = 0.69721 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:40:01.726180 ops/training.py:65 2019-01-16 20:40:01.726089: step 3849, loss = 0.71159 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:40:02.618389 ops/training.py:65 2019-01-16 20:40:02.618300: step 3850, loss = 0.67701 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:40:03.514252 ops/training.py:65 2019-01-16 20:40:03.514189: step 3851, loss = 0.70625 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:40:04.406288 ops/training.py:65 2019-01-16 20:40:04.406186: step 3852, loss = 0.71263 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:40:05.296989 ops/training.py:65 2019-01-16 20:40:05.296898: step 3853, loss = 0.72626 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:40:06.186667 ops/training.py:65 2019-01-16 20:40:06.186579: step 3854, loss = 0.67279 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:40:07.077755 ops/training.py:65 2019-01-16 20:40:07.077670: step 3855, loss = 0.70077 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:40:07.968917 ops/training.py:65 2019-01-16 20:40:07.968810: step 3856, loss = 0.69121 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:40:08.859946 ops/training.py:65 2019-01-16 20:40:08.859852: step 3857, loss = 0.66326 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:40:09.749254 ops/training.py:65 2019-01-16 20:40:09.749180: step 3858, loss = 0.70747 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:40:10.638268 ops/training.py:65 2019-01-16 20:40:10.638200: step 3859, loss = 0.72483 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:40:11.526851 ops/training.py:65 2019-01-16 20:40:11.526778: step 3860, loss = 0.70491 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:40:12.415489 ops/training.py:65 2019-01-16 20:40:12.415422: step 3861, loss = 0.67479 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:40:13.307655 ops/training.py:65 2019-01-16 20:40:13.307588: step 3862, loss = 0.75278 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:40:14.199720 ops/training.py:65 2019-01-16 20:40:14.199614: step 3863, loss = 0.70368 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:40:15.090931 ops/training.py:65 2019-01-16 20:40:15.090833: step 3864, loss = 0.67196 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:40:15.981746 ops/training.py:65 2019-01-16 20:40:15.981675: step 3865, loss = 0.71313 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:40:16.870535 ops/training.py:65 2019-01-16 20:40:16.870458: step 3866, loss = 0.70836 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:40:17.758842 ops/training.py:65 2019-01-16 20:40:17.758780: step 3867, loss = 0.69016 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:40:18.647172 ops/training.py:65 2019-01-16 20:40:18.647103: step 3868, loss = 0.65128 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:40:19.536186 ops/training.py:65 2019-01-16 20:40:19.536128: step 3869, loss = 0.68612 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:40:20.423971 ops/training.py:65 2019-01-16 20:40:20.423897: step 3870, loss = 0.69360 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:40:21.313577 ops/training.py:65 2019-01-16 20:40:21.313510: step 3871, loss = 0.67805 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:40:22.202101 ops/training.py:65 2019-01-16 20:40:22.202038: step 3872, loss = 0.70805 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:40:23.090532 ops/training.py:65 2019-01-16 20:40:23.090467: step 3873, loss = 0.72521 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:40:23.979020 ops/training.py:65 2019-01-16 20:40:23.978954: step 3874, loss = 0.71797 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:40:24.868915 ops/training.py:65 2019-01-16 20:40:24.868848: step 3875, loss = 0.70471 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:40:25.757779 ops/training.py:65 2019-01-16 20:40:25.757720: step 3876, loss = 0.69942 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:40:26.647130 ops/training.py:65 2019-01-16 20:40:26.647075: step 3877, loss = 0.69134 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:40:27.538752 ops/training.py:65 2019-01-16 20:40:27.538641: step 3878, loss = 0.70086 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:40:28.431378 ops/training.py:65 2019-01-16 20:40:28.431281: step 3879, loss = 0.71136 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:40:29.323408 ops/training.py:65 2019-01-16 20:40:29.323327: step 3880, loss = 0.69500 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:40:30.215209 ops/training.py:65 2019-01-16 20:40:30.215105: step 3881, loss = 0.67401 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:40:31.107201 ops/training.py:65 2019-01-16 20:40:31.107134: step 3882, loss = 0.69457 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:40:31.998776 ops/training.py:65 2019-01-16 20:40:31.998676: step 3883, loss = 0.69284 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:40:32.891902 ops/training.py:65 2019-01-16 20:40:32.891797: step 3884, loss = 0.71901 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:40:33.781607 ops/training.py:65 2019-01-16 20:40:33.781518: step 3885, loss = 0.70945 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:40:34.670425 ops/training.py:65 2019-01-16 20:40:34.670361: step 3886, loss = 0.66402 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:40:35.557925 ops/training.py:65 2019-01-16 20:40:35.557852: step 3887, loss = 0.68023 (36.1 examples/sec; 0.886 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:40:36.446204 ops/training.py:65 2019-01-16 20:40:36.446134: step 3888, loss = 0.70004 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:40:37.334478 ops/training.py:65 2019-01-16 20:40:37.334407: step 3889, loss = 0.65474 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:40:38.223413 ops/training.py:65 2019-01-16 20:40:38.223345: step 3890, loss = 0.71723 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:40:39.111662 ops/training.py:65 2019-01-16 20:40:39.111597: step 3891, loss = 0.67960 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:40:40.002962 ops/training.py:65 2019-01-16 20:40:40.002886: step 3892, loss = 0.69446 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:40:40.895046 ops/training.py:65 2019-01-16 20:40:40.894950: step 3893, loss = 0.71232 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:40:41.787215 ops/training.py:65 2019-01-16 20:40:41.787108: step 3894, loss = 0.69211 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:40:42.678918 ops/training.py:65 2019-01-16 20:40:42.678830: step 3895, loss = 0.73439 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:40:43.570174 ops/training.py:65 2019-01-16 20:40:43.570101: step 3896, loss = 0.72876 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:40:44.459755 ops/training.py:65 2019-01-16 20:40:44.459662: step 3897, loss = 0.66776 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:40:45.348511 ops/training.py:65 2019-01-16 20:40:45.348446: step 3898, loss = 0.70564 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:40:46.237600 ops/training.py:65 2019-01-16 20:40:46.237522: step 3899, loss = 0.69471 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:40:47.127314 ops/training.py:65 2019-01-16 20:40:47.127250: step 3900, loss = 0.71750 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:40:48.017245 ops/training.py:65 2019-01-16 20:40:48.017179: step 3901, loss = 0.73480 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:40:48.906288 ops/training.py:65 2019-01-16 20:40:48.906227: step 3902, loss = 0.69407 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:40:49.794882 ops/training.py:65 2019-01-16 20:40:49.794818: step 3903, loss = 0.74254 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:40:50.684138 ops/training.py:65 2019-01-16 20:40:50.684077: step 3904, loss = 0.71611 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:40:51.573197 ops/training.py:65 2019-01-16 20:40:51.573131: step 3905, loss = 0.73664 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:40:52.462873 ops/training.py:65 2019-01-16 20:40:52.462803: step 3906, loss = 0.68300 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:40:53.352691 ops/training.py:65 2019-01-16 20:40:53.352620: step 3907, loss = 0.72264 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:40:54.241403 ops/training.py:65 2019-01-16 20:40:54.241334: step 3908, loss = 0.74915 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:40:55.130888 ops/training.py:65 2019-01-16 20:40:55.130824: step 3909, loss = 0.68462 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:40:56.019962 ops/training.py:65 2019-01-16 20:40:56.019902: step 3910, loss = 0.66142 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:40:56.909322 ops/training.py:65 2019-01-16 20:40:56.909253: step 3911, loss = 0.68945 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:40:57.797999 ops/training.py:65 2019-01-16 20:40:57.797937: step 3912, loss = 0.70735 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:40:58.686419 ops/training.py:65 2019-01-16 20:40:58.686361: step 3913, loss = 0.70835 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:40:59.576620 ops/training.py:65 2019-01-16 20:40:59.576554: step 3914, loss = 0.69683 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:41:00.466668 ops/training.py:65 2019-01-16 20:41:00.466569: step 3915, loss = 0.70559 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:41:01.358711 ops/training.py:65 2019-01-16 20:41:01.358610: step 3916, loss = 0.73299 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:41:02.249513 ops/training.py:65 2019-01-16 20:41:02.249427: step 3917, loss = 0.71704 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:41:03.139582 ops/training.py:65 2019-01-16 20:41:03.139524: step 3918, loss = 0.73057 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:41:04.029570 ops/training.py:65 2019-01-16 20:41:04.029476: step 3919, loss = 0.71953 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:41:04.920227 ops/training.py:65 2019-01-16 20:41:04.920134: step 3920, loss = 0.67579 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:41:05.810346 ops/training.py:65 2019-01-16 20:41:05.810244: step 3921, loss = 0.67221 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:41:06.699600 ops/training.py:65 2019-01-16 20:41:06.699502: step 3922, loss = 0.67607 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:41:07.588986 ops/training.py:65 2019-01-16 20:41:07.588898: step 3923, loss = 0.70501 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:41:08.479391 ops/training.py:65 2019-01-16 20:41:08.479292: step 3924, loss = 0.68559 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:41:09.370221 ops/training.py:65 2019-01-16 20:41:09.370116: step 3925, loss = 0.71665 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:41:10.259065 ops/training.py:65 2019-01-16 20:41:10.258964: step 3926, loss = 0.66593 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:41:11.151303 ops/training.py:65 2019-01-16 20:41:11.151234: step 3927, loss = 0.65329 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:41:12.043127 ops/training.py:65 2019-01-16 20:41:12.043060: step 3928, loss = 0.69212 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:41:12.935318 ops/training.py:65 2019-01-16 20:41:12.935250: step 3929, loss = 0.70670 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:41:13.826549 ops/training.py:65 2019-01-16 20:41:13.826461: step 3930, loss = 0.70274 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:41:14.717948 ops/training.py:65 2019-01-16 20:41:14.717847: step 3931, loss = 0.67008 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:41:15.607540 ops/training.py:65 2019-01-16 20:41:15.607442: step 3932, loss = 0.73701 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:41:16.496007 ops/training.py:65 2019-01-16 20:41:16.495929: step 3933, loss = 0.70967 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:41:17.387518 ops/training.py:65 2019-01-16 20:41:17.387480: step 3934, loss = 0.71824 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:41:18.275890 ops/training.py:65 2019-01-16 20:41:18.275849: step 3935, loss = 0.74236 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:41:19.164727 ops/training.py:65 2019-01-16 20:41:19.164682: step 3936, loss = 0.68906 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:41:20.054390 ops/training.py:65 2019-01-16 20:41:20.054296: step 3937, loss = 0.73269 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:41:20.946528 ops/training.py:65 2019-01-16 20:41:20.946429: step 3938, loss = 0.69682 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:41:21.836857 ops/training.py:65 2019-01-16 20:41:21.836783: step 3939, loss = 0.69565 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:41:22.725681 ops/training.py:65 2019-01-16 20:41:22.725599: step 3940, loss = 0.71535 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:41:23.615378 ops/training.py:65 2019-01-16 20:41:23.615300: step 3941, loss = 0.69472 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:41:24.504191 ops/training.py:65 2019-01-16 20:41:24.504116: step 3942, loss = 0.67996 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:41:25.397791 ops/training.py:65 2019-01-16 20:41:25.397721: step 3943, loss = 0.69178 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:41:26.289692 ops/training.py:65 2019-01-16 20:41:26.289588: step 3944, loss = 0.67685 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:41:27.181192 ops/training.py:65 2019-01-16 20:41:27.181092: step 3945, loss = 0.69293 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:41:28.071591 ops/training.py:65 2019-01-16 20:41:28.071499: step 3946, loss = 0.68951 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:41:28.960716 ops/training.py:65 2019-01-16 20:41:28.960636: step 3947, loss = 0.74011 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 20:41:29.848453 ops/training.py:65 2019-01-16 20:41:29.848383: step 3948, loss = 0.72602 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:41:30.737248 ops/training.py:65 2019-01-16 20:41:30.737174: step 3949, loss = 0.69107 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:41:31.626667 ops/training.py:65 2019-01-16 20:41:31.626592: step 3950, loss = 0.72991 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:41:32.515770 ops/training.py:65 2019-01-16 20:41:32.515700: step 3951, loss = 0.69383 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:41:33.406286 ops/training.py:65 2019-01-16 20:41:33.406216: step 3952, loss = 0.67329 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:41:34.297111 ops/training.py:65 2019-01-16 20:41:34.297021: step 3953, loss = 0.68367 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:41:35.188334 ops/training.py:65 2019-01-16 20:41:35.188263: step 3954, loss = 0.68164 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:41:36.078405 ops/training.py:65 2019-01-16 20:41:36.078331: step 3955, loss = 0.68638 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:41:36.967490 ops/training.py:65 2019-01-16 20:41:36.967419: step 3956, loss = 0.73925 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:41:37.858394 ops/training.py:65 2019-01-16 20:41:37.858323: step 3957, loss = 0.71363 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:41:38.747251 ops/training.py:65 2019-01-16 20:41:38.747186: step 3958, loss = 0.72417 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:41:39.638469 ops/training.py:65 2019-01-16 20:41:39.638404: step 3959, loss = 0.68640 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:41:40.528126 ops/training.py:65 2019-01-16 20:41:40.528055: step 3960, loss = 0.70600 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:41:41.417378 ops/training.py:65 2019-01-16 20:41:41.417306: step 3961, loss = 0.70082 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:41:42.308646 ops/training.py:65 2019-01-16 20:41:42.308564: step 3962, loss = 0.69841 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:41:43.201697 ops/training.py:65 2019-01-16 20:41:43.201595: step 3963, loss = 0.69084 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:41:44.093934 ops/training.py:65 2019-01-16 20:41:44.093823: step 3964, loss = 0.70948 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:41:44.984650 ops/training.py:65 2019-01-16 20:41:44.984575: step 3965, loss = 0.69534 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:41:45.875973 ops/training.py:65 2019-01-16 20:41:45.875917: step 3966, loss = 0.69467 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:41:46.767434 ops/training.py:65 2019-01-16 20:41:46.767331: step 3967, loss = 0.68034 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:41:47.658910 ops/training.py:65 2019-01-16 20:41:47.658809: step 3968, loss = 0.70991 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:41:48.549055 ops/training.py:65 2019-01-16 20:41:48.548988: step 3969, loss = 0.68465 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:41:49.439139 ops/training.py:65 2019-01-16 20:41:49.439067: step 3970, loss = 0.71441 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:41:50.331323 ops/training.py:65 2019-01-16 20:41:50.331212: step 3971, loss = 0.70096 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:41:51.222110 ops/training.py:65 2019-01-16 20:41:51.222015: step 3972, loss = 0.68331 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:41:52.114141 ops/training.py:65 2019-01-16 20:41:52.114039: step 3973, loss = 0.69398 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:41:53.005362 ops/training.py:65 2019-01-16 20:41:53.005300: step 3974, loss = 0.70588 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:41:53.896510 ops/training.py:65 2019-01-16 20:41:53.896421: step 3975, loss = 0.70502 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:41:54.788234 ops/training.py:65 2019-01-16 20:41:54.788173: step 3976, loss = 0.71392 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:41:55.680995 ops/training.py:65 2019-01-16 20:41:55.680963: step 3977, loss = 0.68906 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:41:56.572660 ops/training.py:65 2019-01-16 20:41:56.572604: step 3978, loss = 0.69943 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:41:57.464391 ops/training.py:65 2019-01-16 20:41:57.464286: step 3979, loss = 0.67513 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:41:58.354897 ops/training.py:65 2019-01-16 20:41:58.354802: step 3980, loss = 0.70923 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:41:59.247216 ops/training.py:65 2019-01-16 20:41:59.247150: step 3981, loss = 0.68871 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:42:00.138972 ops/training.py:65 2019-01-16 20:42:00.138914: step 3982, loss = 0.73557 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:42:01.030551 ops/training.py:65 2019-01-16 20:42:01.030456: step 3983, loss = 0.70508 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:42:01.920931 ops/training.py:65 2019-01-16 20:42:01.920874: step 3984, loss = 0.68537 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:42:02.812116 ops/training.py:65 2019-01-16 20:42:02.812052: step 3985, loss = 0.70491 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:42:03.705055 ops/training.py:65 2019-01-16 20:42:03.704955: step 3986, loss = 0.67808 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:42:04.596003 ops/training.py:65 2019-01-16 20:42:04.595872: step 3987, loss = 0.68995 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:42:05.486059 ops/training.py:65 2019-01-16 20:42:05.485996: step 3988, loss = 0.68012 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:42:06.374965 ops/training.py:65 2019-01-16 20:42:06.374902: step 3989, loss = 0.67264 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 20:42:07.263878 ops/training.py:65 2019-01-16 20:42:07.263817: step 3990, loss = 0.68473 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:42:08.153163 ops/training.py:65 2019-01-16 20:42:08.153095: step 3991, loss = 0.70026 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:42:09.041601 ops/training.py:65 2019-01-16 20:42:09.041533: step 3992, loss = 0.68750 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:42:09.929332 ops/training.py:65 2019-01-16 20:42:09.929256: step 3993, loss = 0.70488 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:42:10.818464 ops/training.py:65 2019-01-16 20:42:10.818394: step 3994, loss = 0.69968 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:42:11.707527 ops/training.py:65 2019-01-16 20:42:11.707464: step 3995, loss = 0.67980 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:42:12.596597 ops/training.py:65 2019-01-16 20:42:12.596531: step 3996, loss = 0.70572 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:42:13.485882 ops/training.py:65 2019-01-16 20:42:13.485813: step 3997, loss = 0.69541 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:42:14.375056 ops/training.py:65 2019-01-16 20:42:14.374992: step 3998, loss = 0.68657 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:42:15.264485 ops/training.py:65 2019-01-16 20:42:15.264414: step 3999, loss = 0.68837 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:46:30.390141 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I2992 2019-01-16 20:46:30.391156 ops/training.py:41 2019-01-16 20:46:30.391101: step 4000, loss = 0.65 (0.1 examples/sec; 254.236 sec/batch) | Training accuracy = 0.6875 | Validation accuracy = 0.50565 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_19_33_19_510334
I2992 2019-01-16 20:46:31.282278 ops/training.py:65 2019-01-16 20:46:31.282207: step 4001, loss = 0.69852 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:46:32.174315 ops/training.py:65 2019-01-16 20:46:32.174226: step 4002, loss = 0.68092 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:46:33.069351 ops/training.py:65 2019-01-16 20:46:33.069257: step 4003, loss = 0.75069 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:46:33.962490 ops/training.py:65 2019-01-16 20:46:33.962404: step 4004, loss = 0.68943 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:46:34.854468 ops/training.py:65 2019-01-16 20:46:34.854390: step 4005, loss = 0.68394 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:46:35.746775 ops/training.py:65 2019-01-16 20:46:35.746687: step 4006, loss = 0.67942 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:46:36.640036 ops/training.py:65 2019-01-16 20:46:36.639942: step 4007, loss = 0.73028 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:46:37.533282 ops/training.py:65 2019-01-16 20:46:37.533185: step 4008, loss = 0.68103 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:46:38.427049 ops/training.py:65 2019-01-16 20:46:38.426963: step 4009, loss = 0.76138 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:46:39.317092 ops/training.py:65 2019-01-16 20:46:39.317027: step 4010, loss = 0.68179 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:46:40.206627 ops/training.py:65 2019-01-16 20:46:40.206560: step 4011, loss = 0.69569 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:46:41.095943 ops/training.py:65 2019-01-16 20:46:41.095878: step 4012, loss = 0.68541 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:46:41.986222 ops/training.py:65 2019-01-16 20:46:41.986162: step 4013, loss = 0.74036 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:46:42.875385 ops/training.py:65 2019-01-16 20:46:42.875321: step 4014, loss = 0.67774 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:46:43.765596 ops/training.py:65 2019-01-16 20:46:43.765528: step 4015, loss = 0.68485 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:46:44.655002 ops/training.py:65 2019-01-16 20:46:44.654936: step 4016, loss = 0.69311 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:46:45.544702 ops/training.py:65 2019-01-16 20:46:45.544638: step 4017, loss = 0.68159 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:46:46.433454 ops/training.py:65 2019-01-16 20:46:46.433390: step 4018, loss = 0.69207 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:46:47.323695 ops/training.py:65 2019-01-16 20:46:47.323632: step 4019, loss = 0.68924 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:46:48.213998 ops/training.py:65 2019-01-16 20:46:48.213929: step 4020, loss = 0.70161 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:46:49.102884 ops/training.py:65 2019-01-16 20:46:49.102826: step 4021, loss = 0.69051 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:46:49.993988 ops/training.py:65 2019-01-16 20:46:49.993924: step 4022, loss = 0.68221 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:46:50.886681 ops/training.py:65 2019-01-16 20:46:50.886577: step 4023, loss = 0.68658 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:46:51.779160 ops/training.py:65 2019-01-16 20:46:51.779069: step 4024, loss = 0.70070 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:46:52.669944 ops/training.py:65 2019-01-16 20:46:52.669880: step 4025, loss = 0.70419 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:46:53.559113 ops/training.py:65 2019-01-16 20:46:53.559046: step 4026, loss = 0.69406 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:46:54.449292 ops/training.py:65 2019-01-16 20:46:54.449224: step 4027, loss = 0.68038 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:46:55.341463 ops/training.py:65 2019-01-16 20:46:55.341392: step 4028, loss = 0.67868 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:46:56.232909 ops/training.py:65 2019-01-16 20:46:56.232813: step 4029, loss = 0.70821 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:46:57.125515 ops/training.py:65 2019-01-16 20:46:57.125427: step 4030, loss = 0.69730 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:46:58.018463 ops/training.py:65 2019-01-16 20:46:58.018367: step 4031, loss = 0.69016 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:46:58.910381 ops/training.py:65 2019-01-16 20:46:58.910275: step 4032, loss = 0.69808 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:46:59.802414 ops/training.py:65 2019-01-16 20:46:59.802309: step 4033, loss = 0.66776 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:47:00.693677 ops/training.py:65 2019-01-16 20:47:00.693611: step 4034, loss = 0.70002 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:47:01.581929 ops/training.py:65 2019-01-16 20:47:01.581855: step 4035, loss = 0.70122 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:47:02.471215 ops/training.py:65 2019-01-16 20:47:02.471145: step 4036, loss = 0.71944 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:47:03.361078 ops/training.py:65 2019-01-16 20:47:03.361015: step 4037, loss = 0.70481 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:47:04.251179 ops/training.py:65 2019-01-16 20:47:04.251114: step 4038, loss = 0.69706 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:47:05.141301 ops/training.py:65 2019-01-16 20:47:05.141239: step 4039, loss = 0.69716 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:47:06.030548 ops/training.py:65 2019-01-16 20:47:06.030484: step 4040, loss = 0.68229 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:47:06.919978 ops/training.py:65 2019-01-16 20:47:06.919905: step 4041, loss = 0.70082 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:47:07.809262 ops/training.py:65 2019-01-16 20:47:07.809191: step 4042, loss = 0.68630 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 20:47:08.697584 ops/training.py:65 2019-01-16 20:47:08.697506: step 4043, loss = 0.66617 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:47:09.588777 ops/training.py:65 2019-01-16 20:47:09.588694: step 4044, loss = 0.69170 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:47:10.481814 ops/training.py:65 2019-01-16 20:47:10.481724: step 4045, loss = 0.70043 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:47:11.375042 ops/training.py:65 2019-01-16 20:47:11.374942: step 4046, loss = 0.68313 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:47:12.268338 ops/training.py:65 2019-01-16 20:47:12.268233: step 4047, loss = 0.69607 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:47:13.161437 ops/training.py:65 2019-01-16 20:47:13.161366: step 4048, loss = 0.69251 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:47:14.051662 ops/training.py:65 2019-01-16 20:47:14.051599: step 4049, loss = 0.69523 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:47:14.942113 ops/training.py:65 2019-01-16 20:47:14.942036: step 4050, loss = 0.68555 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:47:15.835238 ops/training.py:65 2019-01-16 20:47:15.835131: step 4051, loss = 0.69044 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:47:16.727265 ops/training.py:65 2019-01-16 20:47:16.727194: step 4052, loss = 0.68987 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:47:17.619296 ops/training.py:65 2019-01-16 20:47:17.619202: step 4053, loss = 0.71688 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:47:18.511217 ops/training.py:65 2019-01-16 20:47:18.511119: step 4054, loss = 0.68531 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:47:19.404021 ops/training.py:65 2019-01-16 20:47:19.403978: step 4055, loss = 0.70601 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:47:20.296609 ops/training.py:65 2019-01-16 20:47:20.296542: step 4056, loss = 0.70368 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:47:21.188012 ops/training.py:65 2019-01-16 20:47:21.187914: step 4057, loss = 0.68215 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:47:22.078985 ops/training.py:65 2019-01-16 20:47:22.078892: step 4058, loss = 0.70924 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:47:22.967898 ops/training.py:65 2019-01-16 20:47:22.967811: step 4059, loss = 0.68147 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:47:23.857787 ops/training.py:65 2019-01-16 20:47:23.857720: step 4060, loss = 0.70474 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:47:24.746309 ops/training.py:65 2019-01-16 20:47:24.746228: step 4061, loss = 0.68733 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:47:25.635948 ops/training.py:65 2019-01-16 20:47:25.635880: step 4062, loss = 0.66123 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:47:26.525164 ops/training.py:65 2019-01-16 20:47:26.525096: step 4063, loss = 0.69548 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:47:27.413835 ops/training.py:65 2019-01-16 20:47:27.413771: step 4064, loss = 0.66661 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 20:47:28.302047 ops/training.py:65 2019-01-16 20:47:28.301986: step 4065, loss = 0.72038 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:47:29.189789 ops/training.py:65 2019-01-16 20:47:29.189728: step 4066, loss = 0.67055 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:47:30.078583 ops/training.py:65 2019-01-16 20:47:30.078524: step 4067, loss = 0.70878 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:47:30.966232 ops/training.py:65 2019-01-16 20:47:30.966175: step 4068, loss = 0.71025 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:47:31.855102 ops/training.py:65 2019-01-16 20:47:31.855041: step 4069, loss = 0.69873 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:47:32.743128 ops/training.py:65 2019-01-16 20:47:32.743069: step 4070, loss = 0.68659 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:47:33.632641 ops/training.py:65 2019-01-16 20:47:33.632573: step 4071, loss = 0.69272 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:47:34.521336 ops/training.py:65 2019-01-16 20:47:34.521277: step 4072, loss = 0.71170 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:47:35.413224 ops/training.py:65 2019-01-16 20:47:35.413164: step 4073, loss = 0.70574 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:47:36.305533 ops/training.py:65 2019-01-16 20:47:36.305435: step 4074, loss = 0.70853 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:47:37.197025 ops/training.py:65 2019-01-16 20:47:37.196941: step 4075, loss = 0.72022 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:47:38.085977 ops/training.py:65 2019-01-16 20:47:38.085918: step 4076, loss = 0.70078 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:47:38.975236 ops/training.py:65 2019-01-16 20:47:38.975176: step 4077, loss = 0.69836 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:47:39.866472 ops/training.py:65 2019-01-16 20:47:39.866414: step 4078, loss = 0.70916 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:47:40.758932 ops/training.py:65 2019-01-16 20:47:40.758847: step 4079, loss = 0.70191 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:47:41.651060 ops/training.py:65 2019-01-16 20:47:41.650963: step 4080, loss = 0.68976 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:47:42.543488 ops/training.py:65 2019-01-16 20:47:42.543411: step 4081, loss = 0.69061 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:47:43.435871 ops/training.py:65 2019-01-16 20:47:43.435775: step 4082, loss = 0.73499 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:47:44.327381 ops/training.py:65 2019-01-16 20:47:44.327315: step 4083, loss = 0.69811 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:47:45.216584 ops/training.py:65 2019-01-16 20:47:45.216521: step 4084, loss = 0.66579 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:47:46.105807 ops/training.py:65 2019-01-16 20:47:46.105746: step 4085, loss = 0.69849 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:47:46.996585 ops/training.py:65 2019-01-16 20:47:46.996534: step 4086, loss = 0.70436 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:47:47.887683 ops/training.py:65 2019-01-16 20:47:47.887609: step 4087, loss = 0.68829 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:47:48.779539 ops/training.py:65 2019-01-16 20:47:48.779437: step 4088, loss = 0.66616 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:47:49.671172 ops/training.py:65 2019-01-16 20:47:49.671095: step 4089, loss = 0.70952 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:47:50.560600 ops/training.py:65 2019-01-16 20:47:50.560541: step 4090, loss = 0.67419 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:47:51.450016 ops/training.py:65 2019-01-16 20:47:51.449950: step 4091, loss = 0.68719 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:47:52.339861 ops/training.py:65 2019-01-16 20:47:52.339804: step 4092, loss = 0.69962 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:47:53.230780 ops/training.py:65 2019-01-16 20:47:53.230731: step 4093, loss = 0.72445 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:47:54.122193 ops/training.py:65 2019-01-16 20:47:54.122115: step 4094, loss = 0.70907 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:47:55.014837 ops/training.py:65 2019-01-16 20:47:55.014737: step 4095, loss = 0.67085 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:47:55.907575 ops/training.py:65 2019-01-16 20:47:55.907475: step 4096, loss = 0.68211 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:47:56.797956 ops/training.py:65 2019-01-16 20:47:56.797894: step 4097, loss = 0.70838 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:47:57.687356 ops/training.py:65 2019-01-16 20:47:57.687297: step 4098, loss = 0.70198 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:47:58.577415 ops/training.py:65 2019-01-16 20:47:58.577356: step 4099, loss = 0.71486 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:47:59.468529 ops/training.py:65 2019-01-16 20:47:59.468480: step 4100, loss = 0.66354 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:48:00.361802 ops/training.py:65 2019-01-16 20:48:00.361765: step 4101, loss = 0.69844 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:48:01.254657 ops/training.py:65 2019-01-16 20:48:01.254605: step 4102, loss = 0.71298 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:48:02.146190 ops/training.py:65 2019-01-16 20:48:02.146090: step 4103, loss = 0.67702 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:48:03.037754 ops/training.py:65 2019-01-16 20:48:03.037660: step 4104, loss = 0.71579 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:48:03.928368 ops/training.py:65 2019-01-16 20:48:03.928304: step 4105, loss = 0.71155 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:48:04.816810 ops/training.py:65 2019-01-16 20:48:04.816756: step 4106, loss = 0.69575 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:48:05.705391 ops/training.py:65 2019-01-16 20:48:05.705336: step 4107, loss = 0.69088 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:48:06.595052 ops/training.py:65 2019-01-16 20:48:06.594991: step 4108, loss = 0.73401 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:48:07.483843 ops/training.py:65 2019-01-16 20:48:07.483782: step 4109, loss = 0.67065 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:48:08.375098 ops/training.py:65 2019-01-16 20:48:08.375037: step 4110, loss = 0.68515 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:48:09.267479 ops/training.py:65 2019-01-16 20:48:09.267376: step 4111, loss = 0.68781 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:48:10.158387 ops/training.py:65 2019-01-16 20:48:10.158326: step 4112, loss = 0.69298 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:48:11.048100 ops/training.py:65 2019-01-16 20:48:11.048038: step 4113, loss = 0.68213 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:48:11.937229 ops/training.py:65 2019-01-16 20:48:11.937167: step 4114, loss = 0.68463 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:48:12.825677 ops/training.py:65 2019-01-16 20:48:12.825615: step 4115, loss = 0.70287 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:48:13.715576 ops/training.py:65 2019-01-16 20:48:13.715514: step 4116, loss = 0.70436 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:48:14.607189 ops/training.py:65 2019-01-16 20:48:14.607138: step 4117, loss = 0.69649 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:48:15.498853 ops/training.py:65 2019-01-16 20:48:15.498746: step 4118, loss = 0.70251 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:48:16.390723 ops/training.py:65 2019-01-16 20:48:16.390663: step 4119, loss = 0.65062 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 20:48:17.280153 ops/training.py:65 2019-01-16 20:48:17.280094: step 4120, loss = 0.68964 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:48:18.171446 ops/training.py:65 2019-01-16 20:48:18.171404: step 4121, loss = 0.70344 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:48:19.062876 ops/training.py:65 2019-01-16 20:48:19.062829: step 4122, loss = 0.67579 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:48:19.954658 ops/training.py:65 2019-01-16 20:48:19.954594: step 4123, loss = 0.68156 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:48:20.844807 ops/training.py:65 2019-01-16 20:48:20.844721: step 4124, loss = 0.69760 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:48:21.734375 ops/training.py:65 2019-01-16 20:48:21.734311: step 4125, loss = 0.67996 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:48:22.622701 ops/training.py:65 2019-01-16 20:48:22.622615: step 4126, loss = 0.69903 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:48:23.513807 ops/training.py:65 2019-01-16 20:48:23.513736: step 4127, loss = 0.68696 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:48:24.405927 ops/training.py:65 2019-01-16 20:48:24.405880: step 4128, loss = 0.70999 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:48:25.297664 ops/training.py:65 2019-01-16 20:48:25.297585: step 4129, loss = 0.69625 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:48:26.189934 ops/training.py:65 2019-01-16 20:48:26.189825: step 4130, loss = 0.71412 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:48:27.080805 ops/training.py:65 2019-01-16 20:48:27.080717: step 4131, loss = 0.70702 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:48:27.969828 ops/training.py:65 2019-01-16 20:48:27.969763: step 4132, loss = 0.67389 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:48:28.858279 ops/training.py:65 2019-01-16 20:48:28.858218: step 4133, loss = 0.69760 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:48:29.747261 ops/training.py:65 2019-01-16 20:48:29.747189: step 4134, loss = 0.69291 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:48:30.638743 ops/training.py:65 2019-01-16 20:48:30.638685: step 4135, loss = 0.70669 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:48:31.531582 ops/training.py:65 2019-01-16 20:48:31.531481: step 4136, loss = 0.68065 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:48:32.423842 ops/training.py:65 2019-01-16 20:48:32.423761: step 4137, loss = 0.68492 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:48:33.317823 ops/training.py:65 2019-01-16 20:48:33.317722: step 4138, loss = 0.69732 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:48:34.209948 ops/training.py:65 2019-01-16 20:48:34.209857: step 4139, loss = 0.70202 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:48:35.103291 ops/training.py:65 2019-01-16 20:48:35.103258: step 4140, loss = 0.69247 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:48:35.994636 ops/training.py:65 2019-01-16 20:48:35.994539: step 4141, loss = 0.68193 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:48:36.886656 ops/training.py:65 2019-01-16 20:48:36.886577: step 4142, loss = 0.70104 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:48:37.775406 ops/training.py:65 2019-01-16 20:48:37.775345: step 4143, loss = 0.70309 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:48:38.664862 ops/training.py:65 2019-01-16 20:48:38.664799: step 4144, loss = 0.70863 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:48:39.554264 ops/training.py:65 2019-01-16 20:48:39.554200: step 4145, loss = 0.67878 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:48:40.443459 ops/training.py:65 2019-01-16 20:48:40.443395: step 4146, loss = 0.68031 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:48:41.331667 ops/training.py:65 2019-01-16 20:48:41.331605: step 4147, loss = 0.67669 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:48:42.220504 ops/training.py:65 2019-01-16 20:48:42.220447: step 4148, loss = 0.70845 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:48:43.109646 ops/training.py:65 2019-01-16 20:48:43.109577: step 4149, loss = 0.69269 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:48:43.998713 ops/training.py:65 2019-01-16 20:48:43.998653: step 4150, loss = 0.71376 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:48:44.888244 ops/training.py:65 2019-01-16 20:48:44.888179: step 4151, loss = 0.68943 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:48:45.776906 ops/training.py:65 2019-01-16 20:48:45.776843: step 4152, loss = 0.67924 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:48:46.666522 ops/training.py:65 2019-01-16 20:48:46.666460: step 4153, loss = 0.69120 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:48:47.559215 ops/training.py:65 2019-01-16 20:48:47.559186: step 4154, loss = 0.68852 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:48:48.452153 ops/training.py:65 2019-01-16 20:48:48.452119: step 4155, loss = 0.68240 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:48:49.344300 ops/training.py:65 2019-01-16 20:48:49.344265: step 4156, loss = 0.69448 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:48:50.236159 ops/training.py:65 2019-01-16 20:48:50.236108: step 4157, loss = 0.71403 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:48:51.128836 ops/training.py:65 2019-01-16 20:48:51.128775: step 4158, loss = 0.70814 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:48:52.022435 ops/training.py:65 2019-01-16 20:48:52.022352: step 4159, loss = 0.71822 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:48:52.914938 ops/training.py:65 2019-01-16 20:48:52.914853: step 4160, loss = 0.68977 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:48:53.805310 ops/training.py:65 2019-01-16 20:48:53.805226: step 4161, loss = 0.69614 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:48:54.695959 ops/training.py:65 2019-01-16 20:48:54.695877: step 4162, loss = 0.69559 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:48:55.586966 ops/training.py:65 2019-01-16 20:48:55.586877: step 4163, loss = 0.69263 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:48:56.477883 ops/training.py:65 2019-01-16 20:48:56.477780: step 4164, loss = 0.71569 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:48:57.368410 ops/training.py:65 2019-01-16 20:48:57.368350: step 4165, loss = 0.69436 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:48:58.257348 ops/training.py:65 2019-01-16 20:48:58.257282: step 4166, loss = 0.66970 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:48:59.145808 ops/training.py:65 2019-01-16 20:48:59.145747: step 4167, loss = 0.69260 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:49:00.034781 ops/training.py:65 2019-01-16 20:49:00.034717: step 4168, loss = 0.70958 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:49:00.923736 ops/training.py:65 2019-01-16 20:49:00.923680: step 4169, loss = 0.70566 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:49:01.811705 ops/training.py:65 2019-01-16 20:49:01.811645: step 4170, loss = 0.68800 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:49:02.702082 ops/training.py:65 2019-01-16 20:49:02.702035: step 4171, loss = 0.71318 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:49:03.593434 ops/training.py:65 2019-01-16 20:49:03.593387: step 4172, loss = 0.70404 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:49:04.485416 ops/training.py:65 2019-01-16 20:49:04.485369: step 4173, loss = 0.69016 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:49:05.378826 ops/training.py:65 2019-01-16 20:49:05.378784: step 4174, loss = 0.68959 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:49:06.271078 ops/training.py:65 2019-01-16 20:49:06.271029: step 4175, loss = 0.68332 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:49:07.162643 ops/training.py:65 2019-01-16 20:49:07.162596: step 4176, loss = 0.70060 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:49:08.054993 ops/training.py:65 2019-01-16 20:49:08.054950: step 4177, loss = 0.71355 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:49:08.946590 ops/training.py:65 2019-01-16 20:49:08.946494: step 4178, loss = 0.70709 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:49:09.836490 ops/training.py:65 2019-01-16 20:49:09.836432: step 4179, loss = 0.71061 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:49:10.727453 ops/training.py:65 2019-01-16 20:49:10.727413: step 4180, loss = 0.71452 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:49:11.618837 ops/training.py:65 2019-01-16 20:49:11.618770: step 4181, loss = 0.71237 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:49:12.511966 ops/training.py:65 2019-01-16 20:49:12.511898: step 4182, loss = 0.71309 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:49:13.404340 ops/training.py:65 2019-01-16 20:49:13.404251: step 4183, loss = 0.68219 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:49:14.296212 ops/training.py:65 2019-01-16 20:49:14.296154: step 4184, loss = 0.70680 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:49:15.188156 ops/training.py:65 2019-01-16 20:49:15.188118: step 4185, loss = 0.64926 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:49:16.078470 ops/training.py:65 2019-01-16 20:49:16.078375: step 4186, loss = 0.69799 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:49:16.969420 ops/training.py:65 2019-01-16 20:49:16.969341: step 4187, loss = 0.68718 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:49:17.858513 ops/training.py:65 2019-01-16 20:49:17.858454: step 4188, loss = 0.67385 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:49:18.747331 ops/training.py:65 2019-01-16 20:49:18.747270: step 4189, loss = 0.71150 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:49:19.640337 ops/training.py:65 2019-01-16 20:49:19.640280: step 4190, loss = 0.70139 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:49:20.531757 ops/training.py:65 2019-01-16 20:49:20.531658: step 4191, loss = 0.69600 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:49:21.422437 ops/training.py:65 2019-01-16 20:49:21.422376: step 4192, loss = 0.71414 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:49:22.314118 ops/training.py:65 2019-01-16 20:49:22.314070: step 4193, loss = 0.68024 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:49:23.205343 ops/training.py:65 2019-01-16 20:49:23.205277: step 4194, loss = 0.69366 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:49:24.097387 ops/training.py:65 2019-01-16 20:49:24.097309: step 4195, loss = 0.68697 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:49:24.990067 ops/training.py:65 2019-01-16 20:49:24.989965: step 4196, loss = 0.69143 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:49:25.883508 ops/training.py:65 2019-01-16 20:49:25.883444: step 4197, loss = 0.69498 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:49:26.775878 ops/training.py:65 2019-01-16 20:49:26.775792: step 4198, loss = 0.69926 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:49:27.668454 ops/training.py:65 2019-01-16 20:49:27.668355: step 4199, loss = 0.67765 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:49:28.560773 ops/training.py:65 2019-01-16 20:49:28.560711: step 4200, loss = 0.70581 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:49:29.453267 ops/training.py:65 2019-01-16 20:49:29.453162: step 4201, loss = 0.68948 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:49:30.345420 ops/training.py:65 2019-01-16 20:49:30.345335: step 4202, loss = 0.68138 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:49:31.235710 ops/training.py:65 2019-01-16 20:49:31.235649: step 4203, loss = 0.67492 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:49:32.125403 ops/training.py:65 2019-01-16 20:49:32.125345: step 4204, loss = 0.69268 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:49:33.013711 ops/training.py:65 2019-01-16 20:49:33.013648: step 4205, loss = 0.70340 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:49:33.902592 ops/training.py:65 2019-01-16 20:49:33.902530: step 4206, loss = 0.68437 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:49:34.791923 ops/training.py:65 2019-01-16 20:49:34.791855: step 4207, loss = 0.69172 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:49:35.682461 ops/training.py:65 2019-01-16 20:49:35.682400: step 4208, loss = 0.67938 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:49:36.574321 ops/training.py:65 2019-01-16 20:49:36.574275: step 4209, loss = 0.68482 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:49:37.466237 ops/training.py:65 2019-01-16 20:49:37.466143: step 4210, loss = 0.67404 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:49:38.358924 ops/training.py:65 2019-01-16 20:49:38.358815: step 4211, loss = 0.70954 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:49:39.250639 ops/training.py:65 2019-01-16 20:49:39.250584: step 4212, loss = 0.68957 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:49:40.143170 ops/training.py:65 2019-01-16 20:49:40.143120: step 4213, loss = 0.67642 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:49:41.035719 ops/training.py:65 2019-01-16 20:49:41.035644: step 4214, loss = 0.67318 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:49:41.927720 ops/training.py:65 2019-01-16 20:49:41.927621: step 4215, loss = 0.70992 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:49:42.820662 ops/training.py:65 2019-01-16 20:49:42.820615: step 4216, loss = 0.68484 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:49:43.713778 ops/training.py:65 2019-01-16 20:49:43.713737: step 4217, loss = 0.70053 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:49:44.605901 ops/training.py:65 2019-01-16 20:49:44.605845: step 4218, loss = 0.72669 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:49:45.498778 ops/training.py:65 2019-01-16 20:49:45.498701: step 4219, loss = 0.67045 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:49:46.390471 ops/training.py:65 2019-01-16 20:49:46.390375: step 4220, loss = 0.68078 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:49:47.281939 ops/training.py:65 2019-01-16 20:49:47.281836: step 4221, loss = 0.69003 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:49:48.171430 ops/training.py:65 2019-01-16 20:49:48.171365: step 4222, loss = 0.68302 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:49:49.060455 ops/training.py:65 2019-01-16 20:49:49.060393: step 4223, loss = 0.70875 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:49:49.951993 ops/training.py:65 2019-01-16 20:49:49.951925: step 4224, loss = 0.71207 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:49:50.844266 ops/training.py:65 2019-01-16 20:49:50.844162: step 4225, loss = 0.75635 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:49:51.735892 ops/training.py:65 2019-01-16 20:49:51.735825: step 4226, loss = 0.68817 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:49:52.625090 ops/training.py:65 2019-01-16 20:49:52.625025: step 4227, loss = 0.69268 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:49:53.514617 ops/training.py:65 2019-01-16 20:49:53.514555: step 4228, loss = 0.70319 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:49:54.404247 ops/training.py:65 2019-01-16 20:49:54.404185: step 4229, loss = 0.68669 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:49:55.293720 ops/training.py:65 2019-01-16 20:49:55.293660: step 4230, loss = 0.66134 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:49:56.183927 ops/training.py:65 2019-01-16 20:49:56.183867: step 4231, loss = 0.70553 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:49:57.074350 ops/training.py:65 2019-01-16 20:49:57.074290: step 4232, loss = 0.70124 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:49:57.966325 ops/training.py:65 2019-01-16 20:49:57.966240: step 4233, loss = 0.69748 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:49:58.858118 ops/training.py:65 2019-01-16 20:49:58.858036: step 4234, loss = 0.72936 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:49:59.751118 ops/training.py:65 2019-01-16 20:49:59.751040: step 4235, loss = 0.70573 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:50:00.643333 ops/training.py:65 2019-01-16 20:50:00.643232: step 4236, loss = 0.69912 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:50:01.535748 ops/training.py:65 2019-01-16 20:50:01.535666: step 4237, loss = 0.70196 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:50:02.426998 ops/training.py:65 2019-01-16 20:50:02.426932: step 4238, loss = 0.69976 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:50:03.318693 ops/training.py:65 2019-01-16 20:50:03.318598: step 4239, loss = 0.69463 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:50:04.210159 ops/training.py:65 2019-01-16 20:50:04.210081: step 4240, loss = 0.69939 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:50:05.100765 ops/training.py:65 2019-01-16 20:50:05.100707: step 4241, loss = 0.69048 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:50:05.992601 ops/training.py:65 2019-01-16 20:50:05.992533: step 4242, loss = 0.65424 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:50:06.884937 ops/training.py:65 2019-01-16 20:50:06.884843: step 4243, loss = 0.70287 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:50:07.776796 ops/training.py:65 2019-01-16 20:50:07.776703: step 4244, loss = 0.66790 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:50:08.669870 ops/training.py:65 2019-01-16 20:50:08.669763: step 4245, loss = 0.65853 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:50:09.561291 ops/training.py:65 2019-01-16 20:50:09.561206: step 4246, loss = 0.70022 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:50:10.450105 ops/training.py:65 2019-01-16 20:50:10.450047: step 4247, loss = 0.64998 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:50:11.338148 ops/training.py:65 2019-01-16 20:50:11.338090: step 4248, loss = 0.70707 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:50:12.226943 ops/training.py:65 2019-01-16 20:50:12.226882: step 4249, loss = 0.73040 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:50:13.115121 ops/training.py:65 2019-01-16 20:50:13.115059: step 4250, loss = 0.72732 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:50:14.003520 ops/training.py:65 2019-01-16 20:50:14.003464: step 4251, loss = 0.73907 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:50:14.894421 ops/training.py:65 2019-01-16 20:50:14.894364: step 4252, loss = 0.71743 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:50:15.786506 ops/training.py:65 2019-01-16 20:50:15.786443: step 4253, loss = 0.71951 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:50:16.679284 ops/training.py:65 2019-01-16 20:50:16.679188: step 4254, loss = 0.68675 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:50:17.570091 ops/training.py:65 2019-01-16 20:50:17.570029: step 4255, loss = 0.72646 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:50:18.460076 ops/training.py:65 2019-01-16 20:50:18.460015: step 4256, loss = 0.67961 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:50:19.350979 ops/training.py:65 2019-01-16 20:50:19.350935: step 4257, loss = 0.68508 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:50:20.242410 ops/training.py:65 2019-01-16 20:50:20.242364: step 4258, loss = 0.69093 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:50:21.134676 ops/training.py:65 2019-01-16 20:50:21.134605: step 4259, loss = 0.70478 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:50:22.027668 ops/training.py:65 2019-01-16 20:50:22.027570: step 4260, loss = 0.69514 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:50:22.919603 ops/training.py:65 2019-01-16 20:50:22.919510: step 4261, loss = 0.69859 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:50:23.809141 ops/training.py:65 2019-01-16 20:50:23.809073: step 4262, loss = 0.69384 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:50:24.698105 ops/training.py:65 2019-01-16 20:50:24.698043: step 4263, loss = 0.70503 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:50:25.587079 ops/training.py:65 2019-01-16 20:50:25.587019: step 4264, loss = 0.70660 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:50:26.475439 ops/training.py:65 2019-01-16 20:50:26.475382: step 4265, loss = 0.70538 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:50:27.367105 ops/training.py:65 2019-01-16 20:50:27.367066: step 4266, loss = 0.70228 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:50:28.258657 ops/training.py:65 2019-01-16 20:50:28.258595: step 4267, loss = 0.72780 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:50:29.149898 ops/training.py:65 2019-01-16 20:50:29.149814: step 4268, loss = 0.72249 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:50:30.043055 ops/training.py:65 2019-01-16 20:50:30.042955: step 4269, loss = 0.68412 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:50:30.934864 ops/training.py:65 2019-01-16 20:50:30.934758: step 4270, loss = 0.74630 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:50:31.825270 ops/training.py:65 2019-01-16 20:50:31.825206: step 4271, loss = 0.71482 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:50:32.714786 ops/training.py:65 2019-01-16 20:50:32.714726: step 4272, loss = 0.69735 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:50:33.605068 ops/training.py:65 2019-01-16 20:50:33.605004: step 4273, loss = 0.69654 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:50:34.497083 ops/training.py:65 2019-01-16 20:50:34.497051: step 4274, loss = 0.69569 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:50:35.389772 ops/training.py:65 2019-01-16 20:50:35.389702: step 4275, loss = 0.70349 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:50:36.281184 ops/training.py:65 2019-01-16 20:50:36.281088: step 4276, loss = 0.68934 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:50:37.172157 ops/training.py:65 2019-01-16 20:50:37.172097: step 4277, loss = 0.68813 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:50:38.061357 ops/training.py:65 2019-01-16 20:50:38.061293: step 4278, loss = 0.70960 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:50:38.950058 ops/training.py:65 2019-01-16 20:50:38.950000: step 4279, loss = 0.71171 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:50:39.838626 ops/training.py:65 2019-01-16 20:50:39.838564: step 4280, loss = 0.70400 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:50:40.727528 ops/training.py:65 2019-01-16 20:50:40.727468: step 4281, loss = 0.69210 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:50:41.615620 ops/training.py:65 2019-01-16 20:50:41.615560: step 4282, loss = 0.69562 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:50:42.504893 ops/training.py:65 2019-01-16 20:50:42.504834: step 4283, loss = 0.71000 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:50:43.392952 ops/training.py:65 2019-01-16 20:50:43.392882: step 4284, loss = 0.67822 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:50:44.282237 ops/training.py:65 2019-01-16 20:50:44.282170: step 4285, loss = 0.68203 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:50:45.174233 ops/training.py:65 2019-01-16 20:50:45.174193: step 4286, loss = 0.68063 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:50:46.066356 ops/training.py:65 2019-01-16 20:50:46.066323: step 4287, loss = 0.71648 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:50:46.958782 ops/training.py:65 2019-01-16 20:50:46.958751: step 4288, loss = 0.69559 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:50:47.852606 ops/training.py:65 2019-01-16 20:50:47.852564: step 4289, loss = 0.68541 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:50:48.744457 ops/training.py:65 2019-01-16 20:50:48.744358: step 4290, loss = 0.69602 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:50:49.634779 ops/training.py:65 2019-01-16 20:50:49.634719: step 4291, loss = 0.68258 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:50:50.527300 ops/training.py:65 2019-01-16 20:50:50.527271: step 4292, loss = 0.70420 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:50:51.419298 ops/training.py:65 2019-01-16 20:50:51.419259: step 4293, loss = 0.68893 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:50:52.311744 ops/training.py:65 2019-01-16 20:50:52.311707: step 4294, loss = 0.68060 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:50:53.204612 ops/training.py:65 2019-01-16 20:50:53.204571: step 4295, loss = 0.71077 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:50:54.095989 ops/training.py:65 2019-01-16 20:50:54.095899: step 4296, loss = 0.67789 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:50:54.987912 ops/training.py:65 2019-01-16 20:50:54.987867: step 4297, loss = 0.66983 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:50:55.878387 ops/training.py:65 2019-01-16 20:50:55.878296: step 4298, loss = 0.69211 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:50:56.768031 ops/training.py:65 2019-01-16 20:50:56.767974: step 4299, loss = 0.70116 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:50:57.659592 ops/training.py:65 2019-01-16 20:50:57.659545: step 4300, loss = 0.70644 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:50:58.551796 ops/training.py:65 2019-01-16 20:50:58.551742: step 4301, loss = 0.69243 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:50:59.443965 ops/training.py:65 2019-01-16 20:50:59.443908: step 4302, loss = 0.69253 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:51:00.336748 ops/training.py:65 2019-01-16 20:51:00.336713: step 4303, loss = 0.71395 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:51:01.228500 ops/training.py:65 2019-01-16 20:51:01.228418: step 4304, loss = 0.72664 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:51:02.120118 ops/training.py:65 2019-01-16 20:51:02.120015: step 4305, loss = 0.69950 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:51:03.012086 ops/training.py:65 2019-01-16 20:51:03.012021: step 4306, loss = 0.69445 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:51:03.900847 ops/training.py:65 2019-01-16 20:51:03.900781: step 4307, loss = 0.70132 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:51:04.789849 ops/training.py:65 2019-01-16 20:51:04.789787: step 4308, loss = 0.67461 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:51:05.678761 ops/training.py:65 2019-01-16 20:51:05.678700: step 4309, loss = 0.68492 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:51:06.571168 ops/training.py:65 2019-01-16 20:51:06.571126: step 4310, loss = 0.69665 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:51:07.463745 ops/training.py:65 2019-01-16 20:51:07.463637: step 4311, loss = 0.68799 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:51:08.356707 ops/training.py:65 2019-01-16 20:51:08.356643: step 4312, loss = 0.68981 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:51:09.250069 ops/training.py:65 2019-01-16 20:51:09.250035: step 4313, loss = 0.69452 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:51:10.143216 ops/training.py:65 2019-01-16 20:51:10.143185: step 4314, loss = 0.68560 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:51:11.035067 ops/training.py:65 2019-01-16 20:51:11.035034: step 4315, loss = 0.71602 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:51:11.927531 ops/training.py:65 2019-01-16 20:51:11.927503: step 4316, loss = 0.69145 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:51:12.821284 ops/training.py:65 2019-01-16 20:51:12.821253: step 4317, loss = 0.69293 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:51:13.713896 ops/training.py:65 2019-01-16 20:51:13.713868: step 4318, loss = 0.71572 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:51:14.607782 ops/training.py:65 2019-01-16 20:51:14.607691: step 4319, loss = 0.68436 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:51:15.499396 ops/training.py:65 2019-01-16 20:51:15.499288: step 4320, loss = 0.73937 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:51:16.390494 ops/training.py:65 2019-01-16 20:51:16.390431: step 4321, loss = 0.68078 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:51:17.279772 ops/training.py:65 2019-01-16 20:51:17.279714: step 4322, loss = 0.69729 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:51:18.168100 ops/training.py:65 2019-01-16 20:51:18.168037: step 4323, loss = 0.66681 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:51:19.057620 ops/training.py:65 2019-01-16 20:51:19.057555: step 4324, loss = 0.68654 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:51:19.947273 ops/training.py:65 2019-01-16 20:51:19.947211: step 4325, loss = 0.69092 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:51:20.836115 ops/training.py:65 2019-01-16 20:51:20.836054: step 4326, loss = 0.71832 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:51:21.725121 ops/training.py:65 2019-01-16 20:51:21.725062: step 4327, loss = 0.66104 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:51:22.614081 ops/training.py:65 2019-01-16 20:51:22.614022: step 4328, loss = 0.71121 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:51:23.502658 ops/training.py:65 2019-01-16 20:51:23.502599: step 4329, loss = 0.71849 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:51:24.391923 ops/training.py:65 2019-01-16 20:51:24.391862: step 4330, loss = 0.69790 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:51:25.281932 ops/training.py:65 2019-01-16 20:51:25.281868: step 4331, loss = 0.70422 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:51:26.171750 ops/training.py:65 2019-01-16 20:51:26.171682: step 4332, loss = 0.68352 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:51:27.061599 ops/training.py:65 2019-01-16 20:51:27.061533: step 4333, loss = 0.68882 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:51:27.951934 ops/training.py:65 2019-01-16 20:51:27.951867: step 4334, loss = 0.67583 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:51:28.842175 ops/training.py:65 2019-01-16 20:51:28.842113: step 4335, loss = 0.67940 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:51:29.733172 ops/training.py:65 2019-01-16 20:51:29.733116: step 4336, loss = 0.69851 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:51:30.620917 ops/training.py:65 2019-01-16 20:51:30.620840: step 4337, loss = 0.68652 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:51:31.512624 ops/training.py:65 2019-01-16 20:51:31.512564: step 4338, loss = 0.70125 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:51:32.404834 ops/training.py:65 2019-01-16 20:51:32.404802: step 4339, loss = 0.70880 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:51:33.298978 ops/training.py:65 2019-01-16 20:51:33.298946: step 4340, loss = 0.69442 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:51:34.192041 ops/training.py:65 2019-01-16 20:51:34.192007: step 4341, loss = 0.70704 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:51:35.085551 ops/training.py:65 2019-01-16 20:51:35.085467: step 4342, loss = 0.72472 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:51:35.978232 ops/training.py:65 2019-01-16 20:51:35.978155: step 4343, loss = 0.68351 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:51:36.870612 ops/training.py:65 2019-01-16 20:51:36.870510: step 4344, loss = 0.69962 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:51:37.760815 ops/training.py:65 2019-01-16 20:51:37.760752: step 4345, loss = 0.70450 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:51:38.649212 ops/training.py:65 2019-01-16 20:51:38.649152: step 4346, loss = 0.67503 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:51:39.537945 ops/training.py:65 2019-01-16 20:51:39.537879: step 4347, loss = 0.72612 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:51:40.427273 ops/training.py:65 2019-01-16 20:51:40.427213: step 4348, loss = 0.75235 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:51:41.319712 ops/training.py:65 2019-01-16 20:51:41.319652: step 4349, loss = 0.70447 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:51:42.211928 ops/training.py:65 2019-01-16 20:51:42.211828: step 4350, loss = 0.69637 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:51:43.104183 ops/training.py:65 2019-01-16 20:51:43.104107: step 4351, loss = 0.69899 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:51:43.993326 ops/training.py:65 2019-01-16 20:51:43.993267: step 4352, loss = 0.71274 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:51:44.882877 ops/training.py:65 2019-01-16 20:51:44.882818: step 4353, loss = 0.68857 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:51:45.770820 ops/training.py:65 2019-01-16 20:51:45.770757: step 4354, loss = 0.67195 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:51:46.659596 ops/training.py:65 2019-01-16 20:51:46.659533: step 4355, loss = 0.68864 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:51:47.548386 ops/training.py:65 2019-01-16 20:51:47.548323: step 4356, loss = 0.67470 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:51:48.436810 ops/training.py:65 2019-01-16 20:51:48.436744: step 4357, loss = 0.71015 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:51:49.329128 ops/training.py:65 2019-01-16 20:51:49.329080: step 4358, loss = 0.70722 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:51:50.220840 ops/training.py:65 2019-01-16 20:51:50.220746: step 4359, loss = 0.71053 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:51:51.112964 ops/training.py:65 2019-01-16 20:51:51.112897: step 4360, loss = 0.72831 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:51:52.004803 ops/training.py:65 2019-01-16 20:51:52.004698: step 4361, loss = 0.69127 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:51:52.896697 ops/training.py:65 2019-01-16 20:51:52.896638: step 4362, loss = 0.71453 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:51:53.785699 ops/training.py:65 2019-01-16 20:51:53.785631: step 4363, loss = 0.71450 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:51:54.674739 ops/training.py:65 2019-01-16 20:51:54.674676: step 4364, loss = 0.69082 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:51:55.565653 ops/training.py:65 2019-01-16 20:51:55.565590: step 4365, loss = 0.70047 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:51:56.457665 ops/training.py:65 2019-01-16 20:51:56.457563: step 4366, loss = 0.67813 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:51:57.349336 ops/training.py:65 2019-01-16 20:51:57.349273: step 4367, loss = 0.70706 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:51:58.238517 ops/training.py:65 2019-01-16 20:51:58.238455: step 4368, loss = 0.68680 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:51:59.128277 ops/training.py:65 2019-01-16 20:51:59.128216: step 4369, loss = 0.71151 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:52:00.017715 ops/training.py:65 2019-01-16 20:52:00.017655: step 4370, loss = 0.67751 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:52:00.906676 ops/training.py:65 2019-01-16 20:52:00.906615: step 4371, loss = 0.68962 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:52:01.797159 ops/training.py:65 2019-01-16 20:52:01.797106: step 4372, loss = 0.67481 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:52:02.689158 ops/training.py:65 2019-01-16 20:52:02.689076: step 4373, loss = 0.68167 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:52:03.582260 ops/training.py:65 2019-01-16 20:52:03.582164: step 4374, loss = 0.67179 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:52:04.474235 ops/training.py:65 2019-01-16 20:52:04.474147: step 4375, loss = 0.70939 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:52:05.363658 ops/training.py:65 2019-01-16 20:52:05.363603: step 4376, loss = 0.71066 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:52:06.252012 ops/training.py:65 2019-01-16 20:52:06.251935: step 4377, loss = 0.69746 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:52:07.141074 ops/training.py:65 2019-01-16 20:52:07.141020: step 4378, loss = 0.69336 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:52:08.029201 ops/training.py:65 2019-01-16 20:52:08.029141: step 4379, loss = 0.68879 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:52:08.918374 ops/training.py:65 2019-01-16 20:52:08.918316: step 4380, loss = 0.69794 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:52:09.810712 ops/training.py:65 2019-01-16 20:52:09.810670: step 4381, loss = 0.67989 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:52:10.703140 ops/training.py:65 2019-01-16 20:52:10.703056: step 4382, loss = 0.68984 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:52:11.594908 ops/training.py:65 2019-01-16 20:52:11.594802: step 4383, loss = 0.70057 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:52:12.487650 ops/training.py:65 2019-01-16 20:52:12.487557: step 4384, loss = 0.69650 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:52:13.377464 ops/training.py:65 2019-01-16 20:52:13.377402: step 4385, loss = 0.66598 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:52:14.266804 ops/training.py:65 2019-01-16 20:52:14.266745: step 4386, loss = 0.67437 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:52:15.156361 ops/training.py:65 2019-01-16 20:52:15.156303: step 4387, loss = 0.69882 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:52:16.045448 ops/training.py:65 2019-01-16 20:52:16.045383: step 4388, loss = 0.69345 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:52:16.939094 ops/training.py:65 2019-01-16 20:52:16.939051: step 4389, loss = 0.68444 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:52:17.833287 ops/training.py:65 2019-01-16 20:52:17.833204: step 4390, loss = 0.73314 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:52:18.726384 ops/training.py:65 2019-01-16 20:52:18.726298: step 4391, loss = 0.69505 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:52:19.619576 ops/training.py:65 2019-01-16 20:52:19.619494: step 4392, loss = 0.72767 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:52:20.513216 ops/training.py:65 2019-01-16 20:52:20.513127: step 4393, loss = 0.70750 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:52:21.404426 ops/training.py:65 2019-01-16 20:52:21.404332: step 4394, loss = 0.71019 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:52:22.295901 ops/training.py:65 2019-01-16 20:52:22.295803: step 4395, loss = 0.71528 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:52:23.187097 ops/training.py:65 2019-01-16 20:52:23.187013: step 4396, loss = 0.69856 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:52:24.080506 ops/training.py:65 2019-01-16 20:52:24.080451: step 4397, loss = 0.72975 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:52:24.972776 ops/training.py:65 2019-01-16 20:52:24.972716: step 4398, loss = 0.71716 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:52:25.864917 ops/training.py:65 2019-01-16 20:52:25.864819: step 4399, loss = 0.69128 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:52:26.754822 ops/training.py:65 2019-01-16 20:52:26.754729: step 4400, loss = 0.70735 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:52:27.643475 ops/training.py:65 2019-01-16 20:52:27.643407: step 4401, loss = 0.69781 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:52:28.532698 ops/training.py:65 2019-01-16 20:52:28.532640: step 4402, loss = 0.67530 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:52:29.420921 ops/training.py:65 2019-01-16 20:52:29.420862: step 4403, loss = 0.71921 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:52:30.309806 ops/training.py:65 2019-01-16 20:52:30.309744: step 4404, loss = 0.70959 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:52:31.199528 ops/training.py:65 2019-01-16 20:52:31.199471: step 4405, loss = 0.69746 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:52:32.091343 ops/training.py:65 2019-01-16 20:52:32.091278: step 4406, loss = 0.64882 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:52:32.983976 ops/training.py:65 2019-01-16 20:52:32.983872: step 4407, loss = 0.68544 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:52:33.877380 ops/training.py:65 2019-01-16 20:52:33.877298: step 4408, loss = 0.69770 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:52:34.770013 ops/training.py:65 2019-01-16 20:52:34.769907: step 4409, loss = 0.69167 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:52:35.660958 ops/training.py:65 2019-01-16 20:52:35.660900: step 4410, loss = 0.67941 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:52:36.550984 ops/training.py:65 2019-01-16 20:52:36.550927: step 4411, loss = 0.69482 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:52:37.441154 ops/training.py:65 2019-01-16 20:52:37.441097: step 4412, loss = 0.69148 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:52:38.332561 ops/training.py:65 2019-01-16 20:52:38.332488: step 4413, loss = 0.70203 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:52:39.225660 ops/training.py:65 2019-01-16 20:52:39.225558: step 4414, loss = 0.66723 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:52:40.117706 ops/training.py:65 2019-01-16 20:52:40.117651: step 4415, loss = 0.69188 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:52:41.007922 ops/training.py:65 2019-01-16 20:52:41.007871: step 4416, loss = 0.71396 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:52:41.900526 ops/training.py:65 2019-01-16 20:52:41.900454: step 4417, loss = 0.70752 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:52:42.794011 ops/training.py:65 2019-01-16 20:52:42.793914: step 4418, loss = 0.70460 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:52:43.686566 ops/training.py:65 2019-01-16 20:52:43.686504: step 4419, loss = 0.72046 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:52:44.577451 ops/training.py:65 2019-01-16 20:52:44.577393: step 4420, loss = 0.70543 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:52:45.471080 ops/training.py:65 2019-01-16 20:52:45.470975: step 4421, loss = 0.71303 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:52:46.363156 ops/training.py:65 2019-01-16 20:52:46.363100: step 4422, loss = 0.71320 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:52:47.255808 ops/training.py:65 2019-01-16 20:52:47.255715: step 4423, loss = 0.73400 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:52:48.148788 ops/training.py:65 2019-01-16 20:52:48.148710: step 4424, loss = 0.72268 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:52:49.041095 ops/training.py:65 2019-01-16 20:52:49.040993: step 4425, loss = 0.71762 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:52:49.933056 ops/training.py:65 2019-01-16 20:52:49.932966: step 4426, loss = 0.66837 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:52:50.826216 ops/training.py:65 2019-01-16 20:52:50.826108: step 4427, loss = 0.69724 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:52:51.718300 ops/training.py:65 2019-01-16 20:52:51.718227: step 4428, loss = 0.67945 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:52:52.611451 ops/training.py:65 2019-01-16 20:52:52.611340: step 4429, loss = 0.66066 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:52:53.504256 ops/training.py:65 2019-01-16 20:52:53.504151: step 4430, loss = 0.70574 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:52:54.395659 ops/training.py:65 2019-01-16 20:52:54.395597: step 4431, loss = 0.75946 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:52:55.285446 ops/training.py:65 2019-01-16 20:52:55.285392: step 4432, loss = 0.71308 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:52:56.173694 ops/training.py:65 2019-01-16 20:52:56.173639: step 4433, loss = 0.70907 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:52:57.061569 ops/training.py:65 2019-01-16 20:52:57.061513: step 4434, loss = 0.71399 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:52:57.950780 ops/training.py:65 2019-01-16 20:52:57.950723: step 4435, loss = 0.70182 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:52:58.840512 ops/training.py:65 2019-01-16 20:52:58.840454: step 4436, loss = 0.67447 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:52:59.731872 ops/training.py:65 2019-01-16 20:52:59.731810: step 4437, loss = 0.67263 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:53:00.623841 ops/training.py:65 2019-01-16 20:53:00.623804: step 4438, loss = 0.69467 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:53:01.513653 ops/training.py:65 2019-01-16 20:53:01.513590: step 4439, loss = 0.70025 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:53:02.405556 ops/training.py:65 2019-01-16 20:53:02.405507: step 4440, loss = 0.72755 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:53:03.296602 ops/training.py:65 2019-01-16 20:53:03.296504: step 4441, loss = 0.70272 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:53:04.192061 ops/training.py:65 2019-01-16 20:53:04.192018: step 4442, loss = 0.69310 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:53:05.084291 ops/training.py:65 2019-01-16 20:53:05.084199: step 4443, loss = 0.67450 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:53:05.975467 ops/training.py:65 2019-01-16 20:53:05.975396: step 4444, loss = 0.69605 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:53:06.864628 ops/training.py:65 2019-01-16 20:53:06.864564: step 4445, loss = 0.71857 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:53:07.757946 ops/training.py:65 2019-01-16 20:53:07.757908: step 4446, loss = 0.67454 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:53:08.649894 ops/training.py:65 2019-01-16 20:53:08.649823: step 4447, loss = 0.69599 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:53:09.541925 ops/training.py:65 2019-01-16 20:53:09.541842: step 4448, loss = 0.68980 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:53:10.434483 ops/training.py:65 2019-01-16 20:53:10.434400: step 4449, loss = 0.71156 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:53:11.325773 ops/training.py:65 2019-01-16 20:53:11.325668: step 4450, loss = 0.69214 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:53:12.219655 ops/training.py:65 2019-01-16 20:53:12.219580: step 4451, loss = 0.69639 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:53:13.110773 ops/training.py:65 2019-01-16 20:53:13.110701: step 4452, loss = 0.70792 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:53:14.001828 ops/training.py:65 2019-01-16 20:53:14.001727: step 4453, loss = 0.71876 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:53:14.890628 ops/training.py:65 2019-01-16 20:53:14.890530: step 4454, loss = 0.70503 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:53:15.780505 ops/training.py:65 2019-01-16 20:53:15.780436: step 4455, loss = 0.71370 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:53:16.669860 ops/training.py:65 2019-01-16 20:53:16.669795: step 4456, loss = 0.68187 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:53:17.558551 ops/training.py:65 2019-01-16 20:53:17.558483: step 4457, loss = 0.72512 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:53:18.451451 ops/training.py:65 2019-01-16 20:53:18.451400: step 4458, loss = 0.71251 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:53:19.343237 ops/training.py:65 2019-01-16 20:53:19.343185: step 4459, loss = 0.69552 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:53:20.235447 ops/training.py:65 2019-01-16 20:53:20.235359: step 4460, loss = 0.69944 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:53:21.126967 ops/training.py:65 2019-01-16 20:53:21.126878: step 4461, loss = 0.70662 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:53:22.016718 ops/training.py:65 2019-01-16 20:53:22.016656: step 4462, loss = 0.68575 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:53:22.906561 ops/training.py:65 2019-01-16 20:53:22.906497: step 4463, loss = 0.69427 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:53:23.795963 ops/training.py:65 2019-01-16 20:53:23.795898: step 4464, loss = 0.71401 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:53:24.685389 ops/training.py:65 2019-01-16 20:53:24.685324: step 4465, loss = 0.69318 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:53:25.574714 ops/training.py:65 2019-01-16 20:53:25.574648: step 4466, loss = 0.67657 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:53:26.464409 ops/training.py:65 2019-01-16 20:53:26.464346: step 4467, loss = 0.69610 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:53:27.353360 ops/training.py:65 2019-01-16 20:53:27.353307: step 4468, loss = 0.69372 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:53:28.241938 ops/training.py:65 2019-01-16 20:53:28.241879: step 4469, loss = 0.68827 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:53:29.131419 ops/training.py:65 2019-01-16 20:53:29.131354: step 4470, loss = 0.71732 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:53:30.020905 ops/training.py:65 2019-01-16 20:53:30.020845: step 4471, loss = 0.66794 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:53:30.910036 ops/training.py:65 2019-01-16 20:53:30.909967: step 4472, loss = 0.74078 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:53:31.799789 ops/training.py:65 2019-01-16 20:53:31.799727: step 4473, loss = 0.71616 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:53:32.689385 ops/training.py:65 2019-01-16 20:53:32.689323: step 4474, loss = 0.73284 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:53:33.578300 ops/training.py:65 2019-01-16 20:53:33.578231: step 4475, loss = 0.71384 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:53:34.468080 ops/training.py:65 2019-01-16 20:53:34.468014: step 4476, loss = 0.67797 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:53:35.355911 ops/training.py:65 2019-01-16 20:53:35.355844: step 4477, loss = 0.69789 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:53:36.244723 ops/training.py:65 2019-01-16 20:53:36.244664: step 4478, loss = 0.70574 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:53:37.136274 ops/training.py:65 2019-01-16 20:53:37.136198: step 4479, loss = 0.71779 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:53:38.027774 ops/training.py:65 2019-01-16 20:53:38.027667: step 4480, loss = 0.70454 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:53:38.918208 ops/training.py:65 2019-01-16 20:53:38.918144: step 4481, loss = 0.68798 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:53:39.806740 ops/training.py:65 2019-01-16 20:53:39.806679: step 4482, loss = 0.68607 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:53:40.695122 ops/training.py:65 2019-01-16 20:53:40.695060: step 4483, loss = 0.68716 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:53:41.584941 ops/training.py:65 2019-01-16 20:53:41.584874: step 4484, loss = 0.69689 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:53:42.474612 ops/training.py:65 2019-01-16 20:53:42.474545: step 4485, loss = 0.67756 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:53:43.363893 ops/training.py:65 2019-01-16 20:53:43.363825: step 4486, loss = 0.71435 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:53:44.252226 ops/training.py:65 2019-01-16 20:53:44.252161: step 4487, loss = 0.68183 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:53:45.140906 ops/training.py:65 2019-01-16 20:53:45.140843: step 4488, loss = 0.69176 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:53:46.032793 ops/training.py:65 2019-01-16 20:53:46.032732: step 4489, loss = 0.69342 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:53:46.923747 ops/training.py:65 2019-01-16 20:53:46.923648: step 4490, loss = 0.68752 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:53:47.814283 ops/training.py:65 2019-01-16 20:53:47.814176: step 4491, loss = 0.71785 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:53:48.705349 ops/training.py:65 2019-01-16 20:53:48.705280: step 4492, loss = 0.69275 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:53:49.593802 ops/training.py:65 2019-01-16 20:53:49.593730: step 4493, loss = 0.68169 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:53:50.482934 ops/training.py:65 2019-01-16 20:53:50.482876: step 4494, loss = 0.68531 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:53:51.371356 ops/training.py:65 2019-01-16 20:53:51.371289: step 4495, loss = 0.69855 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:53:52.259628 ops/training.py:65 2019-01-16 20:53:52.259561: step 4496, loss = 0.68107 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:53:53.148781 ops/training.py:65 2019-01-16 20:53:53.148716: step 4497, loss = 0.70868 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:53:54.037261 ops/training.py:65 2019-01-16 20:53:54.037197: step 4498, loss = 0.67623 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:53:54.926104 ops/training.py:65 2019-01-16 20:53:54.926040: step 4499, loss = 0.68849 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:53:55.815361 ops/training.py:65 2019-01-16 20:53:55.815301: step 4500, loss = 0.70970 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:53:56.704840 ops/training.py:65 2019-01-16 20:53:56.704780: step 4501, loss = 0.68397 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:53:57.593097 ops/training.py:65 2019-01-16 20:53:57.593035: step 4502, loss = 0.68426 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:53:58.481669 ops/training.py:65 2019-01-16 20:53:58.481610: step 4503, loss = 0.66518 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.75
I2992 2019-01-16 20:53:59.369750 ops/training.py:65 2019-01-16 20:53:59.369685: step 4504, loss = 0.72087 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:54:00.259213 ops/training.py:65 2019-01-16 20:54:00.259155: step 4505, loss = 0.68538 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:54:01.148009 ops/training.py:65 2019-01-16 20:54:01.147947: step 4506, loss = 0.70085 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:54:02.036235 ops/training.py:65 2019-01-16 20:54:02.036173: step 4507, loss = 0.70597 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:54:02.926389 ops/training.py:65 2019-01-16 20:54:02.926324: step 4508, loss = 0.68039 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:54:03.815572 ops/training.py:65 2019-01-16 20:54:03.815511: step 4509, loss = 0.68255 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:54:04.704855 ops/training.py:65 2019-01-16 20:54:04.704798: step 4510, loss = 0.70315 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:54:05.593671 ops/training.py:65 2019-01-16 20:54:05.593612: step 4511, loss = 0.70184 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:54:06.482821 ops/training.py:65 2019-01-16 20:54:06.482763: step 4512, loss = 0.69842 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:54:07.375966 ops/training.py:65 2019-01-16 20:54:07.375909: step 4513, loss = 0.68422 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:54:08.269313 ops/training.py:65 2019-01-16 20:54:08.269221: step 4514, loss = 0.70105 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:54:09.160920 ops/training.py:65 2019-01-16 20:54:09.160818: step 4515, loss = 0.67176 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:54:10.053184 ops/training.py:65 2019-01-16 20:54:10.053084: step 4516, loss = 0.68605 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:54:10.945442 ops/training.py:65 2019-01-16 20:54:10.945371: step 4517, loss = 0.69562 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:54:11.837076 ops/training.py:65 2019-01-16 20:54:11.836973: step 4518, loss = 0.68055 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:54:12.729082 ops/training.py:65 2019-01-16 20:54:12.729028: step 4519, loss = 0.70209 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:54:13.620969 ops/training.py:65 2019-01-16 20:54:13.620875: step 4520, loss = 0.68178 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:54:14.513771 ops/training.py:65 2019-01-16 20:54:14.513666: step 4521, loss = 0.70728 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:54:15.405596 ops/training.py:65 2019-01-16 20:54:15.405506: step 4522, loss = 0.70264 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:54:16.298330 ops/training.py:65 2019-01-16 20:54:16.298241: step 4523, loss = 0.70254 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:54:17.189446 ops/training.py:65 2019-01-16 20:54:17.189344: step 4524, loss = 0.66921 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:54:18.080188 ops/training.py:65 2019-01-16 20:54:18.080080: step 4525, loss = 0.69037 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:54:18.971576 ops/training.py:65 2019-01-16 20:54:18.971472: step 4526, loss = 0.68402 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:54:19.864543 ops/training.py:65 2019-01-16 20:54:19.864438: step 4527, loss = 0.67826 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:54:20.754954 ops/training.py:65 2019-01-16 20:54:20.754858: step 4528, loss = 0.71224 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:54:21.645657 ops/training.py:65 2019-01-16 20:54:21.645554: step 4529, loss = 0.64967 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.75
I2992 2019-01-16 20:54:22.535409 ops/training.py:65 2019-01-16 20:54:22.535336: step 4530, loss = 0.69689 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:54:23.425419 ops/training.py:65 2019-01-16 20:54:23.425340: step 4531, loss = 0.68061 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:54:24.314882 ops/training.py:65 2019-01-16 20:54:24.314812: step 4532, loss = 0.70271 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:54:25.204641 ops/training.py:65 2019-01-16 20:54:25.204569: step 4533, loss = 0.68018 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:54:26.094258 ops/training.py:65 2019-01-16 20:54:26.094200: step 4534, loss = 0.72531 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:54:26.983855 ops/training.py:65 2019-01-16 20:54:26.983798: step 4535, loss = 0.70261 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:54:27.873333 ops/training.py:65 2019-01-16 20:54:27.873271: step 4536, loss = 0.70822 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:54:28.762747 ops/training.py:65 2019-01-16 20:54:28.762685: step 4537, loss = 0.72525 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:54:29.652491 ops/training.py:65 2019-01-16 20:54:29.652425: step 4538, loss = 0.73110 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.25
I2992 2019-01-16 20:54:30.541795 ops/training.py:65 2019-01-16 20:54:30.541730: step 4539, loss = 0.69848 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:54:31.430566 ops/training.py:65 2019-01-16 20:54:31.430486: step 4540, loss = 0.69474 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:54:32.319940 ops/training.py:65 2019-01-16 20:54:32.319873: step 4541, loss = 0.70496 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:54:33.209260 ops/training.py:65 2019-01-16 20:54:33.209191: step 4542, loss = 0.69754 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:54:34.098726 ops/training.py:65 2019-01-16 20:54:34.098660: step 4543, loss = 0.70279 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:54:34.988347 ops/training.py:65 2019-01-16 20:54:34.988282: step 4544, loss = 0.65935 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 20:54:35.879051 ops/training.py:65 2019-01-16 20:54:35.878982: step 4545, loss = 0.66921 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:54:36.768704 ops/training.py:65 2019-01-16 20:54:36.768636: step 4546, loss = 0.70328 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:54:37.658944 ops/training.py:65 2019-01-16 20:54:37.658876: step 4547, loss = 0.67480 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 20:54:38.549207 ops/training.py:65 2019-01-16 20:54:38.549141: step 4548, loss = 0.70102 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:54:39.438776 ops/training.py:65 2019-01-16 20:54:39.438712: step 4549, loss = 0.70961 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:54:40.329812 ops/training.py:65 2019-01-16 20:54:40.329741: step 4550, loss = 0.70705 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:54:41.222336 ops/training.py:65 2019-01-16 20:54:41.222238: step 4551, loss = 0.69752 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:54:42.113744 ops/training.py:65 2019-01-16 20:54:42.113651: step 4552, loss = 0.68416 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:54:43.003821 ops/training.py:65 2019-01-16 20:54:43.003733: step 4553, loss = 0.67474 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:54:43.893724 ops/training.py:65 2019-01-16 20:54:43.893645: step 4554, loss = 0.69971 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:54:44.782620 ops/training.py:65 2019-01-16 20:54:44.782553: step 4555, loss = 0.70366 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:54:45.673048 ops/training.py:65 2019-01-16 20:54:45.672985: step 4556, loss = 0.70040 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:54:46.562138 ops/training.py:65 2019-01-16 20:54:46.562081: step 4557, loss = 0.70218 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:54:47.451350 ops/training.py:65 2019-01-16 20:54:47.451290: step 4558, loss = 0.69794 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:54:48.346199 ops/training.py:65 2019-01-16 20:54:48.346125: step 4559, loss = 0.71948 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:54:49.239134 ops/training.py:65 2019-01-16 20:54:49.239051: step 4560, loss = 0.67573 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:54:50.131080 ops/training.py:65 2019-01-16 20:54:50.131009: step 4561, loss = 0.69823 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:54:51.024285 ops/training.py:65 2019-01-16 20:54:51.024205: step 4562, loss = 0.71076 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:54:51.916823 ops/training.py:65 2019-01-16 20:54:51.916723: step 4563, loss = 0.68368 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:54:52.808487 ops/training.py:65 2019-01-16 20:54:52.808426: step 4564, loss = 0.71188 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:54:53.698670 ops/training.py:65 2019-01-16 20:54:53.698603: step 4565, loss = 0.69277 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:54:54.589468 ops/training.py:65 2019-01-16 20:54:54.589414: step 4566, loss = 0.70886 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:54:55.482197 ops/training.py:65 2019-01-16 20:54:55.482093: step 4567, loss = 0.70212 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:54:56.373772 ops/training.py:65 2019-01-16 20:54:56.373669: step 4568, loss = 0.71713 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:54:57.266594 ops/training.py:65 2019-01-16 20:54:57.266498: step 4569, loss = 0.70554 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:54:58.158886 ops/training.py:65 2019-01-16 20:54:58.158777: step 4570, loss = 0.67707 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:54:59.050577 ops/training.py:65 2019-01-16 20:54:59.050510: step 4571, loss = 0.68997 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:54:59.939951 ops/training.py:65 2019-01-16 20:54:59.939881: step 4572, loss = 0.69910 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:55:00.828886 ops/training.py:65 2019-01-16 20:55:00.828816: step 4573, loss = 0.71038 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:55:01.721948 ops/training.py:65 2019-01-16 20:55:01.721877: step 4574, loss = 0.71226 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:55:02.614119 ops/training.py:65 2019-01-16 20:55:02.614017: step 4575, loss = 0.74387 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:55:03.506125 ops/training.py:65 2019-01-16 20:55:03.506054: step 4576, loss = 0.71029 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:55:04.395137 ops/training.py:65 2019-01-16 20:55:04.395081: step 4577, loss = 0.72612 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:55:05.283535 ops/training.py:65 2019-01-16 20:55:05.283474: step 4578, loss = 0.69880 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:55:06.176806 ops/training.py:65 2019-01-16 20:55:06.176750: step 4579, loss = 0.73351 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:55:07.068391 ops/training.py:65 2019-01-16 20:55:07.068291: step 4580, loss = 0.73145 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:55:07.961438 ops/training.py:65 2019-01-16 20:55:07.961350: step 4581, loss = 0.74699 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:55:08.852849 ops/training.py:65 2019-01-16 20:55:08.852761: step 4582, loss = 0.70151 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:55:09.744896 ops/training.py:65 2019-01-16 20:55:09.744799: step 4583, loss = 0.71584 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:55:10.635857 ops/training.py:65 2019-01-16 20:55:10.635786: step 4584, loss = 0.73280 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:55:11.526765 ops/training.py:65 2019-01-16 20:55:11.526693: step 4585, loss = 0.74878 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:55:12.420351 ops/training.py:65 2019-01-16 20:55:12.420263: step 4586, loss = 0.70475 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:55:13.312283 ops/training.py:65 2019-01-16 20:55:13.312203: step 4587, loss = 0.64413 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 20:55:14.203881 ops/training.py:65 2019-01-16 20:55:14.203781: step 4588, loss = 0.75723 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:55:15.094838 ops/training.py:65 2019-01-16 20:55:15.094781: step 4589, loss = 0.70971 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:55:15.983755 ops/training.py:65 2019-01-16 20:55:15.983699: step 4590, loss = 0.65797 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:55:16.873113 ops/training.py:65 2019-01-16 20:55:16.873056: step 4591, loss = 0.75441 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:55:17.761440 ops/training.py:65 2019-01-16 20:55:17.761378: step 4592, loss = 0.70796 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:55:18.651692 ops/training.py:65 2019-01-16 20:55:18.651632: step 4593, loss = 0.70564 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:55:19.542177 ops/training.py:65 2019-01-16 20:55:19.542123: step 4594, loss = 0.69033 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:55:20.431285 ops/training.py:65 2019-01-16 20:55:20.431232: step 4595, loss = 0.69088 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:55:21.319913 ops/training.py:65 2019-01-16 20:55:21.319863: step 4596, loss = 0.67052 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:55:22.208337 ops/training.py:65 2019-01-16 20:55:22.208284: step 4597, loss = 0.68611 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:55:23.096813 ops/training.py:65 2019-01-16 20:55:23.096756: step 4598, loss = 0.73322 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:55:23.986197 ops/training.py:65 2019-01-16 20:55:23.986146: step 4599, loss = 0.67282 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:55:24.875342 ops/training.py:65 2019-01-16 20:55:24.875294: step 4600, loss = 0.68221 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:55:25.763872 ops/training.py:65 2019-01-16 20:55:25.763816: step 4601, loss = 0.71605 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:55:26.652629 ops/training.py:65 2019-01-16 20:55:26.652577: step 4602, loss = 0.76412 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:55:27.541491 ops/training.py:65 2019-01-16 20:55:27.541440: step 4603, loss = 0.77515 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:55:28.431678 ops/training.py:65 2019-01-16 20:55:28.431611: step 4604, loss = 0.75252 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:55:29.321982 ops/training.py:65 2019-01-16 20:55:29.321923: step 4605, loss = 0.72553 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:55:30.214756 ops/training.py:65 2019-01-16 20:55:30.214690: step 4606, loss = 0.76948 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:55:31.106364 ops/training.py:65 2019-01-16 20:55:31.106277: step 4607, loss = 0.71345 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:55:31.998221 ops/training.py:65 2019-01-16 20:55:31.998119: step 4608, loss = 0.69147 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:55:32.890222 ops/training.py:65 2019-01-16 20:55:32.890142: step 4609, loss = 0.70105 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:55:33.780232 ops/training.py:65 2019-01-16 20:55:33.780170: step 4610, loss = 0.70405 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:55:34.669349 ops/training.py:65 2019-01-16 20:55:34.669290: step 4611, loss = 0.65025 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:55:35.561396 ops/training.py:65 2019-01-16 20:55:35.561323: step 4612, loss = 0.72403 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:55:36.453778 ops/training.py:65 2019-01-16 20:55:36.453680: step 4613, loss = 0.66606 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:55:37.344885 ops/training.py:65 2019-01-16 20:55:37.344830: step 4614, loss = 0.71097 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:55:38.233940 ops/training.py:65 2019-01-16 20:55:38.233885: step 4615, loss = 0.74318 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:55:39.124075 ops/training.py:65 2019-01-16 20:55:39.124007: step 4616, loss = 0.69749 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:55:40.016333 ops/training.py:65 2019-01-16 20:55:40.016227: step 4617, loss = 0.72834 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:55:40.908405 ops/training.py:65 2019-01-16 20:55:40.908307: step 4618, loss = 0.71584 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:55:41.800861 ops/training.py:65 2019-01-16 20:55:41.800761: step 4619, loss = 0.72444 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:55:42.692321 ops/training.py:65 2019-01-16 20:55:42.692226: step 4620, loss = 0.70509 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:55:43.583297 ops/training.py:65 2019-01-16 20:55:43.583233: step 4621, loss = 0.65923 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:55:44.473325 ops/training.py:65 2019-01-16 20:55:44.473275: step 4622, loss = 0.73182 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:55:45.361807 ops/training.py:65 2019-01-16 20:55:45.361753: step 4623, loss = 0.67857 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:55:46.250551 ops/training.py:65 2019-01-16 20:55:46.250495: step 4624, loss = 0.75787 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:55:47.140577 ops/training.py:65 2019-01-16 20:55:47.140509: step 4625, loss = 0.73588 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:55:48.031759 ops/training.py:65 2019-01-16 20:55:48.031663: step 4626, loss = 0.68641 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:55:48.924845 ops/training.py:65 2019-01-16 20:55:48.924755: step 4627, loss = 0.73500 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:55:49.817710 ops/training.py:65 2019-01-16 20:55:49.817601: step 4628, loss = 0.77589 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 20:55:50.710316 ops/training.py:65 2019-01-16 20:55:50.710226: step 4629, loss = 0.71941 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:55:51.599911 ops/training.py:65 2019-01-16 20:55:51.599849: step 4630, loss = 0.74427 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:55:52.488609 ops/training.py:65 2019-01-16 20:55:52.488544: step 4631, loss = 0.74463 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:55:53.377677 ops/training.py:65 2019-01-16 20:55:53.377607: step 4632, loss = 0.73397 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:55:54.267267 ops/training.py:65 2019-01-16 20:55:54.267202: step 4633, loss = 0.63443 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:55:55.156180 ops/training.py:65 2019-01-16 20:55:55.156126: step 4634, loss = 0.69054 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:55:56.045287 ops/training.py:65 2019-01-16 20:55:56.045228: step 4635, loss = 0.72171 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:55:56.933408 ops/training.py:65 2019-01-16 20:55:56.933349: step 4636, loss = 0.71822 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:55:57.822015 ops/training.py:65 2019-01-16 20:55:57.821953: step 4637, loss = 0.66923 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:55:58.710297 ops/training.py:65 2019-01-16 20:55:58.710240: step 4638, loss = 0.70067 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:55:59.601709 ops/training.py:65 2019-01-16 20:55:59.601656: step 4639, loss = 0.73991 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 20:56:00.494745 ops/training.py:65 2019-01-16 20:56:00.494665: step 4640, loss = 0.75640 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:56:01.385819 ops/training.py:65 2019-01-16 20:56:01.385721: step 4641, loss = 0.70080 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:56:02.277346 ops/training.py:65 2019-01-16 20:56:02.277247: step 4642, loss = 0.66474 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:56:03.166970 ops/training.py:65 2019-01-16 20:56:03.166908: step 4643, loss = 0.68358 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:56:04.055712 ops/training.py:65 2019-01-16 20:56:04.055652: step 4644, loss = 0.65303 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:56:04.943840 ops/training.py:65 2019-01-16 20:56:04.943781: step 4645, loss = 0.67013 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 20:56:05.835173 ops/training.py:65 2019-01-16 20:56:05.835106: step 4646, loss = 0.72086 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:56:06.727012 ops/training.py:65 2019-01-16 20:56:06.726912: step 4647, loss = 0.72535 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:56:07.618338 ops/training.py:65 2019-01-16 20:56:07.618276: step 4648, loss = 0.76752 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 20:56:08.507441 ops/training.py:65 2019-01-16 20:56:08.507379: step 4649, loss = 0.71184 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:56:09.397353 ops/training.py:65 2019-01-16 20:56:09.397297: step 4650, loss = 0.67488 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:56:10.286477 ops/training.py:65 2019-01-16 20:56:10.286424: step 4651, loss = 0.76109 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:56:11.175633 ops/training.py:65 2019-01-16 20:56:11.175583: step 4652, loss = 0.79205 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:56:12.064273 ops/training.py:65 2019-01-16 20:56:12.064220: step 4653, loss = 0.67077 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:56:12.953299 ops/training.py:65 2019-01-16 20:56:12.953247: step 4654, loss = 0.70933 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:56:13.841356 ops/training.py:65 2019-01-16 20:56:13.841294: step 4655, loss = 0.77662 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:56:14.730492 ops/training.py:65 2019-01-16 20:56:14.730430: step 4656, loss = 0.70987 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:56:15.619865 ops/training.py:65 2019-01-16 20:56:15.619806: step 4657, loss = 0.67485 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:56:16.508870 ops/training.py:65 2019-01-16 20:56:16.508816: step 4658, loss = 0.74851 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:56:17.397991 ops/training.py:65 2019-01-16 20:56:17.397934: step 4659, loss = 0.73861 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:56:18.287797 ops/training.py:65 2019-01-16 20:56:18.287733: step 4660, loss = 0.67669 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:56:19.177325 ops/training.py:65 2019-01-16 20:56:19.177264: step 4661, loss = 0.71816 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:56:20.066049 ops/training.py:65 2019-01-16 20:56:20.065991: step 4662, loss = 0.67618 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:56:20.956861 ops/training.py:65 2019-01-16 20:56:20.956817: step 4663, loss = 0.70591 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:56:21.849243 ops/training.py:65 2019-01-16 20:56:21.849150: step 4664, loss = 0.68137 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:56:22.740389 ops/training.py:65 2019-01-16 20:56:22.740329: step 4665, loss = 0.64957 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:56:23.629575 ops/training.py:65 2019-01-16 20:56:23.629508: step 4666, loss = 0.72743 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:56:24.518909 ops/training.py:65 2019-01-16 20:56:24.518852: step 4667, loss = 0.70942 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:56:25.407742 ops/training.py:65 2019-01-16 20:56:25.407677: step 4668, loss = 0.72935 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:56:26.297062 ops/training.py:65 2019-01-16 20:56:26.296998: step 4669, loss = 0.77912 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:56:27.187562 ops/training.py:65 2019-01-16 20:56:27.187498: step 4670, loss = 0.66918 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:56:28.078469 ops/training.py:65 2019-01-16 20:56:28.078366: step 4671, loss = 0.75150 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:56:28.970335 ops/training.py:65 2019-01-16 20:56:28.970275: step 4672, loss = 0.76763 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:56:29.859311 ops/training.py:65 2019-01-16 20:56:29.859251: step 4673, loss = 0.73594 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:56:30.748803 ops/training.py:65 2019-01-16 20:56:30.748743: step 4674, loss = 0.71271 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:56:31.637980 ops/training.py:65 2019-01-16 20:56:31.637920: step 4675, loss = 0.67717 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:56:32.526571 ops/training.py:65 2019-01-16 20:56:32.526516: step 4676, loss = 0.76575 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:56:33.415097 ops/training.py:65 2019-01-16 20:56:33.415032: step 4677, loss = 0.68063 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:56:34.303497 ops/training.py:65 2019-01-16 20:56:34.303439: step 4678, loss = 0.75259 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:56:35.194297 ops/training.py:65 2019-01-16 20:56:35.194251: step 4679, loss = 0.69455 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:56:36.085738 ops/training.py:65 2019-01-16 20:56:36.085691: step 4680, loss = 0.76909 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:56:36.977589 ops/training.py:65 2019-01-16 20:56:36.977516: step 4681, loss = 0.71074 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:56:37.868774 ops/training.py:65 2019-01-16 20:56:37.868673: step 4682, loss = 0.77301 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:56:38.758978 ops/training.py:65 2019-01-16 20:56:38.758886: step 4683, loss = 0.72583 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:56:39.649594 ops/training.py:65 2019-01-16 20:56:39.649529: step 4684, loss = 0.69306 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:56:40.540369 ops/training.py:65 2019-01-16 20:56:40.540316: step 4685, loss = 0.70873 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:56:41.432094 ops/training.py:65 2019-01-16 20:56:41.431998: step 4686, loss = 0.68580 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:56:42.324433 ops/training.py:65 2019-01-16 20:56:42.324358: step 4687, loss = 0.69829 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:56:43.217380 ops/training.py:65 2019-01-16 20:56:43.217293: step 4688, loss = 0.65766 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:56:44.109709 ops/training.py:65 2019-01-16 20:56:44.109636: step 4689, loss = 0.72057 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:56:45.002034 ops/training.py:65 2019-01-16 20:56:45.001981: step 4690, loss = 0.73936 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:56:45.893094 ops/training.py:65 2019-01-16 20:56:45.893001: step 4691, loss = 0.68149 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:56:46.785240 ops/training.py:65 2019-01-16 20:56:46.785138: step 4692, loss = 0.67839 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:56:47.675960 ops/training.py:65 2019-01-16 20:56:47.675883: step 4693, loss = 0.71256 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:56:48.568231 ops/training.py:65 2019-01-16 20:56:48.568184: step 4694, loss = 0.69474 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:56:49.460307 ops/training.py:65 2019-01-16 20:56:49.460221: step 4695, loss = 0.69148 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:56:50.352114 ops/training.py:65 2019-01-16 20:56:50.352018: step 4696, loss = 0.70022 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:56:51.243473 ops/training.py:65 2019-01-16 20:56:51.243381: step 4697, loss = 0.68669 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:56:52.133079 ops/training.py:65 2019-01-16 20:56:52.133021: step 4698, loss = 0.68765 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:56:53.022338 ops/training.py:65 2019-01-16 20:56:53.022275: step 4699, loss = 0.71277 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:56:53.916716 ops/training.py:65 2019-01-16 20:56:53.916654: step 4700, loss = 0.68716 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:56:54.807196 ops/training.py:65 2019-01-16 20:56:54.807138: step 4701, loss = 0.72939 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:56:55.697995 ops/training.py:65 2019-01-16 20:56:55.697948: step 4702, loss = 0.71009 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:56:56.589754 ops/training.py:65 2019-01-16 20:56:56.589656: step 4703, loss = 0.70559 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:56:57.480647 ops/training.py:65 2019-01-16 20:56:57.480565: step 4704, loss = 0.68675 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:56:58.370152 ops/training.py:65 2019-01-16 20:56:58.370091: step 4705, loss = 0.68607 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:56:59.261541 ops/training.py:65 2019-01-16 20:56:59.261497: step 4706, loss = 0.68624 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:57:00.153865 ops/training.py:65 2019-01-16 20:57:00.153806: step 4707, loss = 0.71490 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:57:01.046352 ops/training.py:65 2019-01-16 20:57:01.046278: step 4708, loss = 0.70557 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:57:01.938351 ops/training.py:65 2019-01-16 20:57:01.938275: step 4709, loss = 0.70142 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:57:02.830273 ops/training.py:65 2019-01-16 20:57:02.830176: step 4710, loss = 0.69638 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:57:03.723590 ops/training.py:65 2019-01-16 20:57:03.723490: step 4711, loss = 0.70474 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:57:04.616175 ops/training.py:65 2019-01-16 20:57:04.616093: step 4712, loss = 0.70855 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:57:05.507861 ops/training.py:65 2019-01-16 20:57:05.507783: step 4713, loss = 0.66648 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:57:06.399655 ops/training.py:65 2019-01-16 20:57:06.399560: step 4714, loss = 0.69868 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:57:07.290159 ops/training.py:65 2019-01-16 20:57:07.290076: step 4715, loss = 0.67885 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:57:08.179531 ops/training.py:65 2019-01-16 20:57:08.179476: step 4716, loss = 0.67674 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:57:09.068441 ops/training.py:65 2019-01-16 20:57:09.068384: step 4717, loss = 0.66447 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:57:09.958355 ops/training.py:65 2019-01-16 20:57:09.958295: step 4718, loss = 0.67902 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:57:10.847511 ops/training.py:65 2019-01-16 20:57:10.847434: step 4719, loss = 0.70682 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:57:11.737445 ops/training.py:65 2019-01-16 20:57:11.737368: step 4720, loss = 0.72424 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:57:12.627191 ops/training.py:65 2019-01-16 20:57:12.627126: step 4721, loss = 0.71740 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:57:13.516410 ops/training.py:65 2019-01-16 20:57:13.516338: step 4722, loss = 0.70649 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:57:14.405172 ops/training.py:65 2019-01-16 20:57:14.405117: step 4723, loss = 0.70734 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:57:15.294145 ops/training.py:65 2019-01-16 20:57:15.294084: step 4724, loss = 0.69913 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:57:16.182868 ops/training.py:65 2019-01-16 20:57:16.182811: step 4725, loss = 0.72176 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:57:17.071623 ops/training.py:65 2019-01-16 20:57:17.071565: step 4726, loss = 0.71929 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:57:17.960460 ops/training.py:65 2019-01-16 20:57:17.960398: step 4727, loss = 0.68760 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:57:18.849075 ops/training.py:65 2019-01-16 20:57:18.849017: step 4728, loss = 0.72062 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:57:19.741606 ops/training.py:65 2019-01-16 20:57:19.741561: step 4729, loss = 0.70103 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:57:20.635349 ops/training.py:65 2019-01-16 20:57:20.635260: step 4730, loss = 0.69032 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:57:21.527126 ops/training.py:65 2019-01-16 20:57:21.527046: step 4731, loss = 0.69469 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:57:22.418819 ops/training.py:65 2019-01-16 20:57:22.418709: step 4732, loss = 0.71688 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:57:23.311855 ops/training.py:65 2019-01-16 20:57:23.311763: step 4733, loss = 0.70190 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:57:24.204089 ops/training.py:65 2019-01-16 20:57:24.204014: step 4734, loss = 0.72692 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:57:25.096417 ops/training.py:65 2019-01-16 20:57:25.096315: step 4735, loss = 0.68060 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:57:25.988415 ops/training.py:65 2019-01-16 20:57:25.988348: step 4736, loss = 0.71728 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:57:26.880738 ops/training.py:65 2019-01-16 20:57:26.880654: step 4737, loss = 0.71352 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:57:27.772689 ops/training.py:65 2019-01-16 20:57:27.772591: step 4738, loss = 0.69082 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:57:28.663210 ops/training.py:65 2019-01-16 20:57:28.663154: step 4739, loss = 0.66891 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:57:29.554196 ops/training.py:65 2019-01-16 20:57:29.554154: step 4740, loss = 0.68561 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:57:30.445556 ops/training.py:65 2019-01-16 20:57:30.445477: step 4741, loss = 0.70260 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:57:31.335806 ops/training.py:65 2019-01-16 20:57:31.335760: step 4742, loss = 0.72145 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:57:32.225435 ops/training.py:65 2019-01-16 20:57:32.225331: step 4743, loss = 0.71853 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:57:33.121189 ops/training.py:65 2019-01-16 20:57:33.121146: step 4744, loss = 0.67238 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:57:34.012344 ops/training.py:65 2019-01-16 20:57:34.012272: step 4745, loss = 0.70943 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:57:34.904489 ops/training.py:65 2019-01-16 20:57:34.904385: step 4746, loss = 0.67853 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:57:35.794602 ops/training.py:65 2019-01-16 20:57:35.794537: step 4747, loss = 0.67684 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:57:36.683638 ops/training.py:65 2019-01-16 20:57:36.683578: step 4748, loss = 0.71741 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:57:37.575600 ops/training.py:65 2019-01-16 20:57:37.575560: step 4749, loss = 0.71186 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:57:38.466934 ops/training.py:65 2019-01-16 20:57:38.466846: step 4750, loss = 0.71116 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:57:39.358052 ops/training.py:65 2019-01-16 20:57:39.357984: step 4751, loss = 0.72051 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:57:40.247537 ops/training.py:65 2019-01-16 20:57:40.247473: step 4752, loss = 0.69581 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:57:41.137306 ops/training.py:65 2019-01-16 20:57:41.137266: step 4753, loss = 0.68836 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:57:42.030867 ops/training.py:65 2019-01-16 20:57:42.030802: step 4754, loss = 0.70980 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:57:42.922962 ops/training.py:65 2019-01-16 20:57:42.922855: step 4755, loss = 0.73857 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:57:43.814345 ops/training.py:65 2019-01-16 20:57:43.814269: step 4756, loss = 0.69774 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:57:44.704176 ops/training.py:65 2019-01-16 20:57:44.704114: step 4757, loss = 0.73565 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:57:45.592985 ops/training.py:65 2019-01-16 20:57:45.592921: step 4758, loss = 0.71570 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:57:46.484631 ops/training.py:65 2019-01-16 20:57:46.484580: step 4759, loss = 0.70077 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:57:47.375295 ops/training.py:65 2019-01-16 20:57:47.375232: step 4760, loss = 0.70650 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:57:48.269341 ops/training.py:65 2019-01-16 20:57:48.269294: step 4761, loss = 0.73485 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:57:49.160739 ops/training.py:65 2019-01-16 20:57:49.160656: step 4762, loss = 0.70808 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:57:50.053189 ops/training.py:65 2019-01-16 20:57:50.053079: step 4763, loss = 0.71703 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:57:50.944995 ops/training.py:65 2019-01-16 20:57:50.944929: step 4764, loss = 0.70495 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:57:51.839924 ops/training.py:65 2019-01-16 20:57:51.839867: step 4765, loss = 0.72060 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:57:52.732371 ops/training.py:65 2019-01-16 20:57:52.732264: step 4766, loss = 0.69283 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:57:53.624206 ops/training.py:65 2019-01-16 20:57:53.624135: step 4767, loss = 0.68952 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:57:54.512894 ops/training.py:65 2019-01-16 20:57:54.512836: step 4768, loss = 0.70710 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:57:55.401495 ops/training.py:65 2019-01-16 20:57:55.401435: step 4769, loss = 0.68483 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:57:56.290025 ops/training.py:65 2019-01-16 20:57:56.289963: step 4770, loss = 0.70769 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:57:57.184216 ops/training.py:65 2019-01-16 20:57:57.184170: step 4771, loss = 0.70172 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:57:58.075330 ops/training.py:65 2019-01-16 20:57:58.075253: step 4772, loss = 0.71824 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:57:58.968330 ops/training.py:65 2019-01-16 20:57:58.968223: step 4773, loss = 0.70323 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:57:59.859854 ops/training.py:65 2019-01-16 20:57:59.859769: step 4774, loss = 0.69401 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:58:00.754966 ops/training.py:65 2019-01-16 20:58:00.754895: step 4775, loss = 0.70620 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:58:01.646037 ops/training.py:65 2019-01-16 20:58:01.645943: step 4776, loss = 0.69250 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:58:02.537364 ops/training.py:65 2019-01-16 20:58:02.537305: step 4777, loss = 0.71943 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:58:03.426229 ops/training.py:65 2019-01-16 20:58:03.426165: step 4778, loss = 0.68684 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:58:04.315506 ops/training.py:65 2019-01-16 20:58:04.315450: step 4779, loss = 0.69898 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:58:05.204650 ops/training.py:65 2019-01-16 20:58:05.204592: step 4780, loss = 0.71051 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:58:06.093984 ops/training.py:65 2019-01-16 20:58:06.093916: step 4781, loss = 0.69802 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:58:06.982561 ops/training.py:65 2019-01-16 20:58:06.982498: step 4782, loss = 0.70317 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:58:07.872720 ops/training.py:65 2019-01-16 20:58:07.872658: step 4783, loss = 0.70750 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:58:08.767317 ops/training.py:65 2019-01-16 20:58:08.767280: step 4784, loss = 0.67212 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:58:09.660426 ops/training.py:65 2019-01-16 20:58:09.660344: step 4785, loss = 0.69417 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:58:10.552636 ops/training.py:65 2019-01-16 20:58:10.552541: step 4786, loss = 0.70415 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:58:11.443714 ops/training.py:65 2019-01-16 20:58:11.443648: step 4787, loss = 0.67742 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:58:12.333091 ops/training.py:65 2019-01-16 20:58:12.333031: step 4788, loss = 0.72667 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:58:13.225612 ops/training.py:65 2019-01-16 20:58:13.225568: step 4789, loss = 0.67414 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:58:14.116332 ops/training.py:65 2019-01-16 20:58:14.116286: step 4790, loss = 0.71175 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:58:15.009091 ops/training.py:65 2019-01-16 20:58:15.008991: step 4791, loss = 0.70100 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:58:15.901500 ops/training.py:65 2019-01-16 20:58:15.901410: step 4792, loss = 0.72267 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:58:16.791838 ops/training.py:65 2019-01-16 20:58:16.791779: step 4793, loss = 0.68078 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:58:17.680575 ops/training.py:65 2019-01-16 20:58:17.680518: step 4794, loss = 0.68565 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:58:18.569345 ops/training.py:65 2019-01-16 20:58:18.569287: step 4795, loss = 0.70241 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:58:19.458688 ops/training.py:65 2019-01-16 20:58:19.458634: step 4796, loss = 0.70008 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:58:20.347262 ops/training.py:65 2019-01-16 20:58:20.347205: step 4797, loss = 0.69233 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:58:21.236201 ops/training.py:65 2019-01-16 20:58:21.236142: step 4798, loss = 0.70570 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:58:22.125900 ops/training.py:65 2019-01-16 20:58:22.125836: step 4799, loss = 0.66788 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:58:23.016061 ops/training.py:65 2019-01-16 20:58:23.015997: step 4800, loss = 0.71405 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:58:23.907257 ops/training.py:65 2019-01-16 20:58:23.907183: step 4801, loss = 0.69088 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:58:24.799888 ops/training.py:65 2019-01-16 20:58:24.799784: step 4802, loss = 0.68613 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:58:25.690694 ops/training.py:65 2019-01-16 20:58:25.690631: step 4803, loss = 0.70011 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:58:26.579432 ops/training.py:65 2019-01-16 20:58:26.579373: step 4804, loss = 0.69881 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:58:27.470989 ops/training.py:65 2019-01-16 20:58:27.470926: step 4805, loss = 0.69468 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:58:28.362222 ops/training.py:65 2019-01-16 20:58:28.362138: step 4806, loss = 0.71889 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:58:29.255256 ops/training.py:65 2019-01-16 20:58:29.255168: step 4807, loss = 0.70073 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:58:30.147629 ops/training.py:65 2019-01-16 20:58:30.147524: step 4808, loss = 0.64804 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.75
I2992 2019-01-16 20:58:31.040304 ops/training.py:65 2019-01-16 20:58:31.040208: step 4809, loss = 0.69246 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:58:31.931319 ops/training.py:65 2019-01-16 20:58:31.931252: step 4810, loss = 0.68756 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:58:32.822599 ops/training.py:65 2019-01-16 20:58:32.822492: step 4811, loss = 0.69974 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:58:33.713818 ops/training.py:65 2019-01-16 20:58:33.713755: step 4812, loss = 0.67060 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:58:34.604640 ops/training.py:65 2019-01-16 20:58:34.604579: step 4813, loss = 0.69537 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:58:35.494160 ops/training.py:65 2019-01-16 20:58:35.494100: step 4814, loss = 0.66370 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.75
I2992 2019-01-16 20:58:36.386375 ops/training.py:65 2019-01-16 20:58:36.386312: step 4815, loss = 0.71791 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:58:37.277591 ops/training.py:65 2019-01-16 20:58:37.277520: step 4816, loss = 0.71061 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:58:38.169852 ops/training.py:65 2019-01-16 20:58:38.169753: step 4817, loss = 0.69741 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:58:39.060911 ops/training.py:65 2019-01-16 20:58:39.060857: step 4818, loss = 0.68835 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:58:39.951373 ops/training.py:65 2019-01-16 20:58:39.951303: step 4819, loss = 0.68869 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:58:40.842559 ops/training.py:65 2019-01-16 20:58:40.842482: step 4820, loss = 0.70424 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:58:41.734985 ops/training.py:65 2019-01-16 20:58:41.734887: step 4821, loss = 0.73027 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:58:42.626469 ops/training.py:65 2019-01-16 20:58:42.626383: step 4822, loss = 0.68670 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:58:43.517233 ops/training.py:65 2019-01-16 20:58:43.517167: step 4823, loss = 0.71585 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:58:44.406960 ops/training.py:65 2019-01-16 20:58:44.406900: step 4824, loss = 0.70224 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:58:45.295742 ops/training.py:65 2019-01-16 20:58:45.295684: step 4825, loss = 0.72636 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:58:46.184545 ops/training.py:65 2019-01-16 20:58:46.184487: step 4826, loss = 0.70984 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:58:47.073560 ops/training.py:65 2019-01-16 20:58:47.073489: step 4827, loss = 0.68848 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:58:47.962744 ops/training.py:65 2019-01-16 20:58:47.962666: step 4828, loss = 0.72542 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:58:48.852119 ops/training.py:65 2019-01-16 20:58:48.852047: step 4829, loss = 0.68824 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:58:49.741504 ops/training.py:65 2019-01-16 20:58:49.741437: step 4830, loss = 0.68799 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:58:50.630590 ops/training.py:65 2019-01-16 20:58:50.630528: step 4831, loss = 0.71219 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:58:51.519020 ops/training.py:65 2019-01-16 20:58:51.518959: step 4832, loss = 0.70360 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:58:52.407227 ops/training.py:65 2019-01-16 20:58:52.407167: step 4833, loss = 0.71596 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:58:53.295498 ops/training.py:65 2019-01-16 20:58:53.295435: step 4834, loss = 0.68755 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:58:54.184508 ops/training.py:65 2019-01-16 20:58:54.184452: step 4835, loss = 0.70100 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:58:55.072997 ops/training.py:65 2019-01-16 20:58:55.072935: step 4836, loss = 0.69593 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:58:55.961893 ops/training.py:65 2019-01-16 20:58:55.961836: step 4837, loss = 0.72846 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 20:58:56.850002 ops/training.py:65 2019-01-16 20:58:56.849942: step 4838, loss = 0.70118 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:58:57.738082 ops/training.py:65 2019-01-16 20:58:57.738022: step 4839, loss = 0.68184 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:58:58.626617 ops/training.py:65 2019-01-16 20:58:58.626556: step 4840, loss = 0.69097 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:58:59.515801 ops/training.py:65 2019-01-16 20:58:59.515723: step 4841, loss = 0.67971 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:59:00.404952 ops/training.py:65 2019-01-16 20:59:00.404868: step 4842, loss = 0.70617 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:59:01.293073 ops/training.py:65 2019-01-16 20:59:01.293012: step 4843, loss = 0.67765 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:59:02.181327 ops/training.py:65 2019-01-16 20:59:02.181272: step 4844, loss = 0.71697 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:59:03.069830 ops/training.py:65 2019-01-16 20:59:03.069765: step 4845, loss = 0.73791 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:59:03.961501 ops/training.py:65 2019-01-16 20:59:03.961430: step 4846, loss = 0.73314 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:59:04.851795 ops/training.py:65 2019-01-16 20:59:04.851712: step 4847, loss = 0.68168 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:59:05.743664 ops/training.py:65 2019-01-16 20:59:05.743566: step 4848, loss = 0.71795 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:59:06.635361 ops/training.py:65 2019-01-16 20:59:06.635259: step 4849, loss = 0.69884 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:59:07.526013 ops/training.py:65 2019-01-16 20:59:07.525947: step 4850, loss = 0.69657 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:59:08.415330 ops/training.py:65 2019-01-16 20:59:08.415267: step 4851, loss = 0.70570 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:59:09.303939 ops/training.py:65 2019-01-16 20:59:09.303878: step 4852, loss = 0.69962 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:59:10.192050 ops/training.py:65 2019-01-16 20:59:10.191989: step 4853, loss = 0.72892 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:59:11.084122 ops/training.py:65 2019-01-16 20:59:11.084060: step 4854, loss = 0.73761 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:59:11.979173 ops/training.py:65 2019-01-16 20:59:11.979091: step 4855, loss = 0.70120 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:59:12.870150 ops/training.py:65 2019-01-16 20:59:12.870045: step 4856, loss = 0.70802 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:59:13.761272 ops/training.py:65 2019-01-16 20:59:13.761195: step 4857, loss = 0.69492 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:59:14.653788 ops/training.py:65 2019-01-16 20:59:14.653703: step 4858, loss = 0.68578 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:59:15.546927 ops/training.py:65 2019-01-16 20:59:15.546833: step 4859, loss = 0.71874 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:59:16.440061 ops/training.py:65 2019-01-16 20:59:16.439957: step 4860, loss = 0.68870 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:59:17.332810 ops/training.py:65 2019-01-16 20:59:17.332709: step 4861, loss = 0.67861 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:59:18.223461 ops/training.py:65 2019-01-16 20:59:18.223398: step 4862, loss = 0.71517 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:59:19.112829 ops/training.py:65 2019-01-16 20:59:19.112766: step 4863, loss = 0.72329 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:59:20.001572 ops/training.py:65 2019-01-16 20:59:20.001510: step 4864, loss = 0.63402 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 20:59:20.892290 ops/training.py:65 2019-01-16 20:59:20.892248: step 4865, loss = 0.68505 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:59:21.784945 ops/training.py:65 2019-01-16 20:59:21.784887: step 4866, loss = 0.70034 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:59:22.677669 ops/training.py:65 2019-01-16 20:59:22.677564: step 4867, loss = 0.69376 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:59:23.569673 ops/training.py:65 2019-01-16 20:59:23.569586: step 4868, loss = 0.66524 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:59:24.459200 ops/training.py:65 2019-01-16 20:59:24.459138: step 4869, loss = 0.69920 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:59:25.348323 ops/training.py:65 2019-01-16 20:59:25.348264: step 4870, loss = 0.68354 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:59:26.236899 ops/training.py:65 2019-01-16 20:59:26.236842: step 4871, loss = 0.69029 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:59:27.124925 ops/training.py:65 2019-01-16 20:59:27.124873: step 4872, loss = 0.66771 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:59:28.018586 ops/training.py:65 2019-01-16 20:59:28.018523: step 4873, loss = 0.72470 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 20:59:28.910543 ops/training.py:65 2019-01-16 20:59:28.910440: step 4874, loss = 0.70163 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:59:29.806481 ops/training.py:65 2019-01-16 20:59:29.806409: step 4875, loss = 0.69752 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:59:30.697415 ops/training.py:65 2019-01-16 20:59:30.697311: step 4876, loss = 0.68377 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:59:31.590584 ops/training.py:65 2019-01-16 20:59:31.590537: step 4877, loss = 0.70871 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:59:32.480012 ops/training.py:65 2019-01-16 20:59:32.479941: step 4878, loss = 0.70313 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:59:33.370007 ops/training.py:65 2019-01-16 20:59:33.369917: step 4879, loss = 0.69897 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:59:34.260074 ops/training.py:65 2019-01-16 20:59:34.259968: step 4880, loss = 0.69956 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:59:35.150982 ops/training.py:65 2019-01-16 20:59:35.150892: step 4881, loss = 0.67672 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 20:59:36.039468 ops/training.py:65 2019-01-16 20:59:36.039408: step 4882, loss = 0.69180 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:59:36.928554 ops/training.py:65 2019-01-16 20:59:36.928499: step 4883, loss = 0.67250 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 20:59:37.817028 ops/training.py:65 2019-01-16 20:59:37.816965: step 4884, loss = 0.67864 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:59:38.706964 ops/training.py:65 2019-01-16 20:59:38.706894: step 4885, loss = 0.68080 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:59:39.596514 ops/training.py:65 2019-01-16 20:59:39.596444: step 4886, loss = 0.67950 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:59:40.486166 ops/training.py:65 2019-01-16 20:59:40.486088: step 4887, loss = 0.68589 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:59:41.375931 ops/training.py:65 2019-01-16 20:59:41.375835: step 4888, loss = 0.70081 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:59:42.265262 ops/training.py:65 2019-01-16 20:59:42.265208: step 4889, loss = 0.69687 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:59:43.154609 ops/training.py:65 2019-01-16 20:59:43.154545: step 4890, loss = 0.68588 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:59:44.043650 ops/training.py:65 2019-01-16 20:59:44.043591: step 4891, loss = 0.70025 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:59:44.931452 ops/training.py:65 2019-01-16 20:59:44.931396: step 4892, loss = 0.69458 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:59:45.820420 ops/training.py:65 2019-01-16 20:59:45.820366: step 4893, loss = 0.70196 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:59:46.713130 ops/training.py:65 2019-01-16 20:59:46.713077: step 4894, loss = 0.70615 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:59:47.606335 ops/training.py:65 2019-01-16 20:59:47.606237: step 4895, loss = 0.70215 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:59:48.498848 ops/training.py:65 2019-01-16 20:59:48.498748: step 4896, loss = 0.72074 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:59:49.389786 ops/training.py:65 2019-01-16 20:59:49.389683: step 4897, loss = 0.69171 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:59:50.279660 ops/training.py:65 2019-01-16 20:59:50.279595: step 4898, loss = 0.71189 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:59:51.168309 ops/training.py:65 2019-01-16 20:59:51.168246: step 4899, loss = 0.70092 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 20:59:52.057133 ops/training.py:65 2019-01-16 20:59:52.057079: step 4900, loss = 0.68855 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 20:59:52.946462 ops/training.py:65 2019-01-16 20:59:52.946400: step 4901, loss = 0.71435 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 20:59:53.838255 ops/training.py:65 2019-01-16 20:59:53.838207: step 4902, loss = 0.73027 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 20:59:54.730042 ops/training.py:65 2019-01-16 20:59:54.729935: step 4903, loss = 0.69644 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 20:59:55.621786 ops/training.py:65 2019-01-16 20:59:55.621728: step 4904, loss = 0.71109 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 20:59:56.511321 ops/training.py:65 2019-01-16 20:59:56.511262: step 4905, loss = 0.69562 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:59:57.400658 ops/training.py:65 2019-01-16 20:59:57.400596: step 4906, loss = 0.68552 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 20:59:58.292439 ops/training.py:65 2019-01-16 20:59:58.292379: step 4907, loss = 0.69192 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 20:59:59.185169 ops/training.py:65 2019-01-16 20:59:59.185076: step 4908, loss = 0.68485 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:00:00.078192 ops/training.py:65 2019-01-16 21:00:00.078091: step 4909, loss = 0.68213 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:00:00.970795 ops/training.py:65 2019-01-16 21:00:00.970733: step 4910, loss = 0.69700 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:00:01.861862 ops/training.py:65 2019-01-16 21:00:01.861790: step 4911, loss = 0.72567 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 21:00:02.754564 ops/training.py:65 2019-01-16 21:00:02.754498: step 4912, loss = 0.71938 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 21:00:03.646082 ops/training.py:65 2019-01-16 21:00:03.645997: step 4913, loss = 0.70336 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:00:04.537538 ops/training.py:65 2019-01-16 21:00:04.537436: step 4914, loss = 0.68315 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:00:05.428734 ops/training.py:65 2019-01-16 21:00:05.428671: step 4915, loss = 0.68698 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:00:06.318113 ops/training.py:65 2019-01-16 21:00:06.318052: step 4916, loss = 0.70790 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:00:07.210144 ops/training.py:65 2019-01-16 21:00:07.210075: step 4917, loss = 0.70754 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:00:08.102363 ops/training.py:65 2019-01-16 21:00:08.102286: step 4918, loss = 0.67801 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:00:08.994290 ops/training.py:65 2019-01-16 21:00:08.994194: step 4919, loss = 0.70588 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:00:09.886946 ops/training.py:65 2019-01-16 21:00:09.886846: step 4920, loss = 0.72502 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:00:10.778399 ops/training.py:65 2019-01-16 21:00:10.778341: step 4921, loss = 0.69466 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:00:11.668891 ops/training.py:65 2019-01-16 21:00:11.668826: step 4922, loss = 0.70210 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:00:12.561297 ops/training.py:65 2019-01-16 21:00:12.561208: step 4923, loss = 0.68441 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:00:13.454490 ops/training.py:65 2019-01-16 21:00:13.454392: step 4924, loss = 0.70202 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:00:14.345763 ops/training.py:65 2019-01-16 21:00:14.345671: step 4925, loss = 0.68618 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:00:15.237748 ops/training.py:65 2019-01-16 21:00:15.237642: step 4926, loss = 0.70034 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:00:16.130439 ops/training.py:65 2019-01-16 21:00:16.130362: step 4927, loss = 0.72188 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:00:17.023155 ops/training.py:65 2019-01-16 21:00:17.023051: step 4928, loss = 0.71885 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:00:17.914706 ops/training.py:65 2019-01-16 21:00:17.914642: step 4929, loss = 0.67552 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:00:18.805266 ops/training.py:65 2019-01-16 21:00:18.805204: step 4930, loss = 0.71688 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:00:19.694857 ops/training.py:65 2019-01-16 21:00:19.694800: step 4931, loss = 0.71959 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:00:20.585152 ops/training.py:65 2019-01-16 21:00:20.585094: step 4932, loss = 0.67989 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:00:21.475111 ops/training.py:65 2019-01-16 21:00:21.475050: step 4933, loss = 0.69920 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:00:22.364681 ops/training.py:65 2019-01-16 21:00:22.364621: step 4934, loss = 0.71665 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:00:23.254149 ops/training.py:65 2019-01-16 21:00:23.254078: step 4935, loss = 0.68771 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:00:24.144250 ops/training.py:65 2019-01-16 21:00:24.144186: step 4936, loss = 0.69938 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:00:25.034022 ops/training.py:65 2019-01-16 21:00:25.033959: step 4937, loss = 0.69341 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:00:25.922654 ops/training.py:65 2019-01-16 21:00:25.922591: step 4938, loss = 0.68039 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:00:26.812669 ops/training.py:65 2019-01-16 21:00:26.812600: step 4939, loss = 0.71576 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:00:27.703234 ops/training.py:65 2019-01-16 21:00:27.703174: step 4940, loss = 0.70677 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:00:28.593121 ops/training.py:65 2019-01-16 21:00:28.593058: step 4941, loss = 0.71220 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:00:29.483655 ops/training.py:65 2019-01-16 21:00:29.483597: step 4942, loss = 0.69664 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:00:30.373344 ops/training.py:65 2019-01-16 21:00:30.373286: step 4943, loss = 0.67028 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:00:31.263442 ops/training.py:65 2019-01-16 21:00:31.263380: step 4944, loss = 0.68567 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:00:32.153821 ops/training.py:65 2019-01-16 21:00:32.153762: step 4945, loss = 0.73314 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:00:33.042946 ops/training.py:65 2019-01-16 21:00:33.042887: step 4946, loss = 0.72426 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:00:33.932983 ops/training.py:65 2019-01-16 21:00:33.932920: step 4947, loss = 0.69136 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:00:34.822314 ops/training.py:65 2019-01-16 21:00:34.822254: step 4948, loss = 0.70953 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:00:35.711837 ops/training.py:65 2019-01-16 21:00:35.711780: step 4949, loss = 0.69761 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:00:36.601341 ops/training.py:65 2019-01-16 21:00:36.601282: step 4950, loss = 0.68225 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:00:37.490234 ops/training.py:65 2019-01-16 21:00:37.490172: step 4951, loss = 0.70258 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:00:38.379895 ops/training.py:65 2019-01-16 21:00:38.379829: step 4952, loss = 0.71357 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:00:39.269543 ops/training.py:65 2019-01-16 21:00:39.269477: step 4953, loss = 0.72140 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:00:40.158876 ops/training.py:65 2019-01-16 21:00:40.158798: step 4954, loss = 0.69644 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:00:41.048450 ops/training.py:65 2019-01-16 21:00:41.048380: step 4955, loss = 0.72540 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:00:41.937196 ops/training.py:65 2019-01-16 21:00:41.937122: step 4956, loss = 0.68280 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:00:42.826931 ops/training.py:65 2019-01-16 21:00:42.826868: step 4957, loss = 0.69658 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:00:43.716048 ops/training.py:65 2019-01-16 21:00:43.715977: step 4958, loss = 0.70434 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:00:44.605817 ops/training.py:65 2019-01-16 21:00:44.605755: step 4959, loss = 0.71522 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:00:45.494443 ops/training.py:65 2019-01-16 21:00:45.494383: step 4960, loss = 0.71152 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:00:46.384169 ops/training.py:65 2019-01-16 21:00:46.384097: step 4961, loss = 0.72076 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:00:47.275852 ops/training.py:65 2019-01-16 21:00:47.275752: step 4962, loss = 0.69986 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:00:48.167501 ops/training.py:65 2019-01-16 21:00:48.167444: step 4963, loss = 0.67734 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:00:49.056401 ops/training.py:65 2019-01-16 21:00:49.056343: step 4964, loss = 0.66295 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:00:49.946104 ops/training.py:65 2019-01-16 21:00:49.946038: step 4965, loss = 0.68459 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:00:50.836381 ops/training.py:65 2019-01-16 21:00:50.836321: step 4966, loss = 0.70758 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:00:51.727983 ops/training.py:65 2019-01-16 21:00:51.727892: step 4967, loss = 0.68214 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:00:52.619782 ops/training.py:65 2019-01-16 21:00:52.619683: step 4968, loss = 0.68928 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:00:53.509935 ops/training.py:65 2019-01-16 21:00:53.509870: step 4969, loss = 0.67989 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:00:54.399247 ops/training.py:65 2019-01-16 21:00:54.399217: step 4970, loss = 0.68260 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:00:55.290976 ops/training.py:65 2019-01-16 21:00:55.290939: step 4971, loss = 0.68116 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:00:56.182765 ops/training.py:65 2019-01-16 21:00:56.182663: step 4972, loss = 0.71400 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:00:57.074036 ops/training.py:65 2019-01-16 21:00:57.073929: step 4973, loss = 0.72160 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:00:57.964334 ops/training.py:65 2019-01-16 21:00:57.964234: step 4974, loss = 0.69513 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:00:58.853061 ops/training.py:65 2019-01-16 21:00:58.853003: step 4975, loss = 0.70088 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:00:59.740705 ops/training.py:65 2019-01-16 21:00:59.740646: step 4976, loss = 0.68266 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:01:00.630150 ops/training.py:65 2019-01-16 21:01:00.630118: step 4977, loss = 0.68390 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:01:01.520496 ops/training.py:65 2019-01-16 21:01:01.520437: step 4978, loss = 0.69076 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:01:02.412215 ops/training.py:65 2019-01-16 21:01:02.412149: step 4979, loss = 0.69253 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:01:03.304476 ops/training.py:65 2019-01-16 21:01:03.304377: step 4980, loss = 0.68028 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:01:04.196703 ops/training.py:65 2019-01-16 21:01:04.196599: step 4981, loss = 0.68953 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:01:05.087271 ops/training.py:65 2019-01-16 21:01:05.087176: step 4982, loss = 0.65960 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:01:05.977316 ops/training.py:65 2019-01-16 21:01:05.977258: step 4983, loss = 0.68925 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:01:06.866755 ops/training.py:65 2019-01-16 21:01:06.866698: step 4984, loss = 0.72585 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:01:07.756191 ops/training.py:65 2019-01-16 21:01:07.756133: step 4985, loss = 0.69634 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:01:08.645328 ops/training.py:65 2019-01-16 21:01:08.645274: step 4986, loss = 0.69687 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:01:09.534420 ops/training.py:65 2019-01-16 21:01:09.534364: step 4987, loss = 0.71152 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:01:10.423102 ops/training.py:65 2019-01-16 21:01:10.423045: step 4988, loss = 0.71923 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:01:11.312364 ops/training.py:65 2019-01-16 21:01:11.312306: step 4989, loss = 0.69694 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:01:12.201666 ops/training.py:65 2019-01-16 21:01:12.201606: step 4990, loss = 0.66737 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:01:13.091025 ops/training.py:65 2019-01-16 21:01:13.090959: step 4991, loss = 0.73309 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:01:13.981683 ops/training.py:65 2019-01-16 21:01:13.981625: step 4992, loss = 0.70916 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:01:14.871438 ops/training.py:65 2019-01-16 21:01:14.871372: step 4993, loss = 0.67868 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:01:15.761396 ops/training.py:65 2019-01-16 21:01:15.761331: step 4994, loss = 0.67223 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:01:16.653421 ops/training.py:65 2019-01-16 21:01:16.653354: step 4995, loss = 0.71124 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:01:17.545551 ops/training.py:65 2019-01-16 21:01:17.545455: step 4996, loss = 0.67876 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:01:18.438180 ops/training.py:65 2019-01-16 21:01:18.438079: step 4997, loss = 0.69316 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:01:19.330843 ops/training.py:65 2019-01-16 21:01:19.330780: step 4998, loss = 0.72491 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:01:20.221438 ops/training.py:65 2019-01-16 21:01:20.221379: step 4999, loss = 0.71354 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:01:21.113937 ops/training.py:65 2019-01-16 21:01:21.113870: step 5000, loss = 0.67910 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:01:22.005196 ops/training.py:65 2019-01-16 21:01:22.005104: step 5001, loss = 0.73054 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:01:22.898036 ops/training.py:65 2019-01-16 21:01:22.897948: step 5002, loss = 0.69915 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:01:23.792119 ops/training.py:65 2019-01-16 21:01:23.792027: step 5003, loss = 0.69576 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:01:24.684143 ops/training.py:65 2019-01-16 21:01:24.684071: step 5004, loss = 0.73247 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:01:25.575446 ops/training.py:65 2019-01-16 21:01:25.575362: step 5005, loss = 0.66240 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:01:26.467430 ops/training.py:65 2019-01-16 21:01:26.467333: step 5006, loss = 0.70355 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:01:27.359388 ops/training.py:65 2019-01-16 21:01:27.359325: step 5007, loss = 0.70472 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:01:28.250757 ops/training.py:65 2019-01-16 21:01:28.250681: step 5008, loss = 0.67893 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:01:29.142721 ops/training.py:65 2019-01-16 21:01:29.142622: step 5009, loss = 0.68851 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:01:30.033705 ops/training.py:65 2019-01-16 21:01:30.033623: step 5010, loss = 0.71741 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 21:01:30.923391 ops/training.py:65 2019-01-16 21:01:30.923330: step 5011, loss = 0.69001 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:01:31.812601 ops/training.py:65 2019-01-16 21:01:31.812536: step 5012, loss = 0.72060 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:01:32.702549 ops/training.py:65 2019-01-16 21:01:32.702486: step 5013, loss = 0.69934 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:01:33.591541 ops/training.py:65 2019-01-16 21:01:33.591475: step 5014, loss = 0.68247 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:01:34.481048 ops/training.py:65 2019-01-16 21:01:34.480994: step 5015, loss = 0.69650 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:01:35.370701 ops/training.py:65 2019-01-16 21:01:35.370637: step 5016, loss = 0.70700 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:01:36.260198 ops/training.py:65 2019-01-16 21:01:36.260138: step 5017, loss = 0.67266 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:01:37.149675 ops/training.py:65 2019-01-16 21:01:37.149628: step 5018, loss = 0.69662 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:01:38.039490 ops/training.py:65 2019-01-16 21:01:38.039443: step 5019, loss = 0.69398 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:01:38.931231 ops/training.py:65 2019-01-16 21:01:38.931197: step 5020, loss = 0.68913 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:01:39.822601 ops/training.py:65 2019-01-16 21:01:39.822537: step 5021, loss = 0.72310 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:01:40.711974 ops/training.py:65 2019-01-16 21:01:40.711913: step 5022, loss = 0.68979 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:01:41.601674 ops/training.py:65 2019-01-16 21:01:41.601631: step 5023, loss = 0.71143 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:01:42.490605 ops/training.py:65 2019-01-16 21:01:42.490565: step 5024, loss = 0.73821 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:01:43.379948 ops/training.py:65 2019-01-16 21:01:43.379900: step 5025, loss = 0.68481 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:01:44.269087 ops/training.py:65 2019-01-16 21:01:44.269039: step 5026, loss = 0.74637 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:01:45.158338 ops/training.py:65 2019-01-16 21:01:45.158287: step 5027, loss = 0.67489 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:01:46.047349 ops/training.py:65 2019-01-16 21:01:46.047297: step 5028, loss = 0.65251 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:01:46.935990 ops/training.py:65 2019-01-16 21:01:46.935946: step 5029, loss = 0.74629 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:01:47.825147 ops/training.py:65 2019-01-16 21:01:47.825092: step 5030, loss = 0.71868 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:01:48.714738 ops/training.py:65 2019-01-16 21:01:48.714688: step 5031, loss = 0.70750 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:01:49.604195 ops/training.py:65 2019-01-16 21:01:49.604145: step 5032, loss = 0.67799 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:01:50.495551 ops/training.py:65 2019-01-16 21:01:50.495513: step 5033, loss = 0.72395 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:01:51.386492 ops/training.py:65 2019-01-16 21:01:51.386460: step 5034, loss = 0.74316 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:01:52.277570 ops/training.py:65 2019-01-16 21:01:52.277498: step 5035, loss = 0.68714 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:01:53.167443 ops/training.py:65 2019-01-16 21:01:53.167375: step 5036, loss = 0.69938 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:01:54.059246 ops/training.py:65 2019-01-16 21:01:54.059167: step 5037, loss = 0.71581 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:01:54.951361 ops/training.py:65 2019-01-16 21:01:54.951254: step 5038, loss = 0.71660 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:01:55.845033 ops/training.py:65 2019-01-16 21:01:55.844985: step 5039, loss = 0.69341 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:01:56.737372 ops/training.py:65 2019-01-16 21:01:56.737264: step 5040, loss = 0.73341 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:01:57.627830 ops/training.py:65 2019-01-16 21:01:57.627759: step 5041, loss = 0.67791 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:01:58.517361 ops/training.py:65 2019-01-16 21:01:58.517301: step 5042, loss = 0.68890 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:01:59.407081 ops/training.py:65 2019-01-16 21:01:59.407018: step 5043, loss = 0.67917 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:02:00.296002 ops/training.py:65 2019-01-16 21:02:00.295942: step 5044, loss = 0.69938 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:02:01.187375 ops/training.py:65 2019-01-16 21:02:01.187303: step 5045, loss = 0.67761 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:02:02.079937 ops/training.py:65 2019-01-16 21:02:02.079833: step 5046, loss = 0.73282 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:02:02.972163 ops/training.py:65 2019-01-16 21:02:02.972093: step 5047, loss = 0.70397 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:02:03.861738 ops/training.py:65 2019-01-16 21:02:03.861675: step 5048, loss = 0.71822 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:02:04.752183 ops/training.py:65 2019-01-16 21:02:04.752121: step 5049, loss = 0.68289 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:02:05.641887 ops/training.py:65 2019-01-16 21:02:05.641827: step 5050, loss = 0.72066 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:02:06.533850 ops/training.py:65 2019-01-16 21:02:06.533789: step 5051, loss = 0.68390 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:02:07.424825 ops/training.py:65 2019-01-16 21:02:07.424758: step 5052, loss = 0.67572 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:02:08.314576 ops/training.py:65 2019-01-16 21:02:08.314512: step 5053, loss = 0.69689 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:02:09.204532 ops/training.py:65 2019-01-16 21:02:09.204469: step 5054, loss = 0.70290 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:02:10.094226 ops/training.py:65 2019-01-16 21:02:10.094160: step 5055, loss = 0.66266 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:02:10.983252 ops/training.py:65 2019-01-16 21:02:10.983189: step 5056, loss = 0.69266 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:02:11.875012 ops/training.py:65 2019-01-16 21:02:11.874934: step 5057, loss = 0.68375 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:02:12.767473 ops/training.py:65 2019-01-16 21:02:12.767381: step 5058, loss = 0.70954 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:02:13.658167 ops/training.py:65 2019-01-16 21:02:13.658081: step 5059, loss = 0.68513 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:02:14.549704 ops/training.py:65 2019-01-16 21:02:14.549616: step 5060, loss = 0.71164 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:02:15.441892 ops/training.py:65 2019-01-16 21:02:15.441782: step 5061, loss = 0.69910 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:02:16.333385 ops/training.py:65 2019-01-16 21:02:16.333304: step 5062, loss = 0.68259 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:02:17.225324 ops/training.py:65 2019-01-16 21:02:17.225226: step 5063, loss = 0.66807 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:02:18.117196 ops/training.py:65 2019-01-16 21:02:18.117134: step 5064, loss = 0.69510 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:02:19.006591 ops/training.py:65 2019-01-16 21:02:19.006528: step 5065, loss = 0.64746 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.75
I2992 2019-01-16 21:02:19.896785 ops/training.py:65 2019-01-16 21:02:19.896720: step 5066, loss = 0.67485 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:02:20.786350 ops/training.py:65 2019-01-16 21:02:20.786277: step 5067, loss = 0.69840 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:02:21.676059 ops/training.py:65 2019-01-16 21:02:21.675992: step 5068, loss = 0.71675 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:02:22.565990 ops/training.py:65 2019-01-16 21:02:22.565930: step 5069, loss = 0.68672 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:02:23.455069 ops/training.py:65 2019-01-16 21:02:23.455004: step 5070, loss = 0.69196 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:02:24.344546 ops/training.py:65 2019-01-16 21:02:24.344478: step 5071, loss = 0.70059 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:02:25.233173 ops/training.py:65 2019-01-16 21:02:25.233107: step 5072, loss = 0.68102 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:02:26.122569 ops/training.py:65 2019-01-16 21:02:26.122498: step 5073, loss = 0.67584 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:02:27.011388 ops/training.py:65 2019-01-16 21:02:27.011321: step 5074, loss = 0.65392 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:02:27.901990 ops/training.py:65 2019-01-16 21:02:27.901911: step 5075, loss = 0.71945 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:02:28.794971 ops/training.py:65 2019-01-16 21:02:28.794863: step 5076, loss = 0.73617 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:02:29.686935 ops/training.py:65 2019-01-16 21:02:29.686875: step 5077, loss = 0.68621 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:02:30.578388 ops/training.py:65 2019-01-16 21:02:30.578285: step 5078, loss = 0.73101 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:02:31.471086 ops/training.py:65 2019-01-16 21:02:31.470979: step 5079, loss = 0.73936 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:02:32.361553 ops/training.py:65 2019-01-16 21:02:32.361446: step 5080, loss = 0.65740 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:02:33.252127 ops/training.py:65 2019-01-16 21:02:33.252061: step 5081, loss = 0.69068 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:02:34.140828 ops/training.py:65 2019-01-16 21:02:34.140765: step 5082, loss = 0.68526 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:02:35.029968 ops/training.py:65 2019-01-16 21:02:35.029904: step 5083, loss = 0.67947 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:02:35.918051 ops/training.py:65 2019-01-16 21:02:35.917988: step 5084, loss = 0.68595 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:02:36.807230 ops/training.py:65 2019-01-16 21:02:36.807164: step 5085, loss = 0.68771 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:02:37.697138 ops/training.py:65 2019-01-16 21:02:37.697069: step 5086, loss = 0.70264 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:02:38.588847 ops/training.py:65 2019-01-16 21:02:38.588740: step 5087, loss = 0.70890 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:02:39.480489 ops/training.py:65 2019-01-16 21:02:39.480388: step 5088, loss = 0.73691 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:02:40.372703 ops/training.py:65 2019-01-16 21:02:40.372610: step 5089, loss = 0.69113 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:02:41.264719 ops/training.py:65 2019-01-16 21:02:41.264630: step 5090, loss = 0.68625 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:02:42.157250 ops/training.py:65 2019-01-16 21:02:42.157155: step 5091, loss = 0.70727 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:02:43.049247 ops/training.py:65 2019-01-16 21:02:43.049148: step 5092, loss = 0.68253 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:02:43.942041 ops/training.py:65 2019-01-16 21:02:43.941946: step 5093, loss = 0.69673 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:02:44.831771 ops/training.py:65 2019-01-16 21:02:44.831712: step 5094, loss = 0.72355 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:02:45.722295 ops/training.py:65 2019-01-16 21:02:45.722228: step 5095, loss = 0.69853 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:02:46.615495 ops/training.py:65 2019-01-16 21:02:46.615392: step 5096, loss = 0.71606 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:02:47.509617 ops/training.py:65 2019-01-16 21:02:47.509509: step 5097, loss = 0.68529 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:02:48.403341 ops/training.py:65 2019-01-16 21:02:48.403274: step 5098, loss = 0.68791 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:02:49.295001 ops/training.py:65 2019-01-16 21:02:49.294939: step 5099, loss = 0.67845 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:02:50.188128 ops/training.py:65 2019-01-16 21:02:50.188032: step 5100, loss = 0.69947 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:02:51.080371 ops/training.py:65 2019-01-16 21:02:51.080282: step 5101, loss = 0.68801 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:02:51.972707 ops/training.py:65 2019-01-16 21:02:51.972615: step 5102, loss = 0.65960 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:02:52.865664 ops/training.py:65 2019-01-16 21:02:52.865570: step 5103, loss = 0.68174 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:02:53.758287 ops/training.py:65 2019-01-16 21:02:53.758189: step 5104, loss = 0.70137 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:02:54.649505 ops/training.py:65 2019-01-16 21:02:54.649410: step 5105, loss = 0.70360 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:02:55.541551 ops/training.py:65 2019-01-16 21:02:55.541455: step 5106, loss = 0.70498 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:02:56.434580 ops/training.py:65 2019-01-16 21:02:56.434507: step 5107, loss = 0.67891 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:02:57.325458 ops/training.py:65 2019-01-16 21:02:57.325363: step 5108, loss = 0.67674 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:02:58.218812 ops/training.py:65 2019-01-16 21:02:58.218721: step 5109, loss = 0.68814 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:02:59.110488 ops/training.py:65 2019-01-16 21:02:59.110382: step 5110, loss = 0.70973 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:03:00.001575 ops/training.py:65 2019-01-16 21:03:00.001471: step 5111, loss = 0.68928 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:03:00.892905 ops/training.py:65 2019-01-16 21:03:00.892801: step 5112, loss = 0.70297 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:03:01.784228 ops/training.py:65 2019-01-16 21:03:01.784163: step 5113, loss = 0.71293 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:03:02.674442 ops/training.py:65 2019-01-16 21:03:02.674386: step 5114, loss = 0.72564 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:03:03.565392 ops/training.py:65 2019-01-16 21:03:03.565331: step 5115, loss = 0.69888 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:03:04.455067 ops/training.py:65 2019-01-16 21:03:04.455006: step 5116, loss = 0.69475 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:03:05.343888 ops/training.py:65 2019-01-16 21:03:05.343827: step 5117, loss = 0.69861 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:03:06.233486 ops/training.py:65 2019-01-16 21:03:06.233423: step 5118, loss = 0.66285 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:03:07.123345 ops/training.py:65 2019-01-16 21:03:07.123287: step 5119, loss = 0.70952 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:03:08.013269 ops/training.py:65 2019-01-16 21:03:08.013212: step 5120, loss = 0.70495 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:03:08.902654 ops/training.py:65 2019-01-16 21:03:08.902585: step 5121, loss = 0.70051 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:03:09.791423 ops/training.py:65 2019-01-16 21:03:09.791358: step 5122, loss = 0.68170 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:03:10.680129 ops/training.py:65 2019-01-16 21:03:10.680074: step 5123, loss = 0.70037 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:03:11.569877 ops/training.py:65 2019-01-16 21:03:11.569820: step 5124, loss = 0.69215 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:03:12.461324 ops/training.py:65 2019-01-16 21:03:12.461261: step 5125, loss = 0.70685 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:03:13.353509 ops/training.py:65 2019-01-16 21:03:13.353378: step 5126, loss = 0.69193 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:03:14.245299 ops/training.py:65 2019-01-16 21:03:14.245198: step 5127, loss = 0.69562 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:03:15.139348 ops/training.py:65 2019-01-16 21:03:15.139245: step 5128, loss = 0.71415 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:03:16.032684 ops/training.py:65 2019-01-16 21:03:16.032578: step 5129, loss = 0.69549 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:03:16.924711 ops/training.py:65 2019-01-16 21:03:16.924645: step 5130, loss = 0.69564 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:03:17.814265 ops/training.py:65 2019-01-16 21:03:17.814203: step 5131, loss = 0.67383 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:03:18.704775 ops/training.py:65 2019-01-16 21:03:18.704717: step 5132, loss = 0.68162 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:03:19.594573 ops/training.py:65 2019-01-16 21:03:19.594514: step 5133, loss = 0.69903 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:03:20.484182 ops/training.py:65 2019-01-16 21:03:20.484119: step 5134, loss = 0.68674 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:03:21.373255 ops/training.py:65 2019-01-16 21:03:21.373192: step 5135, loss = 0.71891 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:03:22.262893 ops/training.py:65 2019-01-16 21:03:22.262829: step 5136, loss = 0.72881 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:03:23.151874 ops/training.py:65 2019-01-16 21:03:23.151811: step 5137, loss = 0.73079 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:03:24.040772 ops/training.py:65 2019-01-16 21:03:24.040708: step 5138, loss = 0.68371 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:03:24.929898 ops/training.py:65 2019-01-16 21:03:24.929840: step 5139, loss = 0.71992 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:03:25.818925 ops/training.py:65 2019-01-16 21:03:25.818875: step 5140, loss = 0.71312 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:03:26.709016 ops/training.py:65 2019-01-16 21:03:26.708942: step 5141, loss = 0.73078 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:03:27.598685 ops/training.py:65 2019-01-16 21:03:27.598630: step 5142, loss = 0.69399 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:03:28.487051 ops/training.py:65 2019-01-16 21:03:28.486988: step 5143, loss = 0.70922 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:03:29.376474 ops/training.py:65 2019-01-16 21:03:29.376409: step 5144, loss = 0.70805 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:03:30.267267 ops/training.py:65 2019-01-16 21:03:30.267197: step 5145, loss = 0.69050 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:03:31.160259 ops/training.py:65 2019-01-16 21:03:31.160151: step 5146, loss = 0.67906 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:03:32.051251 ops/training.py:65 2019-01-16 21:03:32.051191: step 5147, loss = 0.71674 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:03:32.940307 ops/training.py:65 2019-01-16 21:03:32.940249: step 5148, loss = 0.70178 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:03:33.829423 ops/training.py:65 2019-01-16 21:03:33.829360: step 5149, loss = 0.74019 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:03:34.719064 ops/training.py:65 2019-01-16 21:03:34.719009: step 5150, loss = 0.68059 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:03:35.608278 ops/training.py:65 2019-01-16 21:03:35.608226: step 5151, loss = 0.70298 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:03:36.501131 ops/training.py:65 2019-01-16 21:03:36.501066: step 5152, loss = 0.70799 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:03:37.393721 ops/training.py:65 2019-01-16 21:03:37.393618: step 5153, loss = 0.71137 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:03:38.287292 ops/training.py:65 2019-01-16 21:03:38.287193: step 5154, loss = 0.70612 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:03:39.177638 ops/training.py:65 2019-01-16 21:03:39.177578: step 5155, loss = 0.68524 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:03:40.067207 ops/training.py:65 2019-01-16 21:03:40.067146: step 5156, loss = 0.67584 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:03:40.955939 ops/training.py:65 2019-01-16 21:03:40.955876: step 5157, loss = 0.67024 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:03:41.845632 ops/training.py:65 2019-01-16 21:03:41.845574: step 5158, loss = 0.69089 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:03:42.734735 ops/training.py:65 2019-01-16 21:03:42.734679: step 5159, loss = 0.67722 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:03:43.624225 ops/training.py:65 2019-01-16 21:03:43.624167: step 5160, loss = 0.71787 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:03:44.513862 ops/training.py:65 2019-01-16 21:03:44.513804: step 5161, loss = 0.66918 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:03:45.402979 ops/training.py:65 2019-01-16 21:03:45.402922: step 5162, loss = 0.69033 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:03:46.292611 ops/training.py:65 2019-01-16 21:03:46.292552: step 5163, loss = 0.71760 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:03:47.181496 ops/training.py:65 2019-01-16 21:03:47.181436: step 5164, loss = 0.69779 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:03:48.071098 ops/training.py:65 2019-01-16 21:03:48.071027: step 5165, loss = 0.70170 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:03:48.960587 ops/training.py:65 2019-01-16 21:03:48.960528: step 5166, loss = 0.70409 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:03:49.850468 ops/training.py:65 2019-01-16 21:03:49.850408: step 5167, loss = 0.67553 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:03:50.741171 ops/training.py:65 2019-01-16 21:03:50.741107: step 5168, loss = 0.71090 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:03:51.633860 ops/training.py:65 2019-01-16 21:03:51.633797: step 5169, loss = 0.67796 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:03:52.524565 ops/training.py:65 2019-01-16 21:03:52.524497: step 5170, loss = 0.70403 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:03:53.416978 ops/training.py:65 2019-01-16 21:03:53.416874: step 5171, loss = 0.71630 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:03:54.309199 ops/training.py:65 2019-01-16 21:03:54.309088: step 5172, loss = 0.66267 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:03:55.201709 ops/training.py:65 2019-01-16 21:03:55.201630: step 5173, loss = 0.69332 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:03:56.093218 ops/training.py:65 2019-01-16 21:03:56.093121: step 5174, loss = 0.69203 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:03:56.986444 ops/training.py:65 2019-01-16 21:03:56.986351: step 5175, loss = 0.65910 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:03:57.876213 ops/training.py:65 2019-01-16 21:03:57.876118: step 5176, loss = 0.67170 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:03:58.765797 ops/training.py:65 2019-01-16 21:03:58.765696: step 5177, loss = 0.70473 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:03:59.658464 ops/training.py:65 2019-01-16 21:03:59.658355: step 5178, loss = 0.68950 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:04:00.551198 ops/training.py:65 2019-01-16 21:04:00.551105: step 5179, loss = 0.67771 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:04:01.441461 ops/training.py:65 2019-01-16 21:04:01.441394: step 5180, loss = 0.70568 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:04:02.330275 ops/training.py:65 2019-01-16 21:04:02.330217: step 5181, loss = 0.72355 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:04:03.220004 ops/training.py:65 2019-01-16 21:04:03.219933: step 5182, loss = 0.68115 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:04:04.109873 ops/training.py:65 2019-01-16 21:04:04.109807: step 5183, loss = 0.67267 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:04:04.998891 ops/training.py:65 2019-01-16 21:04:04.998826: step 5184, loss = 0.67218 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:04:05.888166 ops/training.py:65 2019-01-16 21:04:05.888102: step 5185, loss = 0.65898 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 21:04:06.777210 ops/training.py:65 2019-01-16 21:04:06.777147: step 5186, loss = 0.67247 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:04:07.666400 ops/training.py:65 2019-01-16 21:04:07.666338: step 5187, loss = 0.70513 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:04:08.555831 ops/training.py:65 2019-01-16 21:04:08.555768: step 5188, loss = 0.69486 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:04:09.445114 ops/training.py:65 2019-01-16 21:04:09.445053: step 5189, loss = 0.71103 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:04:10.333813 ops/training.py:65 2019-01-16 21:04:10.333748: step 5190, loss = 0.71519 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:04:11.223464 ops/training.py:65 2019-01-16 21:04:11.223397: step 5191, loss = 0.71493 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:04:12.112763 ops/training.py:65 2019-01-16 21:04:12.112704: step 5192, loss = 0.67754 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:04:13.001547 ops/training.py:65 2019-01-16 21:04:13.001486: step 5193, loss = 0.70095 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:04:13.892214 ops/training.py:65 2019-01-16 21:04:13.892147: step 5194, loss = 0.73383 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:04:14.781311 ops/training.py:65 2019-01-16 21:04:14.781253: step 5195, loss = 0.69104 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:04:15.670577 ops/training.py:65 2019-01-16 21:04:15.670518: step 5196, loss = 0.66102 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:04:16.558930 ops/training.py:65 2019-01-16 21:04:16.558868: step 5197, loss = 0.70918 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:04:17.447368 ops/training.py:65 2019-01-16 21:04:17.447308: step 5198, loss = 0.70204 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:04:18.336978 ops/training.py:65 2019-01-16 21:04:18.336916: step 5199, loss = 0.67362 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:04:19.226954 ops/training.py:65 2019-01-16 21:04:19.226888: step 5200, loss = 0.70235 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:04:20.117733 ops/training.py:65 2019-01-16 21:04:20.117678: step 5201, loss = 0.72495 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:04:21.010765 ops/training.py:65 2019-01-16 21:04:21.010666: step 5202, loss = 0.68375 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:04:21.902508 ops/training.py:65 2019-01-16 21:04:21.902437: step 5203, loss = 0.68349 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:04:22.795182 ops/training.py:65 2019-01-16 21:04:22.795079: step 5204, loss = 0.65795 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:04:23.687467 ops/training.py:65 2019-01-16 21:04:23.687394: step 5205, loss = 0.68973 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:04:24.577632 ops/training.py:65 2019-01-16 21:04:24.577569: step 5206, loss = 0.67791 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:04:25.467518 ops/training.py:65 2019-01-16 21:04:25.467453: step 5207, loss = 0.68923 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:04:26.357299 ops/training.py:65 2019-01-16 21:04:26.357228: step 5208, loss = 0.70923 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:04:27.246421 ops/training.py:65 2019-01-16 21:04:27.246359: step 5209, loss = 0.68946 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:04:28.134990 ops/training.py:65 2019-01-16 21:04:28.134927: step 5210, loss = 0.69205 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:04:29.023975 ops/training.py:65 2019-01-16 21:04:29.023912: step 5211, loss = 0.68212 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:04:29.912690 ops/training.py:65 2019-01-16 21:04:29.912622: step 5212, loss = 0.70385 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:04:30.802326 ops/training.py:65 2019-01-16 21:04:30.802253: step 5213, loss = 0.71605 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:04:31.690982 ops/training.py:65 2019-01-16 21:04:31.690921: step 5214, loss = 0.69527 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:04:32.585911 ops/training.py:65 2019-01-16 21:04:32.585842: step 5215, loss = 0.70366 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:04:33.478803 ops/training.py:65 2019-01-16 21:04:33.478702: step 5216, loss = 0.70777 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:04:34.369011 ops/training.py:65 2019-01-16 21:04:34.368921: step 5217, loss = 0.69110 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:04:35.262223 ops/training.py:65 2019-01-16 21:04:35.262115: step 5218, loss = 0.71097 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:04:36.153031 ops/training.py:65 2019-01-16 21:04:36.152935: step 5219, loss = 0.68445 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:04:37.043337 ops/training.py:65 2019-01-16 21:04:37.043270: step 5220, loss = 0.68019 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:04:37.932739 ops/training.py:65 2019-01-16 21:04:37.932672: step 5221, loss = 0.69677 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:04:38.823105 ops/training.py:65 2019-01-16 21:04:38.823043: step 5222, loss = 0.71114 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:04:39.713424 ops/training.py:65 2019-01-16 21:04:39.713361: step 5223, loss = 0.71277 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:04:40.603455 ops/training.py:65 2019-01-16 21:04:40.603392: step 5224, loss = 0.70034 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:04:41.492522 ops/training.py:65 2019-01-16 21:04:41.492461: step 5225, loss = 0.71983 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:04:42.380692 ops/training.py:65 2019-01-16 21:04:42.380633: step 5226, loss = 0.69870 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:04:43.269978 ops/training.py:65 2019-01-16 21:04:43.269903: step 5227, loss = 0.69459 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:04:44.159702 ops/training.py:65 2019-01-16 21:04:44.159637: step 5228, loss = 0.67074 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 21:04:45.048805 ops/training.py:65 2019-01-16 21:04:45.048741: step 5229, loss = 0.70483 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:04:45.939065 ops/training.py:65 2019-01-16 21:04:45.938995: step 5230, loss = 0.68047 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:04:46.829110 ops/training.py:65 2019-01-16 21:04:46.829047: step 5231, loss = 0.68414 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:04:47.720630 ops/training.py:65 2019-01-16 21:04:47.720557: step 5232, loss = 0.72311 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:04:48.613497 ops/training.py:65 2019-01-16 21:04:48.613388: step 5233, loss = 0.70618 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:04:49.504646 ops/training.py:65 2019-01-16 21:04:49.504533: step 5234, loss = 0.69781 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:04:50.396308 ops/training.py:65 2019-01-16 21:04:50.396239: step 5235, loss = 0.70249 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:04:51.286913 ops/training.py:65 2019-01-16 21:04:51.286843: step 5236, loss = 0.68418 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:04:52.177159 ops/training.py:65 2019-01-16 21:04:52.177086: step 5237, loss = 0.67964 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:04:53.067135 ops/training.py:65 2019-01-16 21:04:53.067064: step 5238, loss = 0.72591 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:04:53.957825 ops/training.py:65 2019-01-16 21:04:53.957752: step 5239, loss = 0.70698 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:04:54.848744 ops/training.py:65 2019-01-16 21:04:54.848689: step 5240, loss = 0.68749 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:04:55.742669 ops/training.py:65 2019-01-16 21:04:55.742561: step 5241, loss = 0.69741 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:04:56.634505 ops/training.py:65 2019-01-16 21:04:56.634410: step 5242, loss = 0.68170 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:04:57.524679 ops/training.py:65 2019-01-16 21:04:57.524610: step 5243, loss = 0.68166 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:04:58.413889 ops/training.py:65 2019-01-16 21:04:58.413823: step 5244, loss = 0.70928 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:04:59.303828 ops/training.py:65 2019-01-16 21:04:59.303757: step 5245, loss = 0.70581 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:05:00.192482 ops/training.py:65 2019-01-16 21:05:00.192408: step 5246, loss = 0.65833 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:05:01.082164 ops/training.py:65 2019-01-16 21:05:01.082090: step 5247, loss = 0.74872 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 21:05:01.971147 ops/training.py:65 2019-01-16 21:05:01.971059: step 5248, loss = 0.69205 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:05:02.862416 ops/training.py:65 2019-01-16 21:05:02.862339: step 5249, loss = 0.69485 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:05:03.755424 ops/training.py:65 2019-01-16 21:05:03.755322: step 5250, loss = 0.69250 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:05:04.647617 ops/training.py:65 2019-01-16 21:05:04.647543: step 5251, loss = 0.70366 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:05:05.540516 ops/training.py:65 2019-01-16 21:05:05.540406: step 5252, loss = 0.68061 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:05:06.432024 ops/training.py:65 2019-01-16 21:05:06.431932: step 5253, loss = 0.65882 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:05:07.322146 ops/training.py:65 2019-01-16 21:05:07.322073: step 5254, loss = 0.69615 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:05:08.212150 ops/training.py:65 2019-01-16 21:05:08.212079: step 5255, loss = 0.67836 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:05:09.102110 ops/training.py:65 2019-01-16 21:05:09.102027: step 5256, loss = 0.68300 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:05:09.991913 ops/training.py:65 2019-01-16 21:05:09.991816: step 5257, loss = 0.68999 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:05:10.885506 ops/training.py:65 2019-01-16 21:05:10.885433: step 5258, loss = 0.73117 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:05:11.778299 ops/training.py:65 2019-01-16 21:05:11.778191: step 5259, loss = 0.69993 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:05:12.669149 ops/training.py:65 2019-01-16 21:05:12.669073: step 5260, loss = 0.70328 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:05:13.561099 ops/training.py:65 2019-01-16 21:05:13.561046: step 5261, loss = 0.68687 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:05:14.452687 ops/training.py:65 2019-01-16 21:05:14.452610: step 5262, loss = 0.68379 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:05:15.344820 ops/training.py:65 2019-01-16 21:05:15.344720: step 5263, loss = 0.69639 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:05:16.238347 ops/training.py:65 2019-01-16 21:05:16.238240: step 5264, loss = 0.71943 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:05:17.127980 ops/training.py:65 2019-01-16 21:05:17.127899: step 5265, loss = 0.68398 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:05:18.019336 ops/training.py:65 2019-01-16 21:05:18.019263: step 5266, loss = 0.71321 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:05:18.908441 ops/training.py:65 2019-01-16 21:05:18.908368: step 5267, loss = 0.71912 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:05:19.798177 ops/training.py:65 2019-01-16 21:05:19.798101: step 5268, loss = 0.70683 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:05:20.687439 ops/training.py:65 2019-01-16 21:05:20.687372: step 5269, loss = 0.68927 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:05:21.577140 ops/training.py:65 2019-01-16 21:05:21.577070: step 5270, loss = 0.69709 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:05:22.466319 ops/training.py:65 2019-01-16 21:05:22.466251: step 5271, loss = 0.69003 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:05:23.355398 ops/training.py:65 2019-01-16 21:05:23.355330: step 5272, loss = 0.70600 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:05:24.243668 ops/training.py:65 2019-01-16 21:05:24.243601: step 5273, loss = 0.68722 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:05:25.132408 ops/training.py:65 2019-01-16 21:05:25.132318: step 5274, loss = 0.70207 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:05:26.022266 ops/training.py:65 2019-01-16 21:05:26.022181: step 5275, loss = 0.69188 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:05:26.912385 ops/training.py:65 2019-01-16 21:05:26.912319: step 5276, loss = 0.68887 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:05:27.802573 ops/training.py:65 2019-01-16 21:05:27.802505: step 5277, loss = 0.69501 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:05:28.692232 ops/training.py:65 2019-01-16 21:05:28.692164: step 5278, loss = 0.67357 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:05:29.581302 ops/training.py:65 2019-01-16 21:05:29.581233: step 5279, loss = 0.68787 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:05:30.472848 ops/training.py:65 2019-01-16 21:05:30.472776: step 5280, loss = 0.67822 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 21:05:31.365144 ops/training.py:65 2019-01-16 21:05:31.365033: step 5281, loss = 0.68622 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:05:32.256276 ops/training.py:65 2019-01-16 21:05:32.256173: step 5282, loss = 0.71209 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:05:33.148338 ops/training.py:65 2019-01-16 21:05:33.148238: step 5283, loss = 0.69843 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:05:34.038781 ops/training.py:65 2019-01-16 21:05:34.038704: step 5284, loss = 0.70536 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:05:34.930663 ops/training.py:65 2019-01-16 21:05:34.930555: step 5285, loss = 0.67695 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:05:35.823859 ops/training.py:65 2019-01-16 21:05:35.823765: step 5286, loss = 0.70599 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:05:36.714553 ops/training.py:65 2019-01-16 21:05:36.714484: step 5287, loss = 0.69863 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:05:37.605831 ops/training.py:65 2019-01-16 21:05:37.605730: step 5288, loss = 0.71423 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:05:38.498901 ops/training.py:65 2019-01-16 21:05:38.498806: step 5289, loss = 0.70208 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:05:39.389790 ops/training.py:65 2019-01-16 21:05:39.389729: step 5290, loss = 0.70051 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:05:40.280158 ops/training.py:65 2019-01-16 21:05:40.280087: step 5291, loss = 0.70273 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:05:41.172108 ops/training.py:65 2019-01-16 21:05:41.172004: step 5292, loss = 0.68904 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:05:42.064577 ops/training.py:65 2019-01-16 21:05:42.064512: step 5293, loss = 0.68534 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:05:42.954921 ops/training.py:65 2019-01-16 21:05:42.954840: step 5294, loss = 0.71458 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:05:43.845394 ops/training.py:65 2019-01-16 21:05:43.845316: step 5295, loss = 0.69350 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:05:44.736145 ops/training.py:65 2019-01-16 21:05:44.736060: step 5296, loss = 0.69637 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:05:45.625477 ops/training.py:65 2019-01-16 21:05:45.625406: step 5297, loss = 0.66779 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:05:46.514750 ops/training.py:65 2019-01-16 21:05:46.514682: step 5298, loss = 0.68649 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:05:47.405401 ops/training.py:65 2019-01-16 21:05:47.405338: step 5299, loss = 0.68370 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:05:48.295388 ops/training.py:65 2019-01-16 21:05:48.295333: step 5300, loss = 0.67817 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.75
I2992 2019-01-16 21:05:49.185321 ops/training.py:65 2019-01-16 21:05:49.185260: step 5301, loss = 0.70921 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:05:50.076331 ops/training.py:65 2019-01-16 21:05:50.076228: step 5302, loss = 0.66408 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:05:50.969195 ops/training.py:65 2019-01-16 21:05:50.969098: step 5303, loss = 0.72093 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:05:51.860617 ops/training.py:65 2019-01-16 21:05:51.860558: step 5304, loss = 0.71326 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:05:52.751135 ops/training.py:65 2019-01-16 21:05:52.751031: step 5305, loss = 0.71586 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:05:53.641145 ops/training.py:65 2019-01-16 21:05:53.641038: step 5306, loss = 0.69405 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:05:54.533221 ops/training.py:65 2019-01-16 21:05:54.533115: step 5307, loss = 0.66310 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 21:05:55.425652 ops/training.py:65 2019-01-16 21:05:55.425560: step 5308, loss = 0.70276 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:05:56.316190 ops/training.py:65 2019-01-16 21:05:56.316126: step 5309, loss = 0.72036 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:05:57.206008 ops/training.py:65 2019-01-16 21:05:57.205943: step 5310, loss = 0.68002 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:05:58.095564 ops/training.py:65 2019-01-16 21:05:58.095480: step 5311, loss = 0.68679 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:05:58.985140 ops/training.py:65 2019-01-16 21:05:58.985063: step 5312, loss = 0.70936 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:05:59.874344 ops/training.py:65 2019-01-16 21:05:59.874282: step 5313, loss = 0.70467 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:06:00.763873 ops/training.py:65 2019-01-16 21:06:00.763811: step 5314, loss = 0.66868 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:06:01.652722 ops/training.py:65 2019-01-16 21:06:01.652643: step 5315, loss = 0.69034 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:06:02.542257 ops/training.py:65 2019-01-16 21:06:02.542188: step 5316, loss = 0.71244 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:06:03.431620 ops/training.py:65 2019-01-16 21:06:03.431549: step 5317, loss = 0.72400 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:06:04.324697 ops/training.py:65 2019-01-16 21:06:04.324627: step 5318, loss = 0.68702 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:06:05.216201 ops/training.py:65 2019-01-16 21:06:05.216100: step 5319, loss = 0.71178 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:06:06.109262 ops/training.py:65 2019-01-16 21:06:06.109166: step 5320, loss = 0.71456 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:06:07.000792 ops/training.py:65 2019-01-16 21:06:07.000732: step 5321, loss = 0.71808 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:06:07.890223 ops/training.py:65 2019-01-16 21:06:07.890163: step 5322, loss = 0.68317 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:06:08.779443 ops/training.py:65 2019-01-16 21:06:08.779385: step 5323, loss = 0.69288 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:06:09.670188 ops/training.py:65 2019-01-16 21:06:09.670125: step 5324, loss = 0.70530 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:06:10.563330 ops/training.py:65 2019-01-16 21:06:10.563227: step 5325, loss = 0.70358 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:06:11.455617 ops/training.py:65 2019-01-16 21:06:11.455552: step 5326, loss = 0.70451 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:06:12.346133 ops/training.py:65 2019-01-16 21:06:12.346052: step 5327, loss = 0.67856 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:06:13.235794 ops/training.py:65 2019-01-16 21:06:13.235714: step 5328, loss = 0.68899 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:06:14.125348 ops/training.py:65 2019-01-16 21:06:14.125277: step 5329, loss = 0.72196 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:06:15.017082 ops/training.py:65 2019-01-16 21:06:15.017020: step 5330, loss = 0.69545 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:06:15.909498 ops/training.py:65 2019-01-16 21:06:15.909406: step 5331, loss = 0.68785 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:06:16.802193 ops/training.py:65 2019-01-16 21:06:16.802105: step 5332, loss = 0.72460 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:06:17.694505 ops/training.py:65 2019-01-16 21:06:17.694401: step 5333, loss = 0.68146 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:06:18.584878 ops/training.py:65 2019-01-16 21:06:18.584780: step 5334, loss = 0.66726 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:06:19.480320 ops/training.py:65 2019-01-16 21:06:19.480237: step 5335, loss = 0.71183 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:06:20.372669 ops/training.py:65 2019-01-16 21:06:20.372581: step 5336, loss = 0.69091 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:06:21.265689 ops/training.py:65 2019-01-16 21:06:21.265602: step 5337, loss = 0.69592 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:06:22.156266 ops/training.py:65 2019-01-16 21:06:22.156195: step 5338, loss = 0.70665 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:06:23.045979 ops/training.py:65 2019-01-16 21:06:23.045913: step 5339, loss = 0.70072 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:06:23.936131 ops/training.py:65 2019-01-16 21:06:23.936059: step 5340, loss = 0.72278 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:06:24.825472 ops/training.py:65 2019-01-16 21:06:24.825405: step 5341, loss = 0.69838 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:06:25.714673 ops/training.py:65 2019-01-16 21:06:25.714608: step 5342, loss = 0.67807 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:06:26.605159 ops/training.py:65 2019-01-16 21:06:26.605094: step 5343, loss = 0.67834 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:06:27.494640 ops/training.py:65 2019-01-16 21:06:27.494577: step 5344, loss = 0.68913 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:06:28.384287 ops/training.py:65 2019-01-16 21:06:28.384222: step 5345, loss = 0.70975 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:06:29.273692 ops/training.py:65 2019-01-16 21:06:29.273629: step 5346, loss = 0.68595 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:06:30.162345 ops/training.py:65 2019-01-16 21:06:30.162284: step 5347, loss = 0.67437 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:06:31.051127 ops/training.py:65 2019-01-16 21:06:31.051062: step 5348, loss = 0.69780 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:06:31.939992 ops/training.py:65 2019-01-16 21:06:31.939915: step 5349, loss = 0.66495 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:06:32.828776 ops/training.py:65 2019-01-16 21:06:32.828706: step 5350, loss = 0.72740 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:06:33.718339 ops/training.py:65 2019-01-16 21:06:33.718271: step 5351, loss = 0.70179 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:06:34.607240 ops/training.py:65 2019-01-16 21:06:34.607172: step 5352, loss = 0.70136 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:06:35.495980 ops/training.py:65 2019-01-16 21:06:35.495915: step 5353, loss = 0.70718 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:06:36.385978 ops/training.py:65 2019-01-16 21:06:36.385913: step 5354, loss = 0.70078 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:06:37.274717 ops/training.py:65 2019-01-16 21:06:37.274654: step 5355, loss = 0.68341 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:06:38.164810 ops/training.py:65 2019-01-16 21:06:38.164746: step 5356, loss = 0.68258 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:06:39.054401 ops/training.py:65 2019-01-16 21:06:39.054338: step 5357, loss = 0.67510 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:06:39.944300 ops/training.py:65 2019-01-16 21:06:39.944220: step 5358, loss = 0.68902 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:06:40.834202 ops/training.py:65 2019-01-16 21:06:40.834122: step 5359, loss = 0.69037 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:06:41.723032 ops/training.py:65 2019-01-16 21:06:41.722956: step 5360, loss = 0.72455 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:06:42.612422 ops/training.py:65 2019-01-16 21:06:42.612362: step 5361, loss = 0.68583 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:06:43.501272 ops/training.py:65 2019-01-16 21:06:43.501204: step 5362, loss = 0.69029 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:06:44.390243 ops/training.py:65 2019-01-16 21:06:44.390183: step 5363, loss = 0.70546 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:06:45.278756 ops/training.py:65 2019-01-16 21:06:45.278696: step 5364, loss = 0.70068 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:06:46.170089 ops/training.py:65 2019-01-16 21:06:46.170033: step 5365, loss = 0.69957 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:06:47.061085 ops/training.py:65 2019-01-16 21:06:47.060981: step 5366, loss = 0.72344 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:06:47.953940 ops/training.py:65 2019-01-16 21:06:47.953850: step 5367, loss = 0.69130 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:06:48.844408 ops/training.py:65 2019-01-16 21:06:48.844347: step 5368, loss = 0.73207 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:06:49.734470 ops/training.py:65 2019-01-16 21:06:49.734412: step 5369, loss = 0.70723 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:06:50.624299 ops/training.py:65 2019-01-16 21:06:50.624229: step 5370, loss = 0.70440 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:06:51.515372 ops/training.py:65 2019-01-16 21:06:51.515302: step 5371, loss = 0.70652 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:06:52.405345 ops/training.py:65 2019-01-16 21:06:52.405287: step 5372, loss = 0.67127 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:06:53.297112 ops/training.py:65 2019-01-16 21:06:53.297047: step 5373, loss = 0.69181 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:06:54.188783 ops/training.py:65 2019-01-16 21:06:54.188689: step 5374, loss = 0.68977 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:06:55.081206 ops/training.py:65 2019-01-16 21:06:55.081104: step 5375, loss = 0.68604 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:06:55.973051 ops/training.py:65 2019-01-16 21:06:55.972959: step 5376, loss = 0.68176 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:06:56.865257 ops/training.py:65 2019-01-16 21:06:56.865169: step 5377, loss = 0.67405 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:06:57.757937 ops/training.py:65 2019-01-16 21:06:57.757830: step 5378, loss = 0.68220 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:06:58.650329 ops/training.py:65 2019-01-16 21:06:58.650263: step 5379, loss = 0.68489 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:06:59.540004 ops/training.py:65 2019-01-16 21:06:59.539940: step 5380, loss = 0.70844 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:07:00.430332 ops/training.py:65 2019-01-16 21:07:00.430263: step 5381, loss = 0.71278 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:07:01.318986 ops/training.py:65 2019-01-16 21:07:01.318922: step 5382, loss = 0.65818 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:07:02.207759 ops/training.py:65 2019-01-16 21:07:02.207713: step 5383, loss = 0.69191 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:07:03.097957 ops/training.py:65 2019-01-16 21:07:03.097915: step 5384, loss = 0.69814 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:07:03.987512 ops/training.py:65 2019-01-16 21:07:03.987473: step 5385, loss = 0.70407 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:07:04.876523 ops/training.py:65 2019-01-16 21:07:04.876482: step 5386, loss = 0.71654 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:07:05.765700 ops/training.py:65 2019-01-16 21:07:05.765656: step 5387, loss = 0.68710 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:07:06.653846 ops/training.py:65 2019-01-16 21:07:06.653812: step 5388, loss = 0.68410 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:07:07.542270 ops/training.py:65 2019-01-16 21:07:07.542230: step 5389, loss = 0.70087 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:07:08.430495 ops/training.py:65 2019-01-16 21:07:08.430453: step 5390, loss = 0.70552 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:07:09.319104 ops/training.py:65 2019-01-16 21:07:09.319055: step 5391, loss = 0.66698 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:07:10.208351 ops/training.py:65 2019-01-16 21:07:10.208316: step 5392, loss = 0.69079 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:07:11.096827 ops/training.py:65 2019-01-16 21:07:11.096785: step 5393, loss = 0.68899 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:07:11.987429 ops/training.py:65 2019-01-16 21:07:11.987398: step 5394, loss = 0.67613 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:07:12.878239 ops/training.py:65 2019-01-16 21:07:12.878207: step 5395, loss = 0.71543 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:07:13.769957 ops/training.py:65 2019-01-16 21:07:13.769927: step 5396, loss = 0.69411 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:07:14.659767 ops/training.py:65 2019-01-16 21:07:14.659738: step 5397, loss = 0.69083 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:07:15.549342 ops/training.py:65 2019-01-16 21:07:15.549307: step 5398, loss = 0.66803 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:07:16.437306 ops/training.py:65 2019-01-16 21:07:16.437272: step 5399, loss = 0.70830 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:07:17.325904 ops/training.py:65 2019-01-16 21:07:17.325858: step 5400, loss = 0.66779 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:07:18.214587 ops/training.py:65 2019-01-16 21:07:18.214537: step 5401, loss = 0.67070 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:07:19.103664 ops/training.py:65 2019-01-16 21:07:19.103623: step 5402, loss = 0.71937 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:07:19.992305 ops/training.py:65 2019-01-16 21:07:19.992226: step 5403, loss = 0.64583 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.75
I2992 2019-01-16 21:07:20.881044 ops/training.py:65 2019-01-16 21:07:20.880992: step 5404, loss = 0.71582 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:07:21.769619 ops/training.py:65 2019-01-16 21:07:21.769569: step 5405, loss = 0.73953 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:07:22.658047 ops/training.py:65 2019-01-16 21:07:22.657968: step 5406, loss = 0.73364 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:07:23.546316 ops/training.py:65 2019-01-16 21:07:23.546232: step 5407, loss = 0.68427 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:07:24.435562 ops/training.py:65 2019-01-16 21:07:24.435484: step 5408, loss = 0.67252 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:07:25.324772 ops/training.py:65 2019-01-16 21:07:25.324706: step 5409, loss = 0.68819 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:07:26.213975 ops/training.py:65 2019-01-16 21:07:26.213919: step 5410, loss = 0.68429 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:07:27.103186 ops/training.py:65 2019-01-16 21:07:27.103129: step 5411, loss = 0.68017 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:07:27.992479 ops/training.py:65 2019-01-16 21:07:27.992427: step 5412, loss = 0.72180 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:07:28.881620 ops/training.py:65 2019-01-16 21:07:28.881560: step 5413, loss = 0.71209 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:07:29.770944 ops/training.py:65 2019-01-16 21:07:29.770884: step 5414, loss = 0.74498 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:07:30.661984 ops/training.py:65 2019-01-16 21:07:30.661927: step 5415, loss = 0.71691 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:07:32.546261 ops/training.py:65 2019-01-16 21:07:32.546153: step 5416, loss = 0.74435 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:07:33.438487 ops/training.py:65 2019-01-16 21:07:33.438417: step 5417, loss = 0.73861 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:07:34.328266 ops/training.py:65 2019-01-16 21:07:34.328203: step 5418, loss = 0.70677 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:07:35.217958 ops/training.py:65 2019-01-16 21:07:35.217892: step 5419, loss = 0.69004 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:07:36.107857 ops/training.py:65 2019-01-16 21:07:36.107792: step 5420, loss = 0.76511 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:07:36.997499 ops/training.py:65 2019-01-16 21:07:36.997438: step 5421, loss = 0.71768 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:07:37.888784 ops/training.py:65 2019-01-16 21:07:37.888723: step 5422, loss = 0.64551 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:07:38.778205 ops/training.py:65 2019-01-16 21:07:38.778143: step 5423, loss = 0.72778 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:07:39.667370 ops/training.py:65 2019-01-16 21:07:39.667295: step 5424, loss = 0.67142 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:07:40.557397 ops/training.py:65 2019-01-16 21:07:40.557334: step 5425, loss = 0.63979 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 21:07:41.447292 ops/training.py:65 2019-01-16 21:07:41.447227: step 5426, loss = 0.70906 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:07:42.337007 ops/training.py:65 2019-01-16 21:07:42.336943: step 5427, loss = 0.68940 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:07:43.225647 ops/training.py:65 2019-01-16 21:07:43.225576: step 5428, loss = 0.66199 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:07:44.114887 ops/training.py:65 2019-01-16 21:07:44.114823: step 5429, loss = 0.69562 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:07:45.004525 ops/training.py:65 2019-01-16 21:07:45.004458: step 5430, loss = 0.73910 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:07:45.894385 ops/training.py:65 2019-01-16 21:07:45.894320: step 5431, loss = 0.63529 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 21:07:46.784979 ops/training.py:65 2019-01-16 21:07:46.784904: step 5432, loss = 0.81412 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.25
I2992 2019-01-16 21:07:47.674356 ops/training.py:65 2019-01-16 21:07:47.674290: step 5433, loss = 0.71840 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:07:48.565556 ops/training.py:65 2019-01-16 21:07:48.565514: step 5434, loss = 0.72769 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:07:49.455897 ops/training.py:65 2019-01-16 21:07:49.455827: step 5435, loss = 0.68622 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:07:50.346495 ops/training.py:65 2019-01-16 21:07:50.346403: step 5436, loss = 0.67662 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:07:51.237226 ops/training.py:65 2019-01-16 21:07:51.237126: step 5437, loss = 0.66214 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:07:52.130325 ops/training.py:65 2019-01-16 21:07:52.130228: step 5438, loss = 0.69021 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:07:53.020370 ops/training.py:65 2019-01-16 21:07:53.020308: step 5439, loss = 0.71028 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:07:53.911545 ops/training.py:65 2019-01-16 21:07:53.911478: step 5440, loss = 0.72259 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:07:54.800429 ops/training.py:65 2019-01-16 21:07:54.800368: step 5441, loss = 0.70415 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:07:55.689966 ops/training.py:65 2019-01-16 21:07:55.689900: step 5442, loss = 0.68223 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:07:56.579631 ops/training.py:65 2019-01-16 21:07:56.579567: step 5443, loss = 0.67634 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:07:57.468543 ops/training.py:65 2019-01-16 21:07:57.468482: step 5444, loss = 0.68858 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:07:58.357733 ops/training.py:65 2019-01-16 21:07:58.357671: step 5445, loss = 0.70876 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:07:59.247504 ops/training.py:65 2019-01-16 21:07:59.247436: step 5446, loss = 0.72753 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:08:00.137321 ops/training.py:65 2019-01-16 21:08:00.137256: step 5447, loss = 0.67272 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:08:01.026112 ops/training.py:65 2019-01-16 21:08:01.026047: step 5448, loss = 0.71294 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:08:01.915068 ops/training.py:65 2019-01-16 21:08:01.915002: step 5449, loss = 0.65956 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:08:02.804789 ops/training.py:65 2019-01-16 21:08:02.804722: step 5450, loss = 0.70771 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:08:03.694294 ops/training.py:65 2019-01-16 21:08:03.694227: step 5451, loss = 0.73732 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:08:04.584218 ops/training.py:65 2019-01-16 21:08:04.584155: step 5452, loss = 0.65871 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:08:05.473235 ops/training.py:65 2019-01-16 21:08:05.473178: step 5453, loss = 0.70440 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:08:06.361781 ops/training.py:65 2019-01-16 21:08:06.361720: step 5454, loss = 0.68324 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:08:07.251277 ops/training.py:65 2019-01-16 21:08:07.251214: step 5455, loss = 0.70578 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:08:08.140794 ops/training.py:65 2019-01-16 21:08:08.140727: step 5456, loss = 0.73020 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:08:09.029118 ops/training.py:65 2019-01-16 21:08:09.029065: step 5457, loss = 0.69688 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:08:09.917473 ops/training.py:65 2019-01-16 21:08:09.917418: step 5458, loss = 0.67782 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:08:10.811924 ops/training.py:65 2019-01-16 21:08:10.811859: step 5459, loss = 0.70507 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:08:11.703191 ops/training.py:65 2019-01-16 21:08:11.703101: step 5460, loss = 0.69689 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:08:12.594415 ops/training.py:65 2019-01-16 21:08:12.594326: step 5461, loss = 0.69431 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:08:13.487010 ops/training.py:65 2019-01-16 21:08:13.486912: step 5462, loss = 0.71376 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:08:14.380254 ops/training.py:65 2019-01-16 21:08:14.380151: step 5463, loss = 0.67281 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:08:15.271126 ops/training.py:65 2019-01-16 21:08:15.271067: step 5464, loss = 0.70875 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:08:16.162840 ops/training.py:65 2019-01-16 21:08:16.162772: step 5465, loss = 0.69943 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:08:17.363757 ops/training.py:65 2019-01-16 21:08:17.363651: step 5466, loss = 0.71318 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:08:18.255436 ops/training.py:65 2019-01-16 21:08:18.255372: step 5467, loss = 0.70442 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:08:19.145315 ops/training.py:65 2019-01-16 21:08:19.145249: step 5468, loss = 0.70063 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:08:20.034941 ops/training.py:65 2019-01-16 21:08:20.034875: step 5469, loss = 0.67487 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:08:20.924663 ops/training.py:65 2019-01-16 21:08:20.924605: step 5470, loss = 0.68149 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:08:21.813543 ops/training.py:65 2019-01-16 21:08:21.813484: step 5471, loss = 0.66215 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:08:22.703384 ops/training.py:65 2019-01-16 21:08:22.703319: step 5472, loss = 0.68693 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:08:23.592408 ops/training.py:65 2019-01-16 21:08:23.592340: step 5473, loss = 0.69759 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:08:24.481149 ops/training.py:65 2019-01-16 21:08:24.481086: step 5474, loss = 0.69646 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:08:25.370621 ops/training.py:65 2019-01-16 21:08:25.370559: step 5475, loss = 0.68439 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:08:26.259106 ops/training.py:65 2019-01-16 21:08:26.259045: step 5476, loss = 0.69920 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:08:27.148089 ops/training.py:65 2019-01-16 21:08:27.148013: step 5477, loss = 0.70375 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:08:28.037868 ops/training.py:65 2019-01-16 21:08:28.037805: step 5478, loss = 0.71672 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:08:28.935882 ops/training.py:65 2019-01-16 21:08:28.935825: step 5479, loss = 0.67759 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:08:29.824389 ops/training.py:65 2019-01-16 21:08:29.824331: step 5480, loss = 0.71310 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:08:30.713345 ops/training.py:65 2019-01-16 21:08:30.713285: step 5481, loss = 0.72488 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:08:31.603275 ops/training.py:65 2019-01-16 21:08:31.603215: step 5482, loss = 0.69583 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:08:32.493514 ops/training.py:65 2019-01-16 21:08:32.493460: step 5483, loss = 0.68497 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:08:33.381900 ops/training.py:65 2019-01-16 21:08:33.381838: step 5484, loss = 0.71905 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:08:34.271410 ops/training.py:65 2019-01-16 21:08:34.271347: step 5485, loss = 0.70116 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:08:35.160028 ops/training.py:65 2019-01-16 21:08:35.159958: step 5486, loss = 0.68090 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:08:36.048973 ops/training.py:65 2019-01-16 21:08:36.048915: step 5487, loss = 0.69149 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:08:36.938569 ops/training.py:65 2019-01-16 21:08:36.938507: step 5488, loss = 0.73836 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:08:37.827462 ops/training.py:65 2019-01-16 21:08:37.827401: step 5489, loss = 0.67886 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:08:38.716943 ops/training.py:65 2019-01-16 21:08:38.716882: step 5490, loss = 0.68808 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:08:39.607997 ops/training.py:65 2019-01-16 21:08:39.607933: step 5491, loss = 0.70869 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:08:40.500996 ops/training.py:65 2019-01-16 21:08:40.500886: step 5492, loss = 0.70032 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:08:41.393340 ops/training.py:65 2019-01-16 21:08:41.393276: step 5493, loss = 0.69651 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:08:42.284281 ops/training.py:65 2019-01-16 21:08:42.284204: step 5494, loss = 0.75753 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:08:43.176625 ops/training.py:65 2019-01-16 21:08:43.176524: step 5495, loss = 0.71129 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:08:44.067628 ops/training.py:65 2019-01-16 21:08:44.067525: step 5496, loss = 0.72386 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:08:44.960433 ops/training.py:65 2019-01-16 21:08:44.960322: step 5497, loss = 0.73454 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:08:45.852097 ops/training.py:65 2019-01-16 21:08:45.852028: step 5498, loss = 0.69286 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:08:46.741479 ops/training.py:65 2019-01-16 21:08:46.741407: step 5499, loss = 0.72359 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:08:47.631041 ops/training.py:65 2019-01-16 21:08:47.630958: step 5500, loss = 0.74020 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 21:08:48.520816 ops/training.py:65 2019-01-16 21:08:48.520750: step 5501, loss = 0.69823 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:08:49.410582 ops/training.py:65 2019-01-16 21:08:49.410519: step 5502, loss = 0.67382 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:08:50.299882 ops/training.py:65 2019-01-16 21:08:50.299818: step 5503, loss = 0.68349 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:08:51.188523 ops/training.py:65 2019-01-16 21:08:51.188448: step 5504, loss = 0.70536 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:08:52.080059 ops/training.py:65 2019-01-16 21:08:52.079989: step 5505, loss = 0.70409 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:08:52.973206 ops/training.py:65 2019-01-16 21:08:52.973104: step 5506, loss = 0.68804 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:08:53.865849 ops/training.py:65 2019-01-16 21:08:53.865748: step 5507, loss = 0.74020 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:08:54.757300 ops/training.py:65 2019-01-16 21:08:54.757202: step 5508, loss = 0.68667 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:08:55.648835 ops/training.py:65 2019-01-16 21:08:55.648769: step 5509, loss = 0.69902 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:08:56.538235 ops/training.py:65 2019-01-16 21:08:56.538176: step 5510, loss = 0.68500 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:08:57.426692 ops/training.py:65 2019-01-16 21:08:57.426627: step 5511, loss = 0.71062 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:08:58.317294 ops/training.py:65 2019-01-16 21:08:58.317230: step 5512, loss = 0.71451 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:08:59.206729 ops/training.py:65 2019-01-16 21:08:59.206664: step 5513, loss = 0.69108 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:09:00.096456 ops/training.py:65 2019-01-16 21:09:00.096393: step 5514, loss = 0.68954 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:09:00.985649 ops/training.py:65 2019-01-16 21:09:00.985590: step 5515, loss = 0.69599 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:09:01.874994 ops/training.py:65 2019-01-16 21:09:01.874931: step 5516, loss = 0.70487 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:09:02.764342 ops/training.py:65 2019-01-16 21:09:02.764284: step 5517, loss = 0.66683 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:09:03.653511 ops/training.py:65 2019-01-16 21:09:03.653448: step 5518, loss = 0.67656 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:09:04.545140 ops/training.py:65 2019-01-16 21:09:04.545054: step 5519, loss = 0.69673 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:09:05.438734 ops/training.py:65 2019-01-16 21:09:05.438635: step 5520, loss = 0.71394 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:09:06.331243 ops/training.py:65 2019-01-16 21:09:06.331160: step 5521, loss = 0.68782 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:09:07.222405 ops/training.py:65 2019-01-16 21:09:07.222333: step 5522, loss = 0.72318 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:09:08.112978 ops/training.py:65 2019-01-16 21:09:08.112910: step 5523, loss = 0.71093 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:09:09.002268 ops/training.py:65 2019-01-16 21:09:09.002207: step 5524, loss = 0.69317 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:09:09.891202 ops/training.py:65 2019-01-16 21:09:09.891143: step 5525, loss = 0.66540 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:09:10.780010 ops/training.py:65 2019-01-16 21:09:10.779946: step 5526, loss = 0.70802 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:09:11.669948 ops/training.py:65 2019-01-16 21:09:11.669888: step 5527, loss = 0.72904 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:09:12.559922 ops/training.py:65 2019-01-16 21:09:12.559854: step 5528, loss = 0.67821 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:09:13.449842 ops/training.py:65 2019-01-16 21:09:13.449771: step 5529, loss = 0.69872 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:09:14.339144 ops/training.py:65 2019-01-16 21:09:14.339077: step 5530, loss = 0.70634 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:09:15.228629 ops/training.py:65 2019-01-16 21:09:15.228569: step 5531, loss = 0.69306 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:09:16.118426 ops/training.py:65 2019-01-16 21:09:16.118362: step 5532, loss = 0.68159 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:09:17.008213 ops/training.py:65 2019-01-16 21:09:17.008152: step 5533, loss = 0.68557 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:09:17.898357 ops/training.py:65 2019-01-16 21:09:17.898297: step 5534, loss = 0.69564 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:09:18.787479 ops/training.py:65 2019-01-16 21:09:18.787420: step 5535, loss = 0.69677 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:09:19.677255 ops/training.py:65 2019-01-16 21:09:19.677194: step 5536, loss = 0.68750 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:09:20.566770 ops/training.py:65 2019-01-16 21:09:20.566710: step 5537, loss = 0.69464 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:09:21.455992 ops/training.py:65 2019-01-16 21:09:21.455929: step 5538, loss = 0.66400 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:09:22.345406 ops/training.py:65 2019-01-16 21:09:22.345343: step 5539, loss = 0.73083 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:09:23.234462 ops/training.py:65 2019-01-16 21:09:23.234402: step 5540, loss = 0.68592 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:09:24.124375 ops/training.py:65 2019-01-16 21:09:24.124311: step 5541, loss = 0.69070 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:09:25.013778 ops/training.py:65 2019-01-16 21:09:25.013713: step 5542, loss = 0.74163 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:09:25.902270 ops/training.py:65 2019-01-16 21:09:25.902206: step 5543, loss = 0.69292 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:09:26.790412 ops/training.py:65 2019-01-16 21:09:26.790350: step 5544, loss = 0.69610 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:09:27.680751 ops/training.py:65 2019-01-16 21:09:27.680687: step 5545, loss = 0.70427 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:09:28.569988 ops/training.py:65 2019-01-16 21:09:28.569929: step 5546, loss = 0.67555 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:09:29.459690 ops/training.py:65 2019-01-16 21:09:29.459628: step 5547, loss = 0.69185 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:09:30.349311 ops/training.py:65 2019-01-16 21:09:30.349249: step 5548, loss = 0.66549 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:09:31.240056 ops/training.py:65 2019-01-16 21:09:31.239981: step 5549, loss = 0.69261 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:09:32.133219 ops/training.py:65 2019-01-16 21:09:32.133115: step 5550, loss = 0.69826 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:09:33.024403 ops/training.py:65 2019-01-16 21:09:33.024341: step 5551, loss = 0.67667 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:09:33.913433 ops/training.py:65 2019-01-16 21:09:33.913369: step 5552, loss = 0.72134 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:09:34.803248 ops/training.py:65 2019-01-16 21:09:34.803189: step 5553, loss = 0.68834 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:09:35.695440 ops/training.py:65 2019-01-16 21:09:35.695372: step 5554, loss = 0.66935 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:09:36.586793 ops/training.py:65 2019-01-16 21:09:36.586701: step 5555, loss = 0.67576 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:09:37.478403 ops/training.py:65 2019-01-16 21:09:37.478302: step 5556, loss = 0.72892 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:09:38.371160 ops/training.py:65 2019-01-16 21:09:38.371054: step 5557, loss = 0.66923 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:09:39.262778 ops/training.py:65 2019-01-16 21:09:39.262713: step 5558, loss = 0.69629 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:09:40.152367 ops/training.py:65 2019-01-16 21:09:40.152302: step 5559, loss = 0.71002 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:09:41.042396 ops/training.py:65 2019-01-16 21:09:41.042333: step 5560, loss = 0.68688 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:09:41.933582 ops/training.py:65 2019-01-16 21:09:41.933514: step 5561, loss = 0.65532 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:09:42.826103 ops/training.py:65 2019-01-16 21:09:42.825994: step 5562, loss = 0.75289 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 21:09:43.718165 ops/training.py:65 2019-01-16 21:09:43.718065: step 5563, loss = 0.70197 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:09:44.609909 ops/training.py:65 2019-01-16 21:09:44.609810: step 5564, loss = 0.68812 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:09:45.500155 ops/training.py:65 2019-01-16 21:09:45.500099: step 5565, loss = 0.69219 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:09:46.389015 ops/training.py:65 2019-01-16 21:09:46.388950: step 5566, loss = 0.71677 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:09:47.278069 ops/training.py:65 2019-01-16 21:09:47.278002: step 5567, loss = 0.70972 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:09:48.168500 ops/training.py:65 2019-01-16 21:09:48.168437: step 5568, loss = 0.69250 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:09:49.058240 ops/training.py:65 2019-01-16 21:09:49.058178: step 5569, loss = 0.70735 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:09:49.947476 ops/training.py:65 2019-01-16 21:09:49.947413: step 5570, loss = 0.72907 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:09:50.836465 ops/training.py:65 2019-01-16 21:09:50.836398: step 5571, loss = 0.68591 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:09:51.725415 ops/training.py:65 2019-01-16 21:09:51.725350: step 5572, loss = 0.72091 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:09:52.614739 ops/training.py:65 2019-01-16 21:09:52.614678: step 5573, loss = 0.67200 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:09:53.504116 ops/training.py:65 2019-01-16 21:09:53.504049: step 5574, loss = 0.69460 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:09:54.395181 ops/training.py:65 2019-01-16 21:09:54.395119: step 5575, loss = 0.68528 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:09:55.285281 ops/training.py:65 2019-01-16 21:09:55.285223: step 5576, loss = 0.69778 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:09:56.173754 ops/training.py:65 2019-01-16 21:09:56.173688: step 5577, loss = 0.69233 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:09:57.062832 ops/training.py:65 2019-01-16 21:09:57.062770: step 5578, loss = 0.71504 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:09:57.953453 ops/training.py:65 2019-01-16 21:09:57.953387: step 5579, loss = 0.72150 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:09:58.843145 ops/training.py:65 2019-01-16 21:09:58.843084: step 5580, loss = 0.70151 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:09:59.731770 ops/training.py:65 2019-01-16 21:09:59.731704: step 5581, loss = 0.70119 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:10:00.620930 ops/training.py:65 2019-01-16 21:10:00.620885: step 5582, loss = 0.70744 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:10:01.509196 ops/training.py:65 2019-01-16 21:10:01.509134: step 5583, loss = 0.70841 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:10:02.397190 ops/training.py:65 2019-01-16 21:10:02.397126: step 5584, loss = 0.65451 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:10:03.288379 ops/training.py:65 2019-01-16 21:10:03.288350: step 5585, loss = 0.68659 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:10:04.178987 ops/training.py:65 2019-01-16 21:10:04.178953: step 5586, loss = 0.74047 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:10:05.070147 ops/training.py:65 2019-01-16 21:10:05.070093: step 5587, loss = 0.75498 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:10:05.959451 ops/training.py:65 2019-01-16 21:10:05.959377: step 5588, loss = 0.68935 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:10:06.848840 ops/training.py:65 2019-01-16 21:10:06.848751: step 5589, loss = 0.74272 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:10:07.738713 ops/training.py:65 2019-01-16 21:10:07.738647: step 5590, loss = 0.76233 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:10:08.627534 ops/training.py:65 2019-01-16 21:10:08.627486: step 5591, loss = 0.69891 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:10:09.516508 ops/training.py:65 2019-01-16 21:10:09.516455: step 5592, loss = 0.68505 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:10:10.404789 ops/training.py:65 2019-01-16 21:10:10.404719: step 5593, loss = 0.70572 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:10:11.292934 ops/training.py:65 2019-01-16 21:10:11.292868: step 5594, loss = 0.68702 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:10:12.181395 ops/training.py:65 2019-01-16 21:10:12.181328: step 5595, loss = 0.74102 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:10:13.069987 ops/training.py:65 2019-01-16 21:10:13.069953: step 5596, loss = 0.69850 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:10:13.959745 ops/training.py:65 2019-01-16 21:10:13.959715: step 5597, loss = 0.69775 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:10:14.848909 ops/training.py:65 2019-01-16 21:10:14.848880: step 5598, loss = 0.74212 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:10:15.737238 ops/training.py:65 2019-01-16 21:10:15.737205: step 5599, loss = 0.65237 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:10:16.625585 ops/training.py:65 2019-01-16 21:10:16.625550: step 5600, loss = 0.68203 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:10:17.513585 ops/training.py:65 2019-01-16 21:10:17.513554: step 5601, loss = 0.69785 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:10:18.402867 ops/training.py:65 2019-01-16 21:10:18.402828: step 5602, loss = 0.70274 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:10:19.292815 ops/training.py:65 2019-01-16 21:10:19.292766: step 5603, loss = 0.67778 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:10:20.181425 ops/training.py:65 2019-01-16 21:10:20.181386: step 5604, loss = 0.70437 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:10:21.071178 ops/training.py:65 2019-01-16 21:10:21.071141: step 5605, loss = 0.70130 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:10:21.959211 ops/training.py:65 2019-01-16 21:10:21.959180: step 5606, loss = 0.65706 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:10:22.848701 ops/training.py:65 2019-01-16 21:10:22.848661: step 5607, loss = 0.72757 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:10:23.738417 ops/training.py:65 2019-01-16 21:10:23.738374: step 5608, loss = 0.76309 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:10:24.627487 ops/training.py:65 2019-01-16 21:10:24.627447: step 5609, loss = 0.65890 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:10:25.517150 ops/training.py:65 2019-01-16 21:10:25.517105: step 5610, loss = 0.71604 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:10:26.408188 ops/training.py:65 2019-01-16 21:10:26.408157: step 5611, loss = 0.70231 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:10:27.297900 ops/training.py:65 2019-01-16 21:10:27.297803: step 5612, loss = 0.72629 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:10:28.189211 ops/training.py:65 2019-01-16 21:10:28.189149: step 5613, loss = 0.69995 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:10:29.080786 ops/training.py:65 2019-01-16 21:10:29.080736: step 5614, loss = 0.71600 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:10:29.970964 ops/training.py:65 2019-01-16 21:10:29.970909: step 5615, loss = 0.77398 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:10:30.859593 ops/training.py:65 2019-01-16 21:10:30.859519: step 5616, loss = 0.65257 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:10:31.750137 ops/training.py:65 2019-01-16 21:10:31.750098: step 5617, loss = 0.64801 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:10:32.638700 ops/training.py:65 2019-01-16 21:10:32.638630: step 5618, loss = 0.70785 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:10:33.529275 ops/training.py:65 2019-01-16 21:10:33.529243: step 5619, loss = 0.71230 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:10:34.418682 ops/training.py:65 2019-01-16 21:10:34.418615: step 5620, loss = 0.69941 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:10:35.307838 ops/training.py:65 2019-01-16 21:10:35.307772: step 5621, loss = 0.62900 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:10:36.197974 ops/training.py:65 2019-01-16 21:10:36.197921: step 5622, loss = 0.63126 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:10:37.086489 ops/training.py:65 2019-01-16 21:10:37.086409: step 5623, loss = 0.71556 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:10:37.976937 ops/training.py:65 2019-01-16 21:10:37.976850: step 5624, loss = 0.68805 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:10:38.867723 ops/training.py:65 2019-01-16 21:10:38.867624: step 5625, loss = 0.73006 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:10:39.761687 ops/training.py:65 2019-01-16 21:10:39.761585: step 5626, loss = 0.72985 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:10:40.654609 ops/training.py:65 2019-01-16 21:10:40.654504: step 5627, loss = 0.73929 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:10:41.546415 ops/training.py:65 2019-01-16 21:10:41.546346: step 5628, loss = 0.66322 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:10:42.436189 ops/training.py:65 2019-01-16 21:10:42.436125: step 5629, loss = 0.68545 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:10:43.326941 ops/training.py:65 2019-01-16 21:10:43.326875: step 5630, loss = 0.71950 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:10:44.215392 ops/training.py:65 2019-01-16 21:10:44.215323: step 5631, loss = 0.74587 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:10:45.104346 ops/training.py:65 2019-01-16 21:10:45.104277: step 5632, loss = 0.65594 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:10:45.993033 ops/training.py:65 2019-01-16 21:10:45.992968: step 5633, loss = 0.71701 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:10:46.882585 ops/training.py:65 2019-01-16 21:10:46.882531: step 5634, loss = 0.70364 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:10:47.771961 ops/training.py:65 2019-01-16 21:10:47.771899: step 5635, loss = 0.65415 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:10:48.660549 ops/training.py:65 2019-01-16 21:10:48.660458: step 5636, loss = 0.64926 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:10:49.550402 ops/training.py:65 2019-01-16 21:10:49.550304: step 5637, loss = 0.72207 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:10:50.440212 ops/training.py:65 2019-01-16 21:10:50.440176: step 5638, loss = 0.71632 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:10:51.329488 ops/training.py:65 2019-01-16 21:10:51.329446: step 5639, loss = 0.66763 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:10:52.218320 ops/training.py:65 2019-01-16 21:10:52.218281: step 5640, loss = 0.69675 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:10:53.107342 ops/training.py:65 2019-01-16 21:10:53.107293: step 5641, loss = 0.67069 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:10:53.996996 ops/training.py:65 2019-01-16 21:10:53.996950: step 5642, loss = 0.70076 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:10:54.886858 ops/training.py:65 2019-01-16 21:10:54.886769: step 5643, loss = 0.68159 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:10:55.777788 ops/training.py:65 2019-01-16 21:10:55.777718: step 5644, loss = 0.65787 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:10:56.667278 ops/training.py:65 2019-01-16 21:10:56.667210: step 5645, loss = 0.68788 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:10:57.556760 ops/training.py:65 2019-01-16 21:10:57.556694: step 5646, loss = 0.70898 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:10:58.446604 ops/training.py:65 2019-01-16 21:10:58.446540: step 5647, loss = 0.71017 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:10:59.336155 ops/training.py:65 2019-01-16 21:10:59.336090: step 5648, loss = 0.69214 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:11:00.225402 ops/training.py:65 2019-01-16 21:11:00.225333: step 5649, loss = 0.69848 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:11:01.114564 ops/training.py:65 2019-01-16 21:11:01.114496: step 5650, loss = 0.66668 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:11:02.004282 ops/training.py:65 2019-01-16 21:11:02.004213: step 5651, loss = 0.68735 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:11:02.893733 ops/training.py:65 2019-01-16 21:11:02.893668: step 5652, loss = 0.67917 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:11:03.786108 ops/training.py:65 2019-01-16 21:11:03.786048: step 5653, loss = 0.69739 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:11:04.679219 ops/training.py:65 2019-01-16 21:11:04.679110: step 5654, loss = 0.71374 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:11:05.574011 ops/training.py:65 2019-01-16 21:11:05.573918: step 5655, loss = 0.72471 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:11:06.466075 ops/training.py:65 2019-01-16 21:11:06.466012: step 5656, loss = 0.73234 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:11:07.355292 ops/training.py:65 2019-01-16 21:11:07.355225: step 5657, loss = 0.67221 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:11:08.244505 ops/training.py:65 2019-01-16 21:11:08.244441: step 5658, loss = 0.71887 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:11:09.134020 ops/training.py:65 2019-01-16 21:11:09.133962: step 5659, loss = 0.72538 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:11:10.024001 ops/training.py:65 2019-01-16 21:11:10.023920: step 5660, loss = 0.71179 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:11:10.912952 ops/training.py:65 2019-01-16 21:11:10.912869: step 5661, loss = 0.69007 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:11:11.802854 ops/training.py:65 2019-01-16 21:11:11.802788: step 5662, loss = 0.70339 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:11:12.693063 ops/training.py:65 2019-01-16 21:11:12.692999: step 5663, loss = 0.68994 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:11:13.582771 ops/training.py:65 2019-01-16 21:11:13.582700: step 5664, loss = 0.65657 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:11:14.472448 ops/training.py:65 2019-01-16 21:11:14.472381: step 5665, loss = 0.75334 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:11:15.362984 ops/training.py:65 2019-01-16 21:11:15.362919: step 5666, loss = 0.65466 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:11:16.253146 ops/training.py:65 2019-01-16 21:11:16.253084: step 5667, loss = 0.69152 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:11:17.144347 ops/training.py:65 2019-01-16 21:11:17.144285: step 5668, loss = 0.68514 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:11:18.034040 ops/training.py:65 2019-01-16 21:11:18.033981: step 5669, loss = 0.69602 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:11:18.925871 ops/training.py:65 2019-01-16 21:11:18.925806: step 5670, loss = 0.69196 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:11:19.815857 ops/training.py:65 2019-01-16 21:11:19.815797: step 5671, loss = 0.70347 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:11:20.705677 ops/training.py:65 2019-01-16 21:11:20.705618: step 5672, loss = 0.71258 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:11:21.595061 ops/training.py:65 2019-01-16 21:11:21.594999: step 5673, loss = 0.71657 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:11:22.483502 ops/training.py:65 2019-01-16 21:11:22.483425: step 5674, loss = 0.71434 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:11:23.372788 ops/training.py:65 2019-01-16 21:11:23.372721: step 5675, loss = 0.69172 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:11:24.262283 ops/training.py:65 2019-01-16 21:11:24.262218: step 5676, loss = 0.66984 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:11:25.151930 ops/training.py:65 2019-01-16 21:11:25.151870: step 5677, loss = 0.68554 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:11:26.041263 ops/training.py:65 2019-01-16 21:11:26.041204: step 5678, loss = 0.66870 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.75
I2992 2019-01-16 21:11:26.932132 ops/training.py:65 2019-01-16 21:11:26.932069: step 5679, loss = 0.67691 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:11:27.824979 ops/training.py:65 2019-01-16 21:11:27.824907: step 5680, loss = 0.71263 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:11:28.715294 ops/training.py:65 2019-01-16 21:11:28.715206: step 5681, loss = 0.65577 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 21:11:29.608241 ops/training.py:65 2019-01-16 21:11:29.608141: step 5682, loss = 0.68437 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:11:30.501355 ops/training.py:65 2019-01-16 21:11:30.501253: step 5683, loss = 0.68989 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:11:31.392574 ops/training.py:65 2019-01-16 21:11:31.392512: step 5684, loss = 0.70242 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:11:32.282794 ops/training.py:65 2019-01-16 21:11:32.282727: step 5685, loss = 0.68100 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:11:33.173217 ops/training.py:65 2019-01-16 21:11:33.173152: step 5686, loss = 0.69262 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:11:34.063430 ops/training.py:65 2019-01-16 21:11:34.063365: step 5687, loss = 0.71802 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:11:34.953656 ops/training.py:65 2019-01-16 21:11:34.953593: step 5688, loss = 0.70549 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:11:35.843252 ops/training.py:65 2019-01-16 21:11:35.843190: step 5689, loss = 0.69022 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:11:36.735961 ops/training.py:65 2019-01-16 21:11:36.735893: step 5690, loss = 0.69842 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:11:37.628833 ops/training.py:65 2019-01-16 21:11:37.628728: step 5691, loss = 0.69008 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:11:38.519855 ops/training.py:65 2019-01-16 21:11:38.519778: step 5692, loss = 0.67175 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:11:39.410459 ops/training.py:65 2019-01-16 21:11:39.410352: step 5693, loss = 0.70687 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:11:40.301539 ops/training.py:65 2019-01-16 21:11:40.301436: step 5694, loss = 0.64582 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:11:41.191646 ops/training.py:65 2019-01-16 21:11:41.191583: step 5695, loss = 0.71164 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:11:42.082189 ops/training.py:65 2019-01-16 21:11:42.082132: step 5696, loss = 0.68968 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:11:42.972769 ops/training.py:65 2019-01-16 21:11:42.972709: step 5697, loss = 0.70301 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:11:43.863371 ops/training.py:65 2019-01-16 21:11:43.863302: step 5698, loss = 0.68786 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:11:44.752681 ops/training.py:65 2019-01-16 21:11:44.752620: step 5699, loss = 0.70885 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:11:45.641776 ops/training.py:65 2019-01-16 21:11:45.641710: step 5700, loss = 0.70653 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:11:46.531839 ops/training.py:65 2019-01-16 21:11:46.531770: step 5701, loss = 0.72760 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:11:47.421548 ops/training.py:65 2019-01-16 21:11:47.421487: step 5702, loss = 0.68195 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:11:48.311980 ops/training.py:65 2019-01-16 21:11:48.311919: step 5703, loss = 0.68879 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:11:49.201372 ops/training.py:65 2019-01-16 21:11:49.201303: step 5704, loss = 0.73692 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:11:50.090313 ops/training.py:65 2019-01-16 21:11:50.090232: step 5705, loss = 0.70135 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:11:50.978562 ops/training.py:65 2019-01-16 21:11:50.978478: step 5706, loss = 0.70064 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:11:51.869454 ops/training.py:65 2019-01-16 21:11:51.869358: step 5707, loss = 0.71173 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:11:52.758106 ops/training.py:65 2019-01-16 21:11:52.758018: step 5708, loss = 0.69563 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:11:53.648127 ops/training.py:65 2019-01-16 21:11:53.648055: step 5709, loss = 0.68877 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:11:54.537141 ops/training.py:65 2019-01-16 21:11:54.537069: step 5710, loss = 0.72082 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:11:55.427592 ops/training.py:65 2019-01-16 21:11:55.427522: step 5711, loss = 0.68120 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:11:56.318320 ops/training.py:65 2019-01-16 21:11:56.318253: step 5712, loss = 0.69742 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:11:57.207710 ops/training.py:65 2019-01-16 21:11:57.207648: step 5713, loss = 0.70681 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:11:58.098977 ops/training.py:65 2019-01-16 21:11:58.098913: step 5714, loss = 0.66885 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:11:58.990475 ops/training.py:65 2019-01-16 21:11:58.990378: step 5715, loss = 0.73152 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:11:59.882192 ops/training.py:65 2019-01-16 21:11:59.882086: step 5716, loss = 0.67725 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:12:00.775833 ops/training.py:65 2019-01-16 21:12:00.775729: step 5717, loss = 0.68974 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:12:01.668333 ops/training.py:65 2019-01-16 21:12:01.668261: step 5718, loss = 0.69315 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:12:02.558901 ops/training.py:65 2019-01-16 21:12:02.558839: step 5719, loss = 0.69095 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:12:03.448227 ops/training.py:65 2019-01-16 21:12:03.448158: step 5720, loss = 0.69399 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:12:04.338026 ops/training.py:65 2019-01-16 21:12:04.337960: step 5721, loss = 0.68891 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:12:05.226923 ops/training.py:65 2019-01-16 21:12:05.226861: step 5722, loss = 0.68090 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:12:06.117026 ops/training.py:65 2019-01-16 21:12:06.116967: step 5723, loss = 0.70165 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:12:07.010123 ops/training.py:65 2019-01-16 21:12:07.010069: step 5724, loss = 0.69338 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:12:07.901218 ops/training.py:65 2019-01-16 21:12:07.901113: step 5725, loss = 0.69047 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:12:08.792189 ops/training.py:65 2019-01-16 21:12:08.792130: step 5726, loss = 0.69940 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:12:09.682476 ops/training.py:65 2019-01-16 21:12:09.682413: step 5727, loss = 0.69833 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:12:10.572137 ops/training.py:65 2019-01-16 21:12:10.572071: step 5728, loss = 0.72298 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:12:11.461956 ops/training.py:65 2019-01-16 21:12:11.461894: step 5729, loss = 0.68256 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:12:12.352251 ops/training.py:65 2019-01-16 21:12:12.352179: step 5730, loss = 0.70803 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:12:13.242633 ops/training.py:65 2019-01-16 21:12:13.242561: step 5731, loss = 0.67284 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:12:14.133254 ops/training.py:65 2019-01-16 21:12:14.133194: step 5732, loss = 0.74464 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:12:15.022490 ops/training.py:65 2019-01-16 21:12:15.022428: step 5733, loss = 0.66803 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:12:15.912657 ops/training.py:65 2019-01-16 21:12:15.912591: step 5734, loss = 0.68818 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:12:16.802388 ops/training.py:65 2019-01-16 21:12:16.802328: step 5735, loss = 0.68314 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:12:17.691917 ops/training.py:65 2019-01-16 21:12:17.691854: step 5736, loss = 0.71754 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:12:18.583170 ops/training.py:65 2019-01-16 21:12:18.583116: step 5737, loss = 0.72357 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:12:19.474846 ops/training.py:65 2019-01-16 21:12:19.474749: step 5738, loss = 0.67634 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:12:20.367144 ops/training.py:65 2019-01-16 21:12:20.367036: step 5739, loss = 0.69669 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:12:21.258291 ops/training.py:65 2019-01-16 21:12:21.258200: step 5740, loss = 0.68164 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:12:22.150125 ops/training.py:65 2019-01-16 21:12:22.150035: step 5741, loss = 0.69361 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:12:23.043180 ops/training.py:65 2019-01-16 21:12:23.043088: step 5742, loss = 0.70884 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:12:23.936075 ops/training.py:65 2019-01-16 21:12:23.935978: step 5743, loss = 0.70439 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:12:24.829550 ops/training.py:65 2019-01-16 21:12:24.829440: step 5744, loss = 0.71664 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:12:25.721830 ops/training.py:65 2019-01-16 21:12:25.721729: step 5745, loss = 0.70135 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:12:26.612987 ops/training.py:65 2019-01-16 21:12:26.612917: step 5746, loss = 0.69048 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:12:27.505746 ops/training.py:65 2019-01-16 21:12:27.505637: step 5747, loss = 0.69434 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:12:28.397044 ops/training.py:65 2019-01-16 21:12:28.396945: step 5748, loss = 0.69183 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:12:29.287346 ops/training.py:65 2019-01-16 21:12:29.287282: step 5749, loss = 0.70698 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:12:30.176521 ops/training.py:65 2019-01-16 21:12:30.176458: step 5750, loss = 0.68583 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:12:31.065395 ops/training.py:65 2019-01-16 21:12:31.065327: step 5751, loss = 0.69290 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:12:31.955145 ops/training.py:65 2019-01-16 21:12:31.955081: step 5752, loss = 0.69602 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:12:32.846048 ops/training.py:65 2019-01-16 21:12:32.845985: step 5753, loss = 0.71262 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 21:12:33.735752 ops/training.py:65 2019-01-16 21:12:33.735685: step 5754, loss = 0.70338 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:12:34.624593 ops/training.py:65 2019-01-16 21:12:34.624529: step 5755, loss = 0.68983 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:12:35.514222 ops/training.py:65 2019-01-16 21:12:35.514153: step 5756, loss = 0.68921 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:12:36.403734 ops/training.py:65 2019-01-16 21:12:36.403668: step 5757, loss = 0.70064 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:12:37.293490 ops/training.py:65 2019-01-16 21:12:37.293423: step 5758, loss = 0.71663 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:12:38.182413 ops/training.py:65 2019-01-16 21:12:38.182348: step 5759, loss = 0.68039 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:12:39.075120 ops/training.py:65 2019-01-16 21:12:39.075085: step 5760, loss = 0.68282 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:12:39.968066 ops/training.py:65 2019-01-16 21:12:39.967976: step 5761, loss = 0.70728 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:12:40.860468 ops/training.py:65 2019-01-16 21:12:40.860365: step 5762, loss = 0.71610 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:12:41.753160 ops/training.py:65 2019-01-16 21:12:41.753071: step 5763, loss = 0.72652 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:12:42.643266 ops/training.py:65 2019-01-16 21:12:42.643197: step 5764, loss = 0.71995 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:12:43.535590 ops/training.py:65 2019-01-16 21:12:43.535520: step 5765, loss = 0.73906 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 21:12:44.428732 ops/training.py:65 2019-01-16 21:12:44.428626: step 5766, loss = 0.64215 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.75
I2992 2019-01-16 21:12:45.319574 ops/training.py:65 2019-01-16 21:12:45.319519: step 5767, loss = 0.70985 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:12:46.208954 ops/training.py:65 2019-01-16 21:12:46.208893: step 5768, loss = 0.71427 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:12:47.097629 ops/training.py:65 2019-01-16 21:12:47.097575: step 5769, loss = 0.71583 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:12:47.986326 ops/training.py:65 2019-01-16 21:12:47.986265: step 5770, loss = 0.68548 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:12:48.876436 ops/training.py:65 2019-01-16 21:12:48.876377: step 5771, loss = 0.70083 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:12:49.767321 ops/training.py:65 2019-01-16 21:12:49.767257: step 5772, loss = 0.70913 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:12:50.655922 ops/training.py:65 2019-01-16 21:12:50.655853: step 5773, loss = 0.70980 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:12:51.546270 ops/training.py:65 2019-01-16 21:12:51.546208: step 5774, loss = 0.67997 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:12:52.435556 ops/training.py:65 2019-01-16 21:12:52.435493: step 5775, loss = 0.70638 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:12:53.324152 ops/training.py:65 2019-01-16 21:12:53.324085: step 5776, loss = 0.68607 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:12:54.217933 ops/training.py:65 2019-01-16 21:12:54.217858: step 5777, loss = 0.70396 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:12:55.110692 ops/training.py:65 2019-01-16 21:12:55.110609: step 5778, loss = 0.72362 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:12:56.002978 ops/training.py:65 2019-01-16 21:12:56.002881: step 5779, loss = 0.72005 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:12:56.896349 ops/training.py:65 2019-01-16 21:12:56.896252: step 5780, loss = 0.70890 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:12:57.788698 ops/training.py:65 2019-01-16 21:12:57.788595: step 5781, loss = 0.70566 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:12:58.681017 ops/training.py:65 2019-01-16 21:12:58.680918: step 5782, loss = 0.67265 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:12:59.571801 ops/training.py:65 2019-01-16 21:12:59.571762: step 5783, loss = 0.70164 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:13:00.463635 ops/training.py:65 2019-01-16 21:13:00.463607: step 5784, loss = 0.69665 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:13:01.354071 ops/training.py:65 2019-01-16 21:13:01.354041: step 5785, loss = 0.67506 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:13:02.245248 ops/training.py:65 2019-01-16 21:13:02.245217: step 5786, loss = 0.69657 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:13:03.134834 ops/training.py:65 2019-01-16 21:13:03.134794: step 5787, loss = 0.67573 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:13:04.024598 ops/training.py:65 2019-01-16 21:13:04.024555: step 5788, loss = 0.67660 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:13:04.914298 ops/training.py:65 2019-01-16 21:13:04.914261: step 5789, loss = 0.68349 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:13:05.803160 ops/training.py:65 2019-01-16 21:13:05.803116: step 5790, loss = 0.70656 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:13:06.692652 ops/training.py:65 2019-01-16 21:13:06.692609: step 5791, loss = 0.69940 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:13:07.581915 ops/training.py:65 2019-01-16 21:13:07.581870: step 5792, loss = 0.70787 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:13:08.471195 ops/training.py:65 2019-01-16 21:13:08.471142: step 5793, loss = 0.69255 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:13:09.360182 ops/training.py:65 2019-01-16 21:13:09.360143: step 5794, loss = 0.69678 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:13:10.248590 ops/training.py:65 2019-01-16 21:13:10.248516: step 5795, loss = 0.70269 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:13:11.138754 ops/training.py:65 2019-01-16 21:13:11.138666: step 5796, loss = 0.70094 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:13:12.028487 ops/training.py:65 2019-01-16 21:13:12.028422: step 5797, loss = 0.66916 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:13:12.917777 ops/training.py:65 2019-01-16 21:13:12.917712: step 5798, loss = 0.69443 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:13:13.807702 ops/training.py:65 2019-01-16 21:13:13.807632: step 5799, loss = 0.73408 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:13:14.696952 ops/training.py:65 2019-01-16 21:13:14.696889: step 5800, loss = 0.67927 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:13:15.585907 ops/training.py:65 2019-01-16 21:13:15.585845: step 5801, loss = 0.69156 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:13:16.475272 ops/training.py:65 2019-01-16 21:13:16.475213: step 5802, loss = 0.70635 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:13:17.367471 ops/training.py:65 2019-01-16 21:13:17.367402: step 5803, loss = 0.70160 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:13:18.260003 ops/training.py:65 2019-01-16 21:13:18.259890: step 5804, loss = 0.69703 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:13:19.153257 ops/training.py:65 2019-01-16 21:13:19.153169: step 5805, loss = 0.70501 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:13:20.047398 ops/training.py:65 2019-01-16 21:13:20.047313: step 5806, loss = 0.70058 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:13:20.940107 ops/training.py:65 2019-01-16 21:13:20.939999: step 5807, loss = 0.67531 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:13:21.831062 ops/training.py:65 2019-01-16 21:13:21.830999: step 5808, loss = 0.68528 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:13:22.720995 ops/training.py:65 2019-01-16 21:13:22.720936: step 5809, loss = 0.69769 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:13:23.611016 ops/training.py:65 2019-01-16 21:13:23.610950: step 5810, loss = 0.69515 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:13:24.501224 ops/training.py:65 2019-01-16 21:13:24.501159: step 5811, loss = 0.68305 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:13:25.390448 ops/training.py:65 2019-01-16 21:13:25.390386: step 5812, loss = 0.70093 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:13:26.280401 ops/training.py:65 2019-01-16 21:13:26.280341: step 5813, loss = 0.70721 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:13:27.168544 ops/training.py:65 2019-01-16 21:13:27.168487: step 5814, loss = 0.70358 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:13:28.058884 ops/training.py:65 2019-01-16 21:13:28.058817: step 5815, loss = 0.69471 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:13:28.952310 ops/training.py:65 2019-01-16 21:13:28.952201: step 5816, loss = 0.69163 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:13:29.843211 ops/training.py:65 2019-01-16 21:13:29.843143: step 5817, loss = 0.69859 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:13:30.734069 ops/training.py:65 2019-01-16 21:13:30.733992: step 5818, loss = 0.69145 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:13:31.626624 ops/training.py:65 2019-01-16 21:13:31.626533: step 5819, loss = 0.70299 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:13:32.518627 ops/training.py:65 2019-01-16 21:13:32.518526: step 5820, loss = 0.70002 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:13:33.412144 ops/training.py:65 2019-01-16 21:13:33.412046: step 5821, loss = 0.68925 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:13:34.304120 ops/training.py:65 2019-01-16 21:13:34.304051: step 5822, loss = 0.69067 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:13:35.196771 ops/training.py:65 2019-01-16 21:13:35.196669: step 5823, loss = 0.71374 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:13:36.088900 ops/training.py:65 2019-01-16 21:13:36.088836: step 5824, loss = 0.66266 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:13:36.978374 ops/training.py:65 2019-01-16 21:13:36.978313: step 5825, loss = 0.70107 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:13:37.869069 ops/training.py:65 2019-01-16 21:13:37.869007: step 5826, loss = 0.69941 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:13:38.758875 ops/training.py:65 2019-01-16 21:13:38.758815: step 5827, loss = 0.69712 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:13:39.648165 ops/training.py:65 2019-01-16 21:13:39.648109: step 5828, loss = 0.68270 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:13:40.540035 ops/training.py:65 2019-01-16 21:13:40.539954: step 5829, loss = 0.71002 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:13:41.432140 ops/training.py:65 2019-01-16 21:13:41.432033: step 5830, loss = 0.69972 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:13:42.324020 ops/training.py:65 2019-01-16 21:13:42.323945: step 5831, loss = 0.69067 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:13:43.214516 ops/training.py:65 2019-01-16 21:13:43.214450: step 5832, loss = 0.71212 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:13:44.106677 ops/training.py:65 2019-01-16 21:13:44.106608: step 5833, loss = 0.67297 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:13:45.000116 ops/training.py:65 2019-01-16 21:13:45.000014: step 5834, loss = 0.68170 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:13:45.893844 ops/training.py:65 2019-01-16 21:13:45.893749: step 5835, loss = 0.68968 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:13:46.784314 ops/training.py:65 2019-01-16 21:13:46.784252: step 5836, loss = 0.68506 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:13:47.674521 ops/training.py:65 2019-01-16 21:13:47.674459: step 5837, loss = 0.69814 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:13:48.563657 ops/training.py:65 2019-01-16 21:13:48.563594: step 5838, loss = 0.69695 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:13:49.455865 ops/training.py:65 2019-01-16 21:13:49.455789: step 5839, loss = 0.67755 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:13:50.348187 ops/training.py:65 2019-01-16 21:13:50.348085: step 5840, loss = 0.69817 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:13:51.239114 ops/training.py:65 2019-01-16 21:13:51.239022: step 5841, loss = 0.68530 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:13:52.129022 ops/training.py:65 2019-01-16 21:13:52.128961: step 5842, loss = 0.69868 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:13:53.018286 ops/training.py:65 2019-01-16 21:13:53.018229: step 5843, loss = 0.68390 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:13:53.908891 ops/training.py:65 2019-01-16 21:13:53.908795: step 5844, loss = 0.70305 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:13:54.801133 ops/training.py:65 2019-01-16 21:13:54.801032: step 5845, loss = 0.67862 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:13:55.693280 ops/training.py:65 2019-01-16 21:13:55.693214: step 5846, loss = 0.69407 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:13:56.584467 ops/training.py:65 2019-01-16 21:13:56.584399: step 5847, loss = 0.69603 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:13:57.476886 ops/training.py:65 2019-01-16 21:13:57.476800: step 5848, loss = 0.68900 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:13:58.369248 ops/training.py:65 2019-01-16 21:13:58.369149: step 5849, loss = 0.68062 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:13:59.261961 ops/training.py:65 2019-01-16 21:13:59.261859: step 5850, loss = 0.68402 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:14:00.154490 ops/training.py:65 2019-01-16 21:14:00.154385: step 5851, loss = 0.71342 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:14:01.046516 ops/training.py:65 2019-01-16 21:14:01.046417: step 5852, loss = 0.69330 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:14:01.937875 ops/training.py:65 2019-01-16 21:14:01.937817: step 5853, loss = 0.68978 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:14:02.826520 ops/training.py:65 2019-01-16 21:14:02.826455: step 5854, loss = 0.69665 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:14:03.715802 ops/training.py:65 2019-01-16 21:14:03.715739: step 5855, loss = 0.68455 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:14:04.605592 ops/training.py:65 2019-01-16 21:14:04.605524: step 5856, loss = 0.70533 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:14:05.495982 ops/training.py:65 2019-01-16 21:14:05.495911: step 5857, loss = 0.69357 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:14:06.385833 ops/training.py:65 2019-01-16 21:14:06.385761: step 5858, loss = 0.69994 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:14:07.275440 ops/training.py:65 2019-01-16 21:14:07.275368: step 5859, loss = 0.70786 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:14:08.165496 ops/training.py:65 2019-01-16 21:14:08.165435: step 5860, loss = 0.69956 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:14:09.055295 ops/training.py:65 2019-01-16 21:14:09.055233: step 5861, loss = 0.69432 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:14:09.946782 ops/training.py:65 2019-01-16 21:14:09.946710: step 5862, loss = 0.69305 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:14:10.838728 ops/training.py:65 2019-01-16 21:14:10.838628: step 5863, loss = 0.67904 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:14:11.731815 ops/training.py:65 2019-01-16 21:14:11.731705: step 5864, loss = 0.68534 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:14:12.623106 ops/training.py:65 2019-01-16 21:14:12.623047: step 5865, loss = 0.69967 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:14:13.512120 ops/training.py:65 2019-01-16 21:14:13.512058: step 5866, loss = 0.71567 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:14:14.401627 ops/training.py:65 2019-01-16 21:14:14.401573: step 5867, loss = 0.70526 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:14:15.290960 ops/training.py:65 2019-01-16 21:14:15.290899: step 5868, loss = 0.70241 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:14:16.182995 ops/training.py:65 2019-01-16 21:14:16.182927: step 5869, loss = 0.70993 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 21:14:17.076010 ops/training.py:65 2019-01-16 21:14:17.075900: step 5870, loss = 0.70812 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:14:17.966988 ops/training.py:65 2019-01-16 21:14:17.966929: step 5871, loss = 0.68795 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:14:18.856080 ops/training.py:65 2019-01-16 21:14:18.856013: step 5872, loss = 0.69052 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:14:19.745877 ops/training.py:65 2019-01-16 21:14:19.745814: step 5873, loss = 0.69446 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:14:20.634739 ops/training.py:65 2019-01-16 21:14:20.634678: step 5874, loss = 0.67322 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:14:21.524077 ops/training.py:65 2019-01-16 21:14:21.524018: step 5875, loss = 0.71389 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:14:22.413253 ops/training.py:65 2019-01-16 21:14:22.413199: step 5876, loss = 0.69496 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:14:23.301863 ops/training.py:65 2019-01-16 21:14:23.301800: step 5877, loss = 0.72345 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:14:24.191186 ops/training.py:65 2019-01-16 21:14:24.191128: step 5878, loss = 0.71224 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:14:25.080222 ops/training.py:65 2019-01-16 21:14:25.080160: step 5879, loss = 0.72766 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:14:25.969021 ops/training.py:65 2019-01-16 21:14:25.968951: step 5880, loss = 0.73247 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:14:26.858087 ops/training.py:65 2019-01-16 21:14:26.858025: step 5881, loss = 0.70480 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:14:27.748132 ops/training.py:65 2019-01-16 21:14:27.748064: step 5882, loss = 0.70916 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:14:28.637896 ops/training.py:65 2019-01-16 21:14:28.637829: step 5883, loss = 0.69758 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:14:29.527464 ops/training.py:65 2019-01-16 21:14:29.527402: step 5884, loss = 0.69047 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:14:30.416954 ops/training.py:65 2019-01-16 21:14:30.416889: step 5885, loss = 0.77311 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 21:14:31.306470 ops/training.py:65 2019-01-16 21:14:31.306404: step 5886, loss = 0.70714 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:14:32.195970 ops/training.py:65 2019-01-16 21:14:32.195892: step 5887, loss = 0.68292 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:14:33.087161 ops/training.py:65 2019-01-16 21:14:33.087099: step 5888, loss = 0.69180 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:14:33.980907 ops/training.py:65 2019-01-16 21:14:33.980799: step 5889, loss = 0.69594 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:14:34.871998 ops/training.py:65 2019-01-16 21:14:34.871891: step 5890, loss = 0.69346 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:14:35.762104 ops/training.py:65 2019-01-16 21:14:35.762043: step 5891, loss = 0.67128 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:14:36.652144 ops/training.py:65 2019-01-16 21:14:36.652081: step 5892, loss = 0.70077 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:14:37.541189 ops/training.py:65 2019-01-16 21:14:37.541128: step 5893, loss = 0.66108 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:14:38.430625 ops/training.py:65 2019-01-16 21:14:38.430560: step 5894, loss = 0.68000 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:14:39.321779 ops/training.py:65 2019-01-16 21:14:39.321703: step 5895, loss = 0.70702 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:14:40.215390 ops/training.py:65 2019-01-16 21:14:40.215286: step 5896, loss = 0.68510 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:14:41.106937 ops/training.py:65 2019-01-16 21:14:41.106857: step 5897, loss = 0.65827 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.75
I2992 2019-01-16 21:14:41.996197 ops/training.py:65 2019-01-16 21:14:41.996132: step 5898, loss = 0.70009 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:14:42.887260 ops/training.py:65 2019-01-16 21:14:42.887199: step 5899, loss = 0.68764 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:14:43.779923 ops/training.py:65 2019-01-16 21:14:43.779853: step 5900, loss = 0.69806 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:14:44.673849 ops/training.py:65 2019-01-16 21:14:44.673764: step 5901, loss = 0.66026 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 21:14:45.566476 ops/training.py:65 2019-01-16 21:14:45.566364: step 5902, loss = 0.73159 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:14:46.459540 ops/training.py:65 2019-01-16 21:14:46.459469: step 5903, loss = 0.68127 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:14:47.351688 ops/training.py:65 2019-01-16 21:14:47.351582: step 5904, loss = 0.66624 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:14:48.244361 ops/training.py:65 2019-01-16 21:14:48.244290: step 5905, loss = 0.67785 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:14:49.137005 ops/training.py:65 2019-01-16 21:14:49.136909: step 5906, loss = 0.67995 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:14:50.029626 ops/training.py:65 2019-01-16 21:14:50.029520: step 5907, loss = 0.68029 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:14:50.922997 ops/training.py:65 2019-01-16 21:14:50.922922: step 5908, loss = 0.69759 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:14:51.815803 ops/training.py:65 2019-01-16 21:14:51.815720: step 5909, loss = 0.68989 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:14:52.708288 ops/training.py:65 2019-01-16 21:14:52.708182: step 5910, loss = 0.68194 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:14:53.599403 ops/training.py:65 2019-01-16 21:14:53.599332: step 5911, loss = 0.70318 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:14:54.489049 ops/training.py:65 2019-01-16 21:14:54.488989: step 5912, loss = 0.69722 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:14:55.378630 ops/training.py:65 2019-01-16 21:14:55.378568: step 5913, loss = 0.70745 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:14:56.266957 ops/training.py:65 2019-01-16 21:14:56.266885: step 5914, loss = 0.69152 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:14:57.156332 ops/training.py:65 2019-01-16 21:14:57.156266: step 5915, loss = 0.71438 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:14:58.045486 ops/training.py:65 2019-01-16 21:14:58.045427: step 5916, loss = 0.69429 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:14:58.934486 ops/training.py:65 2019-01-16 21:14:58.934430: step 5917, loss = 0.71207 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:14:59.824217 ops/training.py:65 2019-01-16 21:14:59.824159: step 5918, loss = 0.68309 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:15:00.713079 ops/training.py:65 2019-01-16 21:15:00.713021: step 5919, loss = 0.65887 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 21:15:01.602616 ops/training.py:65 2019-01-16 21:15:01.602558: step 5920, loss = 0.72376 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:15:02.491131 ops/training.py:65 2019-01-16 21:15:02.491069: step 5921, loss = 0.67350 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:15:03.379643 ops/training.py:65 2019-01-16 21:15:03.379577: step 5922, loss = 0.70481 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:15:04.270706 ops/training.py:65 2019-01-16 21:15:04.270639: step 5923, loss = 0.69012 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:15:05.162793 ops/training.py:65 2019-01-16 21:15:05.162692: step 5924, loss = 0.71543 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.25
I2992 2019-01-16 21:15:06.054715 ops/training.py:65 2019-01-16 21:15:06.054622: step 5925, loss = 0.70546 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:15:06.944589 ops/training.py:65 2019-01-16 21:15:06.944532: step 5926, loss = 0.71308 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:15:07.833694 ops/training.py:65 2019-01-16 21:15:07.833636: step 5927, loss = 0.71279 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 21:15:08.723405 ops/training.py:65 2019-01-16 21:15:08.723347: step 5928, loss = 0.71615 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:15:09.612708 ops/training.py:65 2019-01-16 21:15:09.612652: step 5929, loss = 0.69972 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:15:10.502702 ops/training.py:65 2019-01-16 21:15:10.502644: step 5930, loss = 0.69137 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:15:11.391522 ops/training.py:65 2019-01-16 21:15:11.391467: step 5931, loss = 0.71018 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:15:12.281051 ops/training.py:65 2019-01-16 21:15:12.280993: step 5932, loss = 0.67953 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 21:15:13.170621 ops/training.py:65 2019-01-16 21:15:13.170558: step 5933, loss = 0.69142 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:15:14.061838 ops/training.py:65 2019-01-16 21:15:14.061770: step 5934, loss = 0.68576 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:15:14.954346 ops/training.py:65 2019-01-16 21:15:14.954242: step 5935, loss = 0.68835 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:15:15.847312 ops/training.py:65 2019-01-16 21:15:15.847211: step 5936, loss = 0.70684 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:15:16.740472 ops/training.py:65 2019-01-16 21:15:16.740376: step 5937, loss = 0.72941 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:15:17.633132 ops/training.py:65 2019-01-16 21:15:17.633039: step 5938, loss = 0.66348 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:15:18.526371 ops/training.py:65 2019-01-16 21:15:18.526287: step 5939, loss = 0.66669 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:15:19.419292 ops/training.py:65 2019-01-16 21:15:19.419186: step 5940, loss = 0.71713 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:15:20.309394 ops/training.py:65 2019-01-16 21:15:20.309322: step 5941, loss = 0.67974 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:15:21.199057 ops/training.py:65 2019-01-16 21:15:21.198986: step 5942, loss = 0.70688 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:15:22.088530 ops/training.py:65 2019-01-16 21:15:22.088465: step 5943, loss = 0.67835 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:15:22.978263 ops/training.py:65 2019-01-16 21:15:22.978205: step 5944, loss = 0.67005 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:15:23.870749 ops/training.py:65 2019-01-16 21:15:23.870681: step 5945, loss = 0.67000 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:15:24.763751 ops/training.py:65 2019-01-16 21:15:24.763663: step 5946, loss = 0.66495 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:15:25.657249 ops/training.py:65 2019-01-16 21:15:25.657143: step 5947, loss = 0.68643 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:15:26.548304 ops/training.py:65 2019-01-16 21:15:26.548250: step 5948, loss = 0.75182 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.25
I2992 2019-01-16 21:15:27.438005 ops/training.py:65 2019-01-16 21:15:27.437946: step 5949, loss = 0.71246 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:15:28.328321 ops/training.py:65 2019-01-16 21:15:28.328264: step 5950, loss = 0.68391 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:15:29.218302 ops/training.py:65 2019-01-16 21:15:29.218243: step 5951, loss = 0.67170 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:15:30.107652 ops/training.py:65 2019-01-16 21:15:30.107591: step 5952, loss = 0.67606 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:15:30.998353 ops/training.py:65 2019-01-16 21:15:30.998289: step 5953, loss = 0.71456 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:15:31.888208 ops/training.py:65 2019-01-16 21:15:31.888148: step 5954, loss = 0.66520 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:15:32.777648 ops/training.py:65 2019-01-16 21:15:32.777588: step 5955, loss = 0.68172 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:15:33.666757 ops/training.py:65 2019-01-16 21:15:33.666696: step 5956, loss = 0.70863 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:15:34.555193 ops/training.py:65 2019-01-16 21:15:34.555132: step 5957, loss = 0.68959 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:15:35.444408 ops/training.py:65 2019-01-16 21:15:35.444344: step 5958, loss = 0.71818 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:15:36.333094 ops/training.py:65 2019-01-16 21:15:36.333034: step 5959, loss = 0.67513 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:15:37.221850 ops/training.py:65 2019-01-16 21:15:37.221794: step 5960, loss = 0.70609 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:15:38.110358 ops/training.py:65 2019-01-16 21:15:38.110293: step 5961, loss = 0.71002 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:15:38.999078 ops/training.py:65 2019-01-16 21:15:38.999015: step 5962, loss = 0.70446 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:15:39.888689 ops/training.py:65 2019-01-16 21:15:39.888623: step 5963, loss = 0.68975 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:15:40.778093 ops/training.py:65 2019-01-16 21:15:40.778019: step 5964, loss = 0.66768 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:15:41.667969 ops/training.py:65 2019-01-16 21:15:41.667896: step 5965, loss = 0.68965 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:15:42.556549 ops/training.py:65 2019-01-16 21:15:42.556472: step 5966, loss = 0.68316 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:15:43.445622 ops/training.py:65 2019-01-16 21:15:43.445540: step 5967, loss = 0.68858 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:15:44.337811 ops/training.py:65 2019-01-16 21:15:44.337736: step 5968, loss = 0.69784 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:15:45.229536 ops/training.py:65 2019-01-16 21:15:45.229436: step 5969, loss = 0.70841 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:15:46.119653 ops/training.py:65 2019-01-16 21:15:46.119589: step 5970, loss = 0.66846 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:15:47.008930 ops/training.py:65 2019-01-16 21:15:47.008870: step 5971, loss = 0.69634 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:15:47.901304 ops/training.py:65 2019-01-16 21:15:47.901240: step 5972, loss = 0.69848 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:15:48.793978 ops/training.py:65 2019-01-16 21:15:48.793871: step 5973, loss = 0.68932 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:15:49.685175 ops/training.py:65 2019-01-16 21:15:49.685121: step 5974, loss = 0.69609 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:15:50.574198 ops/training.py:65 2019-01-16 21:15:50.574140: step 5975, loss = 0.68106 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:15:51.465995 ops/training.py:65 2019-01-16 21:15:51.465952: step 5976, loss = 0.70422 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:15:52.358090 ops/training.py:65 2019-01-16 21:15:52.358008: step 5977, loss = 0.69943 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:15:53.249805 ops/training.py:65 2019-01-16 21:15:53.249713: step 5978, loss = 0.68242 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:15:54.140004 ops/training.py:65 2019-01-16 21:15:54.139927: step 5979, loss = 0.70295 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:15:55.029318 ops/training.py:65 2019-01-16 21:15:55.029263: step 5980, loss = 0.68790 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:15:55.918098 ops/training.py:65 2019-01-16 21:15:55.918034: step 5981, loss = 0.69664 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:15:56.807131 ops/training.py:65 2019-01-16 21:15:56.807067: step 5982, loss = 0.70398 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:15:57.696769 ops/training.py:65 2019-01-16 21:15:57.696701: step 5983, loss = 0.67572 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:15:58.585835 ops/training.py:65 2019-01-16 21:15:58.585771: step 5984, loss = 0.71429 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:15:59.475674 ops/training.py:65 2019-01-16 21:15:59.475606: step 5985, loss = 0.70327 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:16:00.365113 ops/training.py:65 2019-01-16 21:16:00.365045: step 5986, loss = 0.71239 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:16:01.254498 ops/training.py:65 2019-01-16 21:16:01.254431: step 5987, loss = 0.69853 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:16:02.143863 ops/training.py:65 2019-01-16 21:16:02.143798: step 5988, loss = 0.69988 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:16:03.034031 ops/training.py:65 2019-01-16 21:16:03.033964: step 5989, loss = 0.72254 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:16:03.923513 ops/training.py:65 2019-01-16 21:16:03.923445: step 5990, loss = 0.70338 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:16:04.813045 ops/training.py:65 2019-01-16 21:16:04.812987: step 5991, loss = 0.69504 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:16:05.701510 ops/training.py:65 2019-01-16 21:16:05.701450: step 5992, loss = 0.66660 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:16:06.590923 ops/training.py:65 2019-01-16 21:16:06.590865: step 5993, loss = 0.70360 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:16:07.479661 ops/training.py:65 2019-01-16 21:16:07.479603: step 5994, loss = 0.71848 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 21:16:08.369689 ops/training.py:65 2019-01-16 21:16:08.369625: step 5995, loss = 0.71997 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:16:09.259226 ops/training.py:65 2019-01-16 21:16:09.259165: step 5996, loss = 0.68880 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:16:10.149655 ops/training.py:65 2019-01-16 21:16:10.149591: step 5997, loss = 0.72038 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:16:11.041883 ops/training.py:65 2019-01-16 21:16:11.041780: step 5998, loss = 0.73321 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:16:11.933559 ops/training.py:65 2019-01-16 21:16:11.933499: step 5999, loss = 0.68077 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:20:26.859293 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I2992 2019-01-16 21:20:26.860244 ops/training.py:41 2019-01-16 21:20:26.860191: step 6000, loss = 0.71 (0.1 examples/sec; 254.036 sec/batch) | Training accuracy = 0.40625 | Validation accuracy = 0.50785 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_19_33_19_510334
I2992 2019-01-16 21:20:27.753224 ops/training.py:65 2019-01-16 21:20:27.753123: step 6001, loss = 0.69721 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:20:28.645657 ops/training.py:65 2019-01-16 21:20:28.645577: step 6002, loss = 0.70411 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:20:29.534615 ops/training.py:65 2019-01-16 21:20:29.534558: step 6003, loss = 0.70433 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:20:30.424431 ops/training.py:65 2019-01-16 21:20:30.424372: step 6004, loss = 0.69292 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:20:31.314854 ops/training.py:65 2019-01-16 21:20:31.314791: step 6005, loss = 0.66892 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:20:32.205333 ops/training.py:65 2019-01-16 21:20:32.205272: step 6006, loss = 0.68545 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:20:33.095198 ops/training.py:65 2019-01-16 21:20:33.095135: step 6007, loss = 0.70291 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:20:33.985417 ops/training.py:65 2019-01-16 21:20:33.985356: step 6008, loss = 0.71191 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:20:34.875211 ops/training.py:65 2019-01-16 21:20:34.875154: step 6009, loss = 0.69121 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:20:35.765656 ops/training.py:65 2019-01-16 21:20:35.765601: step 6010, loss = 0.70675 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:20:36.655022 ops/training.py:65 2019-01-16 21:20:36.654962: step 6011, loss = 0.72013 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:20:37.544615 ops/training.py:65 2019-01-16 21:20:37.544558: step 6012, loss = 0.68262 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:20:38.434106 ops/training.py:65 2019-01-16 21:20:38.434049: step 6013, loss = 0.70728 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:20:39.325685 ops/training.py:65 2019-01-16 21:20:39.325618: step 6014, loss = 0.71200 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:20:40.216345 ops/training.py:65 2019-01-16 21:20:40.216247: step 6015, loss = 0.66965 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:20:41.107094 ops/training.py:65 2019-01-16 21:20:41.107005: step 6016, loss = 0.68203 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:20:41.999511 ops/training.py:65 2019-01-16 21:20:41.999413: step 6017, loss = 0.67164 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 21:20:42.891614 ops/training.py:65 2019-01-16 21:20:42.891516: step 6018, loss = 0.70309 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:20:43.783910 ops/training.py:65 2019-01-16 21:20:43.783822: step 6019, loss = 0.72369 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:20:44.674458 ops/training.py:65 2019-01-16 21:20:44.674399: step 6020, loss = 0.71092 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:20:45.563772 ops/training.py:65 2019-01-16 21:20:45.563706: step 6021, loss = 0.69101 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:20:46.453366 ops/training.py:65 2019-01-16 21:20:46.453295: step 6022, loss = 0.67631 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:20:47.342880 ops/training.py:65 2019-01-16 21:20:47.342813: step 6023, loss = 0.69685 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:20:48.232519 ops/training.py:65 2019-01-16 21:20:48.232455: step 6024, loss = 0.68892 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:20:49.122142 ops/training.py:65 2019-01-16 21:20:49.122076: step 6025, loss = 0.69988 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:20:50.011641 ops/training.py:65 2019-01-16 21:20:50.011580: step 6026, loss = 0.68847 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:20:50.900926 ops/training.py:65 2019-01-16 21:20:50.900870: step 6027, loss = 0.70955 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:20:51.790006 ops/training.py:65 2019-01-16 21:20:51.789939: step 6028, loss = 0.70541 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:20:52.679353 ops/training.py:65 2019-01-16 21:20:52.679294: step 6029, loss = 0.71667 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:20:53.568689 ops/training.py:65 2019-01-16 21:20:53.568629: step 6030, loss = 0.70595 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:20:54.458216 ops/training.py:65 2019-01-16 21:20:54.458152: step 6031, loss = 0.72908 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:20:55.347854 ops/training.py:65 2019-01-16 21:20:55.347790: step 6032, loss = 0.69382 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:20:56.240689 ops/training.py:65 2019-01-16 21:20:56.240617: step 6033, loss = 0.67442 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:20:57.135699 ops/training.py:65 2019-01-16 21:20:57.135598: step 6034, loss = 0.67987 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:20:58.029981 ops/training.py:65 2019-01-16 21:20:58.029867: step 6035, loss = 0.69927 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:20:58.922030 ops/training.py:65 2019-01-16 21:20:58.921969: step 6036, loss = 0.67938 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:20:59.811978 ops/training.py:65 2019-01-16 21:20:59.811916: step 6037, loss = 0.68145 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:21:00.701021 ops/training.py:65 2019-01-16 21:21:00.700964: step 6038, loss = 0.70322 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:21:01.590602 ops/training.py:65 2019-01-16 21:21:01.590546: step 6039, loss = 0.67930 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:21:02.481238 ops/training.py:65 2019-01-16 21:21:02.481177: step 6040, loss = 0.70671 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:21:03.372356 ops/training.py:65 2019-01-16 21:21:03.372290: step 6041, loss = 0.70364 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:21:04.263546 ops/training.py:65 2019-01-16 21:21:04.263483: step 6042, loss = 0.66858 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:21:05.153813 ops/training.py:65 2019-01-16 21:21:05.153750: step 6043, loss = 0.71546 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:21:06.043203 ops/training.py:65 2019-01-16 21:21:06.043142: step 6044, loss = 0.71462 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:21:06.933126 ops/training.py:65 2019-01-16 21:21:06.933051: step 6045, loss = 0.68129 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:21:07.824205 ops/training.py:65 2019-01-16 21:21:07.824134: step 6046, loss = 0.65987 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.75
I2992 2019-01-16 21:21:08.716637 ops/training.py:65 2019-01-16 21:21:08.716540: step 6047, loss = 0.72863 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:21:09.607895 ops/training.py:65 2019-01-16 21:21:09.607853: step 6048, loss = 0.68081 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:21:10.498127 ops/training.py:65 2019-01-16 21:21:10.498092: step 6049, loss = 0.69973 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:21:11.387985 ops/training.py:65 2019-01-16 21:21:11.387950: step 6050, loss = 0.68213 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:21:12.278556 ops/training.py:65 2019-01-16 21:21:12.278522: step 6051, loss = 0.67592 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:21:13.171205 ops/training.py:65 2019-01-16 21:21:13.171175: step 6052, loss = 0.64506 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.78125
I2992 2019-01-16 21:21:14.061545 ops/training.py:65 2019-01-16 21:21:14.061514: step 6053, loss = 0.70686 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:21:14.950649 ops/training.py:65 2019-01-16 21:21:14.950611: step 6054, loss = 0.69697 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:21:15.840690 ops/training.py:65 2019-01-16 21:21:15.840650: step 6055, loss = 0.68824 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:21:16.729849 ops/training.py:65 2019-01-16 21:21:16.729795: step 6056, loss = 0.67912 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:21:17.618523 ops/training.py:65 2019-01-16 21:21:17.618470: step 6057, loss = 0.68799 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:21:18.508709 ops/training.py:65 2019-01-16 21:21:18.508659: step 6058, loss = 0.68933 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:21:19.398084 ops/training.py:65 2019-01-16 21:21:19.398030: step 6059, loss = 0.70989 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:21:20.287115 ops/training.py:65 2019-01-16 21:21:20.287070: step 6060, loss = 0.70152 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:21:21.176556 ops/training.py:65 2019-01-16 21:21:21.176515: step 6061, loss = 0.70204 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:21:22.067685 ops/training.py:65 2019-01-16 21:21:22.067597: step 6062, loss = 0.69492 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:21:22.961701 ops/training.py:65 2019-01-16 21:21:22.961600: step 6063, loss = 0.69287 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:21:23.852874 ops/training.py:65 2019-01-16 21:21:23.852807: step 6064, loss = 0.69517 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:21:24.742426 ops/training.py:65 2019-01-16 21:21:24.742371: step 6065, loss = 0.70236 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:21:25.632343 ops/training.py:65 2019-01-16 21:21:25.632287: step 6066, loss = 0.69162 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:21:26.521757 ops/training.py:65 2019-01-16 21:21:26.521697: step 6067, loss = 0.68645 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:21:27.411315 ops/training.py:65 2019-01-16 21:21:27.411254: step 6068, loss = 0.68288 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:21:28.301659 ops/training.py:65 2019-01-16 21:21:28.301601: step 6069, loss = 0.69793 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:21:29.191870 ops/training.py:65 2019-01-16 21:21:29.191806: step 6070, loss = 0.71761 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:21:30.081525 ops/training.py:65 2019-01-16 21:21:30.081464: step 6071, loss = 0.68010 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:21:30.970694 ops/training.py:65 2019-01-16 21:21:30.970622: step 6072, loss = 0.67633 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:21:31.860220 ops/training.py:65 2019-01-16 21:21:31.860119: step 6073, loss = 0.72139 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:21:32.749781 ops/training.py:65 2019-01-16 21:21:32.749705: step 6074, loss = 0.71245 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:21:33.641601 ops/training.py:65 2019-01-16 21:21:33.641534: step 6075, loss = 0.70112 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:21:34.534633 ops/training.py:65 2019-01-16 21:21:34.534557: step 6076, loss = 0.68981 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:21:35.427731 ops/training.py:65 2019-01-16 21:21:35.427646: step 6077, loss = 0.64449 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:21:36.321166 ops/training.py:65 2019-01-16 21:21:36.321063: step 6078, loss = 0.69981 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:21:37.212758 ops/training.py:65 2019-01-16 21:21:37.212698: step 6079, loss = 0.69950 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:21:38.102733 ops/training.py:65 2019-01-16 21:21:38.102678: step 6080, loss = 0.69750 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:21:38.991540 ops/training.py:65 2019-01-16 21:21:38.991482: step 6081, loss = 0.69680 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:21:39.880956 ops/training.py:65 2019-01-16 21:21:39.880901: step 6082, loss = 0.69370 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:21:40.770233 ops/training.py:65 2019-01-16 21:21:40.770175: step 6083, loss = 0.68657 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:21:41.661918 ops/training.py:65 2019-01-16 21:21:41.661834: step 6084, loss = 0.70924 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:21:42.555415 ops/training.py:65 2019-01-16 21:21:42.555310: step 6085, loss = 0.69092 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:21:43.447937 ops/training.py:65 2019-01-16 21:21:43.447873: step 6086, loss = 0.68448 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:21:44.337562 ops/training.py:65 2019-01-16 21:21:44.337503: step 6087, loss = 0.67599 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:21:45.227586 ops/training.py:65 2019-01-16 21:21:45.227525: step 6088, loss = 0.68837 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:21:46.117141 ops/training.py:65 2019-01-16 21:21:46.117086: step 6089, loss = 0.71719 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:21:47.006869 ops/training.py:65 2019-01-16 21:21:47.006819: step 6090, loss = 0.68533 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:21:47.895907 ops/training.py:65 2019-01-16 21:21:47.895850: step 6091, loss = 0.70502 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:21:48.785913 ops/training.py:65 2019-01-16 21:21:48.785860: step 6092, loss = 0.70035 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:21:49.675598 ops/training.py:65 2019-01-16 21:21:49.675540: step 6093, loss = 0.69375 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:21:50.567737 ops/training.py:65 2019-01-16 21:21:50.567669: step 6094, loss = 0.70243 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:21:51.460610 ops/training.py:65 2019-01-16 21:21:51.460508: step 6095, loss = 0.69586 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:21:52.353544 ops/training.py:65 2019-01-16 21:21:52.353447: step 6096, loss = 0.71236 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:21:53.246568 ops/training.py:65 2019-01-16 21:21:53.246498: step 6097, loss = 0.70618 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:21:54.139368 ops/training.py:65 2019-01-16 21:21:54.139259: step 6098, loss = 0.69999 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:21:55.031293 ops/training.py:65 2019-01-16 21:21:55.031231: step 6099, loss = 0.71561 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:21:55.921504 ops/training.py:65 2019-01-16 21:21:55.921437: step 6100, loss = 0.69284 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:21:56.812820 ops/training.py:65 2019-01-16 21:21:56.812749: step 6101, loss = 0.67343 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:21:57.705865 ops/training.py:65 2019-01-16 21:21:57.705758: step 6102, loss = 0.72071 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:21:58.598916 ops/training.py:65 2019-01-16 21:21:58.598834: step 6103, loss = 0.71104 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:21:59.491252 ops/training.py:65 2019-01-16 21:21:59.491164: step 6104, loss = 0.70820 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:22:00.384517 ops/training.py:65 2019-01-16 21:22:00.384410: step 6105, loss = 0.69098 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:22:01.276565 ops/training.py:65 2019-01-16 21:22:01.276486: step 6106, loss = 0.70182 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:22:02.169953 ops/training.py:65 2019-01-16 21:22:02.169851: step 6107, loss = 0.70450 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:22:03.063710 ops/training.py:65 2019-01-16 21:22:03.063610: step 6108, loss = 0.70147 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:22:03.956801 ops/training.py:65 2019-01-16 21:22:03.956739: step 6109, loss = 0.68152 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:22:04.847868 ops/training.py:65 2019-01-16 21:22:04.847804: step 6110, loss = 0.73688 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 21:22:05.737378 ops/training.py:65 2019-01-16 21:22:05.737326: step 6111, loss = 0.72743 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:22:06.626506 ops/training.py:65 2019-01-16 21:22:06.626454: step 6112, loss = 0.69213 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:22:07.515357 ops/training.py:65 2019-01-16 21:22:07.515303: step 6113, loss = 0.66887 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:22:08.405331 ops/training.py:65 2019-01-16 21:22:08.405277: step 6114, loss = 0.71490 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:22:09.295004 ops/training.py:65 2019-01-16 21:22:09.294951: step 6115, loss = 0.69961 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:22:10.184329 ops/training.py:65 2019-01-16 21:22:10.184273: step 6116, loss = 0.71739 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:22:11.073257 ops/training.py:65 2019-01-16 21:22:11.073201: step 6117, loss = 0.67089 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:22:11.961333 ops/training.py:65 2019-01-16 21:22:11.961281: step 6118, loss = 0.70005 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:22:12.850935 ops/training.py:65 2019-01-16 21:22:12.850883: step 6119, loss = 0.69369 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:22:13.742915 ops/training.py:65 2019-01-16 21:22:13.742868: step 6120, loss = 0.69563 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:22:14.634309 ops/training.py:65 2019-01-16 21:22:14.634247: step 6121, loss = 0.68437 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:22:15.526243 ops/training.py:65 2019-01-16 21:22:15.526153: step 6122, loss = 0.68207 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:22:16.417913 ops/training.py:65 2019-01-16 21:22:16.417812: step 6123, loss = 0.71318 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:22:17.311098 ops/training.py:65 2019-01-16 21:22:17.310996: step 6124, loss = 0.67394 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:22:18.202576 ops/training.py:65 2019-01-16 21:22:18.202522: step 6125, loss = 0.67315 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:22:19.092121 ops/training.py:65 2019-01-16 21:22:19.092071: step 6126, loss = 0.67995 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:22:19.981278 ops/training.py:65 2019-01-16 21:22:19.981220: step 6127, loss = 0.70635 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:22:20.871094 ops/training.py:65 2019-01-16 21:22:20.871040: step 6128, loss = 0.69134 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:22:21.760152 ops/training.py:65 2019-01-16 21:22:21.760098: step 6129, loss = 0.70277 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:22:22.648483 ops/training.py:65 2019-01-16 21:22:22.648429: step 6130, loss = 0.70289 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:22:23.538643 ops/training.py:65 2019-01-16 21:22:23.538581: step 6131, loss = 0.72470 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:22:24.428824 ops/training.py:65 2019-01-16 21:22:24.428769: step 6132, loss = 0.69503 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:22:25.318279 ops/training.py:65 2019-01-16 21:22:25.318227: step 6133, loss = 0.67422 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:22:26.210855 ops/training.py:65 2019-01-16 21:22:26.210789: step 6134, loss = 0.68103 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:22:27.103443 ops/training.py:65 2019-01-16 21:22:27.103340: step 6135, loss = 0.66765 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:22:27.996813 ops/training.py:65 2019-01-16 21:22:27.996703: step 6136, loss = 0.69646 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:22:28.889113 ops/training.py:65 2019-01-16 21:22:28.889009: step 6137, loss = 0.69045 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:22:29.781923 ops/training.py:65 2019-01-16 21:22:29.781824: step 6138, loss = 0.67214 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:22:30.672346 ops/training.py:65 2019-01-16 21:22:30.672262: step 6139, loss = 0.69706 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:22:31.562352 ops/training.py:65 2019-01-16 21:22:31.562291: step 6140, loss = 0.71933 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:22:32.451574 ops/training.py:65 2019-01-16 21:22:32.451517: step 6141, loss = 0.70775 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:22:33.340615 ops/training.py:65 2019-01-16 21:22:33.340550: step 6142, loss = 0.70759 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:22:34.231774 ops/training.py:65 2019-01-16 21:22:34.231717: step 6143, loss = 0.71085 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:22:35.121443 ops/training.py:65 2019-01-16 21:22:35.121384: step 6144, loss = 0.70670 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:22:36.011228 ops/training.py:65 2019-01-16 21:22:36.011174: step 6145, loss = 0.70467 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:22:36.901030 ops/training.py:65 2019-01-16 21:22:36.900972: step 6146, loss = 0.71723 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:22:37.790557 ops/training.py:65 2019-01-16 21:22:37.790497: step 6147, loss = 0.69583 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:22:38.681459 ops/training.py:65 2019-01-16 21:22:38.681402: step 6148, loss = 0.68395 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:22:39.570969 ops/training.py:65 2019-01-16 21:22:39.570913: step 6149, loss = 0.71709 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 21:22:40.460980 ops/training.py:65 2019-01-16 21:22:40.460930: step 6150, loss = 0.66965 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:22:41.350309 ops/training.py:65 2019-01-16 21:22:41.350253: step 6151, loss = 0.69281 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:22:42.239448 ops/training.py:65 2019-01-16 21:22:42.239393: step 6152, loss = 0.68310 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:22:43.129208 ops/training.py:65 2019-01-16 21:22:43.129148: step 6153, loss = 0.69140 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:22:44.018713 ops/training.py:65 2019-01-16 21:22:44.018655: step 6154, loss = 0.67961 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:22:44.908261 ops/training.py:65 2019-01-16 21:22:44.908201: step 6155, loss = 0.69402 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:22:45.798519 ops/training.py:65 2019-01-16 21:22:45.798458: step 6156, loss = 0.68541 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:22:46.688883 ops/training.py:65 2019-01-16 21:22:46.688819: step 6157, loss = 0.71383 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:22:47.578727 ops/training.py:65 2019-01-16 21:22:47.578663: step 6158, loss = 0.73179 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:22:48.468284 ops/training.py:65 2019-01-16 21:22:48.468224: step 6159, loss = 0.69296 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:22:49.357420 ops/training.py:65 2019-01-16 21:22:49.357361: step 6160, loss = 0.67896 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:22:50.246809 ops/training.py:65 2019-01-16 21:22:50.246759: step 6161, loss = 0.68851 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:22:51.135340 ops/training.py:65 2019-01-16 21:22:51.135290: step 6162, loss = 0.69629 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:22:52.025447 ops/training.py:65 2019-01-16 21:22:52.025392: step 6163, loss = 0.67541 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:22:52.915347 ops/training.py:65 2019-01-16 21:22:52.915286: step 6164, loss = 0.72349 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:22:53.804644 ops/training.py:65 2019-01-16 21:22:53.804578: step 6165, loss = 0.67774 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:22:54.694666 ops/training.py:65 2019-01-16 21:22:54.694608: step 6166, loss = 0.69593 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:22:55.583428 ops/training.py:65 2019-01-16 21:22:55.583368: step 6167, loss = 0.69457 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:22:56.474969 ops/training.py:65 2019-01-16 21:22:56.474903: step 6168, loss = 0.67316 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:22:57.366532 ops/training.py:65 2019-01-16 21:22:57.366440: step 6169, loss = 0.68405 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:22:58.260048 ops/training.py:65 2019-01-16 21:22:58.259937: step 6170, loss = 0.70649 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:22:59.151609 ops/training.py:65 2019-01-16 21:22:59.151549: step 6171, loss = 0.68157 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:23:00.041841 ops/training.py:65 2019-01-16 21:23:00.041782: step 6172, loss = 0.67506 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:23:00.931228 ops/training.py:65 2019-01-16 21:23:00.931172: step 6173, loss = 0.69059 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:23:01.822251 ops/training.py:65 2019-01-16 21:23:01.822188: step 6174, loss = 0.72206 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:23:02.714733 ops/training.py:65 2019-01-16 21:23:02.714628: step 6175, loss = 0.71784 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:23:03.606738 ops/training.py:65 2019-01-16 21:23:03.606673: step 6176, loss = 0.68766 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:23:04.497130 ops/training.py:65 2019-01-16 21:23:04.497068: step 6177, loss = 0.69434 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:23:05.387251 ops/training.py:65 2019-01-16 21:23:05.387183: step 6178, loss = 0.70950 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:23:06.277149 ops/training.py:65 2019-01-16 21:23:06.277076: step 6179, loss = 0.68827 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:23:07.166764 ops/training.py:65 2019-01-16 21:23:07.166689: step 6180, loss = 0.67084 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:23:08.056433 ops/training.py:65 2019-01-16 21:23:08.056369: step 6181, loss = 0.72697 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:23:08.946251 ops/training.py:65 2019-01-16 21:23:08.946191: step 6182, loss = 0.71755 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:23:09.835300 ops/training.py:65 2019-01-16 21:23:09.835237: step 6183, loss = 0.71618 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:23:10.724761 ops/training.py:65 2019-01-16 21:23:10.724704: step 6184, loss = 0.68807 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:23:11.615215 ops/training.py:65 2019-01-16 21:23:11.615145: step 6185, loss = 0.69473 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:23:12.509935 ops/training.py:65 2019-01-16 21:23:12.509827: step 6186, loss = 0.70566 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:23:13.402591 ops/training.py:65 2019-01-16 21:23:13.402526: step 6187, loss = 0.68412 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:23:14.295311 ops/training.py:65 2019-01-16 21:23:14.295205: step 6188, loss = 0.71982 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:23:15.189313 ops/training.py:65 2019-01-16 21:23:15.189207: step 6189, loss = 0.71743 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:23:16.080614 ops/training.py:65 2019-01-16 21:23:16.080556: step 6190, loss = 0.67944 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:23:16.970285 ops/training.py:65 2019-01-16 21:23:16.970230: step 6191, loss = 0.70099 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:23:17.861180 ops/training.py:65 2019-01-16 21:23:17.861128: step 6192, loss = 0.67224 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:23:18.750587 ops/training.py:65 2019-01-16 21:23:18.750539: step 6193, loss = 0.69141 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:23:19.639825 ops/training.py:65 2019-01-16 21:23:19.639771: step 6194, loss = 0.70437 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:23:20.531032 ops/training.py:65 2019-01-16 21:23:20.530955: step 6195, loss = 0.70769 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:23:21.424105 ops/training.py:65 2019-01-16 21:23:21.424001: step 6196, loss = 0.67943 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:23:22.316359 ops/training.py:65 2019-01-16 21:23:22.316298: step 6197, loss = 0.68603 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:23:23.206529 ops/training.py:65 2019-01-16 21:23:23.206462: step 6198, loss = 0.70120 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:23:24.097040 ops/training.py:65 2019-01-16 21:23:24.096983: step 6199, loss = 0.68106 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:23:24.987728 ops/training.py:65 2019-01-16 21:23:24.987673: step 6200, loss = 0.72740 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:23:25.878286 ops/training.py:65 2019-01-16 21:23:25.878223: step 6201, loss = 0.71466 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:23:26.770363 ops/training.py:65 2019-01-16 21:23:26.770263: step 6202, loss = 0.68868 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:23:27.662091 ops/training.py:65 2019-01-16 21:23:27.662033: step 6203, loss = 0.69110 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:23:28.554968 ops/training.py:65 2019-01-16 21:23:28.554896: step 6204, loss = 0.70417 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:23:29.446982 ops/training.py:65 2019-01-16 21:23:29.446878: step 6205, loss = 0.69097 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:23:30.338442 ops/training.py:65 2019-01-16 21:23:30.338346: step 6206, loss = 0.69817 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:23:31.231047 ops/training.py:65 2019-01-16 21:23:31.230945: step 6207, loss = 0.69889 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:23:32.124660 ops/training.py:65 2019-01-16 21:23:32.124553: step 6208, loss = 0.75998 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:23:33.018162 ops/training.py:65 2019-01-16 21:23:33.018066: step 6209, loss = 0.65360 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:23:33.910762 ops/training.py:65 2019-01-16 21:23:33.910660: step 6210, loss = 0.69505 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:23:34.802261 ops/training.py:65 2019-01-16 21:23:34.802161: step 6211, loss = 0.70316 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:23:35.694183 ops/training.py:65 2019-01-16 21:23:35.694123: step 6212, loss = 0.70786 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:23:36.584072 ops/training.py:65 2019-01-16 21:23:36.584015: step 6213, loss = 0.69895 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:23:37.473344 ops/training.py:65 2019-01-16 21:23:37.473288: step 6214, loss = 0.72373 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:23:38.362965 ops/training.py:65 2019-01-16 21:23:38.362911: step 6215, loss = 0.72829 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:23:39.256743 ops/training.py:65 2019-01-16 21:23:39.256674: step 6216, loss = 0.71958 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:23:40.149120 ops/training.py:65 2019-01-16 21:23:40.149020: step 6217, loss = 0.69608 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:23:41.040987 ops/training.py:65 2019-01-16 21:23:41.040932: step 6218, loss = 0.71279 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:23:41.930808 ops/training.py:65 2019-01-16 21:23:41.930752: step 6219, loss = 0.71229 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:23:42.821422 ops/training.py:65 2019-01-16 21:23:42.821351: step 6220, loss = 0.70300 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:23:43.714934 ops/training.py:65 2019-01-16 21:23:43.714834: step 6221, loss = 0.68807 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:23:44.606527 ops/training.py:65 2019-01-16 21:23:44.606466: step 6222, loss = 0.67405 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:23:45.495913 ops/training.py:65 2019-01-16 21:23:45.495850: step 6223, loss = 0.70200 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:23:46.387592 ops/training.py:65 2019-01-16 21:23:46.387526: step 6224, loss = 0.69013 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:23:47.280981 ops/training.py:65 2019-01-16 21:23:47.280876: step 6225, loss = 0.70026 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:23:48.175096 ops/training.py:65 2019-01-16 21:23:48.175013: step 6226, loss = 0.72400 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.25
I2992 2019-01-16 21:23:49.068790 ops/training.py:65 2019-01-16 21:23:49.068695: step 6227, loss = 0.68861 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:23:49.960455 ops/training.py:65 2019-01-16 21:23:49.960399: step 6228, loss = 0.67182 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:23:50.849368 ops/training.py:65 2019-01-16 21:23:50.849313: step 6229, loss = 0.70860 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:23:51.738456 ops/training.py:65 2019-01-16 21:23:51.738396: step 6230, loss = 0.68657 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:23:52.627490 ops/training.py:65 2019-01-16 21:23:52.627435: step 6231, loss = 0.66126 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:23:53.517498 ops/training.py:65 2019-01-16 21:23:53.517449: step 6232, loss = 0.70524 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:23:54.408943 ops/training.py:65 2019-01-16 21:23:54.408885: step 6233, loss = 0.68212 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:23:55.298370 ops/training.py:65 2019-01-16 21:23:55.298311: step 6234, loss = 0.66556 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 21:23:56.186917 ops/training.py:65 2019-01-16 21:23:56.186853: step 6235, loss = 0.68009 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:23:57.076102 ops/training.py:65 2019-01-16 21:23:57.076040: step 6236, loss = 0.69475 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:23:57.964617 ops/training.py:65 2019-01-16 21:23:57.964556: step 6237, loss = 0.69111 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:23:58.852899 ops/training.py:65 2019-01-16 21:23:58.852842: step 6238, loss = 0.77682 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:23:59.746651 ops/training.py:65 2019-01-16 21:23:59.746610: step 6239, loss = 0.73786 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:24:00.638139 ops/training.py:65 2019-01-16 21:24:00.638104: step 6240, loss = 0.71618 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:24:01.528149 ops/training.py:65 2019-01-16 21:24:01.528101: step 6241, loss = 0.72334 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:24:02.418554 ops/training.py:65 2019-01-16 21:24:02.418521: step 6242, loss = 0.68246 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:24:03.310524 ops/training.py:65 2019-01-16 21:24:03.310489: step 6243, loss = 0.68459 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:24:04.199991 ops/training.py:65 2019-01-16 21:24:04.199946: step 6244, loss = 0.69916 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:24:05.087900 ops/training.py:65 2019-01-16 21:24:05.087862: step 6245, loss = 0.70216 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:24:05.977504 ops/training.py:65 2019-01-16 21:24:05.977456: step 6246, loss = 0.71306 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:24:06.866220 ops/training.py:65 2019-01-16 21:24:06.866163: step 6247, loss = 0.71147 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:24:07.757529 ops/training.py:65 2019-01-16 21:24:07.757492: step 6248, loss = 0.68763 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:24:08.649832 ops/training.py:65 2019-01-16 21:24:08.649740: step 6249, loss = 0.65894 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:24:09.540497 ops/training.py:65 2019-01-16 21:24:09.540424: step 6250, loss = 0.71729 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:24:10.430767 ops/training.py:65 2019-01-16 21:24:10.430669: step 6251, loss = 0.74243 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:24:11.320682 ops/training.py:65 2019-01-16 21:24:11.320616: step 6252, loss = 0.71799 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:24:12.208962 ops/training.py:65 2019-01-16 21:24:12.208899: step 6253, loss = 0.68943 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:24:13.097540 ops/training.py:65 2019-01-16 21:24:13.097474: step 6254, loss = 0.64927 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 21:24:13.987529 ops/training.py:65 2019-01-16 21:24:13.987490: step 6255, loss = 0.80145 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:24:14.876578 ops/training.py:65 2019-01-16 21:24:14.876533: step 6256, loss = 0.69860 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:24:15.766036 ops/training.py:65 2019-01-16 21:24:15.765973: step 6257, loss = 0.77341 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:24:16.655982 ops/training.py:65 2019-01-16 21:24:16.655910: step 6258, loss = 0.68345 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:24:17.545799 ops/training.py:65 2019-01-16 21:24:17.545738: step 6259, loss = 0.69123 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:24:18.434424 ops/training.py:65 2019-01-16 21:24:18.434351: step 6260, loss = 0.70431 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:24:19.323802 ops/training.py:65 2019-01-16 21:24:19.323735: step 6261, loss = 0.67398 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:24:20.213371 ops/training.py:65 2019-01-16 21:24:20.213312: step 6262, loss = 0.69382 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:24:21.103040 ops/training.py:65 2019-01-16 21:24:21.102990: step 6263, loss = 0.65113 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:24:21.992872 ops/training.py:65 2019-01-16 21:24:21.992822: step 6264, loss = 0.74709 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:24:22.881790 ops/training.py:65 2019-01-16 21:24:22.881736: step 6265, loss = 0.75527 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:24:23.770720 ops/training.py:65 2019-01-16 21:24:23.770675: step 6266, loss = 0.72790 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:24:24.661233 ops/training.py:65 2019-01-16 21:24:24.661176: step 6267, loss = 0.67922 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:24:25.550471 ops/training.py:65 2019-01-16 21:24:25.550406: step 6268, loss = 0.70196 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:24:26.440790 ops/training.py:65 2019-01-16 21:24:26.440730: step 6269, loss = 0.68867 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:24:27.336513 ops/training.py:65 2019-01-16 21:24:27.336383: step 6270, loss = 0.70267 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:24:28.229952 ops/training.py:65 2019-01-16 21:24:28.229852: step 6271, loss = 0.65404 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:24:29.121629 ops/training.py:65 2019-01-16 21:24:29.121551: step 6272, loss = 0.71452 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:24:30.014503 ops/training.py:65 2019-01-16 21:24:30.014404: step 6273, loss = 0.71142 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:24:30.909608 ops/training.py:65 2019-01-16 21:24:30.909534: step 6274, loss = 0.70371 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:24:31.803933 ops/training.py:65 2019-01-16 21:24:31.803828: step 6275, loss = 0.69729 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:24:32.695253 ops/training.py:65 2019-01-16 21:24:32.695192: step 6276, loss = 0.71042 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:24:33.584629 ops/training.py:65 2019-01-16 21:24:33.584564: step 6277, loss = 0.67545 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:24:34.476122 ops/training.py:65 2019-01-16 21:24:34.476054: step 6278, loss = 0.68190 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:24:35.368139 ops/training.py:65 2019-01-16 21:24:35.368040: step 6279, loss = 0.66874 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:24:36.263258 ops/training.py:65 2019-01-16 21:24:36.263190: step 6280, loss = 0.71092 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:24:37.155454 ops/training.py:65 2019-01-16 21:24:37.155351: step 6281, loss = 0.71352 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:24:38.046882 ops/training.py:65 2019-01-16 21:24:38.046813: step 6282, loss = 0.73650 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:24:38.939175 ops/training.py:65 2019-01-16 21:24:38.939138: step 6283, loss = 0.64488 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:24:39.835201 ops/training.py:65 2019-01-16 21:24:39.835140: step 6284, loss = 0.69600 (35.7 examples/sec; 0.895 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:24:40.728702 ops/training.py:65 2019-01-16 21:24:40.728598: step 6285, loss = 0.69014 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:24:41.620085 ops/training.py:65 2019-01-16 21:24:41.620023: step 6286, loss = 0.73079 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:24:42.511216 ops/training.py:65 2019-01-16 21:24:42.511145: step 6287, loss = 0.66592 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:24:43.400330 ops/training.py:65 2019-01-16 21:24:43.400268: step 6288, loss = 0.68935 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:24:44.290126 ops/training.py:65 2019-01-16 21:24:44.290056: step 6289, loss = 0.76373 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:24:45.179443 ops/training.py:65 2019-01-16 21:24:45.179375: step 6290, loss = 0.71437 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:24:46.068333 ops/training.py:65 2019-01-16 21:24:46.068268: step 6291, loss = 0.71736 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:24:46.957169 ops/training.py:65 2019-01-16 21:24:46.957091: step 6292, loss = 0.72749 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:24:47.846645 ops/training.py:65 2019-01-16 21:24:47.846574: step 6293, loss = 0.73775 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:24:48.736493 ops/training.py:65 2019-01-16 21:24:48.736419: step 6294, loss = 0.69032 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:24:49.626139 ops/training.py:65 2019-01-16 21:24:49.626076: step 6295, loss = 0.70910 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:24:50.515449 ops/training.py:65 2019-01-16 21:24:50.515388: step 6296, loss = 0.72970 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:24:51.404364 ops/training.py:65 2019-01-16 21:24:51.404306: step 6297, loss = 0.68303 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:24:52.297305 ops/training.py:65 2019-01-16 21:24:52.297235: step 6298, loss = 0.75506 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:24:53.188985 ops/training.py:65 2019-01-16 21:24:53.188884: step 6299, loss = 0.72716 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:24:54.080623 ops/training.py:65 2019-01-16 21:24:54.080512: step 6300, loss = 0.70942 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:24:54.971046 ops/training.py:65 2019-01-16 21:24:54.970983: step 6301, loss = 0.71570 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:24:55.860012 ops/training.py:65 2019-01-16 21:24:55.859947: step 6302, loss = 0.68265 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:24:56.753223 ops/training.py:65 2019-01-16 21:24:56.753155: step 6303, loss = 0.70077 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:24:57.646052 ops/training.py:65 2019-01-16 21:24:57.645945: step 6304, loss = 0.67484 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:24:58.537402 ops/training.py:65 2019-01-16 21:24:58.537333: step 6305, loss = 0.71226 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:24:59.426818 ops/training.py:65 2019-01-16 21:24:59.426750: step 6306, loss = 0.66396 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:25:00.316967 ops/training.py:65 2019-01-16 21:25:00.316899: step 6307, loss = 0.68327 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:25:01.208121 ops/training.py:65 2019-01-16 21:25:01.208045: step 6308, loss = 0.66981 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:25:02.099696 ops/training.py:65 2019-01-16 21:25:02.099596: step 6309, loss = 0.72147 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:25:02.992547 ops/training.py:65 2019-01-16 21:25:02.992440: step 6310, loss = 0.69912 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:25:03.884385 ops/training.py:65 2019-01-16 21:25:03.884315: step 6311, loss = 0.69884 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:25:04.774424 ops/training.py:65 2019-01-16 21:25:04.774356: step 6312, loss = 0.70861 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:25:05.663600 ops/training.py:65 2019-01-16 21:25:05.663533: step 6313, loss = 0.72525 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:25:06.552925 ops/training.py:65 2019-01-16 21:25:06.552856: step 6314, loss = 0.72280 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:25:07.443465 ops/training.py:65 2019-01-16 21:25:07.443388: step 6315, loss = 0.67557 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:25:08.335128 ops/training.py:65 2019-01-16 21:25:08.335040: step 6316, loss = 0.73647 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:25:09.227483 ops/training.py:65 2019-01-16 21:25:09.227381: step 6317, loss = 0.74748 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:25:10.119442 ops/training.py:65 2019-01-16 21:25:10.119342: step 6318, loss = 0.69747 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:25:11.009271 ops/training.py:65 2019-01-16 21:25:11.009195: step 6319, loss = 0.71840 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:25:11.898664 ops/training.py:65 2019-01-16 21:25:11.898582: step 6320, loss = 0.70961 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:25:12.788315 ops/training.py:65 2019-01-16 21:25:12.788236: step 6321, loss = 0.74246 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:25:13.678570 ops/training.py:65 2019-01-16 21:25:13.678487: step 6322, loss = 0.69442 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:25:14.568896 ops/training.py:65 2019-01-16 21:25:14.568818: step 6323, loss = 0.69186 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:25:15.459802 ops/training.py:65 2019-01-16 21:25:15.459714: step 6324, loss = 0.71276 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:25:16.349554 ops/training.py:65 2019-01-16 21:25:16.349455: step 6325, loss = 0.76385 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:25:17.243021 ops/training.py:65 2019-01-16 21:25:17.242913: step 6326, loss = 0.73875 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:25:18.134528 ops/training.py:65 2019-01-16 21:25:18.134460: step 6327, loss = 0.70855 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:25:19.023451 ops/training.py:65 2019-01-16 21:25:19.023391: step 6328, loss = 0.74008 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:25:19.912378 ops/training.py:65 2019-01-16 21:25:19.912320: step 6329, loss = 0.72013 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:25:20.803848 ops/training.py:65 2019-01-16 21:25:20.803784: step 6330, loss = 0.74894 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:25:21.696547 ops/training.py:65 2019-01-16 21:25:21.696453: step 6331, loss = 0.71671 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:25:22.588960 ops/training.py:65 2019-01-16 21:25:22.588878: step 6332, loss = 0.72508 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:25:23.482915 ops/training.py:65 2019-01-16 21:25:23.482856: step 6333, loss = 0.70525 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:25:24.375788 ops/training.py:65 2019-01-16 21:25:24.375693: step 6334, loss = 0.70936 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:25:25.270132 ops/training.py:65 2019-01-16 21:25:25.270029: step 6335, loss = 0.71330 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:25:26.162923 ops/training.py:65 2019-01-16 21:25:26.162815: step 6336, loss = 0.74841 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:25:27.055438 ops/training.py:65 2019-01-16 21:25:27.055365: step 6337, loss = 0.70198 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:25:27.949022 ops/training.py:65 2019-01-16 21:25:27.948916: step 6338, loss = 0.66324 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:25:28.841331 ops/training.py:65 2019-01-16 21:25:28.841225: step 6339, loss = 0.73338 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:25:29.733950 ops/training.py:65 2019-01-16 21:25:29.733847: step 6340, loss = 0.72532 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:25:30.627168 ops/training.py:65 2019-01-16 21:25:30.627065: step 6341, loss = 0.67802 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:25:31.519228 ops/training.py:65 2019-01-16 21:25:31.519160: step 6342, loss = 0.64906 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:25:32.413215 ops/training.py:65 2019-01-16 21:25:32.413115: step 6343, loss = 0.69755 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:25:33.304943 ops/training.py:65 2019-01-16 21:25:33.304871: step 6344, loss = 0.69449 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:25:34.195114 ops/training.py:65 2019-01-16 21:25:34.195043: step 6345, loss = 0.68954 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:25:35.084922 ops/training.py:65 2019-01-16 21:25:35.084857: step 6346, loss = 0.71001 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:25:35.976277 ops/training.py:65 2019-01-16 21:25:35.976205: step 6347, loss = 0.71063 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:25:36.868763 ops/training.py:65 2019-01-16 21:25:36.868668: step 6348, loss = 0.72136 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:25:37.763031 ops/training.py:65 2019-01-16 21:25:37.762934: step 6349, loss = 0.70186 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:25:38.654950 ops/training.py:65 2019-01-16 21:25:38.654887: step 6350, loss = 0.68554 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:25:39.545628 ops/training.py:65 2019-01-16 21:25:39.545564: step 6351, loss = 0.71951 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:25:40.435199 ops/training.py:65 2019-01-16 21:25:40.435143: step 6352, loss = 0.69005 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:25:41.324503 ops/training.py:65 2019-01-16 21:25:41.324445: step 6353, loss = 0.70646 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:25:42.214815 ops/training.py:65 2019-01-16 21:25:42.214759: step 6354, loss = 0.69077 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:25:43.104138 ops/training.py:65 2019-01-16 21:25:43.104074: step 6355, loss = 0.70309 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:25:43.993603 ops/training.py:65 2019-01-16 21:25:43.993550: step 6356, loss = 0.65911 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:25:44.883346 ops/training.py:65 2019-01-16 21:25:44.883292: step 6357, loss = 0.71444 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:25:45.775292 ops/training.py:65 2019-01-16 21:25:45.775219: step 6358, loss = 0.70845 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:25:46.668337 ops/training.py:65 2019-01-16 21:25:46.668232: step 6359, loss = 0.73544 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:25:47.562218 ops/training.py:65 2019-01-16 21:25:47.562125: step 6360, loss = 0.71708 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:25:48.455689 ops/training.py:65 2019-01-16 21:25:48.455611: step 6361, loss = 0.73459 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:25:49.346784 ops/training.py:65 2019-01-16 21:25:49.346696: step 6362, loss = 0.68449 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:25:50.236698 ops/training.py:65 2019-01-16 21:25:50.236591: step 6363, loss = 0.68284 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:25:51.126692 ops/training.py:65 2019-01-16 21:25:51.126590: step 6364, loss = 0.65844 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:25:52.019762 ops/training.py:65 2019-01-16 21:25:52.019662: step 6365, loss = 0.68132 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:25:52.911736 ops/training.py:65 2019-01-16 21:25:52.911644: step 6366, loss = 0.69249 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:25:53.802804 ops/training.py:65 2019-01-16 21:25:53.802732: step 6367, loss = 0.70969 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:25:54.693749 ops/training.py:65 2019-01-16 21:25:54.693679: step 6368, loss = 0.67307 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:25:55.587240 ops/training.py:65 2019-01-16 21:25:55.587139: step 6369, loss = 0.69209 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:25:56.478376 ops/training.py:65 2019-01-16 21:25:56.478290: step 6370, loss = 0.69452 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:25:57.368500 ops/training.py:65 2019-01-16 21:25:57.368421: step 6371, loss = 0.69370 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:25:58.258966 ops/training.py:65 2019-01-16 21:25:58.258897: step 6372, loss = 0.68813 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:25:59.147681 ops/training.py:65 2019-01-16 21:25:59.147617: step 6373, loss = 0.71614 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:26:00.037853 ops/training.py:65 2019-01-16 21:26:00.037794: step 6374, loss = 0.68577 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:26:00.927538 ops/training.py:65 2019-01-16 21:26:00.927452: step 6375, loss = 0.67589 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:26:01.818010 ops/training.py:65 2019-01-16 21:26:01.817943: step 6376, loss = 0.70592 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:26:02.707358 ops/training.py:65 2019-01-16 21:26:02.707281: step 6377, loss = 0.71021 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:26:03.597368 ops/training.py:65 2019-01-16 21:26:03.597300: step 6378, loss = 0.68123 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:26:04.486792 ops/training.py:65 2019-01-16 21:26:04.486731: step 6379, loss = 0.70432 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:26:05.379214 ops/training.py:65 2019-01-16 21:26:05.379141: step 6380, loss = 0.70475 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:26:06.271815 ops/training.py:65 2019-01-16 21:26:06.271710: step 6381, loss = 0.69696 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:26:07.164675 ops/training.py:65 2019-01-16 21:26:07.164572: step 6382, loss = 0.70303 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:26:08.058648 ops/training.py:65 2019-01-16 21:26:08.058579: step 6383, loss = 0.65779 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.78125
I2992 2019-01-16 21:26:08.947886 ops/training.py:65 2019-01-16 21:26:08.947816: step 6384, loss = 0.68616 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:26:09.837986 ops/training.py:65 2019-01-16 21:26:09.837917: step 6385, loss = 0.71006 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:26:10.727962 ops/training.py:65 2019-01-16 21:26:10.727903: step 6386, loss = 0.68421 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:26:11.619745 ops/training.py:65 2019-01-16 21:26:11.619666: step 6387, loss = 0.69365 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:26:12.511960 ops/training.py:65 2019-01-16 21:26:12.511861: step 6388, loss = 0.70717 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:26:13.404307 ops/training.py:65 2019-01-16 21:26:13.404232: step 6389, loss = 0.69458 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:26:14.294909 ops/training.py:65 2019-01-16 21:26:14.294836: step 6390, loss = 0.67325 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:26:15.184965 ops/training.py:65 2019-01-16 21:26:15.184887: step 6391, loss = 0.70379 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:26:16.076779 ops/training.py:65 2019-01-16 21:26:16.076699: step 6392, loss = 0.69454 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:26:16.970188 ops/training.py:65 2019-01-16 21:26:16.970086: step 6393, loss = 0.68822 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:26:17.861823 ops/training.py:65 2019-01-16 21:26:17.861761: step 6394, loss = 0.69188 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:26:18.751573 ops/training.py:65 2019-01-16 21:26:18.751513: step 6395, loss = 0.68963 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:26:19.641770 ops/training.py:65 2019-01-16 21:26:19.641705: step 6396, loss = 0.74659 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.25
I2992 2019-01-16 21:26:20.533537 ops/training.py:65 2019-01-16 21:26:20.533465: step 6397, loss = 0.70003 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:26:21.424640 ops/training.py:65 2019-01-16 21:26:21.424541: step 6398, loss = 0.68913 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:26:22.317583 ops/training.py:65 2019-01-16 21:26:22.317489: step 6399, loss = 0.69512 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:26:23.209456 ops/training.py:65 2019-01-16 21:26:23.209375: step 6400, loss = 0.71697 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:26:24.100852 ops/training.py:65 2019-01-16 21:26:24.100746: step 6401, loss = 0.68329 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:26:24.993826 ops/training.py:65 2019-01-16 21:26:24.993718: step 6402, loss = 0.69039 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:26:25.884594 ops/training.py:65 2019-01-16 21:26:25.884496: step 6403, loss = 0.71255 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:26:26.774722 ops/training.py:65 2019-01-16 21:26:26.774654: step 6404, loss = 0.72484 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:26:27.664297 ops/training.py:65 2019-01-16 21:26:27.664226: step 6405, loss = 0.68249 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:26:28.553333 ops/training.py:65 2019-01-16 21:26:28.553260: step 6406, loss = 0.68834 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:26:29.446586 ops/training.py:65 2019-01-16 21:26:29.446506: step 6407, loss = 0.69534 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:26:30.338486 ops/training.py:65 2019-01-16 21:26:30.338385: step 6408, loss = 0.72034 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:26:31.229771 ops/training.py:65 2019-01-16 21:26:31.229705: step 6409, loss = 0.68980 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:26:32.120344 ops/training.py:65 2019-01-16 21:26:32.120284: step 6410, loss = 0.71819 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:26:33.009234 ops/training.py:65 2019-01-16 21:26:33.009174: step 6411, loss = 0.71305 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:26:33.899897 ops/training.py:65 2019-01-16 21:26:33.899814: step 6412, loss = 0.71320 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:26:34.790454 ops/training.py:65 2019-01-16 21:26:34.790359: step 6413, loss = 0.70683 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:26:35.681785 ops/training.py:65 2019-01-16 21:26:35.681683: step 6414, loss = 0.69363 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:26:36.573176 ops/training.py:65 2019-01-16 21:26:36.573081: step 6415, loss = 0.70442 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:26:37.464363 ops/training.py:65 2019-01-16 21:26:37.464271: step 6416, loss = 0.69133 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:26:38.356815 ops/training.py:65 2019-01-16 21:26:38.356713: step 6417, loss = 0.67622 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:26:39.248228 ops/training.py:65 2019-01-16 21:26:39.248165: step 6418, loss = 0.70401 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:26:40.139129 ops/training.py:65 2019-01-16 21:26:40.139051: step 6419, loss = 0.71104 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:26:41.032125 ops/training.py:65 2019-01-16 21:26:41.032024: step 6420, loss = 0.73137 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:26:41.923692 ops/training.py:65 2019-01-16 21:26:41.923625: step 6421, loss = 0.71066 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:26:42.813676 ops/training.py:65 2019-01-16 21:26:42.813605: step 6422, loss = 0.71772 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:26:43.706750 ops/training.py:65 2019-01-16 21:26:43.706678: step 6423, loss = 0.73409 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:26:44.599193 ops/training.py:65 2019-01-16 21:26:44.599087: step 6424, loss = 0.66956 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:26:45.491326 ops/training.py:65 2019-01-16 21:26:45.491219: step 6425, loss = 0.70281 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:26:46.384961 ops/training.py:65 2019-01-16 21:26:46.384855: step 6426, loss = 0.72536 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:26:47.275248 ops/training.py:65 2019-01-16 21:26:47.275144: step 6427, loss = 0.67528 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:26:48.168924 ops/training.py:65 2019-01-16 21:26:48.168838: step 6428, loss = 0.68217 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:26:49.060098 ops/training.py:65 2019-01-16 21:26:49.060003: step 6429, loss = 0.70334 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:26:49.954926 ops/training.py:65 2019-01-16 21:26:49.954822: step 6430, loss = 0.67325 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:26:50.847349 ops/training.py:65 2019-01-16 21:26:50.847254: step 6431, loss = 0.69086 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:26:51.738422 ops/training.py:65 2019-01-16 21:26:51.738347: step 6432, loss = 0.72989 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:26:52.629369 ops/training.py:65 2019-01-16 21:26:52.629282: step 6433, loss = 0.70221 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:26:53.520718 ops/training.py:65 2019-01-16 21:26:53.520624: step 6434, loss = 0.68472 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:26:54.410984 ops/training.py:65 2019-01-16 21:26:54.410883: step 6435, loss = 0.71448 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:26:55.302869 ops/training.py:65 2019-01-16 21:26:55.302765: step 6436, loss = 0.69507 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:26:56.193515 ops/training.py:65 2019-01-16 21:26:56.193446: step 6437, loss = 0.69429 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:26:57.082380 ops/training.py:65 2019-01-16 21:26:57.082311: step 6438, loss = 0.68765 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:26:57.971900 ops/training.py:65 2019-01-16 21:26:57.971829: step 6439, loss = 0.69570 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:26:58.866356 ops/training.py:65 2019-01-16 21:26:58.866284: step 6440, loss = 0.71481 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:26:59.758910 ops/training.py:65 2019-01-16 21:26:59.758806: step 6441, loss = 0.70208 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 21:27:00.650783 ops/training.py:65 2019-01-16 21:27:00.650713: step 6442, loss = 0.66975 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:27:01.539768 ops/training.py:65 2019-01-16 21:27:01.539700: step 6443, loss = 0.68670 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:27:02.429747 ops/training.py:65 2019-01-16 21:27:02.429663: step 6444, loss = 0.71988 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:27:03.320827 ops/training.py:65 2019-01-16 21:27:03.320743: step 6445, loss = 0.71138 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:27:04.211726 ops/training.py:65 2019-01-16 21:27:04.211656: step 6446, loss = 0.70962 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:27:05.101146 ops/training.py:65 2019-01-16 21:27:05.101082: step 6447, loss = 0.71703 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:27:05.990787 ops/training.py:65 2019-01-16 21:27:05.990727: step 6448, loss = 0.70165 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:27:06.879409 ops/training.py:65 2019-01-16 21:27:06.879350: step 6449, loss = 0.68518 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:27:07.768648 ops/training.py:65 2019-01-16 21:27:07.768586: step 6450, loss = 0.69491 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:27:08.658013 ops/training.py:65 2019-01-16 21:27:08.657956: step 6451, loss = 0.69491 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:27:09.547755 ops/training.py:65 2019-01-16 21:27:09.547699: step 6452, loss = 0.69138 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:27:10.439956 ops/training.py:65 2019-01-16 21:27:10.439895: step 6453, loss = 0.68710 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:27:11.333884 ops/training.py:65 2019-01-16 21:27:11.333777: step 6454, loss = 0.68785 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:27:12.226359 ops/training.py:65 2019-01-16 21:27:12.226293: step 6455, loss = 0.70029 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:27:13.116660 ops/training.py:65 2019-01-16 21:27:13.116591: step 6456, loss = 0.69128 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:27:14.007145 ops/training.py:65 2019-01-16 21:27:14.007077: step 6457, loss = 0.69667 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:27:14.898364 ops/training.py:65 2019-01-16 21:27:14.898300: step 6458, loss = 0.71837 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:27:15.788216 ops/training.py:65 2019-01-16 21:27:15.788145: step 6459, loss = 0.70040 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:27:16.678312 ops/training.py:65 2019-01-16 21:27:16.678245: step 6460, loss = 0.67419 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:27:17.567784 ops/training.py:65 2019-01-16 21:27:17.567706: step 6461, loss = 0.69505 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:27:18.456642 ops/training.py:65 2019-01-16 21:27:18.456565: step 6462, loss = 0.68049 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:27:19.346084 ops/training.py:65 2019-01-16 21:27:19.346024: step 6463, loss = 0.67844 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:27:20.236236 ops/training.py:65 2019-01-16 21:27:20.236181: step 6464, loss = 0.68982 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:27:21.125240 ops/training.py:65 2019-01-16 21:27:21.125191: step 6465, loss = 0.68780 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:27:22.014025 ops/training.py:65 2019-01-16 21:27:22.013973: step 6466, loss = 0.67996 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:27:22.902633 ops/training.py:65 2019-01-16 21:27:22.902559: step 6467, loss = 0.69819 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:27:23.791232 ops/training.py:65 2019-01-16 21:27:23.791153: step 6468, loss = 0.70990 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:27:24.679507 ops/training.py:65 2019-01-16 21:27:24.679433: step 6469, loss = 0.69405 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:27:25.567568 ops/training.py:65 2019-01-16 21:27:25.567504: step 6470, loss = 0.67833 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:27:26.456121 ops/training.py:65 2019-01-16 21:27:26.456051: step 6471, loss = 0.68438 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:27:27.345937 ops/training.py:65 2019-01-16 21:27:27.345861: step 6472, loss = 0.69590 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:27:28.235483 ops/training.py:65 2019-01-16 21:27:28.235417: step 6473, loss = 0.67399 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:27:29.124114 ops/training.py:65 2019-01-16 21:27:29.124054: step 6474, loss = 0.68266 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:27:30.012736 ops/training.py:65 2019-01-16 21:27:30.012674: step 6475, loss = 0.71221 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:27:30.901552 ops/training.py:65 2019-01-16 21:27:30.901493: step 6476, loss = 0.69489 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:27:31.791439 ops/training.py:65 2019-01-16 21:27:31.791372: step 6477, loss = 0.68973 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:27:32.683029 ops/training.py:65 2019-01-16 21:27:32.682961: step 6478, loss = 0.69129 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:27:33.572373 ops/training.py:65 2019-01-16 21:27:33.572307: step 6479, loss = 0.67120 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:27:34.461224 ops/training.py:65 2019-01-16 21:27:34.461155: step 6480, loss = 0.70833 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:27:35.350681 ops/training.py:65 2019-01-16 21:27:35.350615: step 6481, loss = 0.67452 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:27:36.240234 ops/training.py:65 2019-01-16 21:27:36.240172: step 6482, loss = 0.67797 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:27:37.129652 ops/training.py:65 2019-01-16 21:27:37.129585: step 6483, loss = 0.69828 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:27:38.019173 ops/training.py:65 2019-01-16 21:27:38.019111: step 6484, loss = 0.67395 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:27:38.908518 ops/training.py:65 2019-01-16 21:27:38.908457: step 6485, loss = 0.68992 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:27:39.798091 ops/training.py:65 2019-01-16 21:27:39.798023: step 6486, loss = 0.70312 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:27:40.687956 ops/training.py:65 2019-01-16 21:27:40.687891: step 6487, loss = 0.68911 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:27:41.576451 ops/training.py:65 2019-01-16 21:27:41.576389: step 6488, loss = 0.67600 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:27:42.464834 ops/training.py:65 2019-01-16 21:27:42.464758: step 6489, loss = 0.73192 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:27:43.353821 ops/training.py:65 2019-01-16 21:27:43.353744: step 6490, loss = 0.69002 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:27:44.243169 ops/training.py:65 2019-01-16 21:27:44.243092: step 6491, loss = 0.72680 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:27:45.132086 ops/training.py:65 2019-01-16 21:27:45.131985: step 6492, loss = 0.70443 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:27:46.021400 ops/training.py:65 2019-01-16 21:27:46.021330: step 6493, loss = 0.72106 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:27:46.915304 ops/training.py:65 2019-01-16 21:27:46.915237: step 6494, loss = 0.69626 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:27:47.808168 ops/training.py:65 2019-01-16 21:27:47.808063: step 6495, loss = 0.66392 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:27:48.699858 ops/training.py:65 2019-01-16 21:27:48.699789: step 6496, loss = 0.69450 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:27:49.589626 ops/training.py:65 2019-01-16 21:27:49.589553: step 6497, loss = 0.66932 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 21:27:50.481178 ops/training.py:65 2019-01-16 21:27:50.481094: step 6498, loss = 0.67843 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:27:51.372483 ops/training.py:65 2019-01-16 21:27:51.372382: step 6499, loss = 0.72005 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.25
I2992 2019-01-16 21:27:52.264127 ops/training.py:65 2019-01-16 21:27:52.264023: step 6500, loss = 0.67256 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:27:53.156725 ops/training.py:65 2019-01-16 21:27:53.156626: step 6501, loss = 0.70669 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:27:54.048994 ops/training.py:65 2019-01-16 21:27:54.048892: step 6502, loss = 0.69532 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:27:54.940674 ops/training.py:65 2019-01-16 21:27:54.940608: step 6503, loss = 0.71253 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:27:55.833401 ops/training.py:65 2019-01-16 21:27:55.833333: step 6504, loss = 0.67291 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:27:56.724515 ops/training.py:65 2019-01-16 21:27:56.724416: step 6505, loss = 0.67145 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:27:57.617392 ops/training.py:65 2019-01-16 21:27:57.617283: step 6506, loss = 0.71721 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:27:58.508781 ops/training.py:65 2019-01-16 21:27:58.508711: step 6507, loss = 0.68079 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:27:59.398724 ops/training.py:65 2019-01-16 21:27:59.398660: step 6508, loss = 0.71142 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:28:00.288461 ops/training.py:65 2019-01-16 21:28:00.288399: step 6509, loss = 0.67841 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:28:01.177496 ops/training.py:65 2019-01-16 21:28:01.177438: step 6510, loss = 0.67258 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:28:02.066133 ops/training.py:65 2019-01-16 21:28:02.066069: step 6511, loss = 0.70993 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:28:02.956769 ops/training.py:65 2019-01-16 21:28:02.956711: step 6512, loss = 0.68957 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:28:03.846747 ops/training.py:65 2019-01-16 21:28:03.846679: step 6513, loss = 0.69396 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:28:04.737229 ops/training.py:65 2019-01-16 21:28:04.737173: step 6514, loss = 0.67604 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:28:05.627296 ops/training.py:65 2019-01-16 21:28:05.627229: step 6515, loss = 0.68292 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:28:06.516967 ops/training.py:65 2019-01-16 21:28:06.516906: step 6516, loss = 0.68087 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:28:07.406872 ops/training.py:65 2019-01-16 21:28:07.406808: step 6517, loss = 0.70008 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:28:08.296668 ops/training.py:65 2019-01-16 21:28:08.296606: step 6518, loss = 0.68645 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:28:09.190850 ops/training.py:65 2019-01-16 21:28:09.190772: step 6519, loss = 0.72302 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:28:10.084368 ops/training.py:65 2019-01-16 21:28:10.084260: step 6520, loss = 0.69570 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:28:10.977279 ops/training.py:65 2019-01-16 21:28:10.977172: step 6521, loss = 0.70727 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:28:11.870503 ops/training.py:65 2019-01-16 21:28:11.870395: step 6522, loss = 0.71803 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:28:12.763863 ops/training.py:65 2019-01-16 21:28:12.763765: step 6523, loss = 0.69461 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:28:13.657227 ops/training.py:65 2019-01-16 21:28:13.657132: step 6524, loss = 0.70063 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:28:14.548560 ops/training.py:65 2019-01-16 21:28:14.548462: step 6525, loss = 0.68994 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:28:15.442882 ops/training.py:65 2019-01-16 21:28:15.442814: step 6526, loss = 0.71094 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:28:16.332532 ops/training.py:65 2019-01-16 21:28:16.332466: step 6527, loss = 0.69272 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:28:17.222564 ops/training.py:65 2019-01-16 21:28:17.222500: step 6528, loss = 0.69148 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:28:18.115039 ops/training.py:65 2019-01-16 21:28:18.114975: step 6529, loss = 0.68317 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:28:19.005852 ops/training.py:65 2019-01-16 21:28:19.005756: step 6530, loss = 0.69677 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:28:19.897867 ops/training.py:65 2019-01-16 21:28:19.897761: step 6531, loss = 0.69089 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:28:20.790735 ops/training.py:65 2019-01-16 21:28:20.790630: step 6532, loss = 0.67548 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:28:21.683737 ops/training.py:65 2019-01-16 21:28:21.683644: step 6533, loss = 0.72332 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:28:22.576986 ops/training.py:65 2019-01-16 21:28:22.576890: step 6534, loss = 0.72831 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:28:23.469332 ops/training.py:65 2019-01-16 21:28:23.469265: step 6535, loss = 0.67860 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:28:24.361068 ops/training.py:65 2019-01-16 21:28:24.360966: step 6536, loss = 0.71096 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:28:25.253986 ops/training.py:65 2019-01-16 21:28:25.253881: step 6537, loss = 0.71018 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:28:26.145011 ops/training.py:65 2019-01-16 21:28:26.144950: step 6538, loss = 0.69007 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:28:27.035427 ops/training.py:65 2019-01-16 21:28:27.035352: step 6539, loss = 0.73269 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:28:27.928727 ops/training.py:65 2019-01-16 21:28:27.928617: step 6540, loss = 0.71639 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:28:28.821488 ops/training.py:65 2019-01-16 21:28:28.821420: step 6541, loss = 0.67767 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:28:29.711590 ops/training.py:65 2019-01-16 21:28:29.711529: step 6542, loss = 0.65720 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:28:30.602423 ops/training.py:65 2019-01-16 21:28:30.602349: step 6543, loss = 0.68251 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:28:31.495147 ops/training.py:65 2019-01-16 21:28:31.495044: step 6544, loss = 0.71914 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:28:32.387110 ops/training.py:65 2019-01-16 21:28:32.387006: step 6545, loss = 0.68714 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:28:33.281347 ops/training.py:65 2019-01-16 21:28:33.281249: step 6546, loss = 0.68551 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:28:34.173912 ops/training.py:65 2019-01-16 21:28:34.173847: step 6547, loss = 0.66754 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:28:35.063991 ops/training.py:65 2019-01-16 21:28:35.063928: step 6548, loss = 0.67783 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:28:35.954312 ops/training.py:65 2019-01-16 21:28:35.954251: step 6549, loss = 0.68943 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:28:36.844518 ops/training.py:65 2019-01-16 21:28:36.844455: step 6550, loss = 0.67607 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:28:37.733670 ops/training.py:65 2019-01-16 21:28:37.733615: step 6551, loss = 0.70515 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:28:38.623668 ops/training.py:65 2019-01-16 21:28:38.623612: step 6552, loss = 0.67265 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:28:39.515733 ops/training.py:65 2019-01-16 21:28:39.515657: step 6553, loss = 0.71763 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:28:40.408073 ops/training.py:65 2019-01-16 21:28:40.407973: step 6554, loss = 0.70312 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:28:41.300469 ops/training.py:65 2019-01-16 21:28:41.300397: step 6555, loss = 0.69189 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:28:42.192713 ops/training.py:65 2019-01-16 21:28:42.192610: step 6556, loss = 0.68108 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:28:43.084664 ops/training.py:65 2019-01-16 21:28:43.084594: step 6557, loss = 0.72985 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:28:43.975444 ops/training.py:65 2019-01-16 21:28:43.975376: step 6558, loss = 0.69349 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:28:44.864918 ops/training.py:65 2019-01-16 21:28:44.864860: step 6559, loss = 0.68011 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:28:45.754416 ops/training.py:65 2019-01-16 21:28:45.754360: step 6560, loss = 0.69775 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:28:46.645089 ops/training.py:65 2019-01-16 21:28:46.645022: step 6561, loss = 0.68831 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:28:47.536996 ops/training.py:65 2019-01-16 21:28:47.536892: step 6562, loss = 0.68633 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:28:48.429875 ops/training.py:65 2019-01-16 21:28:48.429770: step 6563, loss = 0.70153 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:28:49.321631 ops/training.py:65 2019-01-16 21:28:49.321572: step 6564, loss = 0.71500 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:28:50.211344 ops/training.py:65 2019-01-16 21:28:50.211283: step 6565, loss = 0.72626 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:28:51.100835 ops/training.py:65 2019-01-16 21:28:51.100775: step 6566, loss = 0.68356 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:28:51.990804 ops/training.py:65 2019-01-16 21:28:51.990739: step 6567, loss = 0.71870 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:28:52.880501 ops/training.py:65 2019-01-16 21:28:52.880441: step 6568, loss = 0.71465 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:28:53.769956 ops/training.py:65 2019-01-16 21:28:53.769890: step 6569, loss = 0.71424 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:28:54.661526 ops/training.py:65 2019-01-16 21:28:54.661466: step 6570, loss = 0.68990 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:28:55.553243 ops/training.py:65 2019-01-16 21:28:55.553155: step 6571, loss = 0.71337 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:28:56.446342 ops/training.py:65 2019-01-16 21:28:56.446241: step 6572, loss = 0.71166 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:28:57.339828 ops/training.py:65 2019-01-16 21:28:57.339727: step 6573, loss = 0.69314 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:28:58.230729 ops/training.py:65 2019-01-16 21:28:58.230626: step 6574, loss = 0.69867 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:28:59.120859 ops/training.py:65 2019-01-16 21:28:59.120759: step 6575, loss = 0.70413 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:29:00.014050 ops/training.py:65 2019-01-16 21:29:00.013947: step 6576, loss = 0.70681 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:29:00.906012 ops/training.py:65 2019-01-16 21:29:00.905952: step 6577, loss = 0.70975 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:29:01.797981 ops/training.py:65 2019-01-16 21:29:01.797892: step 6578, loss = 0.71844 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:29:02.691170 ops/training.py:65 2019-01-16 21:29:02.691063: step 6579, loss = 0.68792 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:29:03.583045 ops/training.py:65 2019-01-16 21:29:03.582981: step 6580, loss = 0.68913 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:29:04.472612 ops/training.py:65 2019-01-16 21:29:04.472552: step 6581, loss = 0.71303 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:29:05.362117 ops/training.py:65 2019-01-16 21:29:05.362062: step 6582, loss = 0.68413 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:29:06.252892 ops/training.py:65 2019-01-16 21:29:06.252826: step 6583, loss = 0.67361 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:29:07.145873 ops/training.py:65 2019-01-16 21:29:07.145765: step 6584, loss = 0.70298 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:29:08.037493 ops/training.py:65 2019-01-16 21:29:08.037433: step 6585, loss = 0.66321 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:29:08.927176 ops/training.py:65 2019-01-16 21:29:08.927115: step 6586, loss = 0.71017 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:29:09.817495 ops/training.py:65 2019-01-16 21:29:09.817432: step 6587, loss = 0.67454 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:29:10.706562 ops/training.py:65 2019-01-16 21:29:10.706506: step 6588, loss = 0.73161 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:29:11.596314 ops/training.py:65 2019-01-16 21:29:11.596253: step 6589, loss = 0.69674 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:29:12.485989 ops/training.py:65 2019-01-16 21:29:12.485932: step 6590, loss = 0.71019 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:29:13.375804 ops/training.py:65 2019-01-16 21:29:13.375738: step 6591, loss = 0.69120 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:29:14.268583 ops/training.py:65 2019-01-16 21:29:14.268506: step 6592, loss = 0.68524 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:29:15.161594 ops/training.py:65 2019-01-16 21:29:15.161489: step 6593, loss = 0.67243 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:29:16.054983 ops/training.py:65 2019-01-16 21:29:16.054882: step 6594, loss = 0.70716 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:29:16.948162 ops/training.py:65 2019-01-16 21:29:16.948055: step 6595, loss = 0.71380 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:29:17.839749 ops/training.py:65 2019-01-16 21:29:17.839684: step 6596, loss = 0.70864 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:29:18.729419 ops/training.py:65 2019-01-16 21:29:18.729356: step 6597, loss = 0.67837 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:29:19.619507 ops/training.py:65 2019-01-16 21:29:19.619442: step 6598, loss = 0.69320 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:29:20.509847 ops/training.py:65 2019-01-16 21:29:20.509774: step 6599, loss = 0.73283 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 21:29:21.400536 ops/training.py:65 2019-01-16 21:29:21.400469: step 6600, loss = 0.67614 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:29:22.290271 ops/training.py:65 2019-01-16 21:29:22.290209: step 6601, loss = 0.71012 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:29:23.179460 ops/training.py:65 2019-01-16 21:29:23.179389: step 6602, loss = 0.73050 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:29:24.071422 ops/training.py:65 2019-01-16 21:29:24.071345: step 6603, loss = 0.66764 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:29:24.963203 ops/training.py:65 2019-01-16 21:29:24.963121: step 6604, loss = 0.66436 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:29:25.856253 ops/training.py:65 2019-01-16 21:29:25.856151: step 6605, loss = 0.69079 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:29:26.748821 ops/training.py:65 2019-01-16 21:29:26.748765: step 6606, loss = 0.72107 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:29:27.639027 ops/training.py:65 2019-01-16 21:29:27.638967: step 6607, loss = 0.68290 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:29:28.528414 ops/training.py:65 2019-01-16 21:29:28.528354: step 6608, loss = 0.70618 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:29:29.417023 ops/training.py:65 2019-01-16 21:29:29.416969: step 6609, loss = 0.73894 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:29:30.308901 ops/training.py:65 2019-01-16 21:29:30.308831: step 6610, loss = 0.68291 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:29:31.201037 ops/training.py:65 2019-01-16 21:29:31.200947: step 6611, loss = 0.69986 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:29:32.092749 ops/training.py:65 2019-01-16 21:29:32.092649: step 6612, loss = 0.68846 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:29:32.983466 ops/training.py:65 2019-01-16 21:29:32.983411: step 6613, loss = 0.72121 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:29:33.872427 ops/training.py:65 2019-01-16 21:29:33.872371: step 6614, loss = 0.70142 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:29:34.763731 ops/training.py:65 2019-01-16 21:29:34.763655: step 6615, loss = 0.69541 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:29:35.657244 ops/training.py:65 2019-01-16 21:29:35.657142: step 6616, loss = 0.66831 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:29:36.549348 ops/training.py:65 2019-01-16 21:29:36.549287: step 6617, loss = 0.72166 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:29:37.438466 ops/training.py:65 2019-01-16 21:29:37.438404: step 6618, loss = 0.72138 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:29:38.328188 ops/training.py:65 2019-01-16 21:29:38.328127: step 6619, loss = 0.68491 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:29:39.218469 ops/training.py:65 2019-01-16 21:29:39.218399: step 6620, loss = 0.66797 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:29:40.115640 ops/training.py:65 2019-01-16 21:29:40.115543: step 6621, loss = 0.71031 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:29:41.007081 ops/training.py:65 2019-01-16 21:29:41.007019: step 6622, loss = 0.63962 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:29:41.896804 ops/training.py:65 2019-01-16 21:29:41.896746: step 6623, loss = 0.72388 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:29:42.785278 ops/training.py:65 2019-01-16 21:29:42.785227: step 6624, loss = 0.68697 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:29:43.674048 ops/training.py:65 2019-01-16 21:29:43.673989: step 6625, loss = 0.65209 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:29:44.563246 ops/training.py:65 2019-01-16 21:29:44.563197: step 6626, loss = 0.70413 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:29:45.452322 ops/training.py:65 2019-01-16 21:29:45.452270: step 6627, loss = 0.69235 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:29:46.342516 ops/training.py:65 2019-01-16 21:29:46.342468: step 6628, loss = 0.67005 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:29:47.232365 ops/training.py:65 2019-01-16 21:29:47.232312: step 6629, loss = 0.71497 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:29:48.121474 ops/training.py:65 2019-01-16 21:29:48.121420: step 6630, loss = 0.70054 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:29:49.010901 ops/training.py:65 2019-01-16 21:29:49.010843: step 6631, loss = 0.68155 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:29:49.900227 ops/training.py:65 2019-01-16 21:29:49.900160: step 6632, loss = 0.66863 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:29:50.790352 ops/training.py:65 2019-01-16 21:29:50.790297: step 6633, loss = 0.68337 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:29:51.678939 ops/training.py:65 2019-01-16 21:29:51.678883: step 6634, loss = 0.69207 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:29:52.567206 ops/training.py:65 2019-01-16 21:29:52.567150: step 6635, loss = 0.71752 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:29:53.457428 ops/training.py:65 2019-01-16 21:29:53.457369: step 6636, loss = 0.69568 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:29:54.347856 ops/training.py:65 2019-01-16 21:29:54.347791: step 6637, loss = 0.71897 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:29:55.239534 ops/training.py:65 2019-01-16 21:29:55.239437: step 6638, loss = 0.71538 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:29:56.131179 ops/training.py:65 2019-01-16 21:29:56.131069: step 6639, loss = 0.68354 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:29:57.023408 ops/training.py:65 2019-01-16 21:29:57.023312: step 6640, loss = 0.70005 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:29:57.916375 ops/training.py:65 2019-01-16 21:29:57.916277: step 6641, loss = 0.71826 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:29:58.807719 ops/training.py:65 2019-01-16 21:29:58.807645: step 6642, loss = 0.70113 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:29:59.696735 ops/training.py:65 2019-01-16 21:29:59.696664: step 6643, loss = 0.70219 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:30:00.586038 ops/training.py:65 2019-01-16 21:30:00.585964: step 6644, loss = 0.68148 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:30:01.475233 ops/training.py:65 2019-01-16 21:30:01.475170: step 6645, loss = 0.67217 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:30:02.365157 ops/training.py:65 2019-01-16 21:30:02.365086: step 6646, loss = 0.69318 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:30:03.255001 ops/training.py:65 2019-01-16 21:30:03.254929: step 6647, loss = 0.69719 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:30:04.143957 ops/training.py:65 2019-01-16 21:30:04.143889: step 6648, loss = 0.66723 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:30:05.033101 ops/training.py:65 2019-01-16 21:30:05.033033: step 6649, loss = 0.72401 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:30:05.923124 ops/training.py:65 2019-01-16 21:30:05.923059: step 6650, loss = 0.66730 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 21:30:06.812573 ops/training.py:65 2019-01-16 21:30:06.812515: step 6651, loss = 0.72551 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:30:07.701072 ops/training.py:65 2019-01-16 21:30:07.701009: step 6652, loss = 0.72418 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:30:08.590496 ops/training.py:65 2019-01-16 21:30:08.590431: step 6653, loss = 0.69721 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:30:09.479946 ops/training.py:65 2019-01-16 21:30:09.479880: step 6654, loss = 0.69562 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:30:10.370447 ops/training.py:65 2019-01-16 21:30:10.370369: step 6655, loss = 0.72284 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:30:11.260831 ops/training.py:65 2019-01-16 21:30:11.260727: step 6656, loss = 0.65964 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:30:12.154196 ops/training.py:65 2019-01-16 21:30:12.154088: step 6657, loss = 0.69636 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:30:13.045932 ops/training.py:65 2019-01-16 21:30:13.045853: step 6658, loss = 0.71635 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:30:13.936361 ops/training.py:65 2019-01-16 21:30:13.936297: step 6659, loss = 0.70235 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:30:14.825760 ops/training.py:65 2019-01-16 21:30:14.825693: step 6660, loss = 0.71811 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:30:15.715585 ops/training.py:65 2019-01-16 21:30:15.715522: step 6661, loss = 0.70438 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:30:16.604272 ops/training.py:65 2019-01-16 21:30:16.604218: step 6662, loss = 0.69396 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:30:17.493654 ops/training.py:65 2019-01-16 21:30:17.493593: step 6663, loss = 0.74349 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 21:30:18.382685 ops/training.py:65 2019-01-16 21:30:18.382619: step 6664, loss = 0.68531 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:30:19.272411 ops/training.py:65 2019-01-16 21:30:19.272347: step 6665, loss = 0.71097 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:30:20.162004 ops/training.py:65 2019-01-16 21:30:20.161939: step 6666, loss = 0.69445 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:30:21.051082 ops/training.py:65 2019-01-16 21:30:21.051021: step 6667, loss = 0.66860 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:30:21.941093 ops/training.py:65 2019-01-16 21:30:21.941033: step 6668, loss = 0.73714 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:30:22.829635 ops/training.py:65 2019-01-16 21:30:22.829574: step 6669, loss = 0.70707 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:30:23.719404 ops/training.py:65 2019-01-16 21:30:23.719334: step 6670, loss = 0.64112 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:30:24.608811 ops/training.py:65 2019-01-16 21:30:24.608737: step 6671, loss = 0.75895 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 21:30:25.497951 ops/training.py:65 2019-01-16 21:30:25.497869: step 6672, loss = 0.67747 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:30:26.388160 ops/training.py:65 2019-01-16 21:30:26.388079: step 6673, loss = 0.73864 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:30:27.280915 ops/training.py:65 2019-01-16 21:30:27.280832: step 6674, loss = 0.66027 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:30:28.173087 ops/training.py:65 2019-01-16 21:30:28.172977: step 6675, loss = 0.71974 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:30:29.063937 ops/training.py:65 2019-01-16 21:30:29.063869: step 6676, loss = 0.69259 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:30:29.953731 ops/training.py:65 2019-01-16 21:30:29.953662: step 6677, loss = 0.69248 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:30:30.843990 ops/training.py:65 2019-01-16 21:30:30.843927: step 6678, loss = 0.71108 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:30:31.732066 ops/training.py:65 2019-01-16 21:30:31.732001: step 6679, loss = 0.71697 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:30:32.621250 ops/training.py:65 2019-01-16 21:30:32.621181: step 6680, loss = 0.66229 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:30:33.509652 ops/training.py:65 2019-01-16 21:30:33.509584: step 6681, loss = 0.70125 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:30:34.399253 ops/training.py:65 2019-01-16 21:30:34.399182: step 6682, loss = 0.73479 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:30:35.288903 ops/training.py:65 2019-01-16 21:30:35.288829: step 6683, loss = 0.69917 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:30:36.177094 ops/training.py:65 2019-01-16 21:30:36.177021: step 6684, loss = 0.67312 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:30:37.066180 ops/training.py:65 2019-01-16 21:30:37.066096: step 6685, loss = 0.68767 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:30:37.955128 ops/training.py:65 2019-01-16 21:30:37.955051: step 6686, loss = 0.70721 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:30:38.844406 ops/training.py:65 2019-01-16 21:30:38.844336: step 6687, loss = 0.72434 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:30:39.735055 ops/training.py:65 2019-01-16 21:30:39.734984: step 6688, loss = 0.68936 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:30:40.624815 ops/training.py:65 2019-01-16 21:30:40.624748: step 6689, loss = 0.67098 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:30:41.513673 ops/training.py:65 2019-01-16 21:30:41.513605: step 6690, loss = 0.72996 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:30:42.402671 ops/training.py:65 2019-01-16 21:30:42.402594: step 6691, loss = 0.70500 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:30:43.292674 ops/training.py:65 2019-01-16 21:30:43.292593: step 6692, loss = 0.69419 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:30:44.183575 ops/training.py:65 2019-01-16 21:30:44.183495: step 6693, loss = 0.68349 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:30:45.075297 ops/training.py:65 2019-01-16 21:30:45.075218: step 6694, loss = 0.68754 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:30:45.967877 ops/training.py:65 2019-01-16 21:30:45.967779: step 6695, loss = 0.68109 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:30:46.859537 ops/training.py:65 2019-01-16 21:30:46.859438: step 6696, loss = 0.71897 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:30:47.749723 ops/training.py:65 2019-01-16 21:30:47.749645: step 6697, loss = 0.68814 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:30:48.639555 ops/training.py:65 2019-01-16 21:30:48.639471: step 6698, loss = 0.68071 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:30:49.530199 ops/training.py:65 2019-01-16 21:30:49.530119: step 6699, loss = 0.71495 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:30:50.422874 ops/training.py:65 2019-01-16 21:30:50.422765: step 6700, loss = 0.75005 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.21875
I2992 2019-01-16 21:30:51.315371 ops/training.py:65 2019-01-16 21:30:51.315281: step 6701, loss = 0.72328 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:30:52.204581 ops/training.py:65 2019-01-16 21:30:52.204525: step 6702, loss = 0.69015 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:30:53.093318 ops/training.py:65 2019-01-16 21:30:53.093259: step 6703, loss = 0.67635 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:30:53.983589 ops/training.py:65 2019-01-16 21:30:53.983524: step 6704, loss = 0.64381 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:30:54.875409 ops/training.py:65 2019-01-16 21:30:54.875307: step 6705, loss = 0.67728 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:30:55.766533 ops/training.py:65 2019-01-16 21:30:55.766474: step 6706, loss = 0.69292 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:30:56.656178 ops/training.py:65 2019-01-16 21:30:56.656114: step 6707, loss = 0.69226 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:30:57.546032 ops/training.py:65 2019-01-16 21:30:57.545964: step 6708, loss = 0.70063 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:30:58.436269 ops/training.py:65 2019-01-16 21:30:58.436201: step 6709, loss = 0.69570 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:30:59.324586 ops/training.py:65 2019-01-16 21:30:59.324520: step 6710, loss = 0.68381 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:31:00.213992 ops/training.py:65 2019-01-16 21:31:00.213928: step 6711, loss = 0.69857 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:31:01.103212 ops/training.py:65 2019-01-16 21:31:01.103147: step 6712, loss = 0.69836 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:31:01.992863 ops/training.py:65 2019-01-16 21:31:01.992797: step 6713, loss = 0.70774 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:31:02.882158 ops/training.py:65 2019-01-16 21:31:02.882090: step 6714, loss = 0.67708 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:31:03.771766 ops/training.py:65 2019-01-16 21:31:03.771695: step 6715, loss = 0.70572 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:31:04.663626 ops/training.py:65 2019-01-16 21:31:04.663556: step 6716, loss = 0.70812 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:31:05.553291 ops/training.py:65 2019-01-16 21:31:05.553225: step 6717, loss = 0.66890 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:31:06.443011 ops/training.py:65 2019-01-16 21:31:06.442945: step 6718, loss = 0.67752 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:31:07.331575 ops/training.py:65 2019-01-16 21:31:07.331515: step 6719, loss = 0.68649 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:31:08.220513 ops/training.py:65 2019-01-16 21:31:08.220454: step 6720, loss = 0.70528 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:31:09.110764 ops/training.py:65 2019-01-16 21:31:09.110707: step 6721, loss = 0.69347 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:31:10.001068 ops/training.py:65 2019-01-16 21:31:10.001006: step 6722, loss = 0.70048 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:31:10.890449 ops/training.py:65 2019-01-16 21:31:10.890387: step 6723, loss = 0.69833 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:31:11.779961 ops/training.py:65 2019-01-16 21:31:11.779890: step 6724, loss = 0.72871 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:31:12.669566 ops/training.py:65 2019-01-16 21:31:12.669498: step 6725, loss = 0.64770 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:31:13.557813 ops/training.py:65 2019-01-16 21:31:13.557740: step 6726, loss = 0.69242 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:31:14.452023 ops/training.py:65 2019-01-16 21:31:14.451946: step 6727, loss = 0.72390 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:31:15.345173 ops/training.py:65 2019-01-16 21:31:15.345083: step 6728, loss = 0.65284 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:31:16.237773 ops/training.py:65 2019-01-16 21:31:16.237669: step 6729, loss = 0.65857 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:31:17.128589 ops/training.py:65 2019-01-16 21:31:17.128488: step 6730, loss = 0.72003 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:31:18.019136 ops/training.py:65 2019-01-16 21:31:18.019063: step 6731, loss = 0.70091 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:31:18.908473 ops/training.py:65 2019-01-16 21:31:18.908402: step 6732, loss = 0.74493 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:31:19.797207 ops/training.py:65 2019-01-16 21:31:19.797138: step 6733, loss = 0.69454 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:31:20.691978 ops/training.py:65 2019-01-16 21:31:20.691909: step 6734, loss = 0.73885 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:31:21.584012 ops/training.py:65 2019-01-16 21:31:21.583912: step 6735, loss = 0.69650 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:31:22.475650 ops/training.py:65 2019-01-16 21:31:22.475581: step 6736, loss = 0.70638 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:31:23.365501 ops/training.py:65 2019-01-16 21:31:23.365428: step 6737, loss = 0.65169 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:31:24.255701 ops/training.py:65 2019-01-16 21:31:24.255613: step 6738, loss = 0.73136 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:31:25.145547 ops/training.py:65 2019-01-16 21:31:25.145460: step 6739, loss = 0.69176 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:31:26.033814 ops/training.py:65 2019-01-16 21:31:26.033739: step 6740, loss = 0.69536 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:31:26.922560 ops/training.py:65 2019-01-16 21:31:26.922496: step 6741, loss = 0.72424 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:31:27.811251 ops/training.py:65 2019-01-16 21:31:27.811187: step 6742, loss = 0.65124 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:31:28.700325 ops/training.py:65 2019-01-16 21:31:28.700261: step 6743, loss = 0.62410 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.75
I2992 2019-01-16 21:31:29.589011 ops/training.py:65 2019-01-16 21:31:29.588946: step 6744, loss = 0.75230 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:31:30.478810 ops/training.py:65 2019-01-16 21:31:30.478743: step 6745, loss = 0.67634 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:31:31.368744 ops/training.py:65 2019-01-16 21:31:31.368676: step 6746, loss = 0.75069 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:31:32.257840 ops/training.py:65 2019-01-16 21:31:32.257770: step 6747, loss = 0.68877 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:31:33.148641 ops/training.py:65 2019-01-16 21:31:33.148570: step 6748, loss = 0.72435 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:31:34.040609 ops/training.py:65 2019-01-16 21:31:34.040507: step 6749, loss = 0.72341 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:31:34.931795 ops/training.py:65 2019-01-16 21:31:34.931727: step 6750, loss = 0.73510 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:31:35.820153 ops/training.py:65 2019-01-16 21:31:35.820088: step 6751, loss = 0.70866 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:31:36.709309 ops/training.py:65 2019-01-16 21:31:36.709243: step 6752, loss = 0.72578 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:31:37.598027 ops/training.py:65 2019-01-16 21:31:37.597959: step 6753, loss = 0.70429 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:31:38.487848 ops/training.py:65 2019-01-16 21:31:38.487781: step 6754, loss = 0.68920 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:31:39.376360 ops/training.py:65 2019-01-16 21:31:39.376297: step 6755, loss = 0.67831 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:31:40.264683 ops/training.py:65 2019-01-16 21:31:40.264616: step 6756, loss = 0.66249 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:31:41.153873 ops/training.py:65 2019-01-16 21:31:41.153799: step 6757, loss = 0.67931 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:31:42.043165 ops/training.py:65 2019-01-16 21:31:42.043087: step 6758, loss = 0.73926 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:31:42.932554 ops/training.py:65 2019-01-16 21:31:42.932489: step 6759, loss = 0.70582 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:31:43.821236 ops/training.py:65 2019-01-16 21:31:43.821172: step 6760, loss = 0.66383 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:31:44.709855 ops/training.py:65 2019-01-16 21:31:44.709792: step 6761, loss = 0.69347 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:31:45.601249 ops/training.py:65 2019-01-16 21:31:45.601184: step 6762, loss = 0.67733 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:31:46.493670 ops/training.py:65 2019-01-16 21:31:46.493566: step 6763, loss = 0.70505 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:31:47.386852 ops/training.py:65 2019-01-16 21:31:47.386791: step 6764, loss = 0.70431 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:31:48.276350 ops/training.py:65 2019-01-16 21:31:48.276288: step 6765, loss = 0.70786 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:31:49.165727 ops/training.py:65 2019-01-16 21:31:49.165666: step 6766, loss = 0.74726 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:31:50.053501 ops/training.py:65 2019-01-16 21:31:50.053440: step 6767, loss = 0.70689 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:31:50.943564 ops/training.py:65 2019-01-16 21:31:50.943504: step 6768, loss = 0.73991 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:31:51.834470 ops/training.py:65 2019-01-16 21:31:51.834401: step 6769, loss = 0.68965 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:31:52.725394 ops/training.py:65 2019-01-16 21:31:52.725307: step 6770, loss = 0.72538 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:31:53.617257 ops/training.py:65 2019-01-16 21:31:53.617157: step 6771, loss = 0.74362 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:31:54.508628 ops/training.py:65 2019-01-16 21:31:54.508567: step 6772, loss = 0.69826 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:31:55.398164 ops/training.py:65 2019-01-16 21:31:55.398099: step 6773, loss = 0.68982 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:31:56.287347 ops/training.py:65 2019-01-16 21:31:56.287279: step 6774, loss = 0.70695 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:31:57.176584 ops/training.py:65 2019-01-16 21:31:57.176518: step 6775, loss = 0.66666 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:31:58.064670 ops/training.py:65 2019-01-16 21:31:58.064599: step 6776, loss = 0.73901 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:31:58.954455 ops/training.py:65 2019-01-16 21:31:58.954370: step 6777, loss = 0.67055 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:31:59.844407 ops/training.py:65 2019-01-16 21:31:59.844328: step 6778, loss = 0.69358 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:32:00.733509 ops/training.py:65 2019-01-16 21:32:00.733426: step 6779, loss = 0.69541 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:32:01.623249 ops/training.py:65 2019-01-16 21:32:01.623175: step 6780, loss = 0.72603 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:32:02.512738 ops/training.py:65 2019-01-16 21:32:02.512673: step 6781, loss = 0.74098 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:32:03.401462 ops/training.py:65 2019-01-16 21:32:03.401389: step 6782, loss = 0.67609 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:32:04.290817 ops/training.py:65 2019-01-16 21:32:04.290737: step 6783, loss = 0.70100 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:32:05.180489 ops/training.py:65 2019-01-16 21:32:05.180419: step 6784, loss = 0.67915 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:32:06.070105 ops/training.py:65 2019-01-16 21:32:06.070043: step 6785, loss = 0.68240 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:32:06.958972 ops/training.py:65 2019-01-16 21:32:06.958913: step 6786, loss = 0.74009 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:32:07.847936 ops/training.py:65 2019-01-16 21:32:07.847875: step 6787, loss = 0.69893 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:32:08.736844 ops/training.py:65 2019-01-16 21:32:08.736777: step 6788, loss = 0.68370 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:32:09.625760 ops/training.py:65 2019-01-16 21:32:09.625694: step 6789, loss = 0.70508 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:32:10.515897 ops/training.py:65 2019-01-16 21:32:10.515825: step 6790, loss = 0.70628 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:32:11.405759 ops/training.py:65 2019-01-16 21:32:11.405664: step 6791, loss = 0.73762 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:32:12.294596 ops/training.py:65 2019-01-16 21:32:12.294523: step 6792, loss = 0.71151 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:32:13.184593 ops/training.py:65 2019-01-16 21:32:13.184509: step 6793, loss = 0.69897 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:32:14.074387 ops/training.py:65 2019-01-16 21:32:14.074307: step 6794, loss = 0.74371 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:32:14.963362 ops/training.py:65 2019-01-16 21:32:14.963260: step 6795, loss = 0.69343 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:32:15.853131 ops/training.py:65 2019-01-16 21:32:15.853061: step 6796, loss = 0.69234 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:32:16.743056 ops/training.py:65 2019-01-16 21:32:16.742993: step 6797, loss = 0.69405 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:32:17.631429 ops/training.py:65 2019-01-16 21:32:17.631365: step 6798, loss = 0.69776 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:32:18.520084 ops/training.py:65 2019-01-16 21:32:18.520003: step 6799, loss = 0.69063 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:32:19.409648 ops/training.py:65 2019-01-16 21:32:19.409575: step 6800, loss = 0.71111 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:32:20.298275 ops/training.py:65 2019-01-16 21:32:20.298211: step 6801, loss = 0.70121 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:32:21.187202 ops/training.py:65 2019-01-16 21:32:21.187137: step 6802, loss = 0.72642 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:32:22.076234 ops/training.py:65 2019-01-16 21:32:22.076170: step 6803, loss = 0.69943 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:32:22.965261 ops/training.py:65 2019-01-16 21:32:22.965198: step 6804, loss = 0.70830 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:32:23.854568 ops/training.py:65 2019-01-16 21:32:23.854500: step 6805, loss = 0.68321 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:32:24.743109 ops/training.py:65 2019-01-16 21:32:24.743042: step 6806, loss = 0.68209 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:32:25.631965 ops/training.py:65 2019-01-16 21:32:25.631893: step 6807, loss = 0.70214 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:32:26.523498 ops/training.py:65 2019-01-16 21:32:26.523417: step 6808, loss = 0.66518 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:32:27.415829 ops/training.py:65 2019-01-16 21:32:27.415727: step 6809, loss = 0.67564 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:32:28.307823 ops/training.py:65 2019-01-16 21:32:28.307729: step 6810, loss = 0.67891 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:32:29.199774 ops/training.py:65 2019-01-16 21:32:29.199711: step 6811, loss = 0.70064 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:32:30.088358 ops/training.py:65 2019-01-16 21:32:30.088299: step 6812, loss = 0.70360 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:32:30.977484 ops/training.py:65 2019-01-16 21:32:30.977421: step 6813, loss = 0.68522 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:32:31.866592 ops/training.py:65 2019-01-16 21:32:31.866531: step 6814, loss = 0.70658 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:32:32.755599 ops/training.py:65 2019-01-16 21:32:32.755536: step 6815, loss = 0.73157 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:32:33.644062 ops/training.py:65 2019-01-16 21:32:33.643991: step 6816, loss = 0.73142 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:32:34.533156 ops/training.py:65 2019-01-16 21:32:34.533098: step 6817, loss = 0.67483 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:32:35.423996 ops/training.py:65 2019-01-16 21:32:35.423930: step 6818, loss = 0.71137 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:32:36.312901 ops/training.py:65 2019-01-16 21:32:36.312840: step 6819, loss = 0.72407 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:32:37.202708 ops/training.py:65 2019-01-16 21:32:37.202640: step 6820, loss = 0.67942 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:32:38.091905 ops/training.py:65 2019-01-16 21:32:38.091838: step 6821, loss = 0.67340 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:32:38.981276 ops/training.py:65 2019-01-16 21:32:38.981204: step 6822, loss = 0.70796 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:32:39.870060 ops/training.py:65 2019-01-16 21:32:39.869992: step 6823, loss = 0.71052 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:32:40.759599 ops/training.py:65 2019-01-16 21:32:40.759537: step 6824, loss = 0.68626 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:32:41.648449 ops/training.py:65 2019-01-16 21:32:41.648386: step 6825, loss = 0.67398 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:32:42.537739 ops/training.py:65 2019-01-16 21:32:42.537679: step 6826, loss = 0.68502 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:32:43.427307 ops/training.py:65 2019-01-16 21:32:43.427242: step 6827, loss = 0.73597 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:32:44.317275 ops/training.py:65 2019-01-16 21:32:44.317214: step 6828, loss = 0.70719 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:32:45.209383 ops/training.py:65 2019-01-16 21:32:45.209316: step 6829, loss = 0.70675 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:32:46.103716 ops/training.py:65 2019-01-16 21:32:46.103604: step 6830, loss = 0.73098 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:32:46.996160 ops/training.py:65 2019-01-16 21:32:46.996059: step 6831, loss = 0.66519 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:32:47.887782 ops/training.py:65 2019-01-16 21:32:47.887716: step 6832, loss = 0.67919 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:32:48.777356 ops/training.py:65 2019-01-16 21:32:48.777291: step 6833, loss = 0.74043 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:32:49.666569 ops/training.py:65 2019-01-16 21:32:49.666498: step 6834, loss = 0.69111 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:32:50.556901 ops/training.py:65 2019-01-16 21:32:50.556831: step 6835, loss = 0.69364 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:32:51.445987 ops/training.py:65 2019-01-16 21:32:51.445918: step 6836, loss = 0.69694 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:32:52.335382 ops/training.py:65 2019-01-16 21:32:52.335298: step 6837, loss = 0.68881 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:32:53.224801 ops/training.py:65 2019-01-16 21:32:53.224730: step 6838, loss = 0.71264 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:32:54.114088 ops/training.py:65 2019-01-16 21:32:54.114020: step 6839, loss = 0.70920 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:32:55.003410 ops/training.py:65 2019-01-16 21:32:55.003334: step 6840, loss = 0.68380 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:32:55.892747 ops/training.py:65 2019-01-16 21:32:55.892686: step 6841, loss = 0.70321 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:32:56.781740 ops/training.py:65 2019-01-16 21:32:56.781678: step 6842, loss = 0.69413 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:32:57.670336 ops/training.py:65 2019-01-16 21:32:57.670276: step 6843, loss = 0.68748 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:32:58.559227 ops/training.py:65 2019-01-16 21:32:58.559164: step 6844, loss = 0.70024 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:32:59.453366 ops/training.py:65 2019-01-16 21:32:59.453296: step 6845, loss = 0.70857 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:33:00.346042 ops/training.py:65 2019-01-16 21:33:00.345938: step 6846, loss = 0.70355 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:33:01.239110 ops/training.py:65 2019-01-16 21:33:01.239020: step 6847, loss = 0.69760 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:33:02.129164 ops/training.py:65 2019-01-16 21:33:02.129096: step 6848, loss = 0.67438 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.75
I2992 2019-01-16 21:33:03.018523 ops/training.py:65 2019-01-16 21:33:03.018458: step 6849, loss = 0.66341 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:33:03.908810 ops/training.py:65 2019-01-16 21:33:03.908738: step 6850, loss = 0.69857 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:33:04.799818 ops/training.py:65 2019-01-16 21:33:04.799753: step 6851, loss = 0.68517 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:33:05.690523 ops/training.py:65 2019-01-16 21:33:05.690456: step 6852, loss = 0.69353 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:33:06.580484 ops/training.py:65 2019-01-16 21:33:06.580412: step 6853, loss = 0.68467 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:33:07.473475 ops/training.py:65 2019-01-16 21:33:07.473378: step 6854, loss = 0.68816 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:33:08.365559 ops/training.py:65 2019-01-16 21:33:08.365466: step 6855, loss = 0.67458 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:33:09.255381 ops/training.py:65 2019-01-16 21:33:09.255307: step 6856, loss = 0.73558 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:33:10.144353 ops/training.py:65 2019-01-16 21:33:10.144282: step 6857, loss = 0.67542 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:33:11.033325 ops/training.py:65 2019-01-16 21:33:11.033254: step 6858, loss = 0.69010 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:33:11.923058 ops/training.py:65 2019-01-16 21:33:11.922989: step 6859, loss = 0.67592 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:33:12.812686 ops/training.py:65 2019-01-16 21:33:12.812616: step 6860, loss = 0.67058 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:33:13.702050 ops/training.py:65 2019-01-16 21:33:13.701983: step 6861, loss = 0.71889 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:33:14.593148 ops/training.py:65 2019-01-16 21:33:14.593079: step 6862, loss = 0.67405 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 21:33:15.483706 ops/training.py:65 2019-01-16 21:33:15.483639: step 6863, loss = 0.69918 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:33:16.376399 ops/training.py:65 2019-01-16 21:33:16.376298: step 6864, loss = 0.71985 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:33:17.268614 ops/training.py:65 2019-01-16 21:33:17.268518: step 6865, loss = 0.65798 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.75
I2992 2019-01-16 21:33:18.162117 ops/training.py:65 2019-01-16 21:33:18.162018: step 6866, loss = 0.71761 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:33:19.051498 ops/training.py:65 2019-01-16 21:33:19.051398: step 6867, loss = 0.70928 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:33:19.941386 ops/training.py:65 2019-01-16 21:33:19.941284: step 6868, loss = 0.67266 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:33:20.830302 ops/training.py:65 2019-01-16 21:33:20.830228: step 6869, loss = 0.66428 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:33:21.719673 ops/training.py:65 2019-01-16 21:33:21.719602: step 6870, loss = 0.70396 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:33:22.615329 ops/training.py:65 2019-01-16 21:33:22.615248: step 6871, loss = 0.69090 (35.8 examples/sec; 0.895 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:33:23.507531 ops/training.py:65 2019-01-16 21:33:23.507457: step 6872, loss = 0.66896 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 21:33:24.399211 ops/training.py:65 2019-01-16 21:33:24.399137: step 6873, loss = 0.69577 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:33:25.291053 ops/training.py:65 2019-01-16 21:33:25.290963: step 6874, loss = 0.68514 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:33:26.183760 ops/training.py:65 2019-01-16 21:33:26.183662: step 6875, loss = 0.67199 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:33:27.075732 ops/training.py:65 2019-01-16 21:33:27.075639: step 6876, loss = 0.70151 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:33:27.966921 ops/training.py:65 2019-01-16 21:33:27.966854: step 6877, loss = 0.66401 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:33:28.860364 ops/training.py:65 2019-01-16 21:33:28.860263: step 6878, loss = 0.67071 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:33:29.751773 ops/training.py:65 2019-01-16 21:33:29.751702: step 6879, loss = 0.70584 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:33:30.642680 ops/training.py:65 2019-01-16 21:33:30.642584: step 6880, loss = 0.71140 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:33:31.534185 ops/training.py:65 2019-01-16 21:33:31.534088: step 6881, loss = 0.68902 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:33:32.427335 ops/training.py:65 2019-01-16 21:33:32.427241: step 6882, loss = 0.71434 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:33:33.320282 ops/training.py:65 2019-01-16 21:33:33.320139: step 6883, loss = 0.70889 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:33:34.212345 ops/training.py:65 2019-01-16 21:33:34.212236: step 6884, loss = 0.70562 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:33:35.103353 ops/training.py:65 2019-01-16 21:33:35.103258: step 6885, loss = 0.68996 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:33:35.992986 ops/training.py:65 2019-01-16 21:33:35.992915: step 6886, loss = 0.67828 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:33:36.882816 ops/training.py:65 2019-01-16 21:33:36.882758: step 6887, loss = 0.70495 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:33:37.772408 ops/training.py:65 2019-01-16 21:33:37.772344: step 6888, loss = 0.69812 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:33:38.660842 ops/training.py:65 2019-01-16 21:33:38.660787: step 6889, loss = 0.68654 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:33:39.550283 ops/training.py:65 2019-01-16 21:33:39.550221: step 6890, loss = 0.72550 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:33:40.439603 ops/training.py:65 2019-01-16 21:33:40.439537: step 6891, loss = 0.69337 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:33:41.329348 ops/training.py:65 2019-01-16 21:33:41.329287: step 6892, loss = 0.70665 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:33:42.218543 ops/training.py:65 2019-01-16 21:33:42.218480: step 6893, loss = 0.71411 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 21:33:43.107420 ops/training.py:65 2019-01-16 21:33:43.107352: step 6894, loss = 0.69634 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:33:43.996645 ops/training.py:65 2019-01-16 21:33:43.996575: step 6895, loss = 0.71249 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:33:44.885860 ops/training.py:65 2019-01-16 21:33:44.885797: step 6896, loss = 0.68751 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:33:45.775915 ops/training.py:65 2019-01-16 21:33:45.775850: step 6897, loss = 0.71034 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:33:46.665077 ops/training.py:65 2019-01-16 21:33:46.665013: step 6898, loss = 0.69369 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:33:47.554817 ops/training.py:65 2019-01-16 21:33:47.554751: step 6899, loss = 0.67945 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:33:48.444564 ops/training.py:65 2019-01-16 21:33:48.444498: step 6900, loss = 0.68556 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:33:49.334014 ops/training.py:65 2019-01-16 21:33:49.333956: step 6901, loss = 0.71042 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:33:50.222681 ops/training.py:65 2019-01-16 21:33:50.222626: step 6902, loss = 0.70625 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:33:51.111471 ops/training.py:65 2019-01-16 21:33:51.111416: step 6903, loss = 0.68376 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:33:52.003773 ops/training.py:65 2019-01-16 21:33:52.003697: step 6904, loss = 0.70071 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:33:52.896695 ops/training.py:65 2019-01-16 21:33:52.896598: step 6905, loss = 0.68531 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:33:53.789067 ops/training.py:65 2019-01-16 21:33:53.788968: step 6906, loss = 0.68989 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:33:54.681862 ops/training.py:65 2019-01-16 21:33:54.681767: step 6907, loss = 0.69144 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:33:55.574448 ops/training.py:65 2019-01-16 21:33:55.574349: step 6908, loss = 0.66384 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:33:56.467818 ops/training.py:65 2019-01-16 21:33:56.467714: step 6909, loss = 0.68756 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:33:57.360663 ops/training.py:65 2019-01-16 21:33:57.360563: step 6910, loss = 0.68312 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:33:58.252531 ops/training.py:65 2019-01-16 21:33:58.252466: step 6911, loss = 0.69139 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:33:59.143272 ops/training.py:65 2019-01-16 21:33:59.143211: step 6912, loss = 0.69955 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:34:00.033650 ops/training.py:65 2019-01-16 21:34:00.033593: step 6913, loss = 0.68920 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:34:00.924937 ops/training.py:65 2019-01-16 21:34:00.924834: step 6914, loss = 0.67838 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:34:01.818602 ops/training.py:65 2019-01-16 21:34:01.818501: step 6915, loss = 0.69524 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:34:02.711708 ops/training.py:65 2019-01-16 21:34:02.711647: step 6916, loss = 0.74423 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:34:03.600970 ops/training.py:65 2019-01-16 21:34:03.600903: step 6917, loss = 0.67514 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:34:04.490502 ops/training.py:65 2019-01-16 21:34:04.490441: step 6918, loss = 0.65356 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:34:05.379432 ops/training.py:65 2019-01-16 21:34:05.379356: step 6919, loss = 0.70762 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:34:06.268934 ops/training.py:65 2019-01-16 21:34:06.268866: step 6920, loss = 0.73202 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:34:07.158341 ops/training.py:65 2019-01-16 21:34:07.158271: step 6921, loss = 0.70449 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:34:08.047380 ops/training.py:65 2019-01-16 21:34:08.047312: step 6922, loss = 0.74693 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:34:08.937109 ops/training.py:65 2019-01-16 21:34:08.937048: step 6923, loss = 0.74389 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:34:09.827099 ops/training.py:65 2019-01-16 21:34:09.827036: step 6924, loss = 0.74143 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:34:10.715459 ops/training.py:65 2019-01-16 21:34:10.715395: step 6925, loss = 0.69842 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:34:11.605400 ops/training.py:65 2019-01-16 21:34:11.605322: step 6926, loss = 0.71357 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:34:12.494638 ops/training.py:65 2019-01-16 21:34:12.494563: step 6927, loss = 0.72385 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:34:13.384151 ops/training.py:65 2019-01-16 21:34:13.384075: step 6928, loss = 0.75245 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:34:14.272841 ops/training.py:65 2019-01-16 21:34:14.272774: step 6929, loss = 0.66337 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:34:15.162535 ops/training.py:65 2019-01-16 21:34:15.162471: step 6930, loss = 0.72545 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:34:16.051993 ops/training.py:65 2019-01-16 21:34:16.051925: step 6931, loss = 0.67791 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:34:16.941772 ops/training.py:65 2019-01-16 21:34:16.941701: step 6932, loss = 0.74011 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:34:17.830284 ops/training.py:65 2019-01-16 21:34:17.830211: step 6933, loss = 0.68790 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:34:18.719394 ops/training.py:65 2019-01-16 21:34:18.719327: step 6934, loss = 0.71369 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:34:19.608124 ops/training.py:65 2019-01-16 21:34:19.608058: step 6935, loss = 0.70221 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:34:20.499199 ops/training.py:65 2019-01-16 21:34:20.499140: step 6936, loss = 0.66822 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:34:21.391849 ops/training.py:65 2019-01-16 21:34:21.391758: step 6937, loss = 0.73031 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:34:22.283851 ops/training.py:65 2019-01-16 21:34:22.283750: step 6938, loss = 0.68696 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:34:23.176790 ops/training.py:65 2019-01-16 21:34:23.176697: step 6939, loss = 0.69710 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:34:24.067632 ops/training.py:65 2019-01-16 21:34:24.067533: step 6940, loss = 0.68348 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:34:24.959066 ops/training.py:65 2019-01-16 21:34:24.958968: step 6941, loss = 0.69127 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:34:25.848888 ops/training.py:65 2019-01-16 21:34:25.848820: step 6942, loss = 0.71826 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:34:26.737751 ops/training.py:65 2019-01-16 21:34:26.737686: step 6943, loss = 0.65294 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:34:27.628418 ops/training.py:65 2019-01-16 21:34:27.628347: step 6944, loss = 0.67600 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:34:28.522962 ops/training.py:65 2019-01-16 21:34:28.522869: step 6945, loss = 0.68195 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:34:29.416354 ops/training.py:65 2019-01-16 21:34:29.416252: step 6946, loss = 0.67858 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:34:30.308434 ops/training.py:65 2019-01-16 21:34:30.308365: step 6947, loss = 0.75972 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:34:31.198106 ops/training.py:65 2019-01-16 21:34:31.198034: step 6948, loss = 0.73760 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:34:32.087343 ops/training.py:65 2019-01-16 21:34:32.087277: step 6949, loss = 0.66805 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:34:32.976522 ops/training.py:65 2019-01-16 21:34:32.976454: step 6950, loss = 0.65922 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:34:33.866764 ops/training.py:65 2019-01-16 21:34:33.866694: step 6951, loss = 0.70908 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:34:34.757072 ops/training.py:65 2019-01-16 21:34:34.756999: step 6952, loss = 0.69336 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:34:35.647639 ops/training.py:65 2019-01-16 21:34:35.647575: step 6953, loss = 0.69227 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:34:36.539245 ops/training.py:65 2019-01-16 21:34:36.539179: step 6954, loss = 0.69106 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:34:37.428050 ops/training.py:65 2019-01-16 21:34:37.427978: step 6955, loss = 0.69212 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:34:38.318301 ops/training.py:65 2019-01-16 21:34:38.318220: step 6956, loss = 0.69927 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:34:39.207696 ops/training.py:65 2019-01-16 21:34:39.207634: step 6957, loss = 0.67487 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:34:40.096417 ops/training.py:65 2019-01-16 21:34:40.096357: step 6958, loss = 0.68124 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:34:40.985009 ops/training.py:65 2019-01-16 21:34:40.984954: step 6959, loss = 0.66182 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:34:41.874223 ops/training.py:65 2019-01-16 21:34:41.874166: step 6960, loss = 0.72562 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:34:42.762723 ops/training.py:65 2019-01-16 21:34:42.762666: step 6961, loss = 0.70414 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:34:43.651856 ops/training.py:65 2019-01-16 21:34:43.651790: step 6962, loss = 0.68298 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:34:44.540384 ops/training.py:65 2019-01-16 21:34:44.540319: step 6963, loss = 0.68342 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:34:45.429711 ops/training.py:65 2019-01-16 21:34:45.429645: step 6964, loss = 0.67580 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:34:46.319748 ops/training.py:65 2019-01-16 21:34:46.319672: step 6965, loss = 0.68907 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:34:47.209810 ops/training.py:65 2019-01-16 21:34:47.209734: step 6966, loss = 0.67673 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:34:48.099455 ops/training.py:65 2019-01-16 21:34:48.099384: step 6967, loss = 0.75431 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:34:48.989293 ops/training.py:65 2019-01-16 21:34:48.989225: step 6968, loss = 0.66863 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:34:49.878290 ops/training.py:65 2019-01-16 21:34:49.878224: step 6969, loss = 0.72462 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:34:50.767493 ops/training.py:65 2019-01-16 21:34:50.767428: step 6970, loss = 0.74267 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:34:51.655806 ops/training.py:65 2019-01-16 21:34:51.655740: step 6971, loss = 0.66496 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:34:52.546059 ops/training.py:65 2019-01-16 21:34:52.545993: step 6972, loss = 0.71420 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:34:53.435589 ops/training.py:65 2019-01-16 21:34:53.435527: step 6973, loss = 0.73311 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:34:54.325314 ops/training.py:65 2019-01-16 21:34:54.325251: step 6974, loss = 0.74522 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:34:55.214566 ops/training.py:65 2019-01-16 21:34:55.214504: step 6975, loss = 0.66910 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:34:56.103355 ops/training.py:65 2019-01-16 21:34:56.103292: step 6976, loss = 0.64248 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:34:56.991924 ops/training.py:65 2019-01-16 21:34:56.991862: step 6977, loss = 0.68378 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:34:57.880443 ops/training.py:65 2019-01-16 21:34:57.880383: step 6978, loss = 0.81188 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:34:58.768715 ops/training.py:65 2019-01-16 21:34:58.768661: step 6979, loss = 0.71917 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:34:59.657596 ops/training.py:65 2019-01-16 21:34:59.657535: step 6980, loss = 0.78033 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:35:00.546983 ops/training.py:65 2019-01-16 21:35:00.546923: step 6981, loss = 0.73629 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:35:01.437479 ops/training.py:65 2019-01-16 21:35:01.437418: step 6982, loss = 0.72969 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:35:02.327194 ops/training.py:65 2019-01-16 21:35:02.327134: step 6983, loss = 0.65995 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:35:03.216072 ops/training.py:65 2019-01-16 21:35:03.216004: step 6984, loss = 0.71280 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:35:04.110964 ops/training.py:65 2019-01-16 21:35:04.110892: step 6985, loss = 0.72440 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:35:05.004387 ops/training.py:65 2019-01-16 21:35:05.004283: step 6986, loss = 0.65427 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:35:05.896067 ops/training.py:65 2019-01-16 21:35:05.895961: step 6987, loss = 0.71875 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:35:06.790543 ops/training.py:65 2019-01-16 21:35:06.790478: step 6988, loss = 0.74117 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:35:07.682362 ops/training.py:65 2019-01-16 21:35:07.682264: step 6989, loss = 0.77230 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:35:08.575462 ops/training.py:65 2019-01-16 21:35:08.575368: step 6990, loss = 0.67539 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:35:09.466881 ops/training.py:65 2019-01-16 21:35:09.466792: step 6991, loss = 0.75401 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:35:10.358909 ops/training.py:65 2019-01-16 21:35:10.358848: step 6992, loss = 0.63990 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:35:11.251137 ops/training.py:65 2019-01-16 21:35:11.251043: step 6993, loss = 0.83032 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:35:12.144458 ops/training.py:65 2019-01-16 21:35:12.144361: step 6994, loss = 0.78992 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:35:13.036097 ops/training.py:65 2019-01-16 21:35:13.036005: step 6995, loss = 0.86980 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:35:13.929618 ops/training.py:65 2019-01-16 21:35:13.929526: step 6996, loss = 0.69567 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:35:14.821292 ops/training.py:65 2019-01-16 21:35:14.821189: step 6997, loss = 0.77022 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:35:15.713193 ops/training.py:65 2019-01-16 21:35:15.713123: step 6998, loss = 0.70187 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:35:16.603197 ops/training.py:65 2019-01-16 21:35:16.603132: step 6999, loss = 0.88187 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 21:35:17.491952 ops/training.py:65 2019-01-16 21:35:17.491883: step 7000, loss = 0.82902 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:35:18.381547 ops/training.py:65 2019-01-16 21:35:18.381484: step 7001, loss = 0.65632 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:35:19.273114 ops/training.py:65 2019-01-16 21:35:19.273049: step 7002, loss = 0.82075 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:35:20.162458 ops/training.py:65 2019-01-16 21:35:20.162398: step 7003, loss = 0.70893 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:35:21.054063 ops/training.py:65 2019-01-16 21:35:21.053991: step 7004, loss = 0.76270 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:35:21.946741 ops/training.py:65 2019-01-16 21:35:21.946638: step 7005, loss = 0.66219 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:35:22.837864 ops/training.py:65 2019-01-16 21:35:22.837765: step 7006, loss = 0.76033 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:35:23.727607 ops/training.py:65 2019-01-16 21:35:23.727522: step 7007, loss = 0.72907 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:35:24.619731 ops/training.py:65 2019-01-16 21:35:24.619663: step 7008, loss = 0.67140 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:35:25.511893 ops/training.py:65 2019-01-16 21:35:25.511791: step 7009, loss = 0.74373 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:35:26.403756 ops/training.py:65 2019-01-16 21:35:26.403659: step 7010, loss = 0.63873 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:35:27.295238 ops/training.py:65 2019-01-16 21:35:27.295135: step 7011, loss = 0.67554 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:35:28.185287 ops/training.py:65 2019-01-16 21:35:28.185178: step 7012, loss = 0.70141 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:35:29.075424 ops/training.py:65 2019-01-16 21:35:29.075352: step 7013, loss = 0.73624 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:35:29.964576 ops/training.py:65 2019-01-16 21:35:29.964516: step 7014, loss = 0.74272 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:35:30.853443 ops/training.py:65 2019-01-16 21:35:30.853382: step 7015, loss = 0.70768 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:35:31.742518 ops/training.py:65 2019-01-16 21:35:31.742449: step 7016, loss = 0.67553 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:35:32.631427 ops/training.py:65 2019-01-16 21:35:32.631359: step 7017, loss = 0.72143 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:35:33.520215 ops/training.py:65 2019-01-16 21:35:33.520150: step 7018, loss = 0.69884 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:35:34.409351 ops/training.py:65 2019-01-16 21:35:34.409293: step 7019, loss = 0.70755 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:35:35.300977 ops/training.py:65 2019-01-16 21:35:35.300931: step 7020, loss = 0.69746 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:35:36.192437 ops/training.py:65 2019-01-16 21:35:36.192356: step 7021, loss = 0.68413 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:35:37.083999 ops/training.py:65 2019-01-16 21:35:37.083910: step 7022, loss = 0.70294 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:35:37.974312 ops/training.py:65 2019-01-16 21:35:37.974230: step 7023, loss = 0.69041 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:35:38.864002 ops/training.py:65 2019-01-16 21:35:38.863934: step 7024, loss = 0.67067 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:35:39.753070 ops/training.py:65 2019-01-16 21:35:39.753007: step 7025, loss = 0.68430 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:35:40.642961 ops/training.py:65 2019-01-16 21:35:40.642898: step 7026, loss = 0.72116 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:35:41.531787 ops/training.py:65 2019-01-16 21:35:41.531725: step 7027, loss = 0.72358 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:35:42.420811 ops/training.py:65 2019-01-16 21:35:42.420751: step 7028, loss = 0.65191 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.75
I2992 2019-01-16 21:35:43.310498 ops/training.py:65 2019-01-16 21:35:43.310429: step 7029, loss = 0.71403 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:35:44.199826 ops/training.py:65 2019-01-16 21:35:44.199758: step 7030, loss = 0.69037 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:35:45.090173 ops/training.py:65 2019-01-16 21:35:45.090113: step 7031, loss = 0.67966 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:35:45.979924 ops/training.py:65 2019-01-16 21:35:45.979860: step 7032, loss = 0.73193 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:35:46.869289 ops/training.py:65 2019-01-16 21:35:46.869226: step 7033, loss = 0.72220 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:35:47.758756 ops/training.py:65 2019-01-16 21:35:47.758696: step 7034, loss = 0.67650 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:35:48.647279 ops/training.py:65 2019-01-16 21:35:48.647214: step 7035, loss = 0.70374 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:35:49.536299 ops/training.py:65 2019-01-16 21:35:49.536235: step 7036, loss = 0.68108 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:35:50.425833 ops/training.py:65 2019-01-16 21:35:50.425767: step 7037, loss = 0.66835 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:35:51.315889 ops/training.py:65 2019-01-16 21:35:51.315822: step 7038, loss = 0.71096 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:35:52.208888 ops/training.py:65 2019-01-16 21:35:52.208783: step 7039, loss = 0.71100 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:35:53.101221 ops/training.py:65 2019-01-16 21:35:53.101127: step 7040, loss = 0.69118 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:35:53.994256 ops/training.py:65 2019-01-16 21:35:53.994151: step 7041, loss = 0.70825 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:35:54.885064 ops/training.py:65 2019-01-16 21:35:54.884963: step 7042, loss = 0.71687 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:35:55.775109 ops/training.py:65 2019-01-16 21:35:55.775049: step 7043, loss = 0.70780 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:35:56.665035 ops/training.py:65 2019-01-16 21:35:56.664972: step 7044, loss = 0.66355 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:35:57.554694 ops/training.py:65 2019-01-16 21:35:57.554632: step 7045, loss = 0.73167 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:35:58.443828 ops/training.py:65 2019-01-16 21:35:58.443769: step 7046, loss = 0.68368 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:35:59.333869 ops/training.py:65 2019-01-16 21:35:59.333808: step 7047, loss = 0.69429 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:36:00.223023 ops/training.py:65 2019-01-16 21:36:00.222957: step 7048, loss = 0.70796 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:36:01.113986 ops/training.py:65 2019-01-16 21:36:01.113921: step 7049, loss = 0.72718 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:36:02.005023 ops/training.py:65 2019-01-16 21:36:02.004962: step 7050, loss = 0.68395 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:36:02.894308 ops/training.py:65 2019-01-16 21:36:02.894245: step 7051, loss = 0.69506 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:36:03.784775 ops/training.py:65 2019-01-16 21:36:03.784709: step 7052, loss = 0.68513 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:36:04.673681 ops/training.py:65 2019-01-16 21:36:04.673621: step 7053, loss = 0.72927 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:36:05.563826 ops/training.py:65 2019-01-16 21:36:05.563764: step 7054, loss = 0.70573 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:36:06.452878 ops/training.py:65 2019-01-16 21:36:06.452814: step 7055, loss = 0.70195 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:36:07.342363 ops/training.py:65 2019-01-16 21:36:07.342302: step 7056, loss = 0.73790 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:36:08.232096 ops/training.py:65 2019-01-16 21:36:08.232040: step 7057, loss = 0.65558 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:36:09.121229 ops/training.py:65 2019-01-16 21:36:09.121166: step 7058, loss = 0.69782 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:36:10.011568 ops/training.py:65 2019-01-16 21:36:10.011509: step 7059, loss = 0.70464 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:36:10.901705 ops/training.py:65 2019-01-16 21:36:10.901640: step 7060, loss = 0.65221 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:36:11.792151 ops/training.py:65 2019-01-16 21:36:11.792086: step 7061, loss = 0.68614 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:36:12.682823 ops/training.py:65 2019-01-16 21:36:12.682753: step 7062, loss = 0.75767 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:36:13.576569 ops/training.py:65 2019-01-16 21:36:13.576467: step 7063, loss = 0.70970 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:36:14.468270 ops/training.py:65 2019-01-16 21:36:14.468170: step 7064, loss = 0.71730 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:36:15.359088 ops/training.py:65 2019-01-16 21:36:15.359026: step 7065, loss = 0.70648 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:36:16.248883 ops/training.py:65 2019-01-16 21:36:16.248823: step 7066, loss = 0.71107 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:36:17.138212 ops/training.py:65 2019-01-16 21:36:17.138152: step 7067, loss = 0.72672 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:36:18.029061 ops/training.py:65 2019-01-16 21:36:18.028984: step 7068, loss = 0.73582 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:36:18.922039 ops/training.py:65 2019-01-16 21:36:18.921937: step 7069, loss = 0.66386 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:36:19.815365 ops/training.py:65 2019-01-16 21:36:19.815267: step 7070, loss = 0.70966 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:36:20.705574 ops/training.py:65 2019-01-16 21:36:20.705513: step 7071, loss = 0.70353 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:36:21.595572 ops/training.py:65 2019-01-16 21:36:21.595510: step 7072, loss = 0.70856 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:36:22.486351 ops/training.py:65 2019-01-16 21:36:22.486292: step 7073, loss = 0.68476 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:36:23.377390 ops/training.py:65 2019-01-16 21:36:23.377318: step 7074, loss = 0.69716 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:36:24.268986 ops/training.py:65 2019-01-16 21:36:24.268880: step 7075, loss = 0.65079 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:36:25.159947 ops/training.py:65 2019-01-16 21:36:25.159849: step 7076, loss = 0.71538 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:36:26.052674 ops/training.py:65 2019-01-16 21:36:26.052571: step 7077, loss = 0.67634 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:36:26.943846 ops/training.py:65 2019-01-16 21:36:26.943751: step 7078, loss = 0.71032 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:36:27.833246 ops/training.py:65 2019-01-16 21:36:27.833180: step 7079, loss = 0.68562 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:36:28.723174 ops/training.py:65 2019-01-16 21:36:28.723106: step 7080, loss = 0.71716 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:36:29.613278 ops/training.py:65 2019-01-16 21:36:29.613207: step 7081, loss = 0.66905 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:36:30.503232 ops/training.py:65 2019-01-16 21:36:30.503164: step 7082, loss = 0.73025 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:36:31.393342 ops/training.py:65 2019-01-16 21:36:31.393257: step 7083, loss = 0.69278 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:36:32.282281 ops/training.py:65 2019-01-16 21:36:32.282217: step 7084, loss = 0.74035 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:36:33.171629 ops/training.py:65 2019-01-16 21:36:33.171567: step 7085, loss = 0.72113 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:36:34.061960 ops/training.py:65 2019-01-16 21:36:34.061865: step 7086, loss = 0.68962 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:36:34.952841 ops/training.py:65 2019-01-16 21:36:34.952769: step 7087, loss = 0.70723 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:36:35.844988 ops/training.py:65 2019-01-16 21:36:35.844883: step 7088, loss = 0.71745 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:36:36.737327 ops/training.py:65 2019-01-16 21:36:36.737235: step 7089, loss = 0.73792 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:36:37.627808 ops/training.py:65 2019-01-16 21:36:37.627738: step 7090, loss = 0.71399 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:36:38.520414 ops/training.py:65 2019-01-16 21:36:38.520312: step 7091, loss = 0.71499 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:36:39.413256 ops/training.py:65 2019-01-16 21:36:39.413136: step 7092, loss = 0.70671 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:36:40.306835 ops/training.py:65 2019-01-16 21:36:40.306719: step 7093, loss = 0.65966 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:36:41.199570 ops/training.py:65 2019-01-16 21:36:41.199460: step 7094, loss = 0.68313 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:36:42.092294 ops/training.py:65 2019-01-16 21:36:42.092185: step 7095, loss = 0.70114 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:36:42.987758 ops/training.py:65 2019-01-16 21:36:42.987643: step 7096, loss = 0.73498 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:36:43.878658 ops/training.py:65 2019-01-16 21:36:43.878575: step 7097, loss = 0.73463 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:36:44.770418 ops/training.py:65 2019-01-16 21:36:44.770313: step 7098, loss = 0.70044 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:36:45.663189 ops/training.py:65 2019-01-16 21:36:45.663090: step 7099, loss = 0.70875 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:36:46.555001 ops/training.py:65 2019-01-16 21:36:46.554940: step 7100, loss = 0.64996 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:36:47.445642 ops/training.py:65 2019-01-16 21:36:47.445581: step 7101, loss = 0.69779 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:36:48.335137 ops/training.py:65 2019-01-16 21:36:48.335073: step 7102, loss = 0.70866 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:36:49.224688 ops/training.py:65 2019-01-16 21:36:49.224630: step 7103, loss = 0.68911 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:36:50.114104 ops/training.py:65 2019-01-16 21:36:50.114044: step 7104, loss = 0.71838 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:36:51.003688 ops/training.py:65 2019-01-16 21:36:51.003626: step 7105, loss = 0.69029 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:36:51.893033 ops/training.py:65 2019-01-16 21:36:51.892962: step 7106, loss = 0.73063 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:36:52.783354 ops/training.py:65 2019-01-16 21:36:52.783295: step 7107, loss = 0.69428 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:36:53.673382 ops/training.py:65 2019-01-16 21:36:53.673313: step 7108, loss = 0.67942 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:36:54.563504 ops/training.py:65 2019-01-16 21:36:54.563398: step 7109, loss = 0.72360 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:36:55.454845 ops/training.py:65 2019-01-16 21:36:55.454737: step 7110, loss = 0.70172 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:36:56.345185 ops/training.py:65 2019-01-16 21:36:56.345123: step 7111, loss = 0.68263 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:36:57.234985 ops/training.py:65 2019-01-16 21:36:57.234892: step 7112, loss = 0.70530 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:36:58.124591 ops/training.py:65 2019-01-16 21:36:58.124525: step 7113, loss = 0.72313 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:36:59.015210 ops/training.py:65 2019-01-16 21:36:59.015102: step 7114, loss = 0.65368 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:36:59.907378 ops/training.py:65 2019-01-16 21:36:59.907272: step 7115, loss = 0.73690 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.25
I2992 2019-01-16 21:37:00.801442 ops/training.py:65 2019-01-16 21:37:00.801337: step 7116, loss = 0.70864 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:37:01.694111 ops/training.py:65 2019-01-16 21:37:01.694018: step 7117, loss = 0.70850 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:37:02.585144 ops/training.py:65 2019-01-16 21:37:02.585077: step 7118, loss = 0.71344 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:37:03.475293 ops/training.py:65 2019-01-16 21:37:03.475199: step 7119, loss = 0.69236 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:37:04.365883 ops/training.py:65 2019-01-16 21:37:04.365790: step 7120, loss = 0.68847 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:37:05.255458 ops/training.py:65 2019-01-16 21:37:05.255395: step 7121, loss = 0.68371 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:37:06.144477 ops/training.py:65 2019-01-16 21:37:06.144420: step 7122, loss = 0.70623 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:37:07.032756 ops/training.py:65 2019-01-16 21:37:07.032699: step 7123, loss = 0.69069 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:37:07.921457 ops/training.py:65 2019-01-16 21:37:07.921395: step 7124, loss = 0.70204 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:37:08.809932 ops/training.py:65 2019-01-16 21:37:08.809873: step 7125, loss = 0.71240 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:37:09.699698 ops/training.py:65 2019-01-16 21:37:09.699635: step 7126, loss = 0.69063 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:37:10.589131 ops/training.py:65 2019-01-16 21:37:10.589073: step 7127, loss = 0.68290 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:37:11.478435 ops/training.py:65 2019-01-16 21:37:11.478371: step 7128, loss = 0.69311 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:37:12.366840 ops/training.py:65 2019-01-16 21:37:12.366778: step 7129, loss = 0.71582 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:37:13.257371 ops/training.py:65 2019-01-16 21:37:13.257312: step 7130, loss = 0.69018 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:37:14.146969 ops/training.py:65 2019-01-16 21:37:14.146909: step 7131, loss = 0.65972 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 21:37:15.035950 ops/training.py:65 2019-01-16 21:37:15.035892: step 7132, loss = 0.71004 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:37:15.925368 ops/training.py:65 2019-01-16 21:37:15.925308: step 7133, loss = 0.70164 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:37:16.814016 ops/training.py:65 2019-01-16 21:37:16.813957: step 7134, loss = 0.70726 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:37:17.703843 ops/training.py:65 2019-01-16 21:37:17.703770: step 7135, loss = 0.70842 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:37:18.596001 ops/training.py:65 2019-01-16 21:37:18.595890: step 7136, loss = 0.68889 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:37:19.487996 ops/training.py:65 2019-01-16 21:37:19.487925: step 7137, loss = 0.71504 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:37:20.380208 ops/training.py:65 2019-01-16 21:37:20.380101: step 7138, loss = 0.70276 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:37:21.271864 ops/training.py:65 2019-01-16 21:37:21.271789: step 7139, loss = 0.69168 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:37:22.161677 ops/training.py:65 2019-01-16 21:37:22.161602: step 7140, loss = 0.67968 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:37:23.051232 ops/training.py:65 2019-01-16 21:37:23.051156: step 7141, loss = 0.69164 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:37:23.940052 ops/training.py:65 2019-01-16 21:37:23.939985: step 7142, loss = 0.69538 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:37:24.828905 ops/training.py:65 2019-01-16 21:37:24.828811: step 7143, loss = 0.68699 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:37:25.717996 ops/training.py:65 2019-01-16 21:37:25.717931: step 7144, loss = 0.68916 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:37:26.607836 ops/training.py:65 2019-01-16 21:37:26.607771: step 7145, loss = 0.74647 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.25
I2992 2019-01-16 21:37:27.496500 ops/training.py:65 2019-01-16 21:37:27.496435: step 7146, loss = 0.70620 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:37:28.385143 ops/training.py:65 2019-01-16 21:37:28.385082: step 7147, loss = 0.69792 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:37:29.277685 ops/training.py:65 2019-01-16 21:37:29.277605: step 7148, loss = 0.72147 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:37:30.168370 ops/training.py:65 2019-01-16 21:37:30.168266: step 7149, loss = 0.68983 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:37:31.061298 ops/training.py:65 2019-01-16 21:37:31.061195: step 7150, loss = 0.67763 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:37:31.954353 ops/training.py:65 2019-01-16 21:37:31.954259: step 7151, loss = 0.67609 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:37:32.844400 ops/training.py:65 2019-01-16 21:37:32.844338: step 7152, loss = 0.68314 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:37:33.734524 ops/training.py:65 2019-01-16 21:37:33.734458: step 7153, loss = 0.70553 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:37:34.624153 ops/training.py:65 2019-01-16 21:37:34.624094: step 7154, loss = 0.69884 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:37:35.516202 ops/training.py:65 2019-01-16 21:37:35.516140: step 7155, loss = 0.74792 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 21:37:36.409666 ops/training.py:65 2019-01-16 21:37:36.409552: step 7156, loss = 0.69150 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:37:37.302813 ops/training.py:65 2019-01-16 21:37:37.302715: step 7157, loss = 0.67390 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:37:38.193168 ops/training.py:65 2019-01-16 21:37:38.193106: step 7158, loss = 0.72737 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:37:39.082555 ops/training.py:65 2019-01-16 21:37:39.082494: step 7159, loss = 0.72104 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 21:37:39.971628 ops/training.py:65 2019-01-16 21:37:39.971567: step 7160, loss = 0.67263 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:37:40.860638 ops/training.py:65 2019-01-16 21:37:40.860579: step 7161, loss = 0.67873 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:37:41.749667 ops/training.py:65 2019-01-16 21:37:41.749605: step 7162, loss = 0.69430 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:37:42.640969 ops/training.py:65 2019-01-16 21:37:42.640902: step 7163, loss = 0.67773 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:37:43.534523 ops/training.py:65 2019-01-16 21:37:43.534423: step 7164, loss = 0.68349 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:37:44.427372 ops/training.py:65 2019-01-16 21:37:44.427270: step 7165, loss = 0.73653 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:37:45.317927 ops/training.py:65 2019-01-16 21:37:45.317867: step 7166, loss = 0.70740 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:37:46.207069 ops/training.py:65 2019-01-16 21:37:46.207008: step 7167, loss = 0.67882 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:37:47.096171 ops/training.py:65 2019-01-16 21:37:47.096110: step 7168, loss = 0.70844 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:37:47.985215 ops/training.py:65 2019-01-16 21:37:47.985155: step 7169, loss = 0.69055 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:37:48.874674 ops/training.py:65 2019-01-16 21:37:48.874607: step 7170, loss = 0.73569 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:37:49.763911 ops/training.py:65 2019-01-16 21:37:49.763851: step 7171, loss = 0.70013 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:37:50.654953 ops/training.py:65 2019-01-16 21:37:50.654884: step 7172, loss = 0.68696 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:37:51.547779 ops/training.py:65 2019-01-16 21:37:51.547672: step 7173, loss = 0.69572 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:37:52.439685 ops/training.py:65 2019-01-16 21:37:52.439596: step 7174, loss = 0.70007 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:37:53.330324 ops/training.py:65 2019-01-16 21:37:53.330253: step 7175, loss = 0.67907 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:37:54.219783 ops/training.py:65 2019-01-16 21:37:54.219719: step 7176, loss = 0.69967 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:37:55.108837 ops/training.py:65 2019-01-16 21:37:55.108774: step 7177, loss = 0.66615 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:37:55.997507 ops/training.py:65 2019-01-16 21:37:55.997450: step 7178, loss = 0.71616 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:37:56.888749 ops/training.py:65 2019-01-16 21:37:56.888657: step 7179, loss = 0.71186 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:37:57.781020 ops/training.py:65 2019-01-16 21:37:57.780916: step 7180, loss = 0.65898 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:37:58.673550 ops/training.py:65 2019-01-16 21:37:58.673487: step 7181, loss = 0.70679 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:37:59.564102 ops/training.py:65 2019-01-16 21:37:59.564040: step 7182, loss = 0.74417 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:38:00.453215 ops/training.py:65 2019-01-16 21:38:00.453156: step 7183, loss = 0.68068 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:38:01.344761 ops/training.py:65 2019-01-16 21:38:01.344685: step 7184, loss = 0.68959 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:38:02.236264 ops/training.py:65 2019-01-16 21:38:02.236159: step 7185, loss = 0.68880 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:38:03.128859 ops/training.py:65 2019-01-16 21:38:03.128797: step 7186, loss = 0.67224 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:38:04.019149 ops/training.py:65 2019-01-16 21:38:04.019083: step 7187, loss = 0.70233 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:38:04.910248 ops/training.py:65 2019-01-16 21:38:04.910176: step 7188, loss = 0.69616 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:38:05.804229 ops/training.py:65 2019-01-16 21:38:05.804123: step 7189, loss = 0.68600 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:38:06.696334 ops/training.py:65 2019-01-16 21:38:06.696228: step 7190, loss = 0.67066 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:38:07.586978 ops/training.py:65 2019-01-16 21:38:07.586917: step 7191, loss = 0.65833 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:38:08.475861 ops/training.py:65 2019-01-16 21:38:08.475801: step 7192, loss = 0.67540 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:38:09.365830 ops/training.py:65 2019-01-16 21:38:09.365775: step 7193, loss = 0.67869 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:38:10.254981 ops/training.py:65 2019-01-16 21:38:10.254915: step 7194, loss = 0.70913 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:38:11.143897 ops/training.py:65 2019-01-16 21:38:11.143835: step 7195, loss = 0.66733 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:38:12.032354 ops/training.py:65 2019-01-16 21:38:12.032293: step 7196, loss = 0.68737 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:38:12.921002 ops/training.py:65 2019-01-16 21:38:12.920940: step 7197, loss = 0.68251 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:38:13.810323 ops/training.py:65 2019-01-16 21:38:13.810254: step 7198, loss = 0.66801 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:38:14.699501 ops/training.py:65 2019-01-16 21:38:14.699441: step 7199, loss = 0.70468 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:38:15.588448 ops/training.py:65 2019-01-16 21:38:15.588384: step 7200, loss = 0.67235 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:38:16.477532 ops/training.py:65 2019-01-16 21:38:16.477473: step 7201, loss = 0.68347 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:38:17.367501 ops/training.py:65 2019-01-16 21:38:17.367425: step 7202, loss = 0.66512 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:38:18.260004 ops/training.py:65 2019-01-16 21:38:18.259901: step 7203, loss = 0.66142 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:38:19.151407 ops/training.py:65 2019-01-16 21:38:19.151345: step 7204, loss = 0.69107 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:38:20.039499 ops/training.py:65 2019-01-16 21:38:20.039443: step 7205, loss = 0.69329 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:38:20.928605 ops/training.py:65 2019-01-16 21:38:20.928546: step 7206, loss = 0.68697 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:38:21.819938 ops/training.py:65 2019-01-16 21:38:21.819875: step 7207, loss = 0.70856 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:38:22.711592 ops/training.py:65 2019-01-16 21:38:22.711492: step 7208, loss = 0.66618 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:38:23.604258 ops/training.py:65 2019-01-16 21:38:23.604163: step 7209, loss = 0.70166 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:38:24.496324 ops/training.py:65 2019-01-16 21:38:24.496219: step 7210, loss = 0.72999 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:38:25.387846 ops/training.py:65 2019-01-16 21:38:25.387780: step 7211, loss = 0.72511 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:38:26.280607 ops/training.py:65 2019-01-16 21:38:26.280496: step 7212, loss = 0.71038 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:38:27.171197 ops/training.py:65 2019-01-16 21:38:27.171111: step 7213, loss = 0.69481 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:38:28.060210 ops/training.py:65 2019-01-16 21:38:28.060145: step 7214, loss = 0.72713 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:38:28.949404 ops/training.py:65 2019-01-16 21:38:28.949339: step 7215, loss = 0.74652 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:38:29.837922 ops/training.py:65 2019-01-16 21:38:29.837861: step 7216, loss = 0.68072 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:38:30.727234 ops/training.py:65 2019-01-16 21:38:30.727167: step 7217, loss = 0.70624 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:38:31.618052 ops/training.py:65 2019-01-16 21:38:31.617984: step 7218, loss = 0.70458 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:38:32.507724 ops/training.py:65 2019-01-16 21:38:32.507660: step 7219, loss = 0.69518 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:38:33.397526 ops/training.py:65 2019-01-16 21:38:33.397451: step 7220, loss = 0.67404 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:38:34.286238 ops/training.py:65 2019-01-16 21:38:34.286172: step 7221, loss = 0.70069 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:38:35.175214 ops/training.py:65 2019-01-16 21:38:35.175151: step 7222, loss = 0.68193 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:38:36.064163 ops/training.py:65 2019-01-16 21:38:36.064104: step 7223, loss = 0.67107 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:38:36.954691 ops/training.py:65 2019-01-16 21:38:36.954623: step 7224, loss = 0.71674 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:38:37.847268 ops/training.py:65 2019-01-16 21:38:37.847161: step 7225, loss = 0.68253 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:38:38.739086 ops/training.py:65 2019-01-16 21:38:38.739027: step 7226, loss = 0.67922 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:38:39.628227 ops/training.py:65 2019-01-16 21:38:39.628160: step 7227, loss = 0.70860 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:38:40.517527 ops/training.py:65 2019-01-16 21:38:40.517468: step 7228, loss = 0.69423 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:38:41.408613 ops/training.py:65 2019-01-16 21:38:41.408544: step 7229, loss = 0.68663 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:38:42.301071 ops/training.py:65 2019-01-16 21:38:42.300959: step 7230, loss = 0.72169 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:38:43.194068 ops/training.py:65 2019-01-16 21:38:43.193976: step 7231, loss = 0.68814 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:38:44.083887 ops/training.py:65 2019-01-16 21:38:44.083822: step 7232, loss = 0.69991 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:38:44.972994 ops/training.py:65 2019-01-16 21:38:44.972931: step 7233, loss = 0.67833 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:38:45.863174 ops/training.py:65 2019-01-16 21:38:45.863107: step 7234, loss = 0.72557 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:38:46.753987 ops/training.py:65 2019-01-16 21:38:46.753921: step 7235, loss = 0.72931 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:38:47.643124 ops/training.py:65 2019-01-16 21:38:47.643057: step 7236, loss = 0.70324 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:38:48.532693 ops/training.py:65 2019-01-16 21:38:48.532632: step 7237, loss = 0.71320 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:38:49.421815 ops/training.py:65 2019-01-16 21:38:49.421751: step 7238, loss = 0.65504 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:38:50.311430 ops/training.py:65 2019-01-16 21:38:50.311368: step 7239, loss = 0.67635 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:38:51.200657 ops/training.py:65 2019-01-16 21:38:51.200592: step 7240, loss = 0.68793 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:38:52.090593 ops/training.py:65 2019-01-16 21:38:52.090511: step 7241, loss = 0.70921 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:38:52.980389 ops/training.py:65 2019-01-16 21:38:52.980319: step 7242, loss = 0.68729 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:38:53.870605 ops/training.py:65 2019-01-16 21:38:53.870529: step 7243, loss = 0.66435 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:38:54.760668 ops/training.py:65 2019-01-16 21:38:54.760602: step 7244, loss = 0.65100 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 21:38:55.650260 ops/training.py:65 2019-01-16 21:38:55.650190: step 7245, loss = 0.72974 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:38:56.540883 ops/training.py:65 2019-01-16 21:38:56.540770: step 7246, loss = 0.75714 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:38:57.431401 ops/training.py:65 2019-01-16 21:38:57.431287: step 7247, loss = 0.72261 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:38:58.322410 ops/training.py:65 2019-01-16 21:38:58.322297: step 7248, loss = 0.70615 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:38:59.213499 ops/training.py:65 2019-01-16 21:38:59.213400: step 7249, loss = 0.70958 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:39:00.103602 ops/training.py:65 2019-01-16 21:39:00.103492: step 7250, loss = 0.67775 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:39:00.993981 ops/training.py:65 2019-01-16 21:39:00.993867: step 7251, loss = 0.66585 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:39:01.884348 ops/training.py:65 2019-01-16 21:39:01.884285: step 7252, loss = 0.74354 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:39:02.773855 ops/training.py:65 2019-01-16 21:39:02.773797: step 7253, loss = 0.70617 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:39:03.663320 ops/training.py:65 2019-01-16 21:39:03.663248: step 7254, loss = 0.73132 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:39:04.553460 ops/training.py:65 2019-01-16 21:39:04.553352: step 7255, loss = 0.70594 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:39:05.443437 ops/training.py:65 2019-01-16 21:39:05.443374: step 7256, loss = 0.74338 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:39:06.333286 ops/training.py:65 2019-01-16 21:39:06.333218: step 7257, loss = 0.70401 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:39:07.222688 ops/training.py:65 2019-01-16 21:39:07.222624: step 7258, loss = 0.71262 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:39:08.111978 ops/training.py:65 2019-01-16 21:39:08.111913: step 7259, loss = 0.71324 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:39:09.001363 ops/training.py:65 2019-01-16 21:39:09.001303: step 7260, loss = 0.67834 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:39:09.890575 ops/training.py:65 2019-01-16 21:39:09.890511: step 7261, loss = 0.69388 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:39:10.782059 ops/training.py:65 2019-01-16 21:39:10.781989: step 7262, loss = 0.68599 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:39:11.675086 ops/training.py:65 2019-01-16 21:39:11.674984: step 7263, loss = 0.68430 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:39:12.567842 ops/training.py:65 2019-01-16 21:39:12.567729: step 7264, loss = 0.70440 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:39:13.461277 ops/training.py:65 2019-01-16 21:39:13.461180: step 7265, loss = 0.69874 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:39:14.352775 ops/training.py:65 2019-01-16 21:39:14.352671: step 7266, loss = 0.68931 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:39:15.244354 ops/training.py:65 2019-01-16 21:39:15.244252: step 7267, loss = 0.71705 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:39:16.137916 ops/training.py:65 2019-01-16 21:39:16.137802: step 7268, loss = 0.73555 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:39:17.029350 ops/training.py:65 2019-01-16 21:39:17.029272: step 7269, loss = 0.66545 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:39:17.919233 ops/training.py:65 2019-01-16 21:39:17.919162: step 7270, loss = 0.67579 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:39:18.810511 ops/training.py:65 2019-01-16 21:39:18.810401: step 7271, loss = 0.71442 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:39:19.703021 ops/training.py:65 2019-01-16 21:39:19.702955: step 7272, loss = 0.69710 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:39:20.595566 ops/training.py:65 2019-01-16 21:39:20.595525: step 7273, loss = 0.70083 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:39:21.487358 ops/training.py:65 2019-01-16 21:39:21.487326: step 7274, loss = 0.70775 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:39:22.379542 ops/training.py:65 2019-01-16 21:39:22.379512: step 7275, loss = 0.70652 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:39:23.272367 ops/training.py:65 2019-01-16 21:39:23.272337: step 7276, loss = 0.70026 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:39:24.165148 ops/training.py:65 2019-01-16 21:39:24.165118: step 7277, loss = 0.67680 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:39:25.056956 ops/training.py:65 2019-01-16 21:39:25.056854: step 7278, loss = 0.68667 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:39:25.947845 ops/training.py:65 2019-01-16 21:39:25.947780: step 7279, loss = 0.69136 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:39:26.839760 ops/training.py:65 2019-01-16 21:39:26.839690: step 7280, loss = 0.69739 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:39:27.731362 ops/training.py:65 2019-01-16 21:39:27.731322: step 7281, loss = 0.73021 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:39:28.624061 ops/training.py:65 2019-01-16 21:39:28.624013: step 7282, loss = 0.67063 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:39:29.514400 ops/training.py:65 2019-01-16 21:39:29.514368: step 7283, loss = 0.68475 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:39:30.405371 ops/training.py:65 2019-01-16 21:39:30.405337: step 7284, loss = 0.69107 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:39:31.297176 ops/training.py:65 2019-01-16 21:39:31.297143: step 7285, loss = 0.69965 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:39:32.188604 ops/training.py:65 2019-01-16 21:39:32.188575: step 7286, loss = 0.66839 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:39:33.080896 ops/training.py:65 2019-01-16 21:39:33.080867: step 7287, loss = 0.70745 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:39:33.973501 ops/training.py:65 2019-01-16 21:39:33.973471: step 7288, loss = 0.72322 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:39:34.866715 ops/training.py:65 2019-01-16 21:39:34.866683: step 7289, loss = 0.66916 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:39:35.758483 ops/training.py:65 2019-01-16 21:39:35.758382: step 7290, loss = 0.66595 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:39:36.650879 ops/training.py:65 2019-01-16 21:39:36.650779: step 7291, loss = 0.68311 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:39:37.543858 ops/training.py:65 2019-01-16 21:39:37.543747: step 7292, loss = 0.69487 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:39:38.434717 ops/training.py:65 2019-01-16 21:39:38.434650: step 7293, loss = 0.71949 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:39:39.324367 ops/training.py:65 2019-01-16 21:39:39.324302: step 7294, loss = 0.70920 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:39:40.215570 ops/training.py:65 2019-01-16 21:39:40.215494: step 7295, loss = 0.67999 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:39:41.107703 ops/training.py:65 2019-01-16 21:39:41.107598: step 7296, loss = 0.70496 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:39:42.001220 ops/training.py:65 2019-01-16 21:39:42.001111: step 7297, loss = 0.68942 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:39:42.895556 ops/training.py:65 2019-01-16 21:39:42.895493: step 7298, loss = 0.66838 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:39:43.785720 ops/training.py:65 2019-01-16 21:39:43.785648: step 7299, loss = 0.73890 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:39:44.676249 ops/training.py:65 2019-01-16 21:39:44.676179: step 7300, loss = 0.71790 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:39:45.566077 ops/training.py:65 2019-01-16 21:39:45.566018: step 7301, loss = 0.67166 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:39:46.456096 ops/training.py:65 2019-01-16 21:39:46.456028: step 7302, loss = 0.67752 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:39:47.348476 ops/training.py:65 2019-01-16 21:39:47.348410: step 7303, loss = 0.72460 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:39:48.240265 ops/training.py:65 2019-01-16 21:39:48.240154: step 7304, loss = 0.73217 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:39:49.133545 ops/training.py:65 2019-01-16 21:39:49.133467: step 7305, loss = 0.78139 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:39:50.024089 ops/training.py:65 2019-01-16 21:39:50.024025: step 7306, loss = 0.72703 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:39:50.914105 ops/training.py:65 2019-01-16 21:39:50.914039: step 7307, loss = 0.68653 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:39:51.805931 ops/training.py:65 2019-01-16 21:39:51.805854: step 7308, loss = 0.73391 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:39:52.699601 ops/training.py:65 2019-01-16 21:39:52.699491: step 7309, loss = 0.73776 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:39:53.592467 ops/training.py:65 2019-01-16 21:39:53.592400: step 7310, loss = 0.70855 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:39:54.481808 ops/training.py:65 2019-01-16 21:39:54.481745: step 7311, loss = 0.66922 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:39:55.371501 ops/training.py:65 2019-01-16 21:39:55.371439: step 7312, loss = 0.70014 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:39:56.261317 ops/training.py:65 2019-01-16 21:39:56.261256: step 7313, loss = 0.70620 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:39:57.152406 ops/training.py:65 2019-01-16 21:39:57.152338: step 7314, loss = 0.69254 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:39:58.044021 ops/training.py:65 2019-01-16 21:39:58.043917: step 7315, loss = 0.69738 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:39:58.937718 ops/training.py:65 2019-01-16 21:39:58.937610: step 7316, loss = 0.71375 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:39:59.830166 ops/training.py:65 2019-01-16 21:39:59.830102: step 7317, loss = 0.70634 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:40:00.720414 ops/training.py:65 2019-01-16 21:40:00.720353: step 7318, loss = 0.73903 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.21875
I2992 2019-01-16 21:40:01.612422 ops/training.py:65 2019-01-16 21:40:01.612359: step 7319, loss = 0.70978 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:40:02.504758 ops/training.py:65 2019-01-16 21:40:02.504655: step 7320, loss = 0.70551 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:40:03.398734 ops/training.py:65 2019-01-16 21:40:03.398630: step 7321, loss = 0.71650 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:40:04.292733 ops/training.py:65 2019-01-16 21:40:04.292626: step 7322, loss = 0.69773 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:40:05.184923 ops/training.py:65 2019-01-16 21:40:05.184813: step 7323, loss = 0.72165 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:40:06.077455 ops/training.py:65 2019-01-16 21:40:06.077374: step 7324, loss = 0.70274 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:40:06.970942 ops/training.py:65 2019-01-16 21:40:06.970842: step 7325, loss = 0.67594 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:40:07.865021 ops/training.py:65 2019-01-16 21:40:07.864909: step 7326, loss = 0.70681 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:40:08.757809 ops/training.py:65 2019-01-16 21:40:08.757711: step 7327, loss = 0.69888 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:40:09.648715 ops/training.py:65 2019-01-16 21:40:09.648650: step 7328, loss = 0.70616 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:40:10.541094 ops/training.py:65 2019-01-16 21:40:10.541019: step 7329, loss = 0.69826 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:40:11.433964 ops/training.py:65 2019-01-16 21:40:11.433852: step 7330, loss = 0.70428 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:40:12.327152 ops/training.py:65 2019-01-16 21:40:12.327040: step 7331, loss = 0.69373 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:40:13.219055 ops/training.py:65 2019-01-16 21:40:13.218981: step 7332, loss = 0.70450 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:40:14.108149 ops/training.py:65 2019-01-16 21:40:14.108088: step 7333, loss = 0.68455 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:40:14.997079 ops/training.py:65 2019-01-16 21:40:14.997022: step 7334, loss = 0.69296 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:40:15.888580 ops/training.py:65 2019-01-16 21:40:15.888516: step 7335, loss = 0.70140 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:40:16.777894 ops/training.py:65 2019-01-16 21:40:16.777828: step 7336, loss = 0.68772 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:40:17.666829 ops/training.py:65 2019-01-16 21:40:17.666763: step 7337, loss = 0.70526 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:40:18.555265 ops/training.py:65 2019-01-16 21:40:18.555202: step 7338, loss = 0.69802 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:40:19.444863 ops/training.py:65 2019-01-16 21:40:19.444799: step 7339, loss = 0.69115 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:40:20.334703 ops/training.py:65 2019-01-16 21:40:20.334641: step 7340, loss = 0.70794 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:40:21.223930 ops/training.py:65 2019-01-16 21:40:21.223866: step 7341, loss = 0.69493 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:40:22.113121 ops/training.py:65 2019-01-16 21:40:22.113055: step 7342, loss = 0.67634 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:40:23.003009 ops/training.py:65 2019-01-16 21:40:23.002945: step 7343, loss = 0.68735 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:40:23.892549 ops/training.py:65 2019-01-16 21:40:23.892486: step 7344, loss = 0.66766 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:40:24.782330 ops/training.py:65 2019-01-16 21:40:24.782266: step 7345, loss = 0.68970 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:40:25.671833 ops/training.py:65 2019-01-16 21:40:25.671771: step 7346, loss = 0.70720 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:40:26.561462 ops/training.py:65 2019-01-16 21:40:26.561400: step 7347, loss = 0.70013 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:40:27.450547 ops/training.py:65 2019-01-16 21:40:27.450484: step 7348, loss = 0.71101 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:40:28.339965 ops/training.py:65 2019-01-16 21:40:28.339904: step 7349, loss = 0.69698 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:40:29.229934 ops/training.py:65 2019-01-16 21:40:29.229876: step 7350, loss = 0.68501 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:40:30.119764 ops/training.py:65 2019-01-16 21:40:30.119704: step 7351, loss = 0.65699 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:40:31.009903 ops/training.py:65 2019-01-16 21:40:31.009839: step 7352, loss = 0.72077 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:40:31.899693 ops/training.py:65 2019-01-16 21:40:31.899631: step 7353, loss = 0.71489 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:40:32.788997 ops/training.py:65 2019-01-16 21:40:32.788932: step 7354, loss = 0.68738 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:40:33.678224 ops/training.py:65 2019-01-16 21:40:33.678152: step 7355, loss = 0.68535 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:40:34.568393 ops/training.py:65 2019-01-16 21:40:34.568327: step 7356, loss = 0.70648 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:40:35.457328 ops/training.py:65 2019-01-16 21:40:35.457265: step 7357, loss = 0.71630 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:40:36.346902 ops/training.py:65 2019-01-16 21:40:36.346836: step 7358, loss = 0.71079 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:40:37.237318 ops/training.py:65 2019-01-16 21:40:37.237255: step 7359, loss = 0.70192 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:40:38.126948 ops/training.py:65 2019-01-16 21:40:38.126884: step 7360, loss = 0.66937 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:40:39.016267 ops/training.py:65 2019-01-16 21:40:39.016205: step 7361, loss = 0.68991 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:40:39.907710 ops/training.py:65 2019-01-16 21:40:39.907638: step 7362, loss = 0.69254 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:40:40.801100 ops/training.py:65 2019-01-16 21:40:40.800996: step 7363, loss = 0.71678 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:40:41.692911 ops/training.py:65 2019-01-16 21:40:41.692802: step 7364, loss = 0.67283 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:40:42.584835 ops/training.py:65 2019-01-16 21:40:42.584771: step 7365, loss = 0.68563 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:40:43.475361 ops/training.py:65 2019-01-16 21:40:43.475285: step 7366, loss = 0.69057 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:40:44.365005 ops/training.py:65 2019-01-16 21:40:44.364944: step 7367, loss = 0.70267 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:40:45.254103 ops/training.py:65 2019-01-16 21:40:45.254040: step 7368, loss = 0.70682 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:40:46.142312 ops/training.py:65 2019-01-16 21:40:46.142249: step 7369, loss = 0.70874 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:40:47.033834 ops/training.py:65 2019-01-16 21:40:47.033761: step 7370, loss = 0.67804 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:40:47.926773 ops/training.py:65 2019-01-16 21:40:47.926674: step 7371, loss = 0.68170 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:40:48.819188 ops/training.py:65 2019-01-16 21:40:48.819119: step 7372, loss = 0.70889 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:40:49.710664 ops/training.py:65 2019-01-16 21:40:49.710570: step 7373, loss = 0.71618 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:40:50.603253 ops/training.py:65 2019-01-16 21:40:50.603150: step 7374, loss = 0.70906 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:40:51.494715 ops/training.py:65 2019-01-16 21:40:51.494649: step 7375, loss = 0.69546 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:40:52.384302 ops/training.py:65 2019-01-16 21:40:52.384243: step 7376, loss = 0.71134 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:40:53.277330 ops/training.py:65 2019-01-16 21:40:53.277255: step 7377, loss = 0.67915 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:40:54.170490 ops/training.py:65 2019-01-16 21:40:54.170392: step 7378, loss = 0.69414 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:40:55.061933 ops/training.py:65 2019-01-16 21:40:55.061871: step 7379, loss = 0.70122 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:40:55.951508 ops/training.py:65 2019-01-16 21:40:55.951447: step 7380, loss = 0.68203 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:40:56.841610 ops/training.py:65 2019-01-16 21:40:56.841548: step 7381, loss = 0.68696 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:40:57.732390 ops/training.py:65 2019-01-16 21:40:57.732320: step 7382, loss = 0.69877 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:40:58.625703 ops/training.py:65 2019-01-16 21:40:58.625598: step 7383, loss = 0.68737 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:40:59.517465 ops/training.py:65 2019-01-16 21:40:59.517405: step 7384, loss = 0.68084 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:41:00.409560 ops/training.py:65 2019-01-16 21:41:00.409467: step 7385, loss = 0.68946 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:41:01.303422 ops/training.py:65 2019-01-16 21:41:01.303311: step 7386, loss = 0.69099 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:41:02.196121 ops/training.py:65 2019-01-16 21:41:02.196013: step 7387, loss = 0.67038 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:41:03.087329 ops/training.py:65 2019-01-16 21:41:03.087264: step 7388, loss = 0.69326 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:41:03.977528 ops/training.py:65 2019-01-16 21:41:03.977464: step 7389, loss = 0.67446 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:41:04.866654 ops/training.py:65 2019-01-16 21:41:04.866592: step 7390, loss = 0.69836 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:41:05.756108 ops/training.py:65 2019-01-16 21:41:05.756046: step 7391, loss = 0.69865 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:41:06.648201 ops/training.py:65 2019-01-16 21:41:06.648133: step 7392, loss = 0.67666 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:41:07.540437 ops/training.py:65 2019-01-16 21:41:07.540334: step 7393, loss = 0.69845 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:41:08.434936 ops/training.py:65 2019-01-16 21:41:08.434836: step 7394, loss = 0.69636 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:41:09.328674 ops/training.py:65 2019-01-16 21:41:09.328611: step 7395, loss = 0.69016 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:41:10.219599 ops/training.py:65 2019-01-16 21:41:10.219536: step 7396, loss = 0.70687 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:41:11.108803 ops/training.py:65 2019-01-16 21:41:11.108742: step 7397, loss = 0.71713 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:41:11.997524 ops/training.py:65 2019-01-16 21:41:11.997465: step 7398, loss = 0.68654 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:41:12.886640 ops/training.py:65 2019-01-16 21:41:12.886578: step 7399, loss = 0.71450 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:41:13.776884 ops/training.py:65 2019-01-16 21:41:13.776814: step 7400, loss = 0.73611 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:41:14.666838 ops/training.py:65 2019-01-16 21:41:14.666777: step 7401, loss = 0.69581 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:41:15.555813 ops/training.py:65 2019-01-16 21:41:15.555753: step 7402, loss = 0.68142 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:41:16.444890 ops/training.py:65 2019-01-16 21:41:16.444833: step 7403, loss = 0.71813 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:41:17.336839 ops/training.py:65 2019-01-16 21:41:17.336762: step 7404, loss = 0.67385 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:41:18.227940 ops/training.py:65 2019-01-16 21:41:18.227838: step 7405, loss = 0.66256 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:41:19.118624 ops/training.py:65 2019-01-16 21:41:19.118560: step 7406, loss = 0.70924 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:41:20.007742 ops/training.py:65 2019-01-16 21:41:20.007686: step 7407, loss = 0.72996 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:41:20.898324 ops/training.py:65 2019-01-16 21:41:20.898259: step 7408, loss = 0.70633 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:41:21.787162 ops/training.py:65 2019-01-16 21:41:21.787101: step 7409, loss = 0.71321 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:41:22.675934 ops/training.py:65 2019-01-16 21:41:22.675876: step 7410, loss = 0.70923 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:41:23.565764 ops/training.py:65 2019-01-16 21:41:23.565696: step 7411, loss = 0.71275 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:41:24.455559 ops/training.py:65 2019-01-16 21:41:24.455497: step 7412, loss = 0.70036 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:41:25.344772 ops/training.py:65 2019-01-16 21:41:25.344713: step 7413, loss = 0.71034 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:41:26.234273 ops/training.py:65 2019-01-16 21:41:26.234212: step 7414, loss = 0.68802 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:41:27.122755 ops/training.py:65 2019-01-16 21:41:27.122694: step 7415, loss = 0.70300 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:41:28.012267 ops/training.py:65 2019-01-16 21:41:28.012202: step 7416, loss = 0.71600 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:41:28.900929 ops/training.py:65 2019-01-16 21:41:28.900873: step 7417, loss = 0.67507 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:41:29.791190 ops/training.py:65 2019-01-16 21:41:29.791128: step 7418, loss = 0.70195 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:41:30.680257 ops/training.py:65 2019-01-16 21:41:30.680195: step 7419, loss = 0.73285 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:41:31.569602 ops/training.py:65 2019-01-16 21:41:31.569540: step 7420, loss = 0.71114 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:41:32.458237 ops/training.py:65 2019-01-16 21:41:32.458174: step 7421, loss = 0.68224 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:41:33.350049 ops/training.py:65 2019-01-16 21:41:33.349977: step 7422, loss = 0.75630 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:41:34.243443 ops/training.py:65 2019-01-16 21:41:34.243333: step 7423, loss = 0.72768 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:41:35.134554 ops/training.py:65 2019-01-16 21:41:35.134496: step 7424, loss = 0.73031 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:41:36.023913 ops/training.py:65 2019-01-16 21:41:36.023849: step 7425, loss = 0.66278 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:41:36.914419 ops/training.py:65 2019-01-16 21:41:36.914360: step 7426, loss = 0.72201 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:41:37.803812 ops/training.py:65 2019-01-16 21:41:37.803753: step 7427, loss = 0.65100 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:41:38.694270 ops/training.py:65 2019-01-16 21:41:38.694209: step 7428, loss = 0.67137 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:41:39.584310 ops/training.py:65 2019-01-16 21:41:39.584248: step 7429, loss = 0.75085 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:41:40.474358 ops/training.py:65 2019-01-16 21:41:40.474290: step 7430, loss = 0.71148 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:41:41.365842 ops/training.py:65 2019-01-16 21:41:41.365781: step 7431, loss = 0.70530 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:41:42.254765 ops/training.py:65 2019-01-16 21:41:42.254706: step 7432, loss = 0.70720 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:41:43.143496 ops/training.py:65 2019-01-16 21:41:43.143429: step 7433, loss = 0.69186 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:41:44.032799 ops/training.py:65 2019-01-16 21:41:44.032738: step 7434, loss = 0.70003 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:41:44.921691 ops/training.py:65 2019-01-16 21:41:44.921632: step 7435, loss = 0.67539 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:41:45.810256 ops/training.py:65 2019-01-16 21:41:45.810194: step 7436, loss = 0.68868 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:41:46.700263 ops/training.py:65 2019-01-16 21:41:46.700197: step 7437, loss = 0.66274 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:41:47.589262 ops/training.py:65 2019-01-16 21:41:47.589200: step 7438, loss = 0.68578 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:41:48.480746 ops/training.py:65 2019-01-16 21:41:48.480670: step 7439, loss = 0.68083 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:41:49.373790 ops/training.py:65 2019-01-16 21:41:49.373679: step 7440, loss = 0.68508 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:41:50.265423 ops/training.py:65 2019-01-16 21:41:50.265363: step 7441, loss = 0.74012 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:41:51.155240 ops/training.py:65 2019-01-16 21:41:51.155179: step 7442, loss = 0.66425 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:41:52.048165 ops/training.py:65 2019-01-16 21:41:52.048081: step 7443, loss = 0.69742 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:41:52.940145 ops/training.py:65 2019-01-16 21:41:52.940048: step 7444, loss = 0.67705 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:41:53.832240 ops/training.py:65 2019-01-16 21:41:53.832142: step 7445, loss = 0.73670 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:41:54.724651 ops/training.py:65 2019-01-16 21:41:54.724538: step 7446, loss = 0.71476 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:41:55.616380 ops/training.py:65 2019-01-16 21:41:55.616311: step 7447, loss = 0.72318 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:41:56.506695 ops/training.py:65 2019-01-16 21:41:56.506627: step 7448, loss = 0.67278 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:41:57.398870 ops/training.py:65 2019-01-16 21:41:57.398796: step 7449, loss = 0.71941 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:41:58.293207 ops/training.py:65 2019-01-16 21:41:58.293130: step 7450, loss = 0.70656 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:41:59.187033 ops/training.py:65 2019-01-16 21:41:59.186941: step 7451, loss = 0.68408 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:42:00.080449 ops/training.py:65 2019-01-16 21:42:00.080353: step 7452, loss = 0.72652 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:42:00.972401 ops/training.py:65 2019-01-16 21:42:00.972301: step 7453, loss = 0.70047 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:42:01.864851 ops/training.py:65 2019-01-16 21:42:01.864758: step 7454, loss = 0.72787 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 21:42:02.758310 ops/training.py:65 2019-01-16 21:42:02.758194: step 7455, loss = 0.68609 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:42:03.651266 ops/training.py:65 2019-01-16 21:42:03.651170: step 7456, loss = 0.70677 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:42:04.543104 ops/training.py:65 2019-01-16 21:42:04.543042: step 7457, loss = 0.71778 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:42:05.435126 ops/training.py:65 2019-01-16 21:42:05.435014: step 7458, loss = 0.71953 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:42:06.328244 ops/training.py:65 2019-01-16 21:42:06.328135: step 7459, loss = 0.71769 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:42:07.222815 ops/training.py:65 2019-01-16 21:42:07.222702: step 7460, loss = 0.70969 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:42:08.113594 ops/training.py:65 2019-01-16 21:42:08.113531: step 7461, loss = 0.72123 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:42:09.002024 ops/training.py:65 2019-01-16 21:42:09.001958: step 7462, loss = 0.74357 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:42:09.890615 ops/training.py:65 2019-01-16 21:42:09.890556: step 7463, loss = 0.70872 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:42:10.778464 ops/training.py:65 2019-01-16 21:42:10.778401: step 7464, loss = 0.72902 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:42:11.668698 ops/training.py:65 2019-01-16 21:42:11.668630: step 7465, loss = 0.66526 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:42:12.558743 ops/training.py:65 2019-01-16 21:42:12.558679: step 7466, loss = 0.67017 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:42:13.448090 ops/training.py:65 2019-01-16 21:42:13.448019: step 7467, loss = 0.72993 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:42:14.337935 ops/training.py:65 2019-01-16 21:42:14.337867: step 7468, loss = 0.67013 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:42:15.227160 ops/training.py:65 2019-01-16 21:42:15.227095: step 7469, loss = 0.72674 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:42:16.116618 ops/training.py:65 2019-01-16 21:42:16.116557: step 7470, loss = 0.71751 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:42:17.005511 ops/training.py:65 2019-01-16 21:42:17.005451: step 7471, loss = 0.68240 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:42:17.895723 ops/training.py:65 2019-01-16 21:42:17.895658: step 7472, loss = 0.70926 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:42:18.788869 ops/training.py:65 2019-01-16 21:42:18.788836: step 7473, loss = 0.70146 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:42:19.681221 ops/training.py:65 2019-01-16 21:42:19.681182: step 7474, loss = 0.69503 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:42:20.573211 ops/training.py:65 2019-01-16 21:42:20.573130: step 7475, loss = 0.70536 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:42:21.463736 ops/training.py:65 2019-01-16 21:42:21.463674: step 7476, loss = 0.67163 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:42:22.353662 ops/training.py:65 2019-01-16 21:42:22.353595: step 7477, loss = 0.74355 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:42:23.244390 ops/training.py:65 2019-01-16 21:42:23.244325: step 7478, loss = 0.68179 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:42:24.134257 ops/training.py:65 2019-01-16 21:42:24.134193: step 7479, loss = 0.69797 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:42:25.024671 ops/training.py:65 2019-01-16 21:42:25.024608: step 7480, loss = 0.67648 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:42:25.914847 ops/training.py:65 2019-01-16 21:42:25.914784: step 7481, loss = 0.66728 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:42:26.804616 ops/training.py:65 2019-01-16 21:42:26.804554: step 7482, loss = 0.71558 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:42:27.694013 ops/training.py:65 2019-01-16 21:42:27.693951: step 7483, loss = 0.73977 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:42:28.583978 ops/training.py:65 2019-01-16 21:42:28.583912: step 7484, loss = 0.71994 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:42:29.474082 ops/training.py:65 2019-01-16 21:42:29.474017: step 7485, loss = 0.68277 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:42:30.363676 ops/training.py:65 2019-01-16 21:42:30.363616: step 7486, loss = 0.68893 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:42:31.253813 ops/training.py:65 2019-01-16 21:42:31.253748: step 7487, loss = 0.68313 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:42:32.143026 ops/training.py:65 2019-01-16 21:42:32.142960: step 7488, loss = 0.73562 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:42:33.032515 ops/training.py:65 2019-01-16 21:42:33.032453: step 7489, loss = 0.69498 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:42:33.922320 ops/training.py:65 2019-01-16 21:42:33.922253: step 7490, loss = 0.70551 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:42:34.812369 ops/training.py:65 2019-01-16 21:42:34.812306: step 7491, loss = 0.68922 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:42:35.702616 ops/training.py:65 2019-01-16 21:42:35.702556: step 7492, loss = 0.71429 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:42:36.592504 ops/training.py:65 2019-01-16 21:42:36.592443: step 7493, loss = 0.70149 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:42:37.481162 ops/training.py:65 2019-01-16 21:42:37.481097: step 7494, loss = 0.80891 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:42:38.371125 ops/training.py:65 2019-01-16 21:42:38.371066: step 7495, loss = 0.79362 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:42:39.260883 ops/training.py:65 2019-01-16 21:42:39.260819: step 7496, loss = 0.79709 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:42:40.152333 ops/training.py:65 2019-01-16 21:42:40.152293: step 7497, loss = 0.71885 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:42:41.043715 ops/training.py:65 2019-01-16 21:42:41.043648: step 7498, loss = 0.64039 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:42:41.933846 ops/training.py:65 2019-01-16 21:42:41.933782: step 7499, loss = 0.74177 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:42:42.822774 ops/training.py:65 2019-01-16 21:42:42.822712: step 7500, loss = 0.73994 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:42:43.712238 ops/training.py:65 2019-01-16 21:42:43.712169: step 7501, loss = 0.67479 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:42:44.601918 ops/training.py:65 2019-01-16 21:42:44.601856: step 7502, loss = 0.74811 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:42:45.493918 ops/training.py:65 2019-01-16 21:42:45.493832: step 7503, loss = 0.72088 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:42:46.385892 ops/training.py:65 2019-01-16 21:42:46.385784: step 7504, loss = 0.68717 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:42:47.278062 ops/training.py:65 2019-01-16 21:42:47.277952: step 7505, loss = 0.61406 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.75
I2992 2019-01-16 21:42:48.172326 ops/training.py:65 2019-01-16 21:42:48.172221: step 7506, loss = 0.71930 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:42:49.064652 ops/training.py:65 2019-01-16 21:42:49.064536: step 7507, loss = 0.68544 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:42:49.956288 ops/training.py:65 2019-01-16 21:42:49.956230: step 7508, loss = 0.67490 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:42:50.845053 ops/training.py:65 2019-01-16 21:42:50.844988: step 7509, loss = 0.70722 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:42:51.734300 ops/training.py:65 2019-01-16 21:42:51.734240: step 7510, loss = 0.72133 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:42:52.623775 ops/training.py:65 2019-01-16 21:42:52.623710: step 7511, loss = 0.68166 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:42:53.513280 ops/training.py:65 2019-01-16 21:42:53.513212: step 7512, loss = 0.72203 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:42:54.403500 ops/training.py:65 2019-01-16 21:42:54.403437: step 7513, loss = 0.71751 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:42:55.294738 ops/training.py:65 2019-01-16 21:42:55.294685: step 7514, loss = 0.69050 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:42:56.186118 ops/training.py:65 2019-01-16 21:42:56.186040: step 7515, loss = 0.67811 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:42:57.075999 ops/training.py:65 2019-01-16 21:42:57.075933: step 7516, loss = 0.69136 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:42:57.964715 ops/training.py:65 2019-01-16 21:42:57.964655: step 7517, loss = 0.66264 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:42:58.854068 ops/training.py:65 2019-01-16 21:42:58.854005: step 7518, loss = 0.69205 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:42:59.743026 ops/training.py:65 2019-01-16 21:42:59.742967: step 7519, loss = 0.69696 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:43:00.635117 ops/training.py:65 2019-01-16 21:43:00.635045: step 7520, loss = 0.70039 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:43:01.527941 ops/training.py:65 2019-01-16 21:43:01.527839: step 7521, loss = 0.75120 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:43:02.420240 ops/training.py:65 2019-01-16 21:43:02.420139: step 7522, loss = 0.70771 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:43:03.313193 ops/training.py:65 2019-01-16 21:43:03.313085: step 7523, loss = 0.70288 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:43:04.207534 ops/training.py:65 2019-01-16 21:43:04.207423: step 7524, loss = 0.68256 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:43:05.100135 ops/training.py:65 2019-01-16 21:43:05.100034: step 7525, loss = 0.74811 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:43:05.993176 ops/training.py:65 2019-01-16 21:43:05.993110: step 7526, loss = 0.68228 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:43:06.883290 ops/training.py:65 2019-01-16 21:43:06.883224: step 7527, loss = 0.69952 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:43:07.773687 ops/training.py:65 2019-01-16 21:43:07.773619: step 7528, loss = 0.65670 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:43:08.664714 ops/training.py:65 2019-01-16 21:43:08.664651: step 7529, loss = 0.72351 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:43:09.556245 ops/training.py:65 2019-01-16 21:43:09.556174: step 7530, loss = 0.66988 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:43:10.449528 ops/training.py:65 2019-01-16 21:43:10.449418: step 7531, loss = 0.70250 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:43:11.341235 ops/training.py:65 2019-01-16 21:43:11.341177: step 7532, loss = 0.70326 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:43:12.231253 ops/training.py:65 2019-01-16 21:43:12.231187: step 7533, loss = 0.72636 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:43:13.122745 ops/training.py:65 2019-01-16 21:43:13.122670: step 7534, loss = 0.70003 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:43:14.015538 ops/training.py:65 2019-01-16 21:43:14.015434: step 7535, loss = 0.72309 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:43:14.906685 ops/training.py:65 2019-01-16 21:43:14.906620: step 7536, loss = 0.73062 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:43:15.795859 ops/training.py:65 2019-01-16 21:43:15.795796: step 7537, loss = 0.68458 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:43:16.687857 ops/training.py:65 2019-01-16 21:43:16.687811: step 7538, loss = 0.67070 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:43:17.579399 ops/training.py:65 2019-01-16 21:43:17.579328: step 7539, loss = 0.70736 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:43:18.472456 ops/training.py:65 2019-01-16 21:43:18.472349: step 7540, loss = 0.70393 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:43:19.365512 ops/training.py:65 2019-01-16 21:43:19.365446: step 7541, loss = 0.68444 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:43:20.255724 ops/training.py:65 2019-01-16 21:43:20.255663: step 7542, loss = 0.68313 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:43:21.144932 ops/training.py:65 2019-01-16 21:43:21.144873: step 7543, loss = 0.69389 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:43:22.036087 ops/training.py:65 2019-01-16 21:43:22.036024: step 7544, loss = 0.68514 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:43:22.925289 ops/training.py:65 2019-01-16 21:43:22.925228: step 7545, loss = 0.69341 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:43:23.815490 ops/training.py:65 2019-01-16 21:43:23.815422: step 7546, loss = 0.69829 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:43:24.705225 ops/training.py:65 2019-01-16 21:43:24.705164: step 7547, loss = 0.67544 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:43:25.595274 ops/training.py:65 2019-01-16 21:43:25.595210: step 7548, loss = 0.67292 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:43:26.487424 ops/training.py:65 2019-01-16 21:43:26.487315: step 7549, loss = 0.71260 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:43:27.379802 ops/training.py:65 2019-01-16 21:43:27.379694: step 7550, loss = 0.69594 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:43:28.271997 ops/training.py:65 2019-01-16 21:43:28.271887: step 7551, loss = 0.69272 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:43:29.162196 ops/training.py:65 2019-01-16 21:43:29.162137: step 7552, loss = 0.67323 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:43:30.054394 ops/training.py:65 2019-01-16 21:43:30.054327: step 7553, loss = 0.70747 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:43:30.947871 ops/training.py:65 2019-01-16 21:43:30.947760: step 7554, loss = 0.70885 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:43:31.840295 ops/training.py:65 2019-01-16 21:43:31.840233: step 7555, loss = 0.71956 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:43:32.730432 ops/training.py:65 2019-01-16 21:43:32.730368: step 7556, loss = 0.72199 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:43:33.622972 ops/training.py:65 2019-01-16 21:43:33.622905: step 7557, loss = 0.69302 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:43:34.515395 ops/training.py:65 2019-01-16 21:43:34.515291: step 7558, loss = 0.67356 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:43:35.406761 ops/training.py:65 2019-01-16 21:43:35.406702: step 7559, loss = 0.69029 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:43:36.297148 ops/training.py:65 2019-01-16 21:43:36.297085: step 7560, loss = 0.69639 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:43:37.187554 ops/training.py:65 2019-01-16 21:43:37.187491: step 7561, loss = 0.70633 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:43:38.076980 ops/training.py:65 2019-01-16 21:43:38.076916: step 7562, loss = 0.71331 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:43:38.966603 ops/training.py:65 2019-01-16 21:43:38.966541: step 7563, loss = 0.68080 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:43:39.857388 ops/training.py:65 2019-01-16 21:43:39.857324: step 7564, loss = 0.70652 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:43:40.748244 ops/training.py:65 2019-01-16 21:43:40.748179: step 7565, loss = 0.70343 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:43:41.637889 ops/training.py:65 2019-01-16 21:43:41.637829: step 7566, loss = 0.69885 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:43:42.527696 ops/training.py:65 2019-01-16 21:43:42.527632: step 7567, loss = 0.69363 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:43:43.417299 ops/training.py:65 2019-01-16 21:43:43.417220: step 7568, loss = 0.70773 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:43:44.307013 ops/training.py:65 2019-01-16 21:43:44.306949: step 7569, loss = 0.69371 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:43:45.197147 ops/training.py:65 2019-01-16 21:43:45.197086: step 7570, loss = 0.70217 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:43:46.085348 ops/training.py:65 2019-01-16 21:43:46.085288: step 7571, loss = 0.70832 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:43:46.974637 ops/training.py:65 2019-01-16 21:43:46.974575: step 7572, loss = 0.71659 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:43:47.863781 ops/training.py:65 2019-01-16 21:43:47.863716: step 7573, loss = 0.71656 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:43:48.755182 ops/training.py:65 2019-01-16 21:43:48.755116: step 7574, loss = 0.68089 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:43:49.644702 ops/training.py:65 2019-01-16 21:43:49.644639: step 7575, loss = 0.72460 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:43:50.536713 ops/training.py:65 2019-01-16 21:43:50.536667: step 7576, loss = 0.68498 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:43:51.429873 ops/training.py:65 2019-01-16 21:43:51.429816: step 7577, loss = 0.66962 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:43:52.322442 ops/training.py:65 2019-01-16 21:43:52.322349: step 7578, loss = 0.68989 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:43:53.214612 ops/training.py:65 2019-01-16 21:43:53.214530: step 7579, loss = 0.68316 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:43:54.105641 ops/training.py:65 2019-01-16 21:43:54.105551: step 7580, loss = 0.69247 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:43:54.997464 ops/training.py:65 2019-01-16 21:43:54.997384: step 7581, loss = 0.68331 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:43:55.889718 ops/training.py:65 2019-01-16 21:43:55.889621: step 7582, loss = 0.69561 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:43:56.782251 ops/training.py:65 2019-01-16 21:43:56.782142: step 7583, loss = 0.69374 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:43:57.673035 ops/training.py:65 2019-01-16 21:43:57.672972: step 7584, loss = 0.70043 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:43:58.562122 ops/training.py:65 2019-01-16 21:43:58.562063: step 7585, loss = 0.68685 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:43:59.451221 ops/training.py:65 2019-01-16 21:43:59.451160: step 7586, loss = 0.69353 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:44:00.341100 ops/training.py:65 2019-01-16 21:44:00.341041: step 7587, loss = 0.69405 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:44:01.230568 ops/training.py:65 2019-01-16 21:44:01.230509: step 7588, loss = 0.68976 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:44:02.120237 ops/training.py:65 2019-01-16 21:44:02.120174: step 7589, loss = 0.67236 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:44:03.008855 ops/training.py:65 2019-01-16 21:44:03.008795: step 7590, loss = 0.70311 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:44:03.898233 ops/training.py:65 2019-01-16 21:44:03.898165: step 7591, loss = 0.68466 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:44:04.788011 ops/training.py:65 2019-01-16 21:44:04.787950: step 7592, loss = 0.72032 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:44:05.677166 ops/training.py:65 2019-01-16 21:44:05.677110: step 7593, loss = 0.68910 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:44:06.566933 ops/training.py:65 2019-01-16 21:44:06.566874: step 7594, loss = 0.71687 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:44:07.457663 ops/training.py:65 2019-01-16 21:44:07.457599: step 7595, loss = 0.66548 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:44:08.348822 ops/training.py:65 2019-01-16 21:44:08.348755: step 7596, loss = 0.71790 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:44:09.241888 ops/training.py:65 2019-01-16 21:44:09.241785: step 7597, loss = 0.74894 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:44:10.134688 ops/training.py:65 2019-01-16 21:44:10.134576: step 7598, loss = 0.71636 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:44:11.027938 ops/training.py:65 2019-01-16 21:44:11.027832: step 7599, loss = 0.71996 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:44:11.920047 ops/training.py:65 2019-01-16 21:44:11.919955: step 7600, loss = 0.68538 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:44:12.810859 ops/training.py:65 2019-01-16 21:44:12.810794: step 7601, loss = 0.69609 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:44:13.700757 ops/training.py:65 2019-01-16 21:44:13.700686: step 7602, loss = 0.70583 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:44:14.592843 ops/training.py:65 2019-01-16 21:44:14.592775: step 7603, loss = 0.77051 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:44:15.485452 ops/training.py:65 2019-01-16 21:44:15.485375: step 7604, loss = 0.71912 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:44:16.380173 ops/training.py:65 2019-01-16 21:44:16.380071: step 7605, loss = 0.70605 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:44:17.273675 ops/training.py:65 2019-01-16 21:44:17.273556: step 7606, loss = 0.73822 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:44:18.164483 ops/training.py:65 2019-01-16 21:44:18.164418: step 7607, loss = 0.68381 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:44:19.054597 ops/training.py:65 2019-01-16 21:44:19.054531: step 7608, loss = 0.71005 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:44:19.943309 ops/training.py:65 2019-01-16 21:44:19.943250: step 7609, loss = 0.72539 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:44:20.833545 ops/training.py:65 2019-01-16 21:44:20.833485: step 7610, loss = 0.75597 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:44:21.725900 ops/training.py:65 2019-01-16 21:44:21.725851: step 7611, loss = 0.72686 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:44:22.617434 ops/training.py:65 2019-01-16 21:44:22.617370: step 7612, loss = 0.74216 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:44:23.506609 ops/training.py:65 2019-01-16 21:44:23.506542: step 7613, loss = 0.71383 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:44:24.398407 ops/training.py:65 2019-01-16 21:44:24.398343: step 7614, loss = 0.70556 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:44:25.292238 ops/training.py:65 2019-01-16 21:44:25.292121: step 7615, loss = 0.70235 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:44:26.184926 ops/training.py:65 2019-01-16 21:44:26.184829: step 7616, loss = 0.71347 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:44:27.078209 ops/training.py:65 2019-01-16 21:44:27.078107: step 7617, loss = 0.72230 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:44:27.970549 ops/training.py:65 2019-01-16 21:44:27.970437: step 7618, loss = 0.71286 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:44:28.865033 ops/training.py:65 2019-01-16 21:44:28.864923: step 7619, loss = 0.70866 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:44:29.756569 ops/training.py:65 2019-01-16 21:44:29.756513: step 7620, loss = 0.72372 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:44:30.646848 ops/training.py:65 2019-01-16 21:44:30.646789: step 7621, loss = 0.66681 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:44:31.537029 ops/training.py:65 2019-01-16 21:44:31.536970: step 7622, loss = 0.70094 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:44:32.427849 ops/training.py:65 2019-01-16 21:44:32.427790: step 7623, loss = 0.68315 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:44:33.321379 ops/training.py:65 2019-01-16 21:44:33.321277: step 7624, loss = 0.68366 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:44:34.214562 ops/training.py:65 2019-01-16 21:44:34.214460: step 7625, loss = 0.71345 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:44:35.107435 ops/training.py:65 2019-01-16 21:44:35.107333: step 7626, loss = 0.67994 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:44:36.001693 ops/training.py:65 2019-01-16 21:44:36.001587: step 7627, loss = 0.69336 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:44:36.895147 ops/training.py:65 2019-01-16 21:44:36.895039: step 7628, loss = 0.69711 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:44:37.788782 ops/training.py:65 2019-01-16 21:44:37.788672: step 7629, loss = 0.69175 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:44:38.680564 ops/training.py:65 2019-01-16 21:44:38.680502: step 7630, loss = 0.67922 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:44:39.569398 ops/training.py:65 2019-01-16 21:44:39.569338: step 7631, loss = 0.70153 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:44:40.459331 ops/training.py:65 2019-01-16 21:44:40.459268: step 7632, loss = 0.70679 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:44:41.348123 ops/training.py:65 2019-01-16 21:44:41.348065: step 7633, loss = 0.68081 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 21:44:42.237496 ops/training.py:65 2019-01-16 21:44:42.237433: step 7634, loss = 0.68716 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:44:43.126738 ops/training.py:65 2019-01-16 21:44:43.126677: step 7635, loss = 0.69410 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:44:44.016176 ops/training.py:65 2019-01-16 21:44:44.016113: step 7636, loss = 0.70713 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:44:44.905701 ops/training.py:65 2019-01-16 21:44:44.905635: step 7637, loss = 0.69880 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:44:45.794988 ops/training.py:65 2019-01-16 21:44:45.794932: step 7638, loss = 0.69619 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:44:46.684018 ops/training.py:65 2019-01-16 21:44:46.683928: step 7639, loss = 0.70612 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:44:47.576055 ops/training.py:65 2019-01-16 21:44:47.575944: step 7640, loss = 0.67040 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:44:48.466617 ops/training.py:65 2019-01-16 21:44:48.466506: step 7641, loss = 0.70073 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:44:49.357403 ops/training.py:65 2019-01-16 21:44:49.357298: step 7642, loss = 0.68030 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:44:50.247745 ops/training.py:65 2019-01-16 21:44:50.247634: step 7643, loss = 0.70445 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:44:51.139136 ops/training.py:65 2019-01-16 21:44:51.139007: step 7644, loss = 0.71008 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:44:52.032306 ops/training.py:65 2019-01-16 21:44:52.032202: step 7645, loss = 0.66317 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 21:44:52.922621 ops/training.py:65 2019-01-16 21:44:52.922523: step 7646, loss = 0.67088 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:44:53.812528 ops/training.py:65 2019-01-16 21:44:53.812430: step 7647, loss = 0.72147 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:44:54.701547 ops/training.py:65 2019-01-16 21:44:54.701445: step 7648, loss = 0.69781 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:44:55.592860 ops/training.py:65 2019-01-16 21:44:55.592757: step 7649, loss = 0.69492 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:44:56.482553 ops/training.py:65 2019-01-16 21:44:56.482436: step 7650, loss = 0.71684 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:44:57.380841 ops/training.py:65 2019-01-16 21:44:57.380727: step 7651, loss = 0.66306 (35.7 examples/sec; 0.897 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:44:58.275109 ops/training.py:65 2019-01-16 21:44:58.275000: step 7652, loss = 0.75953 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:44:59.167234 ops/training.py:65 2019-01-16 21:44:59.167122: step 7653, loss = 0.69127 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:45:00.059743 ops/training.py:65 2019-01-16 21:45:00.059631: step 7654, loss = 0.72611 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:45:00.953906 ops/training.py:65 2019-01-16 21:45:00.953791: step 7655, loss = 0.71418 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:45:01.845347 ops/training.py:65 2019-01-16 21:45:01.845242: step 7656, loss = 0.71888 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:45:02.738760 ops/training.py:65 2019-01-16 21:45:02.738651: step 7657, loss = 0.79167 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 21:45:03.631385 ops/training.py:65 2019-01-16 21:45:03.631276: step 7658, loss = 0.68876 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:45:04.523771 ops/training.py:65 2019-01-16 21:45:04.523661: step 7659, loss = 0.71690 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:45:05.416403 ops/training.py:65 2019-01-16 21:45:05.416291: step 7660, loss = 0.67833 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:45:06.307927 ops/training.py:65 2019-01-16 21:45:06.307813: step 7661, loss = 0.70504 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:45:07.202690 ops/training.py:65 2019-01-16 21:45:07.202579: step 7662, loss = 0.66126 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:45:08.096532 ops/training.py:65 2019-01-16 21:45:08.096416: step 7663, loss = 0.66773 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:45:08.988870 ops/training.py:65 2019-01-16 21:45:08.988767: step 7664, loss = 0.70647 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:45:09.878352 ops/training.py:65 2019-01-16 21:45:09.878259: step 7665, loss = 0.69046 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:45:10.770777 ops/training.py:65 2019-01-16 21:45:10.770671: step 7666, loss = 0.68517 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:45:11.662860 ops/training.py:65 2019-01-16 21:45:11.662757: step 7667, loss = 0.68512 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:45:12.554615 ops/training.py:65 2019-01-16 21:45:12.554478: step 7668, loss = 0.68591 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:45:13.447200 ops/training.py:65 2019-01-16 21:45:13.447095: step 7669, loss = 0.69533 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:45:14.340993 ops/training.py:65 2019-01-16 21:45:14.340914: step 7670, loss = 0.69163 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:45:15.234730 ops/training.py:65 2019-01-16 21:45:15.234615: step 7671, loss = 0.70265 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:45:16.127591 ops/training.py:65 2019-01-16 21:45:16.127495: step 7672, loss = 0.71251 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:45:17.019914 ops/training.py:65 2019-01-16 21:45:17.019783: step 7673, loss = 0.71796 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:45:17.915591 ops/training.py:65 2019-01-16 21:45:17.915479: step 7674, loss = 0.68236 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:45:18.805225 ops/training.py:65 2019-01-16 21:45:18.805098: step 7675, loss = 0.68248 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:45:19.697919 ops/training.py:65 2019-01-16 21:45:19.697809: step 7676, loss = 0.68154 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:45:20.590535 ops/training.py:65 2019-01-16 21:45:20.590382: step 7677, loss = 0.67621 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:45:21.483656 ops/training.py:65 2019-01-16 21:45:21.483541: step 7678, loss = 0.69888 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:45:22.377951 ops/training.py:65 2019-01-16 21:45:22.377836: step 7679, loss = 0.70285 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:45:23.270795 ops/training.py:65 2019-01-16 21:45:23.270684: step 7680, loss = 0.69726 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:45:24.165720 ops/training.py:65 2019-01-16 21:45:24.165620: step 7681, loss = 0.70847 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:45:25.055623 ops/training.py:65 2019-01-16 21:45:25.055481: step 7682, loss = 0.69420 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:45:25.946034 ops/training.py:65 2019-01-16 21:45:25.945921: step 7683, loss = 0.67363 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:45:26.835477 ops/training.py:65 2019-01-16 21:45:26.835364: step 7684, loss = 0.67770 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:45:27.727104 ops/training.py:65 2019-01-16 21:45:27.727016: step 7685, loss = 0.68819 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:45:28.617132 ops/training.py:65 2019-01-16 21:45:28.617020: step 7686, loss = 0.69383 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:45:29.509861 ops/training.py:65 2019-01-16 21:45:29.509744: step 7687, loss = 0.67862 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:45:30.401820 ops/training.py:65 2019-01-16 21:45:30.401708: step 7688, loss = 0.69483 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:45:31.293594 ops/training.py:65 2019-01-16 21:45:31.293484: step 7689, loss = 0.71715 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:45:32.183504 ops/training.py:65 2019-01-16 21:45:32.183394: step 7690, loss = 0.71035 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:45:33.072308 ops/training.py:65 2019-01-16 21:45:33.072187: step 7691, loss = 0.67464 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:45:33.961327 ops/training.py:65 2019-01-16 21:45:33.961220: step 7692, loss = 0.68903 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:45:34.849287 ops/training.py:65 2019-01-16 21:45:34.849177: step 7693, loss = 0.70420 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:45:35.737286 ops/training.py:65 2019-01-16 21:45:35.737226: step 7694, loss = 0.68720 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:45:36.625457 ops/training.py:65 2019-01-16 21:45:36.625352: step 7695, loss = 0.68441 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:45:37.519020 ops/training.py:65 2019-01-16 21:45:37.518914: step 7696, loss = 0.67589 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:45:38.413197 ops/training.py:65 2019-01-16 21:45:38.413088: step 7697, loss = 0.68222 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:45:39.306293 ops/training.py:65 2019-01-16 21:45:39.306186: step 7698, loss = 0.68817 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:45:40.199949 ops/training.py:65 2019-01-16 21:45:40.199841: step 7699, loss = 0.70066 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:45:41.093316 ops/training.py:65 2019-01-16 21:45:41.093208: step 7700, loss = 0.69657 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:45:41.985412 ops/training.py:65 2019-01-16 21:45:41.985305: step 7701, loss = 0.71063 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:45:42.877839 ops/training.py:65 2019-01-16 21:45:42.877696: step 7702, loss = 0.68749 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:45:43.771342 ops/training.py:65 2019-01-16 21:45:43.771208: step 7703, loss = 0.70898 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:45:44.663085 ops/training.py:65 2019-01-16 21:45:44.662984: step 7704, loss = 0.70249 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:45:45.555321 ops/training.py:65 2019-01-16 21:45:45.555215: step 7705, loss = 0.69593 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:45:46.449482 ops/training.py:65 2019-01-16 21:45:46.449350: step 7706, loss = 0.68912 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:45:47.343183 ops/training.py:65 2019-01-16 21:45:47.343075: step 7707, loss = 0.69121 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:45:48.236239 ops/training.py:65 2019-01-16 21:45:48.236128: step 7708, loss = 0.68568 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:45:49.127546 ops/training.py:65 2019-01-16 21:45:49.127445: step 7709, loss = 0.69794 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:45:50.018214 ops/training.py:65 2019-01-16 21:45:50.018100: step 7710, loss = 0.68483 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:45:50.909345 ops/training.py:65 2019-01-16 21:45:50.909236: step 7711, loss = 0.69036 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:45:51.799990 ops/training.py:65 2019-01-16 21:45:51.799921: step 7712, loss = 0.70676 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:45:52.688646 ops/training.py:65 2019-01-16 21:45:52.688586: step 7713, loss = 0.70124 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:45:53.577727 ops/training.py:65 2019-01-16 21:45:53.577660: step 7714, loss = 0.67007 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:45:54.467442 ops/training.py:65 2019-01-16 21:45:54.467365: step 7715, loss = 0.69738 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:45:55.358943 ops/training.py:65 2019-01-16 21:45:55.358831: step 7716, loss = 0.68863 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:45:56.251163 ops/training.py:65 2019-01-16 21:45:56.251055: step 7717, loss = 0.69320 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:45:57.143056 ops/training.py:65 2019-01-16 21:45:57.142944: step 7718, loss = 0.68934 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:45:58.036367 ops/training.py:65 2019-01-16 21:45:58.036255: step 7719, loss = 0.69753 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:45:58.929442 ops/training.py:65 2019-01-16 21:45:58.929331: step 7720, loss = 0.69071 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:45:59.822633 ops/training.py:65 2019-01-16 21:45:59.822523: step 7721, loss = 0.68111 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:46:00.715228 ops/training.py:65 2019-01-16 21:46:00.715113: step 7722, loss = 0.68220 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:46:01.607179 ops/training.py:65 2019-01-16 21:46:01.607065: step 7723, loss = 0.68151 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:46:02.500412 ops/training.py:65 2019-01-16 21:46:02.500301: step 7724, loss = 0.71098 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:46:03.390543 ops/training.py:65 2019-01-16 21:46:03.390433: step 7725, loss = 0.71500 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:46:04.283035 ops/training.py:65 2019-01-16 21:46:04.282983: step 7726, loss = 0.65646 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.78125
I2992 2019-01-16 21:46:05.175361 ops/training.py:65 2019-01-16 21:46:05.175279: step 7727, loss = 0.69838 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:46:06.068479 ops/training.py:65 2019-01-16 21:46:06.068367: step 7728, loss = 0.69325 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:46:06.960359 ops/training.py:65 2019-01-16 21:46:06.960258: step 7729, loss = 0.67197 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:46:07.851315 ops/training.py:65 2019-01-16 21:46:07.851210: step 7730, loss = 0.67701 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:46:08.743674 ops/training.py:65 2019-01-16 21:46:08.743573: step 7731, loss = 0.68895 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:46:09.633793 ops/training.py:65 2019-01-16 21:46:09.633687: step 7732, loss = 0.69478 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:46:10.524673 ops/training.py:65 2019-01-16 21:46:10.524560: step 7733, loss = 0.70794 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:46:11.414662 ops/training.py:65 2019-01-16 21:46:11.414558: step 7734, loss = 0.68024 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:46:12.304647 ops/training.py:65 2019-01-16 21:46:12.304552: step 7735, loss = 0.65412 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:46:13.197006 ops/training.py:65 2019-01-16 21:46:13.196900: step 7736, loss = 0.68479 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:46:14.092219 ops/training.py:65 2019-01-16 21:46:14.092115: step 7737, loss = 0.69134 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:46:14.982844 ops/training.py:65 2019-01-16 21:46:14.982775: step 7738, loss = 0.68017 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:46:15.871910 ops/training.py:65 2019-01-16 21:46:15.871807: step 7739, loss = 0.68292 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:46:16.762319 ops/training.py:65 2019-01-16 21:46:16.762221: step 7740, loss = 0.73302 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:46:17.651094 ops/training.py:65 2019-01-16 21:46:17.651036: step 7741, loss = 0.71718 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:46:18.540238 ops/training.py:65 2019-01-16 21:46:18.540140: step 7742, loss = 0.69738 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:46:19.429244 ops/training.py:65 2019-01-16 21:46:19.429139: step 7743, loss = 0.72114 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:46:20.319889 ops/training.py:65 2019-01-16 21:46:20.319781: step 7744, loss = 0.70549 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:46:21.213436 ops/training.py:65 2019-01-16 21:46:21.213329: step 7745, loss = 0.70419 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:46:22.106532 ops/training.py:65 2019-01-16 21:46:22.106407: step 7746, loss = 0.71221 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:46:22.999728 ops/training.py:65 2019-01-16 21:46:22.999623: step 7747, loss = 0.65604 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.75
I2992 2019-01-16 21:46:23.891963 ops/training.py:65 2019-01-16 21:46:23.891845: step 7748, loss = 0.71251 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:46:24.781372 ops/training.py:65 2019-01-16 21:46:24.781256: step 7749, loss = 0.68278 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:46:25.672924 ops/training.py:65 2019-01-16 21:46:25.672811: step 7750, loss = 0.71416 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:46:26.564440 ops/training.py:65 2019-01-16 21:46:26.564331: step 7751, loss = 0.67493 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:46:27.456288 ops/training.py:65 2019-01-16 21:46:27.456174: step 7752, loss = 0.71502 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:46:28.348672 ops/training.py:65 2019-01-16 21:46:28.348556: step 7753, loss = 0.68708 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:46:29.241772 ops/training.py:65 2019-01-16 21:46:29.241656: step 7754, loss = 0.68760 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:46:30.133779 ops/training.py:65 2019-01-16 21:46:30.133669: step 7755, loss = 0.68325 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:46:31.025716 ops/training.py:65 2019-01-16 21:46:31.025602: step 7756, loss = 0.70147 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:46:31.918829 ops/training.py:65 2019-01-16 21:46:31.918718: step 7757, loss = 0.68521 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:46:32.810763 ops/training.py:65 2019-01-16 21:46:32.810644: step 7758, loss = 0.70539 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:46:33.703094 ops/training.py:65 2019-01-16 21:46:33.702989: step 7759, loss = 0.70714 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:46:34.594262 ops/training.py:65 2019-01-16 21:46:34.594160: step 7760, loss = 0.70473 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:46:35.482937 ops/training.py:65 2019-01-16 21:46:35.482832: step 7761, loss = 0.68851 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:46:36.371732 ops/training.py:65 2019-01-16 21:46:36.371628: step 7762, loss = 0.71321 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:46:37.262237 ops/training.py:65 2019-01-16 21:46:37.262129: step 7763, loss = 0.71213 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:46:38.153011 ops/training.py:65 2019-01-16 21:46:38.152909: step 7764, loss = 0.69921 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:46:39.041788 ops/training.py:65 2019-01-16 21:46:39.041693: step 7765, loss = 0.69590 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:46:39.930963 ops/training.py:65 2019-01-16 21:46:39.930856: step 7766, loss = 0.70055 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:46:40.820224 ops/training.py:65 2019-01-16 21:46:40.820111: step 7767, loss = 0.70411 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:46:41.709352 ops/training.py:65 2019-01-16 21:46:41.709262: step 7768, loss = 0.67887 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:46:42.599411 ops/training.py:65 2019-01-16 21:46:42.599306: step 7769, loss = 0.68125 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:46:43.491935 ops/training.py:65 2019-01-16 21:46:43.491856: step 7770, loss = 0.70072 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:46:44.383728 ops/training.py:65 2019-01-16 21:46:44.383662: step 7771, loss = 0.68734 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:46:45.273392 ops/training.py:65 2019-01-16 21:46:45.273282: step 7772, loss = 0.69515 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:46:46.164169 ops/training.py:65 2019-01-16 21:46:46.164057: step 7773, loss = 0.65847 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:46:47.053828 ops/training.py:65 2019-01-16 21:46:47.053722: step 7774, loss = 0.68337 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:46:47.944597 ops/training.py:65 2019-01-16 21:46:47.944490: step 7775, loss = 0.71880 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:46:48.834919 ops/training.py:65 2019-01-16 21:46:48.834814: step 7776, loss = 0.66862 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.75
I2992 2019-01-16 21:46:49.724898 ops/training.py:65 2019-01-16 21:46:49.724843: step 7777, loss = 0.69575 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:46:50.613680 ops/training.py:65 2019-01-16 21:46:50.613580: step 7778, loss = 0.68731 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:46:51.503086 ops/training.py:65 2019-01-16 21:46:51.502951: step 7779, loss = 0.69638 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:46:52.394445 ops/training.py:65 2019-01-16 21:46:52.394338: step 7780, loss = 0.69666 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:46:53.284160 ops/training.py:65 2019-01-16 21:46:53.284052: step 7781, loss = 0.67280 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 21:46:54.173123 ops/training.py:65 2019-01-16 21:46:54.173027: step 7782, loss = 0.68496 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:46:55.062020 ops/training.py:65 2019-01-16 21:46:55.061912: step 7783, loss = 0.69247 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:46:55.950722 ops/training.py:65 2019-01-16 21:46:55.950601: step 7784, loss = 0.68418 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:46:56.841743 ops/training.py:65 2019-01-16 21:46:56.841637: step 7785, loss = 0.70579 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:46:57.734243 ops/training.py:65 2019-01-16 21:46:57.734136: step 7786, loss = 0.69115 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:46:58.625835 ops/training.py:65 2019-01-16 21:46:58.625720: step 7787, loss = 0.70315 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:46:59.515801 ops/training.py:65 2019-01-16 21:46:59.515687: step 7788, loss = 0.69155 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:47:00.405695 ops/training.py:65 2019-01-16 21:47:00.405589: step 7789, loss = 0.71165 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:47:01.298609 ops/training.py:65 2019-01-16 21:47:01.298548: step 7790, loss = 0.69700 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:47:02.191455 ops/training.py:65 2019-01-16 21:47:02.191349: step 7791, loss = 0.71258 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:47:03.083785 ops/training.py:65 2019-01-16 21:47:03.083682: step 7792, loss = 0.68092 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:47:03.977012 ops/training.py:65 2019-01-16 21:47:03.976902: step 7793, loss = 0.71994 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:47:04.871239 ops/training.py:65 2019-01-16 21:47:04.871132: step 7794, loss = 0.70411 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:47:05.763103 ops/training.py:65 2019-01-16 21:47:05.762992: step 7795, loss = 0.71024 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:47:06.653438 ops/training.py:65 2019-01-16 21:47:06.653333: step 7796, loss = 0.69118 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:47:07.543259 ops/training.py:65 2019-01-16 21:47:07.543153: step 7797, loss = 0.69034 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:47:08.432648 ops/training.py:65 2019-01-16 21:47:08.432549: step 7798, loss = 0.68751 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:47:09.321348 ops/training.py:65 2019-01-16 21:47:09.321242: step 7799, loss = 0.71598 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:47:10.210089 ops/training.py:65 2019-01-16 21:47:10.209944: step 7800, loss = 0.69716 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:47:11.099749 ops/training.py:65 2019-01-16 21:47:11.099641: step 7801, loss = 0.67150 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:47:11.989967 ops/training.py:65 2019-01-16 21:47:11.989865: step 7802, loss = 0.67957 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:47:12.879464 ops/training.py:65 2019-01-16 21:47:12.879353: step 7803, loss = 0.68761 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:47:13.769756 ops/training.py:65 2019-01-16 21:47:13.769655: step 7804, loss = 0.69218 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:47:14.659304 ops/training.py:65 2019-01-16 21:47:14.659152: step 7805, loss = 0.69903 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:47:15.551097 ops/training.py:65 2019-01-16 21:47:15.550990: step 7806, loss = 0.69891 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:47:16.443962 ops/training.py:65 2019-01-16 21:47:16.443857: step 7807, loss = 0.70080 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:47:17.333524 ops/training.py:65 2019-01-16 21:47:17.333418: step 7808, loss = 0.70383 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:47:18.224524 ops/training.py:65 2019-01-16 21:47:18.224430: step 7809, loss = 0.68482 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:47:19.116493 ops/training.py:65 2019-01-16 21:47:19.116372: step 7810, loss = 0.70144 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:47:20.010248 ops/training.py:65 2019-01-16 21:47:20.010141: step 7811, loss = 0.69025 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:47:20.902233 ops/training.py:65 2019-01-16 21:47:20.902128: step 7812, loss = 0.70983 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:47:21.794329 ops/training.py:65 2019-01-16 21:47:21.794222: step 7813, loss = 0.64299 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:47:22.686303 ops/training.py:65 2019-01-16 21:47:22.686195: step 7814, loss = 0.72849 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:47:23.578811 ops/training.py:65 2019-01-16 21:47:23.578691: step 7815, loss = 0.73612 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:47:24.472879 ops/training.py:65 2019-01-16 21:47:24.472780: step 7816, loss = 0.69408 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:47:25.364573 ops/training.py:65 2019-01-16 21:47:25.364464: step 7817, loss = 0.68665 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:47:26.256361 ops/training.py:65 2019-01-16 21:47:26.256250: step 7818, loss = 0.71612 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:47:27.148144 ops/training.py:65 2019-01-16 21:47:27.148037: step 7819, loss = 0.69455 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:47:28.040675 ops/training.py:65 2019-01-16 21:47:28.040563: step 7820, loss = 0.68697 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:47:28.933217 ops/training.py:65 2019-01-16 21:47:28.933068: step 7821, loss = 0.71481 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:47:29.825619 ops/training.py:65 2019-01-16 21:47:29.825507: step 7822, loss = 0.71994 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:47:30.717872 ops/training.py:65 2019-01-16 21:47:30.717724: step 7823, loss = 0.69576 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:47:31.610683 ops/training.py:65 2019-01-16 21:47:31.610566: step 7824, loss = 0.71285 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:47:32.501842 ops/training.py:65 2019-01-16 21:47:32.501727: step 7825, loss = 0.67730 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:47:33.393807 ops/training.py:65 2019-01-16 21:47:33.393699: step 7826, loss = 0.67572 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:47:34.289500 ops/training.py:65 2019-01-16 21:47:34.289384: step 7827, loss = 0.69721 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:47:35.181673 ops/training.py:65 2019-01-16 21:47:35.181563: step 7828, loss = 0.68787 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:47:36.074392 ops/training.py:65 2019-01-16 21:47:36.074280: step 7829, loss = 0.68117 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:47:36.965721 ops/training.py:65 2019-01-16 21:47:36.965645: step 7830, loss = 0.72339 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:47:37.855187 ops/training.py:65 2019-01-16 21:47:37.855129: step 7831, loss = 0.74779 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:47:38.745708 ops/training.py:65 2019-01-16 21:47:38.745595: step 7832, loss = 0.64462 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.78125
I2992 2019-01-16 21:47:39.636825 ops/training.py:65 2019-01-16 21:47:39.636729: step 7833, loss = 0.66405 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:47:40.527189 ops/training.py:65 2019-01-16 21:47:40.527075: step 7834, loss = 0.66897 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:47:41.416776 ops/training.py:65 2019-01-16 21:47:41.416661: step 7835, loss = 0.69166 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:47:42.306333 ops/training.py:65 2019-01-16 21:47:42.306204: step 7836, loss = 0.73453 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:47:43.198293 ops/training.py:65 2019-01-16 21:47:43.198190: step 7837, loss = 0.70403 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:47:44.088804 ops/training.py:65 2019-01-16 21:47:44.088697: step 7838, loss = 0.74614 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:47:44.977818 ops/training.py:65 2019-01-16 21:47:44.977721: step 7839, loss = 0.73907 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:47:45.866892 ops/training.py:65 2019-01-16 21:47:45.866782: step 7840, loss = 0.68140 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:47:46.756656 ops/training.py:65 2019-01-16 21:47:46.756525: step 7841, loss = 0.72004 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:47:47.648871 ops/training.py:65 2019-01-16 21:47:47.648767: step 7842, loss = 0.69400 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:47:48.538561 ops/training.py:65 2019-01-16 21:47:48.538448: step 7843, loss = 0.68206 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:47:49.430067 ops/training.py:65 2019-01-16 21:47:49.429950: step 7844, loss = 0.69523 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:47:50.320129 ops/training.py:65 2019-01-16 21:47:50.320024: step 7845, loss = 0.65229 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:47:51.213560 ops/training.py:65 2019-01-16 21:47:51.213450: step 7846, loss = 0.72539 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:47:52.105243 ops/training.py:65 2019-01-16 21:47:52.105139: step 7847, loss = 0.67080 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:47:52.994071 ops/training.py:65 2019-01-16 21:47:52.993964: step 7848, loss = 0.72760 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:47:53.883469 ops/training.py:65 2019-01-16 21:47:53.883382: step 7849, loss = 0.71460 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:47:54.775482 ops/training.py:65 2019-01-16 21:47:54.775355: step 7850, loss = 0.67957 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:47:55.670044 ops/training.py:65 2019-01-16 21:47:55.669924: step 7851, loss = 0.68401 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:47:56.563026 ops/training.py:65 2019-01-16 21:47:56.562893: step 7852, loss = 0.71867 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:47:57.455886 ops/training.py:65 2019-01-16 21:47:57.455776: step 7853, loss = 0.73379 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:47:58.347635 ops/training.py:65 2019-01-16 21:47:58.347529: step 7854, loss = 0.72480 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:47:59.240547 ops/training.py:65 2019-01-16 21:47:59.240436: step 7855, loss = 0.70925 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:48:00.131847 ops/training.py:65 2019-01-16 21:48:00.131740: step 7856, loss = 0.72326 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:48:01.023910 ops/training.py:65 2019-01-16 21:48:01.023777: step 7857, loss = 0.72435 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:48:01.916508 ops/training.py:65 2019-01-16 21:48:01.916409: step 7858, loss = 0.63844 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:48:02.808206 ops/training.py:65 2019-01-16 21:48:02.808111: step 7859, loss = 0.70647 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:48:03.698732 ops/training.py:65 2019-01-16 21:48:03.698643: step 7860, loss = 0.74908 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:48:04.588541 ops/training.py:65 2019-01-16 21:48:04.588429: step 7861, loss = 0.73824 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:48:05.481285 ops/training.py:65 2019-01-16 21:48:05.481196: step 7862, loss = 0.71279 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:48:06.373655 ops/training.py:65 2019-01-16 21:48:06.373543: step 7863, loss = 0.70286 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:48:07.266685 ops/training.py:65 2019-01-16 21:48:07.266568: step 7864, loss = 0.76288 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:48:08.159541 ops/training.py:65 2019-01-16 21:48:08.159429: step 7865, loss = 0.65862 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:48:09.053904 ops/training.py:65 2019-01-16 21:48:09.053803: step 7866, loss = 0.70048 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:48:09.944225 ops/training.py:65 2019-01-16 21:48:09.944112: step 7867, loss = 0.68606 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:48:10.833280 ops/training.py:65 2019-01-16 21:48:10.833171: step 7868, loss = 0.71993 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:48:11.725770 ops/training.py:65 2019-01-16 21:48:11.725657: step 7869, loss = 0.71392 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:48:12.617796 ops/training.py:65 2019-01-16 21:48:12.617693: step 7870, loss = 0.64879 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:48:13.509429 ops/training.py:65 2019-01-16 21:48:13.509333: step 7871, loss = 0.67696 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:48:14.401249 ops/training.py:65 2019-01-16 21:48:14.401138: step 7872, loss = 0.71884 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:48:15.290716 ops/training.py:65 2019-01-16 21:48:15.290651: step 7873, loss = 0.78862 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:48:16.179717 ops/training.py:65 2019-01-16 21:48:16.179615: step 7874, loss = 0.68311 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:48:17.069381 ops/training.py:65 2019-01-16 21:48:17.069279: step 7875, loss = 0.68043 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:48:17.960147 ops/training.py:65 2019-01-16 21:48:17.960042: step 7876, loss = 0.70484 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:48:18.850371 ops/training.py:65 2019-01-16 21:48:18.850282: step 7877, loss = 0.63213 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 21:48:19.740338 ops/training.py:65 2019-01-16 21:48:19.740245: step 7878, loss = 0.73167 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:48:20.629429 ops/training.py:65 2019-01-16 21:48:20.629367: step 7879, loss = 0.71349 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:48:21.518654 ops/training.py:65 2019-01-16 21:48:21.518556: step 7880, loss = 0.76452 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:48:22.407733 ops/training.py:65 2019-01-16 21:48:22.407642: step 7881, loss = 0.69107 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:48:23.297484 ops/training.py:65 2019-01-16 21:48:23.297392: step 7882, loss = 0.65469 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:48:24.187601 ops/training.py:65 2019-01-16 21:48:24.187506: step 7883, loss = 0.68341 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:48:25.077048 ops/training.py:65 2019-01-16 21:48:25.076942: step 7884, loss = 0.71907 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:48:25.967642 ops/training.py:65 2019-01-16 21:48:25.967535: step 7885, loss = 0.68500 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:48:26.858007 ops/training.py:65 2019-01-16 21:48:26.857901: step 7886, loss = 0.72131 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:48:27.747226 ops/training.py:65 2019-01-16 21:48:27.747124: step 7887, loss = 0.71042 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:48:28.637274 ops/training.py:65 2019-01-16 21:48:28.637172: step 7888, loss = 0.70328 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:48:29.527252 ops/training.py:65 2019-01-16 21:48:29.527151: step 7889, loss = 0.70952 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:48:30.416563 ops/training.py:65 2019-01-16 21:48:30.416475: step 7890, loss = 0.68447 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:48:31.306131 ops/training.py:65 2019-01-16 21:48:31.306036: step 7891, loss = 0.66423 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 21:48:32.195566 ops/training.py:65 2019-01-16 21:48:32.195478: step 7892, loss = 0.72013 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:48:33.085485 ops/training.py:65 2019-01-16 21:48:33.085392: step 7893, loss = 0.71284 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:48:33.975636 ops/training.py:65 2019-01-16 21:48:33.975533: step 7894, loss = 0.71847 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:48:34.865930 ops/training.py:65 2019-01-16 21:48:34.865835: step 7895, loss = 0.69843 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:48:35.755515 ops/training.py:65 2019-01-16 21:48:35.755418: step 7896, loss = 0.69189 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:48:36.645742 ops/training.py:65 2019-01-16 21:48:36.645652: step 7897, loss = 0.71552 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:48:37.534729 ops/training.py:65 2019-01-16 21:48:37.534669: step 7898, loss = 0.69313 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:48:38.424198 ops/training.py:65 2019-01-16 21:48:38.424137: step 7899, loss = 0.68185 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:48:39.314263 ops/training.py:65 2019-01-16 21:48:39.314200: step 7900, loss = 0.68995 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:48:40.203188 ops/training.py:65 2019-01-16 21:48:40.203123: step 7901, loss = 0.69626 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:48:41.093113 ops/training.py:65 2019-01-16 21:48:41.093044: step 7902, loss = 0.69750 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:48:41.982560 ops/training.py:65 2019-01-16 21:48:41.982500: step 7903, loss = 0.68241 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:48:42.872527 ops/training.py:65 2019-01-16 21:48:42.872459: step 7904, loss = 0.68475 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:48:43.762084 ops/training.py:65 2019-01-16 21:48:43.762017: step 7905, loss = 0.67942 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:48:44.650914 ops/training.py:65 2019-01-16 21:48:44.650845: step 7906, loss = 0.69901 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:48:45.542263 ops/training.py:65 2019-01-16 21:48:45.542203: step 7907, loss = 0.70288 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:48:46.433681 ops/training.py:65 2019-01-16 21:48:46.433617: step 7908, loss = 0.71092 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:48:47.323170 ops/training.py:65 2019-01-16 21:48:47.323109: step 7909, loss = 0.65028 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:48:48.211915 ops/training.py:65 2019-01-16 21:48:48.211855: step 7910, loss = 0.68958 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:48:49.101551 ops/training.py:65 2019-01-16 21:48:49.101484: step 7911, loss = 0.68613 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:48:49.990378 ops/training.py:65 2019-01-16 21:48:49.990318: step 7912, loss = 0.67039 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:48:50.879463 ops/training.py:65 2019-01-16 21:48:50.879402: step 7913, loss = 0.67957 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:48:51.768405 ops/training.py:65 2019-01-16 21:48:51.768333: step 7914, loss = 0.69888 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:48:52.657453 ops/training.py:65 2019-01-16 21:48:52.657389: step 7915, loss = 0.71195 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:48:53.546573 ops/training.py:65 2019-01-16 21:48:53.546502: step 7916, loss = 0.71881 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:48:54.435645 ops/training.py:65 2019-01-16 21:48:54.435574: step 7917, loss = 0.67989 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:48:55.328077 ops/training.py:65 2019-01-16 21:48:55.327994: step 7918, loss = 0.70795 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:48:56.220513 ops/training.py:65 2019-01-16 21:48:56.220406: step 7919, loss = 0.74340 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:48:57.114240 ops/training.py:65 2019-01-16 21:48:57.114133: step 7920, loss = 0.68375 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:48:58.005246 ops/training.py:65 2019-01-16 21:48:58.005135: step 7921, loss = 0.71875 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:48:58.895518 ops/training.py:65 2019-01-16 21:48:58.895446: step 7922, loss = 0.73331 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:48:59.784847 ops/training.py:65 2019-01-16 21:48:59.784784: step 7923, loss = 0.66452 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:49:00.674233 ops/training.py:65 2019-01-16 21:49:00.674167: step 7924, loss = 0.78500 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:49:01.565114 ops/training.py:65 2019-01-16 21:49:01.564997: step 7925, loss = 0.70218 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:49:02.457690 ops/training.py:65 2019-01-16 21:49:02.457576: step 7926, loss = 0.72663 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:49:03.351095 ops/training.py:65 2019-01-16 21:49:03.350986: step 7927, loss = 0.69094 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:49:04.243587 ops/training.py:65 2019-01-16 21:49:04.243471: step 7928, loss = 0.68614 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:49:05.136761 ops/training.py:65 2019-01-16 21:49:05.136648: step 7929, loss = 0.70708 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:49:06.029295 ops/training.py:65 2019-01-16 21:49:06.029191: step 7930, loss = 0.74344 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:49:06.922162 ops/training.py:65 2019-01-16 21:49:06.922046: step 7931, loss = 0.66952 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:49:07.813024 ops/training.py:65 2019-01-16 21:49:07.812966: step 7932, loss = 0.68052 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:49:08.703911 ops/training.py:65 2019-01-16 21:49:08.703840: step 7933, loss = 0.69492 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:49:09.597479 ops/training.py:65 2019-01-16 21:49:09.597377: step 7934, loss = 0.72440 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:49:10.489359 ops/training.py:65 2019-01-16 21:49:10.489250: step 7935, loss = 0.71800 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:49:11.383103 ops/training.py:65 2019-01-16 21:49:11.382989: step 7936, loss = 0.67126 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:49:12.274644 ops/training.py:65 2019-01-16 21:49:12.274573: step 7937, loss = 0.72848 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:49:13.164414 ops/training.py:65 2019-01-16 21:49:13.164321: step 7938, loss = 0.78117 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 21:49:14.055027 ops/training.py:65 2019-01-16 21:49:14.054936: step 7939, loss = 0.69051 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:49:14.944616 ops/training.py:65 2019-01-16 21:49:14.944544: step 7940, loss = 0.69593 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:49:15.833527 ops/training.py:65 2019-01-16 21:49:15.833454: step 7941, loss = 0.74474 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:49:16.723630 ops/training.py:65 2019-01-16 21:49:16.723559: step 7942, loss = 0.72717 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:49:17.614578 ops/training.py:65 2019-01-16 21:49:17.614508: step 7943, loss = 0.66336 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:49:18.506784 ops/training.py:65 2019-01-16 21:49:18.506670: step 7944, loss = 0.72387 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:49:19.399994 ops/training.py:65 2019-01-16 21:49:19.399874: step 7945, loss = 0.71092 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:49:20.294200 ops/training.py:65 2019-01-16 21:49:20.294085: step 7946, loss = 0.70323 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:49:21.186789 ops/training.py:65 2019-01-16 21:49:21.186690: step 7947, loss = 0.69542 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:49:22.076955 ops/training.py:65 2019-01-16 21:49:22.076882: step 7948, loss = 0.72967 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:49:22.970018 ops/training.py:65 2019-01-16 21:49:22.969903: step 7949, loss = 0.69797 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:49:23.863118 ops/training.py:65 2019-01-16 21:49:23.863018: step 7950, loss = 0.67639 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:49:24.757123 ops/training.py:65 2019-01-16 21:49:24.757021: step 7951, loss = 0.71032 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:49:25.648138 ops/training.py:65 2019-01-16 21:49:25.648028: step 7952, loss = 0.76863 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:49:26.538361 ops/training.py:65 2019-01-16 21:49:26.538278: step 7953, loss = 0.70412 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:49:27.429472 ops/training.py:65 2019-01-16 21:49:27.429395: step 7954, loss = 0.76130 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:49:28.321189 ops/training.py:65 2019-01-16 21:49:28.321112: step 7955, loss = 0.70771 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:49:29.213852 ops/training.py:65 2019-01-16 21:49:29.213740: step 7956, loss = 0.67387 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:49:30.104736 ops/training.py:65 2019-01-16 21:49:30.104682: step 7957, loss = 0.66525 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:49:30.996193 ops/training.py:65 2019-01-16 21:49:30.996078: step 7958, loss = 0.71561 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:49:31.887893 ops/training.py:65 2019-01-16 21:49:31.887772: step 7959, loss = 0.72630 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:49:32.781662 ops/training.py:65 2019-01-16 21:49:32.781550: step 7960, loss = 0.68449 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:49:33.673936 ops/training.py:65 2019-01-16 21:49:33.673827: step 7961, loss = 0.67479 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:49:34.565069 ops/training.py:65 2019-01-16 21:49:34.564956: step 7962, loss = 0.70706 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:49:35.455639 ops/training.py:65 2019-01-16 21:49:35.455574: step 7963, loss = 0.69680 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:49:36.345319 ops/training.py:65 2019-01-16 21:49:36.345260: step 7964, loss = 0.74014 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:49:37.234856 ops/training.py:65 2019-01-16 21:49:37.234794: step 7965, loss = 0.67585 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:49:38.127126 ops/training.py:65 2019-01-16 21:49:38.127054: step 7966, loss = 0.69559 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:49:39.020350 ops/training.py:65 2019-01-16 21:49:39.020248: step 7967, loss = 0.68768 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:49:39.913250 ops/training.py:65 2019-01-16 21:49:39.913145: step 7968, loss = 0.73822 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:49:40.805611 ops/training.py:65 2019-01-16 21:49:40.805510: step 7969, loss = 0.69831 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:49:41.695058 ops/training.py:65 2019-01-16 21:49:41.694983: step 7970, loss = 0.70668 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:49:42.584694 ops/training.py:65 2019-01-16 21:49:42.584614: step 7971, loss = 0.68646 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:49:43.474687 ops/training.py:65 2019-01-16 21:49:43.474621: step 7972, loss = 0.68774 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:49:44.364954 ops/training.py:65 2019-01-16 21:49:44.364846: step 7973, loss = 0.73048 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:49:45.255097 ops/training.py:65 2019-01-16 21:49:45.255027: step 7974, loss = 0.71035 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:49:46.144868 ops/training.py:65 2019-01-16 21:49:46.144804: step 7975, loss = 0.69790 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:49:47.034672 ops/training.py:65 2019-01-16 21:49:47.034609: step 7976, loss = 0.68720 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:49:47.923158 ops/training.py:65 2019-01-16 21:49:47.923096: step 7977, loss = 0.68644 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:49:48.811650 ops/training.py:65 2019-01-16 21:49:48.811578: step 7978, loss = 0.72499 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:49:49.700558 ops/training.py:65 2019-01-16 21:49:49.700477: step 7979, loss = 0.68546 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:49:50.593525 ops/training.py:65 2019-01-16 21:49:50.593416: step 7980, loss = 0.69498 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:49:51.486755 ops/training.py:65 2019-01-16 21:49:51.486642: step 7981, loss = 0.69022 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:49:52.379181 ops/training.py:65 2019-01-16 21:49:52.379068: step 7982, loss = 0.71962 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:49:53.271484 ops/training.py:65 2019-01-16 21:49:53.271377: step 7983, loss = 0.68425 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:49:54.164843 ops/training.py:65 2019-01-16 21:49:54.164738: step 7984, loss = 0.72342 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:49:55.055532 ops/training.py:65 2019-01-16 21:49:55.055422: step 7985, loss = 0.71146 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:49:55.945719 ops/training.py:65 2019-01-16 21:49:55.945608: step 7986, loss = 0.68274 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:49:56.838956 ops/training.py:65 2019-01-16 21:49:56.838880: step 7987, loss = 0.70770 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:49:57.731532 ops/training.py:65 2019-01-16 21:49:57.731427: step 7988, loss = 0.73294 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.25
I2992 2019-01-16 21:49:58.624277 ops/training.py:65 2019-01-16 21:49:58.624168: step 7989, loss = 0.71734 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:49:59.515692 ops/training.py:65 2019-01-16 21:49:59.515591: step 7990, loss = 0.71698 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:50:00.406537 ops/training.py:65 2019-01-16 21:50:00.406467: step 7991, loss = 0.69079 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:50:01.295776 ops/training.py:65 2019-01-16 21:50:01.295709: step 7992, loss = 0.70034 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:50:02.186186 ops/training.py:65 2019-01-16 21:50:02.186073: step 7993, loss = 0.70093 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:50:03.076059 ops/training.py:65 2019-01-16 21:50:03.075975: step 7994, loss = 0.70862 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:50:03.966148 ops/training.py:65 2019-01-16 21:50:03.966039: step 7995, loss = 0.76284 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:50:04.856008 ops/training.py:65 2019-01-16 21:50:04.855903: step 7996, loss = 0.70660 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:50:05.745101 ops/training.py:65 2019-01-16 21:50:05.745013: step 7997, loss = 0.70715 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:50:06.633307 ops/training.py:65 2019-01-16 21:50:06.633219: step 7998, loss = 0.68808 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:50:07.521427 ops/training.py:65 2019-01-16 21:50:07.521322: step 7999, loss = 0.71614 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:54:22.840306 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I2992 2019-01-16 21:54:22.841328 ops/training.py:41 2019-01-16 21:54:22.841270: step 8000, loss = 0.69 (0.1 examples/sec; 254.428 sec/batch) | Training accuracy = 0.4375 | Validation accuracy = 0.50285 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_19_33_19_510334
I2992 2019-01-16 21:54:23.733728 ops/training.py:65 2019-01-16 21:54:23.733625: step 8001, loss = 0.68663 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:54:24.624659 ops/training.py:65 2019-01-16 21:54:24.624565: step 8002, loss = 0.69793 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:54:25.514276 ops/training.py:65 2019-01-16 21:54:25.514209: step 8003, loss = 0.70469 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:54:26.402554 ops/training.py:65 2019-01-16 21:54:26.402491: step 8004, loss = 0.70738 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:54:27.291330 ops/training.py:65 2019-01-16 21:54:27.291271: step 8005, loss = 0.67605 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:54:28.179984 ops/training.py:65 2019-01-16 21:54:28.179917: step 8006, loss = 0.70914 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:54:29.070036 ops/training.py:65 2019-01-16 21:54:29.069977: step 8007, loss = 0.68621 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:54:29.958507 ops/training.py:65 2019-01-16 21:54:29.958446: step 8008, loss = 0.69100 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:54:30.847632 ops/training.py:65 2019-01-16 21:54:30.847575: step 8009, loss = 0.68959 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:54:31.736419 ops/training.py:65 2019-01-16 21:54:31.736363: step 8010, loss = 0.69058 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:54:32.626001 ops/training.py:65 2019-01-16 21:54:32.625932: step 8011, loss = 0.68775 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:54:33.518695 ops/training.py:65 2019-01-16 21:54:33.518609: step 8012, loss = 0.69308 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:54:34.412327 ops/training.py:65 2019-01-16 21:54:34.412216: step 8013, loss = 0.72636 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:54:35.303679 ops/training.py:65 2019-01-16 21:54:35.303616: step 8014, loss = 0.69733 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:54:36.193773 ops/training.py:65 2019-01-16 21:54:36.193708: step 8015, loss = 0.71263 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:54:37.083880 ops/training.py:65 2019-01-16 21:54:37.083806: step 8016, loss = 0.69110 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:54:37.973584 ops/training.py:65 2019-01-16 21:54:37.973501: step 8017, loss = 0.69384 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:54:38.865583 ops/training.py:65 2019-01-16 21:54:38.865518: step 8018, loss = 0.70804 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:54:39.756916 ops/training.py:65 2019-01-16 21:54:39.756836: step 8019, loss = 0.68705 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:54:40.649588 ops/training.py:65 2019-01-16 21:54:40.649484: step 8020, loss = 0.68447 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:54:41.541579 ops/training.py:65 2019-01-16 21:54:41.541467: step 8021, loss = 0.70284 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:54:42.432351 ops/training.py:65 2019-01-16 21:54:42.432286: step 8022, loss = 0.67857 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:54:43.321979 ops/training.py:65 2019-01-16 21:54:43.321914: step 8023, loss = 0.71982 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:54:44.211959 ops/training.py:65 2019-01-16 21:54:44.211898: step 8024, loss = 0.70501 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:54:45.102538 ops/training.py:65 2019-01-16 21:54:45.102489: step 8025, loss = 0.68560 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:54:45.993765 ops/training.py:65 2019-01-16 21:54:45.993694: step 8026, loss = 0.69095 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:54:46.886233 ops/training.py:65 2019-01-16 21:54:46.886126: step 8027, loss = 0.71199 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:54:47.778245 ops/training.py:65 2019-01-16 21:54:47.778166: step 8028, loss = 0.69403 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:54:48.668332 ops/training.py:65 2019-01-16 21:54:48.668263: step 8029, loss = 0.67306 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:54:49.558184 ops/training.py:65 2019-01-16 21:54:49.558113: step 8030, loss = 0.67889 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:54:50.448270 ops/training.py:65 2019-01-16 21:54:50.448210: step 8031, loss = 0.69510 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:54:51.337868 ops/training.py:65 2019-01-16 21:54:51.337805: step 8032, loss = 0.70441 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:54:52.227780 ops/training.py:65 2019-01-16 21:54:52.227717: step 8033, loss = 0.72175 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:54:53.118263 ops/training.py:65 2019-01-16 21:54:53.118194: step 8034, loss = 0.69702 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:54:54.008091 ops/training.py:65 2019-01-16 21:54:54.008032: step 8035, loss = 0.70771 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:54:54.897860 ops/training.py:65 2019-01-16 21:54:54.897802: step 8036, loss = 0.73504 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:54:55.787683 ops/training.py:65 2019-01-16 21:54:55.787617: step 8037, loss = 0.69958 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:54:56.677446 ops/training.py:65 2019-01-16 21:54:56.677380: step 8038, loss = 0.68334 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:54:57.568720 ops/training.py:65 2019-01-16 21:54:57.568639: step 8039, loss = 0.70420 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:54:58.460752 ops/training.py:65 2019-01-16 21:54:58.460640: step 8040, loss = 0.70353 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:54:59.353973 ops/training.py:65 2019-01-16 21:54:59.353863: step 8041, loss = 0.70673 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:55:00.244625 ops/training.py:65 2019-01-16 21:55:00.244525: step 8042, loss = 0.67443 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:55:01.133744 ops/training.py:65 2019-01-16 21:55:01.133667: step 8043, loss = 0.69303 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:55:02.023515 ops/training.py:65 2019-01-16 21:55:02.023435: step 8044, loss = 0.72466 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:55:02.912981 ops/training.py:65 2019-01-16 21:55:02.912902: step 8045, loss = 0.68689 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:55:03.802953 ops/training.py:65 2019-01-16 21:55:03.802866: step 8046, loss = 0.72721 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:55:04.692653 ops/training.py:65 2019-01-16 21:55:04.692587: step 8047, loss = 0.70897 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:55:05.582371 ops/training.py:65 2019-01-16 21:55:05.582307: step 8048, loss = 0.70165 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:55:06.471182 ops/training.py:65 2019-01-16 21:55:06.471120: step 8049, loss = 0.71848 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:55:07.360162 ops/training.py:65 2019-01-16 21:55:07.360099: step 8050, loss = 0.73073 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:55:08.249809 ops/training.py:65 2019-01-16 21:55:08.249743: step 8051, loss = 0.69995 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:55:09.139443 ops/training.py:65 2019-01-16 21:55:09.139375: step 8052, loss = 0.77454 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:55:10.027624 ops/training.py:65 2019-01-16 21:55:10.027554: step 8053, loss = 0.70213 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:55:10.916957 ops/training.py:65 2019-01-16 21:55:10.916884: step 8054, loss = 0.69105 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:55:11.806936 ops/training.py:65 2019-01-16 21:55:11.806872: step 8055, loss = 0.67595 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:55:12.699618 ops/training.py:65 2019-01-16 21:55:12.699566: step 8056, loss = 0.73173 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:55:13.591150 ops/training.py:65 2019-01-16 21:55:13.591065: step 8057, loss = 0.71525 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:55:14.485089 ops/training.py:65 2019-01-16 21:55:14.484981: step 8058, loss = 0.74915 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:55:15.377627 ops/training.py:65 2019-01-16 21:55:15.377562: step 8059, loss = 0.71766 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:55:16.268128 ops/training.py:65 2019-01-16 21:55:16.268062: step 8060, loss = 0.75115 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:55:17.158132 ops/training.py:65 2019-01-16 21:55:17.158068: step 8061, loss = 0.71968 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:55:18.047280 ops/training.py:65 2019-01-16 21:55:18.047221: step 8062, loss = 0.70347 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:55:18.935859 ops/training.py:65 2019-01-16 21:55:18.935800: step 8063, loss = 0.71906 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:55:19.825059 ops/training.py:65 2019-01-16 21:55:19.825001: step 8064, loss = 0.73606 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:55:20.716643 ops/training.py:65 2019-01-16 21:55:20.716575: step 8065, loss = 0.75692 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:55:21.610591 ops/training.py:65 2019-01-16 21:55:21.610514: step 8066, loss = 0.70923 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:55:22.503720 ops/training.py:65 2019-01-16 21:55:22.503613: step 8067, loss = 0.71680 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:55:23.397757 ops/training.py:65 2019-01-16 21:55:23.397656: step 8068, loss = 0.70569 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:55:24.290908 ops/training.py:65 2019-01-16 21:55:24.290868: step 8069, loss = 0.70956 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:55:25.183605 ops/training.py:65 2019-01-16 21:55:25.183539: step 8070, loss = 0.75380 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:55:26.075781 ops/training.py:65 2019-01-16 21:55:26.075672: step 8071, loss = 0.68371 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:55:26.966521 ops/training.py:65 2019-01-16 21:55:26.966453: step 8072, loss = 0.67227 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:55:27.856976 ops/training.py:65 2019-01-16 21:55:27.856916: step 8073, loss = 0.70987 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:55:28.750314 ops/training.py:65 2019-01-16 21:55:28.750233: step 8074, loss = 0.70814 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:55:29.643967 ops/training.py:65 2019-01-16 21:55:29.643871: step 8075, loss = 0.67685 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:55:30.536858 ops/training.py:65 2019-01-16 21:55:30.536766: step 8076, loss = 0.69825 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:55:31.430398 ops/training.py:65 2019-01-16 21:55:31.430286: step 8077, loss = 0.68480 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:55:32.322707 ops/training.py:65 2019-01-16 21:55:32.322642: step 8078, loss = 0.66240 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:55:33.212543 ops/training.py:65 2019-01-16 21:55:33.212501: step 8079, loss = 0.72350 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:55:34.106155 ops/training.py:65 2019-01-16 21:55:34.106105: step 8080, loss = 0.75179 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:55:34.998853 ops/training.py:65 2019-01-16 21:55:34.998753: step 8081, loss = 0.69173 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:55:35.889197 ops/training.py:65 2019-01-16 21:55:35.889135: step 8082, loss = 0.66660 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:55:36.777869 ops/training.py:65 2019-01-16 21:55:36.777799: step 8083, loss = 0.68733 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:55:37.666245 ops/training.py:65 2019-01-16 21:55:37.666175: step 8084, loss = 0.71147 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:55:38.554981 ops/training.py:65 2019-01-16 21:55:38.554915: step 8085, loss = 0.70565 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:55:39.444365 ops/training.py:65 2019-01-16 21:55:39.444319: step 8086, loss = 0.69335 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:55:40.333622 ops/training.py:65 2019-01-16 21:55:40.333561: step 8087, loss = 0.71734 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:55:41.223343 ops/training.py:65 2019-01-16 21:55:41.223279: step 8088, loss = 0.69397 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:55:42.111589 ops/training.py:65 2019-01-16 21:55:42.111531: step 8089, loss = 0.67550 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:55:43.001297 ops/training.py:65 2019-01-16 21:55:43.001234: step 8090, loss = 0.68692 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:55:43.893288 ops/training.py:65 2019-01-16 21:55:43.893221: step 8091, loss = 0.72325 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:55:44.785717 ops/training.py:65 2019-01-16 21:55:44.785611: step 8092, loss = 0.69233 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:55:45.678047 ops/training.py:65 2019-01-16 21:55:45.677950: step 8093, loss = 0.71300 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:55:46.570137 ops/training.py:65 2019-01-16 21:55:46.570033: step 8094, loss = 0.70065 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:55:47.462306 ops/training.py:65 2019-01-16 21:55:47.462215: step 8095, loss = 0.70586 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:55:48.354676 ops/training.py:65 2019-01-16 21:55:48.354564: step 8096, loss = 0.69394 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:55:49.246580 ops/training.py:65 2019-01-16 21:55:49.246482: step 8097, loss = 0.69717 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:55:50.138399 ops/training.py:65 2019-01-16 21:55:50.138337: step 8098, loss = 0.68470 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:55:51.031747 ops/training.py:65 2019-01-16 21:55:51.031655: step 8099, loss = 0.68398 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:55:51.923851 ops/training.py:65 2019-01-16 21:55:51.923752: step 8100, loss = 0.70017 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:55:52.814370 ops/training.py:65 2019-01-16 21:55:52.814282: step 8101, loss = 0.69990 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:55:53.703600 ops/training.py:65 2019-01-16 21:55:53.703537: step 8102, loss = 0.66779 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 21:55:54.591974 ops/training.py:65 2019-01-16 21:55:54.591913: step 8103, loss = 0.69082 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:55:55.480477 ops/training.py:65 2019-01-16 21:55:55.480419: step 8104, loss = 0.71699 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:55:56.369226 ops/training.py:65 2019-01-16 21:55:56.369172: step 8105, loss = 0.68882 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:55:57.260059 ops/training.py:65 2019-01-16 21:55:57.259978: step 8106, loss = 0.71334 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:55:58.152505 ops/training.py:65 2019-01-16 21:55:58.152402: step 8107, loss = 0.71118 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:55:59.044275 ops/training.py:65 2019-01-16 21:55:59.044167: step 8108, loss = 0.72106 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:55:59.937738 ops/training.py:65 2019-01-16 21:55:59.937655: step 8109, loss = 0.70824 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:56:00.830309 ops/training.py:65 2019-01-16 21:56:00.830198: step 8110, loss = 0.70662 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:56:01.725836 ops/training.py:65 2019-01-16 21:56:01.725765: step 8111, loss = 0.69947 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:56:02.618934 ops/training.py:65 2019-01-16 21:56:02.618823: step 8112, loss = 0.70726 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:56:03.510912 ops/training.py:65 2019-01-16 21:56:03.510839: step 8113, loss = 0.68439 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:56:04.402510 ops/training.py:65 2019-01-16 21:56:04.402401: step 8114, loss = 0.67860 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:56:05.293944 ops/training.py:65 2019-01-16 21:56:05.293882: step 8115, loss = 0.68981 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:56:06.184009 ops/training.py:65 2019-01-16 21:56:06.183948: step 8116, loss = 0.71748 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:56:07.072702 ops/training.py:65 2019-01-16 21:56:07.072639: step 8117, loss = 0.73021 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:56:07.962076 ops/training.py:65 2019-01-16 21:56:07.962014: step 8118, loss = 0.71982 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:56:08.851906 ops/training.py:65 2019-01-16 21:56:08.851846: step 8119, loss = 0.64981 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:56:09.741384 ops/training.py:65 2019-01-16 21:56:09.741324: step 8120, loss = 0.65700 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:56:10.630048 ops/training.py:65 2019-01-16 21:56:10.629989: step 8121, loss = 0.68849 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:56:11.518200 ops/training.py:65 2019-01-16 21:56:11.518136: step 8122, loss = 0.66306 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:56:12.407952 ops/training.py:65 2019-01-16 21:56:12.407890: step 8123, loss = 0.73016 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:56:13.297368 ops/training.py:65 2019-01-16 21:56:13.297298: step 8124, loss = 0.71404 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:56:14.186368 ops/training.py:65 2019-01-16 21:56:14.186304: step 8125, loss = 0.68633 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:56:15.076468 ops/training.py:65 2019-01-16 21:56:15.076406: step 8126, loss = 0.71877 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:56:15.967685 ops/training.py:65 2019-01-16 21:56:15.967622: step 8127, loss = 0.69106 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:56:16.857439 ops/training.py:65 2019-01-16 21:56:16.857376: step 8128, loss = 0.68524 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:56:17.746836 ops/training.py:65 2019-01-16 21:56:17.746775: step 8129, loss = 0.69808 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:56:18.635924 ops/training.py:65 2019-01-16 21:56:18.635871: step 8130, loss = 0.65792 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.75
I2992 2019-01-16 21:56:19.525543 ops/training.py:65 2019-01-16 21:56:19.525479: step 8131, loss = 0.70158 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:56:20.414228 ops/training.py:65 2019-01-16 21:56:20.414172: step 8132, loss = 0.67281 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:56:21.303603 ops/training.py:65 2019-01-16 21:56:21.303552: step 8133, loss = 0.69344 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:56:22.192533 ops/training.py:65 2019-01-16 21:56:22.192480: step 8134, loss = 0.70919 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:56:23.082103 ops/training.py:65 2019-01-16 21:56:23.082041: step 8135, loss = 0.66545 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:56:23.971562 ops/training.py:65 2019-01-16 21:56:23.971497: step 8136, loss = 0.69761 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:56:24.859862 ops/training.py:65 2019-01-16 21:56:24.859800: step 8137, loss = 0.68097 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:56:25.749275 ops/training.py:65 2019-01-16 21:56:25.749210: step 8138, loss = 0.67917 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:56:26.638470 ops/training.py:65 2019-01-16 21:56:26.638407: step 8139, loss = 0.71751 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:56:27.528292 ops/training.py:65 2019-01-16 21:56:27.528233: step 8140, loss = 0.68836 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:56:28.417256 ops/training.py:65 2019-01-16 21:56:28.417195: step 8141, loss = 0.68787 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:56:29.306916 ops/training.py:65 2019-01-16 21:56:29.306851: step 8142, loss = 0.67225 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:56:30.195833 ops/training.py:65 2019-01-16 21:56:30.195775: step 8143, loss = 0.69571 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:56:31.084138 ops/training.py:65 2019-01-16 21:56:31.084081: step 8144, loss = 0.72729 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:56:31.973176 ops/training.py:65 2019-01-16 21:56:31.973118: step 8145, loss = 0.66185 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:56:32.862409 ops/training.py:65 2019-01-16 21:56:32.862353: step 8146, loss = 0.68729 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:56:33.752070 ops/training.py:65 2019-01-16 21:56:33.752004: step 8147, loss = 0.69461 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:56:34.641755 ops/training.py:65 2019-01-16 21:56:34.641688: step 8148, loss = 0.75220 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:56:35.531415 ops/training.py:65 2019-01-16 21:56:35.531350: step 8149, loss = 0.70872 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:56:36.420552 ops/training.py:65 2019-01-16 21:56:36.420493: step 8150, loss = 0.73791 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:56:37.309067 ops/training.py:65 2019-01-16 21:56:37.309009: step 8151, loss = 0.65853 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:56:38.198578 ops/training.py:65 2019-01-16 21:56:38.198514: step 8152, loss = 0.71975 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:56:39.087157 ops/training.py:65 2019-01-16 21:56:39.087095: step 8153, loss = 0.77272 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:56:39.975357 ops/training.py:65 2019-01-16 21:56:39.975296: step 8154, loss = 0.70993 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:56:40.864207 ops/training.py:65 2019-01-16 21:56:40.864144: step 8155, loss = 0.77130 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:56:41.755405 ops/training.py:65 2019-01-16 21:56:41.755340: step 8156, loss = 0.81994 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 21:56:42.648016 ops/training.py:65 2019-01-16 21:56:42.647927: step 8157, loss = 0.80434 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:56:43.540085 ops/training.py:65 2019-01-16 21:56:43.539976: step 8158, loss = 0.68008 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:56:44.432448 ops/training.py:65 2019-01-16 21:56:44.432353: step 8159, loss = 0.72862 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:56:45.324653 ops/training.py:65 2019-01-16 21:56:45.324582: step 8160, loss = 0.70110 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:56:46.217434 ops/training.py:65 2019-01-16 21:56:46.217328: step 8161, loss = 0.72526 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:56:47.110017 ops/training.py:65 2019-01-16 21:56:47.109894: step 8162, loss = 0.70230 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:56:48.001958 ops/training.py:65 2019-01-16 21:56:48.001895: step 8163, loss = 0.75196 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:56:48.891937 ops/training.py:65 2019-01-16 21:56:48.891878: step 8164, loss = 0.67664 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:56:49.781272 ops/training.py:65 2019-01-16 21:56:49.781206: step 8165, loss = 0.68524 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:56:50.670823 ops/training.py:65 2019-01-16 21:56:50.670762: step 8166, loss = 0.71864 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:56:51.560324 ops/training.py:65 2019-01-16 21:56:51.560266: step 8167, loss = 0.73429 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:56:52.449879 ops/training.py:65 2019-01-16 21:56:52.449815: step 8168, loss = 0.73230 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:56:53.339133 ops/training.py:65 2019-01-16 21:56:53.339072: step 8169, loss = 0.69375 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:56:54.228864 ops/training.py:65 2019-01-16 21:56:54.228806: step 8170, loss = 0.69028 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:56:55.118313 ops/training.py:65 2019-01-16 21:56:55.118255: step 8171, loss = 0.71175 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:56:56.007709 ops/training.py:65 2019-01-16 21:56:56.007649: step 8172, loss = 0.74086 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:56:56.897270 ops/training.py:65 2019-01-16 21:56:56.897209: step 8173, loss = 0.72302 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:56:57.786289 ops/training.py:65 2019-01-16 21:56:57.786222: step 8174, loss = 0.75674 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:56:58.675747 ops/training.py:65 2019-01-16 21:56:58.675683: step 8175, loss = 0.72231 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:56:59.564392 ops/training.py:65 2019-01-16 21:56:59.564327: step 8176, loss = 0.70156 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:57:00.453762 ops/training.py:65 2019-01-16 21:57:00.453696: step 8177, loss = 0.69725 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:57:01.344199 ops/training.py:65 2019-01-16 21:57:01.344120: step 8178, loss = 0.68498 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:57:02.233744 ops/training.py:65 2019-01-16 21:57:02.233670: step 8179, loss = 0.70687 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:57:03.123970 ops/training.py:65 2019-01-16 21:57:03.123892: step 8180, loss = 0.70336 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:57:04.013623 ops/training.py:65 2019-01-16 21:57:04.013554: step 8181, loss = 0.74349 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:57:04.902949 ops/training.py:65 2019-01-16 21:57:04.902889: step 8182, loss = 0.66847 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:57:05.792124 ops/training.py:65 2019-01-16 21:57:05.792062: step 8183, loss = 0.74991 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:57:06.680893 ops/training.py:65 2019-01-16 21:57:06.680828: step 8184, loss = 0.75862 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:57:07.571136 ops/training.py:65 2019-01-16 21:57:07.571068: step 8185, loss = 0.68579 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:57:08.461295 ops/training.py:65 2019-01-16 21:57:08.461235: step 8186, loss = 0.67734 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:57:09.350903 ops/training.py:65 2019-01-16 21:57:09.350850: step 8187, loss = 0.70644 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:57:10.239876 ops/training.py:65 2019-01-16 21:57:10.239822: step 8188, loss = 0.77768 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:57:11.128352 ops/training.py:65 2019-01-16 21:57:11.128298: step 8189, loss = 0.75052 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:57:12.018412 ops/training.py:65 2019-01-16 21:57:12.018347: step 8190, loss = 0.77734 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:57:12.908512 ops/training.py:65 2019-01-16 21:57:12.908458: step 8191, loss = 0.73838 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:57:13.797251 ops/training.py:65 2019-01-16 21:57:13.797186: step 8192, loss = 0.73007 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:57:14.689127 ops/training.py:65 2019-01-16 21:57:14.689045: step 8193, loss = 0.72808 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:57:15.582337 ops/training.py:65 2019-01-16 21:57:15.582238: step 8194, loss = 0.70579 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:57:16.474010 ops/training.py:65 2019-01-16 21:57:16.473909: step 8195, loss = 0.68274 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:57:17.365746 ops/training.py:65 2019-01-16 21:57:17.365632: step 8196, loss = 0.81358 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:57:18.256093 ops/training.py:65 2019-01-16 21:57:18.255982: step 8197, loss = 0.67131 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:57:19.148226 ops/training.py:65 2019-01-16 21:57:19.148110: step 8198, loss = 0.66470 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:57:20.038769 ops/training.py:65 2019-01-16 21:57:20.038688: step 8199, loss = 0.77335 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:57:20.928789 ops/training.py:65 2019-01-16 21:57:20.928709: step 8200, loss = 0.62946 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 21:57:21.818793 ops/training.py:65 2019-01-16 21:57:21.818724: step 8201, loss = 0.75594 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:57:22.709210 ops/training.py:65 2019-01-16 21:57:22.709141: step 8202, loss = 0.69328 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:57:23.599457 ops/training.py:65 2019-01-16 21:57:23.599387: step 8203, loss = 0.74568 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:57:24.489151 ops/training.py:65 2019-01-16 21:57:24.489087: step 8204, loss = 0.77076 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:57:25.378857 ops/training.py:65 2019-01-16 21:57:25.378796: step 8205, loss = 0.70989 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:57:26.268001 ops/training.py:65 2019-01-16 21:57:26.267944: step 8206, loss = 0.72380 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:57:27.160930 ops/training.py:65 2019-01-16 21:57:27.160852: step 8207, loss = 0.73227 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:57:28.054419 ops/training.py:65 2019-01-16 21:57:28.054309: step 8208, loss = 0.66427 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:57:28.947426 ops/training.py:65 2019-01-16 21:57:28.947322: step 8209, loss = 0.74276 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:57:29.840333 ops/training.py:65 2019-01-16 21:57:29.840267: step 8210, loss = 0.73276 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:57:30.730900 ops/training.py:65 2019-01-16 21:57:30.730835: step 8211, loss = 0.66769 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:57:31.621243 ops/training.py:65 2019-01-16 21:57:31.621180: step 8212, loss = 0.69301 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:57:32.511436 ops/training.py:65 2019-01-16 21:57:32.511373: step 8213, loss = 0.67256 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:57:33.401643 ops/training.py:65 2019-01-16 21:57:33.401570: step 8214, loss = 0.69835 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:57:34.291465 ops/training.py:65 2019-01-16 21:57:34.291404: step 8215, loss = 0.73324 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:57:35.181225 ops/training.py:65 2019-01-16 21:57:35.181162: step 8216, loss = 0.67660 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:57:36.071477 ops/training.py:65 2019-01-16 21:57:36.071415: step 8217, loss = 0.67863 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:57:36.961482 ops/training.py:65 2019-01-16 21:57:36.961417: step 8218, loss = 0.68520 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:57:37.850799 ops/training.py:65 2019-01-16 21:57:37.850740: step 8219, loss = 0.67693 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:57:38.740931 ops/training.py:65 2019-01-16 21:57:38.740865: step 8220, loss = 0.71178 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:57:39.629746 ops/training.py:65 2019-01-16 21:57:39.629681: step 8221, loss = 0.69514 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:57:40.519587 ops/training.py:65 2019-01-16 21:57:40.519518: step 8222, loss = 0.70012 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:57:41.408555 ops/training.py:65 2019-01-16 21:57:41.408487: step 8223, loss = 0.67789 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:57:42.298009 ops/training.py:65 2019-01-16 21:57:42.297940: step 8224, loss = 0.71136 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:57:43.187111 ops/training.py:65 2019-01-16 21:57:43.187045: step 8225, loss = 0.68579 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:57:44.077286 ops/training.py:65 2019-01-16 21:57:44.077217: step 8226, loss = 0.68175 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:57:44.966904 ops/training.py:65 2019-01-16 21:57:44.966839: step 8227, loss = 0.68459 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:57:45.858649 ops/training.py:65 2019-01-16 21:57:45.858581: step 8228, loss = 0.66213 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:57:46.751332 ops/training.py:65 2019-01-16 21:57:46.751221: step 8229, loss = 0.69949 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:57:47.642890 ops/training.py:65 2019-01-16 21:57:47.642824: step 8230, loss = 0.69622 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:57:48.532627 ops/training.py:65 2019-01-16 21:57:48.532566: step 8231, loss = 0.70233 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:57:49.422042 ops/training.py:65 2019-01-16 21:57:49.421977: step 8232, loss = 0.72661 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:57:50.311313 ops/training.py:65 2019-01-16 21:57:50.311250: step 8233, loss = 0.71348 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:57:51.201378 ops/training.py:65 2019-01-16 21:57:51.201300: step 8234, loss = 0.69255 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:57:52.093003 ops/training.py:65 2019-01-16 21:57:52.092903: step 8235, loss = 0.68358 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:57:52.985988 ops/training.py:65 2019-01-16 21:57:52.985884: step 8236, loss = 0.69154 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:57:53.879131 ops/training.py:65 2019-01-16 21:57:53.879027: step 8237, loss = 0.69189 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:57:54.772992 ops/training.py:65 2019-01-16 21:57:54.772926: step 8238, loss = 0.68242 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:57:55.662837 ops/training.py:65 2019-01-16 21:57:55.662777: step 8239, loss = 0.69376 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:57:56.552070 ops/training.py:65 2019-01-16 21:57:56.552002: step 8240, loss = 0.71372 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:57:57.442651 ops/training.py:65 2019-01-16 21:57:57.442578: step 8241, loss = 0.70698 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:57:58.335574 ops/training.py:65 2019-01-16 21:57:58.335499: step 8242, loss = 0.69076 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:57:59.229452 ops/training.py:65 2019-01-16 21:57:59.229336: step 8243, loss = 0.68558 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:58:00.120938 ops/training.py:65 2019-01-16 21:58:00.120879: step 8244, loss = 0.70272 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:58:01.011621 ops/training.py:65 2019-01-16 21:58:01.011553: step 8245, loss = 0.69278 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:58:01.902181 ops/training.py:65 2019-01-16 21:58:01.902110: step 8246, loss = 0.67764 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 21:58:02.791824 ops/training.py:65 2019-01-16 21:58:02.791770: step 8247, loss = 0.68720 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:58:03.681807 ops/training.py:65 2019-01-16 21:58:03.681731: step 8248, loss = 0.72659 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:58:04.571661 ops/training.py:65 2019-01-16 21:58:04.571594: step 8249, loss = 0.69786 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:58:05.461875 ops/training.py:65 2019-01-16 21:58:05.461809: step 8250, loss = 0.67574 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:58:06.351408 ops/training.py:65 2019-01-16 21:58:06.351336: step 8251, loss = 0.70166 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:58:07.240814 ops/training.py:65 2019-01-16 21:58:07.240749: step 8252, loss = 0.69314 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:58:08.129976 ops/training.py:65 2019-01-16 21:58:08.129917: step 8253, loss = 0.74197 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:58:09.019187 ops/training.py:65 2019-01-16 21:58:09.019124: step 8254, loss = 0.67508 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:58:09.909652 ops/training.py:65 2019-01-16 21:58:09.909589: step 8255, loss = 0.66213 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:58:10.799323 ops/training.py:65 2019-01-16 21:58:10.799261: step 8256, loss = 0.65996 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:58:11.689295 ops/training.py:65 2019-01-16 21:58:11.689233: step 8257, loss = 0.64983 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:58:12.579080 ops/training.py:65 2019-01-16 21:58:12.579018: step 8258, loss = 0.71114 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:58:13.467453 ops/training.py:65 2019-01-16 21:58:13.467381: step 8259, loss = 0.71442 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:58:14.357280 ops/training.py:65 2019-01-16 21:58:14.357217: step 8260, loss = 0.67319 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:58:15.247397 ops/training.py:65 2019-01-16 21:58:15.247333: step 8261, loss = 0.65193 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:58:16.137871 ops/training.py:65 2019-01-16 21:58:16.137808: step 8262, loss = 0.69187 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:58:17.027371 ops/training.py:65 2019-01-16 21:58:17.027307: step 8263, loss = 0.72003 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:58:17.916888 ops/training.py:65 2019-01-16 21:58:17.916825: step 8264, loss = 0.69125 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:58:18.806451 ops/training.py:65 2019-01-16 21:58:18.806389: step 8265, loss = 0.68552 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:58:19.696253 ops/training.py:65 2019-01-16 21:58:19.696192: step 8266, loss = 0.68512 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:58:20.585263 ops/training.py:65 2019-01-16 21:58:20.585204: step 8267, loss = 0.69335 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:58:21.474401 ops/training.py:65 2019-01-16 21:58:21.474337: step 8268, loss = 0.75272 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:58:22.363496 ops/training.py:65 2019-01-16 21:58:22.363429: step 8269, loss = 0.69189 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:58:23.253574 ops/training.py:65 2019-01-16 21:58:23.253505: step 8270, loss = 0.70309 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:58:24.142379 ops/training.py:65 2019-01-16 21:58:24.142313: step 8271, loss = 0.68987 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:58:25.031840 ops/training.py:65 2019-01-16 21:58:25.031782: step 8272, loss = 0.71711 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:58:25.920883 ops/training.py:65 2019-01-16 21:58:25.920830: step 8273, loss = 0.73854 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:58:26.811745 ops/training.py:65 2019-01-16 21:58:26.811685: step 8274, loss = 0.69632 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:58:27.701595 ops/training.py:65 2019-01-16 21:58:27.701532: step 8275, loss = 0.69799 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:58:28.591234 ops/training.py:65 2019-01-16 21:58:28.591167: step 8276, loss = 0.73900 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:58:29.480749 ops/training.py:65 2019-01-16 21:58:29.480690: step 8277, loss = 0.74150 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:58:30.370956 ops/training.py:65 2019-01-16 21:58:30.370892: step 8278, loss = 0.71867 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:58:31.260742 ops/training.py:65 2019-01-16 21:58:31.260685: step 8279, loss = 0.72100 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:58:32.149671 ops/training.py:65 2019-01-16 21:58:32.149610: step 8280, loss = 0.74505 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:58:33.039061 ops/training.py:65 2019-01-16 21:58:33.038999: step 8281, loss = 0.73862 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:58:33.929141 ops/training.py:65 2019-01-16 21:58:33.929072: step 8282, loss = 0.70948 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:58:34.819457 ops/training.py:65 2019-01-16 21:58:34.819387: step 8283, loss = 0.69469 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:58:35.712988 ops/training.py:65 2019-01-16 21:58:35.712883: step 8284, loss = 0.65385 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 21:58:36.604925 ops/training.py:65 2019-01-16 21:58:36.604863: step 8285, loss = 0.71751 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:58:37.495925 ops/training.py:65 2019-01-16 21:58:37.495859: step 8286, loss = 0.70652 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:58:38.386016 ops/training.py:65 2019-01-16 21:58:38.385938: step 8287, loss = 0.72071 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:58:39.278407 ops/training.py:65 2019-01-16 21:58:39.278295: step 8288, loss = 0.72713 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:58:40.171581 ops/training.py:65 2019-01-16 21:58:40.171509: step 8289, loss = 0.68494 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:58:41.064209 ops/training.py:65 2019-01-16 21:58:41.064106: step 8290, loss = 0.70834 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:58:41.954933 ops/training.py:65 2019-01-16 21:58:41.954873: step 8291, loss = 0.70878 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:58:42.843684 ops/training.py:65 2019-01-16 21:58:42.843620: step 8292, loss = 0.67214 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:58:43.733496 ops/training.py:65 2019-01-16 21:58:43.733425: step 8293, loss = 0.70498 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:58:44.623457 ops/training.py:65 2019-01-16 21:58:44.623392: step 8294, loss = 0.66841 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:58:45.513717 ops/training.py:65 2019-01-16 21:58:45.513654: step 8295, loss = 0.72244 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:58:46.403824 ops/training.py:65 2019-01-16 21:58:46.403760: step 8296, loss = 0.70192 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:58:47.294232 ops/training.py:65 2019-01-16 21:58:47.294160: step 8297, loss = 0.68277 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:58:48.185870 ops/training.py:65 2019-01-16 21:58:48.185760: step 8298, loss = 0.68938 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:58:49.078167 ops/training.py:65 2019-01-16 21:58:49.078056: step 8299, loss = 0.69163 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:58:49.971864 ops/training.py:65 2019-01-16 21:58:49.971749: step 8300, loss = 0.68925 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:58:50.862659 ops/training.py:65 2019-01-16 21:58:50.862565: step 8301, loss = 0.71498 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:58:51.752963 ops/training.py:65 2019-01-16 21:58:51.752898: step 8302, loss = 0.71291 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:58:52.642555 ops/training.py:65 2019-01-16 21:58:52.642488: step 8303, loss = 0.68529 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:58:53.532867 ops/training.py:65 2019-01-16 21:58:53.532797: step 8304, loss = 0.70349 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:58:54.425604 ops/training.py:65 2019-01-16 21:58:54.425503: step 8305, loss = 0.69022 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:58:55.317292 ops/training.py:65 2019-01-16 21:58:55.317227: step 8306, loss = 0.72063 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:58:56.207940 ops/training.py:65 2019-01-16 21:58:56.207870: step 8307, loss = 0.67916 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:58:57.100688 ops/training.py:65 2019-01-16 21:58:57.100581: step 8308, loss = 0.70102 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:58:57.992596 ops/training.py:65 2019-01-16 21:58:57.992482: step 8309, loss = 0.67275 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:58:58.885354 ops/training.py:65 2019-01-16 21:58:58.885242: step 8310, loss = 0.69681 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:58:59.777372 ops/training.py:65 2019-01-16 21:58:59.777305: step 8311, loss = 0.70905 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:59:00.671100 ops/training.py:65 2019-01-16 21:59:00.670990: step 8312, loss = 0.68230 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:59:01.561639 ops/training.py:65 2019-01-16 21:59:01.561576: step 8313, loss = 0.72008 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:59:02.451449 ops/training.py:65 2019-01-16 21:59:02.451383: step 8314, loss = 0.69213 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:59:03.342830 ops/training.py:65 2019-01-16 21:59:03.342754: step 8315, loss = 0.68509 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:59:04.235094 ops/training.py:65 2019-01-16 21:59:04.234990: step 8316, loss = 0.69186 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:59:05.127118 ops/training.py:65 2019-01-16 21:59:05.127055: step 8317, loss = 0.68850 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:59:06.017504 ops/training.py:65 2019-01-16 21:59:06.017444: step 8318, loss = 0.69135 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:59:06.906590 ops/training.py:65 2019-01-16 21:59:06.906529: step 8319, loss = 0.65739 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 21:59:07.796827 ops/training.py:65 2019-01-16 21:59:07.796761: step 8320, loss = 0.69769 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:59:08.686911 ops/training.py:65 2019-01-16 21:59:08.686844: step 8321, loss = 0.70530 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:59:09.577177 ops/training.py:65 2019-01-16 21:59:09.577114: step 8322, loss = 0.71485 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:59:10.467113 ops/training.py:65 2019-01-16 21:59:10.467051: step 8323, loss = 0.73530 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:59:11.357206 ops/training.py:65 2019-01-16 21:59:11.357141: step 8324, loss = 0.67862 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:59:12.247377 ops/training.py:65 2019-01-16 21:59:12.247316: step 8325, loss = 0.73390 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:59:13.136209 ops/training.py:65 2019-01-16 21:59:13.136138: step 8326, loss = 0.71148 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:59:14.025632 ops/training.py:65 2019-01-16 21:59:14.025570: step 8327, loss = 0.73980 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:59:14.915389 ops/training.py:65 2019-01-16 21:59:14.915326: step 8328, loss = 0.73976 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:59:15.805524 ops/training.py:65 2019-01-16 21:59:15.805460: step 8329, loss = 0.71813 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:59:16.695085 ops/training.py:65 2019-01-16 21:59:16.695020: step 8330, loss = 0.68523 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:59:17.584994 ops/training.py:65 2019-01-16 21:59:17.584928: step 8331, loss = 0.72115 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:59:18.474231 ops/training.py:65 2019-01-16 21:59:18.474167: step 8332, loss = 0.70849 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:59:19.363502 ops/training.py:65 2019-01-16 21:59:19.363443: step 8333, loss = 0.68442 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:59:20.253200 ops/training.py:65 2019-01-16 21:59:20.253139: step 8334, loss = 0.73729 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:59:21.143630 ops/training.py:65 2019-01-16 21:59:21.143561: step 8335, loss = 0.69504 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:59:22.036276 ops/training.py:65 2019-01-16 21:59:22.036174: step 8336, loss = 0.69821 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:59:22.928103 ops/training.py:65 2019-01-16 21:59:22.928041: step 8337, loss = 0.71159 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:59:23.817875 ops/training.py:65 2019-01-16 21:59:23.817806: step 8338, loss = 0.68318 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 21:59:24.707419 ops/training.py:65 2019-01-16 21:59:24.707357: step 8339, loss = 0.69668 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:59:25.596202 ops/training.py:65 2019-01-16 21:59:25.596142: step 8340, loss = 0.71302 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:59:26.486870 ops/training.py:65 2019-01-16 21:59:26.486801: step 8341, loss = 0.73871 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:59:27.379196 ops/training.py:65 2019-01-16 21:59:27.379086: step 8342, loss = 0.70361 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:59:28.270898 ops/training.py:65 2019-01-16 21:59:28.270837: step 8343, loss = 0.76931 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:59:29.160768 ops/training.py:65 2019-01-16 21:59:29.160705: step 8344, loss = 0.70985 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:59:30.050298 ops/training.py:65 2019-01-16 21:59:30.050235: step 8345, loss = 0.73525 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:59:30.938767 ops/training.py:65 2019-01-16 21:59:30.938699: step 8346, loss = 0.74634 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:59:31.828051 ops/training.py:65 2019-01-16 21:59:31.827990: step 8347, loss = 0.78232 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:59:32.717948 ops/training.py:65 2019-01-16 21:59:32.717888: step 8348, loss = 0.72061 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:59:33.607847 ops/training.py:65 2019-01-16 21:59:33.607782: step 8349, loss = 0.75934 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 21:59:34.496260 ops/training.py:65 2019-01-16 21:59:34.496203: step 8350, loss = 0.68562 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:59:35.388702 ops/training.py:65 2019-01-16 21:59:35.388623: step 8351, loss = 0.74991 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:59:36.281694 ops/training.py:65 2019-01-16 21:59:36.281587: step 8352, loss = 0.69655 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:59:37.172661 ops/training.py:65 2019-01-16 21:59:37.172595: step 8353, loss = 0.65715 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 21:59:38.060984 ops/training.py:65 2019-01-16 21:59:38.060922: step 8354, loss = 0.72110 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:59:38.950083 ops/training.py:65 2019-01-16 21:59:38.950029: step 8355, loss = 0.69560 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 21:59:39.842156 ops/training.py:65 2019-01-16 21:59:39.842088: step 8356, loss = 0.75561 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:59:40.735408 ops/training.py:65 2019-01-16 21:59:40.735305: step 8357, loss = 0.69783 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:59:41.627631 ops/training.py:65 2019-01-16 21:59:41.627568: step 8358, loss = 0.71809 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:59:42.517403 ops/training.py:65 2019-01-16 21:59:42.517341: step 8359, loss = 0.62620 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 21:59:43.407402 ops/training.py:65 2019-01-16 21:59:43.407333: step 8360, loss = 0.70519 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:59:44.296915 ops/training.py:65 2019-01-16 21:59:44.296851: step 8361, loss = 0.67241 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:59:45.187034 ops/training.py:65 2019-01-16 21:59:45.186972: step 8362, loss = 0.69563 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:59:46.077221 ops/training.py:65 2019-01-16 21:59:46.077153: step 8363, loss = 0.71396 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:59:46.966456 ops/training.py:65 2019-01-16 21:59:46.966392: step 8364, loss = 0.69426 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:59:47.855682 ops/training.py:65 2019-01-16 21:59:47.855615: step 8365, loss = 0.74517 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 21:59:48.745696 ops/training.py:65 2019-01-16 21:59:48.745630: step 8366, loss = 0.68675 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:59:49.635364 ops/training.py:65 2019-01-16 21:59:49.635300: step 8367, loss = 0.71741 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 21:59:50.523863 ops/training.py:65 2019-01-16 21:59:50.523801: step 8368, loss = 0.68058 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:59:51.413963 ops/training.py:65 2019-01-16 21:59:51.413916: step 8369, loss = 0.71837 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 21:59:52.304854 ops/training.py:65 2019-01-16 21:59:52.304789: step 8370, loss = 0.69610 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:59:53.197719 ops/training.py:65 2019-01-16 21:59:53.197623: step 8371, loss = 0.69098 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:59:54.090934 ops/training.py:65 2019-01-16 21:59:54.090821: step 8372, loss = 0.68071 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:59:54.982291 ops/training.py:65 2019-01-16 21:59:54.982224: step 8373, loss = 0.67745 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 21:59:55.872243 ops/training.py:65 2019-01-16 21:59:55.872174: step 8374, loss = 0.69931 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 21:59:56.762409 ops/training.py:65 2019-01-16 21:59:56.762346: step 8375, loss = 0.70051 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 21:59:57.651975 ops/training.py:65 2019-01-16 21:59:57.651913: step 8376, loss = 0.69372 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 21:59:58.541604 ops/training.py:65 2019-01-16 21:59:58.541538: step 8377, loss = 0.69521 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 21:59:59.431616 ops/training.py:65 2019-01-16 21:59:59.431548: step 8378, loss = 0.70167 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:00:00.320686 ops/training.py:65 2019-01-16 22:00:00.320624: step 8379, loss = 0.71955 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:00:01.210346 ops/training.py:65 2019-01-16 22:00:01.210278: step 8380, loss = 0.69381 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:00:02.101045 ops/training.py:65 2019-01-16 22:00:02.100986: step 8381, loss = 0.72296 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:00:02.992902 ops/training.py:65 2019-01-16 22:00:02.992830: step 8382, loss = 0.71102 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:00:03.885119 ops/training.py:65 2019-01-16 22:00:03.885017: step 8383, loss = 0.69666 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:00:04.775984 ops/training.py:65 2019-01-16 22:00:04.775916: step 8384, loss = 0.70063 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:00:05.664724 ops/training.py:65 2019-01-16 22:00:05.664658: step 8385, loss = 0.67603 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:00:06.555828 ops/training.py:65 2019-01-16 22:00:06.555789: step 8386, loss = 0.70380 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:00:07.447714 ops/training.py:65 2019-01-16 22:00:07.447658: step 8387, loss = 0.68720 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:00:08.340335 ops/training.py:65 2019-01-16 22:00:08.340222: step 8388, loss = 0.67987 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:00:09.232898 ops/training.py:65 2019-01-16 22:00:09.232830: step 8389, loss = 0.68005 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:00:10.123030 ops/training.py:65 2019-01-16 22:00:10.122953: step 8390, loss = 0.68640 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:00:11.012478 ops/training.py:65 2019-01-16 22:00:11.012386: step 8391, loss = 0.68754 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:00:11.904996 ops/training.py:65 2019-01-16 22:00:11.904906: step 8392, loss = 0.65790 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 22:00:12.797542 ops/training.py:65 2019-01-16 22:00:12.797486: step 8393, loss = 0.68659 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:00:13.689756 ops/training.py:65 2019-01-16 22:00:13.689722: step 8394, loss = 0.67608 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:00:14.582003 ops/training.py:65 2019-01-16 22:00:14.581948: step 8395, loss = 0.67323 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:00:15.474587 ops/training.py:65 2019-01-16 22:00:15.474496: step 8396, loss = 0.70251 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:00:16.366774 ops/training.py:65 2019-01-16 22:00:16.366659: step 8397, loss = 0.66862 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:00:17.257091 ops/training.py:65 2019-01-16 22:00:17.257024: step 8398, loss = 0.73925 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 22:00:18.146126 ops/training.py:65 2019-01-16 22:00:18.146055: step 8399, loss = 0.70194 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:00:19.036579 ops/training.py:65 2019-01-16 22:00:19.036528: step 8400, loss = 0.70838 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:00:19.926672 ops/training.py:65 2019-01-16 22:00:19.926631: step 8401, loss = 0.76684 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 22:00:20.816195 ops/training.py:65 2019-01-16 22:00:20.816159: step 8402, loss = 0.66223 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:00:21.706239 ops/training.py:65 2019-01-16 22:00:21.706208: step 8403, loss = 0.69914 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:00:22.598106 ops/training.py:65 2019-01-16 22:00:22.598075: step 8404, loss = 0.69093 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:00:23.489697 ops/training.py:65 2019-01-16 22:00:23.489635: step 8405, loss = 0.70693 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:00:24.379500 ops/training.py:65 2019-01-16 22:00:24.379456: step 8406, loss = 0.68449 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:00:25.268249 ops/training.py:65 2019-01-16 22:00:25.268213: step 8407, loss = 0.69671 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:00:26.157497 ops/training.py:65 2019-01-16 22:00:26.157461: step 8408, loss = 0.67795 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:00:27.047284 ops/training.py:65 2019-01-16 22:00:27.047250: step 8409, loss = 0.72510 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:00:27.939162 ops/training.py:65 2019-01-16 22:00:27.939130: step 8410, loss = 0.72638 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:00:28.831738 ops/training.py:65 2019-01-16 22:00:28.831699: step 8411, loss = 0.71664 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:00:29.723296 ops/training.py:65 2019-01-16 22:00:29.723226: step 8412, loss = 0.69351 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:00:30.614013 ops/training.py:65 2019-01-16 22:00:30.613922: step 8413, loss = 0.68678 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:00:31.504751 ops/training.py:65 2019-01-16 22:00:31.504704: step 8414, loss = 0.70948 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:00:32.393502 ops/training.py:65 2019-01-16 22:00:32.393422: step 8415, loss = 0.68363 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:00:33.283781 ops/training.py:65 2019-01-16 22:00:33.283733: step 8416, loss = 0.72391 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:00:34.173753 ops/training.py:65 2019-01-16 22:00:34.173716: step 8417, loss = 0.68911 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:00:35.063600 ops/training.py:65 2019-01-16 22:00:35.063557: step 8418, loss = 0.73673 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:00:35.952702 ops/training.py:65 2019-01-16 22:00:35.952661: step 8419, loss = 0.69583 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:00:36.842202 ops/training.py:65 2019-01-16 22:00:36.842157: step 8420, loss = 0.69691 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:00:37.731157 ops/training.py:65 2019-01-16 22:00:37.731079: step 8421, loss = 0.69112 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:00:38.620226 ops/training.py:65 2019-01-16 22:00:38.620171: step 8422, loss = 0.68443 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:00:39.510326 ops/training.py:65 2019-01-16 22:00:39.510282: step 8423, loss = 0.72510 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.21875
I2992 2019-01-16 22:00:40.399114 ops/training.py:65 2019-01-16 22:00:40.399064: step 8424, loss = 0.68231 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:00:41.288465 ops/training.py:65 2019-01-16 22:00:41.288427: step 8425, loss = 0.69006 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:00:42.177881 ops/training.py:65 2019-01-16 22:00:42.177838: step 8426, loss = 0.72052 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:00:43.067147 ops/training.py:65 2019-01-16 22:00:43.067099: step 8427, loss = 0.71263 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:00:43.956570 ops/training.py:65 2019-01-16 22:00:43.956525: step 8428, loss = 0.70218 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:00:44.847425 ops/training.py:65 2019-01-16 22:00:44.847387: step 8429, loss = 0.68757 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:00:45.738404 ops/training.py:65 2019-01-16 22:00:45.738368: step 8430, loss = 0.69483 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:00:46.630410 ops/training.py:65 2019-01-16 22:00:46.630354: step 8431, loss = 0.69028 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:00:47.520808 ops/training.py:65 2019-01-16 22:00:47.520766: step 8432, loss = 0.69947 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:00:48.410399 ops/training.py:65 2019-01-16 22:00:48.410324: step 8433, loss = 0.69153 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:00:49.302941 ops/training.py:65 2019-01-16 22:00:49.302894: step 8434, loss = 0.69046 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:00:50.195819 ops/training.py:65 2019-01-16 22:00:50.195788: step 8435, loss = 0.67056 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:00:51.087191 ops/training.py:65 2019-01-16 22:00:51.087135: step 8436, loss = 0.68898 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:00:51.978922 ops/training.py:65 2019-01-16 22:00:51.978866: step 8437, loss = 0.70821 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:00:52.871662 ops/training.py:65 2019-01-16 22:00:52.871626: step 8438, loss = 0.68831 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:00:53.764018 ops/training.py:65 2019-01-16 22:00:53.763982: step 8439, loss = 0.70849 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:00:54.656318 ops/training.py:65 2019-01-16 22:00:54.656268: step 8440, loss = 0.67787 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:00:55.548503 ops/training.py:65 2019-01-16 22:00:55.548468: step 8441, loss = 0.68778 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:00:56.441646 ops/training.py:65 2019-01-16 22:00:56.441589: step 8442, loss = 0.68314 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:00:57.334075 ops/training.py:65 2019-01-16 22:00:57.334013: step 8443, loss = 0.70536 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:00:58.225250 ops/training.py:65 2019-01-16 22:00:58.225212: step 8444, loss = 0.68818 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:00:59.116734 ops/training.py:65 2019-01-16 22:00:59.116624: step 8445, loss = 0.68065 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:01:00.008654 ops/training.py:65 2019-01-16 22:01:00.008548: step 8446, loss = 0.72045 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:01:00.899623 ops/training.py:65 2019-01-16 22:01:00.899518: step 8447, loss = 0.69918 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:01:01.789958 ops/training.py:65 2019-01-16 22:01:01.789895: step 8448, loss = 0.73539 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:01:02.679489 ops/training.py:65 2019-01-16 22:01:02.679422: step 8449, loss = 0.68434 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:01:03.569498 ops/training.py:65 2019-01-16 22:01:03.569426: step 8450, loss = 0.70017 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:01:04.459059 ops/training.py:65 2019-01-16 22:01:04.458993: step 8451, loss = 0.69703 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:01:05.347843 ops/training.py:65 2019-01-16 22:01:05.347783: step 8452, loss = 0.70402 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:01:06.237507 ops/training.py:65 2019-01-16 22:01:06.237436: step 8453, loss = 0.71313 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:01:07.126654 ops/training.py:65 2019-01-16 22:01:07.126592: step 8454, loss = 0.68270 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:01:08.016244 ops/training.py:65 2019-01-16 22:01:08.016180: step 8455, loss = 0.71278 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:01:08.906262 ops/training.py:65 2019-01-16 22:01:08.906199: step 8456, loss = 0.65657 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:01:09.798949 ops/training.py:65 2019-01-16 22:01:09.798871: step 8457, loss = 0.69787 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:01:10.691597 ops/training.py:65 2019-01-16 22:01:10.691509: step 8458, loss = 0.70913 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:01:11.583468 ops/training.py:65 2019-01-16 22:01:11.583367: step 8459, loss = 0.70050 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:01:12.479039 ops/training.py:65 2019-01-16 22:01:12.478942: step 8460, loss = 0.70743 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:01:13.372996 ops/training.py:65 2019-01-16 22:01:13.372888: step 8461, loss = 0.70055 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:01:14.266198 ops/training.py:65 2019-01-16 22:01:14.266129: step 8462, loss = 0.68307 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:01:15.159259 ops/training.py:65 2019-01-16 22:01:15.159198: step 8463, loss = 0.70708 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:01:16.052943 ops/training.py:65 2019-01-16 22:01:16.052879: step 8464, loss = 0.69603 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:01:16.945223 ops/training.py:65 2019-01-16 22:01:16.945124: step 8465, loss = 0.67513 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:01:17.838355 ops/training.py:65 2019-01-16 22:01:17.838249: step 8466, loss = 0.67545 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:01:18.729893 ops/training.py:65 2019-01-16 22:01:18.729830: step 8467, loss = 0.68643 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:01:19.620556 ops/training.py:65 2019-01-16 22:01:19.620494: step 8468, loss = 0.66224 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:01:20.511632 ops/training.py:65 2019-01-16 22:01:20.511568: step 8469, loss = 0.71169 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:01:21.403166 ops/training.py:65 2019-01-16 22:01:21.403090: step 8470, loss = 0.71387 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:01:22.297891 ops/training.py:65 2019-01-16 22:01:22.297778: step 8471, loss = 0.68079 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:01:23.188936 ops/training.py:65 2019-01-16 22:01:23.188876: step 8472, loss = 0.70030 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:01:24.079069 ops/training.py:65 2019-01-16 22:01:24.079004: step 8473, loss = 0.67712 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:01:24.969756 ops/training.py:65 2019-01-16 22:01:24.969680: step 8474, loss = 0.69994 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:01:25.861815 ops/training.py:65 2019-01-16 22:01:25.861703: step 8475, loss = 0.68474 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:01:26.754664 ops/training.py:65 2019-01-16 22:01:26.754556: step 8476, loss = 0.70914 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:01:27.648643 ops/training.py:65 2019-01-16 22:01:27.648544: step 8477, loss = 0.71545 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:01:28.540277 ops/training.py:65 2019-01-16 22:01:28.540191: step 8478, loss = 0.67779 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:01:29.429911 ops/training.py:65 2019-01-16 22:01:29.429808: step 8479, loss = 0.67910 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:01:30.320265 ops/training.py:65 2019-01-16 22:01:30.320162: step 8480, loss = 0.69192 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:01:31.211114 ops/training.py:65 2019-01-16 22:01:31.211015: step 8481, loss = 0.67029 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:01:32.101378 ops/training.py:65 2019-01-16 22:01:32.101305: step 8482, loss = 0.68750 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:01:32.992294 ops/training.py:65 2019-01-16 22:01:32.992199: step 8483, loss = 0.69420 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:01:33.882376 ops/training.py:65 2019-01-16 22:01:33.882291: step 8484, loss = 0.71236 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:01:34.772487 ops/training.py:65 2019-01-16 22:01:34.772380: step 8485, loss = 0.67279 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:01:35.663807 ops/training.py:65 2019-01-16 22:01:35.663702: step 8486, loss = 0.73227 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:01:36.555408 ops/training.py:65 2019-01-16 22:01:36.555300: step 8487, loss = 0.70145 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:01:37.446430 ops/training.py:65 2019-01-16 22:01:37.446324: step 8488, loss = 0.71018 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:01:38.336325 ops/training.py:65 2019-01-16 22:01:38.336242: step 8489, loss = 0.71390 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:01:39.225937 ops/training.py:65 2019-01-16 22:01:39.225849: step 8490, loss = 0.71996 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:01:40.114814 ops/training.py:65 2019-01-16 22:01:40.114736: step 8491, loss = 0.72756 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:01:41.003872 ops/training.py:65 2019-01-16 22:01:41.003803: step 8492, loss = 0.73317 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:01:41.891620 ops/training.py:65 2019-01-16 22:01:41.891544: step 8493, loss = 0.69603 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:01:42.780288 ops/training.py:65 2019-01-16 22:01:42.780213: step 8494, loss = 0.73227 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:01:43.670062 ops/training.py:65 2019-01-16 22:01:43.669986: step 8495, loss = 0.71605 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:01:44.559964 ops/training.py:65 2019-01-16 22:01:44.559892: step 8496, loss = 0.68711 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:01:45.448908 ops/training.py:65 2019-01-16 22:01:45.448840: step 8497, loss = 0.72320 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:01:46.339642 ops/training.py:65 2019-01-16 22:01:46.339568: step 8498, loss = 0.69803 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:01:47.230554 ops/training.py:65 2019-01-16 22:01:47.230452: step 8499, loss = 0.71897 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:01:48.122243 ops/training.py:65 2019-01-16 22:01:48.122134: step 8500, loss = 0.69056 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:01:49.014558 ops/training.py:65 2019-01-16 22:01:49.014451: step 8501, loss = 0.65610 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:01:49.905217 ops/training.py:65 2019-01-16 22:01:49.905108: step 8502, loss = 0.69168 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:01:50.795157 ops/training.py:65 2019-01-16 22:01:50.795058: step 8503, loss = 0.71028 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:01:51.684340 ops/training.py:65 2019-01-16 22:01:51.684230: step 8504, loss = 0.68653 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:01:52.573275 ops/training.py:65 2019-01-16 22:01:52.573164: step 8505, loss = 0.73634 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:01:53.462120 ops/training.py:65 2019-01-16 22:01:53.462014: step 8506, loss = 0.71058 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:01:54.350790 ops/training.py:65 2019-01-16 22:01:54.350680: step 8507, loss = 0.71977 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:01:55.241998 ops/training.py:65 2019-01-16 22:01:55.241905: step 8508, loss = 0.69349 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:01:56.133853 ops/training.py:65 2019-01-16 22:01:56.133740: step 8509, loss = 0.68422 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:01:57.024395 ops/training.py:65 2019-01-16 22:01:57.024289: step 8510, loss = 0.66365 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:01:57.914346 ops/training.py:65 2019-01-16 22:01:57.914253: step 8511, loss = 0.69441 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:01:58.804057 ops/training.py:65 2019-01-16 22:01:58.804002: step 8512, loss = 0.71352 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:01:59.693455 ops/training.py:65 2019-01-16 22:01:59.693408: step 8513, loss = 0.71317 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:02:00.582451 ops/training.py:65 2019-01-16 22:02:00.582402: step 8514, loss = 0.70635 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:02:01.472354 ops/training.py:65 2019-01-16 22:02:01.472305: step 8515, loss = 0.68239 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:02:02.360970 ops/training.py:65 2019-01-16 22:02:02.360919: step 8516, loss = 0.71137 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:02:03.250144 ops/training.py:65 2019-01-16 22:02:03.250087: step 8517, loss = 0.69005 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:02:04.139303 ops/training.py:65 2019-01-16 22:02:04.139255: step 8518, loss = 0.71214 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:02:05.031037 ops/training.py:65 2019-01-16 22:02:05.030949: step 8519, loss = 0.71411 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:02:05.924101 ops/training.py:65 2019-01-16 22:02:05.923998: step 8520, loss = 0.71920 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:02:06.816058 ops/training.py:65 2019-01-16 22:02:06.815951: step 8521, loss = 0.70636 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:02:07.708800 ops/training.py:65 2019-01-16 22:02:07.708682: step 8522, loss = 0.70857 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:02:08.601060 ops/training.py:65 2019-01-16 22:02:08.601016: step 8523, loss = 0.69733 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:02:09.492395 ops/training.py:65 2019-01-16 22:02:09.492349: step 8524, loss = 0.67686 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:02:10.381879 ops/training.py:65 2019-01-16 22:02:10.381828: step 8525, loss = 0.69994 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:02:11.271289 ops/training.py:65 2019-01-16 22:02:11.271239: step 8526, loss = 0.72394 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:02:12.160834 ops/training.py:65 2019-01-16 22:02:12.160786: step 8527, loss = 0.66526 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:02:13.050125 ops/training.py:65 2019-01-16 22:02:13.050073: step 8528, loss = 0.72835 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:02:13.939009 ops/training.py:65 2019-01-16 22:02:13.938958: step 8529, loss = 0.68328 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:02:14.828784 ops/training.py:65 2019-01-16 22:02:14.828738: step 8530, loss = 0.70586 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:02:15.717062 ops/training.py:65 2019-01-16 22:02:15.717016: step 8531, loss = 0.70203 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:02:16.606233 ops/training.py:65 2019-01-16 22:02:16.606187: step 8532, loss = 0.68980 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:02:17.494565 ops/training.py:65 2019-01-16 22:02:17.494518: step 8533, loss = 0.71876 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:02:18.384328 ops/training.py:65 2019-01-16 22:02:18.384282: step 8534, loss = 0.67468 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:02:19.273496 ops/training.py:65 2019-01-16 22:02:19.273451: step 8535, loss = 0.69296 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:02:20.162530 ops/training.py:65 2019-01-16 22:02:20.162485: step 8536, loss = 0.69864 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:02:21.053346 ops/training.py:65 2019-01-16 22:02:21.053289: step 8537, loss = 0.72606 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:02:21.944358 ops/training.py:65 2019-01-16 22:02:21.944255: step 8538, loss = 0.69914 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:02:22.836803 ops/training.py:65 2019-01-16 22:02:22.836686: step 8539, loss = 0.67161 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:02:23.729494 ops/training.py:65 2019-01-16 22:02:23.729429: step 8540, loss = 0.69831 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:02:24.623211 ops/training.py:65 2019-01-16 22:02:24.623107: step 8541, loss = 0.68660 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:02:25.515084 ops/training.py:65 2019-01-16 22:02:25.515003: step 8542, loss = 0.69060 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:02:26.406154 ops/training.py:65 2019-01-16 22:02:26.406040: step 8543, loss = 0.68498 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:02:27.299843 ops/training.py:65 2019-01-16 22:02:27.299792: step 8544, loss = 0.68873 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:02:28.190295 ops/training.py:65 2019-01-16 22:02:28.190230: step 8545, loss = 0.70585 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 22:02:29.083203 ops/training.py:65 2019-01-16 22:02:29.083091: step 8546, loss = 0.69591 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:02:29.973802 ops/training.py:65 2019-01-16 22:02:29.973754: step 8547, loss = 0.69689 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:02:30.863383 ops/training.py:65 2019-01-16 22:02:30.863336: step 8548, loss = 0.69787 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:02:31.754575 ops/training.py:65 2019-01-16 22:02:31.754515: step 8549, loss = 0.68465 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:02:32.647026 ops/training.py:65 2019-01-16 22:02:32.646919: step 8550, loss = 0.68540 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:02:33.539734 ops/training.py:65 2019-01-16 22:02:33.539623: step 8551, loss = 0.69205 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:02:34.430458 ops/training.py:65 2019-01-16 22:02:34.430407: step 8552, loss = 0.68672 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:02:35.319333 ops/training.py:65 2019-01-16 22:02:35.319286: step 8553, loss = 0.67103 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:02:36.207768 ops/training.py:65 2019-01-16 22:02:36.207718: step 8554, loss = 0.67275 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:02:37.096268 ops/training.py:65 2019-01-16 22:02:37.096215: step 8555, loss = 0.68592 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:02:37.986264 ops/training.py:65 2019-01-16 22:02:37.986200: step 8556, loss = 0.72920 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 22:02:38.875915 ops/training.py:65 2019-01-16 22:02:38.875841: step 8557, loss = 0.74126 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 22:02:39.766739 ops/training.py:65 2019-01-16 22:02:39.766689: step 8558, loss = 0.67835 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:02:40.656098 ops/training.py:65 2019-01-16 22:02:40.656059: step 8559, loss = 0.71712 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:02:41.544908 ops/training.py:65 2019-01-16 22:02:41.544873: step 8560, loss = 0.70639 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:02:42.433634 ops/training.py:65 2019-01-16 22:02:42.433594: step 8561, loss = 0.67771 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 22:02:43.324460 ops/training.py:65 2019-01-16 22:02:43.324429: step 8562, loss = 0.68048 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:02:44.217557 ops/training.py:65 2019-01-16 22:02:44.217454: step 8563, loss = 0.70345 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:02:45.108564 ops/training.py:65 2019-01-16 22:02:45.108514: step 8564, loss = 0.70317 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:02:45.997776 ops/training.py:65 2019-01-16 22:02:45.997725: step 8565, loss = 0.69132 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:02:46.886491 ops/training.py:65 2019-01-16 22:02:46.886442: step 8566, loss = 0.68163 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:02:47.777260 ops/training.py:65 2019-01-16 22:02:47.777211: step 8567, loss = 0.69488 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:02:48.667163 ops/training.py:65 2019-01-16 22:02:48.667117: step 8568, loss = 0.70425 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:02:49.557133 ops/training.py:65 2019-01-16 22:02:49.557081: step 8569, loss = 0.70275 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:02:50.447425 ops/training.py:65 2019-01-16 22:02:50.447377: step 8570, loss = 0.69029 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:02:51.336662 ops/training.py:65 2019-01-16 22:02:51.336613: step 8571, loss = 0.70585 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:02:52.227383 ops/training.py:65 2019-01-16 22:02:52.227339: step 8572, loss = 0.71849 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:02:53.116974 ops/training.py:65 2019-01-16 22:02:53.116916: step 8573, loss = 0.69711 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:02:54.006091 ops/training.py:65 2019-01-16 22:02:54.006031: step 8574, loss = 0.69050 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:02:54.895776 ops/training.py:65 2019-01-16 22:02:54.895725: step 8575, loss = 0.68396 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:02:55.785374 ops/training.py:65 2019-01-16 22:02:55.785323: step 8576, loss = 0.70523 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:02:56.674264 ops/training.py:65 2019-01-16 22:02:56.674206: step 8577, loss = 0.68527 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:02:57.565715 ops/training.py:65 2019-01-16 22:02:57.565651: step 8578, loss = 0.68370 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:02:58.458250 ops/training.py:65 2019-01-16 22:02:58.458136: step 8579, loss = 0.72026 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 22:02:59.351631 ops/training.py:65 2019-01-16 22:02:59.351512: step 8580, loss = 0.69893 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:03:00.244577 ops/training.py:65 2019-01-16 22:03:00.244526: step 8581, loss = 0.68738 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:03:01.137291 ops/training.py:65 2019-01-16 22:03:01.137174: step 8582, loss = 0.68476 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:03:02.029527 ops/training.py:65 2019-01-16 22:03:02.029482: step 8583, loss = 0.67595 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 22:03:02.918716 ops/training.py:65 2019-01-16 22:03:02.918667: step 8584, loss = 0.69950 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:03:03.808342 ops/training.py:65 2019-01-16 22:03:03.808283: step 8585, loss = 0.72559 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:03:04.697837 ops/training.py:65 2019-01-16 22:03:04.697792: step 8586, loss = 0.69720 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:03:05.586938 ops/training.py:65 2019-01-16 22:03:05.586868: step 8587, loss = 0.69481 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:03:06.476455 ops/training.py:65 2019-01-16 22:03:06.476408: step 8588, loss = 0.72508 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:03:07.366006 ops/training.py:65 2019-01-16 22:03:07.365955: step 8589, loss = 0.70654 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:03:08.255554 ops/training.py:65 2019-01-16 22:03:08.255507: step 8590, loss = 0.66734 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:03:09.144697 ops/training.py:65 2019-01-16 22:03:09.144651: step 8591, loss = 0.68370 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:03:10.034377 ops/training.py:65 2019-01-16 22:03:10.034324: step 8592, loss = 0.69144 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:03:10.924295 ops/training.py:65 2019-01-16 22:03:10.924247: step 8593, loss = 0.69797 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:03:11.813279 ops/training.py:65 2019-01-16 22:03:11.813227: step 8594, loss = 0.69964 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:03:12.702894 ops/training.py:65 2019-01-16 22:03:12.702846: step 8595, loss = 0.69160 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:03:13.592795 ops/training.py:65 2019-01-16 22:03:13.592740: step 8596, loss = 0.66929 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:03:14.482494 ops/training.py:65 2019-01-16 22:03:14.482446: step 8597, loss = 0.68738 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:03:15.370171 ops/training.py:65 2019-01-16 22:03:15.370126: step 8598, loss = 0.68599 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:03:16.257997 ops/training.py:65 2019-01-16 22:03:16.257953: step 8599, loss = 0.68168 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:03:17.146613 ops/training.py:65 2019-01-16 22:03:17.146559: step 8600, loss = 0.66689 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 22:03:18.039058 ops/training.py:65 2019-01-16 22:03:18.038973: step 8601, loss = 0.69323 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:03:18.931563 ops/training.py:65 2019-01-16 22:03:18.931450: step 8602, loss = 0.69859 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:03:19.823214 ops/training.py:65 2019-01-16 22:03:19.823105: step 8603, loss = 0.67350 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.75
I2992 2019-01-16 22:03:20.714622 ops/training.py:65 2019-01-16 22:03:20.714504: step 8604, loss = 0.69452 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:03:21.606570 ops/training.py:65 2019-01-16 22:03:21.606518: step 8605, loss = 0.71578 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:03:22.496655 ops/training.py:65 2019-01-16 22:03:22.496605: step 8606, loss = 0.67429 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 22:03:23.385052 ops/training.py:65 2019-01-16 22:03:23.384991: step 8607, loss = 0.73209 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:03:24.274678 ops/training.py:65 2019-01-16 22:03:24.274629: step 8608, loss = 0.67722 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:03:25.162571 ops/training.py:65 2019-01-16 22:03:25.162520: step 8609, loss = 0.70798 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:03:26.051517 ops/training.py:65 2019-01-16 22:03:26.051466: step 8610, loss = 0.66983 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:03:26.940968 ops/training.py:65 2019-01-16 22:03:26.940919: step 8611, loss = 0.70752 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:03:27.829424 ops/training.py:65 2019-01-16 22:03:27.829378: step 8612, loss = 0.68732 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:03:28.717693 ops/training.py:65 2019-01-16 22:03:28.717642: step 8613, loss = 0.69209 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:03:29.606879 ops/training.py:65 2019-01-16 22:03:29.606835: step 8614, loss = 0.70241 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:03:30.496459 ops/training.py:65 2019-01-16 22:03:30.496411: step 8615, loss = 0.70546 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:03:31.385719 ops/training.py:65 2019-01-16 22:03:31.385671: step 8616, loss = 0.69140 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:03:32.275132 ops/training.py:65 2019-01-16 22:03:32.275084: step 8617, loss = 0.67956 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:03:33.164672 ops/training.py:65 2019-01-16 22:03:33.164611: step 8618, loss = 0.69529 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:03:34.056220 ops/training.py:65 2019-01-16 22:03:34.056173: step 8619, loss = 0.69546 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:03:34.945762 ops/training.py:65 2019-01-16 22:03:34.945710: step 8620, loss = 0.70168 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:03:35.835236 ops/training.py:65 2019-01-16 22:03:35.835189: step 8621, loss = 0.68190 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:03:36.723914 ops/training.py:65 2019-01-16 22:03:36.723867: step 8622, loss = 0.67835 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:03:37.612369 ops/training.py:65 2019-01-16 22:03:37.612322: step 8623, loss = 0.69873 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:03:38.501230 ops/training.py:65 2019-01-16 22:03:38.501184: step 8624, loss = 0.67531 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:03:39.390237 ops/training.py:65 2019-01-16 22:03:39.390188: step 8625, loss = 0.70059 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:03:40.279557 ops/training.py:65 2019-01-16 22:03:40.279511: step 8626, loss = 0.68100 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:03:41.170381 ops/training.py:65 2019-01-16 22:03:41.170316: step 8627, loss = 0.69473 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:03:42.062495 ops/training.py:65 2019-01-16 22:03:42.062389: step 8628, loss = 0.71129 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:03:42.955288 ops/training.py:65 2019-01-16 22:03:42.955174: step 8629, loss = 0.69907 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:03:43.847303 ops/training.py:65 2019-01-16 22:03:43.847194: step 8630, loss = 0.69866 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:03:44.740382 ops/training.py:65 2019-01-16 22:03:44.740270: step 8631, loss = 0.68426 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:03:45.632212 ops/training.py:65 2019-01-16 22:03:45.632094: step 8632, loss = 0.69803 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:03:46.523812 ops/training.py:65 2019-01-16 22:03:46.523763: step 8633, loss = 0.68984 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:03:47.413718 ops/training.py:65 2019-01-16 22:03:47.413667: step 8634, loss = 0.67753 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:03:48.303331 ops/training.py:65 2019-01-16 22:03:48.303280: step 8635, loss = 0.70780 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:03:49.195931 ops/training.py:65 2019-01-16 22:03:49.195863: step 8636, loss = 0.69209 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:03:50.088902 ops/training.py:65 2019-01-16 22:03:50.088785: step 8637, loss = 0.69215 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:03:50.980716 ops/training.py:65 2019-01-16 22:03:50.980670: step 8638, loss = 0.68510 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:03:51.870065 ops/training.py:65 2019-01-16 22:03:51.870019: step 8639, loss = 0.69502 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:03:52.761056 ops/training.py:65 2019-01-16 22:03:52.761019: step 8640, loss = 0.67988 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:03:53.653268 ops/training.py:65 2019-01-16 22:03:53.653214: step 8641, loss = 0.70824 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:03:54.546017 ops/training.py:65 2019-01-16 22:03:54.545963: step 8642, loss = 0.69676 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:03:55.437793 ops/training.py:65 2019-01-16 22:03:55.437715: step 8643, loss = 0.71024 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:03:56.329058 ops/training.py:65 2019-01-16 22:03:56.328949: step 8644, loss = 0.67724 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:03:57.220378 ops/training.py:65 2019-01-16 22:03:57.220330: step 8645, loss = 0.70506 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:03:58.109553 ops/training.py:65 2019-01-16 22:03:58.109508: step 8646, loss = 0.67808 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:03:58.998347 ops/training.py:65 2019-01-16 22:03:58.998300: step 8647, loss = 0.68645 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:03:59.887805 ops/training.py:65 2019-01-16 22:03:59.887760: step 8648, loss = 0.69550 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:04:00.775897 ops/training.py:65 2019-01-16 22:04:00.775852: step 8649, loss = 0.69417 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:04:01.668150 ops/training.py:65 2019-01-16 22:04:01.668112: step 8650, loss = 0.72689 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:04:02.561640 ops/training.py:65 2019-01-16 22:04:02.561537: step 8651, loss = 0.69789 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:04:03.454129 ops/training.py:65 2019-01-16 22:04:03.454018: step 8652, loss = 0.69309 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:04:04.345472 ops/training.py:65 2019-01-16 22:04:04.345415: step 8653, loss = 0.68948 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:04:05.237310 ops/training.py:65 2019-01-16 22:04:05.237196: step 8654, loss = 0.70031 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:04:06.128479 ops/training.py:65 2019-01-16 22:04:06.128431: step 8655, loss = 0.68106 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:04:07.017508 ops/training.py:65 2019-01-16 22:04:07.017460: step 8656, loss = 0.69144 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:04:07.906357 ops/training.py:65 2019-01-16 22:04:07.906312: step 8657, loss = 0.68059 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:04:08.796310 ops/training.py:65 2019-01-16 22:04:08.796266: step 8658, loss = 0.69646 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:04:09.685079 ops/training.py:65 2019-01-16 22:04:09.685027: step 8659, loss = 0.71603 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:04:10.573296 ops/training.py:65 2019-01-16 22:04:10.573249: step 8660, loss = 0.69935 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:04:11.461970 ops/training.py:65 2019-01-16 22:04:11.461916: step 8661, loss = 0.71807 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:04:12.350443 ops/training.py:65 2019-01-16 22:04:12.350393: step 8662, loss = 0.67220 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 22:04:13.239178 ops/training.py:65 2019-01-16 22:04:13.239111: step 8663, loss = 0.67265 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:04:14.131848 ops/training.py:65 2019-01-16 22:04:14.131801: step 8664, loss = 0.66782 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 22:04:15.023311 ops/training.py:65 2019-01-16 22:04:15.023260: step 8665, loss = 0.68270 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:04:15.913142 ops/training.py:65 2019-01-16 22:04:15.913045: step 8666, loss = 0.72602 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:04:16.803293 ops/training.py:65 2019-01-16 22:04:16.803187: step 8667, loss = 0.67080 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:04:17.692900 ops/training.py:65 2019-01-16 22:04:17.692809: step 8668, loss = 0.74053 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:04:18.584266 ops/training.py:65 2019-01-16 22:04:18.584201: step 8669, loss = 0.68321 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:04:19.476614 ops/training.py:65 2019-01-16 22:04:19.476494: step 8670, loss = 0.70904 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:04:20.369569 ops/training.py:65 2019-01-16 22:04:20.369522: step 8671, loss = 0.67195 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:04:21.258573 ops/training.py:65 2019-01-16 22:04:21.258529: step 8672, loss = 0.68194 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:04:22.146848 ops/training.py:65 2019-01-16 22:04:22.146801: step 8673, loss = 0.70427 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:04:23.036411 ops/training.py:65 2019-01-16 22:04:23.036359: step 8674, loss = 0.68057 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:04:23.926584 ops/training.py:65 2019-01-16 22:04:23.926518: step 8675, loss = 0.71228 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:04:24.820822 ops/training.py:65 2019-01-16 22:04:24.820702: step 8676, loss = 0.68065 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:04:25.713947 ops/training.py:65 2019-01-16 22:04:25.713890: step 8677, loss = 0.74360 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 22:04:26.607109 ops/training.py:65 2019-01-16 22:04:26.606993: step 8678, loss = 0.69796 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:04:27.498958 ops/training.py:65 2019-01-16 22:04:27.498911: step 8679, loss = 0.70058 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:04:28.389250 ops/training.py:65 2019-01-16 22:04:28.389199: step 8680, loss = 0.67804 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:04:29.278628 ops/training.py:65 2019-01-16 22:04:29.278582: step 8681, loss = 0.72752 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 22:04:30.167461 ops/training.py:65 2019-01-16 22:04:30.167411: step 8682, loss = 0.67439 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:04:31.056450 ops/training.py:65 2019-01-16 22:04:31.056398: step 8683, loss = 0.69531 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:04:31.945180 ops/training.py:65 2019-01-16 22:04:31.945128: step 8684, loss = 0.72518 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:04:32.833794 ops/training.py:65 2019-01-16 22:04:32.833744: step 8685, loss = 0.68471 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:04:33.722196 ops/training.py:65 2019-01-16 22:04:33.722130: step 8686, loss = 0.70516 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:04:34.610230 ops/training.py:65 2019-01-16 22:04:34.610154: step 8687, loss = 0.69245 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:04:35.498895 ops/training.py:65 2019-01-16 22:04:35.498794: step 8688, loss = 0.69730 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:04:36.389074 ops/training.py:65 2019-01-16 22:04:36.389002: step 8689, loss = 0.68871 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:04:37.281123 ops/training.py:65 2019-01-16 22:04:37.281090: step 8690, loss = 0.68873 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:04:38.172424 ops/training.py:65 2019-01-16 22:04:38.172363: step 8691, loss = 0.70774 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:04:39.063745 ops/training.py:65 2019-01-16 22:04:39.063706: step 8692, loss = 0.73287 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.25
I2992 2019-01-16 22:04:39.954941 ops/training.py:65 2019-01-16 22:04:39.954911: step 8693, loss = 0.70546 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:04:40.847796 ops/training.py:65 2019-01-16 22:04:40.847691: step 8694, loss = 0.71356 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:04:41.740738 ops/training.py:65 2019-01-16 22:04:41.740684: step 8695, loss = 0.70709 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:04:42.632417 ops/training.py:65 2019-01-16 22:04:42.632374: step 8696, loss = 0.68484 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:04:43.525312 ops/training.py:65 2019-01-16 22:04:43.525253: step 8697, loss = 0.71223 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:04:44.417700 ops/training.py:65 2019-01-16 22:04:44.417595: step 8698, loss = 0.70582 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:04:45.311812 ops/training.py:65 2019-01-16 22:04:45.311698: step 8699, loss = 0.70479 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:04:46.203817 ops/training.py:65 2019-01-16 22:04:46.203765: step 8700, loss = 0.70253 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:04:47.093259 ops/training.py:65 2019-01-16 22:04:47.093215: step 8701, loss = 0.69478 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:04:47.984777 ops/training.py:65 2019-01-16 22:04:47.984745: step 8702, loss = 0.67151 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:04:48.875468 ops/training.py:65 2019-01-16 22:04:48.875429: step 8703, loss = 0.68017 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:04:49.766443 ops/training.py:65 2019-01-16 22:04:49.766404: step 8704, loss = 0.71030 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:04:50.656002 ops/training.py:65 2019-01-16 22:04:50.655968: step 8705, loss = 0.68748 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:04:51.545915 ops/training.py:65 2019-01-16 22:04:51.545862: step 8706, loss = 0.70320 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:04:52.435613 ops/training.py:65 2019-01-16 22:04:52.435522: step 8707, loss = 0.69076 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:04:53.326888 ops/training.py:65 2019-01-16 22:04:53.326779: step 8708, loss = 0.68752 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:04:54.218692 ops/training.py:65 2019-01-16 22:04:54.218582: step 8709, loss = 0.70092 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:04:55.111078 ops/training.py:65 2019-01-16 22:04:55.110968: step 8710, loss = 0.67844 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:04:56.002674 ops/training.py:65 2019-01-16 22:04:56.002621: step 8711, loss = 0.71123 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:04:56.891975 ops/training.py:65 2019-01-16 22:04:56.891928: step 8712, loss = 0.71509 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:04:57.782097 ops/training.py:65 2019-01-16 22:04:57.782048: step 8713, loss = 0.69527 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:04:58.671716 ops/training.py:65 2019-01-16 22:04:58.671668: step 8714, loss = 0.68873 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:04:59.561901 ops/training.py:65 2019-01-16 22:04:59.561856: step 8715, loss = 0.69849 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:05:00.451035 ops/training.py:65 2019-01-16 22:05:00.450991: step 8716, loss = 0.70152 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:05:01.340579 ops/training.py:65 2019-01-16 22:05:01.340532: step 8717, loss = 0.70411 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:05:02.229966 ops/training.py:65 2019-01-16 22:05:02.229918: step 8718, loss = 0.71376 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:05:03.119998 ops/training.py:65 2019-01-16 22:05:03.119937: step 8719, loss = 0.69469 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:05:04.010951 ops/training.py:65 2019-01-16 22:05:04.010903: step 8720, loss = 0.67124 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:05:04.901307 ops/training.py:65 2019-01-16 22:05:04.901253: step 8721, loss = 0.66540 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 22:05:05.794528 ops/training.py:65 2019-01-16 22:05:05.794413: step 8722, loss = 0.69783 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:05:06.687816 ops/training.py:65 2019-01-16 22:05:06.687784: step 8723, loss = 0.67730 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:05:07.580332 ops/training.py:65 2019-01-16 22:05:07.580264: step 8724, loss = 0.68710 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:05:08.472743 ops/training.py:65 2019-01-16 22:05:08.472630: step 8725, loss = 0.70861 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:05:09.362649 ops/training.py:65 2019-01-16 22:05:09.362546: step 8726, loss = 0.66572 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:05:10.252384 ops/training.py:65 2019-01-16 22:05:10.252287: step 8727, loss = 0.67593 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:05:11.143598 ops/training.py:65 2019-01-16 22:05:11.143481: step 8728, loss = 0.71941 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:05:12.035091 ops/training.py:65 2019-01-16 22:05:12.035045: step 8729, loss = 0.72195 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:05:12.923715 ops/training.py:65 2019-01-16 22:05:12.923666: step 8730, loss = 0.70064 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:05:13.812029 ops/training.py:65 2019-01-16 22:05:13.811970: step 8731, loss = 0.72065 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:05:14.702397 ops/training.py:65 2019-01-16 22:05:14.702338: step 8732, loss = 0.68989 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:05:15.593882 ops/training.py:65 2019-01-16 22:05:15.593775: step 8733, loss = 0.66572 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:05:16.487272 ops/training.py:65 2019-01-16 22:05:16.487154: step 8734, loss = 0.67114 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:05:17.381760 ops/training.py:65 2019-01-16 22:05:17.381693: step 8735, loss = 0.69795 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:05:18.274613 ops/training.py:65 2019-01-16 22:05:18.274496: step 8736, loss = 0.69476 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:05:19.165859 ops/training.py:65 2019-01-16 22:05:19.165813: step 8737, loss = 0.70738 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:05:20.053680 ops/training.py:65 2019-01-16 22:05:20.053636: step 8738, loss = 0.69784 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:05:20.943211 ops/training.py:65 2019-01-16 22:05:20.943166: step 8739, loss = 0.71151 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:05:21.831450 ops/training.py:65 2019-01-16 22:05:21.831405: step 8740, loss = 0.67467 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:05:22.721722 ops/training.py:65 2019-01-16 22:05:22.721672: step 8741, loss = 0.66552 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:05:23.615730 ops/training.py:65 2019-01-16 22:05:23.615619: step 8742, loss = 0.67867 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:05:24.507681 ops/training.py:65 2019-01-16 22:05:24.507614: step 8743, loss = 0.69987 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:05:25.400077 ops/training.py:65 2019-01-16 22:05:25.399985: step 8744, loss = 0.68713 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:05:26.293092 ops/training.py:65 2019-01-16 22:05:26.292974: step 8745, loss = 0.72795 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:05:27.185115 ops/training.py:65 2019-01-16 22:05:27.185052: step 8746, loss = 0.67653 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:05:28.078242 ops/training.py:65 2019-01-16 22:05:28.078124: step 8747, loss = 0.71690 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:05:28.969674 ops/training.py:65 2019-01-16 22:05:28.969624: step 8748, loss = 0.67722 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:05:29.858982 ops/training.py:65 2019-01-16 22:05:29.858939: step 8749, loss = 0.68857 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:05:30.749655 ops/training.py:65 2019-01-16 22:05:30.749593: step 8750, loss = 0.69399 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:05:31.642204 ops/training.py:65 2019-01-16 22:05:31.642086: step 8751, loss = 0.68148 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:05:32.535247 ops/training.py:65 2019-01-16 22:05:32.535184: step 8752, loss = 0.69333 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:05:33.428319 ops/training.py:65 2019-01-16 22:05:33.428217: step 8753, loss = 0.67433 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:05:34.320826 ops/training.py:65 2019-01-16 22:05:34.320716: step 8754, loss = 0.72408 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:05:35.212130 ops/training.py:65 2019-01-16 22:05:35.212082: step 8755, loss = 0.68574 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:05:36.100277 ops/training.py:65 2019-01-16 22:05:36.100229: step 8756, loss = 0.70498 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:05:36.988639 ops/training.py:65 2019-01-16 22:05:36.988594: step 8757, loss = 0.70151 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:05:37.877563 ops/training.py:65 2019-01-16 22:05:37.877517: step 8758, loss = 0.70018 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:05:38.766334 ops/training.py:65 2019-01-16 22:05:38.766288: step 8759, loss = 0.66154 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 22:05:39.655267 ops/training.py:65 2019-01-16 22:05:39.655219: step 8760, loss = 0.73471 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 22:05:40.544562 ops/training.py:65 2019-01-16 22:05:40.544511: step 8761, loss = 0.67454 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:05:41.434907 ops/training.py:65 2019-01-16 22:05:41.434862: step 8762, loss = 0.70510 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:05:42.323906 ops/training.py:65 2019-01-16 22:05:42.323860: step 8763, loss = 0.68681 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:05:43.213052 ops/training.py:65 2019-01-16 22:05:43.212992: step 8764, loss = 0.71753 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:05:44.102916 ops/training.py:65 2019-01-16 22:05:44.102869: step 8765, loss = 0.67333 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:05:44.992614 ops/training.py:65 2019-01-16 22:05:44.992567: step 8766, loss = 0.68400 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:05:45.881035 ops/training.py:65 2019-01-16 22:05:45.880990: step 8767, loss = 0.69443 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:05:46.769705 ops/training.py:65 2019-01-16 22:05:46.769660: step 8768, loss = 0.71613 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:05:47.659114 ops/training.py:65 2019-01-16 22:05:47.659065: step 8769, loss = 0.70077 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:05:48.548168 ops/training.py:65 2019-01-16 22:05:48.548121: step 8770, loss = 0.68639 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:05:49.437999 ops/training.py:65 2019-01-16 22:05:49.437954: step 8771, loss = 0.70692 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:05:50.328117 ops/training.py:65 2019-01-16 22:05:50.328069: step 8772, loss = 0.70951 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:05:51.217407 ops/training.py:65 2019-01-16 22:05:51.217361: step 8773, loss = 0.67200 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:05:52.106079 ops/training.py:65 2019-01-16 22:05:52.106036: step 8774, loss = 0.69872 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:05:52.997357 ops/training.py:65 2019-01-16 22:05:52.997326: step 8775, loss = 0.69121 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:05:53.892175 ops/training.py:65 2019-01-16 22:05:53.892125: step 8776, loss = 0.69453 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:05:54.783744 ops/training.py:65 2019-01-16 22:05:54.783646: step 8777, loss = 0.67035 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:05:55.676672 ops/training.py:65 2019-01-16 22:05:55.676602: step 8778, loss = 0.68093 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:05:56.567533 ops/training.py:65 2019-01-16 22:05:56.567426: step 8779, loss = 0.68915 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:05:57.458706 ops/training.py:65 2019-01-16 22:05:57.458656: step 8780, loss = 0.72250 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:05:58.350281 ops/training.py:65 2019-01-16 22:05:58.350208: step 8781, loss = 0.68705 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:05:59.242015 ops/training.py:65 2019-01-16 22:05:59.241910: step 8782, loss = 0.68638 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:06:00.134430 ops/training.py:65 2019-01-16 22:06:00.134325: step 8783, loss = 0.68823 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:06:01.024645 ops/training.py:65 2019-01-16 22:06:01.024544: step 8784, loss = 0.68648 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:06:01.915100 ops/training.py:65 2019-01-16 22:06:01.915007: step 8785, loss = 0.69067 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:06:02.805253 ops/training.py:65 2019-01-16 22:06:02.805151: step 8786, loss = 0.69614 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:06:03.694910 ops/training.py:65 2019-01-16 22:06:03.694798: step 8787, loss = 0.69442 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:06:04.587782 ops/training.py:65 2019-01-16 22:06:04.587662: step 8788, loss = 0.69871 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:06:05.479318 ops/training.py:65 2019-01-16 22:06:05.479271: step 8789, loss = 0.70015 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:06:06.369573 ops/training.py:65 2019-01-16 22:06:06.369508: step 8790, loss = 0.68999 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:06:07.262338 ops/training.py:65 2019-01-16 22:06:07.262221: step 8791, loss = 0.70485 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:06:08.153482 ops/training.py:65 2019-01-16 22:06:08.153420: step 8792, loss = 0.69976 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:06:09.045151 ops/training.py:65 2019-01-16 22:06:09.045032: step 8793, loss = 0.69656 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:06:09.936814 ops/training.py:65 2019-01-16 22:06:09.936767: step 8794, loss = 0.69379 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:06:10.825758 ops/training.py:65 2019-01-16 22:06:10.825707: step 8795, loss = 0.70688 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:06:11.715625 ops/training.py:65 2019-01-16 22:06:11.715574: step 8796, loss = 0.69215 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:06:12.605177 ops/training.py:65 2019-01-16 22:06:12.605130: step 8797, loss = 0.72258 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.21875
I2992 2019-01-16 22:06:13.494275 ops/training.py:65 2019-01-16 22:06:13.494219: step 8798, loss = 0.69490 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:06:14.384307 ops/training.py:65 2019-01-16 22:06:14.384258: step 8799, loss = 0.69879 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:06:15.275406 ops/training.py:65 2019-01-16 22:06:15.275352: step 8800, loss = 0.70596 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:06:16.167242 ops/training.py:65 2019-01-16 22:06:16.167144: step 8801, loss = 0.70596 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:06:17.060702 ops/training.py:65 2019-01-16 22:06:17.060581: step 8802, loss = 0.69126 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:06:17.952115 ops/training.py:65 2019-01-16 22:06:17.952062: step 8803, loss = 0.68678 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:06:18.843806 ops/training.py:65 2019-01-16 22:06:18.843689: step 8804, loss = 0.69752 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:06:19.734673 ops/training.py:65 2019-01-16 22:06:19.734622: step 8805, loss = 0.69298 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 22:06:20.624475 ops/training.py:65 2019-01-16 22:06:20.624425: step 8806, loss = 0.70216 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:06:21.513833 ops/training.py:65 2019-01-16 22:06:21.513786: step 8807, loss = 0.67677 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:06:22.403660 ops/training.py:65 2019-01-16 22:06:22.403613: step 8808, loss = 0.70053 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:06:23.294123 ops/training.py:65 2019-01-16 22:06:23.294081: step 8809, loss = 0.68757 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 22:06:24.187787 ops/training.py:65 2019-01-16 22:06:24.187725: step 8810, loss = 0.69429 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:06:25.078847 ops/training.py:65 2019-01-16 22:06:25.078762: step 8811, loss = 0.67999 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:06:25.969206 ops/training.py:65 2019-01-16 22:06:25.969143: step 8812, loss = 0.69337 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:06:26.858535 ops/training.py:65 2019-01-16 22:06:26.858445: step 8813, loss = 0.69964 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:06:27.749082 ops/training.py:65 2019-01-16 22:06:27.748993: step 8814, loss = 0.68586 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:06:28.639180 ops/training.py:65 2019-01-16 22:06:28.639071: step 8815, loss = 0.68248 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:06:29.529131 ops/training.py:65 2019-01-16 22:06:29.529040: step 8816, loss = 0.68531 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:06:30.417930 ops/training.py:65 2019-01-16 22:06:30.417862: step 8817, loss = 0.67861 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:06:31.307969 ops/training.py:65 2019-01-16 22:06:31.307880: step 8818, loss = 0.70102 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:06:32.198871 ops/training.py:65 2019-01-16 22:06:32.198758: step 8819, loss = 0.72137 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 22:06:33.089626 ops/training.py:65 2019-01-16 22:06:33.089512: step 8820, loss = 0.70550 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:06:33.980480 ops/training.py:65 2019-01-16 22:06:33.980367: step 8821, loss = 0.68308 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:06:34.871982 ops/training.py:65 2019-01-16 22:06:34.871919: step 8822, loss = 0.69354 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:06:35.764899 ops/training.py:65 2019-01-16 22:06:35.764798: step 8823, loss = 0.70884 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:06:36.657779 ops/training.py:65 2019-01-16 22:06:36.657664: step 8824, loss = 0.67491 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:06:37.550236 ops/training.py:65 2019-01-16 22:06:37.550119: step 8825, loss = 0.67080 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 22:06:38.443314 ops/training.py:65 2019-01-16 22:06:38.443239: step 8826, loss = 0.67955 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:06:39.337148 ops/training.py:65 2019-01-16 22:06:39.337029: step 8827, loss = 0.69754 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:06:40.227862 ops/training.py:65 2019-01-16 22:06:40.227816: step 8828, loss = 0.69222 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:06:41.120005 ops/training.py:65 2019-01-16 22:06:41.119955: step 8829, loss = 0.68642 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:06:42.012923 ops/training.py:65 2019-01-16 22:06:42.012809: step 8830, loss = 0.69893 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:06:42.902386 ops/training.py:65 2019-01-16 22:06:42.902332: step 8831, loss = 0.66550 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:06:43.790769 ops/training.py:65 2019-01-16 22:06:43.790695: step 8832, loss = 0.69786 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:06:44.680974 ops/training.py:65 2019-01-16 22:06:44.680883: step 8833, loss = 0.68371 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:06:45.569703 ops/training.py:65 2019-01-16 22:06:45.569656: step 8834, loss = 0.72543 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:06:46.457742 ops/training.py:65 2019-01-16 22:06:46.457696: step 8835, loss = 0.68876 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:06:47.350348 ops/training.py:65 2019-01-16 22:06:47.350309: step 8836, loss = 0.68960 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:06:48.243344 ops/training.py:65 2019-01-16 22:06:48.243316: step 8837, loss = 0.72058 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:06:49.135942 ops/training.py:65 2019-01-16 22:06:49.135909: step 8838, loss = 0.70448 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:06:50.027082 ops/training.py:65 2019-01-16 22:06:50.027036: step 8839, loss = 0.66662 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:06:50.918343 ops/training.py:65 2019-01-16 22:06:50.918227: step 8840, loss = 0.72272 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:06:51.812719 ops/training.py:65 2019-01-16 22:06:51.812687: step 8841, loss = 0.70198 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:06:52.704002 ops/training.py:65 2019-01-16 22:06:52.703952: step 8842, loss = 0.68191 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:06:53.596164 ops/training.py:65 2019-01-16 22:06:53.596057: step 8843, loss = 0.69758 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:06:54.488394 ops/training.py:65 2019-01-16 22:06:54.488334: step 8844, loss = 0.70795 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:06:55.382200 ops/training.py:65 2019-01-16 22:06:55.382088: step 8845, loss = 0.69145 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:06:56.275951 ops/training.py:65 2019-01-16 22:06:56.275890: step 8846, loss = 0.69193 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:06:57.168250 ops/training.py:65 2019-01-16 22:06:57.168130: step 8847, loss = 0.69811 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:06:58.061139 ops/training.py:65 2019-01-16 22:06:58.061099: step 8848, loss = 0.71362 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:06:58.951811 ops/training.py:65 2019-01-16 22:06:58.951766: step 8849, loss = 0.70909 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:06:59.840324 ops/training.py:65 2019-01-16 22:06:59.840279: step 8850, loss = 0.70523 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:07:00.729486 ops/training.py:65 2019-01-16 22:07:00.729441: step 8851, loss = 0.69680 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:07:01.621409 ops/training.py:65 2019-01-16 22:07:01.621332: step 8852, loss = 0.69760 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:07:02.513778 ops/training.py:65 2019-01-16 22:07:02.513671: step 8853, loss = 0.71162 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:07:03.407488 ops/training.py:65 2019-01-16 22:07:03.407380: step 8854, loss = 0.68907 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:07:04.299206 ops/training.py:65 2019-01-16 22:07:04.299159: step 8855, loss = 0.69913 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:07:05.187941 ops/training.py:65 2019-01-16 22:07:05.187896: step 8856, loss = 0.70617 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:07:06.076162 ops/training.py:65 2019-01-16 22:07:06.076118: step 8857, loss = 0.70094 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:07:06.966305 ops/training.py:65 2019-01-16 22:07:06.966257: step 8858, loss = 0.69398 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:07:07.854123 ops/training.py:65 2019-01-16 22:07:07.854077: step 8859, loss = 0.69715 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:07:08.743200 ops/training.py:65 2019-01-16 22:07:08.743154: step 8860, loss = 0.69227 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:07:09.632414 ops/training.py:65 2019-01-16 22:07:09.632371: step 8861, loss = 0.69129 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:07:10.523850 ops/training.py:65 2019-01-16 22:07:10.523811: step 8862, loss = 0.69354 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:07:11.415862 ops/training.py:65 2019-01-16 22:07:11.415820: step 8863, loss = 0.70735 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:07:12.306867 ops/training.py:65 2019-01-16 22:07:12.306796: step 8864, loss = 0.69575 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:07:13.196155 ops/training.py:65 2019-01-16 22:07:13.196052: step 8865, loss = 0.70204 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:07:14.089442 ops/training.py:65 2019-01-16 22:07:14.089341: step 8866, loss = 0.68146 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:07:14.981842 ops/training.py:65 2019-01-16 22:07:14.981753: step 8867, loss = 0.68782 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:07:15.872702 ops/training.py:65 2019-01-16 22:07:15.872593: step 8868, loss = 0.69733 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:07:16.763928 ops/training.py:65 2019-01-16 22:07:16.763854: step 8869, loss = 0.68613 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:07:17.654807 ops/training.py:65 2019-01-16 22:07:17.654725: step 8870, loss = 0.70157 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:07:18.546006 ops/training.py:65 2019-01-16 22:07:18.545963: step 8871, loss = 0.67249 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 22:07:19.437888 ops/training.py:65 2019-01-16 22:07:19.437787: step 8872, loss = 0.70907 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:07:20.329628 ops/training.py:65 2019-01-16 22:07:20.329511: step 8873, loss = 0.68026 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:07:21.221379 ops/training.py:65 2019-01-16 22:07:21.221322: step 8874, loss = 0.68577 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:07:22.114586 ops/training.py:65 2019-01-16 22:07:22.114466: step 8875, loss = 0.69127 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:07:23.005345 ops/training.py:65 2019-01-16 22:07:23.005293: step 8876, loss = 0.68149 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:07:23.894835 ops/training.py:65 2019-01-16 22:07:23.894775: step 8877, loss = 0.71238 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:07:24.783821 ops/training.py:65 2019-01-16 22:07:24.783773: step 8878, loss = 0.66156 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 22:07:25.672821 ops/training.py:65 2019-01-16 22:07:25.672775: step 8879, loss = 0.67171 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 22:07:26.561924 ops/training.py:65 2019-01-16 22:07:26.561878: step 8880, loss = 0.68981 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:07:27.450240 ops/training.py:65 2019-01-16 22:07:27.450196: step 8881, loss = 0.68067 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:07:28.339742 ops/training.py:65 2019-01-16 22:07:28.339696: step 8882, loss = 0.70807 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:07:29.229287 ops/training.py:65 2019-01-16 22:07:29.229241: step 8883, loss = 0.69963 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:07:30.120069 ops/training.py:65 2019-01-16 22:07:30.120031: step 8884, loss = 0.70696 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:07:31.011533 ops/training.py:65 2019-01-16 22:07:31.011489: step 8885, loss = 0.67155 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:07:31.900335 ops/training.py:65 2019-01-16 22:07:31.900292: step 8886, loss = 0.68042 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:07:32.789119 ops/training.py:65 2019-01-16 22:07:32.789074: step 8887, loss = 0.68614 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:07:33.680961 ops/training.py:65 2019-01-16 22:07:33.680920: step 8888, loss = 0.71944 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:07:34.573799 ops/training.py:65 2019-01-16 22:07:34.573741: step 8889, loss = 0.67360 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:07:35.466285 ops/training.py:65 2019-01-16 22:07:35.466149: step 8890, loss = 0.70482 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:07:36.357120 ops/training.py:65 2019-01-16 22:07:36.357045: step 8891, loss = 0.71779 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 22:07:37.247445 ops/training.py:65 2019-01-16 22:07:37.247340: step 8892, loss = 0.67716 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:07:38.138975 ops/training.py:65 2019-01-16 22:07:38.138857: step 8893, loss = 0.70353 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:07:39.031260 ops/training.py:65 2019-01-16 22:07:39.031212: step 8894, loss = 0.69245 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:07:39.920173 ops/training.py:65 2019-01-16 22:07:39.920128: step 8895, loss = 0.70677 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:07:40.809896 ops/training.py:65 2019-01-16 22:07:40.809849: step 8896, loss = 0.68229 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:07:41.699302 ops/training.py:65 2019-01-16 22:07:41.699253: step 8897, loss = 0.68801 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:07:42.588364 ops/training.py:65 2019-01-16 22:07:42.588315: step 8898, loss = 0.69771 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:07:43.477324 ops/training.py:65 2019-01-16 22:07:43.477264: step 8899, loss = 0.67844 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:07:44.367030 ops/training.py:65 2019-01-16 22:07:44.366981: step 8900, loss = 0.70970 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:07:45.255286 ops/training.py:65 2019-01-16 22:07:45.255240: step 8901, loss = 0.66260 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:07:46.144706 ops/training.py:65 2019-01-16 22:07:46.144658: step 8902, loss = 0.70934 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:07:47.034891 ops/training.py:65 2019-01-16 22:07:47.034848: step 8903, loss = 0.67265 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:07:47.923235 ops/training.py:65 2019-01-16 22:07:47.923166: step 8904, loss = 0.69006 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:07:48.813728 ops/training.py:65 2019-01-16 22:07:48.813683: step 8905, loss = 0.66985 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:07:49.702777 ops/training.py:65 2019-01-16 22:07:49.702733: step 8906, loss = 0.71419 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:07:50.594548 ops/training.py:65 2019-01-16 22:07:50.594483: step 8907, loss = 0.69508 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:07:51.486065 ops/training.py:65 2019-01-16 22:07:51.485943: step 8908, loss = 0.68337 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:07:52.378001 ops/training.py:65 2019-01-16 22:07:52.377959: step 8909, loss = 0.66777 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 22:07:53.267052 ops/training.py:65 2019-01-16 22:07:53.266995: step 8910, loss = 0.70873 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:07:54.159589 ops/training.py:65 2019-01-16 22:07:54.159557: step 8911, loss = 0.71223 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:07:55.052596 ops/training.py:65 2019-01-16 22:07:55.052537: step 8912, loss = 0.68833 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:07:55.945396 ops/training.py:65 2019-01-16 22:07:55.945349: step 8913, loss = 0.70069 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:07:56.836804 ops/training.py:65 2019-01-16 22:07:56.836763: step 8914, loss = 0.69371 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:07:57.726963 ops/training.py:65 2019-01-16 22:07:57.726891: step 8915, loss = 0.70666 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:07:58.617888 ops/training.py:65 2019-01-16 22:07:58.617777: step 8916, loss = 0.70133 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:07:59.510035 ops/training.py:65 2019-01-16 22:07:59.509989: step 8917, loss = 0.69414 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:08:00.399369 ops/training.py:65 2019-01-16 22:08:00.399314: step 8918, loss = 0.68633 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:08:01.288550 ops/training.py:65 2019-01-16 22:08:01.288494: step 8919, loss = 0.71136 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:08:02.177925 ops/training.py:65 2019-01-16 22:08:02.177878: step 8920, loss = 0.68898 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:08:03.065562 ops/training.py:65 2019-01-16 22:08:03.065503: step 8921, loss = 0.69849 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:08:03.958195 ops/training.py:65 2019-01-16 22:08:03.958163: step 8922, loss = 0.68981 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:08:04.851607 ops/training.py:65 2019-01-16 22:08:04.851575: step 8923, loss = 0.69611 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:08:05.742472 ops/training.py:65 2019-01-16 22:08:05.742424: step 8924, loss = 0.69253 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:08:06.630585 ops/training.py:65 2019-01-16 22:08:06.630538: step 8925, loss = 0.69150 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:08:07.519036 ops/training.py:65 2019-01-16 22:08:07.518983: step 8926, loss = 0.67738 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:08:08.407051 ops/training.py:65 2019-01-16 22:08:08.406998: step 8927, loss = 0.69140 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:08:09.296219 ops/training.py:65 2019-01-16 22:08:09.296169: step 8928, loss = 0.69649 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:08:10.188198 ops/training.py:65 2019-01-16 22:08:10.188170: step 8929, loss = 0.67771 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:08:11.079115 ops/training.py:65 2019-01-16 22:08:11.079078: step 8930, loss = 0.68677 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:08:11.971272 ops/training.py:65 2019-01-16 22:08:11.971184: step 8931, loss = 0.70498 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:08:12.863118 ops/training.py:65 2019-01-16 22:08:12.863012: step 8932, loss = 0.68640 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:08:13.753969 ops/training.py:65 2019-01-16 22:08:13.753912: step 8933, loss = 0.69090 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:08:14.643505 ops/training.py:65 2019-01-16 22:08:14.643459: step 8934, loss = 0.68748 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:08:15.535661 ops/training.py:65 2019-01-16 22:08:15.535586: step 8935, loss = 0.69006 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:08:16.429062 ops/training.py:65 2019-01-16 22:08:16.428941: step 8936, loss = 0.70110 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:08:17.322611 ops/training.py:65 2019-01-16 22:08:17.322563: step 8937, loss = 0.69008 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:08:18.212694 ops/training.py:65 2019-01-16 22:08:18.212641: step 8938, loss = 0.70534 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:08:19.102389 ops/training.py:65 2019-01-16 22:08:19.102342: step 8939, loss = 0.71014 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:08:19.991494 ops/training.py:65 2019-01-16 22:08:19.991446: step 8940, loss = 0.71116 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:08:20.882275 ops/training.py:65 2019-01-16 22:08:20.882228: step 8941, loss = 0.70747 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:08:21.773283 ops/training.py:65 2019-01-16 22:08:21.773228: step 8942, loss = 0.69188 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:08:22.666231 ops/training.py:65 2019-01-16 22:08:22.666123: step 8943, loss = 0.69955 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:08:23.559682 ops/training.py:65 2019-01-16 22:08:23.559574: step 8944, loss = 0.68546 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:08:24.452912 ops/training.py:65 2019-01-16 22:08:24.452858: step 8945, loss = 0.68358 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:08:25.346019 ops/training.py:65 2019-01-16 22:08:25.345912: step 8946, loss = 0.69372 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:08:26.237045 ops/training.py:65 2019-01-16 22:08:26.236997: step 8947, loss = 0.69926 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:08:27.127209 ops/training.py:65 2019-01-16 22:08:27.127147: step 8948, loss = 0.70381 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:08:28.018905 ops/training.py:65 2019-01-16 22:08:28.018790: step 8949, loss = 0.69953 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:08:28.910910 ops/training.py:65 2019-01-16 22:08:28.910855: step 8950, loss = 0.69154 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:08:29.803771 ops/training.py:65 2019-01-16 22:08:29.803652: step 8951, loss = 0.69195 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:08:30.695688 ops/training.py:65 2019-01-16 22:08:30.695640: step 8952, loss = 0.70737 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:08:31.586852 ops/training.py:65 2019-01-16 22:08:31.586802: step 8953, loss = 0.70769 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 22:08:32.475803 ops/training.py:65 2019-01-16 22:08:32.475759: step 8954, loss = 0.70757 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:08:33.367595 ops/training.py:65 2019-01-16 22:08:33.367524: step 8955, loss = 0.68600 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:08:34.259477 ops/training.py:65 2019-01-16 22:08:34.259368: step 8956, loss = 0.68807 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:08:35.151472 ops/training.py:65 2019-01-16 22:08:35.151363: step 8957, loss = 0.68080 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:08:36.043061 ops/training.py:65 2019-01-16 22:08:36.042949: step 8958, loss = 0.69830 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:08:36.934755 ops/training.py:65 2019-01-16 22:08:36.934705: step 8959, loss = 0.67562 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 22:08:37.824112 ops/training.py:65 2019-01-16 22:08:37.824061: step 8960, loss = 0.70210 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:08:38.713396 ops/training.py:65 2019-01-16 22:08:38.713348: step 8961, loss = 0.68716 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:08:39.602459 ops/training.py:65 2019-01-16 22:08:39.602410: step 8962, loss = 0.69966 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:08:40.491289 ops/training.py:65 2019-01-16 22:08:40.491236: step 8963, loss = 0.70228 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:08:41.381061 ops/training.py:65 2019-01-16 22:08:41.381017: step 8964, loss = 0.69775 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:08:42.269676 ops/training.py:65 2019-01-16 22:08:42.269632: step 8965, loss = 0.69585 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:08:43.160774 ops/training.py:65 2019-01-16 22:08:43.160710: step 8966, loss = 0.69347 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:08:44.052753 ops/training.py:65 2019-01-16 22:08:44.052642: step 8967, loss = 0.68566 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:08:44.943352 ops/training.py:65 2019-01-16 22:08:44.943306: step 8968, loss = 0.69358 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:08:45.833115 ops/training.py:65 2019-01-16 22:08:45.833067: step 8969, loss = 0.68538 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:08:46.721883 ops/training.py:65 2019-01-16 22:08:46.721836: step 8970, loss = 0.68962 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:08:47.610150 ops/training.py:65 2019-01-16 22:08:47.610098: step 8971, loss = 0.68328 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:08:48.502434 ops/training.py:65 2019-01-16 22:08:48.502384: step 8972, loss = 0.70382 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:08:49.395127 ops/training.py:65 2019-01-16 22:08:49.395045: step 8973, loss = 0.68397 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:08:50.287051 ops/training.py:65 2019-01-16 22:08:50.286952: step 8974, loss = 0.67141 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:08:51.178563 ops/training.py:65 2019-01-16 22:08:51.178447: step 8975, loss = 0.68792 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:08:52.070153 ops/training.py:65 2019-01-16 22:08:52.070098: step 8976, loss = 0.69640 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:08:52.963257 ops/training.py:65 2019-01-16 22:08:52.963141: step 8977, loss = 0.69681 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:08:53.854483 ops/training.py:65 2019-01-16 22:08:53.854422: step 8978, loss = 0.70474 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:08:54.743941 ops/training.py:65 2019-01-16 22:08:54.743892: step 8979, loss = 0.69039 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:08:55.636635 ops/training.py:65 2019-01-16 22:08:55.636574: step 8980, loss = 0.69841 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:08:56.529857 ops/training.py:65 2019-01-16 22:08:56.529744: step 8981, loss = 0.71407 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:08:57.422697 ops/training.py:65 2019-01-16 22:08:57.422652: step 8982, loss = 0.67536 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:08:58.315655 ops/training.py:65 2019-01-16 22:08:58.315590: step 8983, loss = 0.69138 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:08:59.209004 ops/training.py:65 2019-01-16 22:08:59.208887: step 8984, loss = 0.72333 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:09:00.101260 ops/training.py:65 2019-01-16 22:09:00.101211: step 8985, loss = 0.70818 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:09:00.991593 ops/training.py:65 2019-01-16 22:09:00.991545: step 8986, loss = 0.69275 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:09:01.880185 ops/training.py:65 2019-01-16 22:09:01.880138: step 8987, loss = 0.70154 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:09:02.769412 ops/training.py:65 2019-01-16 22:09:02.769365: step 8988, loss = 0.69025 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:09:03.658503 ops/training.py:65 2019-01-16 22:09:03.658447: step 8989, loss = 0.68987 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:09:04.547566 ops/training.py:65 2019-01-16 22:09:04.547519: step 8990, loss = 0.68103 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:09:05.435721 ops/training.py:65 2019-01-16 22:09:05.435672: step 8991, loss = 0.66031 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.75
I2992 2019-01-16 22:09:06.324799 ops/training.py:65 2019-01-16 22:09:06.324744: step 8992, loss = 0.70645 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:09:07.213042 ops/training.py:65 2019-01-16 22:09:07.212989: step 8993, loss = 0.69960 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:09:08.102300 ops/training.py:65 2019-01-16 22:09:08.102240: step 8994, loss = 0.69841 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:09:08.992046 ops/training.py:65 2019-01-16 22:09:08.991998: step 8995, loss = 0.67742 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:09:09.880618 ops/training.py:65 2019-01-16 22:09:09.880566: step 8996, loss = 0.66478 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:09:10.769102 ops/training.py:65 2019-01-16 22:09:10.769053: step 8997, loss = 0.68476 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:09:11.657384 ops/training.py:65 2019-01-16 22:09:11.657336: step 8998, loss = 0.69778 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:09:12.546385 ops/training.py:65 2019-01-16 22:09:12.546337: step 8999, loss = 0.70123 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:09:13.438006 ops/training.py:65 2019-01-16 22:09:13.437951: step 9000, loss = 0.67895 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:09:14.326529 ops/training.py:65 2019-01-16 22:09:14.326482: step 9001, loss = 0.68411 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:09:15.214252 ops/training.py:65 2019-01-16 22:09:15.214205: step 9002, loss = 0.73308 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 22:09:16.102824 ops/training.py:65 2019-01-16 22:09:16.102778: step 9003, loss = 0.69321 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:09:16.991372 ops/training.py:65 2019-01-16 22:09:16.991320: step 9004, loss = 0.70790 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:09:17.880001 ops/training.py:65 2019-01-16 22:09:17.879940: step 9005, loss = 0.69084 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:09:18.768851 ops/training.py:65 2019-01-16 22:09:18.768799: step 9006, loss = 0.68721 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:09:19.658847 ops/training.py:65 2019-01-16 22:09:19.658797: step 9007, loss = 0.68411 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:09:20.547853 ops/training.py:65 2019-01-16 22:09:20.547804: step 9008, loss = 0.68928 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:09:21.437487 ops/training.py:65 2019-01-16 22:09:21.437443: step 9009, loss = 0.70405 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:09:22.326210 ops/training.py:65 2019-01-16 22:09:22.326166: step 9010, loss = 0.68189 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:09:23.217119 ops/training.py:65 2019-01-16 22:09:23.217055: step 9011, loss = 0.69433 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:09:24.109070 ops/training.py:65 2019-01-16 22:09:24.108956: step 9012, loss = 0.71625 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:09:25.002975 ops/training.py:65 2019-01-16 22:09:25.002856: step 9013, loss = 0.69477 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:09:25.894617 ops/training.py:65 2019-01-16 22:09:25.894562: step 9014, loss = 0.68802 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:09:26.782645 ops/training.py:65 2019-01-16 22:09:26.782598: step 9015, loss = 0.69444 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:09:27.671647 ops/training.py:65 2019-01-16 22:09:27.671593: step 9016, loss = 0.70144 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:09:28.563187 ops/training.py:65 2019-01-16 22:09:28.563138: step 9017, loss = 0.69848 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:09:29.455451 ops/training.py:65 2019-01-16 22:09:29.455338: step 9018, loss = 0.68762 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:09:30.346432 ops/training.py:65 2019-01-16 22:09:30.346387: step 9019, loss = 0.67342 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 22:09:31.234627 ops/training.py:65 2019-01-16 22:09:31.234583: step 9020, loss = 0.70338 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:09:32.123509 ops/training.py:65 2019-01-16 22:09:32.123457: step 9021, loss = 0.69571 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:09:33.013185 ops/training.py:65 2019-01-16 22:09:33.013136: step 9022, loss = 0.70665 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:09:33.901894 ops/training.py:65 2019-01-16 22:09:33.901839: step 9023, loss = 0.70425 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:09:34.791401 ops/training.py:65 2019-01-16 22:09:34.791358: step 9024, loss = 0.69031 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:09:35.683794 ops/training.py:65 2019-01-16 22:09:35.683738: step 9025, loss = 0.71654 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:09:36.575485 ops/training.py:65 2019-01-16 22:09:36.575399: step 9026, loss = 0.71659 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:09:37.466942 ops/training.py:65 2019-01-16 22:09:37.466838: step 9027, loss = 0.69666 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:09:38.359047 ops/training.py:65 2019-01-16 22:09:38.358933: step 9028, loss = 0.68986 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:09:39.251179 ops/training.py:65 2019-01-16 22:09:39.251130: step 9029, loss = 0.69801 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:09:40.143244 ops/training.py:65 2019-01-16 22:09:40.143178: step 9030, loss = 0.69998 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:09:41.036243 ops/training.py:65 2019-01-16 22:09:41.036136: step 9031, loss = 0.69372 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:09:41.928761 ops/training.py:65 2019-01-16 22:09:41.928716: step 9032, loss = 0.70184 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:09:42.818014 ops/training.py:65 2019-01-16 22:09:42.817965: step 9033, loss = 0.69840 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:09:43.708488 ops/training.py:65 2019-01-16 22:09:43.708422: step 9034, loss = 0.70486 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:09:44.601720 ops/training.py:65 2019-01-16 22:09:44.601605: step 9035, loss = 0.70978 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:09:45.493073 ops/training.py:65 2019-01-16 22:09:45.493023: step 9036, loss = 0.68507 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:09:46.381918 ops/training.py:65 2019-01-16 22:09:46.381873: step 9037, loss = 0.69563 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:09:47.271384 ops/training.py:65 2019-01-16 22:09:47.271334: step 9038, loss = 0.68599 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:09:48.160398 ops/training.py:65 2019-01-16 22:09:48.160348: step 9039, loss = 0.69794 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:09:49.050172 ops/training.py:65 2019-01-16 22:09:49.050122: step 9040, loss = 0.70717 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:09:49.939638 ops/training.py:65 2019-01-16 22:09:49.939593: step 9041, loss = 0.68525 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:09:50.827483 ops/training.py:65 2019-01-16 22:09:50.827438: step 9042, loss = 0.69633 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:09:51.715716 ops/training.py:65 2019-01-16 22:09:51.715673: step 9043, loss = 0.67250 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:09:52.604068 ops/training.py:65 2019-01-16 22:09:52.604016: step 9044, loss = 0.66059 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 22:09:53.492893 ops/training.py:65 2019-01-16 22:09:53.492829: step 9045, loss = 0.67400 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:09:54.382866 ops/training.py:65 2019-01-16 22:09:54.382814: step 9046, loss = 0.66873 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:09:55.271347 ops/training.py:65 2019-01-16 22:09:55.271298: step 9047, loss = 0.70177 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:09:56.181256 ops/training.py:65 2019-01-16 22:09:56.181199: step 9048, loss = 0.68921 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:09:57.069382 ops/training.py:65 2019-01-16 22:09:57.069327: step 9049, loss = 0.71855 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:09:57.958070 ops/training.py:65 2019-01-16 22:09:57.958023: step 9050, loss = 0.71008 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:09:58.849606 ops/training.py:65 2019-01-16 22:09:58.849548: step 9051, loss = 0.68965 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:09:59.742371 ops/training.py:65 2019-01-16 22:09:59.742256: step 9052, loss = 0.71305 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:10:00.634366 ops/training.py:65 2019-01-16 22:10:00.634318: step 9053, loss = 0.67722 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:10:01.527632 ops/training.py:65 2019-01-16 22:10:01.527529: step 9054, loss = 0.69867 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:10:02.419759 ops/training.py:65 2019-01-16 22:10:02.419706: step 9055, loss = 0.70968 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:10:03.308258 ops/training.py:65 2019-01-16 22:10:03.308193: step 9056, loss = 0.69290 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:10:04.197420 ops/training.py:65 2019-01-16 22:10:04.197376: step 9057, loss = 0.67451 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:10:05.085515 ops/training.py:65 2019-01-16 22:10:05.085467: step 9058, loss = 0.68213 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:10:05.974561 ops/training.py:65 2019-01-16 22:10:05.974513: step 9059, loss = 0.68690 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:10:06.863331 ops/training.py:65 2019-01-16 22:10:06.863284: step 9060, loss = 0.67813 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:10:07.751006 ops/training.py:65 2019-01-16 22:10:07.750959: step 9061, loss = 0.68166 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:10:08.640207 ops/training.py:65 2019-01-16 22:10:08.640160: step 9062, loss = 0.69792 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:10:09.531118 ops/training.py:65 2019-01-16 22:10:09.531052: step 9063, loss = 0.70629 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:10:10.423332 ops/training.py:65 2019-01-16 22:10:10.423225: step 9064, loss = 0.70413 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:10:11.314404 ops/training.py:65 2019-01-16 22:10:11.314302: step 9065, loss = 0.69558 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:10:12.204612 ops/training.py:65 2019-01-16 22:10:12.204503: step 9066, loss = 0.70150 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:10:13.094408 ops/training.py:65 2019-01-16 22:10:13.094307: step 9067, loss = 0.69834 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:10:13.985981 ops/training.py:65 2019-01-16 22:10:13.985871: step 9068, loss = 0.67610 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:10:14.877791 ops/training.py:65 2019-01-16 22:10:14.877736: step 9069, loss = 0.68821 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:10:15.770740 ops/training.py:65 2019-01-16 22:10:15.770621: step 9070, loss = 0.70486 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:10:16.663406 ops/training.py:65 2019-01-16 22:10:16.663371: step 9071, loss = 0.71141 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:10:17.557310 ops/training.py:65 2019-01-16 22:10:17.557247: step 9072, loss = 0.72786 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:10:18.450107 ops/training.py:65 2019-01-16 22:10:18.449989: step 9073, loss = 0.69080 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:10:19.343434 ops/training.py:65 2019-01-16 22:10:19.343374: step 9074, loss = 0.69920 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:10:20.235858 ops/training.py:65 2019-01-16 22:10:20.235741: step 9075, loss = 0.67554 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:10:21.129335 ops/training.py:65 2019-01-16 22:10:21.129276: step 9076, loss = 0.70241 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:10:22.021188 ops/training.py:65 2019-01-16 22:10:22.021084: step 9077, loss = 0.71868 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:10:22.913611 ops/training.py:65 2019-01-16 22:10:22.913508: step 9078, loss = 0.68246 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:10:23.807010 ops/training.py:65 2019-01-16 22:10:23.806894: step 9079, loss = 0.70265 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:10:24.701279 ops/training.py:65 2019-01-16 22:10:24.701216: step 9080, loss = 0.68349 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:10:25.595164 ops/training.py:65 2019-01-16 22:10:25.595072: step 9081, loss = 0.69663 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:10:26.487588 ops/training.py:65 2019-01-16 22:10:26.487479: step 9082, loss = 0.68863 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:10:27.379858 ops/training.py:65 2019-01-16 22:10:27.379750: step 9083, loss = 0.68992 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:10:28.271035 ops/training.py:65 2019-01-16 22:10:28.270940: step 9084, loss = 0.69690 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:10:29.162618 ops/training.py:65 2019-01-16 22:10:29.162520: step 9085, loss = 0.70684 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:10:30.053256 ops/training.py:65 2019-01-16 22:10:30.053190: step 9086, loss = 0.70773 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:10:30.943744 ops/training.py:65 2019-01-16 22:10:30.943627: step 9087, loss = 0.71647 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:10:31.834356 ops/training.py:65 2019-01-16 22:10:31.834309: step 9088, loss = 0.68831 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:10:32.724065 ops/training.py:65 2019-01-16 22:10:32.724016: step 9089, loss = 0.71136 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:10:33.615707 ops/training.py:65 2019-01-16 22:10:33.615637: step 9090, loss = 0.68844 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:10:34.509476 ops/training.py:65 2019-01-16 22:10:34.509372: step 9091, loss = 0.69639 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:10:35.403316 ops/training.py:65 2019-01-16 22:10:35.403250: step 9092, loss = 0.66660 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:10:36.295048 ops/training.py:65 2019-01-16 22:10:36.294949: step 9093, loss = 0.70685 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:10:37.187534 ops/training.py:65 2019-01-16 22:10:37.187428: step 9094, loss = 0.70526 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:10:38.081287 ops/training.py:65 2019-01-16 22:10:38.081229: step 9095, loss = 0.68124 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:10:38.974524 ops/training.py:65 2019-01-16 22:10:38.974446: step 9096, loss = 0.71698 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:10:39.867376 ops/training.py:65 2019-01-16 22:10:39.867290: step 9097, loss = 0.70189 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:10:40.760659 ops/training.py:65 2019-01-16 22:10:40.760561: step 9098, loss = 0.70220 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:10:41.652980 ops/training.py:65 2019-01-16 22:10:41.652878: step 9099, loss = 0.71659 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:10:42.545746 ops/training.py:65 2019-01-16 22:10:42.545636: step 9100, loss = 0.68413 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:10:43.436713 ops/training.py:65 2019-01-16 22:10:43.436650: step 9101, loss = 0.68703 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:10:44.328777 ops/training.py:65 2019-01-16 22:10:44.328733: step 9102, loss = 0.69983 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:10:45.220427 ops/training.py:65 2019-01-16 22:10:45.220336: step 9103, loss = 0.69242 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:10:46.111393 ops/training.py:65 2019-01-16 22:10:46.111302: step 9104, loss = 0.69571 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:10:47.003336 ops/training.py:65 2019-01-16 22:10:47.003304: step 9105, loss = 0.70357 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:10:47.896346 ops/training.py:65 2019-01-16 22:10:47.896317: step 9106, loss = 0.69516 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:10:48.788444 ops/training.py:65 2019-01-16 22:10:48.788410: step 9107, loss = 0.67534 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:10:49.680608 ops/training.py:65 2019-01-16 22:10:49.680577: step 9108, loss = 0.70042 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:10:50.573426 ops/training.py:65 2019-01-16 22:10:50.573354: step 9109, loss = 0.71357 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:10:51.465534 ops/training.py:65 2019-01-16 22:10:51.465421: step 9110, loss = 0.70505 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:10:52.357433 ops/training.py:65 2019-01-16 22:10:52.357384: step 9111, loss = 0.69913 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:10:53.246783 ops/training.py:65 2019-01-16 22:10:53.246723: step 9112, loss = 0.71666 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:10:54.134717 ops/training.py:65 2019-01-16 22:10:54.134669: step 9113, loss = 0.72143 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 22:10:55.022930 ops/training.py:65 2019-01-16 22:10:55.022886: step 9114, loss = 0.69663 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:10:55.913867 ops/training.py:65 2019-01-16 22:10:55.913804: step 9115, loss = 0.69255 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:10:56.807328 ops/training.py:65 2019-01-16 22:10:56.807207: step 9116, loss = 0.69713 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:10:57.700374 ops/training.py:65 2019-01-16 22:10:57.700296: step 9117, loss = 0.71954 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:10:58.594715 ops/training.py:65 2019-01-16 22:10:58.594601: step 9118, loss = 0.68725 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:10:59.488126 ops/training.py:65 2019-01-16 22:10:59.488004: step 9119, loss = 0.69711 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:11:00.380992 ops/training.py:65 2019-01-16 22:11:00.380940: step 9120, loss = 0.70818 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:11:01.270367 ops/training.py:65 2019-01-16 22:11:01.270317: step 9121, loss = 0.69657 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:11:02.159288 ops/training.py:65 2019-01-16 22:11:02.159235: step 9122, loss = 0.69946 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:11:03.048197 ops/training.py:65 2019-01-16 22:11:03.048143: step 9123, loss = 0.69788 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:11:03.938523 ops/training.py:65 2019-01-16 22:11:03.938451: step 9124, loss = 0.69845 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:11:04.830908 ops/training.py:65 2019-01-16 22:11:04.830792: step 9125, loss = 0.68312 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:11:05.721961 ops/training.py:65 2019-01-16 22:11:05.721913: step 9126, loss = 0.68854 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:11:06.610460 ops/training.py:65 2019-01-16 22:11:06.610407: step 9127, loss = 0.69163 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:11:07.499430 ops/training.py:65 2019-01-16 22:11:07.499379: step 9128, loss = 0.69025 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:11:08.388086 ops/training.py:65 2019-01-16 22:11:08.388036: step 9129, loss = 0.69795 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:11:09.276090 ops/training.py:65 2019-01-16 22:11:09.276042: step 9130, loss = 0.69815 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:11:10.164907 ops/training.py:65 2019-01-16 22:11:10.164856: step 9131, loss = 0.70418 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:11:11.053951 ops/training.py:65 2019-01-16 22:11:11.053900: step 9132, loss = 0.69970 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:11:11.942854 ops/training.py:65 2019-01-16 22:11:11.942803: step 9133, loss = 0.71873 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.25
I2992 2019-01-16 22:11:12.831742 ops/training.py:65 2019-01-16 22:11:12.831686: step 9134, loss = 0.68794 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:11:13.720936 ops/training.py:65 2019-01-16 22:11:13.720871: step 9135, loss = 0.69449 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:11:14.609186 ops/training.py:65 2019-01-16 22:11:14.609135: step 9136, loss = 0.70000 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:11:15.497484 ops/training.py:65 2019-01-16 22:11:15.497432: step 9137, loss = 0.70049 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:11:16.386026 ops/training.py:65 2019-01-16 22:11:16.385974: step 9138, loss = 0.67622 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:11:17.275179 ops/training.py:65 2019-01-16 22:11:17.275131: step 9139, loss = 0.70022 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:11:18.163680 ops/training.py:65 2019-01-16 22:11:18.163630: step 9140, loss = 0.69115 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:11:19.052638 ops/training.py:65 2019-01-16 22:11:19.052590: step 9141, loss = 0.69183 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:11:19.941321 ops/training.py:65 2019-01-16 22:11:19.941273: step 9142, loss = 0.68781 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:11:20.836439 ops/training.py:65 2019-01-16 22:11:20.836392: step 9143, loss = 0.69965 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:11:21.724409 ops/training.py:65 2019-01-16 22:11:21.724360: step 9144, loss = 0.66676 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 22:11:22.615323 ops/training.py:65 2019-01-16 22:11:22.615280: step 9145, loss = 0.69852 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:11:23.507612 ops/training.py:65 2019-01-16 22:11:23.507570: step 9146, loss = 0.68768 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:11:24.400184 ops/training.py:65 2019-01-16 22:11:24.400150: step 9147, loss = 0.69335 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:11:25.291467 ops/training.py:65 2019-01-16 22:11:25.291413: step 9148, loss = 0.71115 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:11:26.180284 ops/training.py:65 2019-01-16 22:11:26.180210: step 9149, loss = 0.68452 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:11:27.069481 ops/training.py:65 2019-01-16 22:11:27.069429: step 9150, loss = 0.71129 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:11:27.958520 ops/training.py:65 2019-01-16 22:11:27.958466: step 9151, loss = 0.70203 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:11:28.846992 ops/training.py:65 2019-01-16 22:11:28.846941: step 9152, loss = 0.69447 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:11:29.735891 ops/training.py:65 2019-01-16 22:11:29.735859: step 9153, loss = 0.72022 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:11:30.627720 ops/training.py:65 2019-01-16 22:11:30.627683: step 9154, loss = 0.69189 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:11:31.519917 ops/training.py:65 2019-01-16 22:11:31.519883: step 9155, loss = 0.68840 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:11:32.413564 ops/training.py:65 2019-01-16 22:11:32.413527: step 9156, loss = 0.69210 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:11:33.306963 ops/training.py:65 2019-01-16 22:11:33.306921: step 9157, loss = 0.69829 (35.9 examples/sec; 0.893 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:11:34.198748 ops/training.py:65 2019-01-16 22:11:34.198718: step 9158, loss = 0.71124 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:11:35.089710 ops/training.py:65 2019-01-16 22:11:35.089652: step 9159, loss = 0.67849 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:11:35.978069 ops/training.py:65 2019-01-16 22:11:35.977998: step 9160, loss = 0.69888 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:11:36.866937 ops/training.py:65 2019-01-16 22:11:36.866849: step 9161, loss = 0.69014 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:11:37.756060 ops/training.py:65 2019-01-16 22:11:37.755955: step 9162, loss = 0.70885 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:11:38.644505 ops/training.py:65 2019-01-16 22:11:38.644448: step 9163, loss = 0.68980 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:11:39.533971 ops/training.py:65 2019-01-16 22:11:39.533920: step 9164, loss = 0.69228 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:11:40.423428 ops/training.py:65 2019-01-16 22:11:40.423374: step 9165, loss = 0.70911 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:11:41.315967 ops/training.py:65 2019-01-16 22:11:41.315931: step 9166, loss = 0.70821 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:11:42.208010 ops/training.py:65 2019-01-16 22:11:42.207980: step 9167, loss = 0.69888 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:11:43.099151 ops/training.py:65 2019-01-16 22:11:43.099090: step 9168, loss = 0.69079 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:11:43.988553 ops/training.py:65 2019-01-16 22:11:43.988495: step 9169, loss = 0.68844 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:11:44.878469 ops/training.py:65 2019-01-16 22:11:44.878414: step 9170, loss = 0.68471 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:11:45.768134 ops/training.py:65 2019-01-16 22:11:45.768082: step 9171, loss = 0.68793 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:11:46.658267 ops/training.py:65 2019-01-16 22:11:46.658201: step 9172, loss = 0.68945 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:11:47.547160 ops/training.py:65 2019-01-16 22:11:47.547117: step 9173, loss = 0.70060 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:11:48.436595 ops/training.py:65 2019-01-16 22:11:48.436514: step 9174, loss = 0.70658 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:11:49.325227 ops/training.py:65 2019-01-16 22:11:49.325113: step 9175, loss = 0.69086 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:11:50.214335 ops/training.py:65 2019-01-16 22:11:50.214230: step 9176, loss = 0.68031 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:11:51.103036 ops/training.py:65 2019-01-16 22:11:51.102961: step 9177, loss = 0.71037 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:11:51.994433 ops/training.py:65 2019-01-16 22:11:51.994365: step 9178, loss = 0.68278 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:11:52.887553 ops/training.py:65 2019-01-16 22:11:52.887436: step 9179, loss = 0.67621 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:11:53.778297 ops/training.py:65 2019-01-16 22:11:53.778234: step 9180, loss = 0.71514 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:11:54.668408 ops/training.py:65 2019-01-16 22:11:54.668359: step 9181, loss = 0.67168 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:11:55.559444 ops/training.py:65 2019-01-16 22:11:55.559391: step 9182, loss = 0.70416 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:11:56.451626 ops/training.py:65 2019-01-16 22:11:56.451521: step 9183, loss = 0.71409 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:11:57.343233 ops/training.py:65 2019-01-16 22:11:57.343185: step 9184, loss = 0.69414 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:11:58.232392 ops/training.py:65 2019-01-16 22:11:58.232331: step 9185, loss = 0.70272 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:11:59.122044 ops/training.py:65 2019-01-16 22:11:59.121984: step 9186, loss = 0.73148 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 22:12:00.010755 ops/training.py:65 2019-01-16 22:12:00.010720: step 9187, loss = 0.70443 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:12:00.899423 ops/training.py:65 2019-01-16 22:12:00.899358: step 9188, loss = 0.68602 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:12:01.788447 ops/training.py:65 2019-01-16 22:12:01.788376: step 9189, loss = 0.68840 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:12:02.677415 ops/training.py:65 2019-01-16 22:12:02.677369: step 9190, loss = 0.69988 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:12:03.568957 ops/training.py:65 2019-01-16 22:12:03.568868: step 9191, loss = 0.69502 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:12:04.458871 ops/training.py:65 2019-01-16 22:12:04.458819: step 9192, loss = 0.69359 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:12:05.347455 ops/training.py:65 2019-01-16 22:12:05.347406: step 9193, loss = 0.69733 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:12:06.236060 ops/training.py:65 2019-01-16 22:12:06.236009: step 9194, loss = 0.70376 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:12:07.123962 ops/training.py:65 2019-01-16 22:12:07.123914: step 9195, loss = 0.68744 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:12:08.013569 ops/training.py:65 2019-01-16 22:12:08.013521: step 9196, loss = 0.68895 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:12:08.903393 ops/training.py:65 2019-01-16 22:12:08.903344: step 9197, loss = 0.71005 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:12:09.792086 ops/training.py:65 2019-01-16 22:12:09.792037: step 9198, loss = 0.69721 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:12:10.682188 ops/training.py:65 2019-01-16 22:12:10.682109: step 9199, loss = 0.69745 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:12:11.576199 ops/training.py:65 2019-01-16 22:12:11.576083: step 9200, loss = 0.70521 (35.8 examples/sec; 0.893 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:12:12.467651 ops/training.py:65 2019-01-16 22:12:12.467597: step 9201, loss = 0.68840 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:12:13.357783 ops/training.py:65 2019-01-16 22:12:13.357718: step 9202, loss = 0.69524 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:12:14.247759 ops/training.py:65 2019-01-16 22:12:14.247709: step 9203, loss = 0.67793 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:12:15.136810 ops/training.py:65 2019-01-16 22:12:15.136757: step 9204, loss = 0.73268 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.1875
I2992 2019-01-16 22:12:16.025852 ops/training.py:65 2019-01-16 22:12:16.025796: step 9205, loss = 0.69456 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:12:16.914455 ops/training.py:65 2019-01-16 22:12:16.914403: step 9206, loss = 0.68842 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:12:17.803492 ops/training.py:65 2019-01-16 22:12:17.803438: step 9207, loss = 0.69456 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:12:18.693163 ops/training.py:65 2019-01-16 22:12:18.693110: step 9208, loss = 0.68048 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 22:12:19.582489 ops/training.py:65 2019-01-16 22:12:19.582438: step 9209, loss = 0.69725 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:12:20.470890 ops/training.py:65 2019-01-16 22:12:20.470843: step 9210, loss = 0.68610 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:12:21.358991 ops/training.py:65 2019-01-16 22:12:21.358938: step 9211, loss = 0.70975 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 22:12:22.248113 ops/training.py:65 2019-01-16 22:12:22.248062: step 9212, loss = 0.68922 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:12:23.136657 ops/training.py:65 2019-01-16 22:12:23.136597: step 9213, loss = 0.69571 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:12:24.025710 ops/training.py:65 2019-01-16 22:12:24.025656: step 9214, loss = 0.68624 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:12:24.915099 ops/training.py:65 2019-01-16 22:12:24.915048: step 9215, loss = 0.69817 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:12:25.803636 ops/training.py:65 2019-01-16 22:12:25.803580: step 9216, loss = 0.68972 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:12:26.691116 ops/training.py:65 2019-01-16 22:12:26.691068: step 9217, loss = 0.70288 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:12:27.581208 ops/training.py:65 2019-01-16 22:12:27.581153: step 9218, loss = 0.70083 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:12:28.471402 ops/training.py:65 2019-01-16 22:12:28.471342: step 9219, loss = 0.69800 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:12:29.359995 ops/training.py:65 2019-01-16 22:12:29.359936: step 9220, loss = 0.70472 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:12:30.247786 ops/training.py:65 2019-01-16 22:12:30.247736: step 9221, loss = 0.68688 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:12:31.136184 ops/training.py:65 2019-01-16 22:12:31.136135: step 9222, loss = 0.69728 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:12:32.026282 ops/training.py:65 2019-01-16 22:12:32.026228: step 9223, loss = 0.68830 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:12:32.914765 ops/training.py:65 2019-01-16 22:12:32.914716: step 9224, loss = 0.67797 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:12:33.803888 ops/training.py:65 2019-01-16 22:12:33.803829: step 9225, loss = 0.69868 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:12:34.693742 ops/training.py:65 2019-01-16 22:12:34.693705: step 9226, loss = 0.69092 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:12:35.586836 ops/training.py:65 2019-01-16 22:12:35.586755: step 9227, loss = 0.69818 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:12:36.480424 ops/training.py:65 2019-01-16 22:12:36.480306: step 9228, loss = 0.69875 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:12:37.375613 ops/training.py:65 2019-01-16 22:12:37.375522: step 9229, loss = 0.69308 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:12:38.268685 ops/training.py:65 2019-01-16 22:12:38.268577: step 9230, loss = 0.68109 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:12:39.159819 ops/training.py:65 2019-01-16 22:12:39.159767: step 9231, loss = 0.68558 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:12:40.048360 ops/training.py:65 2019-01-16 22:12:40.048309: step 9232, loss = 0.69945 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:12:40.937687 ops/training.py:65 2019-01-16 22:12:40.937636: step 9233, loss = 0.68930 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:12:41.826786 ops/training.py:65 2019-01-16 22:12:41.826730: step 9234, loss = 0.69715 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:12:42.715976 ops/training.py:65 2019-01-16 22:12:42.715926: step 9235, loss = 0.69152 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:12:43.604697 ops/training.py:65 2019-01-16 22:12:43.604635: step 9236, loss = 0.67631 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:12:44.494429 ops/training.py:65 2019-01-16 22:12:44.494372: step 9237, loss = 0.70848 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:12:45.383576 ops/training.py:65 2019-01-16 22:12:45.383516: step 9238, loss = 0.69174 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:12:46.278545 ops/training.py:65 2019-01-16 22:12:46.278491: step 9239, loss = 0.68613 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:12:47.167537 ops/training.py:65 2019-01-16 22:12:47.167484: step 9240, loss = 0.69518 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:12:48.056559 ops/training.py:65 2019-01-16 22:12:48.056508: step 9241, loss = 0.69989 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:12:48.945499 ops/training.py:65 2019-01-16 22:12:48.945452: step 9242, loss = 0.68584 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:12:49.834416 ops/training.py:65 2019-01-16 22:12:49.834364: step 9243, loss = 0.67217 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:12:50.723389 ops/training.py:65 2019-01-16 22:12:50.723337: step 9244, loss = 0.68554 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:12:51.613739 ops/training.py:65 2019-01-16 22:12:51.613688: step 9245, loss = 0.69802 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:12:52.502899 ops/training.py:65 2019-01-16 22:12:52.502847: step 9246, loss = 0.69484 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:12:53.392345 ops/training.py:65 2019-01-16 22:12:53.392282: step 9247, loss = 0.69978 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:12:54.282248 ops/training.py:65 2019-01-16 22:12:54.282198: step 9248, loss = 0.70864 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:12:55.173272 ops/training.py:65 2019-01-16 22:12:55.173203: step 9249, loss = 0.69167 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:12:56.064858 ops/training.py:65 2019-01-16 22:12:56.064749: step 9250, loss = 0.68331 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 22:12:56.957241 ops/training.py:65 2019-01-16 22:12:56.957124: step 9251, loss = 0.68935 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:12:57.847824 ops/training.py:65 2019-01-16 22:12:57.847713: step 9252, loss = 0.69637 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:12:58.737778 ops/training.py:65 2019-01-16 22:12:58.737678: step 9253, loss = 0.69564 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:12:59.627258 ops/training.py:65 2019-01-16 22:12:59.627158: step 9254, loss = 0.68785 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:13:00.516883 ops/training.py:65 2019-01-16 22:13:00.516822: step 9255, loss = 0.68449 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:13:01.406266 ops/training.py:65 2019-01-16 22:13:01.406210: step 9256, loss = 0.68859 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:13:02.295651 ops/training.py:65 2019-01-16 22:13:02.295586: step 9257, loss = 0.66822 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 22:13:03.185461 ops/training.py:65 2019-01-16 22:13:03.185403: step 9258, loss = 0.68821 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:13:04.074461 ops/training.py:65 2019-01-16 22:13:04.074410: step 9259, loss = 0.68712 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:13:04.963625 ops/training.py:65 2019-01-16 22:13:04.963579: step 9260, loss = 0.68873 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:13:05.856520 ops/training.py:65 2019-01-16 22:13:05.856408: step 9261, loss = 0.69820 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:13:06.749511 ops/training.py:65 2019-01-16 22:13:06.749418: step 9262, loss = 0.69231 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:13:07.638615 ops/training.py:65 2019-01-16 22:13:07.638563: step 9263, loss = 0.69642 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:13:08.533746 ops/training.py:65 2019-01-16 22:13:08.533659: step 9264, loss = 0.67903 (35.8 examples/sec; 0.894 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:13:09.426129 ops/training.py:65 2019-01-16 22:13:09.426026: step 9265, loss = 0.69444 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:13:10.318107 ops/training.py:65 2019-01-16 22:13:10.318044: step 9266, loss = 0.68753 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:13:11.207249 ops/training.py:65 2019-01-16 22:13:11.207189: step 9267, loss = 0.68037 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 22:13:12.097235 ops/training.py:65 2019-01-16 22:13:12.097174: step 9268, loss = 0.70415 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:13:12.986964 ops/training.py:65 2019-01-16 22:13:12.986901: step 9269, loss = 0.70235 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 22:13:13.876068 ops/training.py:65 2019-01-16 22:13:13.875999: step 9270, loss = 0.68682 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:13:14.765984 ops/training.py:65 2019-01-16 22:13:14.765931: step 9271, loss = 0.68619 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:13:15.655407 ops/training.py:65 2019-01-16 22:13:15.655347: step 9272, loss = 0.69398 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:13:16.543882 ops/training.py:65 2019-01-16 22:13:16.543821: step 9273, loss = 0.68811 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:13:17.432488 ops/training.py:65 2019-01-16 22:13:17.432437: step 9274, loss = 0.69086 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:13:18.320987 ops/training.py:65 2019-01-16 22:13:18.320928: step 9275, loss = 0.70146 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:13:19.210489 ops/training.py:65 2019-01-16 22:13:19.210404: step 9276, loss = 0.68571 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:13:20.100870 ops/training.py:65 2019-01-16 22:13:20.100815: step 9277, loss = 0.69676 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:13:20.991564 ops/training.py:65 2019-01-16 22:13:20.991512: step 9278, loss = 0.70081 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:13:21.881055 ops/training.py:65 2019-01-16 22:13:21.881004: step 9279, loss = 0.69537 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:13:22.770036 ops/training.py:65 2019-01-16 22:13:22.769979: step 9280, loss = 0.68421 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:13:23.658627 ops/training.py:65 2019-01-16 22:13:23.658567: step 9281, loss = 0.71359 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:13:24.547238 ops/training.py:65 2019-01-16 22:13:24.547186: step 9282, loss = 0.68591 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:13:25.436951 ops/training.py:65 2019-01-16 22:13:25.436896: step 9283, loss = 0.69362 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:13:26.326196 ops/training.py:65 2019-01-16 22:13:26.326144: step 9284, loss = 0.69052 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:13:27.215800 ops/training.py:65 2019-01-16 22:13:27.215734: step 9285, loss = 0.70587 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:13:28.106138 ops/training.py:65 2019-01-16 22:13:28.106081: step 9286, loss = 0.70852 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:13:28.994718 ops/training.py:65 2019-01-16 22:13:28.994669: step 9287, loss = 0.69357 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:13:29.883592 ops/training.py:65 2019-01-16 22:13:29.883541: step 9288, loss = 0.68757 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:13:30.773554 ops/training.py:65 2019-01-16 22:13:30.773495: step 9289, loss = 0.68980 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:13:31.662358 ops/training.py:65 2019-01-16 22:13:31.662308: step 9290, loss = 0.72069 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:13:32.550674 ops/training.py:65 2019-01-16 22:13:32.550622: step 9291, loss = 0.69826 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:13:33.439389 ops/training.py:65 2019-01-16 22:13:33.439333: step 9292, loss = 0.70313 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:13:34.328743 ops/training.py:65 2019-01-16 22:13:34.328694: step 9293, loss = 0.68849 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:13:35.217555 ops/training.py:65 2019-01-16 22:13:35.217507: step 9294, loss = 0.69722 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:13:36.106016 ops/training.py:65 2019-01-16 22:13:36.105962: step 9295, loss = 0.71842 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:13:36.995039 ops/training.py:65 2019-01-16 22:13:36.994989: step 9296, loss = 0.68926 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:13:37.885453 ops/training.py:65 2019-01-16 22:13:37.885410: step 9297, loss = 0.67821 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:13:38.777609 ops/training.py:65 2019-01-16 22:13:38.777550: step 9298, loss = 0.68896 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:13:39.666658 ops/training.py:65 2019-01-16 22:13:39.666603: step 9299, loss = 0.70151 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:13:40.555946 ops/training.py:65 2019-01-16 22:13:40.555895: step 9300, loss = 0.68338 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:13:41.445074 ops/training.py:65 2019-01-16 22:13:41.445019: step 9301, loss = 0.69521 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:13:42.333998 ops/training.py:65 2019-01-16 22:13:42.333948: step 9302, loss = 0.68944 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:13:43.222622 ops/training.py:65 2019-01-16 22:13:43.222558: step 9303, loss = 0.68651 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:13:44.111336 ops/training.py:65 2019-01-16 22:13:44.111280: step 9304, loss = 0.70489 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:13:44.999845 ops/training.py:65 2019-01-16 22:13:44.999793: step 9305, loss = 0.69926 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:13:45.888695 ops/training.py:65 2019-01-16 22:13:45.888635: step 9306, loss = 0.71509 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:13:46.777740 ops/training.py:65 2019-01-16 22:13:46.777686: step 9307, loss = 0.69323 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:13:47.667405 ops/training.py:65 2019-01-16 22:13:47.667350: step 9308, loss = 0.68640 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:13:48.555602 ops/training.py:65 2019-01-16 22:13:48.555548: step 9309, loss = 0.69229 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:13:49.443644 ops/training.py:65 2019-01-16 22:13:49.443584: step 9310, loss = 0.69858 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:13:50.332630 ops/training.py:65 2019-01-16 22:13:50.332570: step 9311, loss = 0.71194 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:13:51.221802 ops/training.py:65 2019-01-16 22:13:51.221747: step 9312, loss = 0.68893 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:13:52.110580 ops/training.py:65 2019-01-16 22:13:52.110520: step 9313, loss = 0.69404 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:13:52.999261 ops/training.py:65 2019-01-16 22:13:52.999200: step 9314, loss = 0.69895 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:13:53.888463 ops/training.py:65 2019-01-16 22:13:53.888389: step 9315, loss = 0.70542 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:13:54.777971 ops/training.py:65 2019-01-16 22:13:54.777897: step 9316, loss = 0.69359 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:13:55.667282 ops/training.py:65 2019-01-16 22:13:55.667217: step 9317, loss = 0.71679 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:13:56.555688 ops/training.py:65 2019-01-16 22:13:56.555629: step 9318, loss = 0.68993 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:13:57.444679 ops/training.py:65 2019-01-16 22:13:57.444615: step 9319, loss = 0.69054 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:13:58.333073 ops/training.py:65 2019-01-16 22:13:58.333007: step 9320, loss = 0.67506 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:13:59.222540 ops/training.py:65 2019-01-16 22:13:59.222464: step 9321, loss = 0.69311 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:14:00.111108 ops/training.py:65 2019-01-16 22:14:00.111036: step 9322, loss = 0.68404 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:14:00.999653 ops/training.py:65 2019-01-16 22:14:00.999589: step 9323, loss = 0.68040 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:14:01.887705 ops/training.py:65 2019-01-16 22:14:01.887644: step 9324, loss = 0.68915 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:14:02.775212 ops/training.py:65 2019-01-16 22:14:02.775155: step 9325, loss = 0.68308 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:14:03.663636 ops/training.py:65 2019-01-16 22:14:03.663577: step 9326, loss = 0.69864 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:14:04.552581 ops/training.py:65 2019-01-16 22:14:04.552526: step 9327, loss = 0.69088 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:14:05.440976 ops/training.py:65 2019-01-16 22:14:05.440898: step 9328, loss = 0.69755 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:14:06.329983 ops/training.py:65 2019-01-16 22:14:06.329916: step 9329, loss = 0.68879 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:14:07.218685 ops/training.py:65 2019-01-16 22:14:07.218622: step 9330, loss = 0.68901 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:14:08.108785 ops/training.py:65 2019-01-16 22:14:08.108735: step 9331, loss = 0.69596 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:14:08.997546 ops/training.py:65 2019-01-16 22:14:08.997486: step 9332, loss = 0.67556 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:14:09.886391 ops/training.py:65 2019-01-16 22:14:09.886330: step 9333, loss = 0.72877 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:14:10.776140 ops/training.py:65 2019-01-16 22:14:10.776075: step 9334, loss = 0.70511 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:14:11.664736 ops/training.py:65 2019-01-16 22:14:11.664670: step 9335, loss = 0.69725 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:14:12.553108 ops/training.py:65 2019-01-16 22:14:12.553042: step 9336, loss = 0.70041 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:14:13.442164 ops/training.py:65 2019-01-16 22:14:13.442096: step 9337, loss = 0.71532 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:14:14.331008 ops/training.py:65 2019-01-16 22:14:14.330942: step 9338, loss = 0.70950 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:14:15.219091 ops/training.py:65 2019-01-16 22:14:15.219036: step 9339, loss = 0.69868 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:14:16.107783 ops/training.py:65 2019-01-16 22:14:16.107725: step 9340, loss = 0.69868 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:14:16.995684 ops/training.py:65 2019-01-16 22:14:16.995628: step 9341, loss = 0.70714 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:14:17.884529 ops/training.py:65 2019-01-16 22:14:17.884466: step 9342, loss = 0.67884 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 22:14:18.774022 ops/training.py:65 2019-01-16 22:14:18.773957: step 9343, loss = 0.70078 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:14:19.662855 ops/training.py:65 2019-01-16 22:14:19.662791: step 9344, loss = 0.69547 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:14:20.551785 ops/training.py:65 2019-01-16 22:14:20.551728: step 9345, loss = 0.69508 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:14:21.440742 ops/training.py:65 2019-01-16 22:14:21.440685: step 9346, loss = 0.69624 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:14:22.329861 ops/training.py:65 2019-01-16 22:14:22.329798: step 9347, loss = 0.69112 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:14:23.219373 ops/training.py:65 2019-01-16 22:14:23.219306: step 9348, loss = 0.70121 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:14:24.108769 ops/training.py:65 2019-01-16 22:14:24.108714: step 9349, loss = 0.69587 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:14:24.998383 ops/training.py:65 2019-01-16 22:14:24.998313: step 9350, loss = 0.70390 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:14:25.887612 ops/training.py:65 2019-01-16 22:14:25.887541: step 9351, loss = 0.71488 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 22:14:26.777392 ops/training.py:65 2019-01-16 22:14:26.777323: step 9352, loss = 0.67744 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:14:27.666940 ops/training.py:65 2019-01-16 22:14:27.666872: step 9353, loss = 0.67783 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:14:28.555986 ops/training.py:65 2019-01-16 22:14:28.555926: step 9354, loss = 0.70872 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:14:29.445321 ops/training.py:65 2019-01-16 22:14:29.445274: step 9355, loss = 0.70216 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:14:30.333779 ops/training.py:65 2019-01-16 22:14:30.333709: step 9356, loss = 0.69281 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:14:31.223301 ops/training.py:65 2019-01-16 22:14:31.223250: step 9357, loss = 0.69859 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:14:32.112638 ops/training.py:65 2019-01-16 22:14:32.112582: step 9358, loss = 0.70800 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:14:33.001956 ops/training.py:65 2019-01-16 22:14:33.001900: step 9359, loss = 0.69656 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:14:33.891016 ops/training.py:65 2019-01-16 22:14:33.890954: step 9360, loss = 0.72660 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:14:34.780292 ops/training.py:65 2019-01-16 22:14:34.780238: step 9361, loss = 0.72346 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:14:35.669719 ops/training.py:65 2019-01-16 22:14:35.669661: step 9362, loss = 0.68931 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:14:36.558903 ops/training.py:65 2019-01-16 22:14:36.558848: step 9363, loss = 0.66608 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:14:37.448514 ops/training.py:65 2019-01-16 22:14:37.448454: step 9364, loss = 0.71295 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:14:38.338214 ops/training.py:65 2019-01-16 22:14:38.338155: step 9365, loss = 0.69362 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:14:39.226547 ops/training.py:65 2019-01-16 22:14:39.226487: step 9366, loss = 0.73958 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:14:40.116442 ops/training.py:65 2019-01-16 22:14:40.116391: step 9367, loss = 0.70574 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:14:41.005035 ops/training.py:65 2019-01-16 22:14:41.004979: step 9368, loss = 0.65321 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:14:41.893816 ops/training.py:65 2019-01-16 22:14:41.893767: step 9369, loss = 0.68274 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:14:42.782934 ops/training.py:65 2019-01-16 22:14:42.782904: step 9370, loss = 0.69171 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:14:43.673621 ops/training.py:65 2019-01-16 22:14:43.673554: step 9371, loss = 0.67781 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:14:44.561904 ops/training.py:65 2019-01-16 22:14:44.561849: step 9372, loss = 0.71420 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:14:45.451441 ops/training.py:65 2019-01-16 22:14:45.451387: step 9373, loss = 0.69517 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:14:46.341048 ops/training.py:65 2019-01-16 22:14:46.340984: step 9374, loss = 0.69668 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:14:47.231370 ops/training.py:65 2019-01-16 22:14:47.231309: step 9375, loss = 0.73475 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:14:48.121571 ops/training.py:65 2019-01-16 22:14:48.121520: step 9376, loss = 0.72284 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:14:49.011382 ops/training.py:65 2019-01-16 22:14:49.011332: step 9377, loss = 0.68340 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:14:49.900947 ops/training.py:65 2019-01-16 22:14:49.900888: step 9378, loss = 0.68172 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:14:50.790571 ops/training.py:65 2019-01-16 22:14:50.790514: step 9379, loss = 0.69491 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:14:51.679690 ops/training.py:65 2019-01-16 22:14:51.679634: step 9380, loss = 0.69525 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:14:52.569610 ops/training.py:65 2019-01-16 22:14:52.569560: step 9381, loss = 0.71106 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:14:53.460075 ops/training.py:65 2019-01-16 22:14:53.460020: step 9382, loss = 0.73391 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:14:54.349852 ops/training.py:65 2019-01-16 22:14:54.349799: step 9383, loss = 0.66767 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:14:55.239604 ops/training.py:65 2019-01-16 22:14:55.239550: step 9384, loss = 0.70072 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:14:56.129320 ops/training.py:65 2019-01-16 22:14:56.129271: step 9385, loss = 0.71033 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:14:57.019055 ops/training.py:65 2019-01-16 22:14:57.019004: step 9386, loss = 0.71163 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:14:57.907791 ops/training.py:65 2019-01-16 22:14:57.907732: step 9387, loss = 0.68793 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:14:58.796504 ops/training.py:65 2019-01-16 22:14:58.796449: step 9388, loss = 0.66181 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.71875
I2992 2019-01-16 22:14:59.687409 ops/training.py:65 2019-01-16 22:14:59.687379: step 9389, loss = 0.70160 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:15:00.579045 ops/training.py:65 2019-01-16 22:15:00.578986: step 9390, loss = 0.71254 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:15:01.467867 ops/training.py:65 2019-01-16 22:15:01.467831: step 9391, loss = 0.67286 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:15:02.356915 ops/training.py:65 2019-01-16 22:15:02.356878: step 9392, loss = 0.68231 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:15:03.246138 ops/training.py:65 2019-01-16 22:15:03.246088: step 9393, loss = 0.69232 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:15:04.135337 ops/training.py:65 2019-01-16 22:15:04.135293: step 9394, loss = 0.72376 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:15:05.023569 ops/training.py:65 2019-01-16 22:15:05.023527: step 9395, loss = 0.68984 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:15:05.912413 ops/training.py:65 2019-01-16 22:15:05.912365: step 9396, loss = 0.68456 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:15:06.801489 ops/training.py:65 2019-01-16 22:15:06.801427: step 9397, loss = 0.70655 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:15:07.690815 ops/training.py:65 2019-01-16 22:15:07.690749: step 9398, loss = 0.69873 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:15:08.580614 ops/training.py:65 2019-01-16 22:15:08.580558: step 9399, loss = 0.71558 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:15:09.469029 ops/training.py:65 2019-01-16 22:15:09.468985: step 9400, loss = 0.68567 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:15:10.357244 ops/training.py:65 2019-01-16 22:15:10.357206: step 9401, loss = 0.68973 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:15:11.246008 ops/training.py:65 2019-01-16 22:15:11.245936: step 9402, loss = 0.68696 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:15:12.135138 ops/training.py:65 2019-01-16 22:15:12.135100: step 9403, loss = 0.69402 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:15:13.023851 ops/training.py:65 2019-01-16 22:15:13.023809: step 9404, loss = 0.70375 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:15:13.914848 ops/training.py:65 2019-01-16 22:15:13.914815: step 9405, loss = 0.69506 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:15:14.805502 ops/training.py:65 2019-01-16 22:15:14.805474: step 9406, loss = 0.67256 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:15:15.696516 ops/training.py:65 2019-01-16 22:15:15.696486: step 9407, loss = 0.67877 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:15:16.587846 ops/training.py:65 2019-01-16 22:15:16.587814: step 9408, loss = 0.67165 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:15:17.477548 ops/training.py:65 2019-01-16 22:15:17.477501: step 9409, loss = 0.70807 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:15:18.366425 ops/training.py:65 2019-01-16 22:15:18.366370: step 9410, loss = 0.68380 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:15:19.255683 ops/training.py:65 2019-01-16 22:15:19.255638: step 9411, loss = 0.69652 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:15:20.144394 ops/training.py:65 2019-01-16 22:15:20.144345: step 9412, loss = 0.69213 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:15:21.033117 ops/training.py:65 2019-01-16 22:15:21.033077: step 9413, loss = 0.69510 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:15:21.922565 ops/training.py:65 2019-01-16 22:15:21.922517: step 9414, loss = 0.68795 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:15:22.812508 ops/training.py:65 2019-01-16 22:15:22.812461: step 9415, loss = 0.71263 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:15:23.702245 ops/training.py:65 2019-01-16 22:15:23.702204: step 9416, loss = 0.68836 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:15:24.592664 ops/training.py:65 2019-01-16 22:15:24.592622: step 9417, loss = 0.70825 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:15:25.482379 ops/training.py:65 2019-01-16 22:15:25.482331: step 9418, loss = 0.66592 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:15:26.372503 ops/training.py:65 2019-01-16 22:15:26.372455: step 9419, loss = 0.70098 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:15:27.263066 ops/training.py:65 2019-01-16 22:15:27.263017: step 9420, loss = 0.68350 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:15:28.152888 ops/training.py:65 2019-01-16 22:15:28.152854: step 9421, loss = 0.70478 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:15:29.043123 ops/training.py:65 2019-01-16 22:15:29.043096: step 9422, loss = 0.68146 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:15:29.934248 ops/training.py:65 2019-01-16 22:15:29.934219: step 9423, loss = 0.72230 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:15:30.825828 ops/training.py:65 2019-01-16 22:15:30.825796: step 9424, loss = 0.70379 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:15:31.715461 ops/training.py:65 2019-01-16 22:15:31.715417: step 9425, loss = 0.68908 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:15:32.604700 ops/training.py:65 2019-01-16 22:15:32.604653: step 9426, loss = 0.69155 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:15:33.495015 ops/training.py:65 2019-01-16 22:15:33.494976: step 9427, loss = 0.69998 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:15:34.386627 ops/training.py:65 2019-01-16 22:15:34.386599: step 9428, loss = 0.67592 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:15:35.279483 ops/training.py:65 2019-01-16 22:15:35.279448: step 9429, loss = 0.71725 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:15:36.168512 ops/training.py:65 2019-01-16 22:15:36.168472: step 9430, loss = 0.66257 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:15:37.058590 ops/training.py:65 2019-01-16 22:15:37.058559: step 9431, loss = 0.68598 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:15:37.949888 ops/training.py:65 2019-01-16 22:15:37.949860: step 9432, loss = 0.66460 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:15:38.840293 ops/training.py:65 2019-01-16 22:15:38.840190: step 9433, loss = 0.68964 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:15:39.733668 ops/training.py:65 2019-01-16 22:15:39.733562: step 9434, loss = 0.69867 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:15:40.625367 ops/training.py:65 2019-01-16 22:15:40.625320: step 9435, loss = 0.66762 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:15:41.515647 ops/training.py:65 2019-01-16 22:15:41.515602: step 9436, loss = 0.69898 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:15:42.407183 ops/training.py:65 2019-01-16 22:15:42.407131: step 9437, loss = 0.68970 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:15:43.299201 ops/training.py:65 2019-01-16 22:15:43.299105: step 9438, loss = 0.72246 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:15:44.191731 ops/training.py:65 2019-01-16 22:15:44.191620: step 9439, loss = 0.70695 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:15:45.082923 ops/training.py:65 2019-01-16 22:15:45.082865: step 9440, loss = 0.68990 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:15:45.973556 ops/training.py:65 2019-01-16 22:15:45.973499: step 9441, loss = 0.70865 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:15:46.862642 ops/training.py:65 2019-01-16 22:15:46.862573: step 9442, loss = 0.70523 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:15:47.753395 ops/training.py:65 2019-01-16 22:15:47.753337: step 9443, loss = 0.67905 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:15:48.643561 ops/training.py:65 2019-01-16 22:15:48.643499: step 9444, loss = 0.70215 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:15:49.535063 ops/training.py:65 2019-01-16 22:15:49.534953: step 9445, loss = 0.71192 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:15:50.425953 ops/training.py:65 2019-01-16 22:15:50.425857: step 9446, loss = 0.67354 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:15:51.319615 ops/training.py:65 2019-01-16 22:15:51.319498: step 9447, loss = 0.70311 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:15:52.211517 ops/training.py:65 2019-01-16 22:15:52.211429: step 9448, loss = 0.68690 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:15:53.100753 ops/training.py:65 2019-01-16 22:15:53.100697: step 9449, loss = 0.69731 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:15:53.991631 ops/training.py:65 2019-01-16 22:15:53.991581: step 9450, loss = 0.72253 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:15:54.893782 ops/training.py:65 2019-01-16 22:15:54.893666: step 9451, loss = 0.69688 (35.5 examples/sec; 0.901 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:15:55.785266 ops/training.py:65 2019-01-16 22:15:55.785126: step 9452, loss = 0.68637 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:15:56.675089 ops/training.py:65 2019-01-16 22:15:56.675038: step 9453, loss = 0.69612 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:15:57.564618 ops/training.py:65 2019-01-16 22:15:57.564567: step 9454, loss = 0.70002 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:15:58.454046 ops/training.py:65 2019-01-16 22:15:58.453997: step 9455, loss = 0.71366 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:15:59.343379 ops/training.py:65 2019-01-16 22:15:59.343326: step 9456, loss = 0.67526 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:16:00.232131 ops/training.py:65 2019-01-16 22:16:00.232081: step 9457, loss = 0.69245 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:16:01.121505 ops/training.py:65 2019-01-16 22:16:01.121448: step 9458, loss = 0.71874 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 22:16:02.010648 ops/training.py:65 2019-01-16 22:16:02.010600: step 9459, loss = 0.70535 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:16:02.899111 ops/training.py:65 2019-01-16 22:16:02.899058: step 9460, loss = 0.68013 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:16:03.788541 ops/training.py:65 2019-01-16 22:16:03.788485: step 9461, loss = 0.69012 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:16:04.678335 ops/training.py:65 2019-01-16 22:16:04.678283: step 9462, loss = 0.69182 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:16:05.567332 ops/training.py:65 2019-01-16 22:16:05.567274: step 9463, loss = 0.68623 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:16:06.456356 ops/training.py:65 2019-01-16 22:16:06.456293: step 9464, loss = 0.68361 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:16:07.345069 ops/training.py:65 2019-01-16 22:16:07.345005: step 9465, loss = 0.72679 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 22:16:08.233660 ops/training.py:65 2019-01-16 22:16:08.233607: step 9466, loss = 0.70469 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:16:09.122924 ops/training.py:65 2019-01-16 22:16:09.122876: step 9467, loss = 0.69952 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:16:10.012061 ops/training.py:65 2019-01-16 22:16:10.012009: step 9468, loss = 0.70327 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:16:10.900585 ops/training.py:65 2019-01-16 22:16:10.900541: step 9469, loss = 0.69365 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:16:11.789363 ops/training.py:65 2019-01-16 22:16:11.789315: step 9470, loss = 0.71457 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:16:12.678950 ops/training.py:65 2019-01-16 22:16:12.678900: step 9471, loss = 0.71519 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:16:13.568782 ops/training.py:65 2019-01-16 22:16:13.568731: step 9472, loss = 0.72248 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 22:16:14.459155 ops/training.py:65 2019-01-16 22:16:14.459125: step 9473, loss = 0.68659 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:16:15.351617 ops/training.py:65 2019-01-16 22:16:15.351590: step 9474, loss = 0.70525 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:16:16.243690 ops/training.py:65 2019-01-16 22:16:16.243656: step 9475, loss = 0.69144 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:16:17.133384 ops/training.py:65 2019-01-16 22:16:17.133343: step 9476, loss = 0.68854 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:16:18.024366 ops/training.py:65 2019-01-16 22:16:18.024317: step 9477, loss = 0.69616 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:16:18.913900 ops/training.py:65 2019-01-16 22:16:18.913843: step 9478, loss = 0.69983 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:16:19.803223 ops/training.py:65 2019-01-16 22:16:19.803154: step 9479, loss = 0.69680 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:16:20.693028 ops/training.py:65 2019-01-16 22:16:20.692982: step 9480, loss = 0.68674 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:16:21.583598 ops/training.py:65 2019-01-16 22:16:21.583568: step 9481, loss = 0.68080 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:16:22.476777 ops/training.py:65 2019-01-16 22:16:22.476749: step 9482, loss = 0.69470 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:16:23.368419 ops/training.py:65 2019-01-16 22:16:23.368390: step 9483, loss = 0.68659 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:16:24.257831 ops/training.py:65 2019-01-16 22:16:24.257792: step 9484, loss = 0.69351 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:16:25.147728 ops/training.py:65 2019-01-16 22:16:25.147676: step 9485, loss = 0.70265 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:16:26.037548 ops/training.py:65 2019-01-16 22:16:26.037496: step 9486, loss = 0.70151 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:16:26.927175 ops/training.py:65 2019-01-16 22:16:26.927129: step 9487, loss = 0.67557 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:16:27.816851 ops/training.py:65 2019-01-16 22:16:27.816791: step 9488, loss = 0.69152 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:16:28.706989 ops/training.py:65 2019-01-16 22:16:28.706937: step 9489, loss = 0.68065 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:16:29.596536 ops/training.py:65 2019-01-16 22:16:29.596467: step 9490, loss = 0.70263 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:16:30.485896 ops/training.py:65 2019-01-16 22:16:30.485840: step 9491, loss = 0.69217 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:16:31.375041 ops/training.py:65 2019-01-16 22:16:31.375009: step 9492, loss = 0.70657 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:16:32.263427 ops/training.py:65 2019-01-16 22:16:32.263380: step 9493, loss = 0.69727 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:16:33.152546 ops/training.py:65 2019-01-16 22:16:33.152496: step 9494, loss = 0.69365 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:16:34.041437 ops/training.py:65 2019-01-16 22:16:34.041393: step 9495, loss = 0.69304 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:16:34.930450 ops/training.py:65 2019-01-16 22:16:34.930409: step 9496, loss = 0.67061 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:16:35.819687 ops/training.py:65 2019-01-16 22:16:35.819642: step 9497, loss = 0.68206 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:16:36.708307 ops/training.py:65 2019-01-16 22:16:36.708264: step 9498, loss = 0.67328 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:16:37.596920 ops/training.py:65 2019-01-16 22:16:37.596878: step 9499, loss = 0.70454 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:16:38.485980 ops/training.py:65 2019-01-16 22:16:38.485936: step 9500, loss = 0.71166 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:16:39.376542 ops/training.py:65 2019-01-16 22:16:39.376514: step 9501, loss = 0.71973 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:16:40.268933 ops/training.py:65 2019-01-16 22:16:40.268906: step 9502, loss = 0.70435 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:16:41.160430 ops/training.py:65 2019-01-16 22:16:41.160403: step 9503, loss = 0.69956 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:16:42.051537 ops/training.py:65 2019-01-16 22:16:42.051511: step 9504, loss = 0.68262 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:16:42.943067 ops/training.py:65 2019-01-16 22:16:42.943040: step 9505, loss = 0.69024 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:16:43.834826 ops/training.py:65 2019-01-16 22:16:43.834779: step 9506, loss = 0.70418 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 22:16:44.726681 ops/training.py:65 2019-01-16 22:16:44.726653: step 9507, loss = 0.68536 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:16:45.618479 ops/training.py:65 2019-01-16 22:16:45.618451: step 9508, loss = 0.71707 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:16:46.510426 ops/training.py:65 2019-01-16 22:16:46.510399: step 9509, loss = 0.72550 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:16:47.401883 ops/training.py:65 2019-01-16 22:16:47.401856: step 9510, loss = 0.70083 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:16:48.293903 ops/training.py:65 2019-01-16 22:16:48.293876: step 9511, loss = 0.66232 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:16:49.185723 ops/training.py:65 2019-01-16 22:16:49.185697: step 9512, loss = 0.67929 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:16:50.078158 ops/training.py:65 2019-01-16 22:16:50.078131: step 9513, loss = 0.69628 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:16:50.970528 ops/training.py:65 2019-01-16 22:16:50.970500: step 9514, loss = 0.71098 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:16:51.860167 ops/training.py:65 2019-01-16 22:16:51.860138: step 9515, loss = 0.67700 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:16:52.750180 ops/training.py:65 2019-01-16 22:16:52.750152: step 9516, loss = 0.69482 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:16:53.642205 ops/training.py:65 2019-01-16 22:16:53.642177: step 9517, loss = 0.68949 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:16:54.535488 ops/training.py:65 2019-01-16 22:16:54.535461: step 9518, loss = 0.70451 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:16:55.426993 ops/training.py:65 2019-01-16 22:16:55.426966: step 9519, loss = 0.70352 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:16:56.316979 ops/training.py:65 2019-01-16 22:16:56.316952: step 9520, loss = 0.72787 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:16:57.207727 ops/training.py:65 2019-01-16 22:16:57.207700: step 9521, loss = 0.69249 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:16:58.100030 ops/training.py:65 2019-01-16 22:16:58.100003: step 9522, loss = 0.70183 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:16:58.991134 ops/training.py:65 2019-01-16 22:16:58.991098: step 9523, loss = 0.70176 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:16:59.883750 ops/training.py:65 2019-01-16 22:16:59.883723: step 9524, loss = 0.70045 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:17:00.774777 ops/training.py:65 2019-01-16 22:17:00.774748: step 9525, loss = 0.70734 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:17:01.667188 ops/training.py:65 2019-01-16 22:17:01.667159: step 9526, loss = 0.67218 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:17:02.557869 ops/training.py:65 2019-01-16 22:17:02.557842: step 9527, loss = 0.68371 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:17:03.448474 ops/training.py:65 2019-01-16 22:17:03.448448: step 9528, loss = 0.68768 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:17:04.340414 ops/training.py:65 2019-01-16 22:17:04.340387: step 9529, loss = 0.70836 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:17:05.230933 ops/training.py:65 2019-01-16 22:17:05.230908: step 9530, loss = 0.70132 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:17:06.120592 ops/training.py:65 2019-01-16 22:17:06.120557: step 9531, loss = 0.68453 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:17:07.009077 ops/training.py:65 2019-01-16 22:17:07.009051: step 9532, loss = 0.70183 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:17:07.897760 ops/training.py:65 2019-01-16 22:17:07.897718: step 9533, loss = 0.69341 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:17:08.786735 ops/training.py:65 2019-01-16 22:17:08.786694: step 9534, loss = 0.68576 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:17:09.675793 ops/training.py:65 2019-01-16 22:17:09.675757: step 9535, loss = 0.68124 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:17:10.564803 ops/training.py:65 2019-01-16 22:17:10.564765: step 9536, loss = 0.67497 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:17:11.453829 ops/training.py:65 2019-01-16 22:17:11.453790: step 9537, loss = 0.69922 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:17:12.343110 ops/training.py:65 2019-01-16 22:17:12.343060: step 9538, loss = 0.70053 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:17:13.234036 ops/training.py:65 2019-01-16 22:17:13.234005: step 9539, loss = 0.69644 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:17:14.126385 ops/training.py:65 2019-01-16 22:17:14.126316: step 9540, loss = 0.69216 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:17:15.015225 ops/training.py:65 2019-01-16 22:17:15.015159: step 9541, loss = 0.70116 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:17:15.904168 ops/training.py:65 2019-01-16 22:17:15.904113: step 9542, loss = 0.69197 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:17:16.792993 ops/training.py:65 2019-01-16 22:17:16.792930: step 9543, loss = 0.70160 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:17:17.681504 ops/training.py:65 2019-01-16 22:17:17.681441: step 9544, loss = 0.68376 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:17:18.570336 ops/training.py:65 2019-01-16 22:17:18.570273: step 9545, loss = 0.69920 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:17:19.459118 ops/training.py:65 2019-01-16 22:17:19.459069: step 9546, loss = 0.69990 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:17:20.347926 ops/training.py:65 2019-01-16 22:17:20.347872: step 9547, loss = 0.69481 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:17:21.236616 ops/training.py:65 2019-01-16 22:17:21.236576: step 9548, loss = 0.70796 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:17:22.125024 ops/training.py:65 2019-01-16 22:17:22.124985: step 9549, loss = 0.69636 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:17:23.013481 ops/training.py:65 2019-01-16 22:17:23.013434: step 9550, loss = 0.69290 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:17:23.901868 ops/training.py:65 2019-01-16 22:17:23.901826: step 9551, loss = 0.68910 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:17:24.790170 ops/training.py:65 2019-01-16 22:17:24.790116: step 9552, loss = 0.67423 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 22:17:25.678915 ops/training.py:65 2019-01-16 22:17:25.678874: step 9553, loss = 0.71334 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:17:26.567148 ops/training.py:65 2019-01-16 22:17:26.567096: step 9554, loss = 0.70474 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:17:27.455345 ops/training.py:65 2019-01-16 22:17:27.455280: step 9555, loss = 0.69056 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:17:28.344415 ops/training.py:65 2019-01-16 22:17:28.344350: step 9556, loss = 0.70754 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:17:29.233602 ops/training.py:65 2019-01-16 22:17:29.233545: step 9557, loss = 0.70372 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.40625
I2992 2019-01-16 22:17:30.122235 ops/training.py:65 2019-01-16 22:17:30.122177: step 9558, loss = 0.69704 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:17:31.011062 ops/training.py:65 2019-01-16 22:17:31.011008: step 9559, loss = 0.72915 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 22:17:31.900201 ops/training.py:65 2019-01-16 22:17:31.900147: step 9560, loss = 0.70222 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:17:32.789067 ops/training.py:65 2019-01-16 22:17:32.789012: step 9561, loss = 0.69199 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:17:33.677586 ops/training.py:65 2019-01-16 22:17:33.677530: step 9562, loss = 0.69631 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:17:34.565893 ops/training.py:65 2019-01-16 22:17:34.565843: step 9563, loss = 0.70713 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:17:35.454535 ops/training.py:65 2019-01-16 22:17:35.454483: step 9564, loss = 0.71537 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:17:36.343389 ops/training.py:65 2019-01-16 22:17:36.343327: step 9565, loss = 0.68787 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:17:37.231107 ops/training.py:65 2019-01-16 22:17:37.231051: step 9566, loss = 0.68265 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:17:38.118934 ops/training.py:65 2019-01-16 22:17:38.118878: step 9567, loss = 0.67907 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:17:39.007379 ops/training.py:65 2019-01-16 22:17:39.007316: step 9568, loss = 0.72607 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.3125
I2992 2019-01-16 22:17:39.896221 ops/training.py:65 2019-01-16 22:17:39.896130: step 9569, loss = 0.66872 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:17:40.786314 ops/training.py:65 2019-01-16 22:17:40.786240: step 9570, loss = 0.69211 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:17:41.674425 ops/training.py:65 2019-01-16 22:17:41.674359: step 9571, loss = 0.70019 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:17:42.562948 ops/training.py:65 2019-01-16 22:17:42.562883: step 9572, loss = 0.71861 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:17:43.451049 ops/training.py:65 2019-01-16 22:17:43.450978: step 9573, loss = 0.72124 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:17:44.339735 ops/training.py:65 2019-01-16 22:17:44.339665: step 9574, loss = 0.69172 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:17:45.227892 ops/training.py:65 2019-01-16 22:17:45.227824: step 9575, loss = 0.69001 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:17:46.116391 ops/training.py:65 2019-01-16 22:17:46.116336: step 9576, loss = 0.72330 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:17:47.005912 ops/training.py:65 2019-01-16 22:17:47.005861: step 9577, loss = 0.67976 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:17:47.894102 ops/training.py:65 2019-01-16 22:17:47.894048: step 9578, loss = 0.68324 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:17:48.782809 ops/training.py:65 2019-01-16 22:17:48.782750: step 9579, loss = 0.68658 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:17:49.671489 ops/training.py:65 2019-01-16 22:17:49.671430: step 9580, loss = 0.67794 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:17:50.560471 ops/training.py:65 2019-01-16 22:17:50.560414: step 9581, loss = 0.67056 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:17:51.449607 ops/training.py:65 2019-01-16 22:17:51.449553: step 9582, loss = 0.68041 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:17:52.340190 ops/training.py:65 2019-01-16 22:17:52.340144: step 9583, loss = 0.69907 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:17:53.230932 ops/training.py:65 2019-01-16 22:17:53.230878: step 9584, loss = 0.71322 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:17:54.121976 ops/training.py:65 2019-01-16 22:17:54.121916: step 9585, loss = 0.71081 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:17:55.011024 ops/training.py:65 2019-01-16 22:17:55.010969: step 9586, loss = 0.72987 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:17:55.901168 ops/training.py:65 2019-01-16 22:17:55.901130: step 9587, loss = 0.72795 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:17:56.790176 ops/training.py:65 2019-01-16 22:17:56.790132: step 9588, loss = 0.72003 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:17:57.678766 ops/training.py:65 2019-01-16 22:17:57.678694: step 9589, loss = 0.70765 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:17:58.568379 ops/training.py:65 2019-01-16 22:17:58.568292: step 9590, loss = 0.68970 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:17:59.458420 ops/training.py:65 2019-01-16 22:17:59.458333: step 9591, loss = 0.70962 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:18:00.351157 ops/training.py:65 2019-01-16 22:18:00.351049: step 9592, loss = 0.68640 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:18:01.242896 ops/training.py:65 2019-01-16 22:18:01.242837: step 9593, loss = 0.65478 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.6875
I2992 2019-01-16 22:18:02.134599 ops/training.py:65 2019-01-16 22:18:02.134500: step 9594, loss = 0.68472 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:18:03.025993 ops/training.py:65 2019-01-16 22:18:03.025928: step 9595, loss = 0.69330 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:18:03.915663 ops/training.py:65 2019-01-16 22:18:03.915605: step 9596, loss = 0.70607 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:18:04.805093 ops/training.py:65 2019-01-16 22:18:04.805042: step 9597, loss = 0.68977 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:18:05.694331 ops/training.py:65 2019-01-16 22:18:05.694280: step 9598, loss = 0.69238 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:18:06.584416 ops/training.py:65 2019-01-16 22:18:06.584378: step 9599, loss = 0.71937 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:18:07.476024 ops/training.py:65 2019-01-16 22:18:07.475978: step 9600, loss = 0.72297 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:18:08.365143 ops/training.py:65 2019-01-16 22:18:08.365089: step 9601, loss = 0.72958 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 22:18:09.255893 ops/training.py:65 2019-01-16 22:18:09.255847: step 9602, loss = 0.69532 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:18:10.147642 ops/training.py:65 2019-01-16 22:18:10.147589: step 9603, loss = 0.69580 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:18:11.036908 ops/training.py:65 2019-01-16 22:18:11.036856: step 9604, loss = 0.68691 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:18:11.928401 ops/training.py:65 2019-01-16 22:18:11.928332: step 9605, loss = 0.68845 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:18:12.820661 ops/training.py:65 2019-01-16 22:18:12.820569: step 9606, loss = 0.69439 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:18:13.714072 ops/training.py:65 2019-01-16 22:18:13.713973: step 9607, loss = 0.68495 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:18:14.605362 ops/training.py:65 2019-01-16 22:18:14.605312: step 9608, loss = 0.71156 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:18:15.494471 ops/training.py:65 2019-01-16 22:18:15.494418: step 9609, loss = 0.68043 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:18:16.386238 ops/training.py:65 2019-01-16 22:18:16.386184: step 9610, loss = 0.69264 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:18:17.278289 ops/training.py:65 2019-01-16 22:18:17.278207: step 9611, loss = 0.69903 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:18:18.171312 ops/training.py:65 2019-01-16 22:18:18.171203: step 9612, loss = 0.71396 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:18:19.063220 ops/training.py:65 2019-01-16 22:18:19.063136: step 9613, loss = 0.67615 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:18:19.952867 ops/training.py:65 2019-01-16 22:18:19.952808: step 9614, loss = 0.69564 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.5625
I2992 2019-01-16 22:18:20.841918 ops/training.py:65 2019-01-16 22:18:20.841866: step 9615, loss = 0.72160 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:18:21.730193 ops/training.py:65 2019-01-16 22:18:21.730140: step 9616, loss = 0.70450 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:18:22.619044 ops/training.py:65 2019-01-16 22:18:22.618989: step 9617, loss = 0.71612 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:18:23.507722 ops/training.py:65 2019-01-16 22:18:23.507659: step 9618, loss = 0.68129 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:18:24.396923 ops/training.py:65 2019-01-16 22:18:24.396860: step 9619, loss = 0.68249 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:18:25.288357 ops/training.py:65 2019-01-16 22:18:25.288300: step 9620, loss = 0.70955 (36.0 examples/sec; 0.890 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:18:26.180664 ops/training.py:65 2019-01-16 22:18:26.180575: step 9621, loss = 0.69264 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:18:27.072836 ops/training.py:65 2019-01-16 22:18:27.072725: step 9622, loss = 0.69565 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:18:27.965061 ops/training.py:65 2019-01-16 22:18:27.964971: step 9623, loss = 0.69543 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:18:28.854850 ops/training.py:65 2019-01-16 22:18:28.854797: step 9624, loss = 0.69163 (36.0 examples/sec; 0.889 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:18:29.746802 ops/training.py:65 2019-01-16 22:18:29.746750: step 9625, loss = 0.69102 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:18:30.639376 ops/training.py:65 2019-01-16 22:18:30.639286: step 9626, loss = 0.68680 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:18:31.532623 ops/training.py:65 2019-01-16 22:18:31.532522: step 9627, loss = 0.71352 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.375
I2992 2019-01-16 22:18:32.424607 ops/training.py:65 2019-01-16 22:18:32.424499: step 9628, loss = 0.71760 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:18:33.316533 ops/training.py:65 2019-01-16 22:18:33.316469: step 9629, loss = 0.68134 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:18:34.208644 ops/training.py:65 2019-01-16 22:18:34.208538: step 9630, loss = 0.69473 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:18:35.101864 ops/training.py:65 2019-01-16 22:18:35.101694: step 9631, loss = 0.68772 (35.9 examples/sec; 0.892 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:18:35.994854 ops/training.py:65 2019-01-16 22:18:35.994756: step 9632, loss = 0.69837 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:18:36.887100 ops/training.py:65 2019-01-16 22:18:36.886995: step 9633, loss = 0.69599 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:18:37.779274 ops/training.py:65 2019-01-16 22:18:37.779188: step 9634, loss = 0.70176 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:18:38.668154 ops/training.py:65 2019-01-16 22:18:38.668068: step 9635, loss = 0.69049 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.59375
I2992 2019-01-16 22:18:39.560334 ops/training.py:65 2019-01-16 22:18:39.560293: step 9636, loss = 0.70027 (35.9 examples/sec; 0.891 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:18:40.451397 ops/training.py:65 2019-01-16 22:18:40.451339: step 9637, loss = 0.70446 (35.9 examples/sec; 0.890 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:18:41.339783 ops/training.py:65 2019-01-16 22:18:41.339726: step 9638, loss = 0.69958 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:18:42.228126 ops/training.py:65 2019-01-16 22:18:42.228062: step 9639, loss = 0.70846 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:18:43.117183 ops/training.py:65 2019-01-16 22:18:43.117101: step 9640, loss = 0.69413 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:18:44.006697 ops/training.py:65 2019-01-16 22:18:44.006628: step 9641, loss = 0.68009 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:18:44.895574 ops/training.py:65 2019-01-16 22:18:44.895510: step 9642, loss = 0.68886 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:18:45.784366 ops/training.py:65 2019-01-16 22:18:45.784302: step 9643, loss = 0.70050 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:18:46.672959 ops/training.py:65 2019-01-16 22:18:46.672902: step 9644, loss = 0.71635 (36.1 examples/sec; 0.888 sec/batch) | Training accuracy = 0.5
I2992 2019-01-16 22:18:47.561225 ops/training.py:65 2019-01-16 22:18:47.561168: step 9645, loss = 0.67204 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.625
I2992 2019-01-16 22:18:48.450129 ops/training.py:65 2019-01-16 22:18:48.450067: step 9646, loss = 0.66653 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.65625
I2992 2019-01-16 22:18:49.339153 ops/training.py:65 2019-01-16 22:18:49.339085: step 9647, loss = 0.72300 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.28125
I2992 2019-01-16 22:18:50.228413 ops/training.py:65 2019-01-16 22:18:50.228348: step 9648, loss = 0.68973 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:18:51.117349 ops/training.py:65 2019-01-16 22:18:51.117292: step 9649, loss = 0.70450 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.46875
I2992 2019-01-16 22:18:52.005675 ops/training.py:65 2019-01-16 22:18:52.005623: step 9650, loss = 0.70276 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.34375
I2992 2019-01-16 22:18:52.894432 ops/training.py:65 2019-01-16 22:18:52.894379: step 9651, loss = 0.68761 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:18:53.783101 ops/training.py:65 2019-01-16 22:18:53.783034: step 9652, loss = 0.69575 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.53125
I2992 2019-01-16 22:18:54.670982 ops/training.py:65 2019-01-16 22:18:54.670925: step 9653, loss = 0.70845 (36.1 examples/sec; 0.887 sec/batch) | Training accuracy = 0.4375
I2992 2019-01-16 22:18:55.559634 ops/training.py:65 2019-01-16 22:18:55.559580: step 9654, loss = 0.70878 (36.0 examples/sec; 0.888 sec/batch) | Training accuracy = 0.4375
