I8192 2019-01-16 16:31:41.121710 ops/training.py:229 Log written to /gpfs_home/dlinsley/cluttered_nist_experiments/logs/nist_3_ix2v2_50k_2019_01_16_16_30_45_270295
I8192 2019-01-16 16:36:58.551708 ops/training.py:396 Failed to save checkpoint: global name 'db' is not defined
I8192 2019-01-16 16:36:58.552841 ops/training.py:41 2019-01-16 16:36:58.552725: step 0, loss = 0.76 (0.1 examples/sec; 292.811 sec/batch) | Training accuracy = 0.5 | Validation accuracy = 0.4961 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_16_30_45_270295
I8192 2019-01-16 16:36:59.541216 ops/training.py:65 2019-01-16 16:36:59.541073: step 1, loss = 0.90734 (32.4 examples/sec; 0.987 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:37:00.525823 ops/training.py:65 2019-01-16 16:37:00.525708: step 2, loss = 0.91378 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:37:01.510504 ops/training.py:65 2019-01-16 16:37:01.510408: step 3, loss = 0.88350 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:37:02.496291 ops/training.py:65 2019-01-16 16:37:02.496184: step 4, loss = 0.71243 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:37:03.480832 ops/training.py:65 2019-01-16 16:37:03.480724: step 5, loss = 0.90026 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:37:04.463106 ops/training.py:65 2019-01-16 16:37:04.463015: step 6, loss = 0.75037 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:37:05.446343 ops/training.py:65 2019-01-16 16:37:05.446248: step 7, loss = 0.69667 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:37:06.429592 ops/training.py:65 2019-01-16 16:37:06.429482: step 8, loss = 0.79193 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:37:07.413924 ops/training.py:65 2019-01-16 16:37:07.413834: step 9, loss = 0.79125 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:37:08.397040 ops/training.py:65 2019-01-16 16:37:08.396974: step 10, loss = 0.69493 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:37:09.379258 ops/training.py:65 2019-01-16 16:37:09.379216: step 11, loss = 0.78793 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:37:10.362115 ops/training.py:65 2019-01-16 16:37:10.362069: step 12, loss = 0.72939 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:37:11.345506 ops/training.py:65 2019-01-16 16:37:11.345471: step 13, loss = 0.77972 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:37:12.326982 ops/training.py:65 2019-01-16 16:37:12.326949: step 14, loss = 0.87468 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:37:13.310872 ops/training.py:65 2019-01-16 16:37:13.310839: step 15, loss = 0.70313 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:37:14.294994 ops/training.py:65 2019-01-16 16:37:14.294964: step 16, loss = 0.76294 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:37:15.278449 ops/training.py:65 2019-01-16 16:37:15.278418: step 17, loss = 0.71322 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:37:16.260724 ops/training.py:65 2019-01-16 16:37:16.260692: step 18, loss = 0.74998 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:37:17.244637 ops/training.py:65 2019-01-16 16:37:17.244606: step 19, loss = 0.75424 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:37:18.229957 ops/training.py:65 2019-01-16 16:37:18.229925: step 20, loss = 0.61453 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:37:19.213687 ops/training.py:65 2019-01-16 16:37:19.213653: step 21, loss = 0.68810 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:37:20.198403 ops/training.py:65 2019-01-16 16:37:20.198369: step 22, loss = 0.76863 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:37:21.180609 ops/training.py:65 2019-01-16 16:37:21.180561: step 23, loss = 0.66598 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:37:22.162342 ops/training.py:65 2019-01-16 16:37:22.162247: step 24, loss = 0.77401 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:37:23.145555 ops/training.py:65 2019-01-16 16:37:23.145506: step 25, loss = 0.71167 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:37:24.128444 ops/training.py:65 2019-01-16 16:37:24.128331: step 26, loss = 0.69247 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:37:25.110086 ops/training.py:65 2019-01-16 16:37:25.109990: step 27, loss = 0.65437 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:37:26.094585 ops/training.py:65 2019-01-16 16:37:26.094548: step 28, loss = 0.68555 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:37:27.076481 ops/training.py:65 2019-01-16 16:37:27.076403: step 29, loss = 0.82066 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:37:28.062765 ops/training.py:65 2019-01-16 16:37:28.062659: step 30, loss = 0.80047 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:37:29.047933 ops/training.py:65 2019-01-16 16:37:29.047822: step 31, loss = 0.69254 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:37:30.031192 ops/training.py:65 2019-01-16 16:37:30.031093: step 32, loss = 0.79410 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:37:31.013594 ops/training.py:65 2019-01-16 16:37:31.013524: step 33, loss = 0.79396 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:37:31.994594 ops/training.py:65 2019-01-16 16:37:31.994526: step 34, loss = 0.72517 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:37:32.976502 ops/training.py:65 2019-01-16 16:37:32.976430: step 35, loss = 0.66120 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:37:33.961149 ops/training.py:65 2019-01-16 16:37:33.961057: step 36, loss = 0.74451 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:37:34.944967 ops/training.py:65 2019-01-16 16:37:34.944858: step 37, loss = 0.82802 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:37:35.927487 ops/training.py:65 2019-01-16 16:37:35.927386: step 38, loss = 0.73474 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:37:36.910508 ops/training.py:65 2019-01-16 16:37:36.910409: step 39, loss = 0.75686 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:37:37.893453 ops/training.py:65 2019-01-16 16:37:37.893345: step 40, loss = 0.77277 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:37:38.875897 ops/training.py:65 2019-01-16 16:37:38.875795: step 41, loss = 0.72633 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:37:39.858718 ops/training.py:65 2019-01-16 16:37:39.858607: step 42, loss = 0.75514 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:37:40.845416 ops/training.py:65 2019-01-16 16:37:40.845311: step 43, loss = 0.71321 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:37:41.829691 ops/training.py:65 2019-01-16 16:37:41.829591: step 44, loss = 0.70355 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:37:42.812960 ops/training.py:65 2019-01-16 16:37:42.812856: step 45, loss = 0.62748 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 16:37:43.799913 ops/training.py:65 2019-01-16 16:37:43.799815: step 46, loss = 0.67812 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:37:44.784256 ops/training.py:65 2019-01-16 16:37:44.784130: step 47, loss = 0.75802 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:37:45.769747 ops/training.py:65 2019-01-16 16:37:45.769641: step 48, loss = 0.79028 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:37:46.755722 ops/training.py:65 2019-01-16 16:37:46.755401: step 49, loss = 0.80715 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:37:47.739350 ops/training.py:65 2019-01-16 16:37:47.739233: step 50, loss = 0.72327 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:37:48.726025 ops/training.py:65 2019-01-16 16:37:48.725919: step 51, loss = 0.73545 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:37:49.711830 ops/training.py:65 2019-01-16 16:37:49.711719: step 52, loss = 0.71547 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:37:50.695903 ops/training.py:65 2019-01-16 16:37:50.695787: step 53, loss = 0.81880 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:37:51.678743 ops/training.py:65 2019-01-16 16:37:51.678644: step 54, loss = 0.72174 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:37:52.663760 ops/training.py:65 2019-01-16 16:37:52.663658: step 55, loss = 0.77546 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:37:53.647719 ops/training.py:65 2019-01-16 16:37:53.647616: step 56, loss = 0.63007 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 16:37:54.630171 ops/training.py:65 2019-01-16 16:37:54.630096: step 57, loss = 0.74316 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:37:55.612669 ops/training.py:65 2019-01-16 16:37:55.612600: step 58, loss = 0.75214 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:37:56.595660 ops/training.py:65 2019-01-16 16:37:56.595518: step 59, loss = 0.79772 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:37:57.578449 ops/training.py:65 2019-01-16 16:37:57.578367: step 60, loss = 0.78804 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:37:58.564915 ops/training.py:65 2019-01-16 16:37:58.564801: step 61, loss = 0.72754 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:37:59.546346 ops/training.py:65 2019-01-16 16:37:59.546271: step 62, loss = 0.65570 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:38:00.529633 ops/training.py:65 2019-01-16 16:38:00.529542: step 63, loss = 0.73898 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:38:01.513988 ops/training.py:65 2019-01-16 16:38:01.513888: step 64, loss = 0.71213 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:38:02.500077 ops/training.py:65 2019-01-16 16:38:02.499886: step 65, loss = 0.68009 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:38:03.483412 ops/training.py:65 2019-01-16 16:38:03.483307: step 66, loss = 0.81032 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:38:04.466664 ops/training.py:65 2019-01-16 16:38:04.466553: step 67, loss = 0.74974 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:38:05.450100 ops/training.py:65 2019-01-16 16:38:05.449990: step 68, loss = 0.74471 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:38:06.434771 ops/training.py:65 2019-01-16 16:38:06.434662: step 69, loss = 0.83995 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:38:07.419536 ops/training.py:65 2019-01-16 16:38:07.419427: step 70, loss = 0.62374 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:38:08.403997 ops/training.py:65 2019-01-16 16:38:08.403890: step 71, loss = 0.82988 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 16:38:09.389089 ops/training.py:65 2019-01-16 16:38:09.388964: step 72, loss = 0.69033 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:38:10.372932 ops/training.py:65 2019-01-16 16:38:10.372819: step 73, loss = 0.65948 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:38:11.356970 ops/training.py:65 2019-01-16 16:38:11.356843: step 74, loss = 0.63186 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:38:12.340687 ops/training.py:65 2019-01-16 16:38:12.340558: step 75, loss = 0.68121 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:38:13.326910 ops/training.py:65 2019-01-16 16:38:13.326801: step 76, loss = 0.71515 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:38:14.311156 ops/training.py:65 2019-01-16 16:38:14.311044: step 77, loss = 0.75671 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:38:15.294376 ops/training.py:65 2019-01-16 16:38:15.294268: step 78, loss = 0.67341 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:38:16.276703 ops/training.py:65 2019-01-16 16:38:16.276600: step 79, loss = 0.72140 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:38:17.262614 ops/training.py:65 2019-01-16 16:38:17.262489: step 80, loss = 0.70150 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:38:18.247638 ops/training.py:65 2019-01-16 16:38:18.247524: step 81, loss = 0.70369 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:38:19.231530 ops/training.py:65 2019-01-16 16:38:19.231418: step 82, loss = 0.76786 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:38:20.215714 ops/training.py:65 2019-01-16 16:38:20.215610: step 83, loss = 0.72350 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:38:21.200223 ops/training.py:65 2019-01-16 16:38:21.200033: step 84, loss = 0.81188 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:38:22.185305 ops/training.py:65 2019-01-16 16:38:22.185202: step 85, loss = 0.72636 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:38:23.168670 ops/training.py:65 2019-01-16 16:38:23.168568: step 86, loss = 0.73865 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:38:24.150716 ops/training.py:65 2019-01-16 16:38:24.150613: step 87, loss = 0.75298 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:38:25.133417 ops/training.py:65 2019-01-16 16:38:25.133308: step 88, loss = 0.73562 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:38:26.117134 ops/training.py:65 2019-01-16 16:38:26.117030: step 89, loss = 0.67793 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:38:27.099654 ops/training.py:65 2019-01-16 16:38:27.099528: step 90, loss = 0.76396 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:38:28.082471 ops/training.py:65 2019-01-16 16:38:28.082358: step 91, loss = 0.70412 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:38:29.063577 ops/training.py:65 2019-01-16 16:38:29.063469: step 92, loss = 0.75608 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:38:30.046068 ops/training.py:65 2019-01-16 16:38:30.045959: step 93, loss = 0.64888 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:38:31.032021 ops/training.py:65 2019-01-16 16:38:31.031894: step 94, loss = 0.75858 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:38:32.018495 ops/training.py:65 2019-01-16 16:38:32.018378: step 95, loss = 0.72725 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:38:33.003612 ops/training.py:65 2019-01-16 16:38:33.003504: step 96, loss = 0.76100 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:38:33.986721 ops/training.py:65 2019-01-16 16:38:33.986616: step 97, loss = 0.69807 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:38:34.969239 ops/training.py:65 2019-01-16 16:38:34.969130: step 98, loss = 0.73654 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:38:35.955341 ops/training.py:65 2019-01-16 16:38:35.955232: step 99, loss = 0.78534 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:38:36.940815 ops/training.py:65 2019-01-16 16:38:36.940708: step 100, loss = 0.64920 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 16:38:37.924190 ops/training.py:65 2019-01-16 16:38:37.924089: step 101, loss = 0.73986 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:38:38.907080 ops/training.py:65 2019-01-16 16:38:38.906985: step 102, loss = 0.81012 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:38:39.892681 ops/training.py:65 2019-01-16 16:38:39.892573: step 103, loss = 0.76598 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:38:40.877301 ops/training.py:65 2019-01-16 16:38:40.877194: step 104, loss = 0.68079 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:38:41.860095 ops/training.py:65 2019-01-16 16:38:41.860005: step 105, loss = 0.64772 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:38:42.841785 ops/training.py:65 2019-01-16 16:38:42.841695: step 106, loss = 0.76401 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:38:43.824990 ops/training.py:65 2019-01-16 16:38:43.824893: step 107, loss = 0.68839 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:38:44.808218 ops/training.py:65 2019-01-16 16:38:44.808121: step 108, loss = 0.75215 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:38:45.791381 ops/training.py:65 2019-01-16 16:38:45.791279: step 109, loss = 0.72681 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:38:46.773376 ops/training.py:65 2019-01-16 16:38:46.773292: step 110, loss = 0.69111 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:38:47.757287 ops/training.py:65 2019-01-16 16:38:47.757182: step 111, loss = 0.70368 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:38:48.740224 ops/training.py:65 2019-01-16 16:38:48.740119: step 112, loss = 0.81361 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:38:49.724289 ops/training.py:65 2019-01-16 16:38:49.724183: step 113, loss = 0.73312 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:38:50.708043 ops/training.py:65 2019-01-16 16:38:50.707947: step 114, loss = 0.72955 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:38:51.692339 ops/training.py:65 2019-01-16 16:38:51.692240: step 115, loss = 0.70226 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:38:52.673464 ops/training.py:65 2019-01-16 16:38:52.673387: step 116, loss = 0.79817 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:38:53.657146 ops/training.py:65 2019-01-16 16:38:53.657100: step 117, loss = 0.75808 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:38:54.640611 ops/training.py:65 2019-01-16 16:38:54.640577: step 118, loss = 0.73530 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:38:55.624156 ops/training.py:65 2019-01-16 16:38:55.624117: step 119, loss = 0.80950 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:38:56.607295 ops/training.py:65 2019-01-16 16:38:56.607203: step 120, loss = 0.72690 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:38:57.591516 ops/training.py:65 2019-01-16 16:38:57.591452: step 121, loss = 0.73925 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:38:58.573444 ops/training.py:65 2019-01-16 16:38:58.573403: step 122, loss = 0.79438 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:38:59.554845 ops/training.py:65 2019-01-16 16:38:59.554810: step 123, loss = 0.64340 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:39:00.537412 ops/training.py:65 2019-01-16 16:39:00.537374: step 124, loss = 0.71860 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:39:01.520842 ops/training.py:65 2019-01-16 16:39:01.520805: step 125, loss = 0.77534 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:39:02.503426 ops/training.py:65 2019-01-16 16:39:02.503389: step 126, loss = 0.58771 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.75
I8192 2019-01-16 16:39:03.485805 ops/training.py:65 2019-01-16 16:39:03.485772: step 127, loss = 0.73052 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:39:04.468799 ops/training.py:65 2019-01-16 16:39:04.468765: step 128, loss = 0.72511 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:39:05.452101 ops/training.py:65 2019-01-16 16:39:05.452067: step 129, loss = 0.73072 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:39:06.435213 ops/training.py:65 2019-01-16 16:39:06.435181: step 130, loss = 0.65150 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:39:07.417410 ops/training.py:65 2019-01-16 16:39:07.417378: step 131, loss = 0.69894 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:39:08.399698 ops/training.py:65 2019-01-16 16:39:08.399664: step 132, loss = 0.72176 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:39:09.383738 ops/training.py:65 2019-01-16 16:39:09.383704: step 133, loss = 0.72337 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:39:10.364858 ops/training.py:65 2019-01-16 16:39:10.364823: step 134, loss = 0.64965 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:39:11.345554 ops/training.py:65 2019-01-16 16:39:11.345519: step 135, loss = 0.79744 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:39:12.329194 ops/training.py:65 2019-01-16 16:39:12.329161: step 136, loss = 0.72204 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:39:13.314771 ops/training.py:65 2019-01-16 16:39:13.314739: step 137, loss = 0.68079 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:39:14.299165 ops/training.py:65 2019-01-16 16:39:14.299134: step 138, loss = 0.69752 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:39:15.282853 ops/training.py:65 2019-01-16 16:39:15.282821: step 139, loss = 0.70969 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:39:16.265436 ops/training.py:65 2019-01-16 16:39:16.265403: step 140, loss = 0.71031 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:39:17.247584 ops/training.py:65 2019-01-16 16:39:17.247552: step 141, loss = 0.78093 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:39:18.231563 ops/training.py:65 2019-01-16 16:39:18.231530: step 142, loss = 0.71872 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:39:19.214315 ops/training.py:65 2019-01-16 16:39:19.214282: step 143, loss = 0.69347 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:39:20.196468 ops/training.py:65 2019-01-16 16:39:20.196435: step 144, loss = 0.67846 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:39:21.178467 ops/training.py:65 2019-01-16 16:39:21.178436: step 145, loss = 0.63766 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:39:22.160242 ops/training.py:65 2019-01-16 16:39:22.160212: step 146, loss = 0.73052 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:39:23.141797 ops/training.py:65 2019-01-16 16:39:23.141763: step 147, loss = 0.77644 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:39:24.123688 ops/training.py:65 2019-01-16 16:39:24.123653: step 148, loss = 0.64507 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 16:39:25.105662 ops/training.py:65 2019-01-16 16:39:25.105615: step 149, loss = 0.72737 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:39:26.088407 ops/training.py:65 2019-01-16 16:39:26.088363: step 150, loss = 0.66836 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:39:27.070347 ops/training.py:65 2019-01-16 16:39:27.070308: step 151, loss = 0.87409 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:39:28.051937 ops/training.py:65 2019-01-16 16:39:28.051846: step 152, loss = 0.71882 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:39:29.035935 ops/training.py:65 2019-01-16 16:39:29.035837: step 153, loss = 0.72447 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:39:30.018757 ops/training.py:65 2019-01-16 16:39:30.018656: step 154, loss = 0.75736 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:39:30.999157 ops/training.py:65 2019-01-16 16:39:30.999091: step 155, loss = 0.65606 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:39:31.980259 ops/training.py:65 2019-01-16 16:39:31.980193: step 156, loss = 0.69059 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:39:32.960934 ops/training.py:65 2019-01-16 16:39:32.960842: step 157, loss = 0.67167 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:39:33.946853 ops/training.py:65 2019-01-16 16:39:33.946779: step 158, loss = 0.73938 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:39:34.931551 ops/training.py:65 2019-01-16 16:39:34.931514: step 159, loss = 0.73372 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:39:35.914624 ops/training.py:65 2019-01-16 16:39:35.914588: step 160, loss = 0.76475 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:39:36.896599 ops/training.py:65 2019-01-16 16:39:36.896549: step 161, loss = 0.73948 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:39:37.878271 ops/training.py:65 2019-01-16 16:39:37.878228: step 162, loss = 0.71719 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:39:38.859191 ops/training.py:65 2019-01-16 16:39:38.859153: step 163, loss = 0.74421 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:39:39.840236 ops/training.py:65 2019-01-16 16:39:39.840165: step 164, loss = 0.70052 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:39:40.822574 ops/training.py:65 2019-01-16 16:39:40.822495: step 165, loss = 0.75535 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:39:41.804635 ops/training.py:65 2019-01-16 16:39:41.804534: step 166, loss = 0.73881 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:39:42.787285 ops/training.py:65 2019-01-16 16:39:42.787181: step 167, loss = 0.74183 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:39:43.768915 ops/training.py:65 2019-01-16 16:39:43.768820: step 168, loss = 0.73891 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:39:44.751219 ops/training.py:65 2019-01-16 16:39:44.751122: step 169, loss = 0.78066 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:39:45.733788 ops/training.py:65 2019-01-16 16:39:45.733673: step 170, loss = 0.67233 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:39:46.716103 ops/training.py:65 2019-01-16 16:39:46.716007: step 171, loss = 0.65911 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:39:47.699050 ops/training.py:65 2019-01-16 16:39:47.698943: step 172, loss = 0.70628 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 16:39:48.681474 ops/training.py:65 2019-01-16 16:39:48.681367: step 173, loss = 0.77095 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:39:49.663993 ops/training.py:65 2019-01-16 16:39:49.663887: step 174, loss = 0.64830 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:39:50.647085 ops/training.py:65 2019-01-16 16:39:50.646980: step 175, loss = 0.72874 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:39:51.628642 ops/training.py:65 2019-01-16 16:39:51.628571: step 176, loss = 0.78764 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:39:52.608626 ops/training.py:65 2019-01-16 16:39:52.608561: step 177, loss = 0.82308 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:39:53.594388 ops/training.py:65 2019-01-16 16:39:53.594292: step 178, loss = 0.69187 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:39:54.589240 ops/training.py:65 2019-01-16 16:39:54.589137: step 179, loss = 0.75991 (32.2 examples/sec; 0.993 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:39:55.573631 ops/training.py:65 2019-01-16 16:39:55.573531: step 180, loss = 0.76297 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:39:56.556703 ops/training.py:65 2019-01-16 16:39:56.556602: step 181, loss = 0.67528 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:39:57.540195 ops/training.py:65 2019-01-16 16:39:57.540092: step 182, loss = 0.71755 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:39:58.522709 ops/training.py:65 2019-01-16 16:39:58.522606: step 183, loss = 0.71901 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:39:59.505141 ops/training.py:65 2019-01-16 16:39:59.505039: step 184, loss = 0.77799 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:40:00.487989 ops/training.py:65 2019-01-16 16:40:00.487886: step 185, loss = 0.70792 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:40:01.469960 ops/training.py:65 2019-01-16 16:40:01.469920: step 186, loss = 0.71854 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:40:02.455523 ops/training.py:65 2019-01-16 16:40:02.455487: step 187, loss = 0.74649 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:40:03.440214 ops/training.py:65 2019-01-16 16:40:03.440177: step 188, loss = 0.71747 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:40:04.425022 ops/training.py:65 2019-01-16 16:40:04.424982: step 189, loss = 0.69456 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:40:05.410454 ops/training.py:65 2019-01-16 16:40:05.410416: step 190, loss = 0.77987 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:40:06.392583 ops/training.py:65 2019-01-16 16:40:06.392544: step 191, loss = 0.70869 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:40:07.379169 ops/training.py:65 2019-01-16 16:40:07.379129: step 192, loss = 0.72398 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:40:08.361062 ops/training.py:65 2019-01-16 16:40:08.361027: step 193, loss = 0.65728 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:40:09.341501 ops/training.py:65 2019-01-16 16:40:09.341440: step 194, loss = 0.79678 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:40:10.321227 ops/training.py:65 2019-01-16 16:40:10.321187: step 195, loss = 0.71652 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:40:11.304642 ops/training.py:65 2019-01-16 16:40:11.304603: step 196, loss = 0.70991 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:40:12.288235 ops/training.py:65 2019-01-16 16:40:12.288200: step 197, loss = 0.63841 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:40:13.271671 ops/training.py:65 2019-01-16 16:40:13.271633: step 198, loss = 0.77518 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:40:14.255371 ops/training.py:65 2019-01-16 16:40:14.255336: step 199, loss = 0.69571 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:40:15.237415 ops/training.py:65 2019-01-16 16:40:15.237377: step 200, loss = 0.69227 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:40:16.218534 ops/training.py:65 2019-01-16 16:40:16.218498: step 201, loss = 0.65495 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:40:17.200589 ops/training.py:65 2019-01-16 16:40:17.200556: step 202, loss = 0.64340 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:40:18.184190 ops/training.py:65 2019-01-16 16:40:18.184157: step 203, loss = 0.77150 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:40:19.167974 ops/training.py:65 2019-01-16 16:40:19.167940: step 204, loss = 0.69101 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:40:20.151855 ops/training.py:65 2019-01-16 16:40:20.151821: step 205, loss = 0.79918 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 16:40:21.136841 ops/training.py:65 2019-01-16 16:40:21.136808: step 206, loss = 0.73017 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:40:22.121719 ops/training.py:65 2019-01-16 16:40:22.121686: step 207, loss = 0.68730 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:40:23.103751 ops/training.py:65 2019-01-16 16:40:23.103718: step 208, loss = 0.73755 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:40:24.086388 ops/training.py:65 2019-01-16 16:40:24.086351: step 209, loss = 0.79011 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:40:25.068548 ops/training.py:65 2019-01-16 16:40:25.068510: step 210, loss = 0.69017 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:40:26.051021 ops/training.py:65 2019-01-16 16:40:26.050988: step 211, loss = 0.79118 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:40:27.033668 ops/training.py:65 2019-01-16 16:40:27.033634: step 212, loss = 0.72069 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:40:28.016036 ops/training.py:65 2019-01-16 16:40:28.016000: step 213, loss = 0.81997 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:40:28.997279 ops/training.py:65 2019-01-16 16:40:28.997242: step 214, loss = 0.62213 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:40:29.979442 ops/training.py:65 2019-01-16 16:40:29.979396: step 215, loss = 0.71653 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:40:30.960959 ops/training.py:65 2019-01-16 16:40:30.960900: step 216, loss = 0.72743 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:40:31.943678 ops/training.py:65 2019-01-16 16:40:31.943609: step 217, loss = 0.70143 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:40:32.925625 ops/training.py:65 2019-01-16 16:40:32.925580: step 218, loss = 0.79887 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:40:33.906623 ops/training.py:65 2019-01-16 16:40:33.906593: step 219, loss = 0.74381 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:40:34.887800 ops/training.py:65 2019-01-16 16:40:34.887764: step 220, loss = 0.85990 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:40:35.869683 ops/training.py:65 2019-01-16 16:40:35.869578: step 221, loss = 0.75742 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:40:36.851786 ops/training.py:65 2019-01-16 16:40:36.851692: step 222, loss = 0.67261 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:40:37.834143 ops/training.py:65 2019-01-16 16:40:37.834092: step 223, loss = 0.76743 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:40:38.815512 ops/training.py:65 2019-01-16 16:40:38.815447: step 224, loss = 0.71696 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:40:39.797714 ops/training.py:65 2019-01-16 16:40:39.797667: step 225, loss = 0.75181 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:40:40.780412 ops/training.py:65 2019-01-16 16:40:40.780358: step 226, loss = 0.62735 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 16:40:41.765418 ops/training.py:65 2019-01-16 16:40:41.765380: step 227, loss = 0.69273 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:40:42.746951 ops/training.py:65 2019-01-16 16:40:42.746873: step 228, loss = 0.72819 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:40:43.730579 ops/training.py:65 2019-01-16 16:40:43.730511: step 229, loss = 0.65291 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:40:44.714688 ops/training.py:65 2019-01-16 16:40:44.714599: step 230, loss = 0.74049 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:40:45.698005 ops/training.py:65 2019-01-16 16:40:45.697964: step 231, loss = 0.89689 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.25
I8192 2019-01-16 16:40:46.679757 ops/training.py:65 2019-01-16 16:40:46.679721: step 232, loss = 0.81759 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:40:47.661669 ops/training.py:65 2019-01-16 16:40:47.661635: step 233, loss = 0.72558 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:40:48.645483 ops/training.py:65 2019-01-16 16:40:48.645449: step 234, loss = 0.71310 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:40:49.628627 ops/training.py:65 2019-01-16 16:40:49.628592: step 235, loss = 0.76760 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:40:50.614464 ops/training.py:65 2019-01-16 16:40:50.614426: step 236, loss = 0.75376 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:40:51.598391 ops/training.py:65 2019-01-16 16:40:51.598357: step 237, loss = 0.68522 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:40:52.583529 ops/training.py:65 2019-01-16 16:40:52.583495: step 238, loss = 0.72015 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:40:53.565218 ops/training.py:65 2019-01-16 16:40:53.565180: step 239, loss = 0.79381 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:40:54.549165 ops/training.py:65 2019-01-16 16:40:54.549126: step 240, loss = 0.75934 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:40:55.532261 ops/training.py:65 2019-01-16 16:40:55.532228: step 241, loss = 0.68226 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:40:56.514802 ops/training.py:65 2019-01-16 16:40:56.514762: step 242, loss = 0.83269 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:40:57.497121 ops/training.py:65 2019-01-16 16:40:57.497062: step 243, loss = 0.64879 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:40:58.478888 ops/training.py:65 2019-01-16 16:40:58.478855: step 244, loss = 0.66186 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 16:40:59.462310 ops/training.py:65 2019-01-16 16:40:59.462277: step 245, loss = 0.71940 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:41:00.444899 ops/training.py:65 2019-01-16 16:41:00.444865: step 246, loss = 0.77052 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:41:01.427771 ops/training.py:65 2019-01-16 16:41:01.427735: step 247, loss = 0.73097 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:41:02.409728 ops/training.py:65 2019-01-16 16:41:02.409691: step 248, loss = 0.69902 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:41:03.391065 ops/training.py:65 2019-01-16 16:41:03.391030: step 249, loss = 0.74512 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:41:04.377008 ops/training.py:65 2019-01-16 16:41:04.376972: step 250, loss = 0.71353 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:41:05.358957 ops/training.py:65 2019-01-16 16:41:05.358860: step 251, loss = 0.79142 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:41:06.341042 ops/training.py:65 2019-01-16 16:41:06.341006: step 252, loss = 0.68001 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:41:07.324666 ops/training.py:65 2019-01-16 16:41:07.324632: step 253, loss = 0.73564 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:41:08.305816 ops/training.py:65 2019-01-16 16:41:08.305779: step 254, loss = 0.75625 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:41:09.291016 ops/training.py:65 2019-01-16 16:41:09.290982: step 255, loss = 0.76602 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:41:10.274652 ops/training.py:65 2019-01-16 16:41:10.274592: step 256, loss = 0.67700 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 16:41:11.258789 ops/training.py:65 2019-01-16 16:41:11.258711: step 257, loss = 0.73347 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:41:12.239376 ops/training.py:65 2019-01-16 16:41:12.239293: step 258, loss = 0.75651 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:41:13.221302 ops/training.py:65 2019-01-16 16:41:13.221218: step 259, loss = 0.68629 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:41:14.204355 ops/training.py:65 2019-01-16 16:41:14.204282: step 260, loss = 0.72805 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:41:15.188162 ops/training.py:65 2019-01-16 16:41:15.188052: step 261, loss = 0.68492 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:41:16.170019 ops/training.py:65 2019-01-16 16:41:16.169912: step 262, loss = 0.80176 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:41:17.153800 ops/training.py:65 2019-01-16 16:41:17.153708: step 263, loss = 0.67363 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:41:18.138478 ops/training.py:65 2019-01-16 16:41:18.138368: step 264, loss = 0.71072 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:41:19.121851 ops/training.py:65 2019-01-16 16:41:19.121740: step 265, loss = 0.74615 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:41:20.104704 ops/training.py:65 2019-01-16 16:41:20.104603: step 266, loss = 0.79291 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:41:21.087727 ops/training.py:65 2019-01-16 16:41:21.087646: step 267, loss = 0.59386 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 16:41:22.070483 ops/training.py:65 2019-01-16 16:41:22.070421: step 268, loss = 0.65850 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:41:23.053411 ops/training.py:65 2019-01-16 16:41:23.053347: step 269, loss = 0.73008 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:41:24.036603 ops/training.py:65 2019-01-16 16:41:24.036491: step 270, loss = 0.71629 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:41:25.019477 ops/training.py:65 2019-01-16 16:41:25.019359: step 271, loss = 0.68540 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:41:26.002761 ops/training.py:65 2019-01-16 16:41:26.002662: step 272, loss = 0.76196 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:41:26.985732 ops/training.py:65 2019-01-16 16:41:26.985632: step 273, loss = 0.79424 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:41:27.968311 ops/training.py:65 2019-01-16 16:41:27.968205: step 274, loss = 0.83886 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:41:28.949704 ops/training.py:65 2019-01-16 16:41:28.949599: step 275, loss = 0.70742 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:41:29.935890 ops/training.py:65 2019-01-16 16:41:29.935790: step 276, loss = 0.71735 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:41:30.920008 ops/training.py:65 2019-01-16 16:41:30.919902: step 277, loss = 0.77029 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:41:31.902382 ops/training.py:65 2019-01-16 16:41:31.902290: step 278, loss = 0.70643 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:41:32.886096 ops/training.py:65 2019-01-16 16:41:32.885990: step 279, loss = 0.63316 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:41:33.869269 ops/training.py:65 2019-01-16 16:41:33.869213: step 280, loss = 0.73708 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:41:34.854919 ops/training.py:65 2019-01-16 16:41:34.854817: step 281, loss = 0.76288 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:41:35.841333 ops/training.py:65 2019-01-16 16:41:35.841226: step 282, loss = 0.73848 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:41:36.824658 ops/training.py:65 2019-01-16 16:41:36.824555: step 283, loss = 0.75878 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:41:37.806582 ops/training.py:65 2019-01-16 16:41:37.806485: step 284, loss = 0.69189 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:41:38.789562 ops/training.py:65 2019-01-16 16:41:38.789455: step 285, loss = 0.79685 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:41:39.775503 ops/training.py:65 2019-01-16 16:41:39.775398: step 286, loss = 0.67799 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:41:40.759558 ops/training.py:65 2019-01-16 16:41:40.759455: step 287, loss = 0.73280 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:41:41.743410 ops/training.py:65 2019-01-16 16:41:41.743304: step 288, loss = 0.82753 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:41:42.727160 ops/training.py:65 2019-01-16 16:41:42.727058: step 289, loss = 0.68759 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:41:43.712228 ops/training.py:65 2019-01-16 16:41:43.712134: step 290, loss = 0.70382 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 16:41:44.696097 ops/training.py:65 2019-01-16 16:41:44.695999: step 291, loss = 0.78852 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:41:45.680139 ops/training.py:65 2019-01-16 16:41:45.680042: step 292, loss = 0.66775 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:41:46.664305 ops/training.py:65 2019-01-16 16:41:46.664200: step 293, loss = 0.74332 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:41:47.648528 ops/training.py:65 2019-01-16 16:41:47.648436: step 294, loss = 0.79729 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:41:48.633632 ops/training.py:65 2019-01-16 16:41:48.633522: step 295, loss = 0.68314 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:41:49.618385 ops/training.py:65 2019-01-16 16:41:49.618285: step 296, loss = 0.72273 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:41:50.604454 ops/training.py:65 2019-01-16 16:41:50.604348: step 297, loss = 0.67578 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:41:51.590892 ops/training.py:65 2019-01-16 16:41:51.590766: step 298, loss = 0.72348 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:41:52.576766 ops/training.py:65 2019-01-16 16:41:52.576664: step 299, loss = 0.73694 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:41:53.561727 ops/training.py:65 2019-01-16 16:41:53.561619: step 300, loss = 0.79714 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:41:54.545249 ops/training.py:65 2019-01-16 16:41:54.545144: step 301, loss = 0.66948 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:41:55.527927 ops/training.py:65 2019-01-16 16:41:55.527828: step 302, loss = 0.73571 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:41:56.510409 ops/training.py:65 2019-01-16 16:41:56.510326: step 303, loss = 0.70697 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:41:57.492193 ops/training.py:65 2019-01-16 16:41:57.492073: step 304, loss = 0.74281 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:41:58.472807 ops/training.py:65 2019-01-16 16:41:58.472728: step 305, loss = 0.77223 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:41:59.453758 ops/training.py:65 2019-01-16 16:41:59.453693: step 306, loss = 0.71443 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:42:00.436806 ops/training.py:65 2019-01-16 16:42:00.436742: step 307, loss = 0.79771 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:42:01.419145 ops/training.py:65 2019-01-16 16:42:01.419103: step 308, loss = 0.65638 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:42:02.400984 ops/training.py:65 2019-01-16 16:42:02.400930: step 309, loss = 0.69626 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:42:03.383328 ops/training.py:65 2019-01-16 16:42:03.383280: step 310, loss = 0.74770 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:42:04.364495 ops/training.py:65 2019-01-16 16:42:04.364453: step 311, loss = 0.78804 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:42:05.345357 ops/training.py:65 2019-01-16 16:42:05.345294: step 312, loss = 0.65348 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:42:06.327665 ops/training.py:65 2019-01-16 16:42:06.327582: step 313, loss = 0.79704 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:42:07.313014 ops/training.py:65 2019-01-16 16:42:07.312908: step 314, loss = 0.76495 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:42:08.298037 ops/training.py:65 2019-01-16 16:42:08.297929: step 315, loss = 0.69547 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:42:09.281142 ops/training.py:65 2019-01-16 16:42:09.281037: step 316, loss = 0.72710 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:42:10.263925 ops/training.py:65 2019-01-16 16:42:10.263823: step 317, loss = 0.70770 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:42:11.246879 ops/training.py:65 2019-01-16 16:42:11.246775: step 318, loss = 0.78927 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:42:12.228718 ops/training.py:65 2019-01-16 16:42:12.228613: step 319, loss = 0.80399 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:42:13.211077 ops/training.py:65 2019-01-16 16:42:13.211018: step 320, loss = 0.77469 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:42:14.192585 ops/training.py:65 2019-01-16 16:42:14.192550: step 321, loss = 0.65869 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:42:15.174060 ops/training.py:65 2019-01-16 16:42:15.174027: step 322, loss = 0.75538 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:42:16.156792 ops/training.py:65 2019-01-16 16:42:16.156755: step 323, loss = 0.76919 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:42:17.140104 ops/training.py:65 2019-01-16 16:42:17.140071: step 324, loss = 0.72316 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:42:18.122190 ops/training.py:65 2019-01-16 16:42:18.122153: step 325, loss = 0.75264 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:42:19.105253 ops/training.py:65 2019-01-16 16:42:19.105221: step 326, loss = 0.68693 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:42:20.089442 ops/training.py:65 2019-01-16 16:42:20.089408: step 327, loss = 0.71774 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 16:42:21.072691 ops/training.py:65 2019-01-16 16:42:21.072657: step 328, loss = 0.82142 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:42:22.058752 ops/training.py:65 2019-01-16 16:42:22.058715: step 329, loss = 0.72985 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:42:23.069289 ops/training.py:65 2019-01-16 16:42:23.069238: step 330, loss = 0.75843 (31.7 examples/sec; 1.010 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:42:24.051875 ops/training.py:65 2019-01-16 16:42:24.051833: step 331, loss = 0.72264 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:42:25.034882 ops/training.py:65 2019-01-16 16:42:25.034849: step 332, loss = 0.69707 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:42:26.017860 ops/training.py:65 2019-01-16 16:42:26.017793: step 333, loss = 0.72673 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:42:27.002290 ops/training.py:65 2019-01-16 16:42:27.002254: step 334, loss = 0.75386 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:42:27.985670 ops/training.py:65 2019-01-16 16:42:27.985642: step 335, loss = 0.64819 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:42:28.967938 ops/training.py:65 2019-01-16 16:42:28.967906: step 336, loss = 0.80020 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:42:29.949653 ops/training.py:65 2019-01-16 16:42:29.949624: step 337, loss = 0.70180 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:42:30.932032 ops/training.py:65 2019-01-16 16:42:30.932002: step 338, loss = 0.78401 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:42:31.913422 ops/training.py:65 2019-01-16 16:42:31.913392: step 339, loss = 0.73630 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:42:32.894201 ops/training.py:65 2019-01-16 16:42:32.894171: step 340, loss = 0.68284 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:42:33.874349 ops/training.py:65 2019-01-16 16:42:33.874319: step 341, loss = 0.78206 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:42:34.856031 ops/training.py:65 2019-01-16 16:42:34.856002: step 342, loss = 0.74213 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:42:35.837877 ops/training.py:65 2019-01-16 16:42:35.837846: step 343, loss = 0.76590 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:42:36.819145 ops/training.py:65 2019-01-16 16:42:36.819086: step 344, loss = 0.72306 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:42:37.800328 ops/training.py:65 2019-01-16 16:42:37.800293: step 345, loss = 0.71337 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:42:38.781199 ops/training.py:65 2019-01-16 16:42:38.781168: step 346, loss = 0.76052 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:42:39.761839 ops/training.py:65 2019-01-16 16:42:39.761807: step 347, loss = 0.72113 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:42:40.743549 ops/training.py:65 2019-01-16 16:42:40.743519: step 348, loss = 0.82084 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 16:42:41.724422 ops/training.py:65 2019-01-16 16:42:41.724393: step 349, loss = 0.77742 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:42:42.705662 ops/training.py:65 2019-01-16 16:42:42.705621: step 350, loss = 0.82407 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 16:42:43.686371 ops/training.py:65 2019-01-16 16:42:43.686321: step 351, loss = 0.76031 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:42:44.666691 ops/training.py:65 2019-01-16 16:42:44.666657: step 352, loss = 0.67996 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:42:45.647811 ops/training.py:65 2019-01-16 16:42:45.647775: step 353, loss = 0.64697 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:42:46.628882 ops/training.py:65 2019-01-16 16:42:46.628800: step 354, loss = 0.75144 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:42:47.610182 ops/training.py:65 2019-01-16 16:42:47.610119: step 355, loss = 0.70529 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:42:48.592442 ops/training.py:65 2019-01-16 16:42:48.592347: step 356, loss = 0.76608 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:42:49.576423 ops/training.py:65 2019-01-16 16:42:49.576328: step 357, loss = 0.78329 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:42:50.560045 ops/training.py:65 2019-01-16 16:42:50.559936: step 358, loss = 0.74387 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 16:42:51.542873 ops/training.py:65 2019-01-16 16:42:51.542795: step 359, loss = 0.68918 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:42:52.524336 ops/training.py:65 2019-01-16 16:42:52.524255: step 360, loss = 0.77420 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:42:53.506377 ops/training.py:65 2019-01-16 16:42:53.506308: step 361, loss = 0.72399 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:42:54.489893 ops/training.py:65 2019-01-16 16:42:54.489826: step 362, loss = 0.77867 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 16:42:55.473905 ops/training.py:65 2019-01-16 16:42:55.473796: step 363, loss = 0.73555 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:42:56.460315 ops/training.py:65 2019-01-16 16:42:56.460202: step 364, loss = 0.68488 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:42:57.443506 ops/training.py:65 2019-01-16 16:42:57.443399: step 365, loss = 0.74150 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:42:58.429468 ops/training.py:65 2019-01-16 16:42:58.429359: step 366, loss = 0.75966 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:42:59.413406 ops/training.py:65 2019-01-16 16:42:59.413303: step 367, loss = 0.70489 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:43:00.395922 ops/training.py:65 2019-01-16 16:43:00.395827: step 368, loss = 0.87786 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.25
I8192 2019-01-16 16:43:01.380506 ops/training.py:65 2019-01-16 16:43:01.380400: step 369, loss = 0.72346 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:43:02.363800 ops/training.py:65 2019-01-16 16:43:02.363699: step 370, loss = 0.74310 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:43:03.345814 ops/training.py:65 2019-01-16 16:43:03.345713: step 371, loss = 0.71704 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:43:04.327787 ops/training.py:65 2019-01-16 16:43:04.327682: step 372, loss = 0.74060 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:43:05.311185 ops/training.py:65 2019-01-16 16:43:05.311083: step 373, loss = 0.69326 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:43:06.295035 ops/training.py:65 2019-01-16 16:43:06.294928: step 374, loss = 0.70490 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:43:07.278607 ops/training.py:65 2019-01-16 16:43:07.278519: step 375, loss = 0.62145 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 16:43:08.263426 ops/training.py:65 2019-01-16 16:43:08.263327: step 376, loss = 0.73360 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:43:09.247985 ops/training.py:65 2019-01-16 16:43:09.247882: step 377, loss = 0.64436 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 16:43:10.232940 ops/training.py:65 2019-01-16 16:43:10.232876: step 378, loss = 0.71631 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:43:11.217895 ops/training.py:65 2019-01-16 16:43:11.217796: step 379, loss = 0.78194 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:43:12.201391 ops/training.py:65 2019-01-16 16:43:12.201282: step 380, loss = 0.69960 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:43:13.186351 ops/training.py:65 2019-01-16 16:43:13.186256: step 381, loss = 0.66655 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:43:14.177859 ops/training.py:65 2019-01-16 16:43:14.177758: step 382, loss = 0.76329 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:43:15.162610 ops/training.py:65 2019-01-16 16:43:15.162510: step 383, loss = 0.73683 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:43:16.144913 ops/training.py:65 2019-01-16 16:43:16.144842: step 384, loss = 0.68358 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:43:17.125633 ops/training.py:65 2019-01-16 16:43:17.125558: step 385, loss = 0.79672 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:43:18.107181 ops/training.py:65 2019-01-16 16:43:18.107112: step 386, loss = 0.69416 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:43:19.092175 ops/training.py:65 2019-01-16 16:43:19.092080: step 387, loss = 0.79311 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:43:20.076420 ops/training.py:65 2019-01-16 16:43:20.076323: step 388, loss = 0.75344 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:43:21.058157 ops/training.py:65 2019-01-16 16:43:21.058059: step 389, loss = 0.72567 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:43:22.041455 ops/training.py:65 2019-01-16 16:43:22.041357: step 390, loss = 0.73707 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:43:23.024375 ops/training.py:65 2019-01-16 16:43:23.024269: step 391, loss = 0.71022 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:43:24.006539 ops/training.py:65 2019-01-16 16:43:24.006437: step 392, loss = 0.69389 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:43:24.988120 ops/training.py:65 2019-01-16 16:43:24.988022: step 393, loss = 0.73231 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:43:25.973552 ops/training.py:65 2019-01-16 16:43:25.973450: step 394, loss = 0.67573 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:43:26.956596 ops/training.py:65 2019-01-16 16:43:26.956494: step 395, loss = 0.67993 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:43:27.938584 ops/training.py:65 2019-01-16 16:43:27.938517: step 396, loss = 0.70155 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:43:28.918142 ops/training.py:65 2019-01-16 16:43:28.918067: step 397, loss = 0.72746 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:43:29.900270 ops/training.py:65 2019-01-16 16:43:29.900199: step 398, loss = 0.67245 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:43:30.882064 ops/training.py:65 2019-01-16 16:43:30.881961: step 399, loss = 0.74491 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 16:43:31.864340 ops/training.py:65 2019-01-16 16:43:31.864234: step 400, loss = 0.72678 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:43:32.845825 ops/training.py:65 2019-01-16 16:43:32.845735: step 401, loss = 0.66948 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:43:33.826892 ops/training.py:65 2019-01-16 16:43:33.826785: step 402, loss = 0.74098 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:43:34.809668 ops/training.py:65 2019-01-16 16:43:34.809564: step 403, loss = 0.66351 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:43:35.791163 ops/training.py:65 2019-01-16 16:43:35.791059: step 404, loss = 0.71941 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:43:36.775182 ops/training.py:65 2019-01-16 16:43:36.775034: step 405, loss = 0.75490 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:43:37.760234 ops/training.py:65 2019-01-16 16:43:37.760133: step 406, loss = 0.61730 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 16:43:38.745068 ops/training.py:65 2019-01-16 16:43:38.744954: step 407, loss = 0.74009 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:43:39.728729 ops/training.py:65 2019-01-16 16:43:39.728615: step 408, loss = 0.69340 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:43:40.711390 ops/training.py:65 2019-01-16 16:43:40.711288: step 409, loss = 0.79497 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 16:43:41.693486 ops/training.py:65 2019-01-16 16:43:41.693390: step 410, loss = 0.65971 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:43:42.675395 ops/training.py:65 2019-01-16 16:43:42.675287: step 411, loss = 0.73515 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:43:43.658133 ops/training.py:65 2019-01-16 16:43:43.658032: step 412, loss = 0.72714 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:43:44.641423 ops/training.py:65 2019-01-16 16:43:44.641357: step 413, loss = 0.70377 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:43:45.623172 ops/training.py:65 2019-01-16 16:43:45.623125: step 414, loss = 0.67711 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:43:46.604075 ops/training.py:65 2019-01-16 16:43:46.604033: step 415, loss = 0.67101 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:43:47.584716 ops/training.py:65 2019-01-16 16:43:47.584678: step 416, loss = 0.66935 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:43:48.566625 ops/training.py:65 2019-01-16 16:43:48.566584: step 417, loss = 0.71405 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:43:49.548910 ops/training.py:65 2019-01-16 16:43:49.548870: step 418, loss = 0.72892 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:43:50.531073 ops/training.py:65 2019-01-16 16:43:50.531033: step 419, loss = 0.65803 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:43:51.512575 ops/training.py:65 2019-01-16 16:43:51.512536: step 420, loss = 0.72925 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:43:52.495804 ops/training.py:65 2019-01-16 16:43:52.495769: step 421, loss = 0.68097 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:43:53.479722 ops/training.py:65 2019-01-16 16:43:53.479683: step 422, loss = 0.72311 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:43:54.463562 ops/training.py:65 2019-01-16 16:43:54.463525: step 423, loss = 0.76167 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:43:55.445059 ops/training.py:65 2019-01-16 16:43:55.445020: step 424, loss = 0.73728 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:43:56.428863 ops/training.py:65 2019-01-16 16:43:56.428823: step 425, loss = 0.64619 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:43:57.409477 ops/training.py:65 2019-01-16 16:43:57.409444: step 426, loss = 0.74135 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:43:58.392917 ops/training.py:65 2019-01-16 16:43:58.392883: step 427, loss = 0.67800 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:43:59.378355 ops/training.py:65 2019-01-16 16:43:59.378320: step 428, loss = 0.72557 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:44:00.361776 ops/training.py:65 2019-01-16 16:44:00.361739: step 429, loss = 0.70280 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:44:01.344599 ops/training.py:65 2019-01-16 16:44:01.344536: step 430, loss = 0.76753 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:44:02.326610 ops/training.py:65 2019-01-16 16:44:02.326576: step 431, loss = 0.64638 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:44:03.311678 ops/training.py:65 2019-01-16 16:44:03.311646: step 432, loss = 0.66122 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:44:04.297945 ops/training.py:65 2019-01-16 16:44:04.297913: step 433, loss = 0.66955 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:44:05.280729 ops/training.py:65 2019-01-16 16:44:05.280696: step 434, loss = 0.73038 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:44:06.263991 ops/training.py:65 2019-01-16 16:44:06.263960: step 435, loss = 0.71704 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:44:07.248350 ops/training.py:65 2019-01-16 16:44:07.248316: step 436, loss = 0.75852 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:44:08.233366 ops/training.py:65 2019-01-16 16:44:08.233333: step 437, loss = 0.68242 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:44:09.217590 ops/training.py:65 2019-01-16 16:44:09.217558: step 438, loss = 0.71593 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:44:10.201609 ops/training.py:65 2019-01-16 16:44:10.201576: step 439, loss = 0.71589 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:44:11.183377 ops/training.py:65 2019-01-16 16:44:11.183342: step 440, loss = 0.65821 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 16:44:12.164757 ops/training.py:65 2019-01-16 16:44:12.164723: step 441, loss = 0.67403 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:44:13.145029 ops/training.py:65 2019-01-16 16:44:13.144997: step 442, loss = 0.72731 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:44:14.127551 ops/training.py:65 2019-01-16 16:44:14.127519: step 443, loss = 0.72083 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:44:15.108552 ops/training.py:65 2019-01-16 16:44:15.108520: step 444, loss = 0.74853 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:44:16.089916 ops/training.py:65 2019-01-16 16:44:16.089885: step 445, loss = 0.83292 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.15625
I8192 2019-01-16 16:44:17.073672 ops/training.py:65 2019-01-16 16:44:17.073641: step 446, loss = 0.70671 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:44:18.057480 ops/training.py:65 2019-01-16 16:44:18.057448: step 447, loss = 0.77088 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:44:19.040027 ops/training.py:65 2019-01-16 16:44:19.039992: step 448, loss = 0.64385 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:44:20.022000 ops/training.py:65 2019-01-16 16:44:20.021967: step 449, loss = 0.62138 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:44:21.003340 ops/training.py:65 2019-01-16 16:44:21.003308: step 450, loss = 0.77853 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:44:21.985060 ops/training.py:65 2019-01-16 16:44:21.985027: step 451, loss = 0.68298 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:44:22.966247 ops/training.py:65 2019-01-16 16:44:22.966215: step 452, loss = 0.70323 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:44:23.948055 ops/training.py:65 2019-01-16 16:44:23.948020: step 453, loss = 0.66180 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:44:24.930982 ops/training.py:65 2019-01-16 16:44:24.930949: step 454, loss = 0.77529 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:44:25.914049 ops/training.py:65 2019-01-16 16:44:25.914017: step 455, loss = 0.70544 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:44:26.895360 ops/training.py:65 2019-01-16 16:44:26.895327: step 456, loss = 0.70988 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:44:27.880358 ops/training.py:65 2019-01-16 16:44:27.880261: step 457, loss = 0.76827 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:44:28.861855 ops/training.py:65 2019-01-16 16:44:28.861768: step 458, loss = 0.76061 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:44:29.842940 ops/training.py:65 2019-01-16 16:44:29.842878: step 459, loss = 0.73835 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:44:30.822475 ops/training.py:65 2019-01-16 16:44:30.822411: step 460, loss = 0.70621 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 16:44:31.802202 ops/training.py:65 2019-01-16 16:44:31.802136: step 461, loss = 0.68075 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:44:32.783135 ops/training.py:65 2019-01-16 16:44:32.783076: step 462, loss = 0.79185 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:44:33.765862 ops/training.py:65 2019-01-16 16:44:33.765828: step 463, loss = 0.77935 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:44:34.749877 ops/training.py:65 2019-01-16 16:44:34.749846: step 464, loss = 0.72599 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:44:35.731150 ops/training.py:65 2019-01-16 16:44:35.731118: step 465, loss = 0.67957 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:44:36.712517 ops/training.py:65 2019-01-16 16:44:36.712479: step 466, loss = 0.73694 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:44:37.694649 ops/training.py:65 2019-01-16 16:44:37.694556: step 467, loss = 0.68557 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:44:38.676544 ops/training.py:65 2019-01-16 16:44:38.676456: step 468, loss = 0.74222 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:44:39.657518 ops/training.py:65 2019-01-16 16:44:39.657449: step 469, loss = 0.75100 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:44:40.638237 ops/training.py:65 2019-01-16 16:44:40.638158: step 470, loss = 0.70192 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:44:41.621422 ops/training.py:65 2019-01-16 16:44:41.621342: step 471, loss = 0.75639 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:44:42.603361 ops/training.py:65 2019-01-16 16:44:42.603259: step 472, loss = 0.69939 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:44:43.584605 ops/training.py:65 2019-01-16 16:44:43.584502: step 473, loss = 0.73091 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:44:44.566990 ops/training.py:65 2019-01-16 16:44:44.566952: step 474, loss = 0.65406 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:44:45.549554 ops/training.py:65 2019-01-16 16:44:45.549517: step 475, loss = 0.76898 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:44:46.530687 ops/training.py:65 2019-01-16 16:44:46.530564: step 476, loss = 0.78385 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:44:47.512913 ops/training.py:65 2019-01-16 16:44:47.512830: step 477, loss = 0.70100 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:44:48.496976 ops/training.py:65 2019-01-16 16:44:48.496898: step 478, loss = 0.73617 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:44:49.482514 ops/training.py:65 2019-01-16 16:44:49.482430: step 479, loss = 0.75036 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:44:50.467921 ops/training.py:65 2019-01-16 16:44:50.467820: step 480, loss = 0.69287 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 16:44:51.451210 ops/training.py:65 2019-01-16 16:44:51.451138: step 481, loss = 0.70968 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:44:52.433846 ops/training.py:65 2019-01-16 16:44:52.433735: step 482, loss = 0.73970 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:44:53.416613 ops/training.py:65 2019-01-16 16:44:53.416504: step 483, loss = 0.73364 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:44:54.397612 ops/training.py:65 2019-01-16 16:44:54.397500: step 484, loss = 0.74886 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:44:55.379977 ops/training.py:65 2019-01-16 16:44:55.379856: step 485, loss = 0.70803 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:44:56.361661 ops/training.py:65 2019-01-16 16:44:56.361554: step 486, loss = 0.79190 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:44:57.342870 ops/training.py:65 2019-01-16 16:44:57.342766: step 487, loss = 0.75721 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:44:58.329063 ops/training.py:65 2019-01-16 16:44:58.328954: step 488, loss = 0.72256 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:44:59.313757 ops/training.py:65 2019-01-16 16:44:59.313648: step 489, loss = 0.74384 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:45:00.296488 ops/training.py:65 2019-01-16 16:45:00.296385: step 490, loss = 0.72600 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:45:01.279280 ops/training.py:65 2019-01-16 16:45:01.279176: step 491, loss = 0.67561 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:45:02.261051 ops/training.py:65 2019-01-16 16:45:02.260956: step 492, loss = 0.70459 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:45:03.243291 ops/training.py:65 2019-01-16 16:45:03.243183: step 493, loss = 0.68447 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:45:04.225331 ops/training.py:65 2019-01-16 16:45:04.225220: step 494, loss = 0.64692 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:45:05.206843 ops/training.py:65 2019-01-16 16:45:05.206728: step 495, loss = 0.69413 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:45:06.187435 ops/training.py:65 2019-01-16 16:45:06.187335: step 496, loss = 0.71078 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:45:07.169548 ops/training.py:65 2019-01-16 16:45:07.169444: step 497, loss = 0.74388 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:45:08.151871 ops/training.py:65 2019-01-16 16:45:08.151760: step 498, loss = 0.71174 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:45:09.136542 ops/training.py:65 2019-01-16 16:45:09.136435: step 499, loss = 0.66606 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:45:10.119564 ops/training.py:65 2019-01-16 16:45:10.119460: step 500, loss = 0.64628 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:45:11.104929 ops/training.py:65 2019-01-16 16:45:11.104825: step 501, loss = 0.71285 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:45:12.087424 ops/training.py:65 2019-01-16 16:45:12.087319: step 502, loss = 0.75025 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:45:13.072618 ops/training.py:65 2019-01-16 16:45:13.072512: step 503, loss = 0.74943 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:45:14.056699 ops/training.py:65 2019-01-16 16:45:14.056594: step 504, loss = 0.71150 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:45:15.040677 ops/training.py:65 2019-01-16 16:45:15.040579: step 505, loss = 0.74551 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:45:16.026760 ops/training.py:65 2019-01-16 16:45:16.026651: step 506, loss = 0.70664 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:45:17.011600 ops/training.py:65 2019-01-16 16:45:17.011495: step 507, loss = 0.64860 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:45:17.995718 ops/training.py:65 2019-01-16 16:45:17.995617: step 508, loss = 0.69381 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:45:18.978011 ops/training.py:65 2019-01-16 16:45:18.977911: step 509, loss = 0.72757 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:45:19.960979 ops/training.py:65 2019-01-16 16:45:19.960879: step 510, loss = 0.78040 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.25
I8192 2019-01-16 16:45:20.945559 ops/training.py:65 2019-01-16 16:45:20.945458: step 511, loss = 0.73130 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:45:21.928225 ops/training.py:65 2019-01-16 16:45:21.928116: step 512, loss = 0.73373 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:45:22.910597 ops/training.py:65 2019-01-16 16:45:22.910485: step 513, loss = 0.70428 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:45:23.892693 ops/training.py:65 2019-01-16 16:45:23.892596: step 514, loss = 0.72815 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:45:24.874279 ops/training.py:65 2019-01-16 16:45:24.874169: step 515, loss = 0.70640 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:45:25.857081 ops/training.py:65 2019-01-16 16:45:25.856983: step 516, loss = 0.69498 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:45:26.842462 ops/training.py:65 2019-01-16 16:45:26.842358: step 517, loss = 0.71762 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:45:27.828176 ops/training.py:65 2019-01-16 16:45:27.828060: step 518, loss = 0.74247 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:45:28.812696 ops/training.py:65 2019-01-16 16:45:28.812609: step 519, loss = 0.69758 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 16:45:29.795544 ops/training.py:65 2019-01-16 16:45:29.795473: step 520, loss = 0.71803 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:45:30.777177 ops/training.py:65 2019-01-16 16:45:30.777107: step 521, loss = 0.73796 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:45:31.759878 ops/training.py:65 2019-01-16 16:45:31.759787: step 522, loss = 0.69070 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:45:32.742957 ops/training.py:65 2019-01-16 16:45:32.742860: step 523, loss = 0.70874 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:45:33.723936 ops/training.py:65 2019-01-16 16:45:33.723829: step 524, loss = 0.71172 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:45:34.704763 ops/training.py:65 2019-01-16 16:45:34.704661: step 525, loss = 0.73703 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:45:35.688739 ops/training.py:65 2019-01-16 16:45:35.688637: step 526, loss = 0.71331 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:45:36.673095 ops/training.py:65 2019-01-16 16:45:36.672996: step 527, loss = 0.74465 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 16:45:37.658045 ops/training.py:65 2019-01-16 16:45:37.657935: step 528, loss = 0.71402 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:45:38.643028 ops/training.py:65 2019-01-16 16:45:38.642927: step 529, loss = 0.72509 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:45:39.626148 ops/training.py:65 2019-01-16 16:45:39.626034: step 530, loss = 0.69425 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:45:40.610609 ops/training.py:65 2019-01-16 16:45:40.610543: step 531, loss = 0.67401 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:45:41.595423 ops/training.py:65 2019-01-16 16:45:41.595326: step 532, loss = 0.69116 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:45:42.580456 ops/training.py:65 2019-01-16 16:45:42.580360: step 533, loss = 0.67695 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:45:43.562738 ops/training.py:65 2019-01-16 16:45:43.562641: step 534, loss = 0.70937 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:45:44.547300 ops/training.py:65 2019-01-16 16:45:44.547201: step 535, loss = 0.68669 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 16:45:45.531696 ops/training.py:65 2019-01-16 16:45:45.531599: step 536, loss = 0.71197 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:45:46.517158 ops/training.py:65 2019-01-16 16:45:46.517058: step 537, loss = 0.70978 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:45:47.502286 ops/training.py:65 2019-01-16 16:45:47.502192: step 538, loss = 0.75735 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:45:48.487496 ops/training.py:65 2019-01-16 16:45:48.487417: step 539, loss = 0.72253 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:45:49.469152 ops/training.py:65 2019-01-16 16:45:49.469047: step 540, loss = 0.71617 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:45:50.453629 ops/training.py:65 2019-01-16 16:45:50.453527: step 541, loss = 0.68191 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:45:51.439295 ops/training.py:65 2019-01-16 16:45:51.439190: step 542, loss = 0.67174 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:45:52.424868 ops/training.py:65 2019-01-16 16:45:52.424771: step 543, loss = 0.73317 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:45:53.409742 ops/training.py:65 2019-01-16 16:45:53.409635: step 544, loss = 0.68523 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:45:54.393274 ops/training.py:65 2019-01-16 16:45:54.393172: step 545, loss = 0.70258 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:45:55.375784 ops/training.py:65 2019-01-16 16:45:55.375668: step 546, loss = 0.64174 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:45:56.364288 ops/training.py:65 2019-01-16 16:45:56.364190: step 547, loss = 0.73037 (32.4 examples/sec; 0.987 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:45:57.348673 ops/training.py:65 2019-01-16 16:45:57.348566: step 548, loss = 0.68571 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:45:58.331353 ops/training.py:65 2019-01-16 16:45:58.331247: step 549, loss = 0.71544 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:45:59.317165 ops/training.py:65 2019-01-16 16:45:59.317061: step 550, loss = 0.71549 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:46:00.302765 ops/training.py:65 2019-01-16 16:46:00.302667: step 551, loss = 0.70604 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:46:01.287164 ops/training.py:65 2019-01-16 16:46:01.287064: step 552, loss = 0.67135 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:46:02.272810 ops/training.py:65 2019-01-16 16:46:02.272712: step 553, loss = 0.69833 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:46:03.258723 ops/training.py:65 2019-01-16 16:46:03.258632: step 554, loss = 0.70541 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:46:04.241851 ops/training.py:65 2019-01-16 16:46:04.241752: step 555, loss = 0.70805 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:46:05.225598 ops/training.py:65 2019-01-16 16:46:05.225489: step 556, loss = 0.73115 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:46:06.211209 ops/training.py:65 2019-01-16 16:46:06.211140: step 557, loss = 0.71787 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 16:46:07.194305 ops/training.py:65 2019-01-16 16:46:07.194197: step 558, loss = 0.72016 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:46:08.179042 ops/training.py:65 2019-01-16 16:46:08.178939: step 559, loss = 0.71003 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:46:09.164156 ops/training.py:65 2019-01-16 16:46:09.164049: step 560, loss = 0.65225 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 16:46:10.150187 ops/training.py:65 2019-01-16 16:46:10.150079: step 561, loss = 0.65792 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 16:46:11.132481 ops/training.py:65 2019-01-16 16:46:11.132377: step 562, loss = 0.69197 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:46:12.113600 ops/training.py:65 2019-01-16 16:46:12.113498: step 563, loss = 0.68442 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:46:13.095245 ops/training.py:65 2019-01-16 16:46:13.095148: step 564, loss = 0.67850 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:46:14.079795 ops/training.py:65 2019-01-16 16:46:14.079684: step 565, loss = 0.68700 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:46:15.065399 ops/training.py:65 2019-01-16 16:46:15.065290: step 566, loss = 0.69854 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:46:16.048975 ops/training.py:65 2019-01-16 16:46:16.048876: step 567, loss = 0.69960 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:46:17.033129 ops/training.py:65 2019-01-16 16:46:17.033025: step 568, loss = 0.64917 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:46:18.016666 ops/training.py:65 2019-01-16 16:46:18.016606: step 569, loss = 0.75488 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:46:19.000006 ops/training.py:65 2019-01-16 16:46:18.999898: step 570, loss = 0.72282 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:46:19.983271 ops/training.py:65 2019-01-16 16:46:19.983166: step 571, loss = 0.67652 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 16:46:20.965761 ops/training.py:65 2019-01-16 16:46:20.965654: step 572, loss = 0.69500 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:46:21.947507 ops/training.py:65 2019-01-16 16:46:21.947408: step 573, loss = 0.71945 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:46:22.930260 ops/training.py:65 2019-01-16 16:46:22.930162: step 574, loss = 0.72825 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:46:23.912328 ops/training.py:65 2019-01-16 16:46:23.912227: step 575, loss = 0.71530 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:46:24.893933 ops/training.py:65 2019-01-16 16:46:24.893833: step 576, loss = 0.70141 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:46:25.878422 ops/training.py:65 2019-01-16 16:46:25.878318: step 577, loss = 0.69432 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:46:26.862387 ops/training.py:65 2019-01-16 16:46:26.862284: step 578, loss = 0.71124 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:46:27.844119 ops/training.py:65 2019-01-16 16:46:27.844014: step 579, loss = 0.74007 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:46:28.828810 ops/training.py:65 2019-01-16 16:46:28.828684: step 580, loss = 0.69802 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:46:29.813708 ops/training.py:65 2019-01-16 16:46:29.813605: step 581, loss = 0.66122 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:46:30.796898 ops/training.py:65 2019-01-16 16:46:30.796811: step 582, loss = 0.69665 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:46:31.779889 ops/training.py:65 2019-01-16 16:46:31.779808: step 583, loss = 0.73838 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:46:32.761178 ops/training.py:65 2019-01-16 16:46:32.761107: step 584, loss = 0.69991 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:46:33.745254 ops/training.py:65 2019-01-16 16:46:33.745167: step 585, loss = 0.66265 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:46:34.730764 ops/training.py:65 2019-01-16 16:46:34.730655: step 586, loss = 0.66263 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 16:46:35.715016 ops/training.py:65 2019-01-16 16:46:35.714905: step 587, loss = 0.74257 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:46:36.696515 ops/training.py:65 2019-01-16 16:46:36.696418: step 588, loss = 0.71724 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:46:37.677994 ops/training.py:65 2019-01-16 16:46:37.677889: step 589, loss = 0.75630 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:46:38.660256 ops/training.py:65 2019-01-16 16:46:38.660157: step 590, loss = 0.72264 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:46:39.642300 ops/training.py:65 2019-01-16 16:46:39.642189: step 591, loss = 0.68974 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:46:40.623804 ops/training.py:65 2019-01-16 16:46:40.623711: step 592, loss = 0.72119 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:46:41.608040 ops/training.py:65 2019-01-16 16:46:41.607934: step 593, loss = 0.68653 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:46:42.592907 ops/training.py:65 2019-01-16 16:46:42.592803: step 594, loss = 0.73617 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:46:43.577831 ops/training.py:65 2019-01-16 16:46:43.577721: step 595, loss = 0.64826 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 16:46:44.564052 ops/training.py:65 2019-01-16 16:46:44.563944: step 596, loss = 0.67471 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:46:45.548496 ops/training.py:65 2019-01-16 16:46:45.548391: step 597, loss = 0.74304 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:46:46.530787 ops/training.py:65 2019-01-16 16:46:46.530689: step 598, loss = 0.67646 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:46:47.512526 ops/training.py:65 2019-01-16 16:46:47.512424: step 599, loss = 0.72580 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:46:48.494540 ops/training.py:65 2019-01-16 16:46:48.494429: step 600, loss = 0.64702 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:46:49.475350 ops/training.py:65 2019-01-16 16:46:49.475265: step 601, loss = 0.71587 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:46:50.456929 ops/training.py:65 2019-01-16 16:46:50.456827: step 602, loss = 0.68889 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:46:51.440291 ops/training.py:65 2019-01-16 16:46:51.440195: step 603, loss = 0.67597 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:46:52.422001 ops/training.py:65 2019-01-16 16:46:52.421900: step 604, loss = 0.73558 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:46:53.403806 ops/training.py:65 2019-01-16 16:46:53.403699: step 605, loss = 0.68872 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:46:54.384895 ops/training.py:65 2019-01-16 16:46:54.384801: step 606, loss = 0.77787 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:46:55.369075 ops/training.py:65 2019-01-16 16:46:55.368986: step 607, loss = 0.72740 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:46:56.352398 ops/training.py:65 2019-01-16 16:46:56.352292: step 608, loss = 0.73885 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:46:57.335596 ops/training.py:65 2019-01-16 16:46:57.335493: step 609, loss = 0.66286 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:46:58.318047 ops/training.py:65 2019-01-16 16:46:58.317957: step 610, loss = 0.73583 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:46:59.300196 ops/training.py:65 2019-01-16 16:46:59.300121: step 611, loss = 0.73493 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:47:00.283018 ops/training.py:65 2019-01-16 16:47:00.282938: step 612, loss = 0.66403 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:47:01.266806 ops/training.py:65 2019-01-16 16:47:01.266702: step 613, loss = 0.71449 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:47:02.249174 ops/training.py:65 2019-01-16 16:47:02.249084: step 614, loss = 0.68894 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:47:03.231473 ops/training.py:65 2019-01-16 16:47:03.231372: step 615, loss = 0.67847 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:47:04.214750 ops/training.py:65 2019-01-16 16:47:04.214646: step 616, loss = 0.70653 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:47:05.196917 ops/training.py:65 2019-01-16 16:47:05.196824: step 617, loss = 0.66640 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:47:06.178803 ops/training.py:65 2019-01-16 16:47:06.178699: step 618, loss = 0.67576 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:47:07.160975 ops/training.py:65 2019-01-16 16:47:07.160874: step 619, loss = 0.71519 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:47:08.142886 ops/training.py:65 2019-01-16 16:47:08.142778: step 620, loss = 0.68697 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:47:09.124084 ops/training.py:65 2019-01-16 16:47:09.123980: step 621, loss = 0.76821 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:47:10.107084 ops/training.py:65 2019-01-16 16:47:10.106994: step 622, loss = 0.70030 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:47:11.089833 ops/training.py:65 2019-01-16 16:47:11.089730: step 623, loss = 0.68189 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:47:12.072372 ops/training.py:65 2019-01-16 16:47:12.072270: step 624, loss = 0.70530 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:47:13.055312 ops/training.py:65 2019-01-16 16:47:13.055214: step 625, loss = 0.66011 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 16:47:14.038403 ops/training.py:65 2019-01-16 16:47:14.038290: step 626, loss = 0.73961 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:47:15.023573 ops/training.py:65 2019-01-16 16:47:15.023492: step 627, loss = 0.72487 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:47:16.007022 ops/training.py:65 2019-01-16 16:47:16.006916: step 628, loss = 0.69753 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:47:16.990303 ops/training.py:65 2019-01-16 16:47:16.990216: step 629, loss = 0.75794 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:47:17.973524 ops/training.py:65 2019-01-16 16:47:17.973439: step 630, loss = 0.68753 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:47:18.956837 ops/training.py:65 2019-01-16 16:47:18.956748: step 631, loss = 0.75099 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:47:19.940447 ops/training.py:65 2019-01-16 16:47:19.940347: step 632, loss = 0.72218 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:47:20.926977 ops/training.py:65 2019-01-16 16:47:20.926875: step 633, loss = 0.74478 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:47:21.911811 ops/training.py:65 2019-01-16 16:47:21.911705: step 634, loss = 0.68633 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:47:22.896136 ops/training.py:65 2019-01-16 16:47:22.896035: step 635, loss = 0.69955 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:47:23.878721 ops/training.py:65 2019-01-16 16:47:23.878633: step 636, loss = 0.74745 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:47:24.860566 ops/training.py:65 2019-01-16 16:47:24.860478: step 637, loss = 0.82127 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 16:47:25.844875 ops/training.py:65 2019-01-16 16:47:25.844776: step 638, loss = 0.66748 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:47:26.827910 ops/training.py:65 2019-01-16 16:47:26.827806: step 639, loss = 0.65865 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:47:27.810376 ops/training.py:65 2019-01-16 16:47:27.810284: step 640, loss = 0.69055 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:47:28.795032 ops/training.py:65 2019-01-16 16:47:28.794934: step 641, loss = 0.70497 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:47:29.779505 ops/training.py:65 2019-01-16 16:47:29.779406: step 642, loss = 0.75304 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:47:30.764287 ops/training.py:65 2019-01-16 16:47:30.764192: step 643, loss = 0.67972 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:47:31.749065 ops/training.py:65 2019-01-16 16:47:31.748959: step 644, loss = 0.70788 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:47:32.732999 ops/training.py:65 2019-01-16 16:47:32.732904: step 645, loss = 0.72570 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:47:33.715690 ops/training.py:65 2019-01-16 16:47:33.715593: step 646, loss = 0.72695 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:47:34.697915 ops/training.py:65 2019-01-16 16:47:34.697810: step 647, loss = 0.69554 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:47:35.679904 ops/training.py:65 2019-01-16 16:47:35.679814: step 648, loss = 0.73788 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:47:36.661875 ops/training.py:65 2019-01-16 16:47:36.661781: step 649, loss = 0.71298 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:47:37.643351 ops/training.py:65 2019-01-16 16:47:37.643261: step 650, loss = 0.68922 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:47:38.624332 ops/training.py:65 2019-01-16 16:47:38.624237: step 651, loss = 0.75198 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:47:39.606404 ops/training.py:65 2019-01-16 16:47:39.606302: step 652, loss = 0.73493 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:47:40.587887 ops/training.py:65 2019-01-16 16:47:40.587787: step 653, loss = 0.72865 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:47:41.573475 ops/training.py:65 2019-01-16 16:47:41.573372: step 654, loss = 0.74149 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:47:42.560917 ops/training.py:65 2019-01-16 16:47:42.560821: step 655, loss = 0.67916 (32.4 examples/sec; 0.986 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 16:47:43.546500 ops/training.py:65 2019-01-16 16:47:43.546392: step 656, loss = 0.69793 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:47:44.530614 ops/training.py:65 2019-01-16 16:47:44.530517: step 657, loss = 0.66436 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:47:45.513425 ops/training.py:65 2019-01-16 16:47:45.513320: step 658, loss = 0.64981 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 16:47:46.495001 ops/training.py:65 2019-01-16 16:47:46.494891: step 659, loss = 0.71035 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:47:47.476467 ops/training.py:65 2019-01-16 16:47:47.476377: step 660, loss = 0.66300 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:47:48.457579 ops/training.py:65 2019-01-16 16:47:48.457489: step 661, loss = 0.71566 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:47:49.439119 ops/training.py:65 2019-01-16 16:47:49.439025: step 662, loss = 0.70044 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:47:50.420882 ops/training.py:65 2019-01-16 16:47:50.420785: step 663, loss = 0.71276 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:47:51.402601 ops/training.py:65 2019-01-16 16:47:51.402504: step 664, loss = 0.64286 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:47:52.385378 ops/training.py:65 2019-01-16 16:47:52.385274: step 665, loss = 0.71762 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:47:53.367544 ops/training.py:65 2019-01-16 16:47:53.367446: step 666, loss = 0.64220 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:47:54.350135 ops/training.py:65 2019-01-16 16:47:54.350027: step 667, loss = 0.72624 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:47:55.331697 ops/training.py:65 2019-01-16 16:47:55.331589: step 668, loss = 0.71778 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:47:56.312871 ops/training.py:65 2019-01-16 16:47:56.312779: step 669, loss = 0.70404 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:47:57.295336 ops/training.py:65 2019-01-16 16:47:57.295250: step 670, loss = 0.69537 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:47:58.276258 ops/training.py:65 2019-01-16 16:47:58.276174: step 671, loss = 0.71365 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:47:59.257723 ops/training.py:65 2019-01-16 16:47:59.257652: step 672, loss = 0.70352 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:48:00.237477 ops/training.py:65 2019-01-16 16:48:00.237409: step 673, loss = 0.67456 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:48:01.218040 ops/training.py:65 2019-01-16 16:48:01.217974: step 674, loss = 0.68296 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:48:02.199620 ops/training.py:65 2019-01-16 16:48:02.199558: step 675, loss = 0.71816 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:48:03.179908 ops/training.py:65 2019-01-16 16:48:03.179839: step 676, loss = 0.69257 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:48:04.162023 ops/training.py:65 2019-01-16 16:48:04.161989: step 677, loss = 0.68294 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:48:05.144483 ops/training.py:65 2019-01-16 16:48:05.144413: step 678, loss = 0.71978 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:48:06.127388 ops/training.py:65 2019-01-16 16:48:06.127348: step 679, loss = 0.72606 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:48:07.110698 ops/training.py:65 2019-01-16 16:48:07.110627: step 680, loss = 0.65601 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:48:08.096595 ops/training.py:65 2019-01-16 16:48:08.096486: step 681, loss = 0.69654 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:48:09.082394 ops/training.py:65 2019-01-16 16:48:09.082287: step 682, loss = 0.72929 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:48:10.065835 ops/training.py:65 2019-01-16 16:48:10.065757: step 683, loss = 0.73204 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:48:11.048404 ops/training.py:65 2019-01-16 16:48:11.048335: step 684, loss = 0.68051 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:48:12.030242 ops/training.py:65 2019-01-16 16:48:12.030170: step 685, loss = 0.70059 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:48:13.011804 ops/training.py:65 2019-01-16 16:48:13.011737: step 686, loss = 0.61994 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.78125
I8192 2019-01-16 16:48:13.993450 ops/training.py:65 2019-01-16 16:48:13.993394: step 687, loss = 0.67852 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:48:14.975683 ops/training.py:65 2019-01-16 16:48:14.975650: step 688, loss = 0.72640 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:48:15.957903 ops/training.py:65 2019-01-16 16:48:15.957871: step 689, loss = 0.70235 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:48:16.944869 ops/training.py:65 2019-01-16 16:48:16.944836: step 690, loss = 0.72341 (32.4 examples/sec; 0.986 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:48:17.929359 ops/training.py:65 2019-01-16 16:48:17.929327: step 691, loss = 0.64879 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 16:48:18.915770 ops/training.py:65 2019-01-16 16:48:18.915734: step 692, loss = 0.67644 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:48:19.900611 ops/training.py:65 2019-01-16 16:48:19.900574: step 693, loss = 0.72583 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:48:20.882963 ops/training.py:65 2019-01-16 16:48:20.882930: step 694, loss = 0.69955 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:48:21.865701 ops/training.py:65 2019-01-16 16:48:21.865667: step 695, loss = 0.70826 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:48:22.846644 ops/training.py:65 2019-01-16 16:48:22.846608: step 696, loss = 0.68937 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:48:23.827538 ops/training.py:65 2019-01-16 16:48:23.827505: step 697, loss = 0.70278 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:48:24.810886 ops/training.py:65 2019-01-16 16:48:24.810852: step 698, loss = 0.69590 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:48:25.794413 ops/training.py:65 2019-01-16 16:48:25.794380: step 699, loss = 0.72265 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:48:26.776415 ops/training.py:65 2019-01-16 16:48:26.776312: step 700, loss = 0.75482 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:48:27.759493 ops/training.py:65 2019-01-16 16:48:27.759454: step 701, loss = 0.68528 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:48:28.743443 ops/training.py:65 2019-01-16 16:48:28.743370: step 702, loss = 0.65611 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 16:48:29.728335 ops/training.py:65 2019-01-16 16:48:29.728228: step 703, loss = 0.73754 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:48:30.711448 ops/training.py:65 2019-01-16 16:48:30.711410: step 704, loss = 0.72650 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:48:31.694247 ops/training.py:65 2019-01-16 16:48:31.694210: step 705, loss = 0.68709 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:48:32.675780 ops/training.py:65 2019-01-16 16:48:32.675745: step 706, loss = 0.68433 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:48:33.658163 ops/training.py:65 2019-01-16 16:48:33.658129: step 707, loss = 0.71587 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:48:34.640416 ops/training.py:65 2019-01-16 16:48:34.640383: step 708, loss = 0.71194 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:48:35.622550 ops/training.py:65 2019-01-16 16:48:35.622514: step 709, loss = 0.73004 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:48:36.603861 ops/training.py:65 2019-01-16 16:48:36.603826: step 710, loss = 0.70514 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:48:37.591130 ops/training.py:65 2019-01-16 16:48:37.591095: step 711, loss = 0.70829 (32.4 examples/sec; 0.986 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:48:38.575497 ops/training.py:65 2019-01-16 16:48:38.575462: step 712, loss = 0.70720 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:48:39.558968 ops/training.py:65 2019-01-16 16:48:39.558930: step 713, loss = 0.71276 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:48:40.541610 ops/training.py:65 2019-01-16 16:48:40.541576: step 714, loss = 0.71655 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:48:41.522085 ops/training.py:65 2019-01-16 16:48:41.522050: step 715, loss = 0.72201 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:48:42.506502 ops/training.py:65 2019-01-16 16:48:42.506467: step 716, loss = 0.67950 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:48:43.491117 ops/training.py:65 2019-01-16 16:48:43.491082: step 717, loss = 0.70460 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:48:44.478859 ops/training.py:65 2019-01-16 16:48:44.478825: step 718, loss = 0.69595 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:48:45.461096 ops/training.py:65 2019-01-16 16:48:45.461063: step 719, loss = 0.69496 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:48:46.445893 ops/training.py:65 2019-01-16 16:48:46.445859: step 720, loss = 0.69753 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:48:47.429078 ops/training.py:65 2019-01-16 16:48:47.429044: step 721, loss = 0.67526 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:48:48.412151 ops/training.py:65 2019-01-16 16:48:48.412116: step 722, loss = 0.70133 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:48:49.395919 ops/training.py:65 2019-01-16 16:48:49.395886: step 723, loss = 0.71298 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:48:50.380652 ops/training.py:65 2019-01-16 16:48:50.380617: step 724, loss = 0.67152 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:48:51.364971 ops/training.py:65 2019-01-16 16:48:51.364936: step 725, loss = 0.71251 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:48:52.352970 ops/training.py:65 2019-01-16 16:48:52.352872: step 726, loss = 0.68291 (32.4 examples/sec; 0.987 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:48:53.337835 ops/training.py:65 2019-01-16 16:48:53.337779: step 727, loss = 0.74445 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:48:54.321860 ops/training.py:65 2019-01-16 16:48:54.321820: step 728, loss = 0.74713 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 16:48:55.304506 ops/training.py:65 2019-01-16 16:48:55.304467: step 729, loss = 0.69642 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:48:56.287788 ops/training.py:65 2019-01-16 16:48:56.287751: step 730, loss = 0.71446 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:48:57.271238 ops/training.py:65 2019-01-16 16:48:57.271159: step 731, loss = 0.70841 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:48:58.256765 ops/training.py:65 2019-01-16 16:48:58.256691: step 732, loss = 0.70959 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:48:59.240169 ops/training.py:65 2019-01-16 16:48:59.240129: step 733, loss = 0.71441 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:49:00.224895 ops/training.py:65 2019-01-16 16:49:00.224860: step 734, loss = 0.66452 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:49:01.207629 ops/training.py:65 2019-01-16 16:49:01.207594: step 735, loss = 0.72041 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:49:02.192002 ops/training.py:65 2019-01-16 16:49:02.191967: step 736, loss = 0.70534 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:49:03.174734 ops/training.py:65 2019-01-16 16:49:03.174651: step 737, loss = 0.69077 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:49:04.157326 ops/training.py:65 2019-01-16 16:49:04.157208: step 738, loss = 0.71264 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:49:05.139355 ops/training.py:65 2019-01-16 16:49:05.139251: step 739, loss = 0.70236 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:49:06.120553 ops/training.py:65 2019-01-16 16:49:06.120516: step 740, loss = 0.73541 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:49:07.101874 ops/training.py:65 2019-01-16 16:49:07.101837: step 741, loss = 0.66767 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 16:49:08.082971 ops/training.py:65 2019-01-16 16:49:08.082935: step 742, loss = 0.68916 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:49:09.064680 ops/training.py:65 2019-01-16 16:49:09.064644: step 743, loss = 0.72506 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:49:10.045924 ops/training.py:65 2019-01-16 16:49:10.045887: step 744, loss = 0.70033 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:49:11.026996 ops/training.py:65 2019-01-16 16:49:11.026960: step 745, loss = 0.68310 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:49:12.008167 ops/training.py:65 2019-01-16 16:49:12.008126: step 746, loss = 0.68494 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 16:49:12.989706 ops/training.py:65 2019-01-16 16:49:12.989651: step 747, loss = 0.66530 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:49:13.970446 ops/training.py:65 2019-01-16 16:49:13.970407: step 748, loss = 0.71402 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:49:14.953207 ops/training.py:65 2019-01-16 16:49:14.953157: step 749, loss = 0.72577 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:49:15.938184 ops/training.py:65 2019-01-16 16:49:15.938146: step 750, loss = 0.71726 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:49:16.923157 ops/training.py:65 2019-01-16 16:49:16.923119: step 751, loss = 0.72214 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:49:17.907197 ops/training.py:65 2019-01-16 16:49:17.907159: step 752, loss = 0.68428 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:49:18.891607 ops/training.py:65 2019-01-16 16:49:18.891571: step 753, loss = 0.70657 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:49:19.873623 ops/training.py:65 2019-01-16 16:49:19.873587: step 754, loss = 0.67248 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:49:20.855391 ops/training.py:65 2019-01-16 16:49:20.855355: step 755, loss = 0.72338 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:49:21.837373 ops/training.py:65 2019-01-16 16:49:21.837336: step 756, loss = 0.70745 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:49:22.818476 ops/training.py:65 2019-01-16 16:49:22.818436: step 757, loss = 0.72144 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:49:23.800814 ops/training.py:65 2019-01-16 16:49:23.800775: step 758, loss = 0.70867 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:49:24.785758 ops/training.py:65 2019-01-16 16:49:24.785665: step 759, loss = 0.66479 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:49:25.770406 ops/training.py:65 2019-01-16 16:49:25.770334: step 760, loss = 0.67277 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:49:26.752889 ops/training.py:65 2019-01-16 16:49:26.752851: step 761, loss = 0.67885 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:49:27.736398 ops/training.py:65 2019-01-16 16:49:27.736290: step 762, loss = 0.67907 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:49:28.721253 ops/training.py:65 2019-01-16 16:49:28.721145: step 763, loss = 0.68362 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:49:29.707064 ops/training.py:65 2019-01-16 16:49:29.706956: step 764, loss = 0.71373 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:49:30.692326 ops/training.py:65 2019-01-16 16:49:30.692217: step 765, loss = 0.67910 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:49:31.678881 ops/training.py:65 2019-01-16 16:49:31.678772: step 766, loss = 0.69636 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:49:32.663393 ops/training.py:65 2019-01-16 16:49:32.663300: step 767, loss = 0.73611 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:49:33.647083 ops/training.py:65 2019-01-16 16:49:33.646983: step 768, loss = 0.71157 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:49:34.628964 ops/training.py:65 2019-01-16 16:49:34.628864: step 769, loss = 0.71483 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:49:35.612309 ops/training.py:65 2019-01-16 16:49:35.612201: step 770, loss = 0.72858 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:49:36.598132 ops/training.py:65 2019-01-16 16:49:36.598019: step 771, loss = 0.67021 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:49:37.583836 ops/training.py:65 2019-01-16 16:49:37.583733: step 772, loss = 0.70123 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:49:38.566112 ops/training.py:65 2019-01-16 16:49:38.566004: step 773, loss = 0.69588 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:49:39.547560 ops/training.py:65 2019-01-16 16:49:39.547454: step 774, loss = 0.67413 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:49:40.529003 ops/training.py:65 2019-01-16 16:49:40.528899: step 775, loss = 0.71393 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:49:41.511151 ops/training.py:65 2019-01-16 16:49:41.511052: step 776, loss = 0.68765 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:49:42.493130 ops/training.py:65 2019-01-16 16:49:42.493025: step 777, loss = 0.69264 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:49:43.475277 ops/training.py:65 2019-01-16 16:49:43.475173: step 778, loss = 0.68568 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:49:44.458664 ops/training.py:65 2019-01-16 16:49:44.458558: step 779, loss = 0.66786 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 16:49:45.443621 ops/training.py:65 2019-01-16 16:49:45.443531: step 780, loss = 0.69752 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:49:46.429514 ops/training.py:65 2019-01-16 16:49:46.429404: step 781, loss = 0.69144 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:49:47.413615 ops/training.py:65 2019-01-16 16:49:47.413518: step 782, loss = 0.71063 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:49:48.396859 ops/training.py:65 2019-01-16 16:49:48.396747: step 783, loss = 0.70818 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:49:49.380171 ops/training.py:65 2019-01-16 16:49:49.380094: step 784, loss = 0.70026 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:49:50.365092 ops/training.py:65 2019-01-16 16:49:50.364992: step 785, loss = 0.71196 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:49:51.348505 ops/training.py:65 2019-01-16 16:49:51.348390: step 786, loss = 0.70739 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:49:52.331848 ops/training.py:65 2019-01-16 16:49:52.331742: step 787, loss = 0.74390 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:49:53.313120 ops/training.py:65 2019-01-16 16:49:53.313028: step 788, loss = 0.69209 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:49:54.295420 ops/training.py:65 2019-01-16 16:49:54.295333: step 789, loss = 0.64671 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:49:55.276636 ops/training.py:65 2019-01-16 16:49:55.276537: step 790, loss = 0.68311 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:49:56.259601 ops/training.py:65 2019-01-16 16:49:56.259494: step 791, loss = 0.69914 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:49:57.241604 ops/training.py:65 2019-01-16 16:49:57.241497: step 792, loss = 0.69721 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:49:58.224694 ops/training.py:65 2019-01-16 16:49:58.224583: step 793, loss = 0.70348 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:49:59.208559 ops/training.py:65 2019-01-16 16:49:59.208460: step 794, loss = 0.71580 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:50:00.194449 ops/training.py:65 2019-01-16 16:50:00.194347: step 795, loss = 0.67577 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:50:01.179506 ops/training.py:65 2019-01-16 16:50:01.179408: step 796, loss = 0.68146 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:50:02.163322 ops/training.py:65 2019-01-16 16:50:02.163236: step 797, loss = 0.67721 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:50:03.146012 ops/training.py:65 2019-01-16 16:50:03.145909: step 798, loss = 0.71699 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:50:04.128430 ops/training.py:65 2019-01-16 16:50:04.128327: step 799, loss = 0.71928 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:50:05.110550 ops/training.py:65 2019-01-16 16:50:05.110444: step 800, loss = 0.71611 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:50:06.092574 ops/training.py:65 2019-01-16 16:50:06.092469: step 801, loss = 0.71164 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:50:07.074769 ops/training.py:65 2019-01-16 16:50:07.074660: step 802, loss = 0.71883 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:50:08.059415 ops/training.py:65 2019-01-16 16:50:08.059329: step 803, loss = 0.73282 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:50:09.042629 ops/training.py:65 2019-01-16 16:50:09.042564: step 804, loss = 0.71505 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:50:10.022638 ops/training.py:65 2019-01-16 16:50:10.022572: step 805, loss = 0.72410 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:50:11.005376 ops/training.py:65 2019-01-16 16:50:11.005310: step 806, loss = 0.70348 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:50:11.988905 ops/training.py:65 2019-01-16 16:50:11.988806: step 807, loss = 0.73283 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:50:12.972943 ops/training.py:65 2019-01-16 16:50:12.972833: step 808, loss = 0.66919 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:50:13.957123 ops/training.py:65 2019-01-16 16:50:13.957022: step 809, loss = 0.75020 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 16:50:14.942418 ops/training.py:65 2019-01-16 16:50:14.942304: step 810, loss = 0.69485 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:50:15.927324 ops/training.py:65 2019-01-16 16:50:15.927207: step 811, loss = 0.70794 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:50:16.913214 ops/training.py:65 2019-01-16 16:50:16.913106: step 812, loss = 0.70430 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:50:17.900637 ops/training.py:65 2019-01-16 16:50:17.900540: step 813, loss = 0.75094 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:50:18.885883 ops/training.py:65 2019-01-16 16:50:18.885782: step 814, loss = 0.67872 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:50:19.869369 ops/training.py:65 2019-01-16 16:50:19.869273: step 815, loss = 0.72106 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:50:20.855161 ops/training.py:65 2019-01-16 16:50:20.855059: step 816, loss = 0.71115 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:50:21.839751 ops/training.py:65 2019-01-16 16:50:21.839661: step 817, loss = 0.72942 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:50:22.822409 ops/training.py:65 2019-01-16 16:50:22.822304: step 818, loss = 0.67457 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:50:23.804684 ops/training.py:65 2019-01-16 16:50:23.804589: step 819, loss = 0.74440 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:50:24.788092 ops/training.py:65 2019-01-16 16:50:24.788015: step 820, loss = 0.71348 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:50:25.768991 ops/training.py:65 2019-01-16 16:50:25.768912: step 821, loss = 0.71072 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:50:26.749082 ops/training.py:65 2019-01-16 16:50:26.749004: step 822, loss = 0.71566 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:50:27.732598 ops/training.py:65 2019-01-16 16:50:27.732516: step 823, loss = 0.67547 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:50:28.717057 ops/training.py:65 2019-01-16 16:50:28.716952: step 824, loss = 0.65908 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:50:29.700759 ops/training.py:65 2019-01-16 16:50:29.700659: step 825, loss = 0.70703 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:50:30.683273 ops/training.py:65 2019-01-16 16:50:30.683169: step 826, loss = 0.72184 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:50:31.668778 ops/training.py:65 2019-01-16 16:50:31.668670: step 827, loss = 0.66028 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:50:32.652770 ops/training.py:65 2019-01-16 16:50:32.652672: step 828, loss = 0.65082 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:50:33.635510 ops/training.py:65 2019-01-16 16:50:33.635411: step 829, loss = 0.67553 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:50:34.618259 ops/training.py:65 2019-01-16 16:50:34.618168: step 830, loss = 0.67283 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:50:35.601327 ops/training.py:65 2019-01-16 16:50:35.601217: step 831, loss = 0.71816 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:50:36.586212 ops/training.py:65 2019-01-16 16:50:36.586125: step 832, loss = 0.69907 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:50:37.571510 ops/training.py:65 2019-01-16 16:50:37.571380: step 833, loss = 0.66106 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:50:38.554706 ops/training.py:65 2019-01-16 16:50:38.554609: step 834, loss = 0.70087 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:50:39.535832 ops/training.py:65 2019-01-16 16:50:39.535756: step 835, loss = 0.70714 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:50:40.517251 ops/training.py:65 2019-01-16 16:50:40.517182: step 836, loss = 0.67461 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:50:41.497006 ops/training.py:65 2019-01-16 16:50:41.496933: step 837, loss = 0.70748 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:50:42.480144 ops/training.py:65 2019-01-16 16:50:42.480081: step 838, loss = 0.71696 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:50:43.462324 ops/training.py:65 2019-01-16 16:50:43.462228: step 839, loss = 0.71624 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:50:44.447432 ops/training.py:65 2019-01-16 16:50:44.447331: step 840, loss = 0.65756 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 16:50:45.433859 ops/training.py:65 2019-01-16 16:50:45.433778: step 841, loss = 0.70226 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:50:46.418440 ops/training.py:65 2019-01-16 16:50:46.418330: step 842, loss = 0.72033 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:50:47.401327 ops/training.py:65 2019-01-16 16:50:47.401218: step 843, loss = 0.72046 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:50:48.385492 ops/training.py:65 2019-01-16 16:50:48.385385: step 844, loss = 0.69509 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:50:49.369056 ops/training.py:65 2019-01-16 16:50:49.368955: step 845, loss = 0.66264 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:50:50.352858 ops/training.py:65 2019-01-16 16:50:50.352748: step 846, loss = 0.70441 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:50:51.335457 ops/training.py:65 2019-01-16 16:50:51.335387: step 847, loss = 0.67755 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:50:52.318004 ops/training.py:65 2019-01-16 16:50:52.317928: step 848, loss = 0.72145 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:50:53.300945 ops/training.py:65 2019-01-16 16:50:53.300872: step 849, loss = 0.72836 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:50:54.282284 ops/training.py:65 2019-01-16 16:50:54.282215: step 850, loss = 0.74032 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:50:55.263635 ops/training.py:65 2019-01-16 16:50:55.263569: step 851, loss = 0.69737 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:50:56.246935 ops/training.py:65 2019-01-16 16:50:56.246861: step 852, loss = 0.71119 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:50:57.230025 ops/training.py:65 2019-01-16 16:50:57.229912: step 853, loss = 0.68996 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:50:58.211420 ops/training.py:65 2019-01-16 16:50:58.211308: step 854, loss = 0.72132 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:50:59.194157 ops/training.py:65 2019-01-16 16:50:59.194054: step 855, loss = 0.72911 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 16:51:00.179921 ops/training.py:65 2019-01-16 16:51:00.179822: step 856, loss = 0.68946 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:51:01.166131 ops/training.py:65 2019-01-16 16:51:01.166034: step 857, loss = 0.70180 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:51:02.148496 ops/training.py:65 2019-01-16 16:51:02.148394: step 858, loss = 0.69097 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:51:03.132076 ops/training.py:65 2019-01-16 16:51:03.131980: step 859, loss = 0.68669 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:51:04.114798 ops/training.py:65 2019-01-16 16:51:04.114686: step 860, loss = 0.71208 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:51:05.099493 ops/training.py:65 2019-01-16 16:51:05.099386: step 861, loss = 0.70118 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:51:06.083812 ops/training.py:65 2019-01-16 16:51:06.083711: step 862, loss = 0.69493 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:51:07.067742 ops/training.py:65 2019-01-16 16:51:07.067640: step 863, loss = 0.69612 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:51:08.053065 ops/training.py:65 2019-01-16 16:51:08.052966: step 864, loss = 0.68940 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:51:09.037215 ops/training.py:65 2019-01-16 16:51:09.037110: step 865, loss = 0.68318 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:51:10.020537 ops/training.py:65 2019-01-16 16:51:10.020441: step 866, loss = 0.68423 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:51:11.001489 ops/training.py:65 2019-01-16 16:51:11.001389: step 867, loss = 0.68088 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:51:11.985917 ops/training.py:65 2019-01-16 16:51:11.985812: step 868, loss = 0.69199 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:51:12.972521 ops/training.py:65 2019-01-16 16:51:12.972418: step 869, loss = 0.69650 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:51:13.955749 ops/training.py:65 2019-01-16 16:51:13.955652: step 870, loss = 0.75096 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.25
I8192 2019-01-16 16:51:14.939742 ops/training.py:65 2019-01-16 16:51:14.939648: step 871, loss = 0.69085 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:51:15.922234 ops/training.py:65 2019-01-16 16:51:15.922126: step 872, loss = 0.68598 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:51:16.906650 ops/training.py:65 2019-01-16 16:51:16.906542: step 873, loss = 0.71045 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:51:17.891788 ops/training.py:65 2019-01-16 16:51:17.891698: step 874, loss = 0.63293 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 16:51:18.876799 ops/training.py:65 2019-01-16 16:51:18.876695: step 875, loss = 0.70504 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:51:19.861434 ops/training.py:65 2019-01-16 16:51:19.861336: step 876, loss = 0.70365 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:51:20.844777 ops/training.py:65 2019-01-16 16:51:20.844673: step 877, loss = 0.71055 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:51:21.826949 ops/training.py:65 2019-01-16 16:51:21.826848: step 878, loss = 0.70383 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:51:22.808333 ops/training.py:65 2019-01-16 16:51:22.808235: step 879, loss = 0.71835 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:51:23.790971 ops/training.py:65 2019-01-16 16:51:23.790874: step 880, loss = 0.74255 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:51:24.775384 ops/training.py:65 2019-01-16 16:51:24.775302: step 881, loss = 0.68270 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:51:25.759310 ops/training.py:65 2019-01-16 16:51:25.759206: step 882, loss = 0.70542 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:51:26.742118 ops/training.py:65 2019-01-16 16:51:26.742043: step 883, loss = 0.70446 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:51:27.726900 ops/training.py:65 2019-01-16 16:51:27.726813: step 884, loss = 0.69936 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:51:28.711637 ops/training.py:65 2019-01-16 16:51:28.711531: step 885, loss = 0.69553 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:51:29.696232 ops/training.py:65 2019-01-16 16:51:29.696123: step 886, loss = 0.72186 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:51:30.680006 ops/training.py:65 2019-01-16 16:51:30.679893: step 887, loss = 0.70806 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:51:31.661998 ops/training.py:65 2019-01-16 16:51:31.661916: step 888, loss = 0.70698 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:51:32.644605 ops/training.py:65 2019-01-16 16:51:32.644529: step 889, loss = 0.70626 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:51:33.626821 ops/training.py:65 2019-01-16 16:51:33.626741: step 890, loss = 0.68459 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:51:34.608503 ops/training.py:65 2019-01-16 16:51:34.608427: step 891, loss = 0.72283 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:51:35.592430 ops/training.py:65 2019-01-16 16:51:35.592356: step 892, loss = 0.71810 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:51:36.578233 ops/training.py:65 2019-01-16 16:51:36.578135: step 893, loss = 0.71147 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:51:37.563426 ops/training.py:65 2019-01-16 16:51:37.563325: step 894, loss = 0.69400 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:51:38.548967 ops/training.py:65 2019-01-16 16:51:38.548900: step 895, loss = 0.68950 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:51:39.533406 ops/training.py:65 2019-01-16 16:51:39.533304: step 896, loss = 0.71604 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:51:40.519407 ops/training.py:65 2019-01-16 16:51:40.519300: step 897, loss = 0.71680 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:51:41.505199 ops/training.py:65 2019-01-16 16:51:41.505099: step 898, loss = 0.70153 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:51:42.489340 ops/training.py:65 2019-01-16 16:51:42.489254: step 899, loss = 0.68024 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:51:43.472169 ops/training.py:65 2019-01-16 16:51:43.472095: step 900, loss = 0.71239 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:51:44.455383 ops/training.py:65 2019-01-16 16:51:44.455307: step 901, loss = 0.69681 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:51:45.439365 ops/training.py:65 2019-01-16 16:51:45.439278: step 902, loss = 0.69290 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:51:46.423545 ops/training.py:65 2019-01-16 16:51:46.423441: step 903, loss = 0.68415 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:51:47.407454 ops/training.py:65 2019-01-16 16:51:47.407355: step 904, loss = 0.66655 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:51:48.392701 ops/training.py:65 2019-01-16 16:51:48.392637: step 905, loss = 0.69231 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:51:49.376144 ops/training.py:65 2019-01-16 16:51:49.376045: step 906, loss = 0.71557 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:51:50.360106 ops/training.py:65 2019-01-16 16:51:50.360009: step 907, loss = 0.72291 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:51:51.343596 ops/training.py:65 2019-01-16 16:51:51.343490: step 908, loss = 0.70485 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:51:52.330890 ops/training.py:65 2019-01-16 16:51:52.330782: step 909, loss = 0.70461 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:51:53.313811 ops/training.py:65 2019-01-16 16:51:53.313719: step 910, loss = 0.70029 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:51:54.300311 ops/training.py:65 2019-01-16 16:51:54.300226: step 911, loss = 0.72820 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:51:55.284374 ops/training.py:65 2019-01-16 16:51:55.284269: step 912, loss = 0.68106 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:51:56.267424 ops/training.py:65 2019-01-16 16:51:56.267324: step 913, loss = 0.72159 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:51:57.253215 ops/training.py:65 2019-01-16 16:51:57.253066: step 914, loss = 0.70735 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:51:58.238695 ops/training.py:65 2019-01-16 16:51:58.238582: step 915, loss = 0.69764 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:51:59.224626 ops/training.py:65 2019-01-16 16:51:59.224554: step 916, loss = 0.72221 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:52:00.208718 ops/training.py:65 2019-01-16 16:52:00.208610: step 917, loss = 0.66166 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:52:01.193968 ops/training.py:65 2019-01-16 16:52:01.193856: step 918, loss = 0.72631 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:52:02.177196 ops/training.py:65 2019-01-16 16:52:02.177115: step 919, loss = 0.73241 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:52:03.160354 ops/training.py:65 2019-01-16 16:52:03.160278: step 920, loss = 0.70598 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:52:04.145206 ops/training.py:65 2019-01-16 16:52:04.145120: step 921, loss = 0.71161 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:52:05.129477 ops/training.py:65 2019-01-16 16:52:05.129372: step 922, loss = 0.69926 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:52:06.112650 ops/training.py:65 2019-01-16 16:52:06.112548: step 923, loss = 0.74086 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:52:07.096126 ops/training.py:65 2019-01-16 16:52:07.096024: step 924, loss = 0.71952 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:52:08.081619 ops/training.py:65 2019-01-16 16:52:08.081519: step 925, loss = 0.70403 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:52:09.065009 ops/training.py:65 2019-01-16 16:52:09.064913: step 926, loss = 0.68903 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:52:10.048443 ops/training.py:65 2019-01-16 16:52:10.048339: step 927, loss = 0.68284 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:52:11.030691 ops/training.py:65 2019-01-16 16:52:11.030585: step 928, loss = 0.76090 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:52:12.013327 ops/training.py:65 2019-01-16 16:52:12.013231: step 929, loss = 0.68593 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:52:12.994059 ops/training.py:65 2019-01-16 16:52:12.993945: step 930, loss = 0.69445 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:52:13.976645 ops/training.py:65 2019-01-16 16:52:13.976549: step 931, loss = 0.73533 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:52:14.959912 ops/training.py:65 2019-01-16 16:52:14.959806: step 932, loss = 0.70699 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:52:15.943260 ops/training.py:65 2019-01-16 16:52:15.943154: step 933, loss = 0.67814 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:52:16.924916 ops/training.py:65 2019-01-16 16:52:16.924810: step 934, loss = 0.70751 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:52:17.907488 ops/training.py:65 2019-01-16 16:52:17.907395: step 935, loss = 0.69823 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:52:18.890216 ops/training.py:65 2019-01-16 16:52:18.890107: step 936, loss = 0.67686 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:52:19.875089 ops/training.py:65 2019-01-16 16:52:19.874994: step 937, loss = 0.70211 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:52:20.860437 ops/training.py:65 2019-01-16 16:52:20.860336: step 938, loss = 0.69111 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:52:21.845427 ops/training.py:65 2019-01-16 16:52:21.845323: step 939, loss = 0.71304 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:52:22.830668 ops/training.py:65 2019-01-16 16:52:22.830568: step 940, loss = 0.69888 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:52:23.815267 ops/training.py:65 2019-01-16 16:52:23.815166: step 941, loss = 0.70277 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:52:24.801142 ops/training.py:65 2019-01-16 16:52:24.801037: step 942, loss = 0.70582 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:52:25.786359 ops/training.py:65 2019-01-16 16:52:25.786260: step 943, loss = 0.66977 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:52:26.771479 ops/training.py:65 2019-01-16 16:52:26.771377: step 944, loss = 0.71258 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:52:27.756169 ops/training.py:65 2019-01-16 16:52:27.756078: step 945, loss = 0.67873 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:52:28.740204 ops/training.py:65 2019-01-16 16:52:28.740108: step 946, loss = 0.73042 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:52:29.725533 ops/training.py:65 2019-01-16 16:52:29.725443: step 947, loss = 0.69714 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:52:30.709161 ops/training.py:65 2019-01-16 16:52:30.709060: step 948, loss = 0.70378 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:52:31.691907 ops/training.py:65 2019-01-16 16:52:31.691800: step 949, loss = 0.71112 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:52:32.677328 ops/training.py:65 2019-01-16 16:52:32.677237: step 950, loss = 0.70311 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:52:33.663571 ops/training.py:65 2019-01-16 16:52:33.663466: step 951, loss = 0.70131 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:52:34.648551 ops/training.py:65 2019-01-16 16:52:34.648450: step 952, loss = 0.68017 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:52:35.633354 ops/training.py:65 2019-01-16 16:52:35.633251: step 953, loss = 0.65377 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:52:36.617053 ops/training.py:65 2019-01-16 16:52:36.616948: step 954, loss = 0.71754 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:52:37.601666 ops/training.py:65 2019-01-16 16:52:37.601558: step 955, loss = 0.71691 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:52:38.586799 ops/training.py:65 2019-01-16 16:52:38.586698: step 956, loss = 0.69317 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:52:39.572809 ops/training.py:65 2019-01-16 16:52:39.572701: step 957, loss = 0.74136 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:52:40.556781 ops/training.py:65 2019-01-16 16:52:40.556675: step 958, loss = 0.70917 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:52:41.538147 ops/training.py:65 2019-01-16 16:52:41.538046: step 959, loss = 0.73893 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:52:42.520030 ops/training.py:65 2019-01-16 16:52:42.519944: step 960, loss = 0.73303 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:52:43.504892 ops/training.py:65 2019-01-16 16:52:43.504800: step 961, loss = 0.71867 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:52:44.489355 ops/training.py:65 2019-01-16 16:52:44.489254: step 962, loss = 0.67199 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:52:45.474244 ops/training.py:65 2019-01-16 16:52:45.474145: step 963, loss = 0.70834 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:52:46.457108 ops/training.py:65 2019-01-16 16:52:46.457026: step 964, loss = 0.66592 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:52:47.438666 ops/training.py:65 2019-01-16 16:52:47.438592: step 965, loss = 0.71768 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:52:48.420767 ops/training.py:65 2019-01-16 16:52:48.420699: step 966, loss = 0.67765 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:52:49.404162 ops/training.py:65 2019-01-16 16:52:49.404087: step 967, loss = 0.68346 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:52:50.386407 ops/training.py:65 2019-01-16 16:52:50.386302: step 968, loss = 0.67643 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:52:51.373604 ops/training.py:65 2019-01-16 16:52:51.373497: step 969, loss = 0.61760 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.75
I8192 2019-01-16 16:52:52.360473 ops/training.py:65 2019-01-16 16:52:52.360360: step 970, loss = 0.73776 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:52:53.344601 ops/training.py:65 2019-01-16 16:52:53.344534: step 971, loss = 0.68575 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:52:54.325816 ops/training.py:65 2019-01-16 16:52:54.325716: step 972, loss = 0.67095 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:52:55.311555 ops/training.py:65 2019-01-16 16:52:55.311449: step 973, loss = 0.67509 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:52:56.295854 ops/training.py:65 2019-01-16 16:52:56.295761: step 974, loss = 0.69147 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:52:57.281096 ops/training.py:65 2019-01-16 16:52:57.280989: step 975, loss = 0.72521 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:52:58.265698 ops/training.py:65 2019-01-16 16:52:58.265614: step 976, loss = 0.75379 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:52:59.246836 ops/training.py:65 2019-01-16 16:52:59.246730: step 977, loss = 0.72489 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:53:00.229375 ops/training.py:65 2019-01-16 16:53:00.229270: step 978, loss = 0.73488 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:53:01.214405 ops/training.py:65 2019-01-16 16:53:01.214297: step 979, loss = 0.73799 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:53:02.200558 ops/training.py:65 2019-01-16 16:53:02.200452: step 980, loss = 0.74458 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:53:03.184046 ops/training.py:65 2019-01-16 16:53:03.183954: step 981, loss = 0.72943 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:53:04.168630 ops/training.py:65 2019-01-16 16:53:04.168524: step 982, loss = 0.71311 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:53:05.152043 ops/training.py:65 2019-01-16 16:53:05.151945: step 983, loss = 0.68968 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:53:06.137139 ops/training.py:65 2019-01-16 16:53:06.137032: step 984, loss = 0.69680 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:53:07.122294 ops/training.py:65 2019-01-16 16:53:07.122182: step 985, loss = 0.72844 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:53:08.106706 ops/training.py:65 2019-01-16 16:53:08.106563: step 986, loss = 0.78119 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 16:53:09.089238 ops/training.py:65 2019-01-16 16:53:09.089163: step 987, loss = 0.72442 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:53:10.070926 ops/training.py:65 2019-01-16 16:53:10.070855: step 988, loss = 0.72578 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:53:11.050846 ops/training.py:65 2019-01-16 16:53:11.050774: step 989, loss = 0.70129 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:53:12.032919 ops/training.py:65 2019-01-16 16:53:12.032820: step 990, loss = 0.73971 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:53:13.016705 ops/training.py:65 2019-01-16 16:53:13.016616: step 991, loss = 0.67051 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:53:13.998989 ops/training.py:65 2019-01-16 16:53:13.998915: step 992, loss = 0.69302 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:53:14.982237 ops/training.py:65 2019-01-16 16:53:14.982140: step 993, loss = 0.68767 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:53:15.964875 ops/training.py:65 2019-01-16 16:53:15.964796: step 994, loss = 0.70825 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:53:16.948263 ops/training.py:65 2019-01-16 16:53:16.948162: step 995, loss = 0.72904 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:53:17.930621 ops/training.py:65 2019-01-16 16:53:17.930527: step 996, loss = 0.70070 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:53:18.912109 ops/training.py:65 2019-01-16 16:53:18.912009: step 997, loss = 0.68775 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:53:19.894154 ops/training.py:65 2019-01-16 16:53:19.894053: step 998, loss = 0.71420 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:53:20.875408 ops/training.py:65 2019-01-16 16:53:20.875295: step 999, loss = 0.68304 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:53:21.857887 ops/training.py:65 2019-01-16 16:53:21.857777: step 1000, loss = 0.71411 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:53:22.839335 ops/training.py:65 2019-01-16 16:53:22.839217: step 1001, loss = 0.71204 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:53:23.824053 ops/training.py:65 2019-01-16 16:53:23.823950: step 1002, loss = 0.71984 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 16:53:24.809649 ops/training.py:65 2019-01-16 16:53:24.809541: step 1003, loss = 0.70264 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:53:25.795435 ops/training.py:65 2019-01-16 16:53:25.795336: step 1004, loss = 0.71449 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:53:26.780864 ops/training.py:65 2019-01-16 16:53:26.780795: step 1005, loss = 0.70704 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:53:27.767078 ops/training.py:65 2019-01-16 16:53:27.766975: step 1006, loss = 0.72448 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:53:28.752643 ops/training.py:65 2019-01-16 16:53:28.752540: step 1007, loss = 0.70526 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:53:29.736919 ops/training.py:65 2019-01-16 16:53:29.736817: step 1008, loss = 0.71989 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:53:30.723803 ops/training.py:65 2019-01-16 16:53:30.723690: step 1009, loss = 0.70472 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:53:31.708194 ops/training.py:65 2019-01-16 16:53:31.708090: step 1010, loss = 0.69395 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:53:32.691412 ops/training.py:65 2019-01-16 16:53:32.691319: step 1011, loss = 0.72440 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:53:33.673278 ops/training.py:65 2019-01-16 16:53:33.673173: step 1012, loss = 0.69913 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:53:34.654867 ops/training.py:65 2019-01-16 16:53:34.654768: step 1013, loss = 0.71562 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:53:35.639879 ops/training.py:65 2019-01-16 16:53:35.639772: step 1014, loss = 0.70581 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:53:36.624792 ops/training.py:65 2019-01-16 16:53:36.624689: step 1015, loss = 0.70488 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:53:37.609000 ops/training.py:65 2019-01-16 16:53:37.608896: step 1016, loss = 0.67264 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:53:38.594018 ops/training.py:65 2019-01-16 16:53:38.593931: step 1017, loss = 0.67457 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:53:39.578382 ops/training.py:65 2019-01-16 16:53:39.578266: step 1018, loss = 0.72872 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:53:40.562449 ops/training.py:65 2019-01-16 16:53:40.562340: step 1019, loss = 0.72672 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:53:41.547932 ops/training.py:65 2019-01-16 16:53:41.547828: step 1020, loss = 0.65895 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:53:42.532030 ops/training.py:65 2019-01-16 16:53:42.531928: step 1021, loss = 0.69376 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:53:43.517087 ops/training.py:65 2019-01-16 16:53:43.516981: step 1022, loss = 0.70800 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:53:44.501324 ops/training.py:65 2019-01-16 16:53:44.501216: step 1023, loss = 0.72336 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:53:45.482889 ops/training.py:65 2019-01-16 16:53:45.482797: step 1024, loss = 0.70566 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:53:46.465633 ops/training.py:65 2019-01-16 16:53:46.465533: step 1025, loss = 0.68552 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:53:47.450912 ops/training.py:65 2019-01-16 16:53:47.450815: step 1026, loss = 0.70833 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:53:48.438208 ops/training.py:65 2019-01-16 16:53:48.438120: step 1027, loss = 0.71522 (32.4 examples/sec; 0.986 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:53:49.422651 ops/training.py:65 2019-01-16 16:53:49.422548: step 1028, loss = 0.77009 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 16:53:50.408003 ops/training.py:65 2019-01-16 16:53:50.407900: step 1029, loss = 0.68658 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:53:51.393672 ops/training.py:65 2019-01-16 16:53:51.393561: step 1030, loss = 0.74034 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:53:52.378393 ops/training.py:65 2019-01-16 16:53:52.378292: step 1031, loss = 0.69575 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:53:53.360543 ops/training.py:65 2019-01-16 16:53:53.360442: step 1032, loss = 0.68555 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:53:54.343464 ops/training.py:65 2019-01-16 16:53:54.343364: step 1033, loss = 0.73183 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:53:55.325372 ops/training.py:65 2019-01-16 16:53:55.325274: step 1034, loss = 0.74036 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:53:56.306347 ops/training.py:65 2019-01-16 16:53:56.306244: step 1035, loss = 0.73380 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:53:57.288550 ops/training.py:65 2019-01-16 16:53:57.288456: step 1036, loss = 0.69568 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:53:58.275443 ops/training.py:65 2019-01-16 16:53:58.275333: step 1037, loss = 0.71125 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:53:59.258688 ops/training.py:65 2019-01-16 16:53:59.258586: step 1038, loss = 0.69686 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:54:00.241821 ops/training.py:65 2019-01-16 16:54:00.241715: step 1039, loss = 0.74467 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:54:01.225812 ops/training.py:65 2019-01-16 16:54:01.225710: step 1040, loss = 0.66354 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:54:02.210605 ops/training.py:65 2019-01-16 16:54:02.210496: step 1041, loss = 0.68441 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:54:03.196213 ops/training.py:65 2019-01-16 16:54:03.196118: step 1042, loss = 0.70496 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:54:04.183161 ops/training.py:65 2019-01-16 16:54:04.183053: step 1043, loss = 0.74556 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:54:05.168531 ops/training.py:65 2019-01-16 16:54:05.168427: step 1044, loss = 0.71269 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:54:06.154845 ops/training.py:65 2019-01-16 16:54:06.154742: step 1045, loss = 0.72799 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:54:07.140067 ops/training.py:65 2019-01-16 16:54:07.139976: step 1046, loss = 0.66121 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:54:08.123982 ops/training.py:65 2019-01-16 16:54:08.123884: step 1047, loss = 0.69718 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:54:09.105412 ops/training.py:65 2019-01-16 16:54:09.105308: step 1048, loss = 0.69914 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:54:10.092469 ops/training.py:65 2019-01-16 16:54:10.092358: step 1049, loss = 0.72162 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:54:11.076957 ops/training.py:65 2019-01-16 16:54:11.076848: step 1050, loss = 0.70558 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:54:12.060892 ops/training.py:65 2019-01-16 16:54:12.060790: step 1051, loss = 0.65405 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 16:54:13.045823 ops/training.py:65 2019-01-16 16:54:13.045722: step 1052, loss = 0.70845 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:54:14.029446 ops/training.py:65 2019-01-16 16:54:14.029339: step 1053, loss = 0.67779 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:54:15.014090 ops/training.py:65 2019-01-16 16:54:15.014005: step 1054, loss = 0.70617 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:54:15.998523 ops/training.py:65 2019-01-16 16:54:15.998418: step 1055, loss = 0.73817 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:54:16.982346 ops/training.py:65 2019-01-16 16:54:16.982249: step 1056, loss = 0.68487 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:54:17.967255 ops/training.py:65 2019-01-16 16:54:17.967160: step 1057, loss = 0.74118 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:54:18.952814 ops/training.py:65 2019-01-16 16:54:18.952744: step 1058, loss = 0.72472 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:54:19.937578 ops/training.py:65 2019-01-16 16:54:19.937471: step 1059, loss = 0.73658 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:54:20.922101 ops/training.py:65 2019-01-16 16:54:20.922006: step 1060, loss = 0.70451 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:54:21.904649 ops/training.py:65 2019-01-16 16:54:21.904546: step 1061, loss = 0.73152 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:54:22.886197 ops/training.py:65 2019-01-16 16:54:22.886130: step 1062, loss = 0.71417 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:54:23.868219 ops/training.py:65 2019-01-16 16:54:23.868147: step 1063, loss = 0.67735 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:54:24.851316 ops/training.py:65 2019-01-16 16:54:24.851208: step 1064, loss = 0.72126 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:54:25.835674 ops/training.py:65 2019-01-16 16:54:25.835566: step 1065, loss = 0.70922 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:54:26.820040 ops/training.py:65 2019-01-16 16:54:26.819926: step 1066, loss = 0.66805 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:54:27.804533 ops/training.py:65 2019-01-16 16:54:27.804430: step 1067, loss = 0.70796 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:54:28.787832 ops/training.py:65 2019-01-16 16:54:28.787725: step 1068, loss = 0.69690 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:54:29.771447 ops/training.py:65 2019-01-16 16:54:29.771373: step 1069, loss = 0.70541 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:54:30.753643 ops/training.py:65 2019-01-16 16:54:30.753569: step 1070, loss = 0.72720 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:54:31.735272 ops/training.py:65 2019-01-16 16:54:31.735198: step 1071, loss = 0.68905 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:54:32.719030 ops/training.py:65 2019-01-16 16:54:32.718971: step 1072, loss = 0.70443 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:54:33.704230 ops/training.py:65 2019-01-16 16:54:33.704134: step 1073, loss = 0.73005 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:54:34.689491 ops/training.py:65 2019-01-16 16:54:34.689385: step 1074, loss = 0.71780 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:54:35.672415 ops/training.py:65 2019-01-16 16:54:35.672302: step 1075, loss = 0.68984 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:54:36.657600 ops/training.py:65 2019-01-16 16:54:36.657495: step 1076, loss = 0.65958 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:54:37.645491 ops/training.py:65 2019-01-16 16:54:37.645385: step 1077, loss = 0.65289 (32.4 examples/sec; 0.987 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:54:38.631562 ops/training.py:65 2019-01-16 16:54:38.631453: step 1078, loss = 0.71907 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:54:39.617777 ops/training.py:65 2019-01-16 16:54:39.617667: step 1079, loss = 0.69270 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:54:40.605306 ops/training.py:65 2019-01-16 16:54:40.605212: step 1080, loss = 0.70443 (32.4 examples/sec; 0.986 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:54:41.589840 ops/training.py:65 2019-01-16 16:54:41.589741: step 1081, loss = 0.70091 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:54:42.574982 ops/training.py:65 2019-01-16 16:54:42.574881: step 1082, loss = 0.68539 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:54:43.558680 ops/training.py:65 2019-01-16 16:54:43.558583: step 1083, loss = 0.71025 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:54:44.543085 ops/training.py:65 2019-01-16 16:54:44.542998: step 1084, loss = 0.73722 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 16:54:45.525856 ops/training.py:65 2019-01-16 16:54:45.525780: step 1085, loss = 0.70447 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:54:46.507369 ops/training.py:65 2019-01-16 16:54:46.507295: step 1086, loss = 0.70269 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:54:47.491537 ops/training.py:65 2019-01-16 16:54:47.491456: step 1087, loss = 0.70792 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:54:48.475082 ops/training.py:65 2019-01-16 16:54:48.474990: step 1088, loss = 0.69985 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:54:49.459387 ops/training.py:65 2019-01-16 16:54:49.459285: step 1089, loss = 0.70038 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:54:50.444214 ops/training.py:65 2019-01-16 16:54:50.444116: step 1090, loss = 0.70328 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:54:51.428621 ops/training.py:65 2019-01-16 16:54:51.428519: step 1091, loss = 0.66176 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:54:52.410878 ops/training.py:65 2019-01-16 16:54:52.410802: step 1092, loss = 0.70348 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:54:53.394250 ops/training.py:65 2019-01-16 16:54:53.394160: step 1093, loss = 0.69370 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:54:54.380625 ops/training.py:65 2019-01-16 16:54:54.380517: step 1094, loss = 0.68609 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:54:55.365329 ops/training.py:65 2019-01-16 16:54:55.365227: step 1095, loss = 0.72649 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:54:56.350795 ops/training.py:65 2019-01-16 16:54:56.350684: step 1096, loss = 0.69014 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:54:57.337609 ops/training.py:65 2019-01-16 16:54:57.337506: step 1097, loss = 0.72280 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:54:58.322360 ops/training.py:65 2019-01-16 16:54:58.322299: step 1098, loss = 0.70390 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:54:59.307445 ops/training.py:65 2019-01-16 16:54:59.307336: step 1099, loss = 0.70132 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:55:00.293714 ops/training.py:65 2019-01-16 16:55:00.293609: step 1100, loss = 0.66162 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:55:01.280006 ops/training.py:65 2019-01-16 16:55:01.279894: step 1101, loss = 0.69897 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:55:02.264080 ops/training.py:65 2019-01-16 16:55:02.263985: step 1102, loss = 0.67277 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:55:03.248070 ops/training.py:65 2019-01-16 16:55:03.247993: step 1103, loss = 0.68380 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:55:04.231675 ops/training.py:65 2019-01-16 16:55:04.231609: step 1104, loss = 0.70499 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:55:05.216060 ops/training.py:65 2019-01-16 16:55:05.215957: step 1105, loss = 0.70082 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:55:06.202033 ops/training.py:65 2019-01-16 16:55:06.201931: step 1106, loss = 0.69775 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:55:07.188504 ops/training.py:65 2019-01-16 16:55:07.188395: step 1107, loss = 0.68120 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 16:55:08.171942 ops/training.py:65 2019-01-16 16:55:08.171862: step 1108, loss = 0.70752 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:55:09.154649 ops/training.py:65 2019-01-16 16:55:09.154583: step 1109, loss = 0.69852 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:55:10.137126 ops/training.py:65 2019-01-16 16:55:10.137025: step 1110, loss = 0.73465 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:55:11.119554 ops/training.py:65 2019-01-16 16:55:11.119449: step 1111, loss = 0.70341 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:55:12.103860 ops/training.py:65 2019-01-16 16:55:12.103756: step 1112, loss = 0.65480 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:55:13.087957 ops/training.py:65 2019-01-16 16:55:13.087858: step 1113, loss = 0.70574 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:55:14.073261 ops/training.py:65 2019-01-16 16:55:14.073156: step 1114, loss = 0.69226 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:55:15.057201 ops/training.py:65 2019-01-16 16:55:15.057097: step 1115, loss = 0.67293 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:55:16.043590 ops/training.py:65 2019-01-16 16:55:16.043491: step 1116, loss = 0.69354 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:55:17.028937 ops/training.py:65 2019-01-16 16:55:17.028837: step 1117, loss = 0.68546 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:55:18.014093 ops/training.py:65 2019-01-16 16:55:18.014000: step 1118, loss = 0.73927 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 16:55:18.998248 ops/training.py:65 2019-01-16 16:55:18.998143: step 1119, loss = 0.72184 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:55:19.980453 ops/training.py:65 2019-01-16 16:55:19.980346: step 1120, loss = 0.69150 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:55:20.962765 ops/training.py:65 2019-01-16 16:55:20.962661: step 1121, loss = 0.74070 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:55:21.943696 ops/training.py:65 2019-01-16 16:55:21.943595: step 1122, loss = 0.70828 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:55:22.924709 ops/training.py:65 2019-01-16 16:55:22.924606: step 1123, loss = 0.70977 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:55:23.906486 ops/training.py:65 2019-01-16 16:55:23.906381: step 1124, loss = 0.69858 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:55:24.887421 ops/training.py:65 2019-01-16 16:55:24.887321: step 1125, loss = 0.70466 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:55:25.869696 ops/training.py:65 2019-01-16 16:55:25.869596: step 1126, loss = 0.71780 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:55:26.853885 ops/training.py:65 2019-01-16 16:55:26.853781: step 1127, loss = 0.70662 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:55:27.839003 ops/training.py:65 2019-01-16 16:55:27.838896: step 1128, loss = 0.71221 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:55:28.824200 ops/training.py:65 2019-01-16 16:55:28.824105: step 1129, loss = 0.70180 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:55:29.806293 ops/training.py:65 2019-01-16 16:55:29.806197: step 1130, loss = 0.68081 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:55:30.791708 ops/training.py:65 2019-01-16 16:55:30.791614: step 1131, loss = 0.69717 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:55:31.776258 ops/training.py:65 2019-01-16 16:55:31.776154: step 1132, loss = 0.67673 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:55:32.758938 ops/training.py:65 2019-01-16 16:55:32.758835: step 1133, loss = 0.69105 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:55:33.741693 ops/training.py:65 2019-01-16 16:55:33.741598: step 1134, loss = 0.68283 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:55:34.722971 ops/training.py:65 2019-01-16 16:55:34.722876: step 1135, loss = 0.69001 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:55:35.704888 ops/training.py:65 2019-01-16 16:55:35.704779: step 1136, loss = 0.67358 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:55:36.689494 ops/training.py:65 2019-01-16 16:55:36.689386: step 1137, loss = 0.69028 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:55:37.674821 ops/training.py:65 2019-01-16 16:55:37.674714: step 1138, loss = 0.70098 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:55:38.660254 ops/training.py:65 2019-01-16 16:55:38.660149: step 1139, loss = 0.69390 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:55:39.644607 ops/training.py:65 2019-01-16 16:55:39.644501: step 1140, loss = 0.68553 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:55:40.631575 ops/training.py:65 2019-01-16 16:55:40.631475: step 1141, loss = 0.69504 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:55:41.615344 ops/training.py:65 2019-01-16 16:55:41.615236: step 1142, loss = 0.66980 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:55:42.598833 ops/training.py:65 2019-01-16 16:55:42.598729: step 1143, loss = 0.69924 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:55:43.581248 ops/training.py:65 2019-01-16 16:55:43.581153: step 1144, loss = 0.68448 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:55:44.566184 ops/training.py:65 2019-01-16 16:55:44.566091: step 1145, loss = 0.68413 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:55:45.549064 ops/training.py:65 2019-01-16 16:55:45.548962: step 1146, loss = 0.69601 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:55:46.531411 ops/training.py:65 2019-01-16 16:55:46.531309: step 1147, loss = 0.68024 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:55:47.517023 ops/training.py:65 2019-01-16 16:55:47.516916: step 1148, loss = 0.71328 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:55:48.501624 ops/training.py:65 2019-01-16 16:55:48.501523: step 1149, loss = 0.67977 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:55:49.486076 ops/training.py:65 2019-01-16 16:55:49.485972: step 1150, loss = 0.70885 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:55:50.472192 ops/training.py:65 2019-01-16 16:55:50.472086: step 1151, loss = 0.71393 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:55:51.459117 ops/training.py:65 2019-01-16 16:55:51.459015: step 1152, loss = 0.71370 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:55:52.445067 ops/training.py:65 2019-01-16 16:55:52.444963: step 1153, loss = 0.67096 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 16:55:53.431189 ops/training.py:65 2019-01-16 16:55:53.431088: step 1154, loss = 0.69172 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:55:54.416986 ops/training.py:65 2019-01-16 16:55:54.416878: step 1155, loss = 0.65752 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:55:55.402665 ops/training.py:65 2019-01-16 16:55:55.402559: step 1156, loss = 0.66724 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:55:56.387585 ops/training.py:65 2019-01-16 16:55:56.387483: step 1157, loss = 0.69390 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:55:57.372663 ops/training.py:65 2019-01-16 16:55:57.372573: step 1158, loss = 0.71078 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:55:58.356242 ops/training.py:65 2019-01-16 16:55:58.356136: step 1159, loss = 0.69162 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:55:59.339417 ops/training.py:65 2019-01-16 16:55:59.339316: step 1160, loss = 0.70478 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:56:00.320716 ops/training.py:65 2019-01-16 16:56:00.320615: step 1161, loss = 0.69885 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:56:01.302230 ops/training.py:65 2019-01-16 16:56:01.302125: step 1162, loss = 0.71468 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:56:02.284277 ops/training.py:65 2019-01-16 16:56:02.284167: step 1163, loss = 0.72876 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 16:56:03.266084 ops/training.py:65 2019-01-16 16:56:03.265991: step 1164, loss = 0.68042 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:56:04.247133 ops/training.py:65 2019-01-16 16:56:04.247024: step 1165, loss = 0.70711 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:56:05.232134 ops/training.py:65 2019-01-16 16:56:05.232025: step 1166, loss = 0.69505 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:56:06.216467 ops/training.py:65 2019-01-16 16:56:06.216365: step 1167, loss = 0.68351 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:56:07.200931 ops/training.py:65 2019-01-16 16:56:07.200836: step 1168, loss = 0.70352 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:56:08.184097 ops/training.py:65 2019-01-16 16:56:08.184019: step 1169, loss = 0.70982 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:56:09.168970 ops/training.py:65 2019-01-16 16:56:09.168866: step 1170, loss = 0.70244 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:56:10.154580 ops/training.py:65 2019-01-16 16:56:10.154481: step 1171, loss = 0.68293 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:56:11.139411 ops/training.py:65 2019-01-16 16:56:11.139306: step 1172, loss = 0.67612 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:56:12.124270 ops/training.py:65 2019-01-16 16:56:12.124165: step 1173, loss = 0.67567 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:56:13.109211 ops/training.py:65 2019-01-16 16:56:13.109120: step 1174, loss = 0.67220 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:56:14.097952 ops/training.py:65 2019-01-16 16:56:14.097840: step 1175, loss = 0.69963 (32.4 examples/sec; 0.988 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:56:15.082183 ops/training.py:65 2019-01-16 16:56:15.082077: step 1176, loss = 0.74388 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:56:16.066055 ops/training.py:65 2019-01-16 16:56:16.065943: step 1177, loss = 0.67582 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:56:17.047807 ops/training.py:65 2019-01-16 16:56:17.047703: step 1178, loss = 0.69958 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:56:18.029461 ops/training.py:65 2019-01-16 16:56:18.029368: step 1179, loss = 0.69863 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:56:19.010717 ops/training.py:65 2019-01-16 16:56:19.010608: step 1180, loss = 0.69456 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:56:19.993316 ops/training.py:65 2019-01-16 16:56:19.993223: step 1181, loss = 0.70813 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:56:20.975491 ops/training.py:65 2019-01-16 16:56:20.975383: step 1182, loss = 0.68270 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:56:21.958752 ops/training.py:65 2019-01-16 16:56:21.958645: step 1183, loss = 0.71209 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:56:22.942107 ops/training.py:65 2019-01-16 16:56:22.942000: step 1184, loss = 0.70877 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:56:23.927881 ops/training.py:65 2019-01-16 16:56:23.927780: step 1185, loss = 0.69304 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:56:24.913521 ops/training.py:65 2019-01-16 16:56:24.913414: step 1186, loss = 0.68688 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:56:25.900109 ops/training.py:65 2019-01-16 16:56:25.900003: step 1187, loss = 0.68185 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:56:26.885688 ops/training.py:65 2019-01-16 16:56:26.885597: step 1188, loss = 0.69399 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:56:27.870546 ops/training.py:65 2019-01-16 16:56:27.870449: step 1189, loss = 0.69819 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:56:28.854809 ops/training.py:65 2019-01-16 16:56:28.854695: step 1190, loss = 0.74467 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 16:56:29.840144 ops/training.py:65 2019-01-16 16:56:29.840052: step 1191, loss = 0.71673 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:56:30.823251 ops/training.py:65 2019-01-16 16:56:30.823144: step 1192, loss = 0.69446 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:56:31.805538 ops/training.py:65 2019-01-16 16:56:31.805429: step 1193, loss = 0.71561 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:56:32.791034 ops/training.py:65 2019-01-16 16:56:32.790926: step 1194, loss = 0.71181 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:56:33.778938 ops/training.py:65 2019-01-16 16:56:33.778840: step 1195, loss = 0.70143 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:56:34.764383 ops/training.py:65 2019-01-16 16:56:34.764277: step 1196, loss = 0.70345 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:56:35.748041 ops/training.py:65 2019-01-16 16:56:35.747930: step 1197, loss = 0.71529 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:56:36.731482 ops/training.py:65 2019-01-16 16:56:36.731375: step 1198, loss = 0.68998 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:56:37.713978 ops/training.py:65 2019-01-16 16:56:37.713874: step 1199, loss = 0.68274 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:56:38.699306 ops/training.py:65 2019-01-16 16:56:38.699202: step 1200, loss = 0.69281 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:56:39.685999 ops/training.py:65 2019-01-16 16:56:39.685890: step 1201, loss = 0.68454 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:56:40.671037 ops/training.py:65 2019-01-16 16:56:40.670929: step 1202, loss = 0.71062 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:56:41.655458 ops/training.py:65 2019-01-16 16:56:41.655359: step 1203, loss = 0.68613 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:56:42.640081 ops/training.py:65 2019-01-16 16:56:42.639966: step 1204, loss = 0.69511 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:56:43.625367 ops/training.py:65 2019-01-16 16:56:43.625294: step 1205, loss = 0.69224 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:56:44.609700 ops/training.py:65 2019-01-16 16:56:44.609606: step 1206, loss = 0.70394 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:56:45.592846 ops/training.py:65 2019-01-16 16:56:45.592750: step 1207, loss = 0.70076 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:56:46.579816 ops/training.py:65 2019-01-16 16:56:46.579718: step 1208, loss = 0.71194 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:56:47.564162 ops/training.py:65 2019-01-16 16:56:47.564062: step 1209, loss = 0.70914 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:56:48.546610 ops/training.py:65 2019-01-16 16:56:48.546511: step 1210, loss = 0.70499 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:56:49.529341 ops/training.py:65 2019-01-16 16:56:49.529231: step 1211, loss = 0.72669 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.25
I8192 2019-01-16 16:56:50.510696 ops/training.py:65 2019-01-16 16:56:50.510594: step 1212, loss = 0.71498 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:56:51.492958 ops/training.py:65 2019-01-16 16:56:51.492846: step 1213, loss = 0.69129 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:56:52.479013 ops/training.py:65 2019-01-16 16:56:52.478904: step 1214, loss = 0.69819 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:56:53.466661 ops/training.py:65 2019-01-16 16:56:53.466541: step 1215, loss = 0.69906 (32.4 examples/sec; 0.986 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:56:54.452953 ops/training.py:65 2019-01-16 16:56:54.452841: step 1216, loss = 0.71896 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:56:55.438278 ops/training.py:65 2019-01-16 16:56:55.438172: step 1217, loss = 0.70017 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:56:56.422791 ops/training.py:65 2019-01-16 16:56:56.422689: step 1218, loss = 0.70384 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:56:57.406037 ops/training.py:65 2019-01-16 16:56:57.405944: step 1219, loss = 0.70755 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:56:58.389242 ops/training.py:65 2019-01-16 16:56:58.389133: step 1220, loss = 0.71500 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:56:59.374702 ops/training.py:65 2019-01-16 16:56:59.374604: step 1221, loss = 0.70251 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:57:00.359208 ops/training.py:65 2019-01-16 16:57:00.359096: step 1222, loss = 0.67399 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:57:01.345315 ops/training.py:65 2019-01-16 16:57:01.345203: step 1223, loss = 0.69768 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:57:02.331260 ops/training.py:65 2019-01-16 16:57:02.331158: step 1224, loss = 0.68892 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:57:03.317404 ops/training.py:65 2019-01-16 16:57:03.317305: step 1225, loss = 0.71616 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:57:04.302439 ops/training.py:65 2019-01-16 16:57:04.302339: step 1226, loss = 0.71692 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:57:05.286247 ops/training.py:65 2019-01-16 16:57:05.286140: step 1227, loss = 0.71541 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:57:06.269308 ops/training.py:65 2019-01-16 16:57:06.269198: step 1228, loss = 0.69042 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:57:07.254866 ops/training.py:65 2019-01-16 16:57:07.254760: step 1229, loss = 0.68839 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:57:08.240191 ops/training.py:65 2019-01-16 16:57:08.240083: step 1230, loss = 0.67965 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:57:09.225647 ops/training.py:65 2019-01-16 16:57:09.225550: step 1231, loss = 0.68605 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:57:10.209901 ops/training.py:65 2019-01-16 16:57:10.209795: step 1232, loss = 0.74108 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 16:57:11.195506 ops/training.py:65 2019-01-16 16:57:11.195399: step 1233, loss = 0.67675 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:57:12.180741 ops/training.py:65 2019-01-16 16:57:12.180642: step 1234, loss = 0.67915 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:57:13.166741 ops/training.py:65 2019-01-16 16:57:13.166648: step 1235, loss = 0.68492 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:57:14.150527 ops/training.py:65 2019-01-16 16:57:14.150432: step 1236, loss = 0.69163 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:57:15.132929 ops/training.py:65 2019-01-16 16:57:15.132825: step 1237, loss = 0.72090 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:57:16.114506 ops/training.py:65 2019-01-16 16:57:16.114411: step 1238, loss = 0.69526 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:57:17.097004 ops/training.py:65 2019-01-16 16:57:17.096907: step 1239, loss = 0.68016 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:57:18.079485 ops/training.py:65 2019-01-16 16:57:18.079393: step 1240, loss = 0.69502 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:57:19.062551 ops/training.py:65 2019-01-16 16:57:19.062446: step 1241, loss = 0.70361 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:57:20.045343 ops/training.py:65 2019-01-16 16:57:20.045246: step 1242, loss = 0.67263 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:57:21.031988 ops/training.py:65 2019-01-16 16:57:21.031882: step 1243, loss = 0.74448 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:57:22.017413 ops/training.py:65 2019-01-16 16:57:22.017306: step 1244, loss = 0.70900 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:57:23.001624 ops/training.py:65 2019-01-16 16:57:23.001530: step 1245, loss = 0.69846 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:57:23.985451 ops/training.py:65 2019-01-16 16:57:23.985351: step 1246, loss = 0.70506 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:57:24.968143 ops/training.py:65 2019-01-16 16:57:24.968037: step 1247, loss = 0.69692 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:57:25.950096 ops/training.py:65 2019-01-16 16:57:25.949992: step 1248, loss = 0.67848 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:57:26.934938 ops/training.py:65 2019-01-16 16:57:26.934837: step 1249, loss = 0.72312 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:57:27.919754 ops/training.py:65 2019-01-16 16:57:27.919650: step 1250, loss = 0.68799 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:57:28.904393 ops/training.py:65 2019-01-16 16:57:28.904286: step 1251, loss = 0.69975 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:57:29.889431 ops/training.py:65 2019-01-16 16:57:29.889328: step 1252, loss = 0.72606 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.25
I8192 2019-01-16 16:57:30.873990 ops/training.py:65 2019-01-16 16:57:30.873906: step 1253, loss = 0.72049 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:57:31.857203 ops/training.py:65 2019-01-16 16:57:31.857131: step 1254, loss = 0.69298 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:57:32.839799 ops/training.py:65 2019-01-16 16:57:32.839726: step 1255, loss = 0.68934 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:57:33.825380 ops/training.py:65 2019-01-16 16:57:33.825290: step 1256, loss = 0.67201 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 16:57:34.814176 ops/training.py:65 2019-01-16 16:57:34.814071: step 1257, loss = 0.70632 (32.4 examples/sec; 0.988 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:57:35.799747 ops/training.py:65 2019-01-16 16:57:35.799642: step 1258, loss = 0.72321 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:57:36.782382 ops/training.py:65 2019-01-16 16:57:36.782286: step 1259, loss = 0.70067 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:57:37.765604 ops/training.py:65 2019-01-16 16:57:37.765499: step 1260, loss = 0.70081 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:57:38.748018 ops/training.py:65 2019-01-16 16:57:38.747907: step 1261, loss = 0.69438 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:57:39.729605 ops/training.py:65 2019-01-16 16:57:39.729492: step 1262, loss = 0.67339 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 16:57:40.712248 ops/training.py:65 2019-01-16 16:57:40.712131: step 1263, loss = 0.70482 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:57:41.694595 ops/training.py:65 2019-01-16 16:57:41.694486: step 1264, loss = 0.69810 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:57:42.676042 ops/training.py:65 2019-01-16 16:57:42.675917: step 1265, loss = 0.69000 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:57:43.658419 ops/training.py:65 2019-01-16 16:57:43.658297: step 1266, loss = 0.65697 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:57:44.641537 ops/training.py:65 2019-01-16 16:57:44.641431: step 1267, loss = 0.67368 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 16:57:45.623055 ops/training.py:65 2019-01-16 16:57:45.622958: step 1268, loss = 0.69945 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:57:46.606618 ops/training.py:65 2019-01-16 16:57:46.606510: step 1269, loss = 0.69407 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:57:47.589388 ops/training.py:65 2019-01-16 16:57:47.589279: step 1270, loss = 0.66142 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 16:57:48.572522 ops/training.py:65 2019-01-16 16:57:48.572420: step 1271, loss = 0.71588 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:57:49.554522 ops/training.py:65 2019-01-16 16:57:49.554413: step 1272, loss = 0.69465 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:57:50.536044 ops/training.py:65 2019-01-16 16:57:50.535941: step 1273, loss = 0.68854 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:57:51.517958 ops/training.py:65 2019-01-16 16:57:51.517856: step 1274, loss = 0.68236 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:57:52.500454 ops/training.py:65 2019-01-16 16:57:52.500363: step 1275, loss = 0.69121 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:57:53.485087 ops/training.py:65 2019-01-16 16:57:53.484987: step 1276, loss = 0.69684 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:57:54.469206 ops/training.py:65 2019-01-16 16:57:54.469102: step 1277, loss = 0.69336 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:57:55.453437 ops/training.py:65 2019-01-16 16:57:55.453332: step 1278, loss = 0.69016 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:57:56.438044 ops/training.py:65 2019-01-16 16:57:56.437941: step 1279, loss = 0.70467 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:57:57.421871 ops/training.py:65 2019-01-16 16:57:57.421771: step 1280, loss = 0.69389 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:57:58.405175 ops/training.py:65 2019-01-16 16:57:58.405072: step 1281, loss = 0.72552 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:57:59.386757 ops/training.py:65 2019-01-16 16:57:59.386658: step 1282, loss = 0.69281 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:58:00.368780 ops/training.py:65 2019-01-16 16:58:00.368695: step 1283, loss = 0.69226 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:58:01.350427 ops/training.py:65 2019-01-16 16:58:01.350325: step 1284, loss = 0.71041 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:58:02.334827 ops/training.py:65 2019-01-16 16:58:02.334738: step 1285, loss = 0.68762 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:58:03.319892 ops/training.py:65 2019-01-16 16:58:03.319793: step 1286, loss = 0.70262 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:58:04.305478 ops/training.py:65 2019-01-16 16:58:04.305377: step 1287, loss = 0.70591 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:58:05.290288 ops/training.py:65 2019-01-16 16:58:05.290188: step 1288, loss = 0.72939 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:58:06.274665 ops/training.py:65 2019-01-16 16:58:06.274525: step 1289, loss = 0.67386 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:58:07.260358 ops/training.py:65 2019-01-16 16:58:07.260259: step 1290, loss = 0.71865 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:58:08.247041 ops/training.py:65 2019-01-16 16:58:08.246940: step 1291, loss = 0.68508 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:58:09.230206 ops/training.py:65 2019-01-16 16:58:09.230107: step 1292, loss = 0.69110 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:58:10.212834 ops/training.py:65 2019-01-16 16:58:10.212730: step 1293, loss = 0.68581 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:58:11.195722 ops/training.py:65 2019-01-16 16:58:11.195617: step 1294, loss = 0.67641 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:58:12.178193 ops/training.py:65 2019-01-16 16:58:12.178088: step 1295, loss = 0.69341 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:58:13.164357 ops/training.py:65 2019-01-16 16:58:13.164254: step 1296, loss = 0.69724 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:58:14.150247 ops/training.py:65 2019-01-16 16:58:14.150140: step 1297, loss = 0.72170 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:58:15.135192 ops/training.py:65 2019-01-16 16:58:15.135089: step 1298, loss = 0.70677 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:58:16.119063 ops/training.py:65 2019-01-16 16:58:16.118958: step 1299, loss = 0.72666 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:58:17.103531 ops/training.py:65 2019-01-16 16:58:17.103425: step 1300, loss = 0.72500 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:58:18.087999 ops/training.py:65 2019-01-16 16:58:18.087906: step 1301, loss = 0.75322 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:58:19.071359 ops/training.py:65 2019-01-16 16:58:19.071251: step 1302, loss = 0.66117 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:58:20.056792 ops/training.py:65 2019-01-16 16:58:20.056691: step 1303, loss = 0.65045 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 16:58:21.040248 ops/training.py:65 2019-01-16 16:58:21.040155: step 1304, loss = 0.74051 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:58:22.024219 ops/training.py:65 2019-01-16 16:58:22.024123: step 1305, loss = 0.71792 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:58:23.008666 ops/training.py:65 2019-01-16 16:58:23.008561: step 1306, loss = 0.73100 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:58:23.993785 ops/training.py:65 2019-01-16 16:58:23.993685: step 1307, loss = 0.75754 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:58:24.977543 ops/training.py:65 2019-01-16 16:58:24.977448: step 1308, loss = 0.71191 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:58:25.960371 ops/training.py:65 2019-01-16 16:58:25.960267: step 1309, loss = 0.77156 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:58:26.943513 ops/training.py:65 2019-01-16 16:58:26.943406: step 1310, loss = 0.75195 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:58:27.929779 ops/training.py:65 2019-01-16 16:58:27.929667: step 1311, loss = 0.76318 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:58:28.915162 ops/training.py:65 2019-01-16 16:58:28.915071: step 1312, loss = 0.73605 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:58:29.899253 ops/training.py:65 2019-01-16 16:58:29.899148: step 1313, loss = 0.70872 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:58:30.884359 ops/training.py:65 2019-01-16 16:58:30.884257: step 1314, loss = 0.69936 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:58:31.866197 ops/training.py:65 2019-01-16 16:58:31.866099: step 1315, loss = 0.72569 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:58:32.847413 ops/training.py:65 2019-01-16 16:58:32.847314: step 1316, loss = 0.72593 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:58:33.830363 ops/training.py:65 2019-01-16 16:58:33.830270: step 1317, loss = 0.65543 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:58:34.812784 ops/training.py:65 2019-01-16 16:58:34.812673: step 1318, loss = 0.76560 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 16:58:35.795644 ops/training.py:65 2019-01-16 16:58:35.795532: step 1319, loss = 0.68032 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:58:36.779282 ops/training.py:65 2019-01-16 16:58:36.779173: step 1320, loss = 0.71804 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:58:37.761381 ops/training.py:65 2019-01-16 16:58:37.761281: step 1321, loss = 0.67497 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:58:38.743675 ops/training.py:65 2019-01-16 16:58:38.743576: step 1322, loss = 0.66996 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:58:39.726220 ops/training.py:65 2019-01-16 16:58:39.726119: step 1323, loss = 0.69296 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:58:40.708816 ops/training.py:65 2019-01-16 16:58:40.708708: step 1324, loss = 0.72826 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:58:41.691749 ops/training.py:65 2019-01-16 16:58:41.691642: step 1325, loss = 0.70305 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:58:42.673444 ops/training.py:65 2019-01-16 16:58:42.673361: step 1326, loss = 0.68179 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:58:43.656515 ops/training.py:65 2019-01-16 16:58:43.656412: step 1327, loss = 0.72705 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:58:44.640354 ops/training.py:65 2019-01-16 16:58:44.640248: step 1328, loss = 0.72301 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:58:45.624593 ops/training.py:65 2019-01-16 16:58:45.624483: step 1329, loss = 0.71916 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:58:46.608954 ops/training.py:65 2019-01-16 16:58:46.608844: step 1330, loss = 0.65957 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:58:47.593013 ops/training.py:65 2019-01-16 16:58:47.592906: step 1331, loss = 0.72469 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:58:48.576338 ops/training.py:65 2019-01-16 16:58:48.576246: step 1332, loss = 0.72469 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:58:49.560186 ops/training.py:65 2019-01-16 16:58:49.560105: step 1333, loss = 0.67412 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:58:50.545078 ops/training.py:65 2019-01-16 16:58:50.544970: step 1334, loss = 0.68440 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:58:51.527829 ops/training.py:65 2019-01-16 16:58:51.527726: step 1335, loss = 0.73296 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:58:52.510570 ops/training.py:65 2019-01-16 16:58:52.510461: step 1336, loss = 0.73583 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 16:58:53.495218 ops/training.py:65 2019-01-16 16:58:53.495119: step 1337, loss = 0.65420 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:58:54.480656 ops/training.py:65 2019-01-16 16:58:54.480541: step 1338, loss = 0.72864 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:58:55.465155 ops/training.py:65 2019-01-16 16:58:55.465053: step 1339, loss = 0.71520 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:58:56.450025 ops/training.py:65 2019-01-16 16:58:56.449912: step 1340, loss = 0.73926 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:58:57.434824 ops/training.py:65 2019-01-16 16:58:57.434723: step 1341, loss = 0.71644 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:58:58.420854 ops/training.py:65 2019-01-16 16:58:58.420748: step 1342, loss = 0.69850 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:58:59.405582 ops/training.py:65 2019-01-16 16:58:59.405473: step 1343, loss = 0.70505 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:59:00.389203 ops/training.py:65 2019-01-16 16:59:00.389094: step 1344, loss = 0.68604 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:59:01.372332 ops/training.py:65 2019-01-16 16:59:01.372232: step 1345, loss = 0.69184 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:59:02.356390 ops/training.py:65 2019-01-16 16:59:02.356301: step 1346, loss = 0.67790 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:59:03.340385 ops/training.py:65 2019-01-16 16:59:03.340296: step 1347, loss = 0.69722 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:59:04.323122 ops/training.py:65 2019-01-16 16:59:04.323033: step 1348, loss = 0.67197 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:59:05.306350 ops/training.py:65 2019-01-16 16:59:05.306253: step 1349, loss = 0.69611 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:59:06.290440 ops/training.py:65 2019-01-16 16:59:06.290333: step 1350, loss = 0.71217 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:59:07.274968 ops/training.py:65 2019-01-16 16:59:07.274858: step 1351, loss = 0.70367 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:59:08.259898 ops/training.py:65 2019-01-16 16:59:08.259788: step 1352, loss = 0.72978 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:59:09.244976 ops/training.py:65 2019-01-16 16:59:09.244869: step 1353, loss = 0.70417 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:59:10.228239 ops/training.py:65 2019-01-16 16:59:10.228133: step 1354, loss = 0.69076 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:59:11.210894 ops/training.py:65 2019-01-16 16:59:11.210788: step 1355, loss = 0.72962 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:59:12.194065 ops/training.py:65 2019-01-16 16:59:12.193969: step 1356, loss = 0.66985 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:59:13.177319 ops/training.py:65 2019-01-16 16:59:13.177218: step 1357, loss = 0.69590 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:59:14.160418 ops/training.py:65 2019-01-16 16:59:14.160318: step 1358, loss = 0.68755 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:59:15.142762 ops/training.py:65 2019-01-16 16:59:15.142657: step 1359, loss = 0.71887 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:59:16.125702 ops/training.py:65 2019-01-16 16:59:16.125597: step 1360, loss = 0.71222 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:59:17.108558 ops/training.py:65 2019-01-16 16:59:17.108451: step 1361, loss = 0.69554 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:59:18.091176 ops/training.py:65 2019-01-16 16:59:18.091087: step 1362, loss = 0.69397 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:59:19.073397 ops/training.py:65 2019-01-16 16:59:19.073296: step 1363, loss = 0.70389 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:59:20.057478 ops/training.py:65 2019-01-16 16:59:20.057375: step 1364, loss = 0.68248 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:59:21.041109 ops/training.py:65 2019-01-16 16:59:21.041004: step 1365, loss = 0.70011 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:59:22.024321 ops/training.py:65 2019-01-16 16:59:22.024224: step 1366, loss = 0.70531 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:59:23.009590 ops/training.py:65 2019-01-16 16:59:23.009501: step 1367, loss = 0.69842 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:59:23.994152 ops/training.py:65 2019-01-16 16:59:23.994046: step 1368, loss = 0.72144 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 16:59:24.978366 ops/training.py:65 2019-01-16 16:59:24.978258: step 1369, loss = 0.68785 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:59:25.960607 ops/training.py:65 2019-01-16 16:59:25.960508: step 1370, loss = 0.68919 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:59:26.944027 ops/training.py:65 2019-01-16 16:59:26.943923: step 1371, loss = 0.71299 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:59:27.929354 ops/training.py:65 2019-01-16 16:59:27.929250: step 1372, loss = 0.68807 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:59:28.913594 ops/training.py:65 2019-01-16 16:59:28.913491: step 1373, loss = 0.72882 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:59:29.896256 ops/training.py:65 2019-01-16 16:59:29.896150: step 1374, loss = 0.67839 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:59:30.878796 ops/training.py:65 2019-01-16 16:59:30.878696: step 1375, loss = 0.71767 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:59:31.860846 ops/training.py:65 2019-01-16 16:59:31.860738: step 1376, loss = 0.70153 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:59:32.842621 ops/training.py:65 2019-01-16 16:59:32.842524: step 1377, loss = 0.73456 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 16:59:33.825350 ops/training.py:65 2019-01-16 16:59:33.825263: step 1378, loss = 0.66360 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:59:34.807607 ops/training.py:65 2019-01-16 16:59:34.807510: step 1379, loss = 0.68285 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 16:59:35.793624 ops/training.py:65 2019-01-16 16:59:35.793515: step 1380, loss = 0.69163 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:59:36.779573 ops/training.py:65 2019-01-16 16:59:36.779466: step 1381, loss = 0.67709 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:59:37.765153 ops/training.py:65 2019-01-16 16:59:37.765047: step 1382, loss = 0.68621 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:59:38.750297 ops/training.py:65 2019-01-16 16:59:38.750189: step 1383, loss = 0.72773 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 16:59:39.733665 ops/training.py:65 2019-01-16 16:59:39.733559: step 1384, loss = 0.69839 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:59:40.717213 ops/training.py:65 2019-01-16 16:59:40.717108: step 1385, loss = 0.70077 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:59:41.702869 ops/training.py:65 2019-01-16 16:59:41.702770: step 1386, loss = 0.68893 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 16:59:42.688179 ops/training.py:65 2019-01-16 16:59:42.688074: step 1387, loss = 0.69554 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 16:59:43.672607 ops/training.py:65 2019-01-16 16:59:43.672499: step 1388, loss = 0.70734 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:59:44.656423 ops/training.py:65 2019-01-16 16:59:44.656313: step 1389, loss = 0.70534 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:59:45.639730 ops/training.py:65 2019-01-16 16:59:45.639619: step 1390, loss = 0.70643 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:59:46.625038 ops/training.py:65 2019-01-16 16:59:46.624938: step 1391, loss = 0.69299 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:59:47.609836 ops/training.py:65 2019-01-16 16:59:47.609733: step 1392, loss = 0.69703 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:59:48.593394 ops/training.py:65 2019-01-16 16:59:48.593295: step 1393, loss = 0.69116 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:59:49.575658 ops/training.py:65 2019-01-16 16:59:49.575548: step 1394, loss = 0.73386 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:59:50.557753 ops/training.py:65 2019-01-16 16:59:50.557648: step 1395, loss = 0.69174 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 16:59:51.542169 ops/training.py:65 2019-01-16 16:59:51.542059: step 1396, loss = 0.70711 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:59:52.529165 ops/training.py:65 2019-01-16 16:59:52.529054: step 1397, loss = 0.73228 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 16:59:53.515739 ops/training.py:65 2019-01-16 16:59:53.515641: step 1398, loss = 0.69918 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 16:59:54.500860 ops/training.py:65 2019-01-16 16:59:54.500761: step 1399, loss = 0.67726 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 16:59:55.483644 ops/training.py:65 2019-01-16 16:59:55.483537: step 1400, loss = 0.71451 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:59:56.467865 ops/training.py:65 2019-01-16 16:59:56.467759: step 1401, loss = 0.71837 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 16:59:57.450205 ops/training.py:65 2019-01-16 16:59:57.450094: step 1402, loss = 0.72593 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 16:59:58.433404 ops/training.py:65 2019-01-16 16:59:58.433297: step 1403, loss = 0.69458 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 16:59:59.414762 ops/training.py:65 2019-01-16 16:59:59.414651: step 1404, loss = 0.68337 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:00:00.397095 ops/training.py:65 2019-01-16 17:00:00.396983: step 1405, loss = 0.71745 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:00:01.379313 ops/training.py:65 2019-01-16 17:00:01.379204: step 1406, loss = 0.69271 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:00:02.362009 ops/training.py:65 2019-01-16 17:00:02.361918: step 1407, loss = 0.69771 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:00:03.346469 ops/training.py:65 2019-01-16 17:00:03.346373: step 1408, loss = 0.72659 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:00:04.329730 ops/training.py:65 2019-01-16 17:00:04.329622: step 1409, loss = 0.74814 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.25
I8192 2019-01-16 17:00:05.312035 ops/training.py:65 2019-01-16 17:00:05.311931: step 1410, loss = 0.69673 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:00:06.293850 ops/training.py:65 2019-01-16 17:00:06.293742: step 1411, loss = 0.69934 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:00:07.276611 ops/training.py:65 2019-01-16 17:00:07.276503: step 1412, loss = 0.68694 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:00:08.259355 ops/training.py:65 2019-01-16 17:00:08.259241: step 1413, loss = 0.72231 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:00:09.242118 ops/training.py:65 2019-01-16 17:00:09.242032: step 1414, loss = 0.74507 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:00:10.227912 ops/training.py:65 2019-01-16 17:00:10.227800: step 1415, loss = 0.71915 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:00:11.212710 ops/training.py:65 2019-01-16 17:00:11.212599: step 1416, loss = 0.70692 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:00:12.197657 ops/training.py:65 2019-01-16 17:00:12.197552: step 1417, loss = 0.66184 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:00:13.181602 ops/training.py:65 2019-01-16 17:00:13.181501: step 1418, loss = 0.66149 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:00:14.164059 ops/training.py:65 2019-01-16 17:00:14.163977: step 1419, loss = 0.70025 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:00:15.148611 ops/training.py:65 2019-01-16 17:00:15.148504: step 1420, loss = 0.70298 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:00:16.133049 ops/training.py:65 2019-01-16 17:00:16.132946: step 1421, loss = 0.68124 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:00:17.116512 ops/training.py:65 2019-01-16 17:00:17.116416: step 1422, loss = 0.71951 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:00:18.099518 ops/training.py:65 2019-01-16 17:00:18.099415: step 1423, loss = 0.68267 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:00:19.081453 ops/training.py:65 2019-01-16 17:00:19.081356: step 1424, loss = 0.67754 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:00:20.063931 ops/training.py:65 2019-01-16 17:00:20.063826: step 1425, loss = 0.72411 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:00:21.047165 ops/training.py:65 2019-01-16 17:00:21.047064: step 1426, loss = 0.70835 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:00:22.032881 ops/training.py:65 2019-01-16 17:00:22.032784: step 1427, loss = 0.68276 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:00:23.016791 ops/training.py:65 2019-01-16 17:00:23.016691: step 1428, loss = 0.67647 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:00:24.001808 ops/training.py:65 2019-01-16 17:00:24.001706: step 1429, loss = 0.73940 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:00:24.986424 ops/training.py:65 2019-01-16 17:00:24.986330: step 1430, loss = 0.73605 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:00:25.972326 ops/training.py:65 2019-01-16 17:00:25.972234: step 1431, loss = 0.71807 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:00:26.957294 ops/training.py:65 2019-01-16 17:00:26.957189: step 1432, loss = 0.70151 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:00:27.942793 ops/training.py:65 2019-01-16 17:00:27.942691: step 1433, loss = 0.70407 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:00:28.925329 ops/training.py:65 2019-01-16 17:00:28.925223: step 1434, loss = 0.69154 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:00:29.907693 ops/training.py:65 2019-01-16 17:00:29.907588: step 1435, loss = 0.69919 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:00:30.891690 ops/training.py:65 2019-01-16 17:00:30.891613: step 1436, loss = 0.70357 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:00:31.877963 ops/training.py:65 2019-01-16 17:00:31.877858: step 1437, loss = 0.68777 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:00:32.861867 ops/training.py:65 2019-01-16 17:00:32.861766: step 1438, loss = 0.68439 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:00:33.845049 ops/training.py:65 2019-01-16 17:00:33.844950: step 1439, loss = 0.67963 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:00:34.827900 ops/training.py:65 2019-01-16 17:00:34.827803: step 1440, loss = 0.71187 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:00:35.810550 ops/training.py:65 2019-01-16 17:00:35.810441: step 1441, loss = 0.69392 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:00:36.792836 ops/training.py:65 2019-01-16 17:00:36.792732: step 1442, loss = 0.69327 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:00:37.776054 ops/training.py:65 2019-01-16 17:00:37.775952: step 1443, loss = 0.70432 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:00:38.758379 ops/training.py:65 2019-01-16 17:00:38.758272: step 1444, loss = 0.70578 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:00:39.741422 ops/training.py:65 2019-01-16 17:00:39.741320: step 1445, loss = 0.69040 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:00:40.723723 ops/training.py:65 2019-01-16 17:00:40.723620: step 1446, loss = 0.68572 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:00:41.706273 ops/training.py:65 2019-01-16 17:00:41.706169: step 1447, loss = 0.70611 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:00:42.688560 ops/training.py:65 2019-01-16 17:00:42.688463: step 1448, loss = 0.72059 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:00:43.671116 ops/training.py:65 2019-01-16 17:00:43.671017: step 1449, loss = 0.70693 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:00:44.655052 ops/training.py:65 2019-01-16 17:00:44.654949: step 1450, loss = 0.70911 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:00:45.638451 ops/training.py:65 2019-01-16 17:00:45.638347: step 1451, loss = 0.73538 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.25
I8192 2019-01-16 17:00:46.622177 ops/training.py:65 2019-01-16 17:00:46.622076: step 1452, loss = 0.71608 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:00:47.605176 ops/training.py:65 2019-01-16 17:00:47.605104: step 1453, loss = 0.69513 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:00:48.588534 ops/training.py:65 2019-01-16 17:00:48.588458: step 1454, loss = 0.71030 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:00:49.572401 ops/training.py:65 2019-01-16 17:00:49.572300: step 1455, loss = 0.70635 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:00:50.555131 ops/training.py:65 2019-01-16 17:00:50.555034: step 1456, loss = 0.68584 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:00:51.537246 ops/training.py:65 2019-01-16 17:00:51.537144: step 1457, loss = 0.70530 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:00:52.519175 ops/training.py:65 2019-01-16 17:00:52.519087: step 1458, loss = 0.68857 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:00:53.502454 ops/training.py:65 2019-01-16 17:00:53.502357: step 1459, loss = 0.68995 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:00:54.485060 ops/training.py:65 2019-01-16 17:00:54.484961: step 1460, loss = 0.69765 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:00:55.467512 ops/training.py:65 2019-01-16 17:00:55.467405: step 1461, loss = 0.69945 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:00:56.449691 ops/training.py:65 2019-01-16 17:00:56.449596: step 1462, loss = 0.68221 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:00:57.433412 ops/training.py:65 2019-01-16 17:00:57.433310: step 1463, loss = 0.72469 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:00:58.416043 ops/training.py:65 2019-01-16 17:00:58.415942: step 1464, loss = 0.72059 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:00:59.398784 ops/training.py:65 2019-01-16 17:00:59.398677: step 1465, loss = 0.69986 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:01:00.382184 ops/training.py:65 2019-01-16 17:01:00.382084: step 1466, loss = 0.67670 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:01:01.365938 ops/training.py:65 2019-01-16 17:01:01.365838: step 1467, loss = 0.69323 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:01:02.351720 ops/training.py:65 2019-01-16 17:01:02.351632: step 1468, loss = 0.69454 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:01:03.337663 ops/training.py:65 2019-01-16 17:01:03.337551: step 1469, loss = 0.68746 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:01:04.321822 ops/training.py:65 2019-01-16 17:01:04.321722: step 1470, loss = 0.71140 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:01:05.304836 ops/training.py:65 2019-01-16 17:01:05.304741: step 1471, loss = 0.68782 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:01:06.288258 ops/training.py:65 2019-01-16 17:01:06.288160: step 1472, loss = 0.69564 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:01:07.271670 ops/training.py:65 2019-01-16 17:01:07.271566: step 1473, loss = 0.70863 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:01:08.254791 ops/training.py:65 2019-01-16 17:01:08.254696: step 1474, loss = 0.69688 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:01:09.237167 ops/training.py:65 2019-01-16 17:01:09.237064: step 1475, loss = 0.68111 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:01:10.223424 ops/training.py:65 2019-01-16 17:01:10.223328: step 1476, loss = 0.68509 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:01:11.208876 ops/training.py:65 2019-01-16 17:01:11.208768: step 1477, loss = 0.69029 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:01:12.193259 ops/training.py:65 2019-01-16 17:01:12.193162: step 1478, loss = 0.67772 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 17:01:13.177449 ops/training.py:65 2019-01-16 17:01:13.177343: step 1479, loss = 0.69872 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:01:14.161736 ops/training.py:65 2019-01-16 17:01:14.161652: step 1480, loss = 0.68602 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:01:15.146584 ops/training.py:65 2019-01-16 17:01:15.146474: step 1481, loss = 0.69064 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:01:16.129160 ops/training.py:65 2019-01-16 17:01:16.129064: step 1482, loss = 0.69806 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:01:17.111944 ops/training.py:65 2019-01-16 17:01:17.111843: step 1483, loss = 0.69524 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:01:18.095522 ops/training.py:65 2019-01-16 17:01:18.095416: step 1484, loss = 0.69965 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:01:19.077912 ops/training.py:65 2019-01-16 17:01:19.077813: step 1485, loss = 0.67036 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:01:20.060443 ops/training.py:65 2019-01-16 17:01:20.060344: step 1486, loss = 0.69213 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:01:21.043651 ops/training.py:65 2019-01-16 17:01:21.043556: step 1487, loss = 0.69328 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:01:22.026978 ops/training.py:65 2019-01-16 17:01:22.026873: step 1488, loss = 0.68263 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:01:23.009567 ops/training.py:65 2019-01-16 17:01:23.009471: step 1489, loss = 0.69301 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:01:23.993686 ops/training.py:65 2019-01-16 17:01:23.993595: step 1490, loss = 0.68008 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:01:24.978867 ops/training.py:65 2019-01-16 17:01:24.978765: step 1491, loss = 0.67127 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:01:25.963036 ops/training.py:65 2019-01-16 17:01:25.962931: step 1492, loss = 0.69148 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:01:26.945834 ops/training.py:65 2019-01-16 17:01:26.945734: step 1493, loss = 0.69601 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:01:27.930263 ops/training.py:65 2019-01-16 17:01:27.930161: step 1494, loss = 0.70339 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:01:28.913690 ops/training.py:65 2019-01-16 17:01:28.913591: step 1495, loss = 0.68452 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:01:29.896960 ops/training.py:65 2019-01-16 17:01:29.896864: step 1496, loss = 0.66991 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 17:01:30.879136 ops/training.py:65 2019-01-16 17:01:30.879028: step 1497, loss = 0.69050 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:01:31.862607 ops/training.py:65 2019-01-16 17:01:31.862505: step 1498, loss = 0.69450 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:01:32.845434 ops/training.py:65 2019-01-16 17:01:32.845332: step 1499, loss = 0.71131 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:01:33.827506 ops/training.py:65 2019-01-16 17:01:33.827412: step 1500, loss = 0.69357 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:01:34.810104 ops/training.py:65 2019-01-16 17:01:34.810006: step 1501, loss = 0.69257 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:01:35.794048 ops/training.py:65 2019-01-16 17:01:35.793938: step 1502, loss = 0.70354 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:01:36.777242 ops/training.py:65 2019-01-16 17:01:36.777141: step 1503, loss = 0.68925 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:01:37.759757 ops/training.py:65 2019-01-16 17:01:37.759655: step 1504, loss = 0.71076 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:01:38.741688 ops/training.py:65 2019-01-16 17:01:38.741613: step 1505, loss = 0.69908 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:01:39.722246 ops/training.py:65 2019-01-16 17:01:39.722164: step 1506, loss = 0.68195 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:01:40.706080 ops/training.py:65 2019-01-16 17:01:40.705994: step 1507, loss = 0.69112 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:01:41.691046 ops/training.py:65 2019-01-16 17:01:41.690902: step 1508, loss = 0.70599 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:01:42.673432 ops/training.py:65 2019-01-16 17:01:42.673334: step 1509, loss = 0.70230 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:01:43.659132 ops/training.py:65 2019-01-16 17:01:43.659051: step 1510, loss = 0.68109 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:01:44.643948 ops/training.py:65 2019-01-16 17:01:44.643854: step 1511, loss = 0.70214 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:01:45.627756 ops/training.py:65 2019-01-16 17:01:45.627656: step 1512, loss = 0.71600 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:01:46.610514 ops/training.py:65 2019-01-16 17:01:46.610407: step 1513, loss = 0.68980 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:01:47.593084 ops/training.py:65 2019-01-16 17:01:47.592988: step 1514, loss = 0.70348 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:01:48.577086 ops/training.py:65 2019-01-16 17:01:48.576997: step 1515, loss = 0.68351 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:01:49.560380 ops/training.py:65 2019-01-16 17:01:49.560281: step 1516, loss = 0.69571 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:01:50.542542 ops/training.py:65 2019-01-16 17:01:50.542439: step 1517, loss = 0.68260 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:01:51.525341 ops/training.py:65 2019-01-16 17:01:51.525239: step 1518, loss = 0.70609 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:01:52.508358 ops/training.py:65 2019-01-16 17:01:52.508250: step 1519, loss = 0.69167 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:01:53.491599 ops/training.py:65 2019-01-16 17:01:53.491499: step 1520, loss = 0.70076 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:01:54.474756 ops/training.py:65 2019-01-16 17:01:54.474651: step 1521, loss = 0.68043 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:01:55.457140 ops/training.py:65 2019-01-16 17:01:55.457042: step 1522, loss = 0.70775 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:01:56.440679 ops/training.py:65 2019-01-16 17:01:56.440576: step 1523, loss = 0.68096 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:01:57.424631 ops/training.py:65 2019-01-16 17:01:57.424523: step 1524, loss = 0.69286 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:01:58.406709 ops/training.py:65 2019-01-16 17:01:58.406622: step 1525, loss = 0.69782 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:01:59.390100 ops/training.py:65 2019-01-16 17:01:59.390023: step 1526, loss = 0.69597 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:02:00.372531 ops/training.py:65 2019-01-16 17:02:00.372453: step 1527, loss = 0.69755 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:02:01.352655 ops/training.py:65 2019-01-16 17:02:01.352587: step 1528, loss = 0.65663 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:02:02.334392 ops/training.py:65 2019-01-16 17:02:02.334325: step 1529, loss = 0.69595 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:02:03.319378 ops/training.py:65 2019-01-16 17:02:03.319294: step 1530, loss = 0.67594 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:02:04.304810 ops/training.py:65 2019-01-16 17:02:04.304705: step 1531, loss = 0.70633 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:02:05.288874 ops/training.py:65 2019-01-16 17:02:05.288770: step 1532, loss = 0.69831 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:02:06.272332 ops/training.py:65 2019-01-16 17:02:06.272226: step 1533, loss = 0.72251 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:02:07.254974 ops/training.py:65 2019-01-16 17:02:07.254868: step 1534, loss = 0.71770 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:02:08.238373 ops/training.py:65 2019-01-16 17:02:08.238269: step 1535, loss = 0.66530 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:02:09.222313 ops/training.py:65 2019-01-16 17:02:09.222209: step 1536, loss = 0.71499 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:02:10.206591 ops/training.py:65 2019-01-16 17:02:10.206489: step 1537, loss = 0.71028 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:02:11.190670 ops/training.py:65 2019-01-16 17:02:11.190561: step 1538, loss = 0.71640 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:02:12.174883 ops/training.py:65 2019-01-16 17:02:12.174811: step 1539, loss = 0.70946 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:02:13.160423 ops/training.py:65 2019-01-16 17:02:13.160318: step 1540, loss = 0.72448 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:02:14.144952 ops/training.py:65 2019-01-16 17:02:14.144850: step 1541, loss = 0.71249 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:02:15.129354 ops/training.py:65 2019-01-16 17:02:15.129250: step 1542, loss = 0.70890 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:02:16.113226 ops/training.py:65 2019-01-16 17:02:16.113155: step 1543, loss = 0.70246 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:02:17.096321 ops/training.py:65 2019-01-16 17:02:17.096244: step 1544, loss = 0.71645 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:02:18.081164 ops/training.py:65 2019-01-16 17:02:18.081089: step 1545, loss = 0.68356 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:02:19.065197 ops/training.py:65 2019-01-16 17:02:19.065099: step 1546, loss = 0.68445 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:02:20.049908 ops/training.py:65 2019-01-16 17:02:20.049800: step 1547, loss = 0.70385 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:02:21.035943 ops/training.py:65 2019-01-16 17:02:21.035834: step 1548, loss = 0.69113 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:02:22.019402 ops/training.py:65 2019-01-16 17:02:22.019300: step 1549, loss = 0.69341 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:02:23.001754 ops/training.py:65 2019-01-16 17:02:23.001647: step 1550, loss = 0.69226 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:02:23.982720 ops/training.py:65 2019-01-16 17:02:23.982620: step 1551, loss = 0.70233 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:02:24.966762 ops/training.py:65 2019-01-16 17:02:24.966660: step 1552, loss = 0.68768 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:02:25.951067 ops/training.py:65 2019-01-16 17:02:25.951015: step 1553, loss = 0.68665 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:02:26.934164 ops/training.py:65 2019-01-16 17:02:26.934068: step 1554, loss = 0.68284 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:02:27.918511 ops/training.py:65 2019-01-16 17:02:27.918408: step 1555, loss = 0.70904 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:02:28.902725 ops/training.py:65 2019-01-16 17:02:28.902621: step 1556, loss = 0.70131 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:02:29.886273 ops/training.py:65 2019-01-16 17:02:29.886198: step 1557, loss = 0.70696 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:02:30.868645 ops/training.py:65 2019-01-16 17:02:30.868575: step 1558, loss = 0.68878 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:02:31.852067 ops/training.py:65 2019-01-16 17:02:31.851999: step 1559, loss = 0.68999 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:02:32.836798 ops/training.py:65 2019-01-16 17:02:32.836696: step 1560, loss = 0.71095 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:02:33.820527 ops/training.py:65 2019-01-16 17:02:33.820433: step 1561, loss = 0.67691 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:02:34.804607 ops/training.py:65 2019-01-16 17:02:34.804536: step 1562, loss = 0.69514 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:02:35.789117 ops/training.py:65 2019-01-16 17:02:35.789038: step 1563, loss = 0.67795 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:02:36.773426 ops/training.py:65 2019-01-16 17:02:36.773320: step 1564, loss = 0.71558 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:02:37.756055 ops/training.py:65 2019-01-16 17:02:37.755948: step 1565, loss = 0.71715 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:02:38.741090 ops/training.py:65 2019-01-16 17:02:38.740979: step 1566, loss = 0.71390 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:02:39.727788 ops/training.py:65 2019-01-16 17:02:39.727682: step 1567, loss = 0.69434 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:02:40.713018 ops/training.py:65 2019-01-16 17:02:40.712915: step 1568, loss = 0.73294 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:02:41.697247 ops/training.py:65 2019-01-16 17:02:41.697143: step 1569, loss = 0.67445 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:02:42.681139 ops/training.py:65 2019-01-16 17:02:42.681037: step 1570, loss = 0.67994 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:02:43.663887 ops/training.py:65 2019-01-16 17:02:43.663811: step 1571, loss = 0.69164 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:02:44.645005 ops/training.py:65 2019-01-16 17:02:44.644939: step 1572, loss = 0.68374 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:02:45.629424 ops/training.py:65 2019-01-16 17:02:45.629386: step 1573, loss = 0.69110 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:02:46.613835 ops/training.py:65 2019-01-16 17:02:46.613796: step 1574, loss = 0.70320 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:02:47.596543 ops/training.py:65 2019-01-16 17:02:47.596476: step 1575, loss = 0.67290 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:02:48.583756 ops/training.py:65 2019-01-16 17:02:48.583717: step 1576, loss = 0.68007 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:02:49.567707 ops/training.py:65 2019-01-16 17:02:49.567673: step 1577, loss = 0.69513 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:02:50.550044 ops/training.py:65 2019-01-16 17:02:50.550009: step 1578, loss = 0.71866 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:02:51.533982 ops/training.py:65 2019-01-16 17:02:51.533950: step 1579, loss = 0.71022 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:02:52.518710 ops/training.py:65 2019-01-16 17:02:52.518679: step 1580, loss = 0.70116 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:02:53.503030 ops/training.py:65 2019-01-16 17:02:53.502998: step 1581, loss = 0.66881 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:02:54.488722 ops/training.py:65 2019-01-16 17:02:54.488690: step 1582, loss = 0.68799 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:02:55.471998 ops/training.py:65 2019-01-16 17:02:55.471964: step 1583, loss = 0.69481 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:02:56.455823 ops/training.py:65 2019-01-16 17:02:56.455791: step 1584, loss = 0.71880 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:02:57.440296 ops/training.py:65 2019-01-16 17:02:57.440259: step 1585, loss = 0.71407 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:02:58.424255 ops/training.py:65 2019-01-16 17:02:58.424183: step 1586, loss = 0.69650 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:02:59.408002 ops/training.py:65 2019-01-16 17:02:59.407893: step 1587, loss = 0.68130 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:03:00.390060 ops/training.py:65 2019-01-16 17:03:00.389993: step 1588, loss = 0.67086 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:03:01.375031 ops/training.py:65 2019-01-16 17:03:01.375001: step 1589, loss = 0.69271 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:03:02.358373 ops/training.py:65 2019-01-16 17:03:02.358341: step 1590, loss = 0.69288 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:03:03.340990 ops/training.py:65 2019-01-16 17:03:03.340954: step 1591, loss = 0.68922 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:03:04.325849 ops/training.py:65 2019-01-16 17:03:04.325807: step 1592, loss = 0.68446 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:03:05.310301 ops/training.py:65 2019-01-16 17:03:05.310269: step 1593, loss = 0.68821 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:03:06.294406 ops/training.py:65 2019-01-16 17:03:06.294372: step 1594, loss = 0.71913 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:03:07.276622 ops/training.py:65 2019-01-16 17:03:07.276538: step 1595, loss = 0.68893 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:03:08.259189 ops/training.py:65 2019-01-16 17:03:08.259155: step 1596, loss = 0.69437 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:03:09.240671 ops/training.py:65 2019-01-16 17:03:09.240577: step 1597, loss = 0.69143 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:03:10.226080 ops/training.py:65 2019-01-16 17:03:10.226002: step 1598, loss = 0.69968 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:03:11.212404 ops/training.py:65 2019-01-16 17:03:11.212300: step 1599, loss = 0.68969 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:03:12.197768 ops/training.py:65 2019-01-16 17:03:12.197661: step 1600, loss = 0.68790 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:03:13.183560 ops/training.py:65 2019-01-16 17:03:13.183456: step 1601, loss = 0.73204 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:03:14.167419 ops/training.py:65 2019-01-16 17:03:14.167348: step 1602, loss = 0.69330 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:03:15.149042 ops/training.py:65 2019-01-16 17:03:15.148975: step 1603, loss = 0.71216 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:03:16.130886 ops/training.py:65 2019-01-16 17:03:16.130816: step 1604, loss = 0.65571 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 17:03:17.111961 ops/training.py:65 2019-01-16 17:03:17.111898: step 1605, loss = 0.71377 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:03:18.096866 ops/training.py:65 2019-01-16 17:03:18.096790: step 1606, loss = 0.70807 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:03:19.080885 ops/training.py:65 2019-01-16 17:03:19.080791: step 1607, loss = 0.68526 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:03:20.064663 ops/training.py:65 2019-01-16 17:03:20.064554: step 1608, loss = 0.68438 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:03:21.050008 ops/training.py:65 2019-01-16 17:03:21.049902: step 1609, loss = 0.70000 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:03:22.036760 ops/training.py:65 2019-01-16 17:03:22.036655: step 1610, loss = 0.72040 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:03:23.021801 ops/training.py:65 2019-01-16 17:03:23.021703: step 1611, loss = 0.67902 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:03:24.007271 ops/training.py:65 2019-01-16 17:03:24.007169: step 1612, loss = 0.71894 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:03:24.990432 ops/training.py:65 2019-01-16 17:03:24.990324: step 1613, loss = 0.70671 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:03:25.972918 ops/training.py:65 2019-01-16 17:03:25.972868: step 1614, loss = 0.68754 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:03:26.956053 ops/training.py:65 2019-01-16 17:03:26.956015: step 1615, loss = 0.68709 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:03:27.939909 ops/training.py:65 2019-01-16 17:03:27.939853: step 1616, loss = 0.73530 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 17:03:28.922567 ops/training.py:65 2019-01-16 17:03:28.922517: step 1617, loss = 0.67147 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:03:29.905122 ops/training.py:65 2019-01-16 17:03:29.905091: step 1618, loss = 0.70495 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:03:30.887592 ops/training.py:65 2019-01-16 17:03:30.887558: step 1619, loss = 0.65692 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:03:31.870342 ops/training.py:65 2019-01-16 17:03:31.870306: step 1620, loss = 0.68323 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:03:32.852821 ops/training.py:65 2019-01-16 17:03:32.852788: step 1621, loss = 0.69034 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:03:33.835533 ops/training.py:65 2019-01-16 17:03:33.835454: step 1622, loss = 0.68277 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:03:34.817953 ops/training.py:65 2019-01-16 17:03:34.817879: step 1623, loss = 0.66737 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:03:35.802785 ops/training.py:65 2019-01-16 17:03:35.802701: step 1624, loss = 0.67755 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:03:36.785343 ops/training.py:65 2019-01-16 17:03:36.785241: step 1625, loss = 0.71862 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:03:37.768786 ops/training.py:65 2019-01-16 17:03:37.768681: step 1626, loss = 0.71690 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:03:38.751056 ops/training.py:65 2019-01-16 17:03:38.750979: step 1627, loss = 0.69563 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:03:39.732913 ops/training.py:65 2019-01-16 17:03:39.732848: step 1628, loss = 0.69067 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:03:40.717513 ops/training.py:65 2019-01-16 17:03:40.717429: step 1629, loss = 0.71551 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:03:41.700663 ops/training.py:65 2019-01-16 17:03:41.700556: step 1630, loss = 0.68506 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:03:42.685442 ops/training.py:65 2019-01-16 17:03:42.685343: step 1631, loss = 0.69717 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:03:43.668327 ops/training.py:65 2019-01-16 17:03:43.668254: step 1632, loss = 0.73507 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:03:44.649121 ops/training.py:65 2019-01-16 17:03:44.649049: step 1633, loss = 0.66234 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:03:45.633387 ops/training.py:65 2019-01-16 17:03:45.633309: step 1634, loss = 0.74016 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.25
I8192 2019-01-16 17:03:46.618408 ops/training.py:65 2019-01-16 17:03:46.618300: step 1635, loss = 0.71480 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:03:47.604900 ops/training.py:65 2019-01-16 17:03:47.604791: step 1636, loss = 0.67003 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:03:48.588609 ops/training.py:65 2019-01-16 17:03:48.588509: step 1637, loss = 0.66355 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:03:49.572963 ops/training.py:65 2019-01-16 17:03:49.572854: step 1638, loss = 0.69474 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:03:50.558566 ops/training.py:65 2019-01-16 17:03:50.558478: step 1639, loss = 0.76339 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:03:51.541494 ops/training.py:65 2019-01-16 17:03:51.541388: step 1640, loss = 0.72276 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:03:52.525023 ops/training.py:65 2019-01-16 17:03:52.524917: step 1641, loss = 0.70517 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:03:53.507972 ops/training.py:65 2019-01-16 17:03:53.507870: step 1642, loss = 0.67719 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:03:54.489702 ops/training.py:65 2019-01-16 17:03:54.489604: step 1643, loss = 0.72501 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:03:55.471208 ops/training.py:65 2019-01-16 17:03:55.471144: step 1644, loss = 0.71467 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:03:56.452403 ops/training.py:65 2019-01-16 17:03:56.452329: step 1645, loss = 0.68238 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:03:57.431463 ops/training.py:65 2019-01-16 17:03:57.431394: step 1646, loss = 0.69115 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:03:58.414029 ops/training.py:65 2019-01-16 17:03:58.413983: step 1647, loss = 0.69016 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:03:59.397783 ops/training.py:65 2019-01-16 17:03:59.397738: step 1648, loss = 0.71316 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:04:00.381257 ops/training.py:65 2019-01-16 17:04:00.381182: step 1649, loss = 0.65613 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:04:01.363994 ops/training.py:65 2019-01-16 17:04:01.363892: step 1650, loss = 0.70975 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:04:02.345797 ops/training.py:65 2019-01-16 17:04:02.345734: step 1651, loss = 0.70250 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:04:03.329407 ops/training.py:65 2019-01-16 17:04:03.329354: step 1652, loss = 0.69501 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:04:04.313834 ops/training.py:65 2019-01-16 17:04:04.313732: step 1653, loss = 0.67348 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:04:05.296820 ops/training.py:65 2019-01-16 17:04:05.296720: step 1654, loss = 0.72001 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:04:06.278453 ops/training.py:65 2019-01-16 17:04:06.278387: step 1655, loss = 0.70647 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:04:07.260404 ops/training.py:65 2019-01-16 17:04:07.260347: step 1656, loss = 0.67101 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:04:08.244735 ops/training.py:65 2019-01-16 17:04:08.244677: step 1657, loss = 0.70833 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:04:09.227595 ops/training.py:65 2019-01-16 17:04:09.227483: step 1658, loss = 0.68851 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:04:10.212380 ops/training.py:65 2019-01-16 17:04:10.212272: step 1659, loss = 0.74852 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:04:11.196441 ops/training.py:65 2019-01-16 17:04:11.196332: step 1660, loss = 0.72494 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:04:12.181163 ops/training.py:65 2019-01-16 17:04:12.181089: step 1661, loss = 0.71129 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:04:13.165987 ops/training.py:65 2019-01-16 17:04:13.165884: step 1662, loss = 0.73334 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.21875
I8192 2019-01-16 17:04:14.152436 ops/training.py:65 2019-01-16 17:04:14.152324: step 1663, loss = 0.71509 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:04:15.136579 ops/training.py:65 2019-01-16 17:04:15.136469: step 1664, loss = 0.70263 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:04:16.119390 ops/training.py:65 2019-01-16 17:04:16.119316: step 1665, loss = 0.67502 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:04:17.101434 ops/training.py:65 2019-01-16 17:04:17.101366: step 1666, loss = 0.71648 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:04:18.084365 ops/training.py:65 2019-01-16 17:04:18.084299: step 1667, loss = 0.69058 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:04:19.068128 ops/training.py:65 2019-01-16 17:04:19.068061: step 1668, loss = 0.67461 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:04:20.052759 ops/training.py:65 2019-01-16 17:04:20.052654: step 1669, loss = 0.68466 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:04:21.035806 ops/training.py:65 2019-01-16 17:04:21.035706: step 1670, loss = 0.68596 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:04:22.018751 ops/training.py:65 2019-01-16 17:04:22.018649: step 1671, loss = 0.71860 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:04:23.001962 ops/training.py:65 2019-01-16 17:04:23.001861: step 1672, loss = 0.66320 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:04:23.984318 ops/training.py:65 2019-01-16 17:04:23.984211: step 1673, loss = 0.69047 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:04:24.967361 ops/training.py:65 2019-01-16 17:04:24.967252: step 1674, loss = 0.66808 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:04:25.950089 ops/training.py:65 2019-01-16 17:04:25.949969: step 1675, loss = 0.73568 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:04:26.933491 ops/training.py:65 2019-01-16 17:04:26.933386: step 1676, loss = 0.69454 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:04:27.917886 ops/training.py:65 2019-01-16 17:04:27.917783: step 1677, loss = 0.68633 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:04:28.900953 ops/training.py:65 2019-01-16 17:04:28.900844: step 1678, loss = 0.73530 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:04:29.883463 ops/training.py:65 2019-01-16 17:04:29.883377: step 1679, loss = 0.68256 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:04:30.863901 ops/training.py:65 2019-01-16 17:04:30.863811: step 1680, loss = 0.69327 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:04:31.844053 ops/training.py:65 2019-01-16 17:04:31.843986: step 1681, loss = 0.67942 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:04:32.824876 ops/training.py:65 2019-01-16 17:04:32.824800: step 1682, loss = 0.73359 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:04:33.807720 ops/training.py:65 2019-01-16 17:04:33.807643: step 1683, loss = 0.72166 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:04:34.789077 ops/training.py:65 2019-01-16 17:04:34.788999: step 1684, loss = 0.71449 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:04:35.772408 ops/training.py:65 2019-01-16 17:04:35.772341: step 1685, loss = 0.70067 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:04:36.757920 ops/training.py:65 2019-01-16 17:04:36.757809: step 1686, loss = 0.68460 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:04:37.742833 ops/training.py:65 2019-01-16 17:04:37.742734: step 1687, loss = 0.71963 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:04:38.727389 ops/training.py:65 2019-01-16 17:04:38.727278: step 1688, loss = 0.67560 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:04:39.712069 ops/training.py:65 2019-01-16 17:04:39.711990: step 1689, loss = 0.71435 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:04:40.693999 ops/training.py:65 2019-01-16 17:04:40.693921: step 1690, loss = 0.72686 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:04:41.677987 ops/training.py:65 2019-01-16 17:04:41.677920: step 1691, loss = 0.69611 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:04:42.662083 ops/training.py:65 2019-01-16 17:04:42.661978: step 1692, loss = 0.67727 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:04:43.645021 ops/training.py:65 2019-01-16 17:04:43.644916: step 1693, loss = 0.70070 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:04:44.630336 ops/training.py:65 2019-01-16 17:04:44.630276: step 1694, loss = 0.70243 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:04:45.614872 ops/training.py:65 2019-01-16 17:04:45.614768: step 1695, loss = 0.70747 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:04:46.598042 ops/training.py:65 2019-01-16 17:04:46.597942: step 1696, loss = 0.69952 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:04:47.584390 ops/training.py:65 2019-01-16 17:04:47.584308: step 1697, loss = 0.67313 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:04:48.568597 ops/training.py:65 2019-01-16 17:04:48.568498: step 1698, loss = 0.69882 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:04:49.554063 ops/training.py:65 2019-01-16 17:04:49.553955: step 1699, loss = 0.72179 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:04:50.538104 ops/training.py:65 2019-01-16 17:04:50.538002: step 1700, loss = 0.71759 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:04:51.521963 ops/training.py:65 2019-01-16 17:04:51.521854: step 1701, loss = 0.68435 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:04:52.506936 ops/training.py:65 2019-01-16 17:04:52.506828: step 1702, loss = 0.69629 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:04:53.491139 ops/training.py:65 2019-01-16 17:04:53.491054: step 1703, loss = 0.70238 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:04:54.473515 ops/training.py:65 2019-01-16 17:04:54.473450: step 1704, loss = 0.70119 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:04:55.457590 ops/training.py:65 2019-01-16 17:04:55.457494: step 1705, loss = 0.68746 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:04:56.441912 ops/training.py:65 2019-01-16 17:04:56.441811: step 1706, loss = 0.72530 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:04:57.425792 ops/training.py:65 2019-01-16 17:04:57.425688: step 1707, loss = 0.67815 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:04:58.410619 ops/training.py:65 2019-01-16 17:04:58.410512: step 1708, loss = 0.70352 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:04:59.394391 ops/training.py:65 2019-01-16 17:04:59.394283: step 1709, loss = 0.70100 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:05:00.378160 ops/training.py:65 2019-01-16 17:05:00.378057: step 1710, loss = 0.72777 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:05:01.362346 ops/training.py:65 2019-01-16 17:05:01.362239: step 1711, loss = 0.69709 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:05:02.346369 ops/training.py:65 2019-01-16 17:05:02.346287: step 1712, loss = 0.67977 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:05:03.328609 ops/training.py:65 2019-01-16 17:05:03.328525: step 1713, loss = 0.70651 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:05:04.311568 ops/training.py:65 2019-01-16 17:05:04.311442: step 1714, loss = 0.72249 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:05:05.294644 ops/training.py:65 2019-01-16 17:05:05.294533: step 1715, loss = 0.67945 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:05:06.278124 ops/training.py:65 2019-01-16 17:05:06.278021: step 1716, loss = 0.70945 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:05:07.262329 ops/training.py:65 2019-01-16 17:05:07.262218: step 1717, loss = 0.73059 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:05:08.246561 ops/training.py:65 2019-01-16 17:05:08.246481: step 1718, loss = 0.68778 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:05:09.231108 ops/training.py:65 2019-01-16 17:05:09.231034: step 1719, loss = 0.70594 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:05:10.211723 ops/training.py:65 2019-01-16 17:05:10.211659: step 1720, loss = 0.69851 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:05:11.193982 ops/training.py:65 2019-01-16 17:05:11.193912: step 1721, loss = 0.67481 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:05:12.178556 ops/training.py:65 2019-01-16 17:05:12.178496: step 1722, loss = 0.68814 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:05:13.164763 ops/training.py:65 2019-01-16 17:05:13.164659: step 1723, loss = 0.69198 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:05:14.148852 ops/training.py:65 2019-01-16 17:05:14.148790: step 1724, loss = 0.69324 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:05:15.131421 ops/training.py:65 2019-01-16 17:05:15.131315: step 1725, loss = 0.71074 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:05:16.114476 ops/training.py:65 2019-01-16 17:05:16.114369: step 1726, loss = 0.69000 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:05:17.100033 ops/training.py:65 2019-01-16 17:05:17.099917: step 1727, loss = 0.67486 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:05:18.083982 ops/training.py:65 2019-01-16 17:05:18.083907: step 1728, loss = 0.73364 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:05:19.067048 ops/training.py:65 2019-01-16 17:05:19.066967: step 1729, loss = 0.70504 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:05:20.048863 ops/training.py:65 2019-01-16 17:05:20.048784: step 1730, loss = 0.71669 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:05:21.031483 ops/training.py:65 2019-01-16 17:05:21.031409: step 1731, loss = 0.69670 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:05:22.013616 ops/training.py:65 2019-01-16 17:05:22.013542: step 1732, loss = 0.68412 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:05:22.996316 ops/training.py:65 2019-01-16 17:05:22.996172: step 1733, loss = 0.67243 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:05:23.983454 ops/training.py:65 2019-01-16 17:05:23.983347: step 1734, loss = 0.71063 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:05:24.968877 ops/training.py:65 2019-01-16 17:05:24.968769: step 1735, loss = 0.73050 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:05:25.952010 ops/training.py:65 2019-01-16 17:05:25.951913: step 1736, loss = 0.71181 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:05:26.934722 ops/training.py:65 2019-01-16 17:05:26.934618: step 1737, loss = 0.69425 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:05:27.921411 ops/training.py:65 2019-01-16 17:05:27.921306: step 1738, loss = 0.68055 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:05:28.907298 ops/training.py:65 2019-01-16 17:05:28.907162: step 1739, loss = 0.68368 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:05:29.892381 ops/training.py:65 2019-01-16 17:05:29.892277: step 1740, loss = 0.68552 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 17:05:30.877733 ops/training.py:65 2019-01-16 17:05:30.877628: step 1741, loss = 0.69256 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:05:31.863377 ops/training.py:65 2019-01-16 17:05:31.863271: step 1742, loss = 0.67671 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:05:32.849627 ops/training.py:65 2019-01-16 17:05:32.849525: step 1743, loss = 0.68268 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:05:33.834405 ops/training.py:65 2019-01-16 17:05:33.834305: step 1744, loss = 0.69723 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:05:34.817196 ops/training.py:65 2019-01-16 17:05:34.817092: step 1745, loss = 0.68352 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:05:35.798847 ops/training.py:65 2019-01-16 17:05:35.798740: step 1746, loss = 0.71342 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:05:36.783940 ops/training.py:65 2019-01-16 17:05:36.783840: step 1747, loss = 0.68377 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:05:37.768755 ops/training.py:65 2019-01-16 17:05:37.768653: step 1748, loss = 0.69652 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:05:38.753526 ops/training.py:65 2019-01-16 17:05:38.753464: step 1749, loss = 0.72568 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:05:39.736848 ops/training.py:65 2019-01-16 17:05:39.736759: step 1750, loss = 0.68862 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:05:40.724484 ops/training.py:65 2019-01-16 17:05:40.724393: step 1751, loss = 0.68538 (32.4 examples/sec; 0.986 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:05:41.708653 ops/training.py:65 2019-01-16 17:05:41.708569: step 1752, loss = 0.68171 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:05:42.691307 ops/training.py:65 2019-01-16 17:05:42.691227: step 1753, loss = 0.70555 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:05:43.674510 ops/training.py:65 2019-01-16 17:05:43.674418: step 1754, loss = 0.68390 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:05:44.661327 ops/training.py:65 2019-01-16 17:05:44.661225: step 1755, loss = 0.73120 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:05:45.646855 ops/training.py:65 2019-01-16 17:05:45.646753: step 1756, loss = 0.67092 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:05:46.633829 ops/training.py:65 2019-01-16 17:05:46.633728: step 1757, loss = 0.71802 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:05:47.618193 ops/training.py:65 2019-01-16 17:05:47.618106: step 1758, loss = 0.68149 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:05:48.601696 ops/training.py:65 2019-01-16 17:05:48.601639: step 1759, loss = 0.70631 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:05:49.583227 ops/training.py:65 2019-01-16 17:05:49.583127: step 1760, loss = 0.70709 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:05:50.565226 ops/training.py:65 2019-01-16 17:05:50.565126: step 1761, loss = 0.70645 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:05:51.547138 ops/training.py:65 2019-01-16 17:05:51.547035: step 1762, loss = 0.69767 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:05:52.530058 ops/training.py:65 2019-01-16 17:05:52.529942: step 1763, loss = 0.68982 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:05:53.516086 ops/training.py:65 2019-01-16 17:05:53.515978: step 1764, loss = 0.71029 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:05:54.501111 ops/training.py:65 2019-01-16 17:05:54.501004: step 1765, loss = 0.70073 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:05:55.483067 ops/training.py:65 2019-01-16 17:05:55.482986: step 1766, loss = 0.68408 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:05:56.466709 ops/training.py:65 2019-01-16 17:05:56.466625: step 1767, loss = 0.70553 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:05:57.449063 ops/training.py:65 2019-01-16 17:05:57.448984: step 1768, loss = 0.70396 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:05:58.430180 ops/training.py:65 2019-01-16 17:05:58.430099: step 1769, loss = 0.69523 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:05:59.411955 ops/training.py:65 2019-01-16 17:05:59.411875: step 1770, loss = 0.69587 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:06:00.395116 ops/training.py:65 2019-01-16 17:06:00.395036: step 1771, loss = 0.72335 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:06:01.376688 ops/training.py:65 2019-01-16 17:06:01.376612: step 1772, loss = 0.69272 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:06:02.360083 ops/training.py:65 2019-01-16 17:06:02.360002: step 1773, loss = 0.67514 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:06:03.344155 ops/training.py:65 2019-01-16 17:06:03.344058: step 1774, loss = 0.68025 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 17:06:04.326436 ops/training.py:65 2019-01-16 17:06:04.326349: step 1775, loss = 0.72701 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:06:05.308516 ops/training.py:65 2019-01-16 17:06:05.308419: step 1776, loss = 0.69039 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:06:06.293124 ops/training.py:65 2019-01-16 17:06:06.293023: step 1777, loss = 0.69894 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:06:07.277379 ops/training.py:65 2019-01-16 17:06:07.277278: step 1778, loss = 0.70492 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:06:08.263743 ops/training.py:65 2019-01-16 17:06:08.263645: step 1779, loss = 0.71290 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:06:09.249644 ops/training.py:65 2019-01-16 17:06:09.249536: step 1780, loss = 0.68773 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:06:10.234039 ops/training.py:65 2019-01-16 17:06:10.233942: step 1781, loss = 0.69335 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:06:11.219646 ops/training.py:65 2019-01-16 17:06:11.219544: step 1782, loss = 0.71278 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 17:06:12.203661 ops/training.py:65 2019-01-16 17:06:12.203562: step 1783, loss = 0.70078 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:06:13.186032 ops/training.py:65 2019-01-16 17:06:13.185934: step 1784, loss = 0.69299 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:06:14.170671 ops/training.py:65 2019-01-16 17:06:14.170579: step 1785, loss = 0.70873 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:06:15.155443 ops/training.py:65 2019-01-16 17:06:15.155340: step 1786, loss = 0.71443 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 17:06:16.139527 ops/training.py:65 2019-01-16 17:06:16.139460: step 1787, loss = 0.68927 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:06:17.122044 ops/training.py:65 2019-01-16 17:06:17.121939: step 1788, loss = 0.69809 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:06:18.103960 ops/training.py:65 2019-01-16 17:06:18.103858: step 1789, loss = 0.72950 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.25
I8192 2019-01-16 17:06:19.089310 ops/training.py:65 2019-01-16 17:06:19.089215: step 1790, loss = 0.69095 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:06:20.073989 ops/training.py:65 2019-01-16 17:06:20.073890: step 1791, loss = 0.68063 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:06:21.058030 ops/training.py:65 2019-01-16 17:06:21.057927: step 1792, loss = 0.71128 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:06:22.041447 ops/training.py:65 2019-01-16 17:06:22.041350: step 1793, loss = 0.68028 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:06:23.025596 ops/training.py:65 2019-01-16 17:06:23.025496: step 1794, loss = 0.68779 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:06:24.009804 ops/training.py:65 2019-01-16 17:06:24.009707: step 1795, loss = 0.66841 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:06:24.994956 ops/training.py:65 2019-01-16 17:06:24.994855: step 1796, loss = 0.70203 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:06:25.979286 ops/training.py:65 2019-01-16 17:06:25.979207: step 1797, loss = 0.68978 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:06:26.962206 ops/training.py:65 2019-01-16 17:06:26.962104: step 1798, loss = 0.71451 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:06:27.946707 ops/training.py:65 2019-01-16 17:06:27.946607: step 1799, loss = 0.70873 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:06:28.929924 ops/training.py:65 2019-01-16 17:06:28.929820: step 1800, loss = 0.72414 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:06:29.913713 ops/training.py:65 2019-01-16 17:06:29.913614: step 1801, loss = 0.69754 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:06:30.896730 ops/training.py:65 2019-01-16 17:06:30.896625: step 1802, loss = 0.70294 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:06:31.880592 ops/training.py:65 2019-01-16 17:06:31.880491: step 1803, loss = 0.70275 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:06:32.863701 ops/training.py:65 2019-01-16 17:06:32.863597: step 1804, loss = 0.70032 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:06:33.847173 ops/training.py:65 2019-01-16 17:06:33.847085: step 1805, loss = 0.68284 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:06:34.829690 ops/training.py:65 2019-01-16 17:06:34.829593: step 1806, loss = 0.70170 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:06:35.814324 ops/training.py:65 2019-01-16 17:06:35.814234: step 1807, loss = 0.66790 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:06:36.797480 ops/training.py:65 2019-01-16 17:06:36.797382: step 1808, loss = 0.71001 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:06:37.783178 ops/training.py:65 2019-01-16 17:06:37.783068: step 1809, loss = 0.69484 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:06:38.767935 ops/training.py:65 2019-01-16 17:06:38.767821: step 1810, loss = 0.69150 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:06:39.752065 ops/training.py:65 2019-01-16 17:06:39.751992: step 1811, loss = 0.68842 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:06:40.735349 ops/training.py:65 2019-01-16 17:06:40.735261: step 1812, loss = 0.71956 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:06:41.718532 ops/training.py:65 2019-01-16 17:06:41.718441: step 1813, loss = 0.67937 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:06:42.701439 ops/training.py:65 2019-01-16 17:06:42.701342: step 1814, loss = 0.69754 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:06:43.684953 ops/training.py:65 2019-01-16 17:06:43.684872: step 1815, loss = 0.71448 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:06:44.669070 ops/training.py:65 2019-01-16 17:06:44.668983: step 1816, loss = 0.71260 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:06:45.654201 ops/training.py:65 2019-01-16 17:06:45.654096: step 1817, loss = 0.70377 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:06:46.638538 ops/training.py:65 2019-01-16 17:06:46.638438: step 1818, loss = 0.67921 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:06:47.623070 ops/training.py:65 2019-01-16 17:06:47.622974: step 1819, loss = 0.70323 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:06:48.607393 ops/training.py:65 2019-01-16 17:06:48.607293: step 1820, loss = 0.69843 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:06:49.591225 ops/training.py:65 2019-01-16 17:06:49.591126: step 1821, loss = 0.69325 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:06:50.574922 ops/training.py:65 2019-01-16 17:06:50.574820: step 1822, loss = 0.70150 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:06:51.557735 ops/training.py:65 2019-01-16 17:06:51.557664: step 1823, loss = 0.69068 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:06:52.539247 ops/training.py:65 2019-01-16 17:06:52.539169: step 1824, loss = 0.67978 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:06:53.522477 ops/training.py:65 2019-01-16 17:06:53.522398: step 1825, loss = 0.70555 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:06:54.505983 ops/training.py:65 2019-01-16 17:06:54.505881: step 1826, loss = 0.68377 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:06:55.490507 ops/training.py:65 2019-01-16 17:06:55.490399: step 1827, loss = 0.68719 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:06:56.474636 ops/training.py:65 2019-01-16 17:06:56.474531: step 1828, loss = 0.71132 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:06:57.459062 ops/training.py:65 2019-01-16 17:06:57.458955: step 1829, loss = 0.69533 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:06:58.444377 ops/training.py:65 2019-01-16 17:06:58.444268: step 1830, loss = 0.69158 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:06:59.426949 ops/training.py:65 2019-01-16 17:06:59.426841: step 1831, loss = 0.70317 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:07:00.412240 ops/training.py:65 2019-01-16 17:07:00.412134: step 1832, loss = 0.71353 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:07:01.397314 ops/training.py:65 2019-01-16 17:07:01.397206: step 1833, loss = 0.69559 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:07:02.382480 ops/training.py:65 2019-01-16 17:07:02.382395: step 1834, loss = 0.70072 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:07:03.367875 ops/training.py:65 2019-01-16 17:07:03.367790: step 1835, loss = 0.70258 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:07:04.351637 ops/training.py:65 2019-01-16 17:07:04.351556: step 1836, loss = 0.68659 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:07:05.334890 ops/training.py:65 2019-01-16 17:07:05.334799: step 1837, loss = 0.69232 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:07:06.317655 ops/training.py:65 2019-01-16 17:07:06.317577: step 1838, loss = 0.70278 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:07:07.301254 ops/training.py:65 2019-01-16 17:07:07.301185: step 1839, loss = 0.69964 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:07:08.286601 ops/training.py:65 2019-01-16 17:07:08.286498: step 1840, loss = 0.68121 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:07:09.272813 ops/training.py:65 2019-01-16 17:07:09.272705: step 1841, loss = 0.67832 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:07:10.258276 ops/training.py:65 2019-01-16 17:07:10.258171: step 1842, loss = 0.69777 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:07:11.245183 ops/training.py:65 2019-01-16 17:07:11.245081: step 1843, loss = 0.69411 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:07:12.230152 ops/training.py:65 2019-01-16 17:07:12.230048: step 1844, loss = 0.67545 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:07:13.214244 ops/training.py:65 2019-01-16 17:07:13.214184: step 1845, loss = 0.68109 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:07:14.198484 ops/training.py:65 2019-01-16 17:07:14.198395: step 1846, loss = 0.68595 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:07:15.182265 ops/training.py:65 2019-01-16 17:07:15.182167: step 1847, loss = 0.69637 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:07:16.165542 ops/training.py:65 2019-01-16 17:07:16.165495: step 1848, loss = 0.69694 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:07:17.147869 ops/training.py:65 2019-01-16 17:07:17.147827: step 1849, loss = 0.71445 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:07:18.130181 ops/training.py:65 2019-01-16 17:07:18.130145: step 1850, loss = 0.72362 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:07:19.112012 ops/training.py:65 2019-01-16 17:07:19.111974: step 1851, loss = 0.71913 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:07:20.092706 ops/training.py:65 2019-01-16 17:07:20.092668: step 1852, loss = 0.68725 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:07:21.075226 ops/training.py:65 2019-01-16 17:07:21.075163: step 1853, loss = 0.68780 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:07:22.057116 ops/training.py:65 2019-01-16 17:07:22.057018: step 1854, loss = 0.70086 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:07:23.041256 ops/training.py:65 2019-01-16 17:07:23.041189: step 1855, loss = 0.70395 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:07:24.024282 ops/training.py:65 2019-01-16 17:07:24.024242: step 1856, loss = 0.68433 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:07:25.006630 ops/training.py:65 2019-01-16 17:07:25.006589: step 1857, loss = 0.67968 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:07:25.987928 ops/training.py:65 2019-01-16 17:07:25.987863: step 1858, loss = 0.69394 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:07:26.970725 ops/training.py:65 2019-01-16 17:07:26.970683: step 1859, loss = 0.70588 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:07:27.956041 ops/training.py:65 2019-01-16 17:07:27.955987: step 1860, loss = 0.68628 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:07:28.939209 ops/training.py:65 2019-01-16 17:07:28.939160: step 1861, loss = 0.71397 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:07:29.925547 ops/training.py:65 2019-01-16 17:07:29.925489: step 1862, loss = 0.70780 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:07:30.909214 ops/training.py:65 2019-01-16 17:07:30.909137: step 1863, loss = 0.67697 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:07:31.894033 ops/training.py:65 2019-01-16 17:07:31.893974: step 1864, loss = 0.69068 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:07:32.878236 ops/training.py:65 2019-01-16 17:07:32.878196: step 1865, loss = 0.70920 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:07:33.860371 ops/training.py:65 2019-01-16 17:07:33.860333: step 1866, loss = 0.72915 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:07:34.844128 ops/training.py:65 2019-01-16 17:07:34.844088: step 1867, loss = 0.71426 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:07:35.827983 ops/training.py:65 2019-01-16 17:07:35.827943: step 1868, loss = 0.67702 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:07:36.812254 ops/training.py:65 2019-01-16 17:07:36.812216: step 1869, loss = 0.69662 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:07:37.796675 ops/training.py:65 2019-01-16 17:07:37.796640: step 1870, loss = 0.72081 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:07:38.780966 ops/training.py:65 2019-01-16 17:07:38.780933: step 1871, loss = 0.68167 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:07:39.765665 ops/training.py:65 2019-01-16 17:07:39.765630: step 1872, loss = 0.71598 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:07:40.749918 ops/training.py:65 2019-01-16 17:07:40.749879: step 1873, loss = 0.69347 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:07:41.732411 ops/training.py:65 2019-01-16 17:07:41.732354: step 1874, loss = 0.68884 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:07:42.716216 ops/training.py:65 2019-01-16 17:07:42.716176: step 1875, loss = 0.72516 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:07:43.699212 ops/training.py:65 2019-01-16 17:07:43.699168: step 1876, loss = 0.68011 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:07:44.684822 ops/training.py:65 2019-01-16 17:07:44.684785: step 1877, loss = 0.69293 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:07:45.670739 ops/training.py:65 2019-01-16 17:07:45.670688: step 1878, loss = 0.71607 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:07:46.655524 ops/training.py:65 2019-01-16 17:07:46.655492: step 1879, loss = 0.69374 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:07:47.639197 ops/training.py:65 2019-01-16 17:07:47.639129: step 1880, loss = 0.65158 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 17:07:48.622056 ops/training.py:65 2019-01-16 17:07:48.621988: step 1881, loss = 0.69840 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:07:49.604626 ops/training.py:65 2019-01-16 17:07:49.604553: step 1882, loss = 0.69048 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:07:50.586777 ops/training.py:65 2019-01-16 17:07:50.586701: step 1883, loss = 0.69974 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:07:51.568929 ops/training.py:65 2019-01-16 17:07:51.568892: step 1884, loss = 0.66344 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:07:52.551297 ops/training.py:65 2019-01-16 17:07:52.551264: step 1885, loss = 0.71691 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:07:53.533446 ops/training.py:65 2019-01-16 17:07:53.533348: step 1886, loss = 0.66778 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:07:54.519191 ops/training.py:65 2019-01-16 17:07:54.519152: step 1887, loss = 0.70800 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:07:55.502723 ops/training.py:65 2019-01-16 17:07:55.502683: step 1888, loss = 0.72060 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:07:56.486273 ops/training.py:65 2019-01-16 17:07:56.486228: step 1889, loss = 0.67502 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:07:57.471435 ops/training.py:65 2019-01-16 17:07:57.471396: step 1890, loss = 0.67792 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:07:58.454571 ops/training.py:65 2019-01-16 17:07:58.454537: step 1891, loss = 0.70668 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:07:59.436116 ops/training.py:65 2019-01-16 17:07:59.436057: step 1892, loss = 0.72361 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:08:00.418133 ops/training.py:65 2019-01-16 17:08:00.418049: step 1893, loss = 0.69893 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:08:01.400282 ops/training.py:65 2019-01-16 17:08:01.400211: step 1894, loss = 0.71653 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:08:02.383448 ops/training.py:65 2019-01-16 17:08:02.383356: step 1895, loss = 0.68493 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:08:03.367656 ops/training.py:65 2019-01-16 17:08:03.367576: step 1896, loss = 0.72351 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:08:04.350545 ops/training.py:65 2019-01-16 17:08:04.350442: step 1897, loss = 0.68371 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:08:05.334949 ops/training.py:65 2019-01-16 17:08:05.334843: step 1898, loss = 0.70392 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:08:06.318860 ops/training.py:65 2019-01-16 17:08:06.318748: step 1899, loss = 0.70958 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:08:07.303117 ops/training.py:65 2019-01-16 17:08:07.303012: step 1900, loss = 0.70456 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:08:08.287724 ops/training.py:65 2019-01-16 17:08:08.287614: step 1901, loss = 0.68898 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:08:09.271994 ops/training.py:65 2019-01-16 17:08:09.271895: step 1902, loss = 0.69646 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:08:10.256738 ops/training.py:65 2019-01-16 17:08:10.256628: step 1903, loss = 0.70333 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:08:11.240944 ops/training.py:65 2019-01-16 17:08:11.240866: step 1904, loss = 0.69552 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:08:12.224446 ops/training.py:65 2019-01-16 17:08:12.224340: step 1905, loss = 0.69891 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:08:13.207799 ops/training.py:65 2019-01-16 17:08:13.207697: step 1906, loss = 0.69410 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:08:14.191402 ops/training.py:65 2019-01-16 17:08:14.191304: step 1907, loss = 0.67062 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:08:15.175733 ops/training.py:65 2019-01-16 17:08:15.175624: step 1908, loss = 0.68585 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:08:16.160900 ops/training.py:65 2019-01-16 17:08:16.160800: step 1909, loss = 0.69659 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:08:17.145597 ops/training.py:65 2019-01-16 17:08:17.145493: step 1910, loss = 0.68773 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:08:18.130038 ops/training.py:65 2019-01-16 17:08:18.129925: step 1911, loss = 0.70096 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:08:19.113258 ops/training.py:65 2019-01-16 17:08:19.113163: step 1912, loss = 0.70132 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:08:20.095485 ops/training.py:65 2019-01-16 17:08:20.095380: step 1913, loss = 0.68875 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:08:21.076686 ops/training.py:65 2019-01-16 17:08:21.076582: step 1914, loss = 0.69756 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:08:22.059197 ops/training.py:65 2019-01-16 17:08:22.059088: step 1915, loss = 0.69473 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:08:23.040662 ops/training.py:65 2019-01-16 17:08:23.040566: step 1916, loss = 0.66789 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.78125
I8192 2019-01-16 17:08:24.023325 ops/training.py:65 2019-01-16 17:08:24.023216: step 1917, loss = 0.70731 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:08:25.005010 ops/training.py:65 2019-01-16 17:08:25.004911: step 1918, loss = 0.70376 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:08:25.985814 ops/training.py:65 2019-01-16 17:08:25.985719: step 1919, loss = 0.69626 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:08:26.968998 ops/training.py:65 2019-01-16 17:08:26.968899: step 1920, loss = 0.71017 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:08:27.952968 ops/training.py:65 2019-01-16 17:08:27.952860: step 1921, loss = 0.69556 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:08:28.936237 ops/training.py:65 2019-01-16 17:08:28.936133: step 1922, loss = 0.68649 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:08:29.921481 ops/training.py:65 2019-01-16 17:08:29.921372: step 1923, loss = 0.71565 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:08:30.904306 ops/training.py:65 2019-01-16 17:08:30.904206: step 1924, loss = 0.69757 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:08:31.886483 ops/training.py:65 2019-01-16 17:08:31.886375: step 1925, loss = 0.66170 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:08:32.868269 ops/training.py:65 2019-01-16 17:08:32.868170: step 1926, loss = 0.69963 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:08:33.851269 ops/training.py:65 2019-01-16 17:08:33.851175: step 1927, loss = 0.70320 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:08:34.832578 ops/training.py:65 2019-01-16 17:08:34.832479: step 1928, loss = 0.70616 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:08:35.815025 ops/training.py:65 2019-01-16 17:08:35.814931: step 1929, loss = 0.70669 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:08:36.796884 ops/training.py:65 2019-01-16 17:08:36.796779: step 1930, loss = 0.68065 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:08:37.778409 ops/training.py:65 2019-01-16 17:08:37.778307: step 1931, loss = 0.68371 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:08:38.760596 ops/training.py:65 2019-01-16 17:08:38.760491: step 1932, loss = 0.70040 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:08:39.742679 ops/training.py:65 2019-01-16 17:08:39.742575: step 1933, loss = 0.69354 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:08:40.725372 ops/training.py:65 2019-01-16 17:08:40.725269: step 1934, loss = 0.71658 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:08:41.707235 ops/training.py:65 2019-01-16 17:08:41.707130: step 1935, loss = 0.69970 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:08:42.689397 ops/training.py:65 2019-01-16 17:08:42.689294: step 1936, loss = 0.70833 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:08:43.671382 ops/training.py:65 2019-01-16 17:08:43.671272: step 1937, loss = 0.68382 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:08:44.652865 ops/training.py:65 2019-01-16 17:08:44.652766: step 1938, loss = 0.70549 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:08:45.635527 ops/training.py:65 2019-01-16 17:08:45.635424: step 1939, loss = 0.68612 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:08:46.618175 ops/training.py:65 2019-01-16 17:08:46.618077: step 1940, loss = 0.69365 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:08:47.600012 ops/training.py:65 2019-01-16 17:08:47.599862: step 1941, loss = 0.67394 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:08:48.584908 ops/training.py:65 2019-01-16 17:08:48.584824: step 1942, loss = 0.69595 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:08:49.568741 ops/training.py:65 2019-01-16 17:08:49.568651: step 1943, loss = 0.70115 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:08:50.551607 ops/training.py:65 2019-01-16 17:08:50.551517: step 1944, loss = 0.70720 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:08:51.536437 ops/training.py:65 2019-01-16 17:08:51.536332: step 1945, loss = 0.65949 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:08:52.520175 ops/training.py:65 2019-01-16 17:08:52.520070: step 1946, loss = 0.68430 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:08:53.502252 ops/training.py:65 2019-01-16 17:08:53.502149: step 1947, loss = 0.68662 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:08:54.483352 ops/training.py:65 2019-01-16 17:08:54.483246: step 1948, loss = 0.67684 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:08:55.464528 ops/training.py:65 2019-01-16 17:08:55.464424: step 1949, loss = 0.70046 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:08:56.446350 ops/training.py:65 2019-01-16 17:08:56.446252: step 1950, loss = 0.71268 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:08:57.429729 ops/training.py:65 2019-01-16 17:08:57.429628: step 1951, loss = 0.72031 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:08:58.414103 ops/training.py:65 2019-01-16 17:08:58.414003: step 1952, loss = 0.67823 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:08:59.397477 ops/training.py:65 2019-01-16 17:08:59.397371: step 1953, loss = 0.71987 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:09:00.379112 ops/training.py:65 2019-01-16 17:09:00.379007: step 1954, loss = 0.66639 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:09:01.361598 ops/training.py:65 2019-01-16 17:09:01.361491: step 1955, loss = 0.68537 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:09:02.346039 ops/training.py:65 2019-01-16 17:09:02.345940: step 1956, loss = 0.67857 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:09:03.330558 ops/training.py:65 2019-01-16 17:09:03.330458: step 1957, loss = 0.73518 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:09:04.315693 ops/training.py:65 2019-01-16 17:09:04.315582: step 1958, loss = 0.66608 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:09:05.300791 ops/training.py:65 2019-01-16 17:09:05.300690: step 1959, loss = 0.69575 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:09:06.284942 ops/training.py:65 2019-01-16 17:09:06.284843: step 1960, loss = 0.69375 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:09:07.268855 ops/training.py:65 2019-01-16 17:09:07.268745: step 1961, loss = 0.70127 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:09:08.251003 ops/training.py:65 2019-01-16 17:09:08.250897: step 1962, loss = 0.68207 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:09:09.232957 ops/training.py:65 2019-01-16 17:09:09.232856: step 1963, loss = 0.68407 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:09:10.214302 ops/training.py:65 2019-01-16 17:09:10.214199: step 1964, loss = 0.70152 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:09:11.195235 ops/training.py:65 2019-01-16 17:09:11.195141: step 1965, loss = 0.67799 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:09:12.176025 ops/training.py:65 2019-01-16 17:09:12.175921: step 1966, loss = 0.68191 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:09:13.158318 ops/training.py:65 2019-01-16 17:09:13.158215: step 1967, loss = 0.69617 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:09:14.142501 ops/training.py:65 2019-01-16 17:09:14.142407: step 1968, loss = 0.66609 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:09:15.126992 ops/training.py:65 2019-01-16 17:09:15.126883: step 1969, loss = 0.68213 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:09:16.112845 ops/training.py:65 2019-01-16 17:09:16.112758: step 1970, loss = 0.71414 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:09:17.097032 ops/training.py:65 2019-01-16 17:09:17.096892: step 1971, loss = 0.73192 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.25
I8192 2019-01-16 17:09:18.082382 ops/training.py:65 2019-01-16 17:09:18.082273: step 1972, loss = 0.68168 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:09:19.066769 ops/training.py:65 2019-01-16 17:09:19.066677: step 1973, loss = 0.68423 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:09:20.050388 ops/training.py:65 2019-01-16 17:09:20.050288: step 1974, loss = 0.70052 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:09:21.034869 ops/training.py:65 2019-01-16 17:09:21.034786: step 1975, loss = 0.69908 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:09:22.017959 ops/training.py:65 2019-01-16 17:09:22.017917: step 1976, loss = 0.68519 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:09:23.000366 ops/training.py:65 2019-01-16 17:09:23.000318: step 1977, loss = 0.70624 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:09:23.982775 ops/training.py:65 2019-01-16 17:09:23.982671: step 1978, loss = 0.69874 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:09:24.965400 ops/training.py:65 2019-01-16 17:09:24.965291: step 1979, loss = 0.68970 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:09:25.949581 ops/training.py:65 2019-01-16 17:09:25.949540: step 1980, loss = 0.70323 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:09:26.932943 ops/training.py:65 2019-01-16 17:09:26.932896: step 1981, loss = 0.70601 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:09:27.915889 ops/training.py:65 2019-01-16 17:09:27.915812: step 1982, loss = 0.69255 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:09:28.899854 ops/training.py:65 2019-01-16 17:09:28.899808: step 1983, loss = 0.69245 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:09:29.882720 ops/training.py:65 2019-01-16 17:09:29.882681: step 1984, loss = 0.70888 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:09:30.864875 ops/training.py:65 2019-01-16 17:09:30.864835: step 1985, loss = 0.67936 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:09:31.845613 ops/training.py:65 2019-01-16 17:09:31.845548: step 1986, loss = 0.69147 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:09:32.827562 ops/training.py:65 2019-01-16 17:09:32.827462: step 1987, loss = 0.70302 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:09:33.812290 ops/training.py:65 2019-01-16 17:09:33.812201: step 1988, loss = 0.69263 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:09:34.797442 ops/training.py:65 2019-01-16 17:09:34.797344: step 1989, loss = 0.70906 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:09:35.781984 ops/training.py:65 2019-01-16 17:09:35.781875: step 1990, loss = 0.67565 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:09:36.764985 ops/training.py:65 2019-01-16 17:09:36.764881: step 1991, loss = 0.68685 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:09:37.747210 ops/training.py:65 2019-01-16 17:09:37.747103: step 1992, loss = 0.70036 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:09:38.730647 ops/training.py:65 2019-01-16 17:09:38.730561: step 1993, loss = 0.70016 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:09:39.716126 ops/training.py:65 2019-01-16 17:09:39.716027: step 1994, loss = 0.71102 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:09:40.699145 ops/training.py:65 2019-01-16 17:09:40.699049: step 1995, loss = 0.66560 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.75
I8192 2019-01-16 17:09:41.683481 ops/training.py:65 2019-01-16 17:09:41.683382: step 1996, loss = 0.69022 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:09:42.666626 ops/training.py:65 2019-01-16 17:09:42.666527: step 1997, loss = 0.70918 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:09:43.650452 ops/training.py:65 2019-01-16 17:09:43.650348: step 1998, loss = 0.68711 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:09:44.633056 ops/training.py:65 2019-01-16 17:09:44.632953: step 1999, loss = 0.68828 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:14:29.157102 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I8192 2019-01-16 17:14:29.158249 ops/training.py:41 2019-01-16 17:14:29.158051: step 2000, loss = 0.70 (0.1 examples/sec; 283.539 sec/batch) | Training accuracy = 0.53125 | Validation accuracy = 0.4928 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_16_30_45_270295
I8192 2019-01-16 17:14:30.144903 ops/training.py:65 2019-01-16 17:14:30.144790: step 2001, loss = 0.69019 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:14:31.130694 ops/training.py:65 2019-01-16 17:14:31.130607: step 2002, loss = 0.68484 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:14:32.116063 ops/training.py:65 2019-01-16 17:14:32.115954: step 2003, loss = 0.70044 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:14:33.100154 ops/training.py:65 2019-01-16 17:14:33.100053: step 2004, loss = 0.68722 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:14:34.084532 ops/training.py:65 2019-01-16 17:14:34.084429: step 2005, loss = 0.70071 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:14:35.068356 ops/training.py:65 2019-01-16 17:14:35.068271: step 2006, loss = 0.70274 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:14:36.050942 ops/training.py:65 2019-01-16 17:14:36.050863: step 2007, loss = 0.67671 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:14:37.034637 ops/training.py:65 2019-01-16 17:14:37.034537: step 2008, loss = 0.68985 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:14:38.019621 ops/training.py:65 2019-01-16 17:14:38.019515: step 2009, loss = 0.69094 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:14:39.002562 ops/training.py:65 2019-01-16 17:14:39.002457: step 2010, loss = 0.67857 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:14:39.987974 ops/training.py:65 2019-01-16 17:14:39.987863: step 2011, loss = 0.69130 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:14:40.973900 ops/training.py:65 2019-01-16 17:14:40.973791: step 2012, loss = 0.70992 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:14:41.958114 ops/training.py:65 2019-01-16 17:14:41.958026: step 2013, loss = 0.68248 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:14:42.942184 ops/training.py:65 2019-01-16 17:14:42.942090: step 2014, loss = 0.69233 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:14:43.926539 ops/training.py:65 2019-01-16 17:14:43.926447: step 2015, loss = 0.66816 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 17:14:44.910625 ops/training.py:65 2019-01-16 17:14:44.910534: step 2016, loss = 0.68897 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:14:45.893948 ops/training.py:65 2019-01-16 17:14:45.893858: step 2017, loss = 0.70884 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:14:46.876036 ops/training.py:65 2019-01-16 17:14:46.875936: step 2018, loss = 0.69834 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:14:47.858866 ops/training.py:65 2019-01-16 17:14:47.858769: step 2019, loss = 0.70121 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:14:48.841769 ops/training.py:65 2019-01-16 17:14:48.841634: step 2020, loss = 0.68910 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:14:49.824423 ops/training.py:65 2019-01-16 17:14:49.824329: step 2021, loss = 0.70257 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:14:50.810609 ops/training.py:65 2019-01-16 17:14:50.810504: step 2022, loss = 0.69106 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:14:51.794993 ops/training.py:65 2019-01-16 17:14:51.794890: step 2023, loss = 0.69620 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:14:52.781339 ops/training.py:65 2019-01-16 17:14:52.781241: step 2024, loss = 0.69007 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:14:53.767338 ops/training.py:65 2019-01-16 17:14:53.767236: step 2025, loss = 0.69830 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:14:54.751635 ops/training.py:65 2019-01-16 17:14:54.751541: step 2026, loss = 0.69304 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:14:55.734934 ops/training.py:65 2019-01-16 17:14:55.734824: step 2027, loss = 0.69826 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:14:56.718469 ops/training.py:65 2019-01-16 17:14:56.718365: step 2028, loss = 0.70995 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:14:57.701831 ops/training.py:65 2019-01-16 17:14:57.701723: step 2029, loss = 0.70711 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:14:58.684382 ops/training.py:65 2019-01-16 17:14:58.684299: step 2030, loss = 0.70771 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:14:59.668664 ops/training.py:65 2019-01-16 17:14:59.668572: step 2031, loss = 0.68603 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:15:00.653925 ops/training.py:65 2019-01-16 17:15:00.653829: step 2032, loss = 0.69346 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:15:01.639795 ops/training.py:65 2019-01-16 17:15:01.639717: step 2033, loss = 0.69900 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:15:02.623808 ops/training.py:65 2019-01-16 17:15:02.623698: step 2034, loss = 0.70610 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:15:03.607361 ops/training.py:65 2019-01-16 17:15:03.607263: step 2035, loss = 0.69743 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:15:04.592491 ops/training.py:65 2019-01-16 17:15:04.592396: step 2036, loss = 0.70914 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:15:05.576016 ops/training.py:65 2019-01-16 17:15:05.575911: step 2037, loss = 0.69226 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:15:06.559300 ops/training.py:65 2019-01-16 17:15:06.559193: step 2038, loss = 0.70455 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 17:15:07.542393 ops/training.py:65 2019-01-16 17:15:07.542287: step 2039, loss = 0.68499 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:15:08.523935 ops/training.py:65 2019-01-16 17:15:08.523859: step 2040, loss = 0.69377 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:15:09.503899 ops/training.py:65 2019-01-16 17:15:09.503825: step 2041, loss = 0.69933 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:15:10.486423 ops/training.py:65 2019-01-16 17:15:10.486343: step 2042, loss = 0.70082 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:15:11.469516 ops/training.py:65 2019-01-16 17:15:11.469453: step 2043, loss = 0.70648 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:15:12.452852 ops/training.py:65 2019-01-16 17:15:12.452746: step 2044, loss = 0.68261 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:15:13.436322 ops/training.py:65 2019-01-16 17:15:13.436222: step 2045, loss = 0.67661 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:15:14.418692 ops/training.py:65 2019-01-16 17:15:14.418588: step 2046, loss = 0.66975 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:15:15.402119 ops/training.py:65 2019-01-16 17:15:15.402009: step 2047, loss = 0.69122 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:15:16.385467 ops/training.py:65 2019-01-16 17:15:16.385362: step 2048, loss = 0.68900 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:15:17.369561 ops/training.py:65 2019-01-16 17:15:17.369415: step 2049, loss = 0.70428 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:15:18.353501 ops/training.py:65 2019-01-16 17:15:18.353394: step 2050, loss = 0.70287 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:15:19.340228 ops/training.py:65 2019-01-16 17:15:19.340135: step 2051, loss = 0.67377 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:15:20.323277 ops/training.py:65 2019-01-16 17:15:20.323171: step 2052, loss = 0.69492 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:15:21.305983 ops/training.py:65 2019-01-16 17:15:21.305914: step 2053, loss = 0.70604 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:15:22.290356 ops/training.py:65 2019-01-16 17:15:22.290260: step 2054, loss = 0.69266 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:15:23.273747 ops/training.py:65 2019-01-16 17:15:23.273639: step 2055, loss = 0.68804 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:15:24.256122 ops/training.py:65 2019-01-16 17:15:24.256013: step 2056, loss = 0.71565 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:15:25.238660 ops/training.py:65 2019-01-16 17:15:25.238560: step 2057, loss = 0.68540 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:15:26.221949 ops/training.py:65 2019-01-16 17:15:26.221842: step 2058, loss = 0.69823 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:15:27.205386 ops/training.py:65 2019-01-16 17:15:27.205285: step 2059, loss = 0.67816 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 17:15:28.191545 ops/training.py:65 2019-01-16 17:15:28.191441: step 2060, loss = 0.67833 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.75
I8192 2019-01-16 17:15:29.176089 ops/training.py:65 2019-01-16 17:15:29.175984: step 2061, loss = 0.70020 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:15:30.161136 ops/training.py:65 2019-01-16 17:15:30.161027: step 2062, loss = 0.68252 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:15:31.147502 ops/training.py:65 2019-01-16 17:15:31.147393: step 2063, loss = 0.70268 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:15:32.132863 ops/training.py:65 2019-01-16 17:15:32.132756: step 2064, loss = 0.68841 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:15:33.118875 ops/training.py:65 2019-01-16 17:15:33.118769: step 2065, loss = 0.68432 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:15:34.104705 ops/training.py:65 2019-01-16 17:15:34.104600: step 2066, loss = 0.69986 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:15:35.087609 ops/training.py:65 2019-01-16 17:15:35.087510: step 2067, loss = 0.70775 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:15:36.070786 ops/training.py:65 2019-01-16 17:15:36.070678: step 2068, loss = 0.68013 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:15:37.054452 ops/training.py:65 2019-01-16 17:15:37.054343: step 2069, loss = 0.68326 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:15:38.037208 ops/training.py:65 2019-01-16 17:15:38.037099: step 2070, loss = 0.69930 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:15:39.019946 ops/training.py:65 2019-01-16 17:15:39.019842: step 2071, loss = 0.69312 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:15:40.001425 ops/training.py:65 2019-01-16 17:15:40.001348: step 2072, loss = 0.69080 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:15:40.984393 ops/training.py:65 2019-01-16 17:15:40.984322: step 2073, loss = 0.69995 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:15:41.970410 ops/training.py:65 2019-01-16 17:15:41.970301: step 2074, loss = 0.70304 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:15:42.953799 ops/training.py:65 2019-01-16 17:15:42.953707: step 2075, loss = 0.68633 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:15:43.936019 ops/training.py:65 2019-01-16 17:15:43.935916: step 2076, loss = 0.69325 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:15:44.918679 ops/training.py:65 2019-01-16 17:15:44.918571: step 2077, loss = 0.69643 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:15:45.903147 ops/training.py:65 2019-01-16 17:15:45.903038: step 2078, loss = 0.69695 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:15:46.889335 ops/training.py:65 2019-01-16 17:15:46.889229: step 2079, loss = 0.69109 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:15:47.874246 ops/training.py:65 2019-01-16 17:15:47.874145: step 2080, loss = 0.70405 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:15:48.857519 ops/training.py:65 2019-01-16 17:15:48.857407: step 2081, loss = 0.68218 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:15:49.840483 ops/training.py:65 2019-01-16 17:15:49.840382: step 2082, loss = 0.70595 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:15:50.824388 ops/training.py:65 2019-01-16 17:15:50.824283: step 2083, loss = 0.68020 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:15:51.807892 ops/training.py:65 2019-01-16 17:15:51.807782: step 2084, loss = 0.69971 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:15:52.793849 ops/training.py:65 2019-01-16 17:15:52.793749: step 2085, loss = 0.69539 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:15:53.778754 ops/training.py:65 2019-01-16 17:15:53.778660: step 2086, loss = 0.70908 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:15:54.763450 ops/training.py:65 2019-01-16 17:15:54.763342: step 2087, loss = 0.69861 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:15:55.746186 ops/training.py:65 2019-01-16 17:15:55.746080: step 2088, loss = 0.68012 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:15:56.728965 ops/training.py:65 2019-01-16 17:15:56.728860: step 2089, loss = 0.67603 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:15:57.712586 ops/training.py:65 2019-01-16 17:15:57.712476: step 2090, loss = 0.68931 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:15:58.696517 ops/training.py:65 2019-01-16 17:15:58.696424: step 2091, loss = 0.70670 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:15:59.679103 ops/training.py:65 2019-01-16 17:15:59.678998: step 2092, loss = 0.66636 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:16:00.661201 ops/training.py:65 2019-01-16 17:16:00.661100: step 2093, loss = 0.69386 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:16:01.643345 ops/training.py:65 2019-01-16 17:16:01.643246: step 2094, loss = 0.69052 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:16:02.626829 ops/training.py:65 2019-01-16 17:16:02.626730: step 2095, loss = 0.69279 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:16:03.610875 ops/training.py:65 2019-01-16 17:16:03.610774: step 2096, loss = 0.70576 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:16:04.596269 ops/training.py:65 2019-01-16 17:16:04.596177: step 2097, loss = 0.67794 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:16:05.580041 ops/training.py:65 2019-01-16 17:16:05.579933: step 2098, loss = 0.67421 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:16:06.563770 ops/training.py:65 2019-01-16 17:16:06.563669: step 2099, loss = 0.73106 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 17:16:07.546285 ops/training.py:65 2019-01-16 17:16:07.546178: step 2100, loss = 0.65462 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:16:08.529142 ops/training.py:65 2019-01-16 17:16:08.529032: step 2101, loss = 0.66274 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:16:09.511114 ops/training.py:65 2019-01-16 17:16:09.511008: step 2102, loss = 0.68490 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:16:10.494085 ops/training.py:65 2019-01-16 17:16:10.493995: step 2103, loss = 0.69806 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:16:11.477190 ops/training.py:65 2019-01-16 17:16:11.477094: step 2104, loss = 0.69261 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:16:12.462211 ops/training.py:65 2019-01-16 17:16:12.462104: step 2105, loss = 0.70405 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:16:13.445144 ops/training.py:65 2019-01-16 17:16:13.445051: step 2106, loss = 0.67225 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:16:14.428556 ops/training.py:65 2019-01-16 17:16:14.428450: step 2107, loss = 0.69905 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:16:15.411070 ops/training.py:65 2019-01-16 17:16:15.410976: step 2108, loss = 0.70347 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:16:16.393477 ops/training.py:65 2019-01-16 17:16:16.393387: step 2109, loss = 0.68444 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:16:17.376112 ops/training.py:65 2019-01-16 17:16:17.376004: step 2110, loss = 0.74884 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 17:16:18.360341 ops/training.py:65 2019-01-16 17:16:18.360237: step 2111, loss = 0.67109 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:16:19.342870 ops/training.py:65 2019-01-16 17:16:19.342774: step 2112, loss = 0.65212 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:16:20.325557 ops/training.py:65 2019-01-16 17:16:20.325450: step 2113, loss = 0.70408 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:16:21.308291 ops/training.py:65 2019-01-16 17:16:21.308198: step 2114, loss = 0.73136 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:16:22.290976 ops/training.py:65 2019-01-16 17:16:22.290864: step 2115, loss = 0.70778 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:16:23.273456 ops/training.py:65 2019-01-16 17:16:23.273351: step 2116, loss = 0.69828 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:16:24.256101 ops/training.py:65 2019-01-16 17:16:24.256012: step 2117, loss = 0.70366 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:16:25.239041 ops/training.py:65 2019-01-16 17:16:25.238954: step 2118, loss = 0.69194 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:16:26.222346 ops/training.py:65 2019-01-16 17:16:26.222241: step 2119, loss = 0.69118 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:16:27.205034 ops/training.py:65 2019-01-16 17:16:27.204928: step 2120, loss = 0.66796 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:16:28.187708 ops/training.py:65 2019-01-16 17:16:28.187603: step 2121, loss = 0.70440 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:16:29.171460 ops/training.py:65 2019-01-16 17:16:29.171356: step 2122, loss = 0.72404 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:16:30.153968 ops/training.py:65 2019-01-16 17:16:30.153865: step 2123, loss = 0.70773 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:16:31.136013 ops/training.py:65 2019-01-16 17:16:31.135906: step 2124, loss = 0.70525 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:16:32.118261 ops/training.py:65 2019-01-16 17:16:32.118178: step 2125, loss = 0.70753 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:16:33.102097 ops/training.py:65 2019-01-16 17:16:33.102003: step 2126, loss = 0.71826 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:16:34.086712 ops/training.py:65 2019-01-16 17:16:34.086611: step 2127, loss = 0.69629 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:16:35.073117 ops/training.py:65 2019-01-16 17:16:35.073012: step 2128, loss = 0.71413 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:16:36.058892 ops/training.py:65 2019-01-16 17:16:36.058795: step 2129, loss = 0.72679 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:16:37.042901 ops/training.py:65 2019-01-16 17:16:37.042804: step 2130, loss = 0.70483 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:16:38.027540 ops/training.py:65 2019-01-16 17:16:38.027439: step 2131, loss = 0.70872 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:16:39.010075 ops/training.py:65 2019-01-16 17:16:39.009976: step 2132, loss = 0.70762 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:16:39.992812 ops/training.py:65 2019-01-16 17:16:39.992706: step 2133, loss = 0.69688 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:16:40.975867 ops/training.py:65 2019-01-16 17:16:40.975766: step 2134, loss = 0.71417 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:16:41.958231 ops/training.py:65 2019-01-16 17:16:41.958132: step 2135, loss = 0.68665 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:16:42.939977 ops/training.py:65 2019-01-16 17:16:42.939872: step 2136, loss = 0.69468 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:16:43.923933 ops/training.py:65 2019-01-16 17:16:43.923827: step 2137, loss = 0.71328 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:16:44.908271 ops/training.py:65 2019-01-16 17:16:44.908165: step 2138, loss = 0.69872 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:16:45.891975 ops/training.py:65 2019-01-16 17:16:45.891871: step 2139, loss = 0.68843 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:16:46.874507 ops/training.py:65 2019-01-16 17:16:46.874423: step 2140, loss = 0.70669 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:16:47.858042 ops/training.py:65 2019-01-16 17:16:47.857962: step 2141, loss = 0.68351 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:16:48.841834 ops/training.py:65 2019-01-16 17:16:48.841725: step 2142, loss = 0.69210 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:16:49.825454 ops/training.py:65 2019-01-16 17:16:49.825363: step 2143, loss = 0.69303 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:16:50.807355 ops/training.py:65 2019-01-16 17:16:50.807257: step 2144, loss = 0.68752 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:16:51.790065 ops/training.py:65 2019-01-16 17:16:51.789956: step 2145, loss = 0.69340 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:16:52.777762 ops/training.py:65 2019-01-16 17:16:52.777660: step 2146, loss = 0.69321 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:16:53.764001 ops/training.py:65 2019-01-16 17:16:53.763904: step 2147, loss = 0.68189 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:16:54.748545 ops/training.py:65 2019-01-16 17:16:54.748446: step 2148, loss = 0.70422 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:16:55.732564 ops/training.py:65 2019-01-16 17:16:55.732466: step 2149, loss = 0.68939 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:16:56.716764 ops/training.py:65 2019-01-16 17:16:56.716661: step 2150, loss = 0.69097 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:16:57.700808 ops/training.py:65 2019-01-16 17:16:57.700700: step 2151, loss = 0.68338 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:16:58.685508 ops/training.py:65 2019-01-16 17:16:58.685408: step 2152, loss = 0.69240 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:16:59.668815 ops/training.py:65 2019-01-16 17:16:59.668729: step 2153, loss = 0.68406 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:17:00.650949 ops/training.py:65 2019-01-16 17:17:00.650843: step 2154, loss = 0.68676 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:17:01.633022 ops/training.py:65 2019-01-16 17:17:01.632919: step 2155, loss = 0.68988 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:17:02.615040 ops/training.py:65 2019-01-16 17:17:02.614936: step 2156, loss = 0.69678 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:17:03.597768 ops/training.py:65 2019-01-16 17:17:03.597664: step 2157, loss = 0.69415 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:17:04.579819 ops/training.py:65 2019-01-16 17:17:04.579723: step 2158, loss = 0.68052 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:17:05.561739 ops/training.py:65 2019-01-16 17:17:05.561636: step 2159, loss = 0.69920 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:17:06.543684 ops/training.py:65 2019-01-16 17:17:06.543577: step 2160, loss = 0.68732 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:17:07.526489 ops/training.py:65 2019-01-16 17:17:07.526376: step 2161, loss = 0.69663 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:17:08.509254 ops/training.py:65 2019-01-16 17:17:08.509142: step 2162, loss = 0.69097 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:17:09.493016 ops/training.py:65 2019-01-16 17:17:09.492911: step 2163, loss = 0.69267 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:17:10.477850 ops/training.py:65 2019-01-16 17:17:10.477744: step 2164, loss = 0.69646 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:17:11.462810 ops/training.py:65 2019-01-16 17:17:11.462702: step 2165, loss = 0.69183 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:17:12.450274 ops/training.py:65 2019-01-16 17:17:12.450170: step 2166, loss = 0.69417 (32.4 examples/sec; 0.986 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:17:13.434941 ops/training.py:65 2019-01-16 17:17:13.434836: step 2167, loss = 0.69554 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:17:14.420406 ops/training.py:65 2019-01-16 17:17:14.420298: step 2168, loss = 0.68826 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:17:15.404653 ops/training.py:65 2019-01-16 17:17:15.404563: step 2169, loss = 0.69326 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:17:16.388823 ops/training.py:65 2019-01-16 17:17:16.388715: step 2170, loss = 0.69440 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:17:17.371460 ops/training.py:65 2019-01-16 17:17:17.371355: step 2171, loss = 0.68908 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:17:18.353881 ops/training.py:65 2019-01-16 17:17:18.353775: step 2172, loss = 0.68667 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:17:19.336123 ops/training.py:65 2019-01-16 17:17:19.336009: step 2173, loss = 0.68493 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 17:17:20.319688 ops/training.py:65 2019-01-16 17:17:20.319583: step 2174, loss = 0.70194 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:17:21.304597 ops/training.py:65 2019-01-16 17:17:21.304490: step 2175, loss = 0.70761 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:17:22.289158 ops/training.py:65 2019-01-16 17:17:22.289027: step 2176, loss = 0.69579 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:17:23.274527 ops/training.py:65 2019-01-16 17:17:23.274421: step 2177, loss = 0.71386 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:17:24.256668 ops/training.py:65 2019-01-16 17:17:24.256560: step 2178, loss = 0.69356 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:17:25.238760 ops/training.py:65 2019-01-16 17:17:25.238660: step 2179, loss = 0.69220 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:17:26.223295 ops/training.py:65 2019-01-16 17:17:26.223153: step 2180, loss = 0.69989 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:17:27.207779 ops/training.py:65 2019-01-16 17:17:27.207672: step 2181, loss = 0.69230 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:17:28.193129 ops/training.py:65 2019-01-16 17:17:28.193031: step 2182, loss = 0.69871 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:17:29.176838 ops/training.py:65 2019-01-16 17:17:29.176733: step 2183, loss = 0.67450 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:17:30.158960 ops/training.py:65 2019-01-16 17:17:30.158859: step 2184, loss = 0.69584 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:17:31.141106 ops/training.py:65 2019-01-16 17:17:31.140998: step 2185, loss = 0.69636 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:17:32.124056 ops/training.py:65 2019-01-16 17:17:32.123950: step 2186, loss = 0.67484 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:17:33.106781 ops/training.py:65 2019-01-16 17:17:33.106684: step 2187, loss = 0.69340 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:17:34.088264 ops/training.py:65 2019-01-16 17:17:34.088165: step 2188, loss = 0.69140 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:17:35.069705 ops/training.py:65 2019-01-16 17:17:35.069606: step 2189, loss = 0.69448 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:17:36.052620 ops/training.py:65 2019-01-16 17:17:36.052520: step 2190, loss = 0.69101 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:17:37.036869 ops/training.py:65 2019-01-16 17:17:37.036764: step 2191, loss = 0.69918 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:17:38.022287 ops/training.py:65 2019-01-16 17:17:38.022196: step 2192, loss = 0.69351 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:17:39.006845 ops/training.py:65 2019-01-16 17:17:39.006742: step 2193, loss = 0.68833 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:17:39.993295 ops/training.py:65 2019-01-16 17:17:39.993190: step 2194, loss = 0.69874 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:17:40.979615 ops/training.py:65 2019-01-16 17:17:40.979515: step 2195, loss = 0.69491 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:17:41.964038 ops/training.py:65 2019-01-16 17:17:41.963925: step 2196, loss = 0.69701 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:17:42.947481 ops/training.py:65 2019-01-16 17:17:42.947373: step 2197, loss = 0.70061 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:17:43.929526 ops/training.py:65 2019-01-16 17:17:43.929422: step 2198, loss = 0.69817 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:17:44.911225 ops/training.py:65 2019-01-16 17:17:44.911120: step 2199, loss = 0.68729 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:17:45.894659 ops/training.py:65 2019-01-16 17:17:45.894551: step 2200, loss = 0.69490 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:17:46.876981 ops/training.py:65 2019-01-16 17:17:46.876871: step 2201, loss = 0.69448 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:17:47.859881 ops/training.py:65 2019-01-16 17:17:47.859775: step 2202, loss = 0.69650 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:17:48.842434 ops/training.py:65 2019-01-16 17:17:48.842324: step 2203, loss = 0.69229 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:17:49.827482 ops/training.py:65 2019-01-16 17:17:49.827383: step 2204, loss = 0.68965 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:17:50.812985 ops/training.py:65 2019-01-16 17:17:50.812887: step 2205, loss = 0.70487 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:17:51.797551 ops/training.py:65 2019-01-16 17:17:51.797444: step 2206, loss = 0.70132 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:17:52.781670 ops/training.py:65 2019-01-16 17:17:52.781568: step 2207, loss = 0.68834 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:17:53.763646 ops/training.py:65 2019-01-16 17:17:53.763537: step 2208, loss = 0.69690 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:17:54.745359 ops/training.py:65 2019-01-16 17:17:54.745248: step 2209, loss = 0.69504 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:17:55.727657 ops/training.py:65 2019-01-16 17:17:55.727553: step 2210, loss = 0.68902 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:17:56.710852 ops/training.py:65 2019-01-16 17:17:56.710749: step 2211, loss = 0.70517 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:17:57.695302 ops/training.py:65 2019-01-16 17:17:57.695194: step 2212, loss = 0.70338 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:17:58.678092 ops/training.py:65 2019-01-16 17:17:58.677998: step 2213, loss = 0.67829 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:17:59.660827 ops/training.py:65 2019-01-16 17:17:59.660724: step 2214, loss = 0.69062 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:18:00.642626 ops/training.py:65 2019-01-16 17:18:00.642520: step 2215, loss = 0.69246 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:18:01.625361 ops/training.py:65 2019-01-16 17:18:01.625254: step 2216, loss = 0.68712 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:18:02.608911 ops/training.py:65 2019-01-16 17:18:02.608800: step 2217, loss = 0.72753 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:18:03.591277 ops/training.py:65 2019-01-16 17:18:03.591176: step 2218, loss = 0.69661 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:18:04.573813 ops/training.py:65 2019-01-16 17:18:04.573716: step 2219, loss = 0.69749 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:18:05.558124 ops/training.py:65 2019-01-16 17:18:05.558007: step 2220, loss = 0.67460 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:18:06.540713 ops/training.py:65 2019-01-16 17:18:06.540604: step 2221, loss = 0.69604 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:18:07.523403 ops/training.py:65 2019-01-16 17:18:07.523295: step 2222, loss = 0.70201 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:18:08.506585 ops/training.py:65 2019-01-16 17:18:08.506477: step 2223, loss = 0.71245 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:18:09.488405 ops/training.py:65 2019-01-16 17:18:09.488301: step 2224, loss = 0.70426 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:18:10.470693 ops/training.py:65 2019-01-16 17:18:10.470590: step 2225, loss = 0.69711 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:18:11.452760 ops/training.py:65 2019-01-16 17:18:11.452651: step 2226, loss = 0.67603 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:18:12.435212 ops/training.py:65 2019-01-16 17:18:12.435115: step 2227, loss = 0.68574 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:18:13.417378 ops/training.py:65 2019-01-16 17:18:13.417274: step 2228, loss = 0.72582 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:18:14.399977 ops/training.py:65 2019-01-16 17:18:14.399865: step 2229, loss = 0.68630 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:18:15.383153 ops/training.py:65 2019-01-16 17:18:15.383050: step 2230, loss = 0.68928 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:18:16.365726 ops/training.py:65 2019-01-16 17:18:16.365620: step 2231, loss = 0.68113 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:18:17.348137 ops/training.py:65 2019-01-16 17:18:17.348028: step 2232, loss = 0.70554 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:18:18.334558 ops/training.py:65 2019-01-16 17:18:18.334445: step 2233, loss = 0.68650 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:18:19.319392 ops/training.py:65 2019-01-16 17:18:19.319279: step 2234, loss = 0.69768 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:18:20.302694 ops/training.py:65 2019-01-16 17:18:20.302613: step 2235, loss = 0.69323 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:18:21.285452 ops/training.py:65 2019-01-16 17:18:21.285348: step 2236, loss = 0.68969 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:18:22.267210 ops/training.py:65 2019-01-16 17:18:22.267106: step 2237, loss = 0.69129 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:18:23.250670 ops/training.py:65 2019-01-16 17:18:23.250573: step 2238, loss = 0.70455 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:18:24.233495 ops/training.py:65 2019-01-16 17:18:24.233393: step 2239, loss = 0.69837 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:18:25.215584 ops/training.py:65 2019-01-16 17:18:25.215505: step 2240, loss = 0.69573 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:18:26.196554 ops/training.py:65 2019-01-16 17:18:26.196475: step 2241, loss = 0.70068 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:18:27.178551 ops/training.py:65 2019-01-16 17:18:27.178472: step 2242, loss = 0.69539 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:18:28.159424 ops/training.py:65 2019-01-16 17:18:28.159342: step 2243, loss = 0.70348 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:18:29.139292 ops/training.py:65 2019-01-16 17:18:29.139221: step 2244, loss = 0.71356 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 17:18:30.119610 ops/training.py:65 2019-01-16 17:18:30.119529: step 2245, loss = 0.68930 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:18:31.099063 ops/training.py:65 2019-01-16 17:18:31.098994: step 2246, loss = 0.69323 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:18:32.083446 ops/training.py:65 2019-01-16 17:18:32.083361: step 2247, loss = 0.68926 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:18:33.067782 ops/training.py:65 2019-01-16 17:18:33.067686: step 2248, loss = 0.69367 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:18:34.050562 ops/training.py:65 2019-01-16 17:18:34.050462: step 2249, loss = 0.68557 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:18:35.032767 ops/training.py:65 2019-01-16 17:18:35.032642: step 2250, loss = 0.68519 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:18:36.015506 ops/training.py:65 2019-01-16 17:18:36.015401: step 2251, loss = 0.70049 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:18:36.998034 ops/training.py:65 2019-01-16 17:18:36.997926: step 2252, loss = 0.68801 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:18:37.980566 ops/training.py:65 2019-01-16 17:18:37.980459: step 2253, loss = 0.70523 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:18:38.965859 ops/training.py:65 2019-01-16 17:18:38.965753: step 2254, loss = 0.70971 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:18:39.952000 ops/training.py:65 2019-01-16 17:18:39.951898: step 2255, loss = 0.69463 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:18:40.936207 ops/training.py:65 2019-01-16 17:18:40.936127: step 2256, loss = 0.68148 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:18:41.918625 ops/training.py:65 2019-01-16 17:18:41.918518: step 2257, loss = 0.70020 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:18:42.900739 ops/training.py:65 2019-01-16 17:18:42.900634: step 2258, loss = 0.69413 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:18:43.883534 ops/training.py:65 2019-01-16 17:18:43.883434: step 2259, loss = 0.69168 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:18:44.866269 ops/training.py:65 2019-01-16 17:18:44.866133: step 2260, loss = 0.68878 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:18:45.848725 ops/training.py:65 2019-01-16 17:18:45.848618: step 2261, loss = 0.70062 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:18:46.831096 ops/training.py:65 2019-01-16 17:18:46.830993: step 2262, loss = 0.71485 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:18:47.814138 ops/training.py:65 2019-01-16 17:18:47.814033: step 2263, loss = 0.69233 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:18:48.797849 ops/training.py:65 2019-01-16 17:18:48.797768: step 2264, loss = 0.67673 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:18:49.782562 ops/training.py:65 2019-01-16 17:18:49.782464: step 2265, loss = 0.69488 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:18:50.766553 ops/training.py:65 2019-01-16 17:18:50.766453: step 2266, loss = 0.68320 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:18:51.748398 ops/training.py:65 2019-01-16 17:18:51.748297: step 2267, loss = 0.68662 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:18:52.731037 ops/training.py:65 2019-01-16 17:18:52.730941: step 2268, loss = 0.69667 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:18:53.714793 ops/training.py:65 2019-01-16 17:18:53.714694: step 2269, loss = 0.68673 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:18:54.697225 ops/training.py:65 2019-01-16 17:18:54.697111: step 2270, loss = 0.69407 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:18:55.681647 ops/training.py:65 2019-01-16 17:18:55.681544: step 2271, loss = 0.69129 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:18:56.664645 ops/training.py:65 2019-01-16 17:18:56.664533: step 2272, loss = 0.71345 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:18:57.648031 ops/training.py:65 2019-01-16 17:18:57.647917: step 2273, loss = 0.69016 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:18:58.630954 ops/training.py:65 2019-01-16 17:18:58.630849: step 2274, loss = 0.69114 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:18:59.613790 ops/training.py:65 2019-01-16 17:18:59.613682: step 2275, loss = 0.69093 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:19:00.596458 ops/training.py:65 2019-01-16 17:19:00.596352: step 2276, loss = 0.69905 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:19:01.579660 ops/training.py:65 2019-01-16 17:19:01.579552: step 2277, loss = 0.68354 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:19:02.563542 ops/training.py:65 2019-01-16 17:19:02.563453: step 2278, loss = 0.68945 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:19:03.547231 ops/training.py:65 2019-01-16 17:19:03.547157: step 2279, loss = 0.69490 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:19:04.531864 ops/training.py:65 2019-01-16 17:19:04.531782: step 2280, loss = 0.68783 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:19:05.515499 ops/training.py:65 2019-01-16 17:19:05.515393: step 2281, loss = 0.69913 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:19:06.499276 ops/training.py:65 2019-01-16 17:19:06.499178: step 2282, loss = 0.69699 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:19:07.481710 ops/training.py:65 2019-01-16 17:19:07.481603: step 2283, loss = 0.69149 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:19:08.463635 ops/training.py:65 2019-01-16 17:19:08.463526: step 2284, loss = 0.69763 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:19:09.447452 ops/training.py:65 2019-01-16 17:19:09.447345: step 2285, loss = 0.69816 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:19:10.430240 ops/training.py:65 2019-01-16 17:19:10.430152: step 2286, loss = 0.68711 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:19:11.412663 ops/training.py:65 2019-01-16 17:19:11.412562: step 2287, loss = 0.70643 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:19:12.395238 ops/training.py:65 2019-01-16 17:19:12.395136: step 2288, loss = 0.68682 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:19:13.379718 ops/training.py:65 2019-01-16 17:19:13.379618: step 2289, loss = 0.68564 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:19:14.360777 ops/training.py:65 2019-01-16 17:19:14.360679: step 2290, loss = 0.69624 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:19:15.342909 ops/training.py:65 2019-01-16 17:19:15.342798: step 2291, loss = 0.68137 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:19:16.325469 ops/training.py:65 2019-01-16 17:19:16.325368: step 2292, loss = 0.69329 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:19:17.308541 ops/training.py:65 2019-01-16 17:19:17.308440: step 2293, loss = 0.68719 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:19:18.291108 ops/training.py:65 2019-01-16 17:19:18.291009: step 2294, loss = 0.69555 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:19:19.274189 ops/training.py:65 2019-01-16 17:19:19.274089: step 2295, loss = 0.68815 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:19:20.256887 ops/training.py:65 2019-01-16 17:19:20.256797: step 2296, loss = 0.69109 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:19:21.238666 ops/training.py:65 2019-01-16 17:19:21.238565: step 2297, loss = 0.68434 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:19:22.220764 ops/training.py:65 2019-01-16 17:19:22.220620: step 2298, loss = 0.69927 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:19:23.206883 ops/training.py:65 2019-01-16 17:19:23.206780: step 2299, loss = 0.68878 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:19:24.192690 ops/training.py:65 2019-01-16 17:19:24.192617: step 2300, loss = 0.69638 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:19:25.178127 ops/training.py:65 2019-01-16 17:19:25.178028: step 2301, loss = 0.67806 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:19:26.160138 ops/training.py:65 2019-01-16 17:19:26.160044: step 2302, loss = 0.70901 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:19:27.144053 ops/training.py:65 2019-01-16 17:19:27.143945: step 2303, loss = 0.70314 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:19:28.128485 ops/training.py:65 2019-01-16 17:19:28.128381: step 2304, loss = 0.69334 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:19:29.110754 ops/training.py:65 2019-01-16 17:19:29.110655: step 2305, loss = 0.68989 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:19:30.092550 ops/training.py:65 2019-01-16 17:19:30.092423: step 2306, loss = 0.67455 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:19:31.076642 ops/training.py:65 2019-01-16 17:19:31.076538: step 2307, loss = 0.69932 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:19:32.058685 ops/training.py:65 2019-01-16 17:19:32.058579: step 2308, loss = 0.69847 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:19:33.042039 ops/training.py:65 2019-01-16 17:19:33.041934: step 2309, loss = 0.68545 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:19:34.024100 ops/training.py:65 2019-01-16 17:19:34.024002: step 2310, loss = 0.67994 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:19:35.006104 ops/training.py:65 2019-01-16 17:19:35.005981: step 2311, loss = 0.69551 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:19:35.989420 ops/training.py:65 2019-01-16 17:19:35.989317: step 2312, loss = 0.71985 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:19:36.972210 ops/training.py:65 2019-01-16 17:19:36.972107: step 2313, loss = 0.66773 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:19:37.955201 ops/training.py:65 2019-01-16 17:19:37.955103: step 2314, loss = 0.69695 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:19:38.938492 ops/training.py:65 2019-01-16 17:19:38.938389: step 2315, loss = 0.71229 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:19:39.921666 ops/training.py:65 2019-01-16 17:19:39.921572: step 2316, loss = 0.68279 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:19:40.905542 ops/training.py:65 2019-01-16 17:19:40.905450: step 2317, loss = 0.68995 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:19:41.888354 ops/training.py:65 2019-01-16 17:19:41.888256: step 2318, loss = 0.68900 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:19:42.871712 ops/training.py:65 2019-01-16 17:19:42.871607: step 2319, loss = 0.68106 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:19:43.854771 ops/training.py:65 2019-01-16 17:19:43.854677: step 2320, loss = 0.69594 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:19:44.837441 ops/training.py:65 2019-01-16 17:19:44.837340: step 2321, loss = 0.71354 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:19:45.819862 ops/training.py:65 2019-01-16 17:19:45.819775: step 2322, loss = 0.73335 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:19:46.802237 ops/training.py:65 2019-01-16 17:19:46.802132: step 2323, loss = 0.71050 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:19:47.785114 ops/training.py:65 2019-01-16 17:19:47.785021: step 2324, loss = 0.69085 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:19:48.767735 ops/training.py:65 2019-01-16 17:19:48.767627: step 2325, loss = 0.69750 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:19:49.750711 ops/training.py:65 2019-01-16 17:19:49.750614: step 2326, loss = 0.71970 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:19:50.733920 ops/training.py:65 2019-01-16 17:19:50.733821: step 2327, loss = 0.65390 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 17:19:51.716545 ops/training.py:65 2019-01-16 17:19:51.716438: step 2328, loss = 0.71016 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:19:52.699212 ops/training.py:65 2019-01-16 17:19:52.699109: step 2329, loss = 0.67894 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:19:53.681654 ops/training.py:65 2019-01-16 17:19:53.681553: step 2330, loss = 0.70187 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:19:54.663794 ops/training.py:65 2019-01-16 17:19:54.663693: step 2331, loss = 0.72925 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:19:55.645079 ops/training.py:65 2019-01-16 17:19:55.644980: step 2332, loss = 0.71715 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:19:56.628721 ops/training.py:65 2019-01-16 17:19:56.628620: step 2333, loss = 0.69573 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:19:57.613109 ops/training.py:65 2019-01-16 17:19:57.613009: step 2334, loss = 0.70420 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:19:58.596703 ops/training.py:65 2019-01-16 17:19:58.596613: step 2335, loss = 0.68649 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:19:59.579832 ops/training.py:65 2019-01-16 17:19:59.579738: step 2336, loss = 0.68632 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:20:00.565356 ops/training.py:65 2019-01-16 17:20:00.565262: step 2337, loss = 0.68346 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:20:01.548823 ops/training.py:65 2019-01-16 17:20:01.548720: step 2338, loss = 0.69316 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:20:02.533361 ops/training.py:65 2019-01-16 17:20:02.533279: step 2339, loss = 0.67978 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:20:03.517993 ops/training.py:65 2019-01-16 17:20:03.517895: step 2340, loss = 0.68922 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:20:04.501056 ops/training.py:65 2019-01-16 17:20:04.500956: step 2341, loss = 0.69419 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:20:05.484867 ops/training.py:65 2019-01-16 17:20:05.484772: step 2342, loss = 0.68048 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:20:06.470195 ops/training.py:65 2019-01-16 17:20:06.470089: step 2343, loss = 0.70672 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:20:07.455462 ops/training.py:65 2019-01-16 17:20:07.455375: step 2344, loss = 0.69863 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:20:08.441285 ops/training.py:65 2019-01-16 17:20:08.441184: step 2345, loss = 0.69209 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:20:09.425400 ops/training.py:65 2019-01-16 17:20:09.425311: step 2346, loss = 0.69895 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:20:10.410166 ops/training.py:65 2019-01-16 17:20:10.410069: step 2347, loss = 0.70222 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:20:11.395199 ops/training.py:65 2019-01-16 17:20:11.395103: step 2348, loss = 0.69371 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:20:12.378418 ops/training.py:65 2019-01-16 17:20:12.378319: step 2349, loss = 0.71337 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:20:13.361229 ops/training.py:65 2019-01-16 17:20:13.361139: step 2350, loss = 0.71840 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:20:14.344789 ops/training.py:65 2019-01-16 17:20:14.344685: step 2351, loss = 0.68394 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:20:15.327388 ops/training.py:65 2019-01-16 17:20:15.327296: step 2352, loss = 0.68073 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:20:16.311560 ops/training.py:65 2019-01-16 17:20:16.311469: step 2353, loss = 0.68428 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:20:17.298244 ops/training.py:65 2019-01-16 17:20:17.298145: step 2354, loss = 0.69605 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:20:18.282286 ops/training.py:65 2019-01-16 17:20:18.282182: step 2355, loss = 0.70287 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:20:19.265904 ops/training.py:65 2019-01-16 17:20:19.265812: step 2356, loss = 0.69641 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:20:20.250595 ops/training.py:65 2019-01-16 17:20:20.250507: step 2357, loss = 0.68165 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:20:21.235134 ops/training.py:65 2019-01-16 17:20:21.235032: step 2358, loss = 0.71852 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:20:22.218352 ops/training.py:65 2019-01-16 17:20:22.218259: step 2359, loss = 0.70210 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:20:23.201754 ops/training.py:65 2019-01-16 17:20:23.201665: step 2360, loss = 0.69219 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:20:24.185619 ops/training.py:65 2019-01-16 17:20:24.185523: step 2361, loss = 0.70781 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:20:25.169255 ops/training.py:65 2019-01-16 17:20:25.169157: step 2362, loss = 0.70166 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:20:26.154151 ops/training.py:65 2019-01-16 17:20:26.154050: step 2363, loss = 0.68663 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:20:27.138492 ops/training.py:65 2019-01-16 17:20:27.138394: step 2364, loss = 0.70617 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:20:28.123114 ops/training.py:65 2019-01-16 17:20:28.123020: step 2365, loss = 0.71118 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:20:29.106825 ops/training.py:65 2019-01-16 17:20:29.106722: step 2366, loss = 0.69989 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:20:30.091971 ops/training.py:65 2019-01-16 17:20:30.091873: step 2367, loss = 0.67776 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:20:31.077454 ops/training.py:65 2019-01-16 17:20:31.077345: step 2368, loss = 0.69786 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:20:32.061418 ops/training.py:65 2019-01-16 17:20:32.061325: step 2369, loss = 0.69351 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:20:33.044842 ops/training.py:65 2019-01-16 17:20:33.044746: step 2370, loss = 0.68135 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:20:34.028806 ops/training.py:65 2019-01-16 17:20:34.028705: step 2371, loss = 0.70650 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:20:35.012560 ops/training.py:65 2019-01-16 17:20:35.012470: step 2372, loss = 0.68693 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:20:35.996484 ops/training.py:65 2019-01-16 17:20:35.996387: step 2373, loss = 0.68501 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:20:36.978267 ops/training.py:65 2019-01-16 17:20:36.978153: step 2374, loss = 0.68511 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:20:37.960911 ops/training.py:65 2019-01-16 17:20:37.960816: step 2375, loss = 0.70354 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:20:38.946916 ops/training.py:65 2019-01-16 17:20:38.946815: step 2376, loss = 0.69062 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:20:39.930283 ops/training.py:65 2019-01-16 17:20:39.930182: step 2377, loss = 0.70267 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:20:40.915146 ops/training.py:65 2019-01-16 17:20:40.915042: step 2378, loss = 0.67242 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:20:41.898958 ops/training.py:65 2019-01-16 17:20:41.898852: step 2379, loss = 0.70856 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:20:42.883171 ops/training.py:65 2019-01-16 17:20:42.883065: step 2380, loss = 0.69030 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:20:43.867665 ops/training.py:65 2019-01-16 17:20:43.867580: step 2381, loss = 0.69191 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:20:44.852257 ops/training.py:65 2019-01-16 17:20:44.852162: step 2382, loss = 0.66196 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:20:45.836154 ops/training.py:65 2019-01-16 17:20:45.836031: step 2383, loss = 0.70337 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:20:46.821349 ops/training.py:65 2019-01-16 17:20:46.821253: step 2384, loss = 0.69777 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:20:47.803619 ops/training.py:65 2019-01-16 17:20:47.803525: step 2385, loss = 0.69347 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:20:48.788007 ops/training.py:65 2019-01-16 17:20:48.787906: step 2386, loss = 0.69782 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:20:49.771692 ops/training.py:65 2019-01-16 17:20:49.771605: step 2387, loss = 0.69469 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:20:50.754824 ops/training.py:65 2019-01-16 17:20:50.754732: step 2388, loss = 0.69194 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:20:51.740585 ops/training.py:65 2019-01-16 17:20:51.740485: step 2389, loss = 0.69522 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:20:52.725109 ops/training.py:65 2019-01-16 17:20:52.724975: step 2390, loss = 0.69662 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:20:53.708012 ops/training.py:65 2019-01-16 17:20:53.707917: step 2391, loss = 0.71058 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:20:54.690837 ops/training.py:65 2019-01-16 17:20:54.690743: step 2392, loss = 0.70636 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:20:55.674633 ops/training.py:65 2019-01-16 17:20:55.674535: step 2393, loss = 0.68526 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:20:56.656907 ops/training.py:65 2019-01-16 17:20:56.656806: step 2394, loss = 0.71949 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:20:57.641307 ops/training.py:65 2019-01-16 17:20:57.641171: step 2395, loss = 0.68857 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:20:58.625728 ops/training.py:65 2019-01-16 17:20:58.625624: step 2396, loss = 0.69857 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:20:59.608989 ops/training.py:65 2019-01-16 17:20:59.608888: step 2397, loss = 0.69394 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:21:00.594893 ops/training.py:65 2019-01-16 17:21:00.594792: step 2398, loss = 0.70532 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:21:01.578599 ops/training.py:65 2019-01-16 17:21:01.578500: step 2399, loss = 0.69093 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:21:02.562644 ops/training.py:65 2019-01-16 17:21:02.562544: step 2400, loss = 0.69899 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:21:03.545297 ops/training.py:65 2019-01-16 17:21:03.545199: step 2401, loss = 0.71079 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:21:04.528992 ops/training.py:65 2019-01-16 17:21:04.528888: step 2402, loss = 0.70639 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:21:05.512424 ops/training.py:65 2019-01-16 17:21:05.512325: step 2403, loss = 0.71398 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:21:06.498394 ops/training.py:65 2019-01-16 17:21:06.498261: step 2404, loss = 0.68245 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:21:07.483711 ops/training.py:65 2019-01-16 17:21:07.483610: step 2405, loss = 0.68233 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 17:21:08.466753 ops/training.py:65 2019-01-16 17:21:08.466643: step 2406, loss = 0.71047 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:21:09.450610 ops/training.py:65 2019-01-16 17:21:09.450509: step 2407, loss = 0.68796 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:21:10.433631 ops/training.py:65 2019-01-16 17:21:10.433536: step 2408, loss = 0.68242 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:21:11.418125 ops/training.py:65 2019-01-16 17:21:11.418028: step 2409, loss = 0.70271 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:21:12.400392 ops/training.py:65 2019-01-16 17:21:12.400294: step 2410, loss = 0.70746 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:21:13.383622 ops/training.py:65 2019-01-16 17:21:13.383524: step 2411, loss = 0.68922 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:21:14.366878 ops/training.py:65 2019-01-16 17:21:14.366773: step 2412, loss = 0.69243 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:21:15.350361 ops/training.py:65 2019-01-16 17:21:15.350255: step 2413, loss = 0.70280 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:21:16.332879 ops/training.py:65 2019-01-16 17:21:16.332803: step 2414, loss = 0.67520 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:21:17.315003 ops/training.py:65 2019-01-16 17:21:17.314861: step 2415, loss = 0.70480 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:21:18.298354 ops/training.py:65 2019-01-16 17:21:18.298222: step 2416, loss = 0.70771 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:21:19.282081 ops/training.py:65 2019-01-16 17:21:19.281975: step 2417, loss = 0.69972 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:21:20.263723 ops/training.py:65 2019-01-16 17:21:20.263639: step 2418, loss = 0.69241 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:21:21.248437 ops/training.py:65 2019-01-16 17:21:21.248359: step 2419, loss = 0.68525 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:21:22.231409 ops/training.py:65 2019-01-16 17:21:22.231304: step 2420, loss = 0.70010 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:21:23.214181 ops/training.py:65 2019-01-16 17:21:23.214079: step 2421, loss = 0.69637 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:21:24.198144 ops/training.py:65 2019-01-16 17:21:24.198038: step 2422, loss = 0.69286 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:21:25.182000 ops/training.py:65 2019-01-16 17:21:25.181898: step 2423, loss = 0.68778 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:21:26.165036 ops/training.py:65 2019-01-16 17:21:26.164939: step 2424, loss = 0.70852 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:21:27.147615 ops/training.py:65 2019-01-16 17:21:27.147520: step 2425, loss = 0.70007 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:21:28.132947 ops/training.py:65 2019-01-16 17:21:28.132849: step 2426, loss = 0.67325 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:21:29.116825 ops/training.py:65 2019-01-16 17:21:29.116716: step 2427, loss = 0.71405 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:21:30.099022 ops/training.py:65 2019-01-16 17:21:30.098925: step 2428, loss = 0.70724 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:21:31.083133 ops/training.py:65 2019-01-16 17:21:31.083039: step 2429, loss = 0.68538 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:21:32.066277 ops/training.py:65 2019-01-16 17:21:32.066184: step 2430, loss = 0.71119 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:21:33.049288 ops/training.py:65 2019-01-16 17:21:33.049189: step 2431, loss = 0.70337 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:21:34.032867 ops/training.py:65 2019-01-16 17:21:34.032775: step 2432, loss = 0.68864 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:21:35.016541 ops/training.py:65 2019-01-16 17:21:35.016425: step 2433, loss = 0.72206 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:21:36.003096 ops/training.py:65 2019-01-16 17:21:36.002992: step 2434, loss = 0.70120 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:21:36.985905 ops/training.py:65 2019-01-16 17:21:36.985812: step 2435, loss = 0.70476 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:21:37.970239 ops/training.py:65 2019-01-16 17:21:37.970136: step 2436, loss = 0.68023 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:21:38.955154 ops/training.py:65 2019-01-16 17:21:38.955048: step 2437, loss = 0.69904 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:21:39.938669 ops/training.py:65 2019-01-16 17:21:39.938562: step 2438, loss = 0.69993 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:21:40.921223 ops/training.py:65 2019-01-16 17:21:40.921121: step 2439, loss = 0.70683 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:21:41.903967 ops/training.py:65 2019-01-16 17:21:41.903871: step 2440, loss = 0.72040 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:21:42.888772 ops/training.py:65 2019-01-16 17:21:42.888674: step 2441, loss = 0.67766 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:21:43.871794 ops/training.py:65 2019-01-16 17:21:43.871701: step 2442, loss = 0.71026 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:21:44.854419 ops/training.py:65 2019-01-16 17:21:44.854329: step 2443, loss = 0.68106 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:21:45.836516 ops/training.py:65 2019-01-16 17:21:45.836424: step 2444, loss = 0.67278 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:21:46.819154 ops/training.py:65 2019-01-16 17:21:46.819043: step 2445, loss = 0.69990 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:21:47.802275 ops/training.py:65 2019-01-16 17:21:47.802184: step 2446, loss = 0.69076 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:21:48.784601 ops/training.py:65 2019-01-16 17:21:48.784504: step 2447, loss = 0.69413 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:21:49.767449 ops/training.py:65 2019-01-16 17:21:49.767362: step 2448, loss = 0.67199 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:21:50.750377 ops/training.py:65 2019-01-16 17:21:50.750278: step 2449, loss = 0.68724 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:21:51.735092 ops/training.py:65 2019-01-16 17:21:51.734987: step 2450, loss = 0.71088 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:21:52.719860 ops/training.py:65 2019-01-16 17:21:52.719760: step 2451, loss = 0.70868 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:21:53.702197 ops/training.py:65 2019-01-16 17:21:53.702101: step 2452, loss = 0.70498 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:21:54.685348 ops/training.py:65 2019-01-16 17:21:54.685244: step 2453, loss = 0.70028 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:21:55.670022 ops/training.py:65 2019-01-16 17:21:55.669922: step 2454, loss = 0.69633 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:21:56.654775 ops/training.py:65 2019-01-16 17:21:56.654681: step 2455, loss = 0.69486 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:21:57.638955 ops/training.py:65 2019-01-16 17:21:57.638854: step 2456, loss = 0.67858 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:21:58.623052 ops/training.py:65 2019-01-16 17:21:58.622947: step 2457, loss = 0.70135 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:21:59.607700 ops/training.py:65 2019-01-16 17:21:59.607609: step 2458, loss = 0.69323 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:22:00.590803 ops/training.py:65 2019-01-16 17:22:00.590706: step 2459, loss = 0.70361 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:22:01.574283 ops/training.py:65 2019-01-16 17:22:01.574183: step 2460, loss = 0.67741 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:22:02.558878 ops/training.py:65 2019-01-16 17:22:02.558773: step 2461, loss = 0.68398 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:22:03.541455 ops/training.py:65 2019-01-16 17:22:03.541361: step 2462, loss = 0.67718 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:22:04.523543 ops/training.py:65 2019-01-16 17:22:04.523474: step 2463, loss = 0.69183 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:22:05.507537 ops/training.py:65 2019-01-16 17:22:05.507469: step 2464, loss = 0.70582 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:22:06.491200 ops/training.py:65 2019-01-16 17:22:06.491098: step 2465, loss = 0.70697 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:22:07.474229 ops/training.py:65 2019-01-16 17:22:07.474126: step 2466, loss = 0.68372 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:22:08.457578 ops/training.py:65 2019-01-16 17:22:08.457473: step 2467, loss = 0.67519 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:22:09.439518 ops/training.py:65 2019-01-16 17:22:09.439410: step 2468, loss = 0.70681 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:22:10.421249 ops/training.py:65 2019-01-16 17:22:10.421147: step 2469, loss = 0.69900 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:22:11.403673 ops/training.py:65 2019-01-16 17:22:11.403562: step 2470, loss = 0.68069 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:22:12.386095 ops/training.py:65 2019-01-16 17:22:12.385985: step 2471, loss = 0.69953 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:22:13.368800 ops/training.py:65 2019-01-16 17:22:13.368707: step 2472, loss = 0.69484 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:22:14.352030 ops/training.py:65 2019-01-16 17:22:14.351927: step 2473, loss = 0.69442 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:22:15.335033 ops/training.py:65 2019-01-16 17:22:15.334929: step 2474, loss = 0.69859 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:22:16.319024 ops/training.py:65 2019-01-16 17:22:16.318924: step 2475, loss = 0.70311 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:22:17.302454 ops/training.py:65 2019-01-16 17:22:17.302320: step 2476, loss = 0.70366 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:22:18.285454 ops/training.py:65 2019-01-16 17:22:18.285351: step 2477, loss = 0.68322 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:22:19.270721 ops/training.py:65 2019-01-16 17:22:19.270621: step 2478, loss = 0.68167 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:22:20.255742 ops/training.py:65 2019-01-16 17:22:20.255648: step 2479, loss = 0.70214 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:22:21.242701 ops/training.py:65 2019-01-16 17:22:21.242596: step 2480, loss = 0.69178 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:22:22.226213 ops/training.py:65 2019-01-16 17:22:22.226107: step 2481, loss = 0.68814 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:22:23.209922 ops/training.py:65 2019-01-16 17:22:23.209827: step 2482, loss = 0.70240 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:22:24.192112 ops/training.py:65 2019-01-16 17:22:24.192011: step 2483, loss = 0.67552 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:22:25.174766 ops/training.py:65 2019-01-16 17:22:25.174659: step 2484, loss = 0.70374 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:22:26.159102 ops/training.py:65 2019-01-16 17:22:26.159008: step 2485, loss = 0.69860 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:22:27.143556 ops/training.py:65 2019-01-16 17:22:27.143450: step 2486, loss = 0.71517 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 17:22:28.128887 ops/training.py:65 2019-01-16 17:22:28.128782: step 2487, loss = 0.68582 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:22:29.112824 ops/training.py:65 2019-01-16 17:22:29.112718: step 2488, loss = 0.70137 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:22:30.096930 ops/training.py:65 2019-01-16 17:22:30.096824: step 2489, loss = 0.69194 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:22:31.082493 ops/training.py:65 2019-01-16 17:22:31.082392: step 2490, loss = 0.69708 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:22:32.065848 ops/training.py:65 2019-01-16 17:22:32.065748: step 2491, loss = 0.71335 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:22:33.051653 ops/training.py:65 2019-01-16 17:22:33.051562: step 2492, loss = 0.68320 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:22:34.035514 ops/training.py:65 2019-01-16 17:22:34.035427: step 2493, loss = 0.70165 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:22:35.018672 ops/training.py:65 2019-01-16 17:22:35.018577: step 2494, loss = 0.68030 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:22:36.002009 ops/training.py:65 2019-01-16 17:22:36.001937: step 2495, loss = 0.69022 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:22:36.986018 ops/training.py:65 2019-01-16 17:22:36.985931: step 2496, loss = 0.69433 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:22:37.969736 ops/training.py:65 2019-01-16 17:22:37.969637: step 2497, loss = 0.69970 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:22:38.955858 ops/training.py:65 2019-01-16 17:22:38.955757: step 2498, loss = 0.69273 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:22:39.939026 ops/training.py:65 2019-01-16 17:22:39.938929: step 2499, loss = 0.69678 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:22:40.922491 ops/training.py:65 2019-01-16 17:22:40.922423: step 2500, loss = 0.69409 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:22:41.908382 ops/training.py:65 2019-01-16 17:22:41.908291: step 2501, loss = 0.70545 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:22:42.893808 ops/training.py:65 2019-01-16 17:22:42.893665: step 2502, loss = 0.68716 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:22:43.876966 ops/training.py:65 2019-01-16 17:22:43.876871: step 2503, loss = 0.70260 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:22:44.859644 ops/training.py:65 2019-01-16 17:22:44.859545: step 2504, loss = 0.71199 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:22:45.841633 ops/training.py:65 2019-01-16 17:22:45.841537: step 2505, loss = 0.67922 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:22:46.825913 ops/training.py:65 2019-01-16 17:22:46.825816: step 2506, loss = 0.73872 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:22:47.809251 ops/training.py:65 2019-01-16 17:22:47.809150: step 2507, loss = 0.68914 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:22:48.794514 ops/training.py:65 2019-01-16 17:22:48.794410: step 2508, loss = 0.70086 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:22:49.777442 ops/training.py:65 2019-01-16 17:22:49.777347: step 2509, loss = 0.68229 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:22:50.761582 ops/training.py:65 2019-01-16 17:22:50.761474: step 2510, loss = 0.71095 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:22:51.745568 ops/training.py:65 2019-01-16 17:22:51.745462: step 2511, loss = 0.68952 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:22:52.728500 ops/training.py:65 2019-01-16 17:22:52.728357: step 2512, loss = 0.67532 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:22:53.713588 ops/training.py:65 2019-01-16 17:22:53.713483: step 2513, loss = 0.68916 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:22:54.698589 ops/training.py:65 2019-01-16 17:22:54.698477: step 2514, loss = 0.69181 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:22:55.681829 ops/training.py:65 2019-01-16 17:22:55.681738: step 2515, loss = 0.69646 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:22:56.665236 ops/training.py:65 2019-01-16 17:22:56.665170: step 2516, loss = 0.70943 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:22:57.650104 ops/training.py:65 2019-01-16 17:22:57.650003: step 2517, loss = 0.68882 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:22:58.634347 ops/training.py:65 2019-01-16 17:22:58.634242: step 2518, loss = 0.70248 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:22:59.618284 ops/training.py:65 2019-01-16 17:22:59.618179: step 2519, loss = 0.69237 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:23:00.601508 ops/training.py:65 2019-01-16 17:23:00.601401: step 2520, loss = 0.68572 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:23:01.584143 ops/training.py:65 2019-01-16 17:23:01.584042: step 2521, loss = 0.68354 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:23:02.566622 ops/training.py:65 2019-01-16 17:23:02.566522: step 2522, loss = 0.70504 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:23:03.552490 ops/training.py:65 2019-01-16 17:23:03.552418: step 2523, loss = 0.70241 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:23:04.534870 ops/training.py:65 2019-01-16 17:23:04.534768: step 2524, loss = 0.70687 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:23:05.517895 ops/training.py:65 2019-01-16 17:23:05.517801: step 2525, loss = 0.71780 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:23:06.503890 ops/training.py:65 2019-01-16 17:23:06.503781: step 2526, loss = 0.70657 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:23:07.489947 ops/training.py:65 2019-01-16 17:23:07.489847: step 2527, loss = 0.70168 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:23:08.473863 ops/training.py:65 2019-01-16 17:23:08.473754: step 2528, loss = 0.67495 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 17:23:09.456998 ops/training.py:65 2019-01-16 17:23:09.456897: step 2529, loss = 0.68295 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:23:10.440674 ops/training.py:65 2019-01-16 17:23:10.440571: step 2530, loss = 0.70105 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:23:11.425007 ops/training.py:65 2019-01-16 17:23:11.424904: step 2531, loss = 0.70052 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:23:12.407744 ops/training.py:65 2019-01-16 17:23:12.407634: step 2532, loss = 0.69738 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:23:13.392404 ops/training.py:65 2019-01-16 17:23:13.392305: step 2533, loss = 0.68901 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:23:14.376157 ops/training.py:65 2019-01-16 17:23:14.376052: step 2534, loss = 0.69450 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:23:15.359733 ops/training.py:65 2019-01-16 17:23:15.359627: step 2535, loss = 0.68310 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:23:16.342478 ops/training.py:65 2019-01-16 17:23:16.342409: step 2536, loss = 0.69329 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:23:17.327258 ops/training.py:65 2019-01-16 17:23:17.327187: step 2537, loss = 0.68170 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:23:18.311963 ops/training.py:65 2019-01-16 17:23:18.311857: step 2538, loss = 0.69474 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:23:19.297017 ops/training.py:65 2019-01-16 17:23:19.296904: step 2539, loss = 0.67964 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:23:20.281279 ops/training.py:65 2019-01-16 17:23:20.281186: step 2540, loss = 0.69172 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:23:21.265222 ops/training.py:65 2019-01-16 17:23:21.265120: step 2541, loss = 0.67701 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:23:22.248671 ops/training.py:65 2019-01-16 17:23:22.248533: step 2542, loss = 0.70072 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:23:23.234390 ops/training.py:65 2019-01-16 17:23:23.234293: step 2543, loss = 0.68822 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:23:24.220664 ops/training.py:65 2019-01-16 17:23:24.220559: step 2544, loss = 0.67376 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:23:25.205350 ops/training.py:65 2019-01-16 17:23:25.205243: step 2545, loss = 0.67947 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:23:26.189647 ops/training.py:65 2019-01-16 17:23:26.189548: step 2546, loss = 0.69788 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:23:27.173323 ops/training.py:65 2019-01-16 17:23:27.173219: step 2547, loss = 0.68175 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:23:28.156874 ops/training.py:65 2019-01-16 17:23:28.156765: step 2548, loss = 0.68668 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:23:29.140634 ops/training.py:65 2019-01-16 17:23:29.140524: step 2549, loss = 0.68509 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:23:30.123920 ops/training.py:65 2019-01-16 17:23:30.123813: step 2550, loss = 0.68961 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:23:31.109894 ops/training.py:65 2019-01-16 17:23:31.109786: step 2551, loss = 0.68938 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:23:32.094178 ops/training.py:65 2019-01-16 17:23:32.094071: step 2552, loss = 0.68083 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:23:33.077383 ops/training.py:65 2019-01-16 17:23:33.077284: step 2553, loss = 0.69404 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:23:34.060235 ops/training.py:65 2019-01-16 17:23:34.060141: step 2554, loss = 0.69968 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:23:35.043329 ops/training.py:65 2019-01-16 17:23:35.043201: step 2555, loss = 0.71216 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:23:36.025827 ops/training.py:65 2019-01-16 17:23:36.025723: step 2556, loss = 0.70089 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:23:37.008965 ops/training.py:65 2019-01-16 17:23:37.008866: step 2557, loss = 0.69717 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:23:37.994314 ops/training.py:65 2019-01-16 17:23:37.994239: step 2558, loss = 0.69606 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:23:38.980020 ops/training.py:65 2019-01-16 17:23:38.979880: step 2559, loss = 0.70355 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:23:39.964864 ops/training.py:65 2019-01-16 17:23:39.964765: step 2560, loss = 0.68536 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:23:40.949296 ops/training.py:65 2019-01-16 17:23:40.949196: step 2561, loss = 0.68893 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:23:41.933648 ops/training.py:65 2019-01-16 17:23:41.933542: step 2562, loss = 0.67888 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:23:42.916364 ops/training.py:65 2019-01-16 17:23:42.916264: step 2563, loss = 0.69759 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:23:43.898874 ops/training.py:65 2019-01-16 17:23:43.898781: step 2564, loss = 0.69081 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:23:44.881938 ops/training.py:65 2019-01-16 17:23:44.881805: step 2565, loss = 0.68743 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:23:45.866194 ops/training.py:65 2019-01-16 17:23:45.866089: step 2566, loss = 0.70316 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:23:46.849670 ops/training.py:65 2019-01-16 17:23:46.849533: step 2567, loss = 0.68453 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:23:47.833837 ops/training.py:65 2019-01-16 17:23:47.833734: step 2568, loss = 0.68506 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:23:48.816279 ops/training.py:65 2019-01-16 17:23:48.816175: step 2569, loss = 0.68196 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:23:49.799185 ops/training.py:65 2019-01-16 17:23:49.799091: step 2570, loss = 0.71044 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:23:50.782384 ops/training.py:65 2019-01-16 17:23:50.782290: step 2571, loss = 0.68228 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:23:51.766640 ops/training.py:65 2019-01-16 17:23:51.766537: step 2572, loss = 0.68882 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:23:52.749134 ops/training.py:65 2019-01-16 17:23:52.749027: step 2573, loss = 0.69782 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:23:53.732874 ops/training.py:65 2019-01-16 17:23:53.732773: step 2574, loss = 0.69829 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:23:54.718992 ops/training.py:65 2019-01-16 17:23:54.718886: step 2575, loss = 0.71213 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:23:55.701951 ops/training.py:65 2019-01-16 17:23:55.701846: step 2576, loss = 0.67700 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:23:56.684132 ops/training.py:65 2019-01-16 17:23:56.684030: step 2577, loss = 0.66831 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:23:57.666554 ops/training.py:65 2019-01-16 17:23:57.666459: step 2578, loss = 0.70292 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:23:58.651117 ops/training.py:65 2019-01-16 17:23:58.651016: step 2579, loss = 0.68904 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:23:59.635383 ops/training.py:65 2019-01-16 17:23:59.635279: step 2580, loss = 0.67930 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:24:00.618347 ops/training.py:65 2019-01-16 17:24:00.618277: step 2581, loss = 0.73214 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:24:01.600637 ops/training.py:65 2019-01-16 17:24:01.600568: step 2582, loss = 0.69931 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:24:02.581168 ops/training.py:65 2019-01-16 17:24:02.581099: step 2583, loss = 0.72470 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:24:03.563143 ops/training.py:65 2019-01-16 17:24:03.563076: step 2584, loss = 0.70248 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:24:04.546327 ops/training.py:65 2019-01-16 17:24:04.546262: step 2585, loss = 0.68428 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:24:05.530529 ops/training.py:65 2019-01-16 17:24:05.530457: step 2586, loss = 0.72436 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:24:06.515533 ops/training.py:65 2019-01-16 17:24:06.515433: step 2587, loss = 0.68849 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:24:07.499705 ops/training.py:65 2019-01-16 17:24:07.499602: step 2588, loss = 0.73474 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:24:08.486335 ops/training.py:65 2019-01-16 17:24:08.486226: step 2589, loss = 0.72129 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:24:09.471175 ops/training.py:65 2019-01-16 17:24:09.471073: step 2590, loss = 0.70877 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:24:10.455699 ops/training.py:65 2019-01-16 17:24:10.455598: step 2591, loss = 0.71060 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:24:11.438382 ops/training.py:65 2019-01-16 17:24:11.438273: step 2592, loss = 0.69255 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:24:12.423564 ops/training.py:65 2019-01-16 17:24:12.423463: step 2593, loss = 0.70817 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:24:13.409508 ops/training.py:65 2019-01-16 17:24:13.409410: step 2594, loss = 0.68705 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:24:14.393989 ops/training.py:65 2019-01-16 17:24:14.393889: step 2595, loss = 0.70781 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:24:15.378870 ops/training.py:65 2019-01-16 17:24:15.378764: step 2596, loss = 0.70114 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:24:16.363077 ops/training.py:65 2019-01-16 17:24:16.362974: step 2597, loss = 0.69146 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:24:17.346200 ops/training.py:65 2019-01-16 17:24:17.346099: step 2598, loss = 0.69018 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:24:18.330095 ops/training.py:65 2019-01-16 17:24:18.329988: step 2599, loss = 0.69557 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:24:19.312187 ops/training.py:65 2019-01-16 17:24:19.312082: step 2600, loss = 0.71623 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:24:20.293693 ops/training.py:65 2019-01-16 17:24:20.293597: step 2601, loss = 0.69720 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:24:21.276987 ops/training.py:65 2019-01-16 17:24:21.276881: step 2602, loss = 0.69396 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:24:22.260575 ops/training.py:65 2019-01-16 17:24:22.260473: step 2603, loss = 0.68609 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:24:23.243869 ops/training.py:65 2019-01-16 17:24:23.243772: step 2604, loss = 0.70544 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:24:24.227510 ops/training.py:65 2019-01-16 17:24:24.227409: step 2605, loss = 0.68341 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:24:25.209832 ops/training.py:65 2019-01-16 17:24:25.209728: step 2606, loss = 0.70232 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:24:26.192283 ops/training.py:65 2019-01-16 17:24:26.192178: step 2607, loss = 0.68522 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:24:27.174892 ops/training.py:65 2019-01-16 17:24:27.174788: step 2608, loss = 0.67691 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:24:28.158120 ops/training.py:65 2019-01-16 17:24:28.158018: step 2609, loss = 0.69510 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:24:29.140925 ops/training.py:65 2019-01-16 17:24:29.140829: step 2610, loss = 0.68413 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:24:30.124469 ops/training.py:65 2019-01-16 17:24:30.124373: step 2611, loss = 0.70358 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:24:31.108106 ops/training.py:65 2019-01-16 17:24:31.108004: step 2612, loss = 0.70491 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:24:32.091142 ops/training.py:65 2019-01-16 17:24:32.091038: step 2613, loss = 0.71871 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:24:33.073736 ops/training.py:65 2019-01-16 17:24:33.073640: step 2614, loss = 0.69685 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:24:34.058595 ops/training.py:65 2019-01-16 17:24:34.058499: step 2615, loss = 0.69553 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:24:35.041842 ops/training.py:65 2019-01-16 17:24:35.041754: step 2616, loss = 0.70583 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:24:36.024084 ops/training.py:65 2019-01-16 17:24:36.023989: step 2617, loss = 0.70503 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:24:37.005804 ops/training.py:65 2019-01-16 17:24:37.005704: step 2618, loss = 0.69392 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:24:37.987919 ops/training.py:65 2019-01-16 17:24:37.987815: step 2619, loss = 0.69654 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:24:38.972643 ops/training.py:65 2019-01-16 17:24:38.972534: step 2620, loss = 0.69586 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:24:39.957649 ops/training.py:65 2019-01-16 17:24:39.957549: step 2621, loss = 0.71111 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:24:40.941826 ops/training.py:65 2019-01-16 17:24:40.941728: step 2622, loss = 0.66542 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.75
I8192 2019-01-16 17:24:41.926006 ops/training.py:65 2019-01-16 17:24:41.925899: step 2623, loss = 0.67704 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:24:42.910474 ops/training.py:65 2019-01-16 17:24:42.910373: step 2624, loss = 0.69007 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:24:43.893919 ops/training.py:65 2019-01-16 17:24:43.893823: step 2625, loss = 0.69960 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:24:44.877854 ops/training.py:65 2019-01-16 17:24:44.877767: step 2626, loss = 0.67090 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:24:45.862995 ops/training.py:65 2019-01-16 17:24:45.862894: step 2627, loss = 0.69721 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:24:46.847827 ops/training.py:65 2019-01-16 17:24:46.847734: step 2628, loss = 0.68537 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:24:47.831642 ops/training.py:65 2019-01-16 17:24:47.831541: step 2629, loss = 0.69775 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:24:48.815882 ops/training.py:65 2019-01-16 17:24:48.815785: step 2630, loss = 0.69906 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:24:49.799855 ops/training.py:65 2019-01-16 17:24:49.799753: step 2631, loss = 0.68739 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:24:50.783096 ops/training.py:65 2019-01-16 17:24:50.783004: step 2632, loss = 0.70554 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:24:51.766949 ops/training.py:65 2019-01-16 17:24:51.766851: step 2633, loss = 0.69577 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:24:52.750530 ops/training.py:65 2019-01-16 17:24:52.750438: step 2634, loss = 0.69724 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:24:53.734465 ops/training.py:65 2019-01-16 17:24:53.734372: step 2635, loss = 0.69653 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:24:54.720863 ops/training.py:65 2019-01-16 17:24:54.720762: step 2636, loss = 0.69931 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:24:55.703437 ops/training.py:65 2019-01-16 17:24:55.703344: step 2637, loss = 0.68507 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:24:56.686068 ops/training.py:65 2019-01-16 17:24:56.685982: step 2638, loss = 0.69064 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:24:57.669242 ops/training.py:65 2019-01-16 17:24:57.669149: step 2639, loss = 0.70479 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:24:58.653595 ops/training.py:65 2019-01-16 17:24:58.653489: step 2640, loss = 0.70155 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:24:59.637800 ops/training.py:65 2019-01-16 17:24:59.637702: step 2641, loss = 0.69745 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:25:00.621233 ops/training.py:65 2019-01-16 17:25:00.621136: step 2642, loss = 0.71276 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:25:01.604535 ops/training.py:65 2019-01-16 17:25:01.604437: step 2643, loss = 0.67988 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:25:02.588656 ops/training.py:65 2019-01-16 17:25:02.588567: step 2644, loss = 0.69218 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:25:03.571530 ops/training.py:65 2019-01-16 17:25:03.571435: step 2645, loss = 0.68996 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:25:04.554362 ops/training.py:65 2019-01-16 17:25:04.554259: step 2646, loss = 0.72644 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:25:05.538284 ops/training.py:65 2019-01-16 17:25:05.538197: step 2647, loss = 0.69200 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:25:06.521108 ops/training.py:65 2019-01-16 17:25:06.521009: step 2648, loss = 0.73022 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 17:25:07.503809 ops/training.py:65 2019-01-16 17:25:07.503707: step 2649, loss = 0.69487 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:25:08.487348 ops/training.py:65 2019-01-16 17:25:08.487248: step 2650, loss = 0.67777 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:25:09.471143 ops/training.py:65 2019-01-16 17:25:09.471052: step 2651, loss = 0.68421 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:25:10.453058 ops/training.py:65 2019-01-16 17:25:10.452973: step 2652, loss = 0.70319 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:25:11.436606 ops/training.py:65 2019-01-16 17:25:11.436499: step 2653, loss = 0.72513 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:25:12.420499 ops/training.py:65 2019-01-16 17:25:12.420399: step 2654, loss = 0.69978 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:25:13.404773 ops/training.py:65 2019-01-16 17:25:13.404668: step 2655, loss = 0.67848 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:25:14.386854 ops/training.py:65 2019-01-16 17:25:14.386790: step 2656, loss = 0.69340 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:25:15.368625 ops/training.py:65 2019-01-16 17:25:15.368556: step 2657, loss = 0.70128 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:25:16.349675 ops/training.py:65 2019-01-16 17:25:16.349612: step 2658, loss = 0.68112 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:25:17.331023 ops/training.py:65 2019-01-16 17:25:17.330959: step 2659, loss = 0.69805 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:25:18.312583 ops/training.py:65 2019-01-16 17:25:18.312522: step 2660, loss = 0.70169 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:25:19.293581 ops/training.py:65 2019-01-16 17:25:19.293514: step 2661, loss = 0.69762 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:25:20.273493 ops/training.py:65 2019-01-16 17:25:20.273427: step 2662, loss = 0.70691 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:25:21.255180 ops/training.py:65 2019-01-16 17:25:21.255095: step 2663, loss = 0.69920 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:25:22.235804 ops/training.py:65 2019-01-16 17:25:22.235735: step 2664, loss = 0.69982 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:25:23.216082 ops/training.py:65 2019-01-16 17:25:23.215999: step 2665, loss = 0.69356 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:25:24.201701 ops/training.py:65 2019-01-16 17:25:24.201629: step 2666, loss = 0.69944 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:25:25.186092 ops/training.py:65 2019-01-16 17:25:25.185993: step 2667, loss = 0.70344 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:25:26.170748 ops/training.py:65 2019-01-16 17:25:26.170642: step 2668, loss = 0.70383 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:25:27.154050 ops/training.py:65 2019-01-16 17:25:27.153949: step 2669, loss = 0.68539 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:25:28.140047 ops/training.py:65 2019-01-16 17:25:28.139940: step 2670, loss = 0.69808 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:25:29.124044 ops/training.py:65 2019-01-16 17:25:29.123935: step 2671, loss = 0.69370 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:25:30.108121 ops/training.py:65 2019-01-16 17:25:30.108012: step 2672, loss = 0.69955 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:25:31.091971 ops/training.py:65 2019-01-16 17:25:31.091865: step 2673, loss = 0.68454 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:25:32.074353 ops/training.py:65 2019-01-16 17:25:32.074255: step 2674, loss = 0.68872 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:25:33.056426 ops/training.py:65 2019-01-16 17:25:33.056327: step 2675, loss = 0.69053 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:25:34.039470 ops/training.py:65 2019-01-16 17:25:34.039385: step 2676, loss = 0.69383 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:25:35.024278 ops/training.py:65 2019-01-16 17:25:35.024189: step 2677, loss = 0.69327 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:25:36.007624 ops/training.py:65 2019-01-16 17:25:36.007525: step 2678, loss = 0.70109 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:25:36.991461 ops/training.py:65 2019-01-16 17:25:36.991363: step 2679, loss = 0.69483 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:25:37.975105 ops/training.py:65 2019-01-16 17:25:37.975001: step 2680, loss = 0.69419 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:25:38.958874 ops/training.py:65 2019-01-16 17:25:38.958778: step 2681, loss = 0.70173 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:25:39.942644 ops/training.py:65 2019-01-16 17:25:39.942543: step 2682, loss = 0.68088 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:25:40.926106 ops/training.py:65 2019-01-16 17:25:40.926003: step 2683, loss = 0.68809 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:25:41.909027 ops/training.py:65 2019-01-16 17:25:41.908917: step 2684, loss = 0.68471 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:25:42.891759 ops/training.py:65 2019-01-16 17:25:42.891656: step 2685, loss = 0.69450 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:25:43.873550 ops/training.py:65 2019-01-16 17:25:43.873446: step 2686, loss = 0.69661 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:25:44.855869 ops/training.py:65 2019-01-16 17:25:44.855766: step 2687, loss = 0.68748 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:25:45.840904 ops/training.py:65 2019-01-16 17:25:45.840795: step 2688, loss = 0.68800 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:25:46.835348 ops/training.py:65 2019-01-16 17:25:46.835247: step 2689, loss = 0.69570 (32.2 examples/sec; 0.993 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:25:47.818366 ops/training.py:65 2019-01-16 17:25:47.818257: step 2690, loss = 0.69491 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:25:48.800970 ops/training.py:65 2019-01-16 17:25:48.800859: step 2691, loss = 0.70151 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:25:49.783294 ops/training.py:65 2019-01-16 17:25:49.783159: step 2692, loss = 0.70460 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:25:50.765676 ops/training.py:65 2019-01-16 17:25:50.765584: step 2693, loss = 0.69239 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:25:51.748010 ops/training.py:65 2019-01-16 17:25:51.747910: step 2694, loss = 0.69003 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:25:52.731186 ops/training.py:65 2019-01-16 17:25:52.731084: step 2695, loss = 0.68314 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:25:53.713185 ops/training.py:65 2019-01-16 17:25:53.713060: step 2696, loss = 0.70118 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:25:54.697012 ops/training.py:65 2019-01-16 17:25:54.696921: step 2697, loss = 0.69013 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:25:55.680099 ops/training.py:65 2019-01-16 17:25:55.679990: step 2698, loss = 0.68465 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:25:56.662290 ops/training.py:65 2019-01-16 17:25:56.662194: step 2699, loss = 0.69293 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:25:57.644110 ops/training.py:65 2019-01-16 17:25:57.643979: step 2700, loss = 0.69742 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:25:58.629216 ops/training.py:65 2019-01-16 17:25:58.629113: step 2701, loss = 0.69968 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:25:59.613187 ops/training.py:65 2019-01-16 17:25:59.613078: step 2702, loss = 0.68886 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:26:00.597261 ops/training.py:65 2019-01-16 17:26:00.597117: step 2703, loss = 0.67954 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:26:01.580409 ops/training.py:65 2019-01-16 17:26:01.580309: step 2704, loss = 0.69483 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:26:02.566064 ops/training.py:65 2019-01-16 17:26:02.565958: step 2705, loss = 0.69367 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:26:03.552027 ops/training.py:65 2019-01-16 17:26:03.551928: step 2706, loss = 0.69488 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:26:04.537288 ops/training.py:65 2019-01-16 17:26:04.537184: step 2707, loss = 0.68908 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:26:05.522150 ops/training.py:65 2019-01-16 17:26:05.522025: step 2708, loss = 0.69287 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:26:06.507634 ops/training.py:65 2019-01-16 17:26:06.507544: step 2709, loss = 0.70890 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:26:07.489894 ops/training.py:65 2019-01-16 17:26:07.489814: step 2710, loss = 0.68029 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:26:08.470376 ops/training.py:65 2019-01-16 17:26:08.470314: step 2711, loss = 0.70186 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:26:09.454170 ops/training.py:65 2019-01-16 17:26:09.454081: step 2712, loss = 0.68825 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:26:10.440078 ops/training.py:65 2019-01-16 17:26:10.439980: step 2713, loss = 0.68403 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:26:11.423045 ops/training.py:65 2019-01-16 17:26:11.422944: step 2714, loss = 0.70580 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:26:12.406492 ops/training.py:65 2019-01-16 17:26:12.406389: step 2715, loss = 0.68828 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:26:13.389380 ops/training.py:65 2019-01-16 17:26:13.389283: step 2716, loss = 0.70361 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:26:14.372072 ops/training.py:65 2019-01-16 17:26:14.371970: step 2717, loss = 0.70160 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:26:15.358158 ops/training.py:65 2019-01-16 17:26:15.358061: step 2718, loss = 0.70180 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:26:16.341605 ops/training.py:65 2019-01-16 17:26:16.341504: step 2719, loss = 0.69854 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:26:17.327811 ops/training.py:65 2019-01-16 17:26:17.327720: step 2720, loss = 0.71859 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:26:18.311755 ops/training.py:65 2019-01-16 17:26:18.311658: step 2721, loss = 0.69869 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:26:19.294545 ops/training.py:65 2019-01-16 17:26:19.294443: step 2722, loss = 0.68160 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:26:20.278238 ops/training.py:65 2019-01-16 17:26:20.278140: step 2723, loss = 0.70185 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:26:21.260928 ops/training.py:65 2019-01-16 17:26:21.260829: step 2724, loss = 0.68417 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:26:22.244080 ops/training.py:65 2019-01-16 17:26:22.243993: step 2725, loss = 0.69250 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:26:23.226539 ops/training.py:65 2019-01-16 17:26:23.226437: step 2726, loss = 0.68856 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:26:24.210592 ops/training.py:65 2019-01-16 17:26:24.210495: step 2727, loss = 0.69716 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:26:25.193937 ops/training.py:65 2019-01-16 17:26:25.193811: step 2728, loss = 0.69068 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:26:26.177224 ops/training.py:65 2019-01-16 17:26:26.177121: step 2729, loss = 0.70499 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:26:27.159320 ops/training.py:65 2019-01-16 17:26:27.159220: step 2730, loss = 0.67908 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:26:28.141549 ops/training.py:65 2019-01-16 17:26:28.141448: step 2731, loss = 0.69699 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:26:29.125838 ops/training.py:65 2019-01-16 17:26:29.125738: step 2732, loss = 0.69434 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:26:30.111563 ops/training.py:65 2019-01-16 17:26:30.111462: step 2733, loss = 0.68993 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:26:31.095551 ops/training.py:65 2019-01-16 17:26:31.095440: step 2734, loss = 0.69991 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:26:32.080353 ops/training.py:65 2019-01-16 17:26:32.080246: step 2735, loss = 0.69166 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:26:33.062659 ops/training.py:65 2019-01-16 17:26:33.062559: step 2736, loss = 0.69217 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:26:34.044865 ops/training.py:65 2019-01-16 17:26:34.044764: step 2737, loss = 0.69800 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:26:35.026749 ops/training.py:65 2019-01-16 17:26:35.026661: step 2738, loss = 0.69595 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:26:36.009791 ops/training.py:65 2019-01-16 17:26:36.009704: step 2739, loss = 0.70413 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:26:36.993012 ops/training.py:65 2019-01-16 17:26:36.992919: step 2740, loss = 0.67704 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:26:37.975742 ops/training.py:65 2019-01-16 17:26:37.975646: step 2741, loss = 0.68781 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:26:38.957708 ops/training.py:65 2019-01-16 17:26:38.957602: step 2742, loss = 0.69248 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:26:39.940930 ops/training.py:65 2019-01-16 17:26:39.940823: step 2743, loss = 0.69135 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:26:40.924902 ops/training.py:65 2019-01-16 17:26:40.924798: step 2744, loss = 0.69220 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:26:41.909666 ops/training.py:65 2019-01-16 17:26:41.909561: step 2745, loss = 0.68504 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:26:42.892372 ops/training.py:65 2019-01-16 17:26:42.892270: step 2746, loss = 0.69313 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:26:43.874247 ops/training.py:65 2019-01-16 17:26:43.874172: step 2747, loss = 0.69687 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:26:44.854308 ops/training.py:65 2019-01-16 17:26:44.854230: step 2748, loss = 0.69786 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:26:45.834979 ops/training.py:65 2019-01-16 17:26:45.834906: step 2749, loss = 0.70109 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:26:46.815302 ops/training.py:65 2019-01-16 17:26:46.815225: step 2750, loss = 0.68957 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:26:47.797156 ops/training.py:65 2019-01-16 17:26:47.797076: step 2751, loss = 0.69039 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:26:48.778627 ops/training.py:65 2019-01-16 17:26:48.778547: step 2752, loss = 0.70821 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:26:49.758989 ops/training.py:65 2019-01-16 17:26:49.758906: step 2753, loss = 0.68239 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:26:50.742182 ops/training.py:65 2019-01-16 17:26:50.742110: step 2754, loss = 0.69650 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:26:51.727886 ops/training.py:65 2019-01-16 17:26:51.727793: step 2755, loss = 0.69797 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:26:52.713931 ops/training.py:65 2019-01-16 17:26:52.713836: step 2756, loss = 0.69495 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:26:53.699659 ops/training.py:65 2019-01-16 17:26:53.699564: step 2757, loss = 0.67746 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:26:54.683559 ops/training.py:65 2019-01-16 17:26:54.683457: step 2758, loss = 0.69223 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:26:55.666762 ops/training.py:65 2019-01-16 17:26:55.666659: step 2759, loss = 0.69621 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:26:56.651021 ops/training.py:65 2019-01-16 17:26:56.650918: step 2760, loss = 0.69279 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:26:57.634539 ops/training.py:65 2019-01-16 17:26:57.634435: step 2761, loss = 0.67844 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:26:58.618760 ops/training.py:65 2019-01-16 17:26:58.618667: step 2762, loss = 0.70592 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:26:59.603208 ops/training.py:65 2019-01-16 17:26:59.603106: step 2763, loss = 0.71808 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:27:00.587175 ops/training.py:65 2019-01-16 17:27:00.587078: step 2764, loss = 0.69831 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:27:01.572066 ops/training.py:65 2019-01-16 17:27:01.571955: step 2765, loss = 0.69085 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:27:02.556114 ops/training.py:65 2019-01-16 17:27:02.556009: step 2766, loss = 0.69134 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:27:03.541231 ops/training.py:65 2019-01-16 17:27:03.541135: step 2767, loss = 0.70023 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:27:04.527764 ops/training.py:65 2019-01-16 17:27:04.527658: step 2768, loss = 0.70238 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:27:05.512479 ops/training.py:65 2019-01-16 17:27:05.512352: step 2769, loss = 0.70024 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:27:06.495948 ops/training.py:65 2019-01-16 17:27:06.495848: step 2770, loss = 0.68945 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:27:07.479742 ops/training.py:65 2019-01-16 17:27:07.479642: step 2771, loss = 0.69505 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:27:08.466380 ops/training.py:65 2019-01-16 17:27:08.466291: step 2772, loss = 0.69392 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:27:09.449655 ops/training.py:65 2019-01-16 17:27:09.449562: step 2773, loss = 0.68439 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:27:10.432224 ops/training.py:65 2019-01-16 17:27:10.432084: step 2774, loss = 0.68473 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:27:11.417443 ops/training.py:65 2019-01-16 17:27:11.417332: step 2775, loss = 0.68250 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:27:12.404462 ops/training.py:65 2019-01-16 17:27:12.404359: step 2776, loss = 0.69921 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:27:13.388998 ops/training.py:65 2019-01-16 17:27:13.388897: step 2777, loss = 0.69620 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:27:14.373767 ops/training.py:65 2019-01-16 17:27:14.373657: step 2778, loss = 0.70178 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:27:15.357541 ops/training.py:65 2019-01-16 17:27:15.357446: step 2779, loss = 0.69487 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:27:16.341419 ops/training.py:65 2019-01-16 17:27:16.341315: step 2780, loss = 0.66235 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.78125
I8192 2019-01-16 17:27:17.326306 ops/training.py:65 2019-01-16 17:27:17.326206: step 2781, loss = 0.71997 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:27:18.310413 ops/training.py:65 2019-01-16 17:27:18.310308: step 2782, loss = 0.68217 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:27:19.294149 ops/training.py:65 2019-01-16 17:27:19.294040: step 2783, loss = 0.69487 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:27:20.278376 ops/training.py:65 2019-01-16 17:27:20.278273: step 2784, loss = 0.68404 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:27:21.262891 ops/training.py:65 2019-01-16 17:27:21.262793: step 2785, loss = 0.69611 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:27:22.245959 ops/training.py:65 2019-01-16 17:27:22.245866: step 2786, loss = 0.70902 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:27:23.229752 ops/training.py:65 2019-01-16 17:27:23.229653: step 2787, loss = 0.70243 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:27:24.212789 ops/training.py:65 2019-01-16 17:27:24.212684: step 2788, loss = 0.69990 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:27:25.195302 ops/training.py:65 2019-01-16 17:27:25.195189: step 2789, loss = 0.69894 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:27:26.183819 ops/training.py:65 2019-01-16 17:27:26.183708: step 2790, loss = 0.69311 (32.4 examples/sec; 0.987 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:27:27.168505 ops/training.py:65 2019-01-16 17:27:27.168401: step 2791, loss = 0.70184 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:27:28.152159 ops/training.py:65 2019-01-16 17:27:28.152057: step 2792, loss = 0.70227 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:27:29.137545 ops/training.py:65 2019-01-16 17:27:29.137438: step 2793, loss = 0.69118 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:27:30.121311 ops/training.py:65 2019-01-16 17:27:30.121214: step 2794, loss = 0.67869 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:27:31.105517 ops/training.py:65 2019-01-16 17:27:31.105412: step 2795, loss = 0.69427 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:27:32.088951 ops/training.py:65 2019-01-16 17:27:32.088857: step 2796, loss = 0.69259 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:27:33.072128 ops/training.py:65 2019-01-16 17:27:33.072024: step 2797, loss = 0.70003 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:27:34.054424 ops/training.py:65 2019-01-16 17:27:34.054333: step 2798, loss = 0.70241 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:27:35.038601 ops/training.py:65 2019-01-16 17:27:35.038507: step 2799, loss = 0.70145 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:27:36.021343 ops/training.py:65 2019-01-16 17:27:36.021248: step 2800, loss = 0.69541 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:27:37.004172 ops/training.py:65 2019-01-16 17:27:37.004060: step 2801, loss = 0.68905 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:27:37.986646 ops/training.py:65 2019-01-16 17:27:37.986555: step 2802, loss = 0.69788 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:27:38.969527 ops/training.py:65 2019-01-16 17:27:38.969429: step 2803, loss = 0.70083 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:27:39.953086 ops/training.py:65 2019-01-16 17:27:39.952989: step 2804, loss = 0.68729 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:27:40.936123 ops/training.py:65 2019-01-16 17:27:40.936018: step 2805, loss = 0.69636 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:27:41.918823 ops/training.py:65 2019-01-16 17:27:41.918737: step 2806, loss = 0.69920 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:27:42.902505 ops/training.py:65 2019-01-16 17:27:42.902401: step 2807, loss = 0.69275 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:27:43.885684 ops/training.py:65 2019-01-16 17:27:43.885584: step 2808, loss = 0.69236 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:27:44.874556 ops/training.py:65 2019-01-16 17:27:44.874451: step 2809, loss = 0.69317 (32.4 examples/sec; 0.988 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:27:45.859333 ops/training.py:65 2019-01-16 17:27:45.859240: step 2810, loss = 0.67651 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:27:46.843204 ops/training.py:65 2019-01-16 17:27:46.843111: step 2811, loss = 0.71481 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:27:47.827569 ops/training.py:65 2019-01-16 17:27:47.827468: step 2812, loss = 0.70421 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:27:48.812303 ops/training.py:65 2019-01-16 17:27:48.812192: step 2813, loss = 0.68909 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:27:49.795152 ops/training.py:65 2019-01-16 17:27:49.795058: step 2814, loss = 0.68536 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:27:50.777641 ops/training.py:65 2019-01-16 17:27:50.777555: step 2815, loss = 0.69702 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:27:51.760145 ops/training.py:65 2019-01-16 17:27:51.760050: step 2816, loss = 0.70486 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:27:52.744381 ops/training.py:65 2019-01-16 17:27:52.744277: step 2817, loss = 0.69773 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:27:53.728439 ops/training.py:65 2019-01-16 17:27:53.728347: step 2818, loss = 0.72285 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.21875
I8192 2019-01-16 17:27:54.712646 ops/training.py:65 2019-01-16 17:27:54.712546: step 2819, loss = 0.69123 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:27:55.697157 ops/training.py:65 2019-01-16 17:27:55.697059: step 2820, loss = 0.66929 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:27:56.681005 ops/training.py:65 2019-01-16 17:27:56.680908: step 2821, loss = 0.67545 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:27:57.666669 ops/training.py:65 2019-01-16 17:27:57.666581: step 2822, loss = 0.68575 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:27:58.649479 ops/training.py:65 2019-01-16 17:27:58.649381: step 2823, loss = 0.68300 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:27:59.633488 ops/training.py:65 2019-01-16 17:27:59.633384: step 2824, loss = 0.68587 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:28:00.616533 ops/training.py:65 2019-01-16 17:28:00.616437: step 2825, loss = 0.67050 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:28:01.599864 ops/training.py:65 2019-01-16 17:28:01.599769: step 2826, loss = 0.70336 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:28:02.582978 ops/training.py:65 2019-01-16 17:28:02.582882: step 2827, loss = 0.66906 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:28:03.566566 ops/training.py:65 2019-01-16 17:28:03.566464: step 2828, loss = 0.69199 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:28:04.550013 ops/training.py:65 2019-01-16 17:28:04.549907: step 2829, loss = 0.71754 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:28:05.533425 ops/training.py:65 2019-01-16 17:28:05.533334: step 2830, loss = 0.68338 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:28:06.518051 ops/training.py:65 2019-01-16 17:28:06.517949: step 2831, loss = 0.67728 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:28:07.501907 ops/training.py:65 2019-01-16 17:28:07.501796: step 2832, loss = 0.69452 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:28:08.485396 ops/training.py:65 2019-01-16 17:28:08.485302: step 2833, loss = 0.70040 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:28:09.467632 ops/training.py:65 2019-01-16 17:28:09.467531: step 2834, loss = 0.68485 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:28:10.450190 ops/training.py:65 2019-01-16 17:28:10.450084: step 2835, loss = 0.71029 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:28:11.436805 ops/training.py:65 2019-01-16 17:28:11.436697: step 2836, loss = 0.68138 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:28:12.421344 ops/training.py:65 2019-01-16 17:28:12.421241: step 2837, loss = 0.67376 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:28:13.405379 ops/training.py:65 2019-01-16 17:28:13.405283: step 2838, loss = 0.68955 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:28:14.389013 ops/training.py:65 2019-01-16 17:28:14.388911: step 2839, loss = 0.70538 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:28:15.374826 ops/training.py:65 2019-01-16 17:28:15.374721: step 2840, loss = 0.71091 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:28:16.359198 ops/training.py:65 2019-01-16 17:28:16.359096: step 2841, loss = 0.68347 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:28:17.342445 ops/training.py:65 2019-01-16 17:28:17.342338: step 2842, loss = 0.69756 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:28:18.327818 ops/training.py:65 2019-01-16 17:28:18.327723: step 2843, loss = 0.68835 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:28:19.310714 ops/training.py:65 2019-01-16 17:28:19.310606: step 2844, loss = 0.71015 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:28:20.293944 ops/training.py:65 2019-01-16 17:28:20.293850: step 2845, loss = 0.68811 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:28:21.276489 ops/training.py:65 2019-01-16 17:28:21.276386: step 2846, loss = 0.69949 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:28:22.259490 ops/training.py:65 2019-01-16 17:28:22.259381: step 2847, loss = 0.71194 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:28:23.242310 ops/training.py:65 2019-01-16 17:28:23.242210: step 2848, loss = 0.68882 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:28:24.226566 ops/training.py:65 2019-01-16 17:28:24.226455: step 2849, loss = 0.68487 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:28:25.209316 ops/training.py:65 2019-01-16 17:28:25.209214: step 2850, loss = 0.69669 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:28:26.191936 ops/training.py:65 2019-01-16 17:28:26.191836: step 2851, loss = 0.69514 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:28:27.177019 ops/training.py:65 2019-01-16 17:28:27.176915: step 2852, loss = 0.71115 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:28:28.160267 ops/training.py:65 2019-01-16 17:28:28.160161: step 2853, loss = 0.69742 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:28:29.144063 ops/training.py:65 2019-01-16 17:28:29.143978: step 2854, loss = 0.70518 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:28:30.127328 ops/training.py:65 2019-01-16 17:28:30.127231: step 2855, loss = 0.68041 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:28:31.111815 ops/training.py:65 2019-01-16 17:28:31.111710: step 2856, loss = 0.67931 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:28:32.094559 ops/training.py:65 2019-01-16 17:28:32.094461: step 2857, loss = 0.68063 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:28:33.077619 ops/training.py:65 2019-01-16 17:28:33.077542: step 2858, loss = 0.69429 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:28:34.061600 ops/training.py:65 2019-01-16 17:28:34.061508: step 2859, loss = 0.71642 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:28:35.047010 ops/training.py:65 2019-01-16 17:28:35.046916: step 2860, loss = 0.69290 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:28:36.031571 ops/training.py:65 2019-01-16 17:28:36.031482: step 2861, loss = 0.68209 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:28:37.013438 ops/training.py:65 2019-01-16 17:28:37.013355: step 2862, loss = 0.68364 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:28:37.997701 ops/training.py:65 2019-01-16 17:28:37.997605: step 2863, loss = 0.67973 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 17:28:38.981108 ops/training.py:65 2019-01-16 17:28:38.981011: step 2864, loss = 0.69144 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:28:39.964749 ops/training.py:65 2019-01-16 17:28:39.964652: step 2865, loss = 0.70515 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:28:40.948276 ops/training.py:65 2019-01-16 17:28:40.948183: step 2866, loss = 0.69804 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:28:41.931297 ops/training.py:65 2019-01-16 17:28:41.931198: step 2867, loss = 0.69880 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:28:42.914208 ops/training.py:65 2019-01-16 17:28:42.914112: step 2868, loss = 0.69210 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:28:43.898102 ops/training.py:65 2019-01-16 17:28:43.898009: step 2869, loss = 0.69064 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:28:44.881752 ops/training.py:65 2019-01-16 17:28:44.881654: step 2870, loss = 0.69233 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:28:45.863576 ops/training.py:65 2019-01-16 17:28:45.863497: step 2871, loss = 0.70335 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:28:46.846481 ops/training.py:65 2019-01-16 17:28:46.846388: step 2872, loss = 0.67243 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 17:28:47.829215 ops/training.py:65 2019-01-16 17:28:47.829125: step 2873, loss = 0.68592 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:28:48.811736 ops/training.py:65 2019-01-16 17:28:48.811644: step 2874, loss = 0.69159 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:28:49.797006 ops/training.py:65 2019-01-16 17:28:49.796912: step 2875, loss = 0.69432 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:28:50.779586 ops/training.py:65 2019-01-16 17:28:50.779496: step 2876, loss = 0.68939 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:28:51.764089 ops/training.py:65 2019-01-16 17:28:51.763982: step 2877, loss = 0.68275 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:28:52.750857 ops/training.py:65 2019-01-16 17:28:52.750760: step 2878, loss = 0.70993 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:28:53.736146 ops/training.py:65 2019-01-16 17:28:53.736050: step 2879, loss = 0.69872 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:28:54.719974 ops/training.py:65 2019-01-16 17:28:54.719877: step 2880, loss = 0.71619 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:28:55.705775 ops/training.py:65 2019-01-16 17:28:55.705674: step 2881, loss = 0.69997 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:28:56.689368 ops/training.py:65 2019-01-16 17:28:56.689286: step 2882, loss = 0.69441 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:28:57.672146 ops/training.py:65 2019-01-16 17:28:57.672065: step 2883, loss = 0.69594 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:28:58.654726 ops/training.py:65 2019-01-16 17:28:58.654633: step 2884, loss = 0.69286 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:28:59.637349 ops/training.py:65 2019-01-16 17:28:59.637241: step 2885, loss = 0.68421 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:29:00.620561 ops/training.py:65 2019-01-16 17:29:00.620466: step 2886, loss = 0.71116 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:29:01.603434 ops/training.py:65 2019-01-16 17:29:01.603343: step 2887, loss = 0.68559 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:29:02.585964 ops/training.py:65 2019-01-16 17:29:02.585870: step 2888, loss = 0.66966 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:29:03.568491 ops/training.py:65 2019-01-16 17:29:03.568400: step 2889, loss = 0.69971 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:29:04.552442 ops/training.py:65 2019-01-16 17:29:04.552346: step 2890, loss = 0.69772 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:29:05.535675 ops/training.py:65 2019-01-16 17:29:05.535590: step 2891, loss = 0.69516 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:29:06.519101 ops/training.py:65 2019-01-16 17:29:06.519006: step 2892, loss = 0.68055 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:29:07.504012 ops/training.py:65 2019-01-16 17:29:07.503906: step 2893, loss = 0.68602 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:29:08.489447 ops/training.py:65 2019-01-16 17:29:08.489341: step 2894, loss = 0.68654 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:29:09.473210 ops/training.py:65 2019-01-16 17:29:09.473113: step 2895, loss = 0.69486 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:29:10.457252 ops/training.py:65 2019-01-16 17:29:10.457155: step 2896, loss = 0.68229 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:29:11.442154 ops/training.py:65 2019-01-16 17:29:11.442050: step 2897, loss = 0.68872 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:29:12.426598 ops/training.py:65 2019-01-16 17:29:12.426505: step 2898, loss = 0.67395 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:29:13.411597 ops/training.py:65 2019-01-16 17:29:13.411501: step 2899, loss = 0.69658 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:29:14.394712 ops/training.py:65 2019-01-16 17:29:14.394620: step 2900, loss = 0.68795 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:29:15.379357 ops/training.py:65 2019-01-16 17:29:15.379252: step 2901, loss = 0.69680 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:29:16.363727 ops/training.py:65 2019-01-16 17:29:16.363624: step 2902, loss = 0.69182 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:29:17.350650 ops/training.py:65 2019-01-16 17:29:17.350552: step 2903, loss = 0.69852 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:29:18.336101 ops/training.py:65 2019-01-16 17:29:18.336002: step 2904, loss = 0.71666 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:29:19.321434 ops/training.py:65 2019-01-16 17:29:19.321332: step 2905, loss = 0.69260 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:29:20.306414 ops/training.py:65 2019-01-16 17:29:20.306323: step 2906, loss = 0.68672 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:29:21.292722 ops/training.py:65 2019-01-16 17:29:21.292635: step 2907, loss = 0.67684 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:29:22.278636 ops/training.py:65 2019-01-16 17:29:22.278545: step 2908, loss = 0.67739 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:29:23.264604 ops/training.py:65 2019-01-16 17:29:23.264503: step 2909, loss = 0.70220 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:29:24.247632 ops/training.py:65 2019-01-16 17:29:24.247541: step 2910, loss = 0.69018 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:29:25.232840 ops/training.py:65 2019-01-16 17:29:25.232736: step 2911, loss = 0.70091 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:29:26.215689 ops/training.py:65 2019-01-16 17:29:26.215602: step 2912, loss = 0.67850 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:29:27.197126 ops/training.py:65 2019-01-16 17:29:27.197061: step 2913, loss = 0.71232 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:29:28.176808 ops/training.py:65 2019-01-16 17:29:28.176743: step 2914, loss = 0.70489 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:29:29.157897 ops/training.py:65 2019-01-16 17:29:29.157832: step 2915, loss = 0.68166 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:29:30.139483 ops/training.py:65 2019-01-16 17:29:30.139395: step 2916, loss = 0.67822 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:29:31.119398 ops/training.py:65 2019-01-16 17:29:31.119332: step 2917, loss = 0.68580 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:29:32.102571 ops/training.py:65 2019-01-16 17:29:32.102488: step 2918, loss = 0.68284 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:29:33.087039 ops/training.py:65 2019-01-16 17:29:33.086938: step 2919, loss = 0.69578 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:29:34.070571 ops/training.py:65 2019-01-16 17:29:34.070467: step 2920, loss = 0.67560 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:29:35.053143 ops/training.py:65 2019-01-16 17:29:35.053039: step 2921, loss = 0.69457 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:29:36.036185 ops/training.py:65 2019-01-16 17:29:36.036086: step 2922, loss = 0.70316 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:29:37.019276 ops/training.py:65 2019-01-16 17:29:37.019128: step 2923, loss = 0.70806 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:29:38.005223 ops/training.py:65 2019-01-16 17:29:38.005125: step 2924, loss = 0.70846 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:29:38.988932 ops/training.py:65 2019-01-16 17:29:38.988794: step 2925, loss = 0.70773 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:29:39.971712 ops/training.py:65 2019-01-16 17:29:39.971613: step 2926, loss = 0.68188 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:29:40.954609 ops/training.py:65 2019-01-16 17:29:40.954507: step 2927, loss = 0.68602 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:29:41.936892 ops/training.py:65 2019-01-16 17:29:41.936793: step 2928, loss = 0.70449 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:29:42.918854 ops/training.py:65 2019-01-16 17:29:42.918761: step 2929, loss = 0.70000 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:29:43.900336 ops/training.py:65 2019-01-16 17:29:43.900243: step 2930, loss = 0.69763 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:29:44.883799 ops/training.py:65 2019-01-16 17:29:44.883700: step 2931, loss = 0.71629 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:29:45.867516 ops/training.py:65 2019-01-16 17:29:45.867414: step 2932, loss = 0.69105 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:29:46.851591 ops/training.py:65 2019-01-16 17:29:46.851489: step 2933, loss = 0.69622 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:29:47.836396 ops/training.py:65 2019-01-16 17:29:47.836286: step 2934, loss = 0.70010 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:29:48.818030 ops/training.py:65 2019-01-16 17:29:48.817953: step 2935, loss = 0.68927 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:29:49.798382 ops/training.py:65 2019-01-16 17:29:49.798307: step 2936, loss = 0.68565 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:29:50.782376 ops/training.py:65 2019-01-16 17:29:50.782308: step 2937, loss = 0.71136 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:29:51.766910 ops/training.py:65 2019-01-16 17:29:51.766809: step 2938, loss = 0.70219 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:29:52.749653 ops/training.py:65 2019-01-16 17:29:52.749550: step 2939, loss = 0.67707 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:29:53.732756 ops/training.py:65 2019-01-16 17:29:53.732662: step 2940, loss = 0.66185 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:29:54.715348 ops/training.py:65 2019-01-16 17:29:54.715246: step 2941, loss = 0.69249 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:29:55.698131 ops/training.py:65 2019-01-16 17:29:55.698031: step 2942, loss = 0.68985 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:29:56.681655 ops/training.py:65 2019-01-16 17:29:56.681552: step 2943, loss = 0.69913 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:29:57.662882 ops/training.py:65 2019-01-16 17:29:57.662772: step 2944, loss = 0.68610 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:29:58.645438 ops/training.py:65 2019-01-16 17:29:58.645348: step 2945, loss = 0.69446 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:29:59.627285 ops/training.py:65 2019-01-16 17:29:59.627187: step 2946, loss = 0.70761 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:30:00.610509 ops/training.py:65 2019-01-16 17:30:00.610406: step 2947, loss = 0.68007 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:30:01.591721 ops/training.py:65 2019-01-16 17:30:01.591630: step 2948, loss = 0.68228 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:30:02.573902 ops/training.py:65 2019-01-16 17:30:02.573805: step 2949, loss = 0.71711 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:30:03.557301 ops/training.py:65 2019-01-16 17:30:03.557200: step 2950, loss = 0.68069 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:30:04.541294 ops/training.py:65 2019-01-16 17:30:04.541185: step 2951, loss = 0.69372 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:30:05.525900 ops/training.py:65 2019-01-16 17:30:05.525809: step 2952, loss = 0.68663 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:30:06.510899 ops/training.py:65 2019-01-16 17:30:06.510794: step 2953, loss = 0.70308 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:30:07.495665 ops/training.py:65 2019-01-16 17:30:07.495559: step 2954, loss = 0.69994 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:30:08.479329 ops/training.py:65 2019-01-16 17:30:08.479223: step 2955, loss = 0.69169 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:30:09.462900 ops/training.py:65 2019-01-16 17:30:09.462804: step 2956, loss = 0.67481 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:30:10.446151 ops/training.py:65 2019-01-16 17:30:10.446047: step 2957, loss = 0.68127 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:30:11.429019 ops/training.py:65 2019-01-16 17:30:11.428910: step 2958, loss = 0.70258 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:30:12.412213 ops/training.py:65 2019-01-16 17:30:12.412129: step 2959, loss = 0.68187 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:30:13.397097 ops/training.py:65 2019-01-16 17:30:13.397002: step 2960, loss = 0.69718 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:30:14.381043 ops/training.py:65 2019-01-16 17:30:14.380955: step 2961, loss = 0.69894 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:30:15.363181 ops/training.py:65 2019-01-16 17:30:15.363075: step 2962, loss = 0.70077 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:30:16.343626 ops/training.py:65 2019-01-16 17:30:16.343540: step 2963, loss = 0.68072 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:30:17.324633 ops/training.py:65 2019-01-16 17:30:17.324529: step 2964, loss = 0.71541 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:30:18.305769 ops/training.py:65 2019-01-16 17:30:18.305662: step 2965, loss = 0.69055 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:30:19.288741 ops/training.py:65 2019-01-16 17:30:19.288639: step 2966, loss = 0.71131 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:30:20.271306 ops/training.py:65 2019-01-16 17:30:20.271203: step 2967, loss = 0.70990 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:30:21.253028 ops/training.py:65 2019-01-16 17:30:21.252956: step 2968, loss = 0.69959 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:30:22.235801 ops/training.py:65 2019-01-16 17:30:22.235694: step 2969, loss = 0.71527 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:30:23.218023 ops/training.py:65 2019-01-16 17:30:23.217917: step 2970, loss = 0.72047 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:30:24.200450 ops/training.py:65 2019-01-16 17:30:24.200348: step 2971, loss = 0.70912 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:30:25.185659 ops/training.py:65 2019-01-16 17:30:25.185562: step 2972, loss = 0.71117 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:30:26.170594 ops/training.py:65 2019-01-16 17:30:26.170494: step 2973, loss = 0.68976 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:30:27.155767 ops/training.py:65 2019-01-16 17:30:27.155662: step 2974, loss = 0.71391 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:30:28.139942 ops/training.py:65 2019-01-16 17:30:28.139841: step 2975, loss = 0.67679 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:30:29.123902 ops/training.py:65 2019-01-16 17:30:29.123798: step 2976, loss = 0.70971 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:30:30.106999 ops/training.py:65 2019-01-16 17:30:30.106899: step 2977, loss = 0.69005 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:30:31.092706 ops/training.py:65 2019-01-16 17:30:31.092599: step 2978, loss = 0.69775 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:30:32.074817 ops/training.py:65 2019-01-16 17:30:32.074720: step 2979, loss = 0.68584 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:30:33.058031 ops/training.py:65 2019-01-16 17:30:33.057927: step 2980, loss = 0.69263 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:30:34.041037 ops/training.py:65 2019-01-16 17:30:34.040940: step 2981, loss = 0.68799 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:30:35.023552 ops/training.py:65 2019-01-16 17:30:35.023447: step 2982, loss = 0.68043 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:30:36.007202 ops/training.py:65 2019-01-16 17:30:36.007110: step 2983, loss = 0.72362 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:30:36.991754 ops/training.py:65 2019-01-16 17:30:36.991653: step 2984, loss = 0.70429 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:30:37.974989 ops/training.py:65 2019-01-16 17:30:37.974891: step 2985, loss = 0.67466 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:30:38.959373 ops/training.py:65 2019-01-16 17:30:38.959272: step 2986, loss = 0.67548 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:30:39.943501 ops/training.py:65 2019-01-16 17:30:39.943395: step 2987, loss = 0.70813 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:30:40.925913 ops/training.py:65 2019-01-16 17:30:40.925778: step 2988, loss = 0.69538 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:30:41.908438 ops/training.py:65 2019-01-16 17:30:41.908335: step 2989, loss = 0.70340 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:30:42.889632 ops/training.py:65 2019-01-16 17:30:42.889543: step 2990, loss = 0.66508 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:30:43.873758 ops/training.py:65 2019-01-16 17:30:43.873668: step 2991, loss = 0.69482 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:30:44.857355 ops/training.py:65 2019-01-16 17:30:44.857255: step 2992, loss = 0.69417 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:30:45.840499 ops/training.py:65 2019-01-16 17:30:45.840394: step 2993, loss = 0.70224 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:30:46.823933 ops/training.py:65 2019-01-16 17:30:46.823847: step 2994, loss = 0.70732 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:30:47.807151 ops/training.py:65 2019-01-16 17:30:47.807041: step 2995, loss = 0.70531 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:30:48.790222 ops/training.py:65 2019-01-16 17:30:48.790113: step 2996, loss = 0.66339 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:30:49.771089 ops/training.py:65 2019-01-16 17:30:49.770992: step 2997, loss = 0.70241 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:30:50.753295 ops/training.py:65 2019-01-16 17:30:50.753201: step 2998, loss = 0.67935 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:30:51.736105 ops/training.py:65 2019-01-16 17:30:51.735997: step 2999, loss = 0.67937 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:30:52.717898 ops/training.py:65 2019-01-16 17:30:52.717796: step 3000, loss = 0.70043 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:30:53.700247 ops/training.py:65 2019-01-16 17:30:53.700145: step 3001, loss = 0.70806 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:30:54.681859 ops/training.py:65 2019-01-16 17:30:54.681713: step 3002, loss = 0.71273 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:30:55.665056 ops/training.py:65 2019-01-16 17:30:55.664950: step 3003, loss = 0.69175 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:30:56.646351 ops/training.py:65 2019-01-16 17:30:56.646245: step 3004, loss = 0.71115 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:30:57.627481 ops/training.py:65 2019-01-16 17:30:57.627389: step 3005, loss = 0.69519 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:30:58.609837 ops/training.py:65 2019-01-16 17:30:58.609732: step 3006, loss = 0.70859 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:30:59.594243 ops/training.py:65 2019-01-16 17:30:59.594135: step 3007, loss = 0.67849 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:31:00.576420 ops/training.py:65 2019-01-16 17:31:00.576320: step 3008, loss = 0.67089 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:31:01.558008 ops/training.py:65 2019-01-16 17:31:01.557904: step 3009, loss = 0.68619 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:31:02.539452 ops/training.py:65 2019-01-16 17:31:02.539354: step 3010, loss = 0.69288 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:31:03.522015 ops/training.py:65 2019-01-16 17:31:03.521912: step 3011, loss = 0.70839 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:31:04.506735 ops/training.py:65 2019-01-16 17:31:04.506628: step 3012, loss = 0.67198 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:31:05.490634 ops/training.py:65 2019-01-16 17:31:05.490550: step 3013, loss = 0.69414 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:31:06.474656 ops/training.py:65 2019-01-16 17:31:06.474552: step 3014, loss = 0.70110 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:31:07.458416 ops/training.py:65 2019-01-16 17:31:07.458341: step 3015, loss = 0.69072 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:31:08.441156 ops/training.py:65 2019-01-16 17:31:08.441090: step 3016, loss = 0.68830 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:31:09.426786 ops/training.py:65 2019-01-16 17:31:09.426645: step 3017, loss = 0.71790 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:31:10.412586 ops/training.py:65 2019-01-16 17:31:10.412480: step 3018, loss = 0.69774 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:31:11.396122 ops/training.py:65 2019-01-16 17:31:11.396013: step 3019, loss = 0.67131 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.75
I8192 2019-01-16 17:31:12.380569 ops/training.py:65 2019-01-16 17:31:12.380457: step 3020, loss = 0.69754 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:31:13.363719 ops/training.py:65 2019-01-16 17:31:13.363623: step 3021, loss = 0.70957 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:31:14.347180 ops/training.py:65 2019-01-16 17:31:14.347076: step 3022, loss = 0.70035 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:31:15.332201 ops/training.py:65 2019-01-16 17:31:15.332098: step 3023, loss = 0.70166 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:31:16.315711 ops/training.py:65 2019-01-16 17:31:16.315618: step 3024, loss = 0.68953 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:31:17.297513 ops/training.py:65 2019-01-16 17:31:17.297408: step 3025, loss = 0.71611 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:31:18.280162 ops/training.py:65 2019-01-16 17:31:18.280054: step 3026, loss = 0.68842 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:31:19.262928 ops/training.py:65 2019-01-16 17:31:19.262840: step 3027, loss = 0.71258 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:31:20.244045 ops/training.py:65 2019-01-16 17:31:20.243978: step 3028, loss = 0.68791 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:31:21.227993 ops/training.py:65 2019-01-16 17:31:21.227917: step 3029, loss = 0.71498 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:31:22.211327 ops/training.py:65 2019-01-16 17:31:22.211225: step 3030, loss = 0.69789 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:31:23.193852 ops/training.py:65 2019-01-16 17:31:23.193752: step 3031, loss = 0.69035 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:31:24.174700 ops/training.py:65 2019-01-16 17:31:24.174596: step 3032, loss = 0.69226 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:31:25.157464 ops/training.py:65 2019-01-16 17:31:25.157359: step 3033, loss = 0.68115 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:31:26.139310 ops/training.py:65 2019-01-16 17:31:26.139226: step 3034, loss = 0.69267 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:31:27.122350 ops/training.py:65 2019-01-16 17:31:27.122248: step 3035, loss = 0.69808 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:31:28.105449 ops/training.py:65 2019-01-16 17:31:28.105344: step 3036, loss = 0.70737 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:31:29.088215 ops/training.py:65 2019-01-16 17:31:29.088113: step 3037, loss = 0.68377 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:31:30.072261 ops/training.py:65 2019-01-16 17:31:30.072160: step 3038, loss = 0.69160 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:31:31.057451 ops/training.py:65 2019-01-16 17:31:31.057344: step 3039, loss = 0.69864 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:31:32.039841 ops/training.py:65 2019-01-16 17:31:32.039743: step 3040, loss = 0.68564 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:31:33.021360 ops/training.py:65 2019-01-16 17:31:33.021267: step 3041, loss = 0.70144 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:31:34.003182 ops/training.py:65 2019-01-16 17:31:34.003073: step 3042, loss = 0.70239 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:31:34.985266 ops/training.py:65 2019-01-16 17:31:34.985166: step 3043, loss = 0.69953 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:31:35.969022 ops/training.py:65 2019-01-16 17:31:35.968924: step 3044, loss = 0.70685 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:31:36.952632 ops/training.py:65 2019-01-16 17:31:36.952533: step 3045, loss = 0.70614 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:31:37.935502 ops/training.py:65 2019-01-16 17:31:37.935401: step 3046, loss = 0.72159 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:31:38.920619 ops/training.py:65 2019-01-16 17:31:38.920509: step 3047, loss = 0.71522 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:31:39.903529 ops/training.py:65 2019-01-16 17:31:39.903422: step 3048, loss = 0.69708 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:31:40.884724 ops/training.py:65 2019-01-16 17:31:40.884632: step 3049, loss = 0.69206 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:31:41.867197 ops/training.py:65 2019-01-16 17:31:41.867098: step 3050, loss = 0.70075 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:31:42.852051 ops/training.py:65 2019-01-16 17:31:42.851939: step 3051, loss = 0.66681 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:31:43.835388 ops/training.py:65 2019-01-16 17:31:43.835290: step 3052, loss = 0.67925 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:31:44.818219 ops/training.py:65 2019-01-16 17:31:44.818118: step 3053, loss = 0.71900 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:31:45.799379 ops/training.py:65 2019-01-16 17:31:45.799269: step 3054, loss = 0.72816 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:31:46.781521 ops/training.py:65 2019-01-16 17:31:46.781419: step 3055, loss = 0.70381 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:31:47.762412 ops/training.py:65 2019-01-16 17:31:47.762306: step 3056, loss = 0.69405 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:31:48.745549 ops/training.py:65 2019-01-16 17:31:48.745444: step 3057, loss = 0.70347 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:31:49.728338 ops/training.py:65 2019-01-16 17:31:49.728232: step 3058, loss = 0.68646 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:31:50.710808 ops/training.py:65 2019-01-16 17:31:50.710712: step 3059, loss = 0.69367 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:31:51.692677 ops/training.py:65 2019-01-16 17:31:51.692565: step 3060, loss = 0.71377 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:31:52.675020 ops/training.py:65 2019-01-16 17:31:52.674921: step 3061, loss = 0.70088 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:31:53.656953 ops/training.py:65 2019-01-16 17:31:53.656859: step 3062, loss = 0.67892 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:31:54.641765 ops/training.py:65 2019-01-16 17:31:54.641667: step 3063, loss = 0.72153 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:31:55.625429 ops/training.py:65 2019-01-16 17:31:55.625325: step 3064, loss = 0.69749 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:31:56.608794 ops/training.py:65 2019-01-16 17:31:56.608690: step 3065, loss = 0.68089 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:31:57.594046 ops/training.py:65 2019-01-16 17:31:57.593944: step 3066, loss = 0.67714 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:31:58.578718 ops/training.py:65 2019-01-16 17:31:58.578613: step 3067, loss = 0.70751 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:31:59.561627 ops/training.py:65 2019-01-16 17:31:59.561523: step 3068, loss = 0.70392 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:32:00.544626 ops/training.py:65 2019-01-16 17:32:00.544539: step 3069, loss = 0.71094 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:32:01.528174 ops/training.py:65 2019-01-16 17:32:01.528078: step 3070, loss = 0.69313 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:32:02.511266 ops/training.py:65 2019-01-16 17:32:02.511166: step 3071, loss = 0.69254 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:32:03.495449 ops/training.py:65 2019-01-16 17:32:03.495349: step 3072, loss = 0.69328 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:32:04.478855 ops/training.py:65 2019-01-16 17:32:04.478768: step 3073, loss = 0.67879 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:32:05.461701 ops/training.py:65 2019-01-16 17:32:05.461615: step 3074, loss = 0.70337 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:32:06.444938 ops/training.py:65 2019-01-16 17:32:06.444837: step 3075, loss = 0.69360 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:32:07.427141 ops/training.py:65 2019-01-16 17:32:07.427035: step 3076, loss = 0.68668 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:32:08.410465 ops/training.py:65 2019-01-16 17:32:08.410361: step 3077, loss = 0.70019 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:32:09.393815 ops/training.py:65 2019-01-16 17:32:09.393714: step 3078, loss = 0.70026 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:32:10.376547 ops/training.py:65 2019-01-16 17:32:10.376464: step 3079, loss = 0.68664 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:32:11.358711 ops/training.py:65 2019-01-16 17:32:11.358607: step 3080, loss = 0.71381 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:32:12.343073 ops/training.py:65 2019-01-16 17:32:12.342982: step 3081, loss = 0.71882 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:32:13.326306 ops/training.py:65 2019-01-16 17:32:13.326209: step 3082, loss = 0.69834 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:32:14.310697 ops/training.py:65 2019-01-16 17:32:14.310614: step 3083, loss = 0.68840 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:32:15.293672 ops/training.py:65 2019-01-16 17:32:15.293569: step 3084, loss = 0.67876 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:32:16.276355 ops/training.py:65 2019-01-16 17:32:16.276249: step 3085, loss = 0.69963 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:32:17.262691 ops/training.py:65 2019-01-16 17:32:17.262589: step 3086, loss = 0.66379 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.75
I8192 2019-01-16 17:32:18.246533 ops/training.py:65 2019-01-16 17:32:18.246434: step 3087, loss = 0.69932 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:32:19.229838 ops/training.py:65 2019-01-16 17:32:19.229735: step 3088, loss = 0.72309 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:32:20.214077 ops/training.py:65 2019-01-16 17:32:20.213979: step 3089, loss = 0.68623 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:32:21.196804 ops/training.py:65 2019-01-16 17:32:21.196712: step 3090, loss = 0.72022 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:32:22.178981 ops/training.py:65 2019-01-16 17:32:22.178891: step 3091, loss = 0.69173 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:32:23.162593 ops/training.py:65 2019-01-16 17:32:23.162498: step 3092, loss = 0.70115 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:32:24.144878 ops/training.py:65 2019-01-16 17:32:24.144779: step 3093, loss = 0.69386 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:32:25.127621 ops/training.py:65 2019-01-16 17:32:25.127517: step 3094, loss = 0.69290 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:32:26.110690 ops/training.py:65 2019-01-16 17:32:26.110586: step 3095, loss = 0.69861 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:32:27.093061 ops/training.py:65 2019-01-16 17:32:27.092953: step 3096, loss = 0.69095 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:32:28.076170 ops/training.py:65 2019-01-16 17:32:28.076072: step 3097, loss = 0.69491 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:32:29.058142 ops/training.py:65 2019-01-16 17:32:29.058046: step 3098, loss = 0.69284 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:32:30.042147 ops/training.py:65 2019-01-16 17:32:30.042040: step 3099, loss = 0.67697 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:32:31.026159 ops/training.py:65 2019-01-16 17:32:31.026057: step 3100, loss = 0.69906 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:32:32.010774 ops/training.py:65 2019-01-16 17:32:32.010675: step 3101, loss = 0.69128 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:32:32.993727 ops/training.py:65 2019-01-16 17:32:32.993633: step 3102, loss = 0.70322 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:32:33.977484 ops/training.py:65 2019-01-16 17:32:33.977388: step 3103, loss = 0.69554 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:32:34.960851 ops/training.py:65 2019-01-16 17:32:34.960757: step 3104, loss = 0.71270 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:32:35.943933 ops/training.py:65 2019-01-16 17:32:35.943846: step 3105, loss = 0.69247 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:32:36.928575 ops/training.py:65 2019-01-16 17:32:36.928480: step 3106, loss = 0.69459 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:32:37.910562 ops/training.py:65 2019-01-16 17:32:37.910466: step 3107, loss = 0.69048 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:32:38.892712 ops/training.py:65 2019-01-16 17:32:38.892603: step 3108, loss = 0.70495 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:32:39.873973 ops/training.py:65 2019-01-16 17:32:39.873876: step 3109, loss = 0.70527 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:32:40.855674 ops/training.py:65 2019-01-16 17:32:40.855575: step 3110, loss = 0.68746 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:32:41.838815 ops/training.py:65 2019-01-16 17:32:41.838728: step 3111, loss = 0.67798 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:32:42.822586 ops/training.py:65 2019-01-16 17:32:42.822492: step 3112, loss = 0.68879 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:32:43.806668 ops/training.py:65 2019-01-16 17:32:43.806574: step 3113, loss = 0.66982 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.8125
I8192 2019-01-16 17:32:44.791121 ops/training.py:65 2019-01-16 17:32:44.791019: step 3114, loss = 0.69617 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:32:45.775889 ops/training.py:65 2019-01-16 17:32:45.775791: step 3115, loss = 0.68597 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:32:46.758672 ops/training.py:65 2019-01-16 17:32:46.758578: step 3116, loss = 0.70257 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:32:47.742532 ops/training.py:65 2019-01-16 17:32:47.742430: step 3117, loss = 0.67710 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:32:48.725561 ops/training.py:65 2019-01-16 17:32:48.725454: step 3118, loss = 0.69551 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:32:49.708091 ops/training.py:65 2019-01-16 17:32:49.707992: step 3119, loss = 0.69849 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:32:50.691137 ops/training.py:65 2019-01-16 17:32:50.691049: step 3120, loss = 0.69758 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:32:51.674961 ops/training.py:65 2019-01-16 17:32:51.674862: step 3121, loss = 0.68781 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:32:52.658367 ops/training.py:65 2019-01-16 17:32:52.658271: step 3122, loss = 0.69420 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:32:53.641678 ops/training.py:65 2019-01-16 17:32:53.641577: step 3123, loss = 0.69864 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:32:54.625674 ops/training.py:65 2019-01-16 17:32:54.625576: step 3124, loss = 0.68399 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:32:55.608865 ops/training.py:65 2019-01-16 17:32:55.608757: step 3125, loss = 0.71321 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:32:56.592600 ops/training.py:65 2019-01-16 17:32:56.592501: step 3126, loss = 0.70508 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:32:57.577625 ops/training.py:65 2019-01-16 17:32:57.577546: step 3127, loss = 0.68021 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:32:58.560615 ops/training.py:65 2019-01-16 17:32:58.560515: step 3128, loss = 0.70564 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:32:59.543760 ops/training.py:65 2019-01-16 17:32:59.543659: step 3129, loss = 0.70783 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:33:00.525138 ops/training.py:65 2019-01-16 17:33:00.525039: step 3130, loss = 0.69386 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:33:01.508196 ops/training.py:65 2019-01-16 17:33:01.508091: step 3131, loss = 0.68069 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:33:02.492145 ops/training.py:65 2019-01-16 17:33:02.492037: step 3132, loss = 0.71604 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:33:03.477610 ops/training.py:65 2019-01-16 17:33:03.477514: step 3133, loss = 0.70570 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:33:04.459845 ops/training.py:65 2019-01-16 17:33:04.459747: step 3134, loss = 0.69342 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:33:05.442418 ops/training.py:65 2019-01-16 17:33:05.442320: step 3135, loss = 0.68581 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:33:06.424737 ops/training.py:65 2019-01-16 17:33:06.424649: step 3136, loss = 0.69612 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:33:07.408590 ops/training.py:65 2019-01-16 17:33:07.408481: step 3137, loss = 0.70080 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:33:08.391011 ops/training.py:65 2019-01-16 17:33:08.390912: step 3138, loss = 0.71052 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:33:09.374292 ops/training.py:65 2019-01-16 17:33:09.374184: step 3139, loss = 0.71799 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:33:10.356869 ops/training.py:65 2019-01-16 17:33:10.356768: step 3140, loss = 0.70336 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:33:11.338655 ops/training.py:65 2019-01-16 17:33:11.338550: step 3141, loss = 0.68487 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:33:12.320373 ops/training.py:65 2019-01-16 17:33:12.320269: step 3142, loss = 0.68770 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:33:13.302619 ops/training.py:65 2019-01-16 17:33:13.302538: step 3143, loss = 0.68682 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:33:14.285467 ops/training.py:65 2019-01-16 17:33:14.285369: step 3144, loss = 0.67964 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:33:15.268470 ops/training.py:65 2019-01-16 17:33:15.268376: step 3145, loss = 0.68748 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:33:16.254841 ops/training.py:65 2019-01-16 17:33:16.254743: step 3146, loss = 0.68921 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:33:17.238239 ops/training.py:65 2019-01-16 17:33:17.238139: step 3147, loss = 0.70157 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:33:18.221529 ops/training.py:65 2019-01-16 17:33:18.221426: step 3148, loss = 0.69791 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:33:19.204605 ops/training.py:65 2019-01-16 17:33:19.204496: step 3149, loss = 0.70058 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:33:20.188259 ops/training.py:65 2019-01-16 17:33:20.188156: step 3150, loss = 0.69224 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:33:21.173124 ops/training.py:65 2019-01-16 17:33:21.173034: step 3151, loss = 0.70351 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:33:22.156816 ops/training.py:65 2019-01-16 17:33:22.156715: step 3152, loss = 0.67174 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:33:23.141649 ops/training.py:65 2019-01-16 17:33:23.141548: step 3153, loss = 0.67226 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:33:24.126393 ops/training.py:65 2019-01-16 17:33:24.126294: step 3154, loss = 0.69785 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:33:25.110667 ops/training.py:65 2019-01-16 17:33:25.110563: step 3155, loss = 0.67390 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:33:26.095654 ops/training.py:65 2019-01-16 17:33:26.095549: step 3156, loss = 0.71339 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:33:27.078952 ops/training.py:65 2019-01-16 17:33:27.078844: step 3157, loss = 0.69629 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:33:28.062951 ops/training.py:65 2019-01-16 17:33:28.062843: step 3158, loss = 0.68168 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:33:29.045698 ops/training.py:65 2019-01-16 17:33:29.045590: step 3159, loss = 0.67628 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:33:30.029696 ops/training.py:65 2019-01-16 17:33:30.029598: step 3160, loss = 0.70532 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:33:31.014288 ops/training.py:65 2019-01-16 17:33:31.014184: step 3161, loss = 0.69218 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:33:31.998500 ops/training.py:65 2019-01-16 17:33:31.998390: step 3162, loss = 0.71078 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:33:32.979628 ops/training.py:65 2019-01-16 17:33:32.979543: step 3163, loss = 0.69954 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:33:33.962825 ops/training.py:65 2019-01-16 17:33:33.962735: step 3164, loss = 0.68837 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:33:34.944595 ops/training.py:65 2019-01-16 17:33:34.944505: step 3165, loss = 0.68762 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:33:35.927356 ops/training.py:65 2019-01-16 17:33:35.927265: step 3166, loss = 0.69827 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:33:36.908892 ops/training.py:65 2019-01-16 17:33:36.908794: step 3167, loss = 0.67910 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:33:37.890168 ops/training.py:65 2019-01-16 17:33:37.890065: step 3168, loss = 0.71833 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:33:38.872883 ops/training.py:65 2019-01-16 17:33:38.872790: step 3169, loss = 0.69877 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:33:39.856489 ops/training.py:65 2019-01-16 17:33:39.856380: step 3170, loss = 0.69181 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:33:40.839925 ops/training.py:65 2019-01-16 17:33:40.839822: step 3171, loss = 0.71451 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:33:41.822390 ops/training.py:65 2019-01-16 17:33:41.822286: step 3172, loss = 0.68850 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:33:42.805251 ops/training.py:65 2019-01-16 17:33:42.805139: step 3173, loss = 0.71858 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:33:43.790010 ops/training.py:65 2019-01-16 17:33:43.789909: step 3174, loss = 0.69480 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:33:44.774790 ops/training.py:65 2019-01-16 17:33:44.774694: step 3175, loss = 0.69651 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:33:45.757781 ops/training.py:65 2019-01-16 17:33:45.757681: step 3176, loss = 0.69995 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:33:46.739270 ops/training.py:65 2019-01-16 17:33:46.739161: step 3177, loss = 0.69917 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:33:47.721176 ops/training.py:65 2019-01-16 17:33:47.721072: step 3178, loss = 0.70694 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:33:48.704199 ops/training.py:65 2019-01-16 17:33:48.704087: step 3179, loss = 0.68211 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:33:49.688736 ops/training.py:65 2019-01-16 17:33:49.688627: step 3180, loss = 0.68008 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:33:50.672734 ops/training.py:65 2019-01-16 17:33:50.672655: step 3181, loss = 0.69260 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:33:51.656929 ops/training.py:65 2019-01-16 17:33:51.656854: step 3182, loss = 0.69858 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:33:52.639743 ops/training.py:65 2019-01-16 17:33:52.639643: step 3183, loss = 0.67915 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:33:53.624554 ops/training.py:65 2019-01-16 17:33:53.624457: step 3184, loss = 0.70263 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:33:54.608054 ops/training.py:65 2019-01-16 17:33:54.607956: step 3185, loss = 0.68349 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:33:55.590134 ops/training.py:65 2019-01-16 17:33:55.590033: step 3186, loss = 0.69428 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:33:56.572279 ops/training.py:65 2019-01-16 17:33:56.572181: step 3187, loss = 0.68486 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:33:57.554624 ops/training.py:65 2019-01-16 17:33:57.554524: step 3188, loss = 0.67312 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:33:58.537335 ops/training.py:65 2019-01-16 17:33:58.537226: step 3189, loss = 0.68733 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:33:59.519288 ops/training.py:65 2019-01-16 17:33:59.519181: step 3190, loss = 0.67969 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:34:00.502326 ops/training.py:65 2019-01-16 17:34:00.502216: step 3191, loss = 0.69727 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:34:01.485322 ops/training.py:65 2019-01-16 17:34:01.485221: step 3192, loss = 0.69356 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:34:02.467883 ops/training.py:65 2019-01-16 17:34:02.467780: step 3193, loss = 0.70544 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:34:03.452274 ops/training.py:65 2019-01-16 17:34:03.452178: step 3194, loss = 0.70324 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:34:04.436902 ops/training.py:65 2019-01-16 17:34:04.436790: step 3195, loss = 0.69058 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:34:05.420166 ops/training.py:65 2019-01-16 17:34:05.420062: step 3196, loss = 0.69525 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:34:06.402687 ops/training.py:65 2019-01-16 17:34:06.402594: step 3197, loss = 0.68003 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:34:07.386470 ops/training.py:65 2019-01-16 17:34:07.386358: step 3198, loss = 0.71591 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:34:08.368892 ops/training.py:65 2019-01-16 17:34:08.368787: step 3199, loss = 0.72771 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.21875
I8192 2019-01-16 17:34:09.350212 ops/training.py:65 2019-01-16 17:34:09.350111: step 3200, loss = 0.69270 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:34:10.331736 ops/training.py:65 2019-01-16 17:34:10.331628: step 3201, loss = 0.70813 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:34:11.313665 ops/training.py:65 2019-01-16 17:34:11.313558: step 3202, loss = 0.69383 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:34:12.297939 ops/training.py:65 2019-01-16 17:34:12.297834: step 3203, loss = 0.68622 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:34:13.281952 ops/training.py:65 2019-01-16 17:34:13.281844: step 3204, loss = 0.68118 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:34:14.266617 ops/training.py:65 2019-01-16 17:34:14.266506: step 3205, loss = 0.68324 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:34:15.249214 ops/training.py:65 2019-01-16 17:34:15.249102: step 3206, loss = 0.68542 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:34:16.232620 ops/training.py:65 2019-01-16 17:34:16.232476: step 3207, loss = 0.70234 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:34:17.216966 ops/training.py:65 2019-01-16 17:34:17.216861: step 3208, loss = 0.68647 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:34:18.201994 ops/training.py:65 2019-01-16 17:34:18.201906: step 3209, loss = 0.68890 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:34:19.185618 ops/training.py:65 2019-01-16 17:34:19.185517: step 3210, loss = 0.68162 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:34:20.168607 ops/training.py:65 2019-01-16 17:34:20.168514: step 3211, loss = 0.69374 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:34:21.153681 ops/training.py:65 2019-01-16 17:34:21.153589: step 3212, loss = 0.70625 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:34:22.137805 ops/training.py:65 2019-01-16 17:34:22.137701: step 3213, loss = 0.70655 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:34:23.122486 ops/training.py:65 2019-01-16 17:34:23.122387: step 3214, loss = 0.71357 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:34:24.106795 ops/training.py:65 2019-01-16 17:34:24.106665: step 3215, loss = 0.70381 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:34:25.093111 ops/training.py:65 2019-01-16 17:34:25.093008: step 3216, loss = 0.66614 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.75
I8192 2019-01-16 17:34:26.077375 ops/training.py:65 2019-01-16 17:34:26.077255: step 3217, loss = 0.70503 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:34:27.059546 ops/training.py:65 2019-01-16 17:34:27.059453: step 3218, loss = 0.70722 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:34:28.041969 ops/training.py:65 2019-01-16 17:34:28.041858: step 3219, loss = 0.71921 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 17:34:29.025034 ops/training.py:65 2019-01-16 17:34:29.024925: step 3220, loss = 0.69679 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:34:30.006523 ops/training.py:65 2019-01-16 17:34:30.006420: step 3221, loss = 0.68783 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:34:30.987632 ops/training.py:65 2019-01-16 17:34:30.987544: step 3222, loss = 0.67771 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:34:31.969249 ops/training.py:65 2019-01-16 17:34:31.969148: step 3223, loss = 0.70405 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:34:32.951166 ops/training.py:65 2019-01-16 17:34:32.951065: step 3224, loss = 0.69094 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:34:33.933058 ops/training.py:65 2019-01-16 17:34:33.932966: step 3225, loss = 0.70551 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:34:34.916510 ops/training.py:65 2019-01-16 17:34:34.916403: step 3226, loss = 0.70298 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:34:35.900954 ops/training.py:65 2019-01-16 17:34:35.900855: step 3227, loss = 0.68265 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:34:36.884855 ops/training.py:65 2019-01-16 17:34:36.884751: step 3228, loss = 0.68020 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:34:37.868952 ops/training.py:65 2019-01-16 17:34:37.868843: step 3229, loss = 0.69954 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:34:38.853595 ops/training.py:65 2019-01-16 17:34:38.853497: step 3230, loss = 0.69121 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:34:39.836455 ops/training.py:65 2019-01-16 17:34:39.836346: step 3231, loss = 0.70123 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:34:40.819761 ops/training.py:65 2019-01-16 17:34:40.819664: step 3232, loss = 0.70288 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:34:41.801031 ops/training.py:65 2019-01-16 17:34:41.800937: step 3233, loss = 0.69273 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:34:42.784164 ops/training.py:65 2019-01-16 17:34:42.784064: step 3234, loss = 0.68604 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:34:43.766150 ops/training.py:65 2019-01-16 17:34:43.766050: step 3235, loss = 0.69449 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:34:44.749008 ops/training.py:65 2019-01-16 17:34:44.748904: step 3236, loss = 0.69471 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:34:45.731125 ops/training.py:65 2019-01-16 17:34:45.731027: step 3237, loss = 0.68701 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:34:46.714111 ops/training.py:65 2019-01-16 17:34:46.714013: step 3238, loss = 0.69304 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:34:47.696079 ops/training.py:65 2019-01-16 17:34:47.695977: step 3239, loss = 0.69308 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:34:48.678280 ops/training.py:65 2019-01-16 17:34:48.678179: step 3240, loss = 0.70910 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:34:49.660363 ops/training.py:65 2019-01-16 17:34:49.660259: step 3241, loss = 0.70950 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:34:50.644579 ops/training.py:65 2019-01-16 17:34:50.644487: step 3242, loss = 0.70520 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:34:51.629877 ops/training.py:65 2019-01-16 17:34:51.629769: step 3243, loss = 0.70322 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:34:52.613059 ops/training.py:65 2019-01-16 17:34:52.612959: step 3244, loss = 0.69333 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:34:53.595665 ops/training.py:65 2019-01-16 17:34:53.595558: step 3245, loss = 0.68770 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:34:54.578607 ops/training.py:65 2019-01-16 17:34:54.578502: step 3246, loss = 0.67270 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 17:34:55.560915 ops/training.py:65 2019-01-16 17:34:55.560814: step 3247, loss = 0.69733 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:34:56.546523 ops/training.py:65 2019-01-16 17:34:56.546422: step 3248, loss = 0.69019 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:34:57.530963 ops/training.py:65 2019-01-16 17:34:57.530847: step 3249, loss = 0.69480 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:34:58.515879 ops/training.py:65 2019-01-16 17:34:58.515774: step 3250, loss = 0.69254 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:34:59.499735 ops/training.py:65 2019-01-16 17:34:59.499624: step 3251, loss = 0.70644 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:35:00.481920 ops/training.py:65 2019-01-16 17:35:00.481762: step 3252, loss = 0.69407 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:35:01.464629 ops/training.py:65 2019-01-16 17:35:01.464522: step 3253, loss = 0.69067 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:35:02.446719 ops/training.py:65 2019-01-16 17:35:02.446612: step 3254, loss = 0.67403 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:35:03.428429 ops/training.py:65 2019-01-16 17:35:03.428331: step 3255, loss = 0.69156 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:35:04.409501 ops/training.py:65 2019-01-16 17:35:04.409378: step 3256, loss = 0.68595 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:35:05.395623 ops/training.py:65 2019-01-16 17:35:05.395511: step 3257, loss = 0.70526 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:35:06.380290 ops/training.py:65 2019-01-16 17:35:06.380195: step 3258, loss = 0.68549 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:35:07.362725 ops/training.py:65 2019-01-16 17:35:07.362618: step 3259, loss = 0.69415 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:35:08.343903 ops/training.py:65 2019-01-16 17:35:08.343794: step 3260, loss = 0.71510 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:35:09.325074 ops/training.py:65 2019-01-16 17:35:09.324932: step 3261, loss = 0.67900 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:35:10.307781 ops/training.py:65 2019-01-16 17:35:10.307672: step 3262, loss = 0.67519 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:35:11.289023 ops/training.py:65 2019-01-16 17:35:11.288910: step 3263, loss = 0.68396 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:35:12.271058 ops/training.py:65 2019-01-16 17:35:12.270944: step 3264, loss = 0.71133 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:35:13.254637 ops/training.py:65 2019-01-16 17:35:13.254510: step 3265, loss = 0.70035 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:35:14.237258 ops/training.py:65 2019-01-16 17:35:14.237153: step 3266, loss = 0.68050 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:35:15.220700 ops/training.py:65 2019-01-16 17:35:15.220573: step 3267, loss = 0.69852 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:35:16.203022 ops/training.py:65 2019-01-16 17:35:16.202913: step 3268, loss = 0.68790 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:35:17.185163 ops/training.py:65 2019-01-16 17:35:17.185048: step 3269, loss = 0.70075 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:35:18.167662 ops/training.py:65 2019-01-16 17:35:18.167555: step 3270, loss = 0.69557 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:35:19.150089 ops/training.py:65 2019-01-16 17:35:19.149983: step 3271, loss = 0.68787 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:35:20.132556 ops/training.py:65 2019-01-16 17:35:20.132453: step 3272, loss = 0.69317 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:35:21.115234 ops/training.py:65 2019-01-16 17:35:21.115082: step 3273, loss = 0.69113 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:35:22.098104 ops/training.py:65 2019-01-16 17:35:22.097997: step 3274, loss = 0.68658 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:35:23.080560 ops/training.py:65 2019-01-16 17:35:23.080381: step 3275, loss = 0.69212 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:35:24.066975 ops/training.py:65 2019-01-16 17:35:24.066871: step 3276, loss = 0.69780 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:35:25.051520 ops/training.py:65 2019-01-16 17:35:25.051405: step 3277, loss = 0.69312 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:35:26.034439 ops/training.py:65 2019-01-16 17:35:26.034316: step 3278, loss = 0.69845 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:35:27.016918 ops/training.py:65 2019-01-16 17:35:27.016794: step 3279, loss = 0.69994 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:35:28.000368 ops/training.py:65 2019-01-16 17:35:28.000267: step 3280, loss = 0.70625 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:35:28.983153 ops/training.py:65 2019-01-16 17:35:28.983032: step 3281, loss = 0.68572 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:35:29.965700 ops/training.py:65 2019-01-16 17:35:29.965589: step 3282, loss = 0.68866 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:35:30.948360 ops/training.py:65 2019-01-16 17:35:30.948194: step 3283, loss = 0.69783 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:35:31.931111 ops/training.py:65 2019-01-16 17:35:31.931006: step 3284, loss = 0.68821 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:35:32.912587 ops/training.py:65 2019-01-16 17:35:32.912444: step 3285, loss = 0.68619 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:35:33.895761 ops/training.py:65 2019-01-16 17:35:33.895660: step 3286, loss = 0.70229 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:35:34.878129 ops/training.py:65 2019-01-16 17:35:34.878004: step 3287, loss = 0.68511 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:35:35.860831 ops/training.py:65 2019-01-16 17:35:35.860733: step 3288, loss = 0.69417 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:35:36.844084 ops/training.py:65 2019-01-16 17:35:36.843973: step 3289, loss = 0.69243 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:35:37.827466 ops/training.py:65 2019-01-16 17:35:37.827353: step 3290, loss = 0.67672 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:35:38.809207 ops/training.py:65 2019-01-16 17:35:38.809084: step 3291, loss = 0.68951 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:35:39.792190 ops/training.py:65 2019-01-16 17:35:39.792085: step 3292, loss = 0.70688 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:35:40.774709 ops/training.py:65 2019-01-16 17:35:40.774531: step 3293, loss = 0.69475 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:35:41.758403 ops/training.py:65 2019-01-16 17:35:41.758254: step 3294, loss = 0.70957 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:35:42.741610 ops/training.py:65 2019-01-16 17:35:42.741493: step 3295, loss = 0.67618 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:35:43.724344 ops/training.py:65 2019-01-16 17:35:43.724234: step 3296, loss = 0.69801 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:35:44.708028 ops/training.py:65 2019-01-16 17:35:44.707915: step 3297, loss = 0.69406 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:35:45.690908 ops/training.py:65 2019-01-16 17:35:45.690796: step 3298, loss = 0.68333 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:35:46.673635 ops/training.py:65 2019-01-16 17:35:46.673529: step 3299, loss = 0.71559 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:35:47.655791 ops/training.py:65 2019-01-16 17:35:47.655678: step 3300, loss = 0.70344 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:35:48.639777 ops/training.py:65 2019-01-16 17:35:48.639669: step 3301, loss = 0.65982 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:35:49.624005 ops/training.py:65 2019-01-16 17:35:49.623898: step 3302, loss = 0.67971 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:35:50.605527 ops/training.py:65 2019-01-16 17:35:50.605418: step 3303, loss = 0.69043 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:35:51.587456 ops/training.py:65 2019-01-16 17:35:51.587357: step 3304, loss = 0.72676 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:35:52.568751 ops/training.py:65 2019-01-16 17:35:52.568643: step 3305, loss = 0.68594 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:35:53.555030 ops/training.py:65 2019-01-16 17:35:53.554921: step 3306, loss = 0.71547 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:35:54.540240 ops/training.py:65 2019-01-16 17:35:54.540131: step 3307, loss = 0.68896 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:35:55.523669 ops/training.py:65 2019-01-16 17:35:55.523559: step 3308, loss = 0.69783 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:35:56.506507 ops/training.py:65 2019-01-16 17:35:56.506404: step 3309, loss = 0.69482 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:35:57.489428 ops/training.py:65 2019-01-16 17:35:57.489315: step 3310, loss = 0.69880 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:35:58.472493 ops/training.py:65 2019-01-16 17:35:58.472381: step 3311, loss = 0.70192 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:35:59.455074 ops/training.py:65 2019-01-16 17:35:59.454962: step 3312, loss = 0.67124 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.75
I8192 2019-01-16 17:36:00.437163 ops/training.py:65 2019-01-16 17:36:00.437056: step 3313, loss = 0.71620 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:36:01.419613 ops/training.py:65 2019-01-16 17:36:01.419503: step 3314, loss = 0.68210 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:36:02.401250 ops/training.py:65 2019-01-16 17:36:02.401147: step 3315, loss = 0.72230 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:36:03.382964 ops/training.py:65 2019-01-16 17:36:03.382859: step 3316, loss = 0.69707 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:36:04.365767 ops/training.py:65 2019-01-16 17:36:04.365651: step 3317, loss = 0.71873 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:36:05.349605 ops/training.py:65 2019-01-16 17:36:05.349481: step 3318, loss = 0.69330 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:36:06.332938 ops/training.py:65 2019-01-16 17:36:06.332820: step 3319, loss = 0.69648 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:36:07.317497 ops/training.py:65 2019-01-16 17:36:07.317386: step 3320, loss = 0.70444 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:36:08.300848 ops/training.py:65 2019-01-16 17:36:08.300739: step 3321, loss = 0.68651 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:36:09.284279 ops/training.py:65 2019-01-16 17:36:09.284169: step 3322, loss = 0.71267 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 17:36:10.268720 ops/training.py:65 2019-01-16 17:36:10.268614: step 3323, loss = 0.69876 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:36:11.252785 ops/training.py:65 2019-01-16 17:36:11.252690: step 3324, loss = 0.69645 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:36:12.234597 ops/training.py:65 2019-01-16 17:36:12.234511: step 3325, loss = 0.68694 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:36:13.218493 ops/training.py:65 2019-01-16 17:36:13.218377: step 3326, loss = 0.67321 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.75
I8192 2019-01-16 17:36:14.202005 ops/training.py:65 2019-01-16 17:36:14.201905: step 3327, loss = 0.69095 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:36:15.185846 ops/training.py:65 2019-01-16 17:36:15.185780: step 3328, loss = 0.69580 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:36:16.168010 ops/training.py:65 2019-01-16 17:36:16.167908: step 3329, loss = 0.70010 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:36:17.152597 ops/training.py:65 2019-01-16 17:36:17.152493: step 3330, loss = 0.69126 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:36:18.135834 ops/training.py:65 2019-01-16 17:36:18.135717: step 3331, loss = 0.69407 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:36:19.119475 ops/training.py:65 2019-01-16 17:36:19.119357: step 3332, loss = 0.69389 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:36:20.102624 ops/training.py:65 2019-01-16 17:36:20.102516: step 3333, loss = 0.68454 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:36:21.084381 ops/training.py:65 2019-01-16 17:36:21.084289: step 3334, loss = 0.69296 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:36:22.067043 ops/training.py:65 2019-01-16 17:36:22.066930: step 3335, loss = 0.69742 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:36:23.050573 ops/training.py:65 2019-01-16 17:36:23.050466: step 3336, loss = 0.68586 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:36:24.034094 ops/training.py:65 2019-01-16 17:36:24.033985: step 3337, loss = 0.68689 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:36:25.016135 ops/training.py:65 2019-01-16 17:36:25.016008: step 3338, loss = 0.68647 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:36:25.998566 ops/training.py:65 2019-01-16 17:36:25.998458: step 3339, loss = 0.69618 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:36:26.980661 ops/training.py:65 2019-01-16 17:36:26.980540: step 3340, loss = 0.70330 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:36:27.962185 ops/training.py:65 2019-01-16 17:36:27.962066: step 3341, loss = 0.69586 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:36:28.944390 ops/training.py:65 2019-01-16 17:36:28.944219: step 3342, loss = 0.69589 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:36:29.927456 ops/training.py:65 2019-01-16 17:36:29.927350: step 3343, loss = 0.69763 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:36:30.909022 ops/training.py:65 2019-01-16 17:36:30.908902: step 3344, loss = 0.68595 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:36:31.891604 ops/training.py:65 2019-01-16 17:36:31.891495: step 3345, loss = 0.68208 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:36:32.872659 ops/training.py:65 2019-01-16 17:36:32.872530: step 3346, loss = 0.71211 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:36:33.855187 ops/training.py:65 2019-01-16 17:36:33.855070: step 3347, loss = 0.71388 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:36:34.837876 ops/training.py:65 2019-01-16 17:36:34.837767: step 3348, loss = 0.69174 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:36:35.821329 ops/training.py:65 2019-01-16 17:36:35.821227: step 3349, loss = 0.71087 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:36:36.803257 ops/training.py:65 2019-01-16 17:36:36.803151: step 3350, loss = 0.68379 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:36:37.784666 ops/training.py:65 2019-01-16 17:36:37.784557: step 3351, loss = 0.71931 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:36:38.766418 ops/training.py:65 2019-01-16 17:36:38.766290: step 3352, loss = 0.68149 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:36:39.749179 ops/training.py:65 2019-01-16 17:36:39.749065: step 3353, loss = 0.69912 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:36:40.731255 ops/training.py:65 2019-01-16 17:36:40.731135: step 3354, loss = 0.70151 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:36:41.713536 ops/training.py:65 2019-01-16 17:36:41.713424: step 3355, loss = 0.71483 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:36:42.696764 ops/training.py:65 2019-01-16 17:36:42.696641: step 3356, loss = 0.67526 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:36:43.679153 ops/training.py:65 2019-01-16 17:36:43.679045: step 3357, loss = 0.68441 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:36:44.661893 ops/training.py:65 2019-01-16 17:36:44.661770: step 3358, loss = 0.72024 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:36:45.645402 ops/training.py:65 2019-01-16 17:36:45.645287: step 3359, loss = 0.72934 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:36:46.627572 ops/training.py:65 2019-01-16 17:36:46.627465: step 3360, loss = 0.68865 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:36:47.608876 ops/training.py:65 2019-01-16 17:36:47.608770: step 3361, loss = 0.68089 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:36:48.592430 ops/training.py:65 2019-01-16 17:36:48.592322: step 3362, loss = 0.71606 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:36:49.574746 ops/training.py:65 2019-01-16 17:36:49.574640: step 3363, loss = 0.72505 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:36:50.556161 ops/training.py:65 2019-01-16 17:36:50.556054: step 3364, loss = 0.68798 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:36:51.538517 ops/training.py:65 2019-01-16 17:36:51.538420: step 3365, loss = 0.71163 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:36:52.521193 ops/training.py:65 2019-01-16 17:36:52.521088: step 3366, loss = 0.71448 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:36:53.503900 ops/training.py:65 2019-01-16 17:36:53.503794: step 3367, loss = 0.70164 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:36:54.486683 ops/training.py:65 2019-01-16 17:36:54.486579: step 3368, loss = 0.68564 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:36:55.469731 ops/training.py:65 2019-01-16 17:36:55.469628: step 3369, loss = 0.67938 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:36:56.451817 ops/training.py:65 2019-01-16 17:36:56.451712: step 3370, loss = 0.67730 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:36:57.434238 ops/training.py:65 2019-01-16 17:36:57.434137: step 3371, loss = 0.67457 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:36:58.416618 ops/training.py:65 2019-01-16 17:36:58.416524: step 3372, loss = 0.69274 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:36:59.399129 ops/training.py:65 2019-01-16 17:36:59.399022: step 3373, loss = 0.70309 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:37:00.381012 ops/training.py:65 2019-01-16 17:37:00.380910: step 3374, loss = 0.68826 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:37:01.363441 ops/training.py:65 2019-01-16 17:37:01.363338: step 3375, loss = 0.66977 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:37:02.346657 ops/training.py:65 2019-01-16 17:37:02.346557: step 3376, loss = 0.68522 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:37:03.329425 ops/training.py:65 2019-01-16 17:37:03.329326: step 3377, loss = 0.71488 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:37:04.312713 ops/training.py:65 2019-01-16 17:37:04.312609: step 3378, loss = 0.69682 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:37:05.294669 ops/training.py:65 2019-01-16 17:37:05.294566: step 3379, loss = 0.68331 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:37:06.277514 ops/training.py:65 2019-01-16 17:37:06.277420: step 3380, loss = 0.68397 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:37:07.259292 ops/training.py:65 2019-01-16 17:37:07.259188: step 3381, loss = 0.70031 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:37:08.243101 ops/training.py:65 2019-01-16 17:37:08.243000: step 3382, loss = 0.69549 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:37:09.225738 ops/training.py:65 2019-01-16 17:37:09.225637: step 3383, loss = 0.70585 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:37:10.207520 ops/training.py:65 2019-01-16 17:37:10.207421: step 3384, loss = 0.70365 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:37:11.191933 ops/training.py:65 2019-01-16 17:37:11.191829: step 3385, loss = 0.68403 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:37:12.174029 ops/training.py:65 2019-01-16 17:37:12.173923: step 3386, loss = 0.70531 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:37:13.156991 ops/training.py:65 2019-01-16 17:37:13.156885: step 3387, loss = 0.71767 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:37:14.140140 ops/training.py:65 2019-01-16 17:37:14.140040: step 3388, loss = 0.70862 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:37:15.123942 ops/training.py:65 2019-01-16 17:37:15.123842: step 3389, loss = 0.70097 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:37:16.105761 ops/training.py:65 2019-01-16 17:37:16.105664: step 3390, loss = 0.69784 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:37:17.089533 ops/training.py:65 2019-01-16 17:37:17.089428: step 3391, loss = 0.69184 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:37:18.073320 ops/training.py:65 2019-01-16 17:37:18.073174: step 3392, loss = 0.70629 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:37:19.056890 ops/training.py:65 2019-01-16 17:37:19.056786: step 3393, loss = 0.68806 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:37:20.039480 ops/training.py:65 2019-01-16 17:37:20.039346: step 3394, loss = 0.68611 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:37:21.021330 ops/training.py:65 2019-01-16 17:37:21.021207: step 3395, loss = 0.70717 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:37:22.004097 ops/training.py:65 2019-01-16 17:37:22.003988: step 3396, loss = 0.69920 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:37:22.986637 ops/training.py:65 2019-01-16 17:37:22.986540: step 3397, loss = 0.68998 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:37:23.969135 ops/training.py:65 2019-01-16 17:37:23.969041: step 3398, loss = 0.70181 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:37:24.951990 ops/training.py:65 2019-01-16 17:37:24.951888: step 3399, loss = 0.69592 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:37:25.934425 ops/training.py:65 2019-01-16 17:37:25.934327: step 3400, loss = 0.68311 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:37:26.916915 ops/training.py:65 2019-01-16 17:37:26.916818: step 3401, loss = 0.70660 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:37:27.900247 ops/training.py:65 2019-01-16 17:37:27.900156: step 3402, loss = 0.68759 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:37:28.882935 ops/training.py:65 2019-01-16 17:37:28.882834: step 3403, loss = 0.70168 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:37:29.866259 ops/training.py:65 2019-01-16 17:37:29.866125: step 3404, loss = 0.69377 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:37:30.849432 ops/training.py:65 2019-01-16 17:37:30.849334: step 3405, loss = 0.68699 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:37:31.834476 ops/training.py:65 2019-01-16 17:37:31.834403: step 3406, loss = 0.68453 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:37:32.817391 ops/training.py:65 2019-01-16 17:37:32.817286: step 3407, loss = 0.69573 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:37:33.801148 ops/training.py:65 2019-01-16 17:37:33.801048: step 3408, loss = 0.70234 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:37:34.784297 ops/training.py:65 2019-01-16 17:37:34.784187: step 3409, loss = 0.69696 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:37:35.766858 ops/training.py:65 2019-01-16 17:37:35.766757: step 3410, loss = 0.69073 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:37:36.749431 ops/training.py:65 2019-01-16 17:37:36.749366: step 3411, loss = 0.69295 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:37:37.733198 ops/training.py:65 2019-01-16 17:37:37.733129: step 3412, loss = 0.69854 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:37:38.717388 ops/training.py:65 2019-01-16 17:37:38.717286: step 3413, loss = 0.70036 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:37:39.701390 ops/training.py:65 2019-01-16 17:37:39.701290: step 3414, loss = 0.69674 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:37:40.683939 ops/training.py:65 2019-01-16 17:37:40.683835: step 3415, loss = 0.69317 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:37:41.666596 ops/training.py:65 2019-01-16 17:37:41.666496: step 3416, loss = 0.70132 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:37:42.651146 ops/training.py:65 2019-01-16 17:37:42.651044: step 3417, loss = 0.69126 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:37:43.634364 ops/training.py:65 2019-01-16 17:37:43.634264: step 3418, loss = 0.69542 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:37:44.617080 ops/training.py:65 2019-01-16 17:37:44.616980: step 3419, loss = 0.69208 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:37:45.600884 ops/training.py:65 2019-01-16 17:37:45.600785: step 3420, loss = 0.68750 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:37:46.584527 ops/training.py:65 2019-01-16 17:37:46.584430: step 3421, loss = 0.70137 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:37:47.567685 ops/training.py:65 2019-01-16 17:37:47.567591: step 3422, loss = 0.68655 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:37:48.549858 ops/training.py:65 2019-01-16 17:37:48.549764: step 3423, loss = 0.66069 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 17:37:49.533033 ops/training.py:65 2019-01-16 17:37:49.532928: step 3424, loss = 0.69519 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:37:50.517526 ops/training.py:65 2019-01-16 17:37:50.517425: step 3425, loss = 0.68836 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:37:51.501541 ops/training.py:65 2019-01-16 17:37:51.501478: step 3426, loss = 0.70083 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:37:52.483565 ops/training.py:65 2019-01-16 17:37:52.483536: step 3427, loss = 0.68999 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:37:53.465840 ops/training.py:65 2019-01-16 17:37:53.465804: step 3428, loss = 0.70441 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:37:54.448989 ops/training.py:65 2019-01-16 17:37:54.448959: step 3429, loss = 0.70309 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:37:55.430920 ops/training.py:65 2019-01-16 17:37:55.430879: step 3430, loss = 0.70038 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:37:56.413021 ops/training.py:65 2019-01-16 17:37:56.412921: step 3431, loss = 0.68793 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:37:57.399697 ops/training.py:65 2019-01-16 17:37:57.399626: step 3432, loss = 0.71435 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:37:58.383193 ops/training.py:65 2019-01-16 17:37:58.383161: step 3433, loss = 0.68877 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:37:59.366497 ops/training.py:65 2019-01-16 17:37:59.366441: step 3434, loss = 0.69124 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:38:00.348708 ops/training.py:65 2019-01-16 17:38:00.348681: step 3435, loss = 0.71024 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:38:01.330031 ops/training.py:65 2019-01-16 17:38:01.329919: step 3436, loss = 0.72140 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:38:02.310524 ops/training.py:65 2019-01-16 17:38:02.310461: step 3437, loss = 0.69884 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:38:03.289523 ops/training.py:65 2019-01-16 17:38:03.289450: step 3438, loss = 0.68098 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:38:04.273421 ops/training.py:65 2019-01-16 17:38:04.273375: step 3439, loss = 0.70424 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:38:05.256967 ops/training.py:65 2019-01-16 17:38:05.256926: step 3440, loss = 0.70298 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:38:06.240706 ops/training.py:65 2019-01-16 17:38:06.240668: step 3441, loss = 0.69246 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:38:07.223127 ops/training.py:65 2019-01-16 17:38:07.223098: step 3442, loss = 0.67870 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:38:08.206201 ops/training.py:65 2019-01-16 17:38:08.206174: step 3443, loss = 0.67788 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:38:09.189224 ops/training.py:65 2019-01-16 17:38:09.189161: step 3444, loss = 0.72253 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:38:10.172718 ops/training.py:65 2019-01-16 17:38:10.172656: step 3445, loss = 0.68828 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:38:11.155743 ops/training.py:65 2019-01-16 17:38:11.155638: step 3446, loss = 0.69392 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:38:12.137823 ops/training.py:65 2019-01-16 17:38:12.137733: step 3447, loss = 0.70229 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:38:13.118739 ops/training.py:65 2019-01-16 17:38:13.118667: step 3448, loss = 0.70573 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:38:14.102098 ops/training.py:65 2019-01-16 17:38:14.102014: step 3449, loss = 0.69371 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:38:15.085332 ops/training.py:65 2019-01-16 17:38:15.085220: step 3450, loss = 0.67682 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:38:16.068295 ops/training.py:65 2019-01-16 17:38:16.068190: step 3451, loss = 0.68383 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:38:17.052330 ops/training.py:65 2019-01-16 17:38:17.052230: step 3452, loss = 0.68762 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:38:18.036693 ops/training.py:65 2019-01-16 17:38:18.036586: step 3453, loss = 0.70069 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:38:19.019335 ops/training.py:65 2019-01-16 17:38:19.019231: step 3454, loss = 0.70230 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:38:20.002666 ops/training.py:65 2019-01-16 17:38:20.002561: step 3455, loss = 0.68199 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:38:20.985802 ops/training.py:65 2019-01-16 17:38:20.985710: step 3456, loss = 0.70907 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:38:21.969801 ops/training.py:65 2019-01-16 17:38:21.969694: step 3457, loss = 0.69302 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:38:22.954062 ops/training.py:65 2019-01-16 17:38:22.953951: step 3458, loss = 0.70112 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:38:23.937656 ops/training.py:65 2019-01-16 17:38:23.937552: step 3459, loss = 0.69102 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:38:24.920596 ops/training.py:65 2019-01-16 17:38:24.920495: step 3460, loss = 0.70165 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:38:25.902944 ops/training.py:65 2019-01-16 17:38:25.902836: step 3461, loss = 0.70771 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:38:26.885059 ops/training.py:65 2019-01-16 17:38:26.884957: step 3462, loss = 0.69763 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:38:27.866226 ops/training.py:65 2019-01-16 17:38:27.866148: step 3463, loss = 0.68228 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:38:28.849898 ops/training.py:65 2019-01-16 17:38:28.849818: step 3464, loss = 0.69494 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:38:29.834450 ops/training.py:65 2019-01-16 17:38:29.834346: step 3465, loss = 0.68784 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:38:30.816665 ops/training.py:65 2019-01-16 17:38:30.816559: step 3466, loss = 0.70746 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:38:31.798447 ops/training.py:65 2019-01-16 17:38:31.798339: step 3467, loss = 0.72080 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:38:32.780519 ops/training.py:65 2019-01-16 17:38:32.780417: step 3468, loss = 0.71205 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:38:33.762533 ops/training.py:65 2019-01-16 17:38:33.762392: step 3469, loss = 0.70281 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:38:34.743836 ops/training.py:65 2019-01-16 17:38:34.743735: step 3470, loss = 0.68745 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:38:35.725807 ops/training.py:65 2019-01-16 17:38:35.725708: step 3471, loss = 0.69973 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:38:36.708042 ops/training.py:65 2019-01-16 17:38:36.707954: step 3472, loss = 0.69608 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:38:37.691564 ops/training.py:65 2019-01-16 17:38:37.691464: step 3473, loss = 0.68072 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:38:38.673438 ops/training.py:65 2019-01-16 17:38:38.673338: step 3474, loss = 0.70617 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:38:39.657486 ops/training.py:65 2019-01-16 17:38:39.657381: step 3475, loss = 0.69729 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:38:40.640256 ops/training.py:65 2019-01-16 17:38:40.640154: step 3476, loss = 0.68886 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:38:41.622901 ops/training.py:65 2019-01-16 17:38:41.622800: step 3477, loss = 0.70266 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:38:42.604612 ops/training.py:65 2019-01-16 17:38:42.604524: step 3478, loss = 0.68141 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:38:43.585931 ops/training.py:65 2019-01-16 17:38:43.585826: step 3479, loss = 0.71835 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:38:44.568287 ops/training.py:65 2019-01-16 17:38:44.568181: step 3480, loss = 0.69797 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:38:45.553183 ops/training.py:65 2019-01-16 17:38:45.553083: step 3481, loss = 0.71214 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:38:46.536719 ops/training.py:65 2019-01-16 17:38:46.536620: step 3482, loss = 0.68605 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:38:47.520276 ops/training.py:65 2019-01-16 17:38:47.520170: step 3483, loss = 0.71586 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:38:48.504030 ops/training.py:65 2019-01-16 17:38:48.503924: step 3484, loss = 0.68154 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:38:49.487305 ops/training.py:65 2019-01-16 17:38:49.487204: step 3485, loss = 0.69695 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:38:50.469855 ops/training.py:65 2019-01-16 17:38:50.469755: step 3486, loss = 0.70465 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:38:51.453448 ops/training.py:65 2019-01-16 17:38:51.453346: step 3487, loss = 0.70082 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:38:52.436471 ops/training.py:65 2019-01-16 17:38:52.436370: step 3488, loss = 0.69557 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:38:53.418609 ops/training.py:65 2019-01-16 17:38:53.418515: step 3489, loss = 0.67657 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:38:54.399859 ops/training.py:65 2019-01-16 17:38:54.399751: step 3490, loss = 0.68931 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:38:55.385095 ops/training.py:65 2019-01-16 17:38:55.384985: step 3491, loss = 0.69947 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:38:56.371415 ops/training.py:65 2019-01-16 17:38:56.371302: step 3492, loss = 0.69940 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:38:57.353940 ops/training.py:65 2019-01-16 17:38:57.353855: step 3493, loss = 0.70665 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:38:58.336823 ops/training.py:65 2019-01-16 17:38:58.336724: step 3494, loss = 0.69808 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:38:59.320030 ops/training.py:65 2019-01-16 17:38:59.319927: step 3495, loss = 0.70508 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:39:00.301873 ops/training.py:65 2019-01-16 17:39:00.301776: step 3496, loss = 0.69570 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:39:01.284399 ops/training.py:65 2019-01-16 17:39:01.284300: step 3497, loss = 0.67068 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:39:02.268214 ops/training.py:65 2019-01-16 17:39:02.268113: step 3498, loss = 0.68401 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:39:03.251893 ops/training.py:65 2019-01-16 17:39:03.251791: step 3499, loss = 0.69245 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:39:04.233775 ops/training.py:65 2019-01-16 17:39:04.233671: step 3500, loss = 0.71199 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:39:05.218217 ops/training.py:65 2019-01-16 17:39:05.218120: step 3501, loss = 0.69949 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:39:06.204555 ops/training.py:65 2019-01-16 17:39:06.204457: step 3502, loss = 0.69518 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:39:07.187887 ops/training.py:65 2019-01-16 17:39:07.187777: step 3503, loss = 0.66934 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:39:08.173112 ops/training.py:65 2019-01-16 17:39:08.173007: step 3504, loss = 0.68518 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:39:09.156436 ops/training.py:65 2019-01-16 17:39:09.156331: step 3505, loss = 0.69777 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:39:10.141627 ops/training.py:65 2019-01-16 17:39:10.141523: step 3506, loss = 0.68910 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:39:11.126165 ops/training.py:65 2019-01-16 17:39:11.126060: step 3507, loss = 0.69466 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:39:12.110361 ops/training.py:65 2019-01-16 17:39:12.110263: step 3508, loss = 0.70332 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:39:13.094024 ops/training.py:65 2019-01-16 17:39:13.093928: step 3509, loss = 0.70095 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:39:14.077614 ops/training.py:65 2019-01-16 17:39:14.077508: step 3510, loss = 0.69172 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:39:15.060737 ops/training.py:65 2019-01-16 17:39:15.060637: step 3511, loss = 0.69152 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:39:16.044291 ops/training.py:65 2019-01-16 17:39:16.044181: step 3512, loss = 0.68430 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:39:17.028463 ops/training.py:65 2019-01-16 17:39:17.028364: step 3513, loss = 0.67880 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:39:18.011188 ops/training.py:65 2019-01-16 17:39:18.011084: step 3514, loss = 0.68950 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:39:18.995706 ops/training.py:65 2019-01-16 17:39:18.995612: step 3515, loss = 0.68127 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:39:19.979324 ops/training.py:65 2019-01-16 17:39:19.979217: step 3516, loss = 0.71704 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:39:20.964273 ops/training.py:65 2019-01-16 17:39:20.964186: step 3517, loss = 0.71395 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:39:21.948098 ops/training.py:65 2019-01-16 17:39:21.947995: step 3518, loss = 0.69495 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:39:22.932111 ops/training.py:65 2019-01-16 17:39:22.932010: step 3519, loss = 0.70980 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:39:23.916471 ops/training.py:65 2019-01-16 17:39:23.916378: step 3520, loss = 0.69560 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:39:24.900566 ops/training.py:65 2019-01-16 17:39:24.900468: step 3521, loss = 0.69416 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:39:25.882399 ops/training.py:65 2019-01-16 17:39:25.882300: step 3522, loss = 0.67555 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:39:26.865135 ops/training.py:65 2019-01-16 17:39:26.865035: step 3523, loss = 0.68868 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:39:27.849890 ops/training.py:65 2019-01-16 17:39:27.849796: step 3524, loss = 0.69405 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:39:28.834563 ops/training.py:65 2019-01-16 17:39:28.834458: step 3525, loss = 0.68973 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:39:29.820165 ops/training.py:65 2019-01-16 17:39:29.820063: step 3526, loss = 0.69983 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:39:30.804033 ops/training.py:65 2019-01-16 17:39:30.803941: step 3527, loss = 0.68470 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:39:31.787676 ops/training.py:65 2019-01-16 17:39:31.787603: step 3528, loss = 0.69745 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:39:32.768189 ops/training.py:65 2019-01-16 17:39:32.768121: step 3529, loss = 0.71126 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:39:33.751722 ops/training.py:65 2019-01-16 17:39:33.751657: step 3530, loss = 0.71315 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:39:34.734822 ops/training.py:65 2019-01-16 17:39:34.734727: step 3531, loss = 0.70114 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:39:35.716282 ops/training.py:65 2019-01-16 17:39:35.716188: step 3532, loss = 0.68253 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:39:36.698530 ops/training.py:65 2019-01-16 17:39:36.698401: step 3533, loss = 0.69092 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:39:37.682631 ops/training.py:65 2019-01-16 17:39:37.682523: step 3534, loss = 0.71218 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:39:38.667974 ops/training.py:65 2019-01-16 17:39:38.667867: step 3535, loss = 0.68282 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:39:39.652952 ops/training.py:65 2019-01-16 17:39:39.652844: step 3536, loss = 0.68414 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:39:40.637066 ops/training.py:65 2019-01-16 17:39:40.636960: step 3537, loss = 0.71111 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:39:41.619631 ops/training.py:65 2019-01-16 17:39:41.619535: step 3538, loss = 0.68873 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:39:42.604027 ops/training.py:65 2019-01-16 17:39:42.603949: step 3539, loss = 0.67752 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:39:43.587006 ops/training.py:65 2019-01-16 17:39:43.586900: step 3540, loss = 0.68568 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:39:44.570023 ops/training.py:65 2019-01-16 17:39:44.569902: step 3541, loss = 0.69215 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:39:45.551325 ops/training.py:65 2019-01-16 17:39:45.551222: step 3542, loss = 0.69069 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:39:46.534435 ops/training.py:65 2019-01-16 17:39:46.534321: step 3543, loss = 0.68970 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:39:47.517260 ops/training.py:65 2019-01-16 17:39:47.517158: step 3544, loss = 0.70732 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:39:48.499707 ops/training.py:65 2019-01-16 17:39:48.499598: step 3545, loss = 0.69387 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:39:49.482420 ops/training.py:65 2019-01-16 17:39:49.482310: step 3546, loss = 0.69363 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:39:50.464737 ops/training.py:65 2019-01-16 17:39:50.464632: step 3547, loss = 0.70086 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:39:51.448942 ops/training.py:65 2019-01-16 17:39:51.448841: step 3548, loss = 0.69972 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:39:52.431186 ops/training.py:65 2019-01-16 17:39:52.431087: step 3549, loss = 0.69368 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:39:53.413858 ops/training.py:65 2019-01-16 17:39:53.413755: step 3550, loss = 0.71465 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:39:54.396441 ops/training.py:65 2019-01-16 17:39:54.396353: step 3551, loss = 0.67637 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:39:55.380234 ops/training.py:65 2019-01-16 17:39:55.380125: step 3552, loss = 0.67672 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:39:56.363486 ops/training.py:65 2019-01-16 17:39:56.363388: step 3553, loss = 0.67148 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:39:57.346687 ops/training.py:65 2019-01-16 17:39:57.346585: step 3554, loss = 0.70002 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:39:58.329914 ops/training.py:65 2019-01-16 17:39:58.329806: step 3555, loss = 0.69496 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:39:59.312300 ops/training.py:65 2019-01-16 17:39:59.312192: step 3556, loss = 0.69132 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:40:00.295245 ops/training.py:65 2019-01-16 17:40:00.295140: step 3557, loss = 0.70535 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:40:01.277667 ops/training.py:65 2019-01-16 17:40:01.277580: step 3558, loss = 0.67916 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:40:02.260288 ops/training.py:65 2019-01-16 17:40:02.260189: step 3559, loss = 0.71943 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:40:03.245258 ops/training.py:65 2019-01-16 17:40:03.245160: step 3560, loss = 0.68305 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:40:04.228761 ops/training.py:65 2019-01-16 17:40:04.228665: step 3561, loss = 0.69963 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:40:05.210396 ops/training.py:65 2019-01-16 17:40:05.210291: step 3562, loss = 0.70913 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:40:06.191568 ops/training.py:65 2019-01-16 17:40:06.191475: step 3563, loss = 0.68901 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:40:07.174095 ops/training.py:65 2019-01-16 17:40:07.174006: step 3564, loss = 0.70569 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:40:08.159273 ops/training.py:65 2019-01-16 17:40:08.159180: step 3565, loss = 0.68131 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:40:09.141523 ops/training.py:65 2019-01-16 17:40:09.141428: step 3566, loss = 0.67843 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:40:10.123837 ops/training.py:65 2019-01-16 17:40:10.123743: step 3567, loss = 0.69191 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:40:11.105961 ops/training.py:65 2019-01-16 17:40:11.105864: step 3568, loss = 0.69368 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:40:12.088038 ops/training.py:65 2019-01-16 17:40:12.087927: step 3569, loss = 0.69004 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:40:13.069016 ops/training.py:65 2019-01-16 17:40:13.068918: step 3570, loss = 0.67000 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:40:14.053427 ops/training.py:65 2019-01-16 17:40:14.053322: step 3571, loss = 0.73028 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:40:15.036609 ops/training.py:65 2019-01-16 17:40:15.036506: step 3572, loss = 0.70313 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:40:16.018486 ops/training.py:65 2019-01-16 17:40:16.018407: step 3573, loss = 0.68753 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:40:17.000981 ops/training.py:65 2019-01-16 17:40:17.000919: step 3574, loss = 0.64988 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:40:17.985305 ops/training.py:65 2019-01-16 17:40:17.985206: step 3575, loss = 0.71075 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:40:18.968394 ops/training.py:65 2019-01-16 17:40:18.968326: step 3576, loss = 0.69637 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:40:19.952946 ops/training.py:65 2019-01-16 17:40:19.952844: step 3577, loss = 0.64500 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:40:20.935491 ops/training.py:65 2019-01-16 17:40:20.935389: step 3578, loss = 0.71096 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:40:21.920999 ops/training.py:65 2019-01-16 17:40:21.920913: step 3579, loss = 0.70603 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:40:22.904202 ops/training.py:65 2019-01-16 17:40:22.904099: step 3580, loss = 0.69920 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:40:23.888673 ops/training.py:65 2019-01-16 17:40:23.888579: step 3581, loss = 0.71643 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:40:24.872286 ops/training.py:65 2019-01-16 17:40:24.872173: step 3582, loss = 0.69346 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:40:25.858098 ops/training.py:65 2019-01-16 17:40:25.857984: step 3583, loss = 0.71696 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:40:26.840674 ops/training.py:65 2019-01-16 17:40:26.840584: step 3584, loss = 0.67699 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:40:27.825936 ops/training.py:65 2019-01-16 17:40:27.825844: step 3585, loss = 0.73248 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:40:28.810024 ops/training.py:65 2019-01-16 17:40:28.809914: step 3586, loss = 0.71337 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:40:29.793198 ops/training.py:65 2019-01-16 17:40:29.793090: step 3587, loss = 0.76110 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.25
I8192 2019-01-16 17:40:30.777642 ops/training.py:65 2019-01-16 17:40:30.777535: step 3588, loss = 0.72532 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:40:31.759856 ops/training.py:65 2019-01-16 17:40:31.759746: step 3589, loss = 0.70907 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:40:32.741983 ops/training.py:65 2019-01-16 17:40:32.741898: step 3590, loss = 0.64138 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:40:33.724080 ops/training.py:65 2019-01-16 17:40:33.723990: step 3591, loss = 0.65771 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:40:34.706070 ops/training.py:65 2019-01-16 17:40:34.705968: step 3592, loss = 0.67909 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:40:35.688362 ops/training.py:65 2019-01-16 17:40:35.688258: step 3593, loss = 0.68576 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:40:36.671573 ops/training.py:65 2019-01-16 17:40:36.671482: step 3594, loss = 0.66551 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:40:37.654561 ops/training.py:65 2019-01-16 17:40:37.654467: step 3595, loss = 0.70277 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:40:38.637138 ops/training.py:65 2019-01-16 17:40:38.637036: step 3596, loss = 0.68399 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:40:39.618790 ops/training.py:65 2019-01-16 17:40:39.618691: step 3597, loss = 0.68603 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:40:40.601802 ops/training.py:65 2019-01-16 17:40:40.601696: step 3598, loss = 0.70590 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:40:41.587097 ops/training.py:65 2019-01-16 17:40:41.586989: step 3599, loss = 0.69672 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:40:42.569663 ops/training.py:65 2019-01-16 17:40:42.569557: step 3600, loss = 0.68534 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:40:43.554683 ops/training.py:65 2019-01-16 17:40:43.554583: step 3601, loss = 0.70436 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:40:44.537912 ops/training.py:65 2019-01-16 17:40:44.537809: step 3602, loss = 0.69743 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:40:45.520699 ops/training.py:65 2019-01-16 17:40:45.520587: step 3603, loss = 0.67059 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:40:46.503919 ops/training.py:65 2019-01-16 17:40:46.503823: step 3604, loss = 0.76987 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:40:47.487020 ops/training.py:65 2019-01-16 17:40:47.486912: step 3605, loss = 0.67252 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:40:48.470100 ops/training.py:65 2019-01-16 17:40:48.469995: step 3606, loss = 0.68883 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:40:49.452094 ops/training.py:65 2019-01-16 17:40:49.451990: step 3607, loss = 0.70369 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:40:50.434297 ops/training.py:65 2019-01-16 17:40:50.434194: step 3608, loss = 0.71207 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:40:51.417097 ops/training.py:65 2019-01-16 17:40:51.417010: step 3609, loss = 0.70357 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:40:52.399126 ops/training.py:65 2019-01-16 17:40:52.399024: step 3610, loss = 0.71044 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:40:53.382010 ops/training.py:65 2019-01-16 17:40:53.381913: step 3611, loss = 0.68951 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:40:54.365165 ops/training.py:65 2019-01-16 17:40:54.365066: step 3612, loss = 0.70312 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:40:55.348536 ops/training.py:65 2019-01-16 17:40:55.348431: step 3613, loss = 0.69943 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:40:56.330024 ops/training.py:65 2019-01-16 17:40:56.329915: step 3614, loss = 0.66017 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:40:57.313348 ops/training.py:65 2019-01-16 17:40:57.313254: step 3615, loss = 0.70000 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:40:58.297018 ops/training.py:65 2019-01-16 17:40:58.296906: step 3616, loss = 0.70028 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:40:59.279680 ops/training.py:65 2019-01-16 17:40:59.279575: step 3617, loss = 0.69463 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:41:00.262735 ops/training.py:65 2019-01-16 17:41:00.262627: step 3618, loss = 0.68461 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:41:01.246833 ops/training.py:65 2019-01-16 17:41:01.246697: step 3619, loss = 0.69971 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:41:02.229543 ops/training.py:65 2019-01-16 17:41:02.229469: step 3620, loss = 0.69735 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:41:03.213092 ops/training.py:65 2019-01-16 17:41:03.213010: step 3621, loss = 0.70177 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:41:04.196096 ops/training.py:65 2019-01-16 17:41:04.195998: step 3622, loss = 0.70782 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:41:05.183192 ops/training.py:65 2019-01-16 17:41:05.183085: step 3623, loss = 0.67154 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:41:06.169032 ops/training.py:65 2019-01-16 17:41:06.168910: step 3624, loss = 0.70580 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:41:07.152420 ops/training.py:65 2019-01-16 17:41:07.152316: step 3625, loss = 0.71057 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:41:08.133831 ops/training.py:65 2019-01-16 17:41:08.133729: step 3626, loss = 0.69450 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:41:09.116919 ops/training.py:65 2019-01-16 17:41:09.116810: step 3627, loss = 0.69058 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:41:10.100369 ops/training.py:65 2019-01-16 17:41:10.100270: step 3628, loss = 0.70896 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:41:11.082528 ops/training.py:65 2019-01-16 17:41:11.082425: step 3629, loss = 0.69571 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:41:12.064738 ops/training.py:65 2019-01-16 17:41:12.064632: step 3630, loss = 0.71068 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:41:13.046485 ops/training.py:65 2019-01-16 17:41:13.046380: step 3631, loss = 0.68813 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:41:14.029139 ops/training.py:65 2019-01-16 17:41:14.029031: step 3632, loss = 0.69099 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:41:15.013163 ops/training.py:65 2019-01-16 17:41:15.013069: step 3633, loss = 0.70244 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:41:15.994674 ops/training.py:65 2019-01-16 17:41:15.994595: step 3634, loss = 0.70202 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:41:16.976728 ops/training.py:65 2019-01-16 17:41:16.976652: step 3635, loss = 0.68526 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:41:17.957623 ops/training.py:65 2019-01-16 17:41:17.957537: step 3636, loss = 0.69846 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:41:18.939373 ops/training.py:65 2019-01-16 17:41:18.939300: step 3637, loss = 0.70615 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:41:19.920562 ops/training.py:65 2019-01-16 17:41:19.920490: step 3638, loss = 0.70323 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:41:20.902058 ops/training.py:65 2019-01-16 17:41:20.901983: step 3639, loss = 0.69270 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:41:21.884032 ops/training.py:65 2019-01-16 17:41:21.883969: step 3640, loss = 0.68804 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:41:22.868671 ops/training.py:65 2019-01-16 17:41:22.868571: step 3641, loss = 0.69016 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:41:23.852812 ops/training.py:65 2019-01-16 17:41:23.852706: step 3642, loss = 0.70694 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:41:24.837765 ops/training.py:65 2019-01-16 17:41:24.837662: step 3643, loss = 0.68487 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:41:25.820334 ops/training.py:65 2019-01-16 17:41:25.820239: step 3644, loss = 0.68037 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:41:26.804277 ops/training.py:65 2019-01-16 17:41:26.804169: step 3645, loss = 0.69469 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:41:27.788471 ops/training.py:65 2019-01-16 17:41:27.788368: step 3646, loss = 0.71147 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:41:28.772373 ops/training.py:65 2019-01-16 17:41:28.772275: step 3647, loss = 0.70529 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:41:29.756474 ops/training.py:65 2019-01-16 17:41:29.756370: step 3648, loss = 0.71931 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:41:30.740338 ops/training.py:65 2019-01-16 17:41:30.740231: step 3649, loss = 0.67040 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:41:31.723827 ops/training.py:65 2019-01-16 17:41:31.723722: step 3650, loss = 0.69766 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:41:32.706237 ops/training.py:65 2019-01-16 17:41:32.706147: step 3651, loss = 0.68009 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:41:33.689737 ops/training.py:65 2019-01-16 17:41:33.689665: step 3652, loss = 0.68731 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:41:34.672570 ops/training.py:65 2019-01-16 17:41:34.672466: step 3653, loss = 0.70197 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:41:35.655210 ops/training.py:65 2019-01-16 17:41:35.655100: step 3654, loss = 0.69643 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:41:36.640632 ops/training.py:65 2019-01-16 17:41:36.640534: step 3655, loss = 0.68707 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:41:37.625760 ops/training.py:65 2019-01-16 17:41:37.625653: step 3656, loss = 0.67747 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:41:38.610627 ops/training.py:65 2019-01-16 17:41:38.610517: step 3657, loss = 0.68743 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:41:39.593265 ops/training.py:65 2019-01-16 17:41:39.593160: step 3658, loss = 0.67798 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:41:40.577917 ops/training.py:65 2019-01-16 17:41:40.577771: step 3659, loss = 0.69322 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:41:41.562874 ops/training.py:65 2019-01-16 17:41:41.562767: step 3660, loss = 0.66986 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:41:42.547292 ops/training.py:65 2019-01-16 17:41:42.547181: step 3661, loss = 0.70197 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:41:43.532182 ops/training.py:65 2019-01-16 17:41:43.532086: step 3662, loss = 0.70352 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:41:44.517393 ops/training.py:65 2019-01-16 17:41:44.517284: step 3663, loss = 0.71341 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:41:45.500393 ops/training.py:65 2019-01-16 17:41:45.500296: step 3664, loss = 0.68118 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:41:46.483463 ops/training.py:65 2019-01-16 17:41:46.483327: step 3665, loss = 0.67272 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:41:47.467008 ops/training.py:65 2019-01-16 17:41:47.466904: step 3666, loss = 0.67864 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:41:48.452977 ops/training.py:65 2019-01-16 17:41:48.452868: step 3667, loss = 0.69848 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:41:49.436172 ops/training.py:65 2019-01-16 17:41:49.436061: step 3668, loss = 0.70765 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:41:50.418689 ops/training.py:65 2019-01-16 17:41:50.418613: step 3669, loss = 0.69154 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:41:51.401591 ops/training.py:65 2019-01-16 17:41:51.401517: step 3670, loss = 0.71947 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:41:52.385186 ops/training.py:65 2019-01-16 17:41:52.385083: step 3671, loss = 0.69539 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:41:53.370646 ops/training.py:65 2019-01-16 17:41:53.370550: step 3672, loss = 0.69465 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:41:54.352751 ops/training.py:65 2019-01-16 17:41:54.352640: step 3673, loss = 0.70212 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:41:55.335268 ops/training.py:65 2019-01-16 17:41:55.335167: step 3674, loss = 0.68839 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:41:56.317407 ops/training.py:65 2019-01-16 17:41:56.317303: step 3675, loss = 0.69679 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:41:57.299161 ops/training.py:65 2019-01-16 17:41:57.299057: step 3676, loss = 0.71320 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:41:58.281656 ops/training.py:65 2019-01-16 17:41:58.281553: step 3677, loss = 0.68883 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:41:59.263693 ops/training.py:65 2019-01-16 17:41:59.263580: step 3678, loss = 0.66914 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:42:00.245628 ops/training.py:65 2019-01-16 17:42:00.245519: step 3679, loss = 0.69619 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:42:01.228202 ops/training.py:65 2019-01-16 17:42:01.228097: step 3680, loss = 0.69180 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:42:02.211906 ops/training.py:65 2019-01-16 17:42:02.211797: step 3681, loss = 0.69441 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:42:03.195905 ops/training.py:65 2019-01-16 17:42:03.195810: step 3682, loss = 0.70165 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:42:04.179801 ops/training.py:65 2019-01-16 17:42:04.179697: step 3683, loss = 0.68537 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:42:05.162521 ops/training.py:65 2019-01-16 17:42:05.162427: step 3684, loss = 0.70619 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:42:06.145427 ops/training.py:65 2019-01-16 17:42:06.145359: step 3685, loss = 0.68950 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:42:07.129042 ops/training.py:65 2019-01-16 17:42:07.128975: step 3686, loss = 0.69506 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:42:08.112404 ops/training.py:65 2019-01-16 17:42:08.112301: step 3687, loss = 0.70744 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:42:09.094841 ops/training.py:65 2019-01-16 17:42:09.094739: step 3688, loss = 0.69435 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:42:10.077131 ops/training.py:65 2019-01-16 17:42:10.077027: step 3689, loss = 0.69269 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:42:11.059850 ops/training.py:65 2019-01-16 17:42:11.059743: step 3690, loss = 0.70149 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:42:12.042707 ops/training.py:65 2019-01-16 17:42:12.042604: step 3691, loss = 0.68244 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:42:13.025132 ops/training.py:65 2019-01-16 17:42:13.025029: step 3692, loss = 0.69216 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:42:14.006860 ops/training.py:65 2019-01-16 17:42:14.006757: step 3693, loss = 0.70910 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:42:14.989214 ops/training.py:65 2019-01-16 17:42:14.989121: step 3694, loss = 0.70382 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:42:15.971322 ops/training.py:65 2019-01-16 17:42:15.971215: step 3695, loss = 0.70135 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:42:16.952011 ops/training.py:65 2019-01-16 17:42:16.951941: step 3696, loss = 0.70367 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:42:17.935922 ops/training.py:65 2019-01-16 17:42:17.935836: step 3697, loss = 0.70381 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:42:18.920571 ops/training.py:65 2019-01-16 17:42:18.920468: step 3698, loss = 0.70170 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:42:19.902749 ops/training.py:65 2019-01-16 17:42:19.902645: step 3699, loss = 0.69869 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:42:20.884849 ops/training.py:65 2019-01-16 17:42:20.884743: step 3700, loss = 0.68849 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:42:21.866690 ops/training.py:65 2019-01-16 17:42:21.866595: step 3701, loss = 0.69209 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:42:22.849060 ops/training.py:65 2019-01-16 17:42:22.848957: step 3702, loss = 0.69548 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:42:23.832520 ops/training.py:65 2019-01-16 17:42:23.832438: step 3703, loss = 0.69215 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:42:24.815700 ops/training.py:65 2019-01-16 17:42:24.815598: step 3704, loss = 0.69126 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:42:25.798196 ops/training.py:65 2019-01-16 17:42:25.798095: step 3705, loss = 0.68387 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:42:26.779839 ops/training.py:65 2019-01-16 17:42:26.779742: step 3706, loss = 0.69663 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:42:27.761990 ops/training.py:65 2019-01-16 17:42:27.761891: step 3707, loss = 0.68753 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:42:28.745672 ops/training.py:65 2019-01-16 17:42:28.745568: step 3708, loss = 0.69067 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:42:29.730280 ops/training.py:65 2019-01-16 17:42:29.730184: step 3709, loss = 0.68920 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:42:30.711695 ops/training.py:65 2019-01-16 17:42:30.711595: step 3710, loss = 0.69460 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:42:31.694853 ops/training.py:65 2019-01-16 17:42:31.694751: step 3711, loss = 0.70248 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:42:32.678235 ops/training.py:65 2019-01-16 17:42:32.678133: step 3712, loss = 0.68794 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:42:33.660931 ops/training.py:65 2019-01-16 17:42:33.660840: step 3713, loss = 0.68734 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:42:34.642950 ops/training.py:65 2019-01-16 17:42:34.642850: step 3714, loss = 0.69208 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:42:35.624698 ops/training.py:65 2019-01-16 17:42:35.624590: step 3715, loss = 0.70343 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:42:36.605187 ops/training.py:65 2019-01-16 17:42:36.605096: step 3716, loss = 0.69885 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:42:37.586304 ops/training.py:65 2019-01-16 17:42:37.586197: step 3717, loss = 0.70596 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:42:38.569280 ops/training.py:65 2019-01-16 17:42:38.569178: step 3718, loss = 0.68252 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:42:39.550511 ops/training.py:65 2019-01-16 17:42:39.550403: step 3719, loss = 0.69290 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:42:40.533390 ops/training.py:65 2019-01-16 17:42:40.533286: step 3720, loss = 0.68567 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:42:41.521096 ops/training.py:65 2019-01-16 17:42:41.520997: step 3721, loss = 0.68366 (32.4 examples/sec; 0.987 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:42:42.505834 ops/training.py:65 2019-01-16 17:42:42.505732: step 3722, loss = 0.69708 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:42:43.490659 ops/training.py:65 2019-01-16 17:42:43.490566: step 3723, loss = 0.68598 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:42:44.475329 ops/training.py:65 2019-01-16 17:42:44.475234: step 3724, loss = 0.69895 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:42:45.459732 ops/training.py:65 2019-01-16 17:42:45.459633: step 3725, loss = 0.69382 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:42:46.444655 ops/training.py:65 2019-01-16 17:42:46.444555: step 3726, loss = 0.68056 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:42:47.430972 ops/training.py:65 2019-01-16 17:42:47.430869: step 3727, loss = 0.70389 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:42:48.415414 ops/training.py:65 2019-01-16 17:42:48.415337: step 3728, loss = 0.68273 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:42:49.400264 ops/training.py:65 2019-01-16 17:42:49.400166: step 3729, loss = 0.70976 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:42:50.385486 ops/training.py:65 2019-01-16 17:42:50.385390: step 3730, loss = 0.69149 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:42:51.370507 ops/training.py:65 2019-01-16 17:42:51.370413: step 3731, loss = 0.68486 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:42:52.355200 ops/training.py:65 2019-01-16 17:42:52.355101: step 3732, loss = 0.68397 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:42:53.340559 ops/training.py:65 2019-01-16 17:42:53.340469: step 3733, loss = 0.70213 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:42:54.326334 ops/training.py:65 2019-01-16 17:42:54.326234: step 3734, loss = 0.69682 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:42:55.311083 ops/training.py:65 2019-01-16 17:42:55.310979: step 3735, loss = 0.69504 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:42:56.296049 ops/training.py:65 2019-01-16 17:42:56.295957: step 3736, loss = 0.70283 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:42:57.281339 ops/training.py:65 2019-01-16 17:42:57.281231: step 3737, loss = 0.69496 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:42:58.267454 ops/training.py:65 2019-01-16 17:42:58.267352: step 3738, loss = 0.68205 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:42:59.251726 ops/training.py:65 2019-01-16 17:42:59.251626: step 3739, loss = 0.70180 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:43:00.236971 ops/training.py:65 2019-01-16 17:43:00.236869: step 3740, loss = 0.70340 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:43:01.221793 ops/training.py:65 2019-01-16 17:43:01.221691: step 3741, loss = 0.68868 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:43:02.206076 ops/training.py:65 2019-01-16 17:43:02.205974: step 3742, loss = 0.69042 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:43:03.191284 ops/training.py:65 2019-01-16 17:43:03.191185: step 3743, loss = 0.68919 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:43:04.175048 ops/training.py:65 2019-01-16 17:43:04.174948: step 3744, loss = 0.67562 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:43:05.156907 ops/training.py:65 2019-01-16 17:43:05.156821: step 3745, loss = 0.70998 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:43:06.139988 ops/training.py:65 2019-01-16 17:43:06.139886: step 3746, loss = 0.69482 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:43:07.122829 ops/training.py:65 2019-01-16 17:43:07.122733: step 3747, loss = 0.71298 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:43:08.105176 ops/training.py:65 2019-01-16 17:43:08.105073: step 3748, loss = 0.69911 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:43:09.087898 ops/training.py:65 2019-01-16 17:43:09.087793: step 3749, loss = 0.69754 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:43:10.070507 ops/training.py:65 2019-01-16 17:43:10.070410: step 3750, loss = 0.68472 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:43:11.057961 ops/training.py:65 2019-01-16 17:43:11.057861: step 3751, loss = 0.72551 (32.4 examples/sec; 0.986 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:43:12.040873 ops/training.py:65 2019-01-16 17:43:12.040772: step 3752, loss = 0.68679 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:43:13.023665 ops/training.py:65 2019-01-16 17:43:13.023576: step 3753, loss = 0.67567 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:43:14.007697 ops/training.py:65 2019-01-16 17:43:14.007597: step 3754, loss = 0.70066 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:43:14.991105 ops/training.py:65 2019-01-16 17:43:14.990994: step 3755, loss = 0.70026 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:43:15.977186 ops/training.py:65 2019-01-16 17:43:15.977085: step 3756, loss = 0.69893 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:43:16.960714 ops/training.py:65 2019-01-16 17:43:16.960609: step 3757, loss = 0.71951 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:43:17.949934 ops/training.py:65 2019-01-16 17:43:17.949835: step 3758, loss = 0.68713 (32.4 examples/sec; 0.988 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:43:18.934677 ops/training.py:65 2019-01-16 17:43:18.934571: step 3759, loss = 0.68377 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:43:19.918872 ops/training.py:65 2019-01-16 17:43:19.918773: step 3760, loss = 0.71543 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:43:20.903289 ops/training.py:65 2019-01-16 17:43:20.903176: step 3761, loss = 0.69470 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:43:21.887357 ops/training.py:65 2019-01-16 17:43:21.887263: step 3762, loss = 0.71274 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:43:22.869432 ops/training.py:65 2019-01-16 17:43:22.869330: step 3763, loss = 0.68145 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:43:23.852201 ops/training.py:65 2019-01-16 17:43:23.852103: step 3764, loss = 0.69199 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:43:24.835931 ops/training.py:65 2019-01-16 17:43:24.835834: step 3765, loss = 0.71531 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:43:25.820346 ops/training.py:65 2019-01-16 17:43:25.820202: step 3766, loss = 0.69405 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:43:26.806359 ops/training.py:65 2019-01-16 17:43:26.806288: step 3767, loss = 0.69337 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:43:27.789131 ops/training.py:65 2019-01-16 17:43:27.789030: step 3768, loss = 0.69632 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:43:28.772943 ops/training.py:65 2019-01-16 17:43:28.772840: step 3769, loss = 0.69485 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:43:29.755664 ops/training.py:65 2019-01-16 17:43:29.755568: step 3770, loss = 0.71015 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:43:30.739427 ops/training.py:65 2019-01-16 17:43:30.739330: step 3771, loss = 0.69436 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:43:31.724319 ops/training.py:65 2019-01-16 17:43:31.724232: step 3772, loss = 0.69241 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:43:32.708770 ops/training.py:65 2019-01-16 17:43:32.708675: step 3773, loss = 0.70555 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:43:33.690625 ops/training.py:65 2019-01-16 17:43:33.690530: step 3774, loss = 0.69500 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:43:34.673651 ops/training.py:65 2019-01-16 17:43:34.673547: step 3775, loss = 0.69482 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:43:35.656411 ops/training.py:65 2019-01-16 17:43:35.656310: step 3776, loss = 0.69421 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:43:36.640619 ops/training.py:65 2019-01-16 17:43:36.640527: step 3777, loss = 0.70339 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:43:37.622879 ops/training.py:65 2019-01-16 17:43:37.622781: step 3778, loss = 0.70054 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:43:38.606269 ops/training.py:65 2019-01-16 17:43:38.606161: step 3779, loss = 0.69758 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:43:39.588475 ops/training.py:65 2019-01-16 17:43:39.588379: step 3780, loss = 0.68713 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:43:40.573346 ops/training.py:65 2019-01-16 17:43:40.573243: step 3781, loss = 0.69451 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:43:41.558169 ops/training.py:65 2019-01-16 17:43:41.558021: step 3782, loss = 0.69726 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:43:42.542563 ops/training.py:65 2019-01-16 17:43:42.542456: step 3783, loss = 0.69415 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:43:43.527435 ops/training.py:65 2019-01-16 17:43:43.527357: step 3784, loss = 0.70302 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:43:44.513534 ops/training.py:65 2019-01-16 17:43:44.513431: step 3785, loss = 0.68493 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:43:45.497634 ops/training.py:65 2019-01-16 17:43:45.497534: step 3786, loss = 0.68596 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:43:46.480210 ops/training.py:65 2019-01-16 17:43:46.480131: step 3787, loss = 0.69096 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:43:47.466101 ops/training.py:65 2019-01-16 17:43:47.466028: step 3788, loss = 0.70092 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:43:48.450776 ops/training.py:65 2019-01-16 17:43:48.450672: step 3789, loss = 0.68991 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:43:49.436508 ops/training.py:65 2019-01-16 17:43:49.436410: step 3790, loss = 0.69316 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:43:50.420713 ops/training.py:65 2019-01-16 17:43:50.420610: step 3791, loss = 0.68575 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:43:51.406259 ops/training.py:65 2019-01-16 17:43:51.406167: step 3792, loss = 0.70268 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:43:52.391022 ops/training.py:65 2019-01-16 17:43:52.390918: step 3793, loss = 0.69497 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:43:53.377159 ops/training.py:65 2019-01-16 17:43:53.377059: step 3794, loss = 0.69250 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:43:54.363579 ops/training.py:65 2019-01-16 17:43:54.363473: step 3795, loss = 0.68963 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:43:55.350325 ops/training.py:65 2019-01-16 17:43:55.350220: step 3796, loss = 0.70799 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:43:56.336663 ops/training.py:65 2019-01-16 17:43:56.336558: step 3797, loss = 0.67937 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:43:57.321368 ops/training.py:65 2019-01-16 17:43:57.321265: step 3798, loss = 0.69226 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:43:58.307319 ops/training.py:65 2019-01-16 17:43:58.307218: step 3799, loss = 0.69721 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:43:59.292310 ops/training.py:65 2019-01-16 17:43:59.292209: step 3800, loss = 0.69583 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:44:00.277450 ops/training.py:65 2019-01-16 17:44:00.277352: step 3801, loss = 0.70106 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:44:01.260436 ops/training.py:65 2019-01-16 17:44:01.260336: step 3802, loss = 0.68925 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:44:02.245016 ops/training.py:65 2019-01-16 17:44:02.244924: step 3803, loss = 0.70442 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:44:03.229331 ops/training.py:65 2019-01-16 17:44:03.229241: step 3804, loss = 0.70177 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:44:04.213259 ops/training.py:65 2019-01-16 17:44:04.213158: step 3805, loss = 0.68214 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:44:05.197660 ops/training.py:65 2019-01-16 17:44:05.197562: step 3806, loss = 0.68522 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:44:06.180438 ops/training.py:65 2019-01-16 17:44:06.180335: step 3807, loss = 0.69078 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:44:07.163354 ops/training.py:65 2019-01-16 17:44:07.163260: step 3808, loss = 0.69312 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:44:08.149228 ops/training.py:65 2019-01-16 17:44:08.149131: step 3809, loss = 0.70091 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:44:09.134141 ops/training.py:65 2019-01-16 17:44:09.134040: step 3810, loss = 0.67708 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:44:10.117700 ops/training.py:65 2019-01-16 17:44:10.117606: step 3811, loss = 0.69739 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:44:11.101628 ops/training.py:65 2019-01-16 17:44:11.101539: step 3812, loss = 0.69462 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:44:12.085559 ops/training.py:65 2019-01-16 17:44:12.085457: step 3813, loss = 0.69020 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:44:13.068429 ops/training.py:65 2019-01-16 17:44:13.068335: step 3814, loss = 0.69447 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:44:14.052825 ops/training.py:65 2019-01-16 17:44:14.052720: step 3815, loss = 0.68578 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:44:15.037715 ops/training.py:65 2019-01-16 17:44:15.037610: step 3816, loss = 0.70937 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:44:16.022198 ops/training.py:65 2019-01-16 17:44:16.022091: step 3817, loss = 0.68582 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:44:17.005158 ops/training.py:65 2019-01-16 17:44:17.005058: step 3818, loss = 0.67085 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:44:17.988676 ops/training.py:65 2019-01-16 17:44:17.988572: step 3819, loss = 0.67928 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:44:18.970806 ops/training.py:65 2019-01-16 17:44:18.970706: step 3820, loss = 0.69687 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:44:19.953110 ops/training.py:65 2019-01-16 17:44:19.953033: step 3821, loss = 0.69136 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:44:20.934161 ops/training.py:65 2019-01-16 17:44:20.934089: step 3822, loss = 0.73435 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:44:21.914496 ops/training.py:65 2019-01-16 17:44:21.914428: step 3823, loss = 0.72062 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:44:22.898310 ops/training.py:65 2019-01-16 17:44:22.898246: step 3824, loss = 0.67657 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:44:23.883166 ops/training.py:65 2019-01-16 17:44:23.883068: step 3825, loss = 0.72541 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:44:24.866929 ops/training.py:65 2019-01-16 17:44:24.866831: step 3826, loss = 0.68767 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:44:25.850808 ops/training.py:65 2019-01-16 17:44:25.850704: step 3827, loss = 0.70199 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:44:26.835487 ops/training.py:65 2019-01-16 17:44:26.835391: step 3828, loss = 0.69171 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:44:27.819398 ops/training.py:65 2019-01-16 17:44:27.819295: step 3829, loss = 0.70632 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:44:28.802610 ops/training.py:65 2019-01-16 17:44:28.802505: step 3830, loss = 0.68785 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:44:29.789634 ops/training.py:65 2019-01-16 17:44:29.789531: step 3831, loss = 0.68737 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:44:30.775105 ops/training.py:65 2019-01-16 17:44:30.774996: step 3832, loss = 0.68633 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:44:31.758134 ops/training.py:65 2019-01-16 17:44:31.758026: step 3833, loss = 0.68726 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:44:32.739161 ops/training.py:65 2019-01-16 17:44:32.739068: step 3834, loss = 0.69201 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:44:33.725548 ops/training.py:65 2019-01-16 17:44:33.725457: step 3835, loss = 0.70471 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:44:34.711015 ops/training.py:65 2019-01-16 17:44:34.710952: step 3836, loss = 0.70685 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:44:35.693765 ops/training.py:65 2019-01-16 17:44:35.693663: step 3837, loss = 0.70856 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:44:36.679377 ops/training.py:65 2019-01-16 17:44:36.679281: step 3838, loss = 0.73383 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:44:37.664411 ops/training.py:65 2019-01-16 17:44:37.664306: step 3839, loss = 0.71564 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:44:38.648993 ops/training.py:65 2019-01-16 17:44:38.648884: step 3840, loss = 0.70099 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:44:39.632542 ops/training.py:65 2019-01-16 17:44:39.632436: step 3841, loss = 0.68669 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:44:40.615796 ops/training.py:65 2019-01-16 17:44:40.615722: step 3842, loss = 0.68439 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:44:41.600807 ops/training.py:65 2019-01-16 17:44:41.600719: step 3843, loss = 0.67340 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:44:42.584346 ops/training.py:65 2019-01-16 17:44:42.584250: step 3844, loss = 0.69336 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:44:43.568826 ops/training.py:65 2019-01-16 17:44:43.568728: step 3845, loss = 0.68318 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:44:44.551617 ops/training.py:65 2019-01-16 17:44:44.551520: step 3846, loss = 0.67085 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.75
I8192 2019-01-16 17:44:45.536778 ops/training.py:65 2019-01-16 17:44:45.536672: step 3847, loss = 0.68792 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:44:46.522867 ops/training.py:65 2019-01-16 17:44:46.522766: step 3848, loss = 0.69309 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:44:47.508180 ops/training.py:65 2019-01-16 17:44:47.508081: step 3849, loss = 0.68302 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:44:48.491710 ops/training.py:65 2019-01-16 17:44:48.491604: step 3850, loss = 0.69966 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:44:49.476998 ops/training.py:65 2019-01-16 17:44:49.476896: step 3851, loss = 0.68803 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:44:50.460947 ops/training.py:65 2019-01-16 17:44:50.460835: step 3852, loss = 0.68630 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:44:51.447637 ops/training.py:65 2019-01-16 17:44:51.447539: step 3853, loss = 0.68626 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:44:52.432369 ops/training.py:65 2019-01-16 17:44:52.432258: step 3854, loss = 0.70733 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:44:53.416769 ops/training.py:65 2019-01-16 17:44:53.416671: step 3855, loss = 0.71637 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:44:54.401085 ops/training.py:65 2019-01-16 17:44:54.400976: step 3856, loss = 0.67947 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:44:55.387251 ops/training.py:65 2019-01-16 17:44:55.387152: step 3857, loss = 0.69192 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:44:56.372716 ops/training.py:65 2019-01-16 17:44:56.372613: step 3858, loss = 0.70298 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:44:57.357595 ops/training.py:65 2019-01-16 17:44:57.357496: step 3859, loss = 0.68895 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:44:58.340322 ops/training.py:65 2019-01-16 17:44:58.340230: step 3860, loss = 0.67750 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:44:59.327210 ops/training.py:65 2019-01-16 17:44:59.327108: step 3861, loss = 0.70934 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:45:00.309817 ops/training.py:65 2019-01-16 17:45:00.309721: step 3862, loss = 0.70626 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:45:01.293498 ops/training.py:65 2019-01-16 17:45:01.293395: step 3863, loss = 0.67792 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:45:02.276699 ops/training.py:65 2019-01-16 17:45:02.276570: step 3864, loss = 0.70122 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:45:03.260349 ops/training.py:65 2019-01-16 17:45:03.260248: step 3865, loss = 0.70562 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:45:04.243804 ops/training.py:65 2019-01-16 17:45:04.243708: step 3866, loss = 0.69609 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:45:05.230052 ops/training.py:65 2019-01-16 17:45:05.229941: step 3867, loss = 0.69826 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:45:06.216756 ops/training.py:65 2019-01-16 17:45:06.216653: step 3868, loss = 0.68370 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:45:07.202025 ops/training.py:65 2019-01-16 17:45:07.201936: step 3869, loss = 0.68495 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:45:08.185809 ops/training.py:65 2019-01-16 17:45:08.185706: step 3870, loss = 0.70365 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:45:09.169379 ops/training.py:65 2019-01-16 17:45:09.169286: step 3871, loss = 0.67728 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:45:10.151946 ops/training.py:65 2019-01-16 17:45:10.151847: step 3872, loss = 0.70228 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:45:11.135226 ops/training.py:65 2019-01-16 17:45:11.135130: step 3873, loss = 0.69369 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:45:12.118697 ops/training.py:65 2019-01-16 17:45:12.118596: step 3874, loss = 0.70241 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:45:13.103708 ops/training.py:65 2019-01-16 17:45:13.103610: step 3875, loss = 0.68139 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:45:14.090061 ops/training.py:65 2019-01-16 17:45:14.089952: step 3876, loss = 0.68819 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:45:15.074690 ops/training.py:65 2019-01-16 17:45:15.074592: step 3877, loss = 0.70123 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:45:16.058454 ops/training.py:65 2019-01-16 17:45:16.058320: step 3878, loss = 0.69446 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:45:17.042714 ops/training.py:65 2019-01-16 17:45:17.042615: step 3879, loss = 0.69990 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:45:18.026593 ops/training.py:65 2019-01-16 17:45:18.026494: step 3880, loss = 0.68280 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:45:19.009367 ops/training.py:65 2019-01-16 17:45:19.009272: step 3881, loss = 0.69816 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:45:19.991332 ops/training.py:65 2019-01-16 17:45:19.991232: step 3882, loss = 0.69265 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:45:20.974975 ops/training.py:65 2019-01-16 17:45:20.974878: step 3883, loss = 0.69905 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:45:21.957150 ops/training.py:65 2019-01-16 17:45:21.957061: step 3884, loss = 0.70014 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:45:22.939122 ops/training.py:65 2019-01-16 17:45:22.939022: step 3885, loss = 0.70167 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:45:23.922637 ops/training.py:65 2019-01-16 17:45:23.922525: step 3886, loss = 0.69538 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:45:24.905254 ops/training.py:65 2019-01-16 17:45:24.905169: step 3887, loss = 0.70607 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:45:25.888019 ops/training.py:65 2019-01-16 17:45:25.887923: step 3888, loss = 0.68793 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:45:26.870936 ops/training.py:65 2019-01-16 17:45:26.870848: step 3889, loss = 0.67702 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:45:27.855144 ops/training.py:65 2019-01-16 17:45:27.855037: step 3890, loss = 0.68610 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:45:28.839718 ops/training.py:65 2019-01-16 17:45:28.839612: step 3891, loss = 0.68884 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:45:29.823129 ops/training.py:65 2019-01-16 17:45:29.823036: step 3892, loss = 0.69938 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:45:30.806855 ops/training.py:65 2019-01-16 17:45:30.806755: step 3893, loss = 0.71225 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:45:31.790057 ops/training.py:65 2019-01-16 17:45:31.789942: step 3894, loss = 0.69734 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:45:32.776213 ops/training.py:65 2019-01-16 17:45:32.776108: step 3895, loss = 0.70313 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:45:33.759369 ops/training.py:65 2019-01-16 17:45:33.759268: step 3896, loss = 0.68703 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:45:34.740449 ops/training.py:65 2019-01-16 17:45:34.740352: step 3897, loss = 0.69242 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:45:35.722747 ops/training.py:65 2019-01-16 17:45:35.722644: step 3898, loss = 0.69955 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:45:36.705935 ops/training.py:65 2019-01-16 17:45:36.705842: step 3899, loss = 0.69173 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:45:37.688377 ops/training.py:65 2019-01-16 17:45:37.688280: step 3900, loss = 0.69402 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:45:38.672190 ops/training.py:65 2019-01-16 17:45:38.672081: step 3901, loss = 0.69416 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:45:39.656206 ops/training.py:65 2019-01-16 17:45:39.656099: step 3902, loss = 0.69396 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:45:40.639004 ops/training.py:65 2019-01-16 17:45:40.638892: step 3903, loss = 0.70420 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:45:41.622728 ops/training.py:65 2019-01-16 17:45:41.622635: step 3904, loss = 0.68640 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:45:42.606609 ops/training.py:65 2019-01-16 17:45:42.606514: step 3905, loss = 0.69667 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:45:43.589932 ops/training.py:65 2019-01-16 17:45:43.589829: step 3906, loss = 0.70184 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:45:44.576378 ops/training.py:65 2019-01-16 17:45:44.576274: step 3907, loss = 0.70146 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:45:45.559148 ops/training.py:65 2019-01-16 17:45:45.559044: step 3908, loss = 0.69961 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:45:46.543242 ops/training.py:65 2019-01-16 17:45:46.543141: step 3909, loss = 0.70522 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:45:47.525765 ops/training.py:65 2019-01-16 17:45:47.525661: step 3910, loss = 0.70931 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:45:48.508272 ops/training.py:65 2019-01-16 17:45:48.508160: step 3911, loss = 0.66948 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:45:49.490794 ops/training.py:65 2019-01-16 17:45:49.490691: step 3912, loss = 0.69747 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:45:50.473589 ops/training.py:65 2019-01-16 17:45:50.473483: step 3913, loss = 0.69271 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:45:51.457584 ops/training.py:65 2019-01-16 17:45:51.457492: step 3914, loss = 0.69870 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:45:52.440215 ops/training.py:65 2019-01-16 17:45:52.440108: step 3915, loss = 0.69887 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:45:53.425232 ops/training.py:65 2019-01-16 17:45:53.425128: step 3916, loss = 0.68159 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:45:54.411293 ops/training.py:65 2019-01-16 17:45:54.411192: step 3917, loss = 0.70613 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:45:55.395300 ops/training.py:65 2019-01-16 17:45:55.395194: step 3918, loss = 0.67706 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:45:56.377761 ops/training.py:65 2019-01-16 17:45:56.377666: step 3919, loss = 0.69659 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:45:57.359530 ops/training.py:65 2019-01-16 17:45:57.359441: step 3920, loss = 0.69662 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:45:58.343147 ops/training.py:65 2019-01-16 17:45:58.343045: step 3921, loss = 0.69832 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:45:59.327899 ops/training.py:65 2019-01-16 17:45:59.327795: step 3922, loss = 0.69677 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:46:00.311886 ops/training.py:65 2019-01-16 17:46:00.311756: step 3923, loss = 0.68589 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:46:01.295580 ops/training.py:65 2019-01-16 17:46:01.295482: step 3924, loss = 0.71249 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:46:02.279182 ops/training.py:65 2019-01-16 17:46:02.279080: step 3925, loss = 0.67872 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:46:03.262211 ops/training.py:65 2019-01-16 17:46:03.262118: step 3926, loss = 0.69090 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:46:04.246122 ops/training.py:65 2019-01-16 17:46:04.246016: step 3927, loss = 0.69462 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:46:05.229015 ops/training.py:65 2019-01-16 17:46:05.228923: step 3928, loss = 0.69598 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:46:06.211791 ops/training.py:65 2019-01-16 17:46:06.211689: step 3929, loss = 0.71214 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:46:07.195535 ops/training.py:65 2019-01-16 17:46:07.195434: step 3930, loss = 0.68308 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:46:08.177893 ops/training.py:65 2019-01-16 17:46:08.177787: step 3931, loss = 0.69489 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:46:09.160909 ops/training.py:65 2019-01-16 17:46:09.160805: step 3932, loss = 0.70009 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:46:10.143923 ops/training.py:65 2019-01-16 17:46:10.143823: step 3933, loss = 0.69373 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:46:11.126409 ops/training.py:65 2019-01-16 17:46:11.126300: step 3934, loss = 0.69515 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:46:12.107899 ops/training.py:65 2019-01-16 17:46:12.107803: step 3935, loss = 0.69468 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:46:13.090831 ops/training.py:65 2019-01-16 17:46:13.090728: step 3936, loss = 0.70398 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:46:14.073434 ops/training.py:65 2019-01-16 17:46:14.073330: step 3937, loss = 0.68914 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:46:15.056136 ops/training.py:65 2019-01-16 17:46:15.056053: step 3938, loss = 0.69657 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:46:16.037526 ops/training.py:65 2019-01-16 17:46:16.037440: step 3939, loss = 0.68264 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:46:17.020255 ops/training.py:65 2019-01-16 17:46:17.020162: step 3940, loss = 0.68784 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:46:18.002698 ops/training.py:65 2019-01-16 17:46:18.002599: step 3941, loss = 0.70088 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:46:18.985153 ops/training.py:65 2019-01-16 17:46:18.985056: step 3942, loss = 0.69593 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:46:19.966938 ops/training.py:65 2019-01-16 17:46:19.966831: step 3943, loss = 0.67989 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:46:20.952690 ops/training.py:65 2019-01-16 17:46:20.952590: step 3944, loss = 0.69254 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:46:21.935247 ops/training.py:65 2019-01-16 17:46:21.935166: step 3945, loss = 0.69667 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:46:22.919706 ops/training.py:65 2019-01-16 17:46:22.919614: step 3946, loss = 0.69023 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:46:23.902963 ops/training.py:65 2019-01-16 17:46:23.902865: step 3947, loss = 0.68093 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:46:24.885130 ops/training.py:65 2019-01-16 17:46:24.885024: step 3948, loss = 0.68584 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:46:25.867776 ops/training.py:65 2019-01-16 17:46:25.867676: step 3949, loss = 0.68786 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:46:26.850014 ops/training.py:65 2019-01-16 17:46:26.849909: step 3950, loss = 0.69528 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:46:27.831549 ops/training.py:65 2019-01-16 17:46:27.831446: step 3951, loss = 0.69390 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:46:28.813495 ops/training.py:65 2019-01-16 17:46:28.813398: step 3952, loss = 0.69181 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:46:29.797555 ops/training.py:65 2019-01-16 17:46:29.797448: step 3953, loss = 0.69658 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:46:30.781481 ops/training.py:65 2019-01-16 17:46:30.781376: step 3954, loss = 0.70084 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:46:31.766364 ops/training.py:65 2019-01-16 17:46:31.766254: step 3955, loss = 0.69584 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:46:32.751036 ops/training.py:65 2019-01-16 17:46:32.750929: step 3956, loss = 0.69413 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:46:33.734493 ops/training.py:65 2019-01-16 17:46:33.734397: step 3957, loss = 0.69191 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:46:34.719402 ops/training.py:65 2019-01-16 17:46:34.719294: step 3958, loss = 0.70856 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:46:35.705048 ops/training.py:65 2019-01-16 17:46:35.704958: step 3959, loss = 0.69499 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:46:36.690407 ops/training.py:65 2019-01-16 17:46:36.690316: step 3960, loss = 0.68798 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:46:37.675452 ops/training.py:65 2019-01-16 17:46:37.675347: step 3961, loss = 0.70954 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:46:38.661235 ops/training.py:65 2019-01-16 17:46:38.661128: step 3962, loss = 0.67690 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:46:39.644318 ops/training.py:65 2019-01-16 17:46:39.644222: step 3963, loss = 0.68124 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:46:40.628056 ops/training.py:65 2019-01-16 17:46:40.627961: step 3964, loss = 0.67962 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:46:41.611663 ops/training.py:65 2019-01-16 17:46:41.611557: step 3965, loss = 0.67796 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:46:42.595776 ops/training.py:65 2019-01-16 17:46:42.595669: step 3966, loss = 0.69446 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:46:43.579515 ops/training.py:65 2019-01-16 17:46:43.579412: step 3967, loss = 0.69665 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:46:44.561994 ops/training.py:65 2019-01-16 17:46:44.561887: step 3968, loss = 0.69412 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:46:45.544625 ops/training.py:65 2019-01-16 17:46:45.544515: step 3969, loss = 0.69623 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:46:46.527034 ops/training.py:65 2019-01-16 17:46:46.526945: step 3970, loss = 0.70903 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:46:47.511275 ops/training.py:65 2019-01-16 17:46:47.511174: step 3971, loss = 0.69102 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:46:48.493952 ops/training.py:65 2019-01-16 17:46:48.493843: step 3972, loss = 0.69110 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:46:49.476019 ops/training.py:65 2019-01-16 17:46:49.475912: step 3973, loss = 0.68585 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:46:50.458115 ops/training.py:65 2019-01-16 17:46:50.458006: step 3974, loss = 0.70631 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:46:51.440885 ops/training.py:65 2019-01-16 17:46:51.440781: step 3975, loss = 0.71219 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:46:52.423034 ops/training.py:65 2019-01-16 17:46:52.422942: step 3976, loss = 0.70721 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:46:53.405189 ops/training.py:65 2019-01-16 17:46:53.405086: step 3977, loss = 0.69790 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:46:54.387178 ops/training.py:65 2019-01-16 17:46:54.387078: step 3978, loss = 0.67835 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.75
I8192 2019-01-16 17:46:55.369849 ops/training.py:65 2019-01-16 17:46:55.369747: step 3979, loss = 0.69295 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:46:56.353308 ops/training.py:65 2019-01-16 17:46:56.353198: step 3980, loss = 0.70350 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:46:57.335925 ops/training.py:65 2019-01-16 17:46:57.335789: step 3981, loss = 0.69699 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:46:58.319015 ops/training.py:65 2019-01-16 17:46:58.318914: step 3982, loss = 0.69421 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:46:59.302537 ops/training.py:65 2019-01-16 17:46:59.302432: step 3983, loss = 0.70405 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:47:00.284770 ops/training.py:65 2019-01-16 17:47:00.284672: step 3984, loss = 0.69242 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:47:01.266753 ops/training.py:65 2019-01-16 17:47:01.266663: step 3985, loss = 0.69324 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:47:02.249023 ops/training.py:65 2019-01-16 17:47:02.248918: step 3986, loss = 0.70319 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:47:03.232309 ops/training.py:65 2019-01-16 17:47:03.232207: step 3987, loss = 0.67473 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 17:47:04.214520 ops/training.py:65 2019-01-16 17:47:04.214377: step 3988, loss = 0.69734 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:47:05.196973 ops/training.py:65 2019-01-16 17:47:05.196830: step 3989, loss = 0.68607 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.75
I8192 2019-01-16 17:47:06.178936 ops/training.py:65 2019-01-16 17:47:06.178828: step 3990, loss = 0.69233 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:47:07.161407 ops/training.py:65 2019-01-16 17:47:07.161312: step 3991, loss = 0.68927 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:47:08.144963 ops/training.py:65 2019-01-16 17:47:08.144857: step 3992, loss = 0.69214 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:47:09.127462 ops/training.py:65 2019-01-16 17:47:09.127361: step 3993, loss = 0.68927 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:47:10.109531 ops/training.py:65 2019-01-16 17:47:10.109439: step 3994, loss = 0.68658 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:47:11.092994 ops/training.py:65 2019-01-16 17:47:11.092954: step 3995, loss = 0.68697 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:47:12.074814 ops/training.py:65 2019-01-16 17:47:12.074733: step 3996, loss = 0.69709 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:47:13.058277 ops/training.py:65 2019-01-16 17:47:13.058230: step 3997, loss = 0.68992 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:47:14.042363 ops/training.py:65 2019-01-16 17:47:14.042322: step 3998, loss = 0.69476 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:47:15.024458 ops/training.py:65 2019-01-16 17:47:15.024416: step 3999, loss = 0.69044 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:51:59.487820 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I8192 2019-01-16 17:51:59.489161 ops/training.py:41 2019-01-16 17:51:59.489064: step 4000, loss = 0.69 (0.1 examples/sec; 283.481 sec/batch) | Training accuracy = 0.4375 | Validation accuracy = 0.51 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_16_30_45_270295
I8192 2019-01-16 17:52:00.475593 ops/training.py:65 2019-01-16 17:52:00.475517: step 4001, loss = 0.68972 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:52:01.461180 ops/training.py:65 2019-01-16 17:52:01.461111: step 4002, loss = 0.70138 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:52:02.443562 ops/training.py:65 2019-01-16 17:52:02.443502: step 4003, loss = 0.67594 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:52:03.427259 ops/training.py:65 2019-01-16 17:52:03.427181: step 4004, loss = 0.69924 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:52:04.411803 ops/training.py:65 2019-01-16 17:52:04.411713: step 4005, loss = 0.69233 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:52:05.393375 ops/training.py:65 2019-01-16 17:52:05.393286: step 4006, loss = 0.67919 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:52:06.375681 ops/training.py:65 2019-01-16 17:52:06.375584: step 4007, loss = 0.69050 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:52:07.357810 ops/training.py:65 2019-01-16 17:52:07.357715: step 4008, loss = 0.69846 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:52:08.339828 ops/training.py:65 2019-01-16 17:52:08.339721: step 4009, loss = 0.70253 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:52:09.321363 ops/training.py:65 2019-01-16 17:52:09.321256: step 4010, loss = 0.69962 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:52:10.305174 ops/training.py:65 2019-01-16 17:52:10.305067: step 4011, loss = 0.69030 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:52:11.289072 ops/training.py:65 2019-01-16 17:52:11.288968: step 4012, loss = 0.69119 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:52:12.274334 ops/training.py:65 2019-01-16 17:52:12.274212: step 4013, loss = 0.68753 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:52:13.259915 ops/training.py:65 2019-01-16 17:52:13.259841: step 4014, loss = 0.69357 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:52:14.244690 ops/training.py:65 2019-01-16 17:52:14.244592: step 4015, loss = 0.69979 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:52:15.229019 ops/training.py:65 2019-01-16 17:52:15.228948: step 4016, loss = 0.69357 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:52:16.214357 ops/training.py:65 2019-01-16 17:52:16.214290: step 4017, loss = 0.67483 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:52:17.200969 ops/training.py:65 2019-01-16 17:52:17.200864: step 4018, loss = 0.68226 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:52:18.188461 ops/training.py:65 2019-01-16 17:52:18.188394: step 4019, loss = 0.70093 (32.4 examples/sec; 0.986 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:52:19.171857 ops/training.py:65 2019-01-16 17:52:19.171750: step 4020, loss = 0.70019 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:52:20.155446 ops/training.py:65 2019-01-16 17:52:20.155363: step 4021, loss = 0.68512 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:52:21.139871 ops/training.py:65 2019-01-16 17:52:21.139789: step 4022, loss = 0.68805 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:52:22.123697 ops/training.py:65 2019-01-16 17:52:22.123622: step 4023, loss = 0.69746 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:52:23.107167 ops/training.py:65 2019-01-16 17:52:23.107097: step 4024, loss = 0.71127 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:52:24.091656 ops/training.py:65 2019-01-16 17:52:24.091562: step 4025, loss = 0.67352 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:52:25.077700 ops/training.py:65 2019-01-16 17:52:25.077595: step 4026, loss = 0.69732 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:52:26.064023 ops/training.py:65 2019-01-16 17:52:26.063894: step 4027, loss = 0.70516 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:52:27.048906 ops/training.py:65 2019-01-16 17:52:27.048820: step 4028, loss = 0.69488 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:52:28.033536 ops/training.py:65 2019-01-16 17:52:28.033465: step 4029, loss = 0.69814 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:52:29.017485 ops/training.py:65 2019-01-16 17:52:29.017408: step 4030, loss = 0.70508 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:52:30.002695 ops/training.py:65 2019-01-16 17:52:30.002626: step 4031, loss = 0.68300 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:52:30.986433 ops/training.py:65 2019-01-16 17:52:30.986376: step 4032, loss = 0.68995 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:52:31.970372 ops/training.py:65 2019-01-16 17:52:31.970287: step 4033, loss = 0.69300 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:52:32.956093 ops/training.py:65 2019-01-16 17:52:32.955983: step 4034, loss = 0.70021 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:52:33.938698 ops/training.py:65 2019-01-16 17:52:33.938597: step 4035, loss = 0.68992 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:52:34.922729 ops/training.py:65 2019-01-16 17:52:34.922578: step 4036, loss = 0.69445 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:52:35.906784 ops/training.py:65 2019-01-16 17:52:35.906678: step 4037, loss = 0.69207 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:52:36.892004 ops/training.py:65 2019-01-16 17:52:36.891901: step 4038, loss = 0.70370 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:52:37.877046 ops/training.py:65 2019-01-16 17:52:37.876951: step 4039, loss = 0.68914 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:52:38.860386 ops/training.py:65 2019-01-16 17:52:38.860234: step 4040, loss = 0.69725 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:52:39.846410 ops/training.py:65 2019-01-16 17:52:39.846295: step 4041, loss = 0.69220 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:52:40.831485 ops/training.py:65 2019-01-16 17:52:40.831416: step 4042, loss = 0.69590 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:52:41.814770 ops/training.py:65 2019-01-16 17:52:41.814678: step 4043, loss = 0.68874 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:52:42.799620 ops/training.py:65 2019-01-16 17:52:42.799549: step 4044, loss = 0.69239 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:52:43.782684 ops/training.py:65 2019-01-16 17:52:43.782589: step 4045, loss = 0.69162 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:52:44.771865 ops/training.py:65 2019-01-16 17:52:44.771737: step 4046, loss = 0.69591 (32.4 examples/sec; 0.988 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:52:45.756879 ops/training.py:65 2019-01-16 17:52:45.756693: step 4047, loss = 0.70360 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:52:46.741787 ops/training.py:65 2019-01-16 17:52:46.741678: step 4048, loss = 0.69833 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:52:47.724900 ops/training.py:65 2019-01-16 17:52:47.724813: step 4049, loss = 0.68520 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:52:48.709293 ops/training.py:65 2019-01-16 17:52:48.709191: step 4050, loss = 0.70258 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:52:49.691606 ops/training.py:65 2019-01-16 17:52:49.691480: step 4051, loss = 0.69860 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:52:50.675336 ops/training.py:65 2019-01-16 17:52:50.675227: step 4052, loss = 0.68879 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:52:51.657871 ops/training.py:65 2019-01-16 17:52:51.657780: step 4053, loss = 0.70035 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:52:52.641805 ops/training.py:65 2019-01-16 17:52:52.641728: step 4054, loss = 0.70432 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:52:53.623268 ops/training.py:65 2019-01-16 17:52:53.623161: step 4055, loss = 0.69719 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:52:54.609355 ops/training.py:65 2019-01-16 17:52:54.609231: step 4056, loss = 0.69098 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:52:55.595766 ops/training.py:65 2019-01-16 17:52:55.595666: step 4057, loss = 0.70615 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:52:56.581465 ops/training.py:65 2019-01-16 17:52:56.581381: step 4058, loss = 0.69086 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:52:57.564556 ops/training.py:65 2019-01-16 17:52:57.564490: step 4059, loss = 0.70333 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:52:58.547144 ops/training.py:65 2019-01-16 17:52:58.547084: step 4060, loss = 0.70417 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:52:59.530509 ops/training.py:65 2019-01-16 17:52:59.530424: step 4061, loss = 0.69885 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:53:00.515425 ops/training.py:65 2019-01-16 17:53:00.515329: step 4062, loss = 0.69390 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:53:01.498353 ops/training.py:65 2019-01-16 17:53:01.498266: step 4063, loss = 0.70237 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:53:02.479956 ops/training.py:65 2019-01-16 17:53:02.479892: step 4064, loss = 0.69929 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:53:03.462769 ops/training.py:65 2019-01-16 17:53:03.462709: step 4065, loss = 0.69119 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:53:04.444622 ops/training.py:65 2019-01-16 17:53:04.444495: step 4066, loss = 0.70166 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:53:05.428275 ops/training.py:65 2019-01-16 17:53:05.428146: step 4067, loss = 0.69168 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:53:06.415484 ops/training.py:65 2019-01-16 17:53:06.415377: step 4068, loss = 0.69853 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:53:07.398971 ops/training.py:65 2019-01-16 17:53:07.398857: step 4069, loss = 0.70058 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:53:08.382370 ops/training.py:65 2019-01-16 17:53:08.382260: step 4070, loss = 0.68977 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:53:09.368214 ops/training.py:65 2019-01-16 17:53:09.368092: step 4071, loss = 0.70327 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:53:10.354112 ops/training.py:65 2019-01-16 17:53:10.354044: step 4072, loss = 0.68686 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:53:11.337797 ops/training.py:65 2019-01-16 17:53:11.337656: step 4073, loss = 0.69610 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:53:12.325653 ops/training.py:65 2019-01-16 17:53:12.325544: step 4074, loss = 0.69577 (32.4 examples/sec; 0.986 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:53:13.310493 ops/training.py:65 2019-01-16 17:53:13.310409: step 4075, loss = 0.69075 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:53:14.293286 ops/training.py:65 2019-01-16 17:53:14.293183: step 4076, loss = 0.69681 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:53:15.276977 ops/training.py:65 2019-01-16 17:53:15.276892: step 4077, loss = 0.69113 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:53:16.261251 ops/training.py:65 2019-01-16 17:53:16.261145: step 4078, loss = 0.69237 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:53:17.247100 ops/training.py:65 2019-01-16 17:53:17.246991: step 4079, loss = 0.69474 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:53:18.231606 ops/training.py:65 2019-01-16 17:53:18.231495: step 4080, loss = 0.69993 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:53:19.214944 ops/training.py:65 2019-01-16 17:53:19.214816: step 4081, loss = 0.68633 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:53:20.196888 ops/training.py:65 2019-01-16 17:53:20.196807: step 4082, loss = 0.70378 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 17:53:21.180737 ops/training.py:65 2019-01-16 17:53:21.180672: step 4083, loss = 0.69157 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:53:22.162589 ops/training.py:65 2019-01-16 17:53:22.162492: step 4084, loss = 0.69001 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:53:23.148859 ops/training.py:65 2019-01-16 17:53:23.148750: step 4085, loss = 0.68045 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:53:24.133924 ops/training.py:65 2019-01-16 17:53:24.133822: step 4086, loss = 0.69883 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:53:25.117678 ops/training.py:65 2019-01-16 17:53:25.117551: step 4087, loss = 0.70237 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:53:26.101046 ops/training.py:65 2019-01-16 17:53:26.100955: step 4088, loss = 0.69332 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:53:27.084775 ops/training.py:65 2019-01-16 17:53:27.084689: step 4089, loss = 0.70550 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:53:28.066587 ops/training.py:65 2019-01-16 17:53:28.066530: step 4090, loss = 0.70396 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:53:29.049162 ops/training.py:65 2019-01-16 17:53:29.049089: step 4091, loss = 0.69576 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:53:30.031824 ops/training.py:65 2019-01-16 17:53:30.031784: step 4092, loss = 0.68352 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:53:31.013182 ops/training.py:65 2019-01-16 17:53:31.013144: step 4093, loss = 0.70514 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:53:31.994486 ops/training.py:65 2019-01-16 17:53:31.994448: step 4094, loss = 0.69336 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:53:32.976840 ops/training.py:65 2019-01-16 17:53:32.976803: step 4095, loss = 0.68628 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:53:33.958526 ops/training.py:65 2019-01-16 17:53:33.958483: step 4096, loss = 0.69961 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.25
I8192 2019-01-16 17:53:34.943519 ops/training.py:65 2019-01-16 17:53:34.943444: step 4097, loss = 0.70159 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:53:35.926415 ops/training.py:65 2019-01-16 17:53:35.926363: step 4098, loss = 0.69298 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:53:36.909830 ops/training.py:65 2019-01-16 17:53:36.909776: step 4099, loss = 0.68692 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:53:37.892278 ops/training.py:65 2019-01-16 17:53:37.892239: step 4100, loss = 0.69114 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:53:38.873931 ops/training.py:65 2019-01-16 17:53:38.873892: step 4101, loss = 0.69590 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:53:39.855618 ops/training.py:65 2019-01-16 17:53:39.855577: step 4102, loss = 0.69859 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:53:40.837901 ops/training.py:65 2019-01-16 17:53:40.837865: step 4103, loss = 0.70430 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:53:41.819670 ops/training.py:65 2019-01-16 17:53:41.819633: step 4104, loss = 0.70031 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:53:42.803092 ops/training.py:65 2019-01-16 17:53:42.803046: step 4105, loss = 0.69160 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:53:43.785657 ops/training.py:65 2019-01-16 17:53:43.785555: step 4106, loss = 0.69934 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:53:44.770599 ops/training.py:65 2019-01-16 17:53:44.770559: step 4107, loss = 0.68849 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:53:45.753051 ops/training.py:65 2019-01-16 17:53:45.753015: step 4108, loss = 0.68799 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:53:46.735319 ops/training.py:65 2019-01-16 17:53:46.735279: step 4109, loss = 0.68328 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:53:47.717599 ops/training.py:65 2019-01-16 17:53:47.717563: step 4110, loss = 0.68823 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:53:48.699665 ops/training.py:65 2019-01-16 17:53:48.699617: step 4111, loss = 0.67626 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:53:49.681362 ops/training.py:65 2019-01-16 17:53:49.681306: step 4112, loss = 0.70420 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:53:50.662926 ops/training.py:65 2019-01-16 17:53:50.662881: step 4113, loss = 0.69581 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:53:51.644281 ops/training.py:65 2019-01-16 17:53:51.644200: step 4114, loss = 0.71074 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:53:52.626391 ops/training.py:65 2019-01-16 17:53:52.626341: step 4115, loss = 0.68331 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:53:53.609645 ops/training.py:65 2019-01-16 17:53:53.609601: step 4116, loss = 0.70231 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:53:54.590473 ops/training.py:65 2019-01-16 17:53:54.590436: step 4117, loss = 0.69428 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:53:55.571700 ops/training.py:65 2019-01-16 17:53:55.571647: step 4118, loss = 0.67900 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:53:56.553702 ops/training.py:65 2019-01-16 17:53:56.553653: step 4119, loss = 0.67470 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.78125
I8192 2019-01-16 17:53:57.537255 ops/training.py:65 2019-01-16 17:53:57.537211: step 4120, loss = 0.68934 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:53:58.521835 ops/training.py:65 2019-01-16 17:53:58.521778: step 4121, loss = 0.69950 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:53:59.505642 ops/training.py:65 2019-01-16 17:53:59.505573: step 4122, loss = 0.67598 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:54:00.488871 ops/training.py:65 2019-01-16 17:54:00.488815: step 4123, loss = 0.69583 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:54:01.473072 ops/training.py:65 2019-01-16 17:54:01.473021: step 4124, loss = 0.69406 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:54:02.457042 ops/training.py:65 2019-01-16 17:54:02.457003: step 4125, loss = 0.69710 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:54:03.440549 ops/training.py:65 2019-01-16 17:54:03.440510: step 4126, loss = 0.68787 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:54:04.422280 ops/training.py:65 2019-01-16 17:54:04.422236: step 4127, loss = 0.68589 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:54:05.404894 ops/training.py:65 2019-01-16 17:54:05.404820: step 4128, loss = 0.69348 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:54:06.387658 ops/training.py:65 2019-01-16 17:54:06.387602: step 4129, loss = 0.68791 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:54:07.369097 ops/training.py:65 2019-01-16 17:54:07.369045: step 4130, loss = 0.69186 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:54:08.352174 ops/training.py:65 2019-01-16 17:54:08.352125: step 4131, loss = 0.67065 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 17:54:09.334746 ops/training.py:65 2019-01-16 17:54:09.334701: step 4132, loss = 0.68312 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:54:10.319908 ops/training.py:65 2019-01-16 17:54:10.319851: step 4133, loss = 0.68732 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:54:11.303711 ops/training.py:65 2019-01-16 17:54:11.303656: step 4134, loss = 0.69380 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:54:12.287217 ops/training.py:65 2019-01-16 17:54:12.287160: step 4135, loss = 0.69672 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:54:13.268800 ops/training.py:65 2019-01-16 17:54:13.268718: step 4136, loss = 0.70437 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:54:14.251190 ops/training.py:65 2019-01-16 17:54:14.251125: step 4137, loss = 0.68376 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:54:15.232677 ops/training.py:65 2019-01-16 17:54:15.232620: step 4138, loss = 0.68655 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:54:16.214657 ops/training.py:65 2019-01-16 17:54:16.214602: step 4139, loss = 0.67884 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:54:17.196870 ops/training.py:65 2019-01-16 17:54:17.196809: step 4140, loss = 0.68348 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:54:18.179219 ops/training.py:65 2019-01-16 17:54:18.179152: step 4141, loss = 0.68520 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:54:19.160550 ops/training.py:65 2019-01-16 17:54:19.160490: step 4142, loss = 0.68046 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:54:20.142092 ops/training.py:65 2019-01-16 17:54:20.142017: step 4143, loss = 0.71729 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:54:21.123108 ops/training.py:65 2019-01-16 17:54:21.123056: step 4144, loss = 0.72453 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:54:22.107212 ops/training.py:65 2019-01-16 17:54:22.107160: step 4145, loss = 0.69098 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:54:23.088547 ops/training.py:65 2019-01-16 17:54:23.088492: step 4146, loss = 0.71594 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:54:24.070817 ops/training.py:65 2019-01-16 17:54:24.070771: step 4147, loss = 0.68987 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:54:25.051847 ops/training.py:65 2019-01-16 17:54:25.051800: step 4148, loss = 0.69985 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:54:26.032397 ops/training.py:65 2019-01-16 17:54:26.032341: step 4149, loss = 0.70733 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:54:27.013275 ops/training.py:65 2019-01-16 17:54:27.013226: step 4150, loss = 0.65593 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:54:27.995353 ops/training.py:65 2019-01-16 17:54:27.995267: step 4151, loss = 0.70545 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:54:28.978031 ops/training.py:65 2019-01-16 17:54:28.977975: step 4152, loss = 0.68326 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:54:29.960217 ops/training.py:65 2019-01-16 17:54:29.960159: step 4153, loss = 0.71157 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:54:30.941445 ops/training.py:65 2019-01-16 17:54:30.941389: step 4154, loss = 0.68428 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:54:31.923265 ops/training.py:65 2019-01-16 17:54:31.923223: step 4155, loss = 0.69904 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:54:32.904855 ops/training.py:65 2019-01-16 17:54:32.904818: step 4156, loss = 0.69847 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:54:33.886603 ops/training.py:65 2019-01-16 17:54:33.886565: step 4157, loss = 0.70788 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:54:34.868107 ops/training.py:65 2019-01-16 17:54:34.868051: step 4158, loss = 0.72355 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:54:35.849615 ops/training.py:65 2019-01-16 17:54:35.849579: step 4159, loss = 0.68259 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:54:36.831637 ops/training.py:65 2019-01-16 17:54:36.831600: step 4160, loss = 0.70854 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:54:37.813510 ops/training.py:65 2019-01-16 17:54:37.813473: step 4161, loss = 0.66136 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:54:38.796803 ops/training.py:65 2019-01-16 17:54:38.796764: step 4162, loss = 0.69830 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:54:39.781235 ops/training.py:65 2019-01-16 17:54:39.781186: step 4163, loss = 0.69912 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:54:40.764118 ops/training.py:65 2019-01-16 17:54:40.764068: step 4164, loss = 0.74155 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:54:41.745673 ops/training.py:65 2019-01-16 17:54:41.745627: step 4165, loss = 0.68677 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:54:42.727715 ops/training.py:65 2019-01-16 17:54:42.727633: step 4166, loss = 0.72845 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:54:43.709679 ops/training.py:65 2019-01-16 17:54:43.709618: step 4167, loss = 0.70608 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:54:44.691659 ops/training.py:65 2019-01-16 17:54:44.691592: step 4168, loss = 0.71748 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:54:45.673186 ops/training.py:65 2019-01-16 17:54:45.673127: step 4169, loss = 0.69302 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:54:46.655210 ops/training.py:65 2019-01-16 17:54:46.655158: step 4170, loss = 0.69997 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:54:47.637346 ops/training.py:65 2019-01-16 17:54:47.637290: step 4171, loss = 0.70426 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:54:48.618805 ops/training.py:65 2019-01-16 17:54:48.618750: step 4172, loss = 0.68518 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:54:49.600363 ops/training.py:65 2019-01-16 17:54:49.600279: step 4173, loss = 0.68077 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:54:50.582121 ops/training.py:65 2019-01-16 17:54:50.582063: step 4174, loss = 0.68882 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:54:51.563861 ops/training.py:65 2019-01-16 17:54:51.563796: step 4175, loss = 0.71832 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:54:52.545912 ops/training.py:65 2019-01-16 17:54:52.545851: step 4176, loss = 0.69312 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:54:53.527661 ops/training.py:65 2019-01-16 17:54:53.527612: step 4177, loss = 0.68236 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:54:54.509120 ops/training.py:65 2019-01-16 17:54:54.509078: step 4178, loss = 0.69516 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:54:55.491120 ops/training.py:65 2019-01-16 17:54:55.491081: step 4179, loss = 0.70469 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:54:56.472803 ops/training.py:65 2019-01-16 17:54:56.472767: step 4180, loss = 0.70161 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:54:57.454762 ops/training.py:65 2019-01-16 17:54:57.454719: step 4181, loss = 0.70098 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:54:58.436535 ops/training.py:65 2019-01-16 17:54:58.436500: step 4182, loss = 0.65201 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.78125
I8192 2019-01-16 17:54:59.418082 ops/training.py:65 2019-01-16 17:54:59.418046: step 4183, loss = 0.69788 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:55:00.399528 ops/training.py:65 2019-01-16 17:55:00.399481: step 4184, loss = 0.69521 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:55:01.381544 ops/training.py:65 2019-01-16 17:55:01.381501: step 4185, loss = 0.67373 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:55:02.363253 ops/training.py:65 2019-01-16 17:55:02.363203: step 4186, loss = 0.69855 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:55:03.345193 ops/training.py:65 2019-01-16 17:55:03.345147: step 4187, loss = 0.72909 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:55:04.328006 ops/training.py:65 2019-01-16 17:55:04.327915: step 4188, loss = 0.69413 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:55:05.310890 ops/training.py:65 2019-01-16 17:55:05.310830: step 4189, loss = 0.67741 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:55:06.293384 ops/training.py:65 2019-01-16 17:55:06.293337: step 4190, loss = 0.69969 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:55:07.275826 ops/training.py:65 2019-01-16 17:55:07.275781: step 4191, loss = 0.70347 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:55:08.257970 ops/training.py:65 2019-01-16 17:55:08.257933: step 4192, loss = 0.68844 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:55:09.241564 ops/training.py:65 2019-01-16 17:55:09.241506: step 4193, loss = 0.68942 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:55:10.222613 ops/training.py:65 2019-01-16 17:55:10.222557: step 4194, loss = 0.67731 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:55:11.204187 ops/training.py:65 2019-01-16 17:55:11.204116: step 4195, loss = 0.69116 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:55:12.185698 ops/training.py:65 2019-01-16 17:55:12.185623: step 4196, loss = 0.69945 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:55:13.168491 ops/training.py:65 2019-01-16 17:55:13.168426: step 4197, loss = 0.70886 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:55:14.152938 ops/training.py:65 2019-01-16 17:55:14.152880: step 4198, loss = 0.69057 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:55:15.137129 ops/training.py:65 2019-01-16 17:55:15.137048: step 4199, loss = 0.69634 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:55:16.120560 ops/training.py:65 2019-01-16 17:55:16.120433: step 4200, loss = 0.70783 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:55:17.103927 ops/training.py:65 2019-01-16 17:55:17.103828: step 4201, loss = 0.68463 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:55:18.086309 ops/training.py:65 2019-01-16 17:55:18.086199: step 4202, loss = 0.68761 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:55:19.071775 ops/training.py:65 2019-01-16 17:55:19.071694: step 4203, loss = 0.70547 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:55:20.056679 ops/training.py:65 2019-01-16 17:55:20.056596: step 4204, loss = 0.69575 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:55:21.041040 ops/training.py:65 2019-01-16 17:55:21.040946: step 4205, loss = 0.68769 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:55:22.022731 ops/training.py:65 2019-01-16 17:55:22.022626: step 4206, loss = 0.69570 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:55:23.005429 ops/training.py:65 2019-01-16 17:55:23.005330: step 4207, loss = 0.67722 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:55:23.987695 ops/training.py:65 2019-01-16 17:55:23.987591: step 4208, loss = 0.65467 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.78125
I8192 2019-01-16 17:55:24.970515 ops/training.py:65 2019-01-16 17:55:24.970417: step 4209, loss = 0.70109 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:55:25.952618 ops/training.py:65 2019-01-16 17:55:25.952508: step 4210, loss = 0.68475 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:55:26.934431 ops/training.py:65 2019-01-16 17:55:26.934328: step 4211, loss = 0.68503 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:55:27.916498 ops/training.py:65 2019-01-16 17:55:27.916388: step 4212, loss = 0.70532 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:55:28.898960 ops/training.py:65 2019-01-16 17:55:28.898844: step 4213, loss = 0.67125 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:55:29.882118 ops/training.py:65 2019-01-16 17:55:29.882019: step 4214, loss = 0.66124 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:55:30.865582 ops/training.py:65 2019-01-16 17:55:30.865481: step 4215, loss = 0.69651 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:55:31.848584 ops/training.py:65 2019-01-16 17:55:31.848482: step 4216, loss = 0.70314 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:55:32.831664 ops/training.py:65 2019-01-16 17:55:32.831557: step 4217, loss = 0.70935 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:55:33.813306 ops/training.py:65 2019-01-16 17:55:33.813182: step 4218, loss = 0.71117 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:55:34.795592 ops/training.py:65 2019-01-16 17:55:34.795470: step 4219, loss = 0.70700 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:55:35.777956 ops/training.py:65 2019-01-16 17:55:35.777847: step 4220, loss = 0.68905 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:55:36.760382 ops/training.py:65 2019-01-16 17:55:36.760275: step 4221, loss = 0.70792 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:55:37.743341 ops/training.py:65 2019-01-16 17:55:37.743252: step 4222, loss = 0.70500 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:55:38.729322 ops/training.py:65 2019-01-16 17:55:38.729220: step 4223, loss = 0.70988 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:55:39.714173 ops/training.py:65 2019-01-16 17:55:39.714066: step 4224, loss = 0.70090 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:55:40.698196 ops/training.py:65 2019-01-16 17:55:40.698093: step 4225, loss = 0.67502 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:55:41.681929 ops/training.py:65 2019-01-16 17:55:41.681826: step 4226, loss = 0.71605 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:55:42.664515 ops/training.py:65 2019-01-16 17:55:42.664412: step 4227, loss = 0.71002 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:55:43.647553 ops/training.py:65 2019-01-16 17:55:43.647445: step 4228, loss = 0.70342 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:55:44.630669 ops/training.py:65 2019-01-16 17:55:44.630562: step 4229, loss = 0.67965 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:55:45.612322 ops/training.py:65 2019-01-16 17:55:45.612212: step 4230, loss = 0.69639 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:55:46.593719 ops/training.py:65 2019-01-16 17:55:46.593602: step 4231, loss = 0.70793 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:55:47.576322 ops/training.py:65 2019-01-16 17:55:47.576233: step 4232, loss = 0.70751 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:55:48.559944 ops/training.py:65 2019-01-16 17:55:48.559823: step 4233, loss = 0.69039 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:55:49.542205 ops/training.py:65 2019-01-16 17:55:49.542080: step 4234, loss = 0.71427 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:55:50.524890 ops/training.py:65 2019-01-16 17:55:50.524788: step 4235, loss = 0.67162 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:55:51.507988 ops/training.py:65 2019-01-16 17:55:51.507877: step 4236, loss = 0.70421 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:55:52.489423 ops/training.py:65 2019-01-16 17:55:52.489329: step 4237, loss = 0.69236 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:55:53.471093 ops/training.py:65 2019-01-16 17:55:53.470990: step 4238, loss = 0.69304 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:55:54.454288 ops/training.py:65 2019-01-16 17:55:54.454174: step 4239, loss = 0.68842 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:55:55.438015 ops/training.py:65 2019-01-16 17:55:55.437892: step 4240, loss = 0.69606 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:55:56.420240 ops/training.py:65 2019-01-16 17:55:56.420102: step 4241, loss = 0.69963 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:55:57.403956 ops/training.py:65 2019-01-16 17:55:57.403851: step 4242, loss = 0.69859 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:55:58.390342 ops/training.py:65 2019-01-16 17:55:58.390240: step 4243, loss = 0.68188 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:55:59.376076 ops/training.py:65 2019-01-16 17:55:59.375967: step 4244, loss = 0.69416 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:56:00.360987 ops/training.py:65 2019-01-16 17:56:00.360883: step 4245, loss = 0.67696 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:56:01.343125 ops/training.py:65 2019-01-16 17:56:01.343031: step 4246, loss = 0.69239 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:56:02.325301 ops/training.py:65 2019-01-16 17:56:02.325211: step 4247, loss = 0.70963 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:56:03.307593 ops/training.py:65 2019-01-16 17:56:03.307492: step 4248, loss = 0.70831 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:56:04.295372 ops/training.py:65 2019-01-16 17:56:04.295275: step 4249, loss = 0.69093 (32.4 examples/sec; 0.987 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:56:05.281725 ops/training.py:65 2019-01-16 17:56:05.281615: step 4250, loss = 0.68668 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:56:06.265113 ops/training.py:65 2019-01-16 17:56:06.265036: step 4251, loss = 0.70379 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:56:07.248562 ops/training.py:65 2019-01-16 17:56:07.248480: step 4252, loss = 0.70314 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:56:08.231226 ops/training.py:65 2019-01-16 17:56:08.231132: step 4253, loss = 0.69678 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:56:09.213389 ops/training.py:65 2019-01-16 17:56:09.213269: step 4254, loss = 0.68830 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:56:10.195873 ops/training.py:65 2019-01-16 17:56:10.195756: step 4255, loss = 0.70337 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:56:11.177831 ops/training.py:65 2019-01-16 17:56:11.177722: step 4256, loss = 0.69015 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:56:12.159326 ops/training.py:65 2019-01-16 17:56:12.159221: step 4257, loss = 0.69243 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:56:13.141360 ops/training.py:65 2019-01-16 17:56:13.141252: step 4258, loss = 0.68610 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:56:14.124147 ops/training.py:65 2019-01-16 17:56:14.124040: step 4259, loss = 0.69963 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:56:15.105556 ops/training.py:65 2019-01-16 17:56:15.105431: step 4260, loss = 0.70247 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:56:16.088600 ops/training.py:65 2019-01-16 17:56:16.088477: step 4261, loss = 0.67824 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:56:17.071736 ops/training.py:65 2019-01-16 17:56:17.071631: step 4262, loss = 0.68574 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:56:18.052996 ops/training.py:65 2019-01-16 17:56:18.052889: step 4263, loss = 0.70280 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:56:19.034492 ops/training.py:65 2019-01-16 17:56:19.034385: step 4264, loss = 0.70655 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 17:56:20.016166 ops/training.py:65 2019-01-16 17:56:20.016060: step 4265, loss = 0.69730 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:56:20.998662 ops/training.py:65 2019-01-16 17:56:20.998542: step 4266, loss = 0.70103 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:56:21.982275 ops/training.py:65 2019-01-16 17:56:21.982170: step 4267, loss = 0.68159 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:56:22.964397 ops/training.py:65 2019-01-16 17:56:22.964297: step 4268, loss = 0.69585 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:56:23.947082 ops/training.py:65 2019-01-16 17:56:23.946933: step 4269, loss = 0.68511 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:56:24.929977 ops/training.py:65 2019-01-16 17:56:24.929820: step 4270, loss = 0.70431 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:56:25.913838 ops/training.py:65 2019-01-16 17:56:25.913683: step 4271, loss = 0.72168 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 17:56:26.896366 ops/training.py:65 2019-01-16 17:56:26.896265: step 4272, loss = 0.68180 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:56:27.878926 ops/training.py:65 2019-01-16 17:56:27.878818: step 4273, loss = 0.69221 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:56:28.862624 ops/training.py:65 2019-01-16 17:56:28.862522: step 4274, loss = 0.68617 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:56:29.846550 ops/training.py:65 2019-01-16 17:56:29.846430: step 4275, loss = 0.70237 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:56:30.829880 ops/training.py:65 2019-01-16 17:56:30.829762: step 4276, loss = 0.68466 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:56:31.812132 ops/training.py:65 2019-01-16 17:56:31.812025: step 4277, loss = 0.69179 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:56:32.794555 ops/training.py:65 2019-01-16 17:56:32.794454: step 4278, loss = 0.68430 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:56:33.776361 ops/training.py:65 2019-01-16 17:56:33.776254: step 4279, loss = 0.70293 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:56:34.759285 ops/training.py:65 2019-01-16 17:56:34.759178: step 4280, loss = 0.68789 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:56:35.741984 ops/training.py:65 2019-01-16 17:56:35.741876: step 4281, loss = 0.68093 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:56:36.723783 ops/training.py:65 2019-01-16 17:56:36.723679: step 4282, loss = 0.69100 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:56:37.706746 ops/training.py:65 2019-01-16 17:56:37.706642: step 4283, loss = 0.70118 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:56:38.692727 ops/training.py:65 2019-01-16 17:56:38.692625: step 4284, loss = 0.68839 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:56:39.677314 ops/training.py:65 2019-01-16 17:56:39.677193: step 4285, loss = 0.67893 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:56:40.663473 ops/training.py:65 2019-01-16 17:56:40.663347: step 4286, loss = 0.68213 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:56:41.649264 ops/training.py:65 2019-01-16 17:56:41.649139: step 4287, loss = 0.68268 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:56:42.635662 ops/training.py:65 2019-01-16 17:56:42.635533: step 4288, loss = 0.69989 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:56:43.618620 ops/training.py:65 2019-01-16 17:56:43.618534: step 4289, loss = 0.68565 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:56:44.601708 ops/training.py:65 2019-01-16 17:56:44.601604: step 4290, loss = 0.69155 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:56:45.588738 ops/training.py:65 2019-01-16 17:56:45.588642: step 4291, loss = 0.71819 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:56:46.573670 ops/training.py:65 2019-01-16 17:56:46.573514: step 4292, loss = 0.68808 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:56:47.556929 ops/training.py:65 2019-01-16 17:56:47.556771: step 4293, loss = 0.70462 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:56:48.541285 ops/training.py:65 2019-01-16 17:56:48.541197: step 4294, loss = 0.70611 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:56:49.525837 ops/training.py:65 2019-01-16 17:56:49.525736: step 4295, loss = 0.68668 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:56:50.510477 ops/training.py:65 2019-01-16 17:56:50.510375: step 4296, loss = 0.71594 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:56:51.493176 ops/training.py:65 2019-01-16 17:56:51.493074: step 4297, loss = 0.69942 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:56:52.475341 ops/training.py:65 2019-01-16 17:56:52.475237: step 4298, loss = 0.69443 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:56:53.459271 ops/training.py:65 2019-01-16 17:56:53.459122: step 4299, loss = 0.65233 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 17:56:54.442265 ops/training.py:65 2019-01-16 17:56:54.442159: step 4300, loss = 0.70707 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:56:55.423835 ops/training.py:65 2019-01-16 17:56:55.423731: step 4301, loss = 0.69508 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:56:56.405212 ops/training.py:65 2019-01-16 17:56:56.405087: step 4302, loss = 0.67335 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:56:57.388828 ops/training.py:65 2019-01-16 17:56:57.388707: step 4303, loss = 0.69843 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:56:58.371428 ops/training.py:65 2019-01-16 17:56:58.371329: step 4304, loss = 0.72546 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:56:59.354326 ops/training.py:65 2019-01-16 17:56:59.354240: step 4305, loss = 0.69022 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:57:00.343051 ops/training.py:65 2019-01-16 17:57:00.342935: step 4306, loss = 0.69132 (32.4 examples/sec; 0.987 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:57:01.325857 ops/training.py:65 2019-01-16 17:57:01.325736: step 4307, loss = 0.69979 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:57:02.311040 ops/training.py:65 2019-01-16 17:57:02.310933: step 4308, loss = 0.69700 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:57:03.295042 ops/training.py:65 2019-01-16 17:57:03.294936: step 4309, loss = 0.68699 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:57:04.277491 ops/training.py:65 2019-01-16 17:57:04.277385: step 4310, loss = 0.68346 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:57:05.260794 ops/training.py:65 2019-01-16 17:57:05.260709: step 4311, loss = 0.69952 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:57:06.245931 ops/training.py:65 2019-01-16 17:57:06.245827: step 4312, loss = 0.69499 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:57:07.230318 ops/training.py:65 2019-01-16 17:57:07.230208: step 4313, loss = 0.67510 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:57:08.214161 ops/training.py:65 2019-01-16 17:57:08.214059: step 4314, loss = 0.69903 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:57:09.200250 ops/training.py:65 2019-01-16 17:57:09.200142: step 4315, loss = 0.71156 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:57:10.184934 ops/training.py:65 2019-01-16 17:57:10.184828: step 4316, loss = 0.69836 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:57:11.170596 ops/training.py:65 2019-01-16 17:57:11.170487: step 4317, loss = 0.70193 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:57:12.156943 ops/training.py:65 2019-01-16 17:57:12.156840: step 4318, loss = 0.70367 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:57:13.140699 ops/training.py:65 2019-01-16 17:57:13.140594: step 4319, loss = 0.69201 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:57:14.125665 ops/training.py:65 2019-01-16 17:57:14.125579: step 4320, loss = 0.68476 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:57:15.111004 ops/training.py:65 2019-01-16 17:57:15.110903: step 4321, loss = 0.71245 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:57:16.095016 ops/training.py:65 2019-01-16 17:57:16.094877: step 4322, loss = 0.69096 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:57:17.077738 ops/training.py:65 2019-01-16 17:57:17.077637: step 4323, loss = 0.69830 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:57:18.062002 ops/training.py:65 2019-01-16 17:57:18.061888: step 4324, loss = 0.70297 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:57:19.046590 ops/training.py:65 2019-01-16 17:57:19.046487: step 4325, loss = 0.68838 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:57:20.028874 ops/training.py:65 2019-01-16 17:57:20.028763: step 4326, loss = 0.69535 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:57:21.010001 ops/training.py:65 2019-01-16 17:57:21.009895: step 4327, loss = 0.70759 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:57:21.991366 ops/training.py:65 2019-01-16 17:57:21.991258: step 4328, loss = 0.70304 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:57:22.974843 ops/training.py:65 2019-01-16 17:57:22.974766: step 4329, loss = 0.67786 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:57:23.957905 ops/training.py:65 2019-01-16 17:57:23.957813: step 4330, loss = 0.70717 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:57:24.943735 ops/training.py:65 2019-01-16 17:57:24.943624: step 4331, loss = 0.68767 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:57:25.927075 ops/training.py:65 2019-01-16 17:57:25.926962: step 4332, loss = 0.67959 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:57:26.912053 ops/training.py:65 2019-01-16 17:57:26.911941: step 4333, loss = 0.69476 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:57:27.895128 ops/training.py:65 2019-01-16 17:57:27.895032: step 4334, loss = 0.68656 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:57:28.878424 ops/training.py:65 2019-01-16 17:57:28.878324: step 4335, loss = 0.69525 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:57:29.862599 ops/training.py:65 2019-01-16 17:57:29.862492: step 4336, loss = 0.68199 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:57:30.847018 ops/training.py:65 2019-01-16 17:57:30.846894: step 4337, loss = 0.67309 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:57:31.831187 ops/training.py:65 2019-01-16 17:57:31.831081: step 4338, loss = 0.69775 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:57:32.815015 ops/training.py:65 2019-01-16 17:57:32.814903: step 4339, loss = 0.71326 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:57:33.797415 ops/training.py:65 2019-01-16 17:57:33.797267: step 4340, loss = 0.69202 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:57:34.780445 ops/training.py:65 2019-01-16 17:57:34.780329: step 4341, loss = 0.71382 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:57:35.762905 ops/training.py:65 2019-01-16 17:57:35.762792: step 4342, loss = 0.68249 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:57:36.745309 ops/training.py:65 2019-01-16 17:57:36.745197: step 4343, loss = 0.70930 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:57:37.727946 ops/training.py:65 2019-01-16 17:57:37.727846: step 4344, loss = 0.72082 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:57:38.710349 ops/training.py:65 2019-01-16 17:57:38.710244: step 4345, loss = 0.70019 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:57:39.691792 ops/training.py:65 2019-01-16 17:57:39.691680: step 4346, loss = 0.67211 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:57:40.673654 ops/training.py:65 2019-01-16 17:57:40.673559: step 4347, loss = 0.69426 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:57:41.656837 ops/training.py:65 2019-01-16 17:57:41.656728: step 4348, loss = 0.69202 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:57:42.638443 ops/training.py:65 2019-01-16 17:57:42.638325: step 4349, loss = 0.69208 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:57:43.621084 ops/training.py:65 2019-01-16 17:57:43.620971: step 4350, loss = 0.71492 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:57:44.603781 ops/training.py:65 2019-01-16 17:57:44.603669: step 4351, loss = 0.68770 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:57:45.585126 ops/training.py:65 2019-01-16 17:57:45.585019: step 4352, loss = 0.71150 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:57:46.566639 ops/training.py:65 2019-01-16 17:57:46.566514: step 4353, loss = 0.70379 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:57:47.549047 ops/training.py:65 2019-01-16 17:57:47.548922: step 4354, loss = 0.70270 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:57:48.536701 ops/training.py:65 2019-01-16 17:57:48.536617: step 4355, loss = 0.70650 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:57:49.520256 ops/training.py:65 2019-01-16 17:57:49.520214: step 4356, loss = 0.69691 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:57:50.503936 ops/training.py:65 2019-01-16 17:57:50.503896: step 4357, loss = 0.70680 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:57:51.487955 ops/training.py:65 2019-01-16 17:57:51.487915: step 4358, loss = 0.68743 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:57:52.469707 ops/training.py:65 2019-01-16 17:57:52.469669: step 4359, loss = 0.69287 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:57:53.451161 ops/training.py:65 2019-01-16 17:57:53.451122: step 4360, loss = 0.69570 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:57:54.432815 ops/training.py:65 2019-01-16 17:57:54.432776: step 4361, loss = 0.69668 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:57:55.413953 ops/training.py:65 2019-01-16 17:57:55.413914: step 4362, loss = 0.68332 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:57:56.395877 ops/training.py:65 2019-01-16 17:57:56.395838: step 4363, loss = 0.69256 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:57:57.377754 ops/training.py:65 2019-01-16 17:57:57.377711: step 4364, loss = 0.68720 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:57:58.359247 ops/training.py:65 2019-01-16 17:57:58.359207: step 4365, loss = 0.68879 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:57:59.340229 ops/training.py:65 2019-01-16 17:57:59.340190: step 4366, loss = 0.68443 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:58:00.321399 ops/training.py:65 2019-01-16 17:58:00.321342: step 4367, loss = 0.70797 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:58:01.303449 ops/training.py:65 2019-01-16 17:58:01.303411: step 4368, loss = 0.70603 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:58:02.285113 ops/training.py:65 2019-01-16 17:58:02.285051: step 4369, loss = 0.68427 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:58:03.266904 ops/training.py:65 2019-01-16 17:58:03.266833: step 4370, loss = 0.67693 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:58:04.249750 ops/training.py:65 2019-01-16 17:58:04.249706: step 4371, loss = 0.67906 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:58:05.231509 ops/training.py:65 2019-01-16 17:58:05.231450: step 4372, loss = 0.67836 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:58:06.212728 ops/training.py:65 2019-01-16 17:58:06.212686: step 4373, loss = 0.68788 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:58:07.194110 ops/training.py:65 2019-01-16 17:58:07.194071: step 4374, loss = 0.69370 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:58:08.175645 ops/training.py:65 2019-01-16 17:58:08.175602: step 4375, loss = 0.70952 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:58:09.155865 ops/training.py:65 2019-01-16 17:58:09.155827: step 4376, loss = 0.69404 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:58:10.137544 ops/training.py:65 2019-01-16 17:58:10.137507: step 4377, loss = 0.68719 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:58:11.119796 ops/training.py:65 2019-01-16 17:58:11.119753: step 4378, loss = 0.69506 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:58:12.100629 ops/training.py:65 2019-01-16 17:58:12.100577: step 4379, loss = 0.68933 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:58:13.083404 ops/training.py:65 2019-01-16 17:58:13.083304: step 4380, loss = 0.69640 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:58:14.065353 ops/training.py:65 2019-01-16 17:58:14.065255: step 4381, loss = 0.68870 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:58:15.049094 ops/training.py:65 2019-01-16 17:58:15.049037: step 4382, loss = 0.68790 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:58:16.034853 ops/training.py:65 2019-01-16 17:58:16.034782: step 4383, loss = 0.70998 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:58:17.018575 ops/training.py:65 2019-01-16 17:58:17.018532: step 4384, loss = 0.69676 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:58:18.001456 ops/training.py:65 2019-01-16 17:58:18.001420: step 4385, loss = 0.70251 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:58:18.983744 ops/training.py:65 2019-01-16 17:58:18.983711: step 4386, loss = 0.69489 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:58:19.966842 ops/training.py:65 2019-01-16 17:58:19.966809: step 4387, loss = 0.68590 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:58:20.947906 ops/training.py:65 2019-01-16 17:58:20.947859: step 4388, loss = 0.69767 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:58:21.928792 ops/training.py:65 2019-01-16 17:58:21.928754: step 4389, loss = 0.68962 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:58:22.909480 ops/training.py:65 2019-01-16 17:58:22.909441: step 4390, loss = 0.71219 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:58:23.891071 ops/training.py:65 2019-01-16 17:58:23.891033: step 4391, loss = 0.71373 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:58:24.872071 ops/training.py:65 2019-01-16 17:58:24.872027: step 4392, loss = 0.71141 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:58:25.853700 ops/training.py:65 2019-01-16 17:58:25.853649: step 4393, loss = 0.71921 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 17:58:26.835414 ops/training.py:65 2019-01-16 17:58:26.835365: step 4394, loss = 0.70181 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:58:27.817075 ops/training.py:65 2019-01-16 17:58:27.817036: step 4395, loss = 0.70225 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:58:28.798924 ops/training.py:65 2019-01-16 17:58:28.798889: step 4396, loss = 0.69941 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:58:29.780481 ops/training.py:65 2019-01-16 17:58:29.780380: step 4397, loss = 0.68346 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:58:30.764530 ops/training.py:65 2019-01-16 17:58:30.764489: step 4398, loss = 0.69808 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:58:31.748240 ops/training.py:65 2019-01-16 17:58:31.748188: step 4399, loss = 0.70330 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:58:32.731114 ops/training.py:65 2019-01-16 17:58:32.731076: step 4400, loss = 0.68686 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:58:33.712248 ops/training.py:65 2019-01-16 17:58:33.712217: step 4401, loss = 0.70003 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:58:34.693606 ops/training.py:65 2019-01-16 17:58:34.693570: step 4402, loss = 0.69734 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:58:35.674810 ops/training.py:65 2019-01-16 17:58:35.674775: step 4403, loss = 0.68668 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:58:36.655838 ops/training.py:65 2019-01-16 17:58:36.655803: step 4404, loss = 0.70799 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:58:37.636939 ops/training.py:65 2019-01-16 17:58:37.636902: step 4405, loss = 0.68367 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:58:38.618202 ops/training.py:65 2019-01-16 17:58:38.618161: step 4406, loss = 0.69063 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:58:39.601146 ops/training.py:65 2019-01-16 17:58:39.601046: step 4407, loss = 0.69632 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:58:40.586215 ops/training.py:65 2019-01-16 17:58:40.586103: step 4408, loss = 0.68866 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:58:41.570007 ops/training.py:65 2019-01-16 17:58:41.569893: step 4409, loss = 0.70627 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:58:42.553824 ops/training.py:65 2019-01-16 17:58:42.553719: step 4410, loss = 0.68536 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:58:43.540020 ops/training.py:65 2019-01-16 17:58:43.539917: step 4411, loss = 0.68423 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:58:44.523703 ops/training.py:65 2019-01-16 17:58:44.523611: step 4412, loss = 0.69424 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:58:45.506096 ops/training.py:65 2019-01-16 17:58:45.506000: step 4413, loss = 0.69372 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:58:46.487380 ops/training.py:65 2019-01-16 17:58:46.487283: step 4414, loss = 0.69502 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:58:47.469777 ops/training.py:65 2019-01-16 17:58:47.469671: step 4415, loss = 0.68574 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:58:48.451511 ops/training.py:65 2019-01-16 17:58:48.451417: step 4416, loss = 0.68257 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:58:49.434285 ops/training.py:65 2019-01-16 17:58:49.434181: step 4417, loss = 0.68929 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:58:50.419247 ops/training.py:65 2019-01-16 17:58:50.419143: step 4418, loss = 0.71148 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:58:51.403994 ops/training.py:65 2019-01-16 17:58:51.403885: step 4419, loss = 0.71106 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:58:52.386858 ops/training.py:65 2019-01-16 17:58:52.386766: step 4420, loss = 0.69390 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:58:53.368159 ops/training.py:65 2019-01-16 17:58:53.368056: step 4421, loss = 0.70139 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:58:54.349179 ops/training.py:65 2019-01-16 17:58:54.349078: step 4422, loss = 0.69659 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:58:55.331551 ops/training.py:65 2019-01-16 17:58:55.331467: step 4423, loss = 0.72029 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:58:56.313950 ops/training.py:65 2019-01-16 17:58:56.313849: step 4424, loss = 0.69386 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:58:57.297192 ops/training.py:65 2019-01-16 17:58:57.297098: step 4425, loss = 0.68827 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:58:58.281640 ops/training.py:65 2019-01-16 17:58:58.281538: step 4426, loss = 0.70001 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:58:59.266897 ops/training.py:65 2019-01-16 17:58:59.266796: step 4427, loss = 0.70850 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 17:59:00.250181 ops/training.py:65 2019-01-16 17:59:00.250078: step 4428, loss = 0.69021 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:59:01.232086 ops/training.py:65 2019-01-16 17:59:01.231988: step 4429, loss = 0.70082 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:59:02.214470 ops/training.py:65 2019-01-16 17:59:02.214370: step 4430, loss = 0.69896 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:59:03.197467 ops/training.py:65 2019-01-16 17:59:03.197367: step 4431, loss = 0.69274 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:59:04.179292 ops/training.py:65 2019-01-16 17:59:04.179190: step 4432, loss = 0.69642 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:59:05.162481 ops/training.py:65 2019-01-16 17:59:05.162380: step 4433, loss = 0.68999 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:59:06.147795 ops/training.py:65 2019-01-16 17:59:06.147692: step 4434, loss = 0.69160 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 17:59:07.131528 ops/training.py:65 2019-01-16 17:59:07.131424: step 4435, loss = 0.70425 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 17:59:08.115117 ops/training.py:65 2019-01-16 17:59:08.115017: step 4436, loss = 0.70125 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:59:09.097719 ops/training.py:65 2019-01-16 17:59:09.097618: step 4437, loss = 0.68234 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:59:10.078916 ops/training.py:65 2019-01-16 17:59:10.078825: step 4438, loss = 0.70775 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:59:11.060848 ops/training.py:65 2019-01-16 17:59:11.060752: step 4439, loss = 0.69276 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:59:12.043732 ops/training.py:65 2019-01-16 17:59:12.043632: step 4440, loss = 0.69435 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:59:13.025929 ops/training.py:65 2019-01-16 17:59:13.025830: step 4441, loss = 0.68424 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:59:14.007655 ops/training.py:65 2019-01-16 17:59:14.007546: step 4442, loss = 0.69131 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:59:14.989034 ops/training.py:65 2019-01-16 17:59:14.988935: step 4443, loss = 0.68736 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:59:15.971054 ops/training.py:65 2019-01-16 17:59:15.970946: step 4444, loss = 0.69835 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:59:16.953337 ops/training.py:65 2019-01-16 17:59:16.953234: step 4445, loss = 0.70248 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:59:17.935237 ops/training.py:65 2019-01-16 17:59:17.935132: step 4446, loss = 0.69446 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:59:18.916852 ops/training.py:65 2019-01-16 17:59:18.916757: step 4447, loss = 0.69103 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:59:19.898166 ops/training.py:65 2019-01-16 17:59:19.898071: step 4448, loss = 0.69538 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:59:20.880789 ops/training.py:65 2019-01-16 17:59:20.880694: step 4449, loss = 0.67386 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:59:21.863634 ops/training.py:65 2019-01-16 17:59:21.863530: step 4450, loss = 0.67779 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:59:22.847824 ops/training.py:65 2019-01-16 17:59:22.847731: step 4451, loss = 0.68802 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:59:23.831737 ops/training.py:65 2019-01-16 17:59:23.831643: step 4452, loss = 0.70000 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:59:24.816786 ops/training.py:65 2019-01-16 17:59:24.816687: step 4453, loss = 0.70361 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:59:25.801445 ops/training.py:65 2019-01-16 17:59:25.801354: step 4454, loss = 0.69380 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:59:26.784785 ops/training.py:65 2019-01-16 17:59:26.784691: step 4455, loss = 0.70354 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 17:59:27.766772 ops/training.py:65 2019-01-16 17:59:27.766669: step 4456, loss = 0.68743 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:59:28.749628 ops/training.py:65 2019-01-16 17:59:28.749525: step 4457, loss = 0.70495 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:59:29.732155 ops/training.py:65 2019-01-16 17:59:29.732060: step 4458, loss = 0.70157 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:59:30.714290 ops/training.py:65 2019-01-16 17:59:30.714193: step 4459, loss = 0.68646 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:59:31.697298 ops/training.py:65 2019-01-16 17:59:31.697202: step 4460, loss = 0.69163 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:59:32.679539 ops/training.py:65 2019-01-16 17:59:32.679487: step 4461, loss = 0.69912 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:59:33.661820 ops/training.py:65 2019-01-16 17:59:33.661767: step 4462, loss = 0.69376 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:59:34.642025 ops/training.py:65 2019-01-16 17:59:34.641975: step 4463, loss = 0.69099 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:59:35.623734 ops/training.py:65 2019-01-16 17:59:35.623642: step 4464, loss = 0.66827 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 17:59:36.608834 ops/training.py:65 2019-01-16 17:59:36.608734: step 4465, loss = 0.68867 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:59:37.594592 ops/training.py:65 2019-01-16 17:59:37.594498: step 4466, loss = 0.71604 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:59:38.579047 ops/training.py:65 2019-01-16 17:59:38.578937: step 4467, loss = 0.68705 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:59:39.564237 ops/training.py:65 2019-01-16 17:59:39.564129: step 4468, loss = 0.71519 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:59:40.548229 ops/training.py:65 2019-01-16 17:59:40.548097: step 4469, loss = 0.70879 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:59:41.532935 ops/training.py:65 2019-01-16 17:59:41.532828: step 4470, loss = 0.73456 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 17:59:42.516547 ops/training.py:65 2019-01-16 17:59:42.516403: step 4471, loss = 0.69870 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:59:43.502378 ops/training.py:65 2019-01-16 17:59:43.502279: step 4472, loss = 0.70097 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:59:44.485458 ops/training.py:65 2019-01-16 17:59:44.485359: step 4473, loss = 0.70435 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 17:59:45.468152 ops/training.py:65 2019-01-16 17:59:45.468049: step 4474, loss = 0.70072 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:59:46.452588 ops/training.py:65 2019-01-16 17:59:46.452489: step 4475, loss = 0.72891 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:59:47.436208 ops/training.py:65 2019-01-16 17:59:47.436106: step 4476, loss = 0.65886 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 17:59:48.418574 ops/training.py:65 2019-01-16 17:59:48.418475: step 4477, loss = 0.69685 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:59:49.400428 ops/training.py:65 2019-01-16 17:59:49.400326: step 4478, loss = 0.68579 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 17:59:50.384420 ops/training.py:65 2019-01-16 17:59:50.384317: step 4479, loss = 0.70709 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:59:51.370059 ops/training.py:65 2019-01-16 17:59:51.369946: step 4480, loss = 0.68207 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:59:52.355005 ops/training.py:65 2019-01-16 17:59:52.354902: step 4481, loss = 0.68794 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 17:59:53.337730 ops/training.py:65 2019-01-16 17:59:53.337639: step 4482, loss = 0.70178 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:59:54.318619 ops/training.py:65 2019-01-16 17:59:54.318512: step 4483, loss = 0.69947 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:59:55.300323 ops/training.py:65 2019-01-16 17:59:55.300219: step 4484, loss = 0.71277 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 17:59:56.283128 ops/training.py:65 2019-01-16 17:59:56.283022: step 4485, loss = 0.71182 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 17:59:57.264507 ops/training.py:65 2019-01-16 17:59:57.264399: step 4486, loss = 0.70793 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 17:59:58.245654 ops/training.py:65 2019-01-16 17:59:58.245568: step 4487, loss = 0.68493 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 17:59:59.227074 ops/training.py:65 2019-01-16 17:59:59.226973: step 4488, loss = 0.66850 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:00:00.208144 ops/training.py:65 2019-01-16 18:00:00.208004: step 4489, loss = 0.67738 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:00:01.190946 ops/training.py:65 2019-01-16 18:00:01.190834: step 4490, loss = 0.71974 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:00:02.174165 ops/training.py:65 2019-01-16 18:00:02.174069: step 4491, loss = 0.67934 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:00:03.155590 ops/training.py:65 2019-01-16 18:00:03.155489: step 4492, loss = 0.67011 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:00:04.137404 ops/training.py:65 2019-01-16 18:00:04.137306: step 4493, loss = 0.70980 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:00:05.120797 ops/training.py:65 2019-01-16 18:00:05.120695: step 4494, loss = 0.72904 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:00:06.106454 ops/training.py:65 2019-01-16 18:00:06.106356: step 4495, loss = 0.73128 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:00:07.090022 ops/training.py:65 2019-01-16 18:00:07.089910: step 4496, loss = 0.70274 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:00:08.073337 ops/training.py:65 2019-01-16 18:00:08.073253: step 4497, loss = 0.70544 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:00:09.055487 ops/training.py:65 2019-01-16 18:00:09.055389: step 4498, loss = 0.68991 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:00:10.041507 ops/training.py:65 2019-01-16 18:00:10.041397: step 4499, loss = 0.69189 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:00:11.025925 ops/training.py:65 2019-01-16 18:00:11.025828: step 4500, loss = 0.69341 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:00:12.008492 ops/training.py:65 2019-01-16 18:00:12.008385: step 4501, loss = 0.71082 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:00:12.991913 ops/training.py:65 2019-01-16 18:00:12.991803: step 4502, loss = 0.69348 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:00:13.977079 ops/training.py:65 2019-01-16 18:00:13.976978: step 4503, loss = 0.69680 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:00:14.961411 ops/training.py:65 2019-01-16 18:00:14.961303: step 4504, loss = 0.69692 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:00:15.946565 ops/training.py:65 2019-01-16 18:00:15.946460: step 4505, loss = 0.69345 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:00:16.930002 ops/training.py:65 2019-01-16 18:00:16.929894: step 4506, loss = 0.69798 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:00:17.911938 ops/training.py:65 2019-01-16 18:00:17.911824: step 4507, loss = 0.68701 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:00:18.894443 ops/training.py:65 2019-01-16 18:00:18.894299: step 4508, loss = 0.72377 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 18:00:19.877209 ops/training.py:65 2019-01-16 18:00:19.877108: step 4509, loss = 0.70288 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:00:20.859107 ops/training.py:65 2019-01-16 18:00:20.859000: step 4510, loss = 0.70949 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:00:21.840235 ops/training.py:65 2019-01-16 18:00:21.840133: step 4511, loss = 0.70333 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:00:22.823307 ops/training.py:65 2019-01-16 18:00:22.823211: step 4512, loss = 0.68074 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:00:23.805122 ops/training.py:65 2019-01-16 18:00:23.805025: step 4513, loss = 0.68853 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:00:24.787167 ops/training.py:65 2019-01-16 18:00:24.787061: step 4514, loss = 0.67877 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:00:25.768874 ops/training.py:65 2019-01-16 18:00:25.768773: step 4515, loss = 0.70742 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:00:26.750152 ops/training.py:65 2019-01-16 18:00:26.750067: step 4516, loss = 0.70706 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:00:27.731691 ops/training.py:65 2019-01-16 18:00:27.731593: step 4517, loss = 0.69684 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:00:28.713057 ops/training.py:65 2019-01-16 18:00:28.712960: step 4518, loss = 0.69573 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:00:29.697101 ops/training.py:65 2019-01-16 18:00:29.697004: step 4519, loss = 0.72051 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:00:30.678566 ops/training.py:65 2019-01-16 18:00:30.678469: step 4520, loss = 0.69203 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:00:31.661835 ops/training.py:65 2019-01-16 18:00:31.661725: step 4521, loss = 0.71827 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:00:32.644083 ops/training.py:65 2019-01-16 18:00:32.643977: step 4522, loss = 0.72709 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:00:33.626206 ops/training.py:65 2019-01-16 18:00:33.626110: step 4523, loss = 0.68609 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:00:34.609035 ops/training.py:65 2019-01-16 18:00:34.608933: step 4524, loss = 0.73449 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 18:00:35.591751 ops/training.py:65 2019-01-16 18:00:35.591644: step 4525, loss = 0.73281 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:00:36.575644 ops/training.py:65 2019-01-16 18:00:36.575534: step 4526, loss = 0.73020 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:00:37.556723 ops/training.py:65 2019-01-16 18:00:37.556632: step 4527, loss = 0.69699 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:00:38.538266 ops/training.py:65 2019-01-16 18:00:38.538154: step 4528, loss = 0.69712 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:00:39.521317 ops/training.py:65 2019-01-16 18:00:39.521213: step 4529, loss = 0.72099 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:00:40.504006 ops/training.py:65 2019-01-16 18:00:40.503904: step 4530, loss = 0.65411 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:00:41.486577 ops/training.py:65 2019-01-16 18:00:41.486477: step 4531, loss = 0.71540 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:00:42.470343 ops/training.py:65 2019-01-16 18:00:42.470240: step 4532, loss = 0.70050 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:00:43.452845 ops/training.py:65 2019-01-16 18:00:43.452746: step 4533, loss = 0.74763 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:00:44.437538 ops/training.py:65 2019-01-16 18:00:44.437440: step 4534, loss = 0.71077 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:00:45.421496 ops/training.py:65 2019-01-16 18:00:45.421391: step 4535, loss = 0.70473 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:00:46.405162 ops/training.py:65 2019-01-16 18:00:46.405061: step 4536, loss = 0.70350 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:00:47.388622 ops/training.py:65 2019-01-16 18:00:47.388516: step 4537, loss = 0.71177 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:00:48.370529 ops/training.py:65 2019-01-16 18:00:48.370428: step 4538, loss = 0.66549 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:00:49.354040 ops/training.py:65 2019-01-16 18:00:49.353936: step 4539, loss = 0.69407 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:00:50.340198 ops/training.py:65 2019-01-16 18:00:50.340117: step 4540, loss = 0.67204 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:00:51.324721 ops/training.py:65 2019-01-16 18:00:51.324625: step 4541, loss = 0.70674 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:00:52.307989 ops/training.py:65 2019-01-16 18:00:52.307895: step 4542, loss = 0.70217 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:00:53.289864 ops/training.py:65 2019-01-16 18:00:53.289770: step 4543, loss = 0.71033 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:00:54.272295 ops/training.py:65 2019-01-16 18:00:54.272190: step 4544, loss = 0.71136 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:00:55.255276 ops/training.py:65 2019-01-16 18:00:55.255173: step 4545, loss = 0.71178 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:00:56.236765 ops/training.py:65 2019-01-16 18:00:56.236658: step 4546, loss = 0.69227 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:00:57.218719 ops/training.py:65 2019-01-16 18:00:57.218616: step 4547, loss = 0.67744 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:00:58.200644 ops/training.py:65 2019-01-16 18:00:58.200561: step 4548, loss = 0.70162 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:00:59.182821 ops/training.py:65 2019-01-16 18:00:59.182714: step 4549, loss = 0.67544 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:01:00.165300 ops/training.py:65 2019-01-16 18:01:00.165200: step 4550, loss = 0.68111 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:01:01.147890 ops/training.py:65 2019-01-16 18:01:01.147790: step 4551, loss = 0.69057 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:01:02.129827 ops/training.py:65 2019-01-16 18:01:02.129741: step 4552, loss = 0.69492 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:01:03.112295 ops/training.py:65 2019-01-16 18:01:03.112184: step 4553, loss = 0.68979 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:01:04.094137 ops/training.py:65 2019-01-16 18:01:04.094038: step 4554, loss = 0.68612 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:01:05.075696 ops/training.py:65 2019-01-16 18:01:05.075594: step 4555, loss = 0.69977 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:01:06.057528 ops/training.py:65 2019-01-16 18:01:06.057392: step 4556, loss = 0.70443 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:01:07.039476 ops/training.py:65 2019-01-16 18:01:07.039333: step 4557, loss = 0.68674 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:01:08.021845 ops/training.py:65 2019-01-16 18:01:08.021746: step 4558, loss = 0.69371 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:01:09.004740 ops/training.py:65 2019-01-16 18:01:09.004600: step 4559, loss = 0.70587 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:01:09.988120 ops/training.py:65 2019-01-16 18:01:09.988019: step 4560, loss = 0.69005 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:01:10.973252 ops/training.py:65 2019-01-16 18:01:10.973156: step 4561, loss = 0.67116 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:01:11.957637 ops/training.py:65 2019-01-16 18:01:11.957531: step 4562, loss = 0.68134 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:01:12.943775 ops/training.py:65 2019-01-16 18:01:12.943669: step 4563, loss = 0.68970 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:01:13.928221 ops/training.py:65 2019-01-16 18:01:13.928095: step 4564, loss = 0.68976 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:01:14.913415 ops/training.py:65 2019-01-16 18:01:14.913267: step 4565, loss = 0.69780 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:01:15.898543 ops/training.py:65 2019-01-16 18:01:15.898442: step 4566, loss = 0.69130 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:01:16.881257 ops/training.py:65 2019-01-16 18:01:16.881155: step 4567, loss = 0.69781 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:01:17.865274 ops/training.py:65 2019-01-16 18:01:17.865165: step 4568, loss = 0.70648 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:01:18.851844 ops/training.py:65 2019-01-16 18:01:18.851742: step 4569, loss = 0.71356 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:01:19.836018 ops/training.py:65 2019-01-16 18:01:19.835935: step 4570, loss = 0.70468 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:01:20.820395 ops/training.py:65 2019-01-16 18:01:20.820290: step 4571, loss = 0.70998 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:01:21.802529 ops/training.py:65 2019-01-16 18:01:21.802434: step 4572, loss = 0.68729 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:01:22.785349 ops/training.py:65 2019-01-16 18:01:22.785255: step 4573, loss = 0.71461 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:01:23.770357 ops/training.py:65 2019-01-16 18:01:23.770258: step 4574, loss = 0.68472 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:01:24.755962 ops/training.py:65 2019-01-16 18:01:24.755857: step 4575, loss = 0.67695 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:01:25.739927 ops/training.py:65 2019-01-16 18:01:25.739790: step 4576, loss = 0.69415 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:01:26.723303 ops/training.py:65 2019-01-16 18:01:26.723198: step 4577, loss = 0.71409 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:01:27.708079 ops/training.py:65 2019-01-16 18:01:27.707974: step 4578, loss = 0.71398 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:01:28.693147 ops/training.py:65 2019-01-16 18:01:28.693047: step 4579, loss = 0.68231 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:01:29.677521 ops/training.py:65 2019-01-16 18:01:29.677425: step 4580, loss = 0.67384 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:01:30.660242 ops/training.py:65 2019-01-16 18:01:30.660141: step 4581, loss = 0.69217 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:01:31.641883 ops/training.py:65 2019-01-16 18:01:31.641778: step 4582, loss = 0.69253 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:01:32.623330 ops/training.py:65 2019-01-16 18:01:32.623225: step 4583, loss = 0.69134 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:01:33.604427 ops/training.py:65 2019-01-16 18:01:33.604323: step 4584, loss = 0.70878 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:01:34.589940 ops/training.py:65 2019-01-16 18:01:34.589846: step 4585, loss = 0.69932 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:01:35.573152 ops/training.py:65 2019-01-16 18:01:35.573050: step 4586, loss = 0.70270 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:01:36.557040 ops/training.py:65 2019-01-16 18:01:36.556942: step 4587, loss = 0.67656 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:01:37.539078 ops/training.py:65 2019-01-16 18:01:37.538997: step 4588, loss = 0.69326 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:01:38.522125 ops/training.py:65 2019-01-16 18:01:38.522047: step 4589, loss = 0.65513 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:01:39.505744 ops/training.py:65 2019-01-16 18:01:39.505669: step 4590, loss = 0.69023 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:01:40.490003 ops/training.py:65 2019-01-16 18:01:40.489891: step 4591, loss = 0.69759 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:01:41.475723 ops/training.py:65 2019-01-16 18:01:41.475623: step 4592, loss = 0.68496 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:01:42.459885 ops/training.py:65 2019-01-16 18:01:42.459782: step 4593, loss = 0.69161 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:01:43.444722 ops/training.py:65 2019-01-16 18:01:43.444620: step 4594, loss = 0.67045 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:01:44.427497 ops/training.py:65 2019-01-16 18:01:44.427388: step 4595, loss = 0.69750 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:01:45.408396 ops/training.py:65 2019-01-16 18:01:45.408285: step 4596, loss = 0.69167 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:01:46.391764 ops/training.py:65 2019-01-16 18:01:46.391616: step 4597, loss = 0.70354 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:01:47.378428 ops/training.py:65 2019-01-16 18:01:47.378320: step 4598, loss = 0.70245 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:01:48.364968 ops/training.py:65 2019-01-16 18:01:48.364866: step 4599, loss = 0.70249 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:01:49.348091 ops/training.py:65 2019-01-16 18:01:49.347948: step 4600, loss = 0.68741 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:01:50.334450 ops/training.py:65 2019-01-16 18:01:50.334306: step 4601, loss = 0.68218 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:01:51.318765 ops/training.py:65 2019-01-16 18:01:51.318653: step 4602, loss = 0.68970 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:01:52.303156 ops/training.py:65 2019-01-16 18:01:52.303065: step 4603, loss = 0.67489 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.78125
I8192 2019-01-16 18:01:53.285843 ops/training.py:65 2019-01-16 18:01:53.285747: step 4604, loss = 0.69385 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:01:54.266969 ops/training.py:65 2019-01-16 18:01:54.266899: step 4605, loss = 0.70071 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:01:55.247719 ops/training.py:65 2019-01-16 18:01:55.247636: step 4606, loss = 0.68227 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:01:56.230321 ops/training.py:65 2019-01-16 18:01:56.230215: step 4607, loss = 0.68406 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:01:57.213713 ops/training.py:65 2019-01-16 18:01:57.213615: step 4608, loss = 0.67693 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:01:58.199300 ops/training.py:65 2019-01-16 18:01:58.199194: step 4609, loss = 0.71070 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:01:59.182709 ops/training.py:65 2019-01-16 18:01:59.182600: step 4610, loss = 0.67200 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:02:00.164202 ops/training.py:65 2019-01-16 18:02:00.164101: step 4611, loss = 0.70588 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:02:01.145992 ops/training.py:65 2019-01-16 18:02:01.145882: step 4612, loss = 0.68956 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:02:02.128196 ops/training.py:65 2019-01-16 18:02:02.128092: step 4613, loss = 0.70366 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:02:03.110442 ops/training.py:65 2019-01-16 18:02:03.110336: step 4614, loss = 0.70241 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:02:04.095739 ops/training.py:65 2019-01-16 18:02:04.095642: step 4615, loss = 0.69575 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:02:05.078801 ops/training.py:65 2019-01-16 18:02:05.078697: step 4616, loss = 0.67441 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:02:06.063649 ops/training.py:65 2019-01-16 18:02:06.063561: step 4617, loss = 0.69846 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:02:07.047307 ops/training.py:65 2019-01-16 18:02:07.047210: step 4618, loss = 0.71199 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:02:08.030378 ops/training.py:65 2019-01-16 18:02:08.030286: step 4619, loss = 0.68531 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:02:09.012943 ops/training.py:65 2019-01-16 18:02:09.012842: step 4620, loss = 0.67593 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:02:09.995838 ops/training.py:65 2019-01-16 18:02:09.995754: step 4621, loss = 0.68442 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:02:10.977660 ops/training.py:65 2019-01-16 18:02:10.977557: step 4622, loss = 0.68227 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:02:11.959667 ops/training.py:65 2019-01-16 18:02:11.959563: step 4623, loss = 0.70339 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:02:12.941073 ops/training.py:65 2019-01-16 18:02:12.940977: step 4624, loss = 0.68225 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:02:13.922497 ops/training.py:65 2019-01-16 18:02:13.922396: step 4625, loss = 0.71662 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:02:14.907417 ops/training.py:65 2019-01-16 18:02:14.907315: step 4626, loss = 0.68907 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:02:15.891328 ops/training.py:65 2019-01-16 18:02:15.891227: step 4627, loss = 0.70333 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:02:16.876027 ops/training.py:65 2019-01-16 18:02:16.875929: step 4628, loss = 0.68146 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:02:17.861402 ops/training.py:65 2019-01-16 18:02:17.861295: step 4629, loss = 0.71548 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:02:18.845093 ops/training.py:65 2019-01-16 18:02:18.844997: step 4630, loss = 0.69945 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:02:19.829921 ops/training.py:65 2019-01-16 18:02:19.829823: step 4631, loss = 0.71154 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:02:20.813779 ops/training.py:65 2019-01-16 18:02:20.813676: step 4632, loss = 0.69412 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:02:21.798884 ops/training.py:65 2019-01-16 18:02:21.798779: step 4633, loss = 0.70691 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:02:22.783240 ops/training.py:65 2019-01-16 18:02:22.783150: step 4634, loss = 0.68532 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:02:23.767402 ops/training.py:65 2019-01-16 18:02:23.767311: step 4635, loss = 0.70774 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:02:24.751903 ops/training.py:65 2019-01-16 18:02:24.751803: step 4636, loss = 0.69282 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:02:25.734946 ops/training.py:65 2019-01-16 18:02:25.734849: step 4637, loss = 0.69615 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:02:26.717557 ops/training.py:65 2019-01-16 18:02:26.717479: step 4638, loss = 0.69287 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:02:27.698954 ops/training.py:65 2019-01-16 18:02:27.698872: step 4639, loss = 0.69467 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:02:28.679946 ops/training.py:65 2019-01-16 18:02:28.679865: step 4640, loss = 0.69458 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:02:29.663015 ops/training.py:65 2019-01-16 18:02:29.662945: step 4641, loss = 0.68812 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:02:30.645576 ops/training.py:65 2019-01-16 18:02:30.645470: step 4642, loss = 0.69178 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:02:31.629252 ops/training.py:65 2019-01-16 18:02:31.629142: step 4643, loss = 0.67306 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:02:32.614012 ops/training.py:65 2019-01-16 18:02:32.613927: step 4644, loss = 0.68324 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:02:33.595679 ops/training.py:65 2019-01-16 18:02:33.595587: step 4645, loss = 0.68997 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:02:34.578792 ops/training.py:65 2019-01-16 18:02:34.578695: step 4646, loss = 0.69177 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:02:35.565032 ops/training.py:65 2019-01-16 18:02:35.564933: step 4647, loss = 0.68785 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:02:36.547749 ops/training.py:65 2019-01-16 18:02:36.547624: step 4648, loss = 0.72529 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:02:37.530711 ops/training.py:65 2019-01-16 18:02:37.530591: step 4649, loss = 0.69239 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:02:38.512411 ops/training.py:65 2019-01-16 18:02:38.512305: step 4650, loss = 0.69573 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:02:39.495096 ops/training.py:65 2019-01-16 18:02:39.494998: step 4651, loss = 0.70685 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:02:40.476765 ops/training.py:65 2019-01-16 18:02:40.476673: step 4652, loss = 0.71072 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:02:41.458875 ops/training.py:65 2019-01-16 18:02:41.458776: step 4653, loss = 0.71426 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:02:42.440712 ops/training.py:65 2019-01-16 18:02:42.440612: step 4654, loss = 0.68537 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:02:43.423697 ops/training.py:65 2019-01-16 18:02:43.423592: step 4655, loss = 0.69280 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:02:44.406347 ops/training.py:65 2019-01-16 18:02:44.406242: step 4656, loss = 0.71841 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:02:45.391322 ops/training.py:65 2019-01-16 18:02:45.391221: step 4657, loss = 0.70796 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:02:46.375049 ops/training.py:65 2019-01-16 18:02:46.374961: step 4658, loss = 0.71856 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:02:47.359403 ops/training.py:65 2019-01-16 18:02:47.359296: step 4659, loss = 0.70691 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:02:48.341553 ops/training.py:65 2019-01-16 18:02:48.341452: step 4660, loss = 0.71288 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.21875
I8192 2019-01-16 18:02:49.323676 ops/training.py:65 2019-01-16 18:02:49.323577: step 4661, loss = 0.68677 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:02:50.306217 ops/training.py:65 2019-01-16 18:02:50.306108: step 4662, loss = 0.67598 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:02:51.288498 ops/training.py:65 2019-01-16 18:02:51.288404: step 4663, loss = 0.69258 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:02:52.270590 ops/training.py:65 2019-01-16 18:02:52.270492: step 4664, loss = 0.68954 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:02:53.253173 ops/training.py:65 2019-01-16 18:02:53.253102: step 4665, loss = 0.69269 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:02:54.235001 ops/training.py:65 2019-01-16 18:02:54.234905: step 4666, loss = 0.69016 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:02:55.216996 ops/training.py:65 2019-01-16 18:02:55.216887: step 4667, loss = 0.69934 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:02:56.198538 ops/training.py:65 2019-01-16 18:02:56.198434: step 4668, loss = 0.69073 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:02:57.181166 ops/training.py:65 2019-01-16 18:02:57.181066: step 4669, loss = 0.69014 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:02:58.162469 ops/training.py:65 2019-01-16 18:02:58.162372: step 4670, loss = 0.69983 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:02:59.145181 ops/training.py:65 2019-01-16 18:02:59.145085: step 4671, loss = 0.68759 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:03:00.130323 ops/training.py:65 2019-01-16 18:03:00.130230: step 4672, loss = 0.70282 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:03:01.113756 ops/training.py:65 2019-01-16 18:03:01.113665: step 4673, loss = 0.67918 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:03:02.095200 ops/training.py:65 2019-01-16 18:03:02.095102: step 4674, loss = 0.69738 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:03:03.079228 ops/training.py:65 2019-01-16 18:03:03.079126: step 4675, loss = 0.69865 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:03:04.063512 ops/training.py:65 2019-01-16 18:03:04.063413: step 4676, loss = 0.68954 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:03:05.047299 ops/training.py:65 2019-01-16 18:03:05.047194: step 4677, loss = 0.71450 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:03:06.031436 ops/training.py:65 2019-01-16 18:03:06.031338: step 4678, loss = 0.69708 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:03:07.013759 ops/training.py:65 2019-01-16 18:03:07.013657: step 4679, loss = 0.70442 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:03:07.996633 ops/training.py:65 2019-01-16 18:03:07.996539: step 4680, loss = 0.70853 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:03:08.979576 ops/training.py:65 2019-01-16 18:03:08.979473: step 4681, loss = 0.71837 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:03:09.960651 ops/training.py:65 2019-01-16 18:03:09.960553: step 4682, loss = 0.68879 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:03:10.942098 ops/training.py:65 2019-01-16 18:03:10.941997: step 4683, loss = 0.68781 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:03:11.923078 ops/training.py:65 2019-01-16 18:03:11.922972: step 4684, loss = 0.69458 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:03:12.905990 ops/training.py:65 2019-01-16 18:03:12.905887: step 4685, loss = 0.69519 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:03:13.888912 ops/training.py:65 2019-01-16 18:03:13.888777: step 4686, loss = 0.69960 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:03:14.872172 ops/training.py:65 2019-01-16 18:03:14.872050: step 4687, loss = 0.70048 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:03:15.857369 ops/training.py:65 2019-01-16 18:03:15.857265: step 4688, loss = 0.67650 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:03:16.841751 ops/training.py:65 2019-01-16 18:03:16.841647: step 4689, loss = 0.69263 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:03:17.824838 ops/training.py:65 2019-01-16 18:03:17.824729: step 4690, loss = 0.69730 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:03:18.808643 ops/training.py:65 2019-01-16 18:03:18.808542: step 4691, loss = 0.70818 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:03:19.794173 ops/training.py:65 2019-01-16 18:03:19.794071: step 4692, loss = 0.70397 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:03:20.778561 ops/training.py:65 2019-01-16 18:03:20.778462: step 4693, loss = 0.71396 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:03:21.762089 ops/training.py:65 2019-01-16 18:03:21.761984: step 4694, loss = 0.69348 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:03:22.746868 ops/training.py:65 2019-01-16 18:03:22.746775: step 4695, loss = 0.68078 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:03:23.730950 ops/training.py:65 2019-01-16 18:03:23.730857: step 4696, loss = 0.69513 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:03:24.715720 ops/training.py:65 2019-01-16 18:03:24.715620: step 4697, loss = 0.69226 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:03:25.700836 ops/training.py:65 2019-01-16 18:03:25.700711: step 4698, loss = 0.67980 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:03:26.685416 ops/training.py:65 2019-01-16 18:03:26.685322: step 4699, loss = 0.68684 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:03:27.669235 ops/training.py:65 2019-01-16 18:03:27.669130: step 4700, loss = 0.68191 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:03:28.651511 ops/training.py:65 2019-01-16 18:03:28.651411: step 4701, loss = 0.69331 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:03:29.634909 ops/training.py:65 2019-01-16 18:03:29.634807: step 4702, loss = 0.67659 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:03:30.619944 ops/training.py:65 2019-01-16 18:03:30.619841: step 4703, loss = 0.68981 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:03:31.603493 ops/training.py:65 2019-01-16 18:03:31.603384: step 4704, loss = 0.69463 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:03:32.589159 ops/training.py:65 2019-01-16 18:03:32.589054: step 4705, loss = 0.71434 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:03:33.571409 ops/training.py:65 2019-01-16 18:03:33.571299: step 4706, loss = 0.68746 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:03:34.556758 ops/training.py:65 2019-01-16 18:03:34.556660: step 4707, loss = 0.68692 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:03:35.542922 ops/training.py:65 2019-01-16 18:03:35.542819: step 4708, loss = 0.69242 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:03:36.526421 ops/training.py:65 2019-01-16 18:03:36.526319: step 4709, loss = 0.68873 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:03:37.512701 ops/training.py:65 2019-01-16 18:03:37.512602: step 4710, loss = 0.70754 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:03:38.497079 ops/training.py:65 2019-01-16 18:03:38.496980: step 4711, loss = 0.69346 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:03:39.480514 ops/training.py:65 2019-01-16 18:03:39.480408: step 4712, loss = 0.68526 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:03:40.462714 ops/training.py:65 2019-01-16 18:03:40.462576: step 4713, loss = 0.69526 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:03:41.446139 ops/training.py:65 2019-01-16 18:03:41.445990: step 4714, loss = 0.69433 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:03:42.430360 ops/training.py:65 2019-01-16 18:03:42.430216: step 4715, loss = 0.69982 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:03:43.415424 ops/training.py:65 2019-01-16 18:03:43.415339: step 4716, loss = 0.68056 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:03:44.401569 ops/training.py:65 2019-01-16 18:03:44.401476: step 4717, loss = 0.70078 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:03:45.385333 ops/training.py:65 2019-01-16 18:03:45.385202: step 4718, loss = 0.67973 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:03:46.368115 ops/training.py:65 2019-01-16 18:03:46.368020: step 4719, loss = 0.69041 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:03:47.350647 ops/training.py:65 2019-01-16 18:03:47.350540: step 4720, loss = 0.68228 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:03:48.333956 ops/training.py:65 2019-01-16 18:03:48.333847: step 4721, loss = 0.68524 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:03:49.318289 ops/training.py:65 2019-01-16 18:03:49.318184: step 4722, loss = 0.68829 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:03:50.302011 ops/training.py:65 2019-01-16 18:03:50.301902: step 4723, loss = 0.67590 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:03:51.286155 ops/training.py:65 2019-01-16 18:03:51.286053: step 4724, loss = 0.69164 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:03:52.272580 ops/training.py:65 2019-01-16 18:03:52.272473: step 4725, loss = 0.68381 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:03:53.256724 ops/training.py:65 2019-01-16 18:03:53.256626: step 4726, loss = 0.68007 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:03:54.240001 ops/training.py:65 2019-01-16 18:03:54.239885: step 4727, loss = 0.68965 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:03:55.223421 ops/training.py:65 2019-01-16 18:03:55.223315: step 4728, loss = 0.69533 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:03:56.205504 ops/training.py:65 2019-01-16 18:03:56.205426: step 4729, loss = 0.68371 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:03:57.189075 ops/training.py:65 2019-01-16 18:03:57.188975: step 4730, loss = 0.69444 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:03:58.174724 ops/training.py:65 2019-01-16 18:03:58.174620: step 4731, loss = 0.68064 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:03:59.159639 ops/training.py:65 2019-01-16 18:03:59.159529: step 4732, loss = 0.71650 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:04:00.142989 ops/training.py:65 2019-01-16 18:04:00.142889: step 4733, loss = 0.71784 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:04:01.125549 ops/training.py:65 2019-01-16 18:04:01.125415: step 4734, loss = 0.69512 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:04:02.108440 ops/training.py:65 2019-01-16 18:04:02.108295: step 4735, loss = 0.68283 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:04:03.091279 ops/training.py:65 2019-01-16 18:04:03.091185: step 4736, loss = 0.68746 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:04:04.073991 ops/training.py:65 2019-01-16 18:04:04.073890: step 4737, loss = 0.67607 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:04:05.058120 ops/training.py:65 2019-01-16 18:04:05.058014: step 4738, loss = 0.69466 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:04:06.044598 ops/training.py:65 2019-01-16 18:04:06.044492: step 4739, loss = 0.68303 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:04:07.028959 ops/training.py:65 2019-01-16 18:04:07.028853: step 4740, loss = 0.69170 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:04:08.013840 ops/training.py:65 2019-01-16 18:04:08.013744: step 4741, loss = 0.67522 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:04:08.997918 ops/training.py:65 2019-01-16 18:04:08.997809: step 4742, loss = 0.69096 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:04:09.983204 ops/training.py:65 2019-01-16 18:04:09.983066: step 4743, loss = 0.69367 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:04:10.967055 ops/training.py:65 2019-01-16 18:04:10.966957: step 4744, loss = 0.68919 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:04:11.951965 ops/training.py:65 2019-01-16 18:04:11.951859: step 4745, loss = 0.70502 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:04:12.935338 ops/training.py:65 2019-01-16 18:04:12.935224: step 4746, loss = 0.68150 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:04:13.918063 ops/training.py:65 2019-01-16 18:04:13.917965: step 4747, loss = 0.69121 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:04:14.899683 ops/training.py:65 2019-01-16 18:04:14.899575: step 4748, loss = 0.70340 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:04:15.882720 ops/training.py:65 2019-01-16 18:04:15.882607: step 4749, loss = 0.69471 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:04:16.865197 ops/training.py:65 2019-01-16 18:04:16.865094: step 4750, loss = 0.67665 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:04:17.848035 ops/training.py:65 2019-01-16 18:04:17.847924: step 4751, loss = 0.69387 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:04:18.831174 ops/training.py:65 2019-01-16 18:04:18.831068: step 4752, loss = 0.69896 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:04:19.814915 ops/training.py:65 2019-01-16 18:04:19.814817: step 4753, loss = 0.68693 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:04:20.797499 ops/training.py:65 2019-01-16 18:04:20.797396: step 4754, loss = 0.70047 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:04:21.780082 ops/training.py:65 2019-01-16 18:04:21.779978: step 4755, loss = 0.68061 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:04:22.762488 ops/training.py:65 2019-01-16 18:04:22.762388: step 4756, loss = 0.68790 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:04:23.746208 ops/training.py:65 2019-01-16 18:04:23.746115: step 4757, loss = 0.69268 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:04:24.730226 ops/training.py:65 2019-01-16 18:04:24.730093: step 4758, loss = 0.68624 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:04:25.713222 ops/training.py:65 2019-01-16 18:04:25.713121: step 4759, loss = 0.70281 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:04:26.695399 ops/training.py:65 2019-01-16 18:04:26.695278: step 4760, loss = 0.67662 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.8125
I8192 2019-01-16 18:04:27.679181 ops/training.py:65 2019-01-16 18:04:27.679081: step 4761, loss = 0.70488 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:04:28.662438 ops/training.py:65 2019-01-16 18:04:28.662331: step 4762, loss = 0.70403 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:04:29.646644 ops/training.py:65 2019-01-16 18:04:29.646534: step 4763, loss = 0.68626 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:04:30.634126 ops/training.py:65 2019-01-16 18:04:30.634030: step 4764, loss = 0.68310 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:04:31.617951 ops/training.py:65 2019-01-16 18:04:31.617845: step 4765, loss = 0.69446 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:04:32.603502 ops/training.py:65 2019-01-16 18:04:32.603398: step 4766, loss = 0.68399 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:04:33.587650 ops/training.py:65 2019-01-16 18:04:33.587553: step 4767, loss = 0.66847 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:04:34.572406 ops/training.py:65 2019-01-16 18:04:34.572273: step 4768, loss = 0.68947 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:04:35.556756 ops/training.py:65 2019-01-16 18:04:35.556653: step 4769, loss = 0.68974 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:04:36.540484 ops/training.py:65 2019-01-16 18:04:36.540382: step 4770, loss = 0.70360 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:04:37.523658 ops/training.py:65 2019-01-16 18:04:37.523558: step 4771, loss = 0.68969 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:04:38.505758 ops/training.py:65 2019-01-16 18:04:38.505664: step 4772, loss = 0.69610 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:04:39.488163 ops/training.py:65 2019-01-16 18:04:39.488067: step 4773, loss = 0.70281 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:04:40.470861 ops/training.py:65 2019-01-16 18:04:40.470725: step 4774, loss = 0.71699 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:04:41.453490 ops/training.py:65 2019-01-16 18:04:41.453385: step 4775, loss = 0.69222 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:04:42.438324 ops/training.py:65 2019-01-16 18:04:42.438232: step 4776, loss = 0.69150 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:04:43.423160 ops/training.py:65 2019-01-16 18:04:43.423064: step 4777, loss = 0.70872 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:04:44.405885 ops/training.py:65 2019-01-16 18:04:44.405780: step 4778, loss = 0.69995 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:04:45.388442 ops/training.py:65 2019-01-16 18:04:45.388335: step 4779, loss = 0.71095 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:04:46.371101 ops/training.py:65 2019-01-16 18:04:46.370994: step 4780, loss = 0.71169 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:04:47.356682 ops/training.py:65 2019-01-16 18:04:47.356573: step 4781, loss = 0.69617 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:04:48.342192 ops/training.py:65 2019-01-16 18:04:48.342103: step 4782, loss = 0.69794 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:04:49.327850 ops/training.py:65 2019-01-16 18:04:49.327743: step 4783, loss = 0.68034 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:04:50.311838 ops/training.py:65 2019-01-16 18:04:50.311731: step 4784, loss = 0.70635 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:04:51.297005 ops/training.py:65 2019-01-16 18:04:51.296915: step 4785, loss = 0.69831 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:04:52.281346 ops/training.py:65 2019-01-16 18:04:52.281267: step 4786, loss = 0.69150 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:04:53.266412 ops/training.py:65 2019-01-16 18:04:53.266331: step 4787, loss = 0.67797 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:04:54.250781 ops/training.py:65 2019-01-16 18:04:54.250647: step 4788, loss = 0.67870 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:04:55.237673 ops/training.py:65 2019-01-16 18:04:55.237573: step 4789, loss = 0.70152 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:04:56.222945 ops/training.py:65 2019-01-16 18:04:56.222852: step 4790, loss = 0.69174 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:04:57.207559 ops/training.py:65 2019-01-16 18:04:57.207432: step 4791, loss = 0.69811 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:04:58.190225 ops/training.py:65 2019-01-16 18:04:58.190123: step 4792, loss = 0.68049 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:04:59.174099 ops/training.py:65 2019-01-16 18:04:59.173998: step 4793, loss = 0.67651 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:05:00.158171 ops/training.py:65 2019-01-16 18:05:00.158065: step 4794, loss = 0.67858 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:05:01.142604 ops/training.py:65 2019-01-16 18:05:01.142494: step 4795, loss = 0.67910 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:05:02.125216 ops/training.py:65 2019-01-16 18:05:02.125115: step 4796, loss = 0.69270 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:05:03.110338 ops/training.py:65 2019-01-16 18:05:03.110236: step 4797, loss = 0.69060 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:05:04.094241 ops/training.py:65 2019-01-16 18:05:04.094139: step 4798, loss = 0.70156 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:05:05.077461 ops/training.py:65 2019-01-16 18:05:05.077357: step 4799, loss = 0.69329 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:05:06.062324 ops/training.py:65 2019-01-16 18:05:06.062222: step 4800, loss = 0.68555 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:05:07.047815 ops/training.py:65 2019-01-16 18:05:07.047710: step 4801, loss = 0.70454 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:05:08.032109 ops/training.py:65 2019-01-16 18:05:08.032016: step 4802, loss = 0.68019 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:05:09.016838 ops/training.py:65 2019-01-16 18:05:09.016737: step 4803, loss = 0.68084 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:05:10.001463 ops/training.py:65 2019-01-16 18:05:10.001364: step 4804, loss = 0.69312 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:05:10.985832 ops/training.py:65 2019-01-16 18:05:10.985731: step 4805, loss = 0.70178 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:05:11.968628 ops/training.py:65 2019-01-16 18:05:11.968525: step 4806, loss = 0.70128 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:05:12.950891 ops/training.py:65 2019-01-16 18:05:12.950788: step 4807, loss = 0.69021 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:05:13.934509 ops/training.py:65 2019-01-16 18:05:13.934415: step 4808, loss = 0.67311 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:05:14.919553 ops/training.py:65 2019-01-16 18:05:14.919446: step 4809, loss = 0.70669 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:05:15.905444 ops/training.py:65 2019-01-16 18:05:15.905337: step 4810, loss = 0.69059 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:05:16.890276 ops/training.py:65 2019-01-16 18:05:16.890176: step 4811, loss = 0.69798 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:05:17.876554 ops/training.py:65 2019-01-16 18:05:17.876467: step 4812, loss = 0.69597 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:05:18.861177 ops/training.py:65 2019-01-16 18:05:18.861080: step 4813, loss = 0.69983 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:05:19.844185 ops/training.py:65 2019-01-16 18:05:19.844074: step 4814, loss = 0.69582 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:05:20.828162 ops/training.py:65 2019-01-16 18:05:20.828056: step 4815, loss = 0.69681 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:05:21.813721 ops/training.py:65 2019-01-16 18:05:21.813616: step 4816, loss = 0.69042 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:05:22.799341 ops/training.py:65 2019-01-16 18:05:22.799233: step 4817, loss = 0.69622 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:05:23.783672 ops/training.py:65 2019-01-16 18:05:23.783576: step 4818, loss = 0.70476 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:05:24.768148 ops/training.py:65 2019-01-16 18:05:24.768038: step 4819, loss = 0.70300 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:05:25.752709 ops/training.py:65 2019-01-16 18:05:25.752603: step 4820, loss = 0.69427 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:05:26.736545 ops/training.py:65 2019-01-16 18:05:26.736440: step 4821, loss = 0.70017 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:05:27.720713 ops/training.py:65 2019-01-16 18:05:27.720608: step 4822, loss = 0.69007 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:05:28.704063 ops/training.py:65 2019-01-16 18:05:28.703954: step 4823, loss = 0.70144 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:05:29.688037 ops/training.py:65 2019-01-16 18:05:29.687939: step 4824, loss = 0.69431 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:05:30.671704 ops/training.py:65 2019-01-16 18:05:30.671601: step 4825, loss = 0.71890 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 18:05:31.656909 ops/training.py:65 2019-01-16 18:05:31.656808: step 4826, loss = 0.67692 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:05:32.641417 ops/training.py:65 2019-01-16 18:05:32.641312: step 4827, loss = 0.70529 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:05:33.627293 ops/training.py:65 2019-01-16 18:05:33.627193: step 4828, loss = 0.70826 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:05:34.612580 ops/training.py:65 2019-01-16 18:05:34.612478: step 4829, loss = 0.69451 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:05:35.597825 ops/training.py:65 2019-01-16 18:05:35.597725: step 4830, loss = 0.67529 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:05:36.582430 ops/training.py:65 2019-01-16 18:05:36.582325: step 4831, loss = 0.68531 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:05:37.567440 ops/training.py:65 2019-01-16 18:05:37.567291: step 4832, loss = 0.69839 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:05:38.554626 ops/training.py:65 2019-01-16 18:05:38.554544: step 4833, loss = 0.68485 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:05:39.540746 ops/training.py:65 2019-01-16 18:05:39.540641: step 4834, loss = 0.70171 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:05:40.525954 ops/training.py:65 2019-01-16 18:05:40.525857: step 4835, loss = 0.70344 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:05:41.510916 ops/training.py:65 2019-01-16 18:05:41.510842: step 4836, loss = 0.68802 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:05:42.493377 ops/training.py:65 2019-01-16 18:05:42.493292: step 4837, loss = 0.70874 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:05:43.474982 ops/training.py:65 2019-01-16 18:05:43.474898: step 4838, loss = 0.69168 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:05:44.456984 ops/training.py:65 2019-01-16 18:05:44.456900: step 4839, loss = 0.69726 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:05:45.439694 ops/training.py:65 2019-01-16 18:05:45.439616: step 4840, loss = 0.68370 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:05:46.420631 ops/training.py:65 2019-01-16 18:05:46.420550: step 4841, loss = 0.69779 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:05:47.404722 ops/training.py:65 2019-01-16 18:05:47.404642: step 4842, loss = 0.67828 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:05:48.388501 ops/training.py:65 2019-01-16 18:05:48.388406: step 4843, loss = 0.68771 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:05:49.372423 ops/training.py:65 2019-01-16 18:05:49.372328: step 4844, loss = 0.68080 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:05:50.356584 ops/training.py:65 2019-01-16 18:05:50.356479: step 4845, loss = 0.67929 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:05:51.338969 ops/training.py:65 2019-01-16 18:05:51.338861: step 4846, loss = 0.68475 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:05:52.321897 ops/training.py:65 2019-01-16 18:05:52.321793: step 4847, loss = 0.69680 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:05:53.306800 ops/training.py:65 2019-01-16 18:05:53.306713: step 4848, loss = 0.70103 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:05:54.291258 ops/training.py:65 2019-01-16 18:05:54.291164: step 4849, loss = 0.70753 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:05:55.275157 ops/training.py:65 2019-01-16 18:05:55.275050: step 4850, loss = 0.70703 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:05:56.257487 ops/training.py:65 2019-01-16 18:05:56.257385: step 4851, loss = 0.70276 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:05:57.238655 ops/training.py:65 2019-01-16 18:05:57.238552: step 4852, loss = 0.68097 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:05:58.222202 ops/training.py:65 2019-01-16 18:05:58.222094: step 4853, loss = 0.69226 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:05:59.207944 ops/training.py:65 2019-01-16 18:05:59.207842: step 4854, loss = 0.69540 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:06:00.192868 ops/training.py:65 2019-01-16 18:06:00.192764: step 4855, loss = 0.69523 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:06:01.175519 ops/training.py:65 2019-01-16 18:06:01.175445: step 4856, loss = 0.69262 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:06:02.159168 ops/training.py:65 2019-01-16 18:06:02.159107: step 4857, loss = 0.70944 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:06:03.142632 ops/training.py:65 2019-01-16 18:06:03.142537: step 4858, loss = 0.67896 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:06:04.127877 ops/training.py:65 2019-01-16 18:06:04.127768: step 4859, loss = 0.67629 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:06:05.110623 ops/training.py:65 2019-01-16 18:06:05.110537: step 4860, loss = 0.70184 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:06:06.092190 ops/training.py:65 2019-01-16 18:06:06.092118: step 4861, loss = 0.70493 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:06:07.074009 ops/training.py:65 2019-01-16 18:06:07.073937: step 4862, loss = 0.71987 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:06:08.054838 ops/training.py:65 2019-01-16 18:06:08.054768: step 4863, loss = 0.67153 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:06:09.037882 ops/training.py:65 2019-01-16 18:06:09.037812: step 4864, loss = 0.69483 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:06:10.022336 ops/training.py:65 2019-01-16 18:06:10.022233: step 4865, loss = 0.69908 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:06:11.005713 ops/training.py:65 2019-01-16 18:06:11.005609: step 4866, loss = 0.69890 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:06:11.990913 ops/training.py:65 2019-01-16 18:06:11.990813: step 4867, loss = 0.69656 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:06:12.975168 ops/training.py:65 2019-01-16 18:06:12.975060: step 4868, loss = 0.68761 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:06:13.958339 ops/training.py:65 2019-01-16 18:06:13.958259: step 4869, loss = 0.69617 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:06:14.941584 ops/training.py:65 2019-01-16 18:06:14.941486: step 4870, loss = 0.70902 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:06:15.926014 ops/training.py:65 2019-01-16 18:06:15.925913: step 4871, loss = 0.69005 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:06:16.909470 ops/training.py:65 2019-01-16 18:06:16.909320: step 4872, loss = 0.69735 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:06:17.896169 ops/training.py:65 2019-01-16 18:06:17.896083: step 4873, loss = 0.69710 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:06:18.879769 ops/training.py:65 2019-01-16 18:06:18.879667: step 4874, loss = 0.69084 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:06:19.864014 ops/training.py:65 2019-01-16 18:06:19.863903: step 4875, loss = 0.70596 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:06:20.848300 ops/training.py:65 2019-01-16 18:06:20.848154: step 4876, loss = 0.68082 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:06:21.834035 ops/training.py:65 2019-01-16 18:06:21.833925: step 4877, loss = 0.69409 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:06:22.817844 ops/training.py:65 2019-01-16 18:06:22.817736: step 4878, loss = 0.67526 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:06:23.802332 ops/training.py:65 2019-01-16 18:06:23.802234: step 4879, loss = 0.67724 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:06:24.785867 ops/training.py:65 2019-01-16 18:06:24.785761: step 4880, loss = 0.68408 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:06:25.767988 ops/training.py:65 2019-01-16 18:06:25.767891: step 4881, loss = 0.69976 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:06:26.749760 ops/training.py:65 2019-01-16 18:06:26.749661: step 4882, loss = 0.67715 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:06:27.733268 ops/training.py:65 2019-01-16 18:06:27.733196: step 4883, loss = 0.70544 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:06:28.718191 ops/training.py:65 2019-01-16 18:06:28.718082: step 4884, loss = 0.68920 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:06:29.702235 ops/training.py:65 2019-01-16 18:06:29.702099: step 4885, loss = 0.69558 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:06:30.686026 ops/training.py:65 2019-01-16 18:06:30.685875: step 4886, loss = 0.71103 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:06:31.672447 ops/training.py:65 2019-01-16 18:06:31.672340: step 4887, loss = 0.68110 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:06:32.656630 ops/training.py:65 2019-01-16 18:06:32.656518: step 4888, loss = 0.68086 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:06:33.639844 ops/training.py:65 2019-01-16 18:06:33.639742: step 4889, loss = 0.67503 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:06:34.623226 ops/training.py:65 2019-01-16 18:06:34.623082: step 4890, loss = 0.68842 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:06:35.609360 ops/training.py:65 2019-01-16 18:06:35.609258: step 4891, loss = 0.69024 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:06:36.593152 ops/training.py:65 2019-01-16 18:06:36.593012: step 4892, loss = 0.71300 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:06:37.579696 ops/training.py:65 2019-01-16 18:06:37.579588: step 4893, loss = 0.71410 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:06:38.566015 ops/training.py:65 2019-01-16 18:06:38.565925: step 4894, loss = 0.69508 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:06:39.550723 ops/training.py:65 2019-01-16 18:06:39.550617: step 4895, loss = 0.67858 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:06:40.533564 ops/training.py:65 2019-01-16 18:06:40.533468: step 4896, loss = 0.68128 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:06:41.516290 ops/training.py:65 2019-01-16 18:06:41.516194: step 4897, loss = 0.65688 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:06:42.500094 ops/training.py:65 2019-01-16 18:06:42.499992: step 4898, loss = 0.70884 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:06:43.483449 ops/training.py:65 2019-01-16 18:06:43.483345: step 4899, loss = 0.68791 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:06:44.466123 ops/training.py:65 2019-01-16 18:06:44.466025: step 4900, loss = 0.68625 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:06:45.450277 ops/training.py:65 2019-01-16 18:06:45.450185: step 4901, loss = 0.70132 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:06:46.435701 ops/training.py:65 2019-01-16 18:06:46.435604: step 4902, loss = 0.70424 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:06:47.419555 ops/training.py:65 2019-01-16 18:06:47.419448: step 4903, loss = 0.69788 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:06:48.402390 ops/training.py:65 2019-01-16 18:06:48.402286: step 4904, loss = 0.67937 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:06:49.384740 ops/training.py:65 2019-01-16 18:06:49.384630: step 4905, loss = 0.70764 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:06:50.367235 ops/training.py:65 2019-01-16 18:06:50.367137: step 4906, loss = 0.69407 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:06:51.350554 ops/training.py:65 2019-01-16 18:06:51.350446: step 4907, loss = 0.69272 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:06:52.333678 ops/training.py:65 2019-01-16 18:06:52.333578: step 4908, loss = 0.68575 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:06:53.317243 ops/training.py:65 2019-01-16 18:06:53.317144: step 4909, loss = 0.68176 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:06:54.300536 ops/training.py:65 2019-01-16 18:06:54.300431: step 4910, loss = 0.69910 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:06:55.284361 ops/training.py:65 2019-01-16 18:06:55.284252: step 4911, loss = 0.69054 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:06:56.268938 ops/training.py:65 2019-01-16 18:06:56.268862: step 4912, loss = 0.70632 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:06:57.252712 ops/training.py:65 2019-01-16 18:06:57.252620: step 4913, loss = 0.68114 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:06:58.235555 ops/training.py:65 2019-01-16 18:06:58.235459: step 4914, loss = 0.71048 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:06:59.216966 ops/training.py:65 2019-01-16 18:06:59.216870: step 4915, loss = 0.70077 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:07:00.199947 ops/training.py:65 2019-01-16 18:07:00.199854: step 4916, loss = 0.70544 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:07:01.183231 ops/training.py:65 2019-01-16 18:07:01.183135: step 4917, loss = 0.70970 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:07:02.165939 ops/training.py:65 2019-01-16 18:07:02.165844: step 4918, loss = 0.68900 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:07:03.149659 ops/training.py:65 2019-01-16 18:07:03.149560: step 4919, loss = 0.72310 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.21875
I8192 2019-01-16 18:07:04.131920 ops/training.py:65 2019-01-16 18:07:04.131823: step 4920, loss = 0.70288 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:07:05.114850 ops/training.py:65 2019-01-16 18:07:05.114755: step 4921, loss = 0.68110 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:07:06.097069 ops/training.py:65 2019-01-16 18:07:06.096968: step 4922, loss = 0.69464 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:07:07.080076 ops/training.py:65 2019-01-16 18:07:07.079974: step 4923, loss = 0.69404 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:07:08.062267 ops/training.py:65 2019-01-16 18:07:08.062164: step 4924, loss = 0.69503 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:07:09.046394 ops/training.py:65 2019-01-16 18:07:09.046286: step 4925, loss = 0.69661 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:07:10.031161 ops/training.py:65 2019-01-16 18:07:10.031055: step 4926, loss = 0.68814 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:07:11.013694 ops/training.py:65 2019-01-16 18:07:11.013607: step 4927, loss = 0.68108 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:07:11.998823 ops/training.py:65 2019-01-16 18:07:11.998753: step 4928, loss = 0.70372 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:07:12.985487 ops/training.py:65 2019-01-16 18:07:12.985391: step 4929, loss = 0.67643 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:07:14.177104 ops/training.py:65 2019-01-16 18:07:14.177004: step 4930, loss = 0.70276 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:07:15.161042 ops/training.py:65 2019-01-16 18:07:15.160938: step 4931, loss = 0.69952 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:07:16.144930 ops/training.py:65 2019-01-16 18:07:16.144852: step 4932, loss = 0.68806 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:07:17.129256 ops/training.py:65 2019-01-16 18:07:17.129177: step 4933, loss = 0.71336 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:07:18.117851 ops/training.py:65 2019-01-16 18:07:18.117753: step 4934, loss = 0.69852 (32.4 examples/sec; 0.988 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:07:19.102038 ops/training.py:65 2019-01-16 18:07:19.101933: step 4935, loss = 0.69801 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:07:20.084725 ops/training.py:65 2019-01-16 18:07:20.084620: step 4936, loss = 0.67829 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:07:21.069820 ops/training.py:65 2019-01-16 18:07:21.069749: step 4937, loss = 0.70347 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:07:22.053185 ops/training.py:65 2019-01-16 18:07:22.053082: step 4938, loss = 0.68579 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:07:23.039032 ops/training.py:65 2019-01-16 18:07:23.038934: step 4939, loss = 0.69885 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:07:24.022127 ops/training.py:65 2019-01-16 18:07:24.022028: step 4940, loss = 0.69127 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:07:25.007077 ops/training.py:65 2019-01-16 18:07:25.006986: step 4941, loss = 0.69143 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:07:25.990431 ops/training.py:65 2019-01-16 18:07:25.990335: step 4942, loss = 0.67560 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:07:26.973913 ops/training.py:65 2019-01-16 18:07:26.973815: step 4943, loss = 0.67874 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:07:27.957813 ops/training.py:65 2019-01-16 18:07:27.957710: step 4944, loss = 0.70530 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:07:28.941572 ops/training.py:65 2019-01-16 18:07:28.941469: step 4945, loss = 0.69302 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:07:29.923948 ops/training.py:65 2019-01-16 18:07:29.923853: step 4946, loss = 0.69621 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:07:30.906804 ops/training.py:65 2019-01-16 18:07:30.906696: step 4947, loss = 0.71224 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:07:31.889821 ops/training.py:65 2019-01-16 18:07:31.889717: step 4948, loss = 0.67825 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:07:32.872585 ops/training.py:65 2019-01-16 18:07:32.872484: step 4949, loss = 0.69363 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:07:33.855429 ops/training.py:65 2019-01-16 18:07:33.855327: step 4950, loss = 0.70619 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:07:34.838651 ops/training.py:65 2019-01-16 18:07:34.838549: step 4951, loss = 0.69745 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:07:35.821416 ops/training.py:65 2019-01-16 18:07:35.821311: step 4952, loss = 0.66935 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:07:36.803844 ops/training.py:65 2019-01-16 18:07:36.803738: step 4953, loss = 0.72019 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:07:37.787637 ops/training.py:65 2019-01-16 18:07:37.787570: step 4954, loss = 0.71446 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:07:38.767510 ops/training.py:65 2019-01-16 18:07:38.767437: step 4955, loss = 0.68580 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:07:39.747341 ops/training.py:65 2019-01-16 18:07:39.747277: step 4956, loss = 0.68651 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:07:40.731246 ops/training.py:65 2019-01-16 18:07:40.731168: step 4957, loss = 0.74078 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 18:07:41.715039 ops/training.py:65 2019-01-16 18:07:41.714935: step 4958, loss = 0.67116 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:07:42.698055 ops/training.py:65 2019-01-16 18:07:42.697949: step 4959, loss = 0.71036 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:07:43.680488 ops/training.py:65 2019-01-16 18:07:43.680390: step 4960, loss = 0.71440 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:07:44.664646 ops/training.py:65 2019-01-16 18:07:44.664540: step 4961, loss = 0.75290 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:07:45.648602 ops/training.py:65 2019-01-16 18:07:45.648493: step 4962, loss = 0.72124 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:07:46.635879 ops/training.py:65 2019-01-16 18:07:46.635778: step 4963, loss = 0.74493 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:07:47.619660 ops/training.py:65 2019-01-16 18:07:47.619547: step 4964, loss = 0.73801 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:07:48.603392 ops/training.py:65 2019-01-16 18:07:48.603283: step 4965, loss = 0.66116 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:07:49.585417 ops/training.py:65 2019-01-16 18:07:49.585315: step 4966, loss = 0.69224 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:07:50.567464 ops/training.py:65 2019-01-16 18:07:50.567395: step 4967, loss = 0.68786 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:07:51.547872 ops/training.py:65 2019-01-16 18:07:51.547804: step 4968, loss = 0.65163 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:07:52.527622 ops/training.py:65 2019-01-16 18:07:52.527561: step 4969, loss = 0.66596 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:07:53.511441 ops/training.py:65 2019-01-16 18:07:53.511370: step 4970, loss = 0.66612 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:07:54.494761 ops/training.py:65 2019-01-16 18:07:54.494652: step 4971, loss = 0.71897 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:07:55.477869 ops/training.py:65 2019-01-16 18:07:55.477765: step 4972, loss = 0.69967 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:07:56.460546 ops/training.py:65 2019-01-16 18:07:56.460478: step 4973, loss = 0.70245 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:07:57.441032 ops/training.py:65 2019-01-16 18:07:57.440967: step 4974, loss = 0.66740 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:07:58.421736 ops/training.py:65 2019-01-16 18:07:58.421666: step 4975, loss = 0.67169 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:07:59.405186 ops/training.py:65 2019-01-16 18:07:59.405094: step 4976, loss = 0.69808 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:08:00.390281 ops/training.py:65 2019-01-16 18:08:00.390184: step 4977, loss = 0.67816 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:08:01.373902 ops/training.py:65 2019-01-16 18:08:01.373801: step 4978, loss = 0.70169 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:08:02.356775 ops/training.py:65 2019-01-16 18:08:02.356666: step 4979, loss = 0.70687 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:08:03.337944 ops/training.py:65 2019-01-16 18:08:03.337879: step 4980, loss = 0.71653 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:08:04.319070 ops/training.py:65 2019-01-16 18:08:04.319000: step 4981, loss = 0.72062 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:08:05.298867 ops/training.py:65 2019-01-16 18:08:05.298787: step 4982, loss = 0.71397 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:08:06.283065 ops/training.py:65 2019-01-16 18:08:06.282988: step 4983, loss = 0.69555 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:08:07.266576 ops/training.py:65 2019-01-16 18:08:07.266462: step 4984, loss = 0.70705 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:08:08.250084 ops/training.py:65 2019-01-16 18:08:08.249985: step 4985, loss = 0.68716 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:08:09.235085 ops/training.py:65 2019-01-16 18:08:09.234978: step 4986, loss = 0.68204 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:08:10.219870 ops/training.py:65 2019-01-16 18:08:10.219761: step 4987, loss = 0.69939 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:08:11.204111 ops/training.py:65 2019-01-16 18:08:11.204003: step 4988, loss = 0.68315 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:08:12.189094 ops/training.py:65 2019-01-16 18:08:12.189005: step 4989, loss = 0.70336 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:08:13.172351 ops/training.py:65 2019-01-16 18:08:13.172247: step 4990, loss = 0.69976 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:08:14.154571 ops/training.py:65 2019-01-16 18:08:14.154472: step 4991, loss = 0.69382 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:08:15.138857 ops/training.py:65 2019-01-16 18:08:15.138757: step 4992, loss = 0.69708 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:08:16.121570 ops/training.py:65 2019-01-16 18:08:16.121470: step 4993, loss = 0.68888 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:08:17.103815 ops/training.py:65 2019-01-16 18:08:17.103713: step 4994, loss = 0.68038 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:08:18.088599 ops/training.py:65 2019-01-16 18:08:18.088496: step 4995, loss = 0.69334 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:08:19.071017 ops/training.py:65 2019-01-16 18:08:19.070911: step 4996, loss = 0.67325 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:08:20.054829 ops/training.py:65 2019-01-16 18:08:20.054725: step 4997, loss = 0.69016 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:08:21.036851 ops/training.py:65 2019-01-16 18:08:21.036746: step 4998, loss = 0.70858 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:08:22.017810 ops/training.py:65 2019-01-16 18:08:22.017738: step 4999, loss = 0.69738 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:08:22.998158 ops/training.py:65 2019-01-16 18:08:22.998084: step 5000, loss = 0.70704 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:08:23.981104 ops/training.py:65 2019-01-16 18:08:23.981040: step 5001, loss = 0.67331 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:08:24.964706 ops/training.py:65 2019-01-16 18:08:24.964600: step 5002, loss = 0.69808 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:08:25.946012 ops/training.py:65 2019-01-16 18:08:25.945913: step 5003, loss = 0.69957 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:08:26.928017 ops/training.py:65 2019-01-16 18:08:26.927914: step 5004, loss = 0.67688 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:08:27.910611 ops/training.py:65 2019-01-16 18:08:27.910503: step 5005, loss = 0.65667 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:08:28.891720 ops/training.py:65 2019-01-16 18:08:28.891662: step 5006, loss = 0.68516 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:08:29.875192 ops/training.py:65 2019-01-16 18:08:29.875108: step 5007, loss = 0.68951 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:08:30.858496 ops/training.py:65 2019-01-16 18:08:30.858393: step 5008, loss = 0.73880 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:08:31.841890 ops/training.py:65 2019-01-16 18:08:31.841785: step 5009, loss = 0.69590 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:08:32.824489 ops/training.py:65 2019-01-16 18:08:32.824389: step 5010, loss = 0.73480 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:08:33.806660 ops/training.py:65 2019-01-16 18:08:33.806558: step 5011, loss = 0.69678 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:08:34.788059 ops/training.py:65 2019-01-16 18:08:34.787966: step 5012, loss = 0.72241 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:08:35.770003 ops/training.py:65 2019-01-16 18:08:35.769892: step 5013, loss = 0.71018 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:08:36.752401 ops/training.py:65 2019-01-16 18:08:36.752295: step 5014, loss = 0.73227 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:08:37.734974 ops/training.py:65 2019-01-16 18:08:37.734869: step 5015, loss = 0.70216 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:08:38.722924 ops/training.py:65 2019-01-16 18:08:38.722861: step 5016, loss = 0.68624 (32.4 examples/sec; 0.987 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:08:39.706455 ops/training.py:65 2019-01-16 18:08:39.706348: step 5017, loss = 0.75491 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:08:40.692208 ops/training.py:65 2019-01-16 18:08:40.692106: step 5018, loss = 0.72787 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:08:41.676782 ops/training.py:65 2019-01-16 18:08:41.676679: step 5019, loss = 0.70676 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:08:42.659979 ops/training.py:65 2019-01-16 18:08:42.659874: step 5020, loss = 0.69758 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:08:43.643497 ops/training.py:65 2019-01-16 18:08:43.643394: step 5021, loss = 0.68745 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:08:44.627452 ops/training.py:65 2019-01-16 18:08:44.627352: step 5022, loss = 0.64777 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:08:45.611193 ops/training.py:65 2019-01-16 18:08:45.611086: step 5023, loss = 0.72447 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:08:46.594368 ops/training.py:65 2019-01-16 18:08:46.594264: step 5024, loss = 0.71058 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:08:47.577412 ops/training.py:65 2019-01-16 18:08:47.577310: step 5025, loss = 0.68265 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:08:48.559847 ops/training.py:65 2019-01-16 18:08:48.559747: step 5026, loss = 0.70570 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:08:49.543053 ops/training.py:65 2019-01-16 18:08:49.542952: step 5027, loss = 0.67917 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:08:50.527067 ops/training.py:65 2019-01-16 18:08:50.526970: step 5028, loss = 0.68817 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:08:51.510810 ops/training.py:65 2019-01-16 18:08:51.510708: step 5029, loss = 0.72511 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:08:52.493755 ops/training.py:65 2019-01-16 18:08:52.493663: step 5030, loss = 0.71242 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:08:53.476729 ops/training.py:65 2019-01-16 18:08:53.476633: step 5031, loss = 0.74575 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:08:54.459710 ops/training.py:65 2019-01-16 18:08:54.459606: step 5032, loss = 0.71244 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:08:55.442185 ops/training.py:65 2019-01-16 18:08:55.442081: step 5033, loss = 0.68895 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:08:56.424113 ops/training.py:65 2019-01-16 18:08:56.424008: step 5034, loss = 0.68447 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:08:57.405980 ops/training.py:65 2019-01-16 18:08:57.405870: step 5035, loss = 0.69153 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:08:58.389801 ops/training.py:65 2019-01-16 18:08:58.389697: step 5036, loss = 0.69259 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:08:59.372394 ops/training.py:65 2019-01-16 18:08:59.372298: step 5037, loss = 0.67690 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:09:00.355628 ops/training.py:65 2019-01-16 18:09:00.355525: step 5038, loss = 0.71446 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:09:01.338649 ops/training.py:65 2019-01-16 18:09:01.338538: step 5039, loss = 0.68705 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:09:02.322014 ops/training.py:65 2019-01-16 18:09:02.321913: step 5040, loss = 0.70215 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:09:03.304718 ops/training.py:65 2019-01-16 18:09:03.304608: step 5041, loss = 0.67996 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:09:04.286377 ops/training.py:65 2019-01-16 18:09:04.286273: step 5042, loss = 0.71398 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:09:05.267918 ops/training.py:65 2019-01-16 18:09:05.267802: step 5043, loss = 0.72117 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:09:06.253148 ops/training.py:65 2019-01-16 18:09:06.253007: step 5044, loss = 0.71043 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:09:07.239056 ops/training.py:65 2019-01-16 18:09:07.238946: step 5045, loss = 0.69652 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:09:08.223129 ops/training.py:65 2019-01-16 18:09:08.223032: step 5046, loss = 0.69968 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:09:09.207459 ops/training.py:65 2019-01-16 18:09:09.207346: step 5047, loss = 0.68644 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:09:10.191313 ops/training.py:65 2019-01-16 18:09:10.191235: step 5048, loss = 0.70925 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:09:11.175308 ops/training.py:65 2019-01-16 18:09:11.175230: step 5049, loss = 0.70748 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:09:12.161339 ops/training.py:65 2019-01-16 18:09:12.161266: step 5050, loss = 0.69594 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:09:13.146422 ops/training.py:65 2019-01-16 18:09:13.146324: step 5051, loss = 0.70043 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:09:14.130877 ops/training.py:65 2019-01-16 18:09:14.130762: step 5052, loss = 0.68241 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:09:15.115873 ops/training.py:65 2019-01-16 18:09:15.115764: step 5053, loss = 0.70577 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:09:16.099734 ops/training.py:65 2019-01-16 18:09:16.099630: step 5054, loss = 0.69821 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:09:17.082745 ops/training.py:65 2019-01-16 18:09:17.082639: step 5055, loss = 0.68889 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:09:18.067378 ops/training.py:65 2019-01-16 18:09:18.067268: step 5056, loss = 0.70140 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:09:19.053005 ops/training.py:65 2019-01-16 18:09:19.052900: step 5057, loss = 0.67714 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:09:20.036903 ops/training.py:65 2019-01-16 18:09:20.036829: step 5058, loss = 0.69255 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:09:21.019725 ops/training.py:65 2019-01-16 18:09:21.019659: step 5059, loss = 0.68271 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:09:22.002858 ops/training.py:65 2019-01-16 18:09:22.002751: step 5060, loss = 0.70227 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:09:22.985503 ops/training.py:65 2019-01-16 18:09:22.985393: step 5061, loss = 0.73392 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:09:23.966735 ops/training.py:65 2019-01-16 18:09:23.966643: step 5062, loss = 0.66600 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:09:24.951513 ops/training.py:65 2019-01-16 18:09:24.951401: step 5063, loss = 0.69935 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:09:25.937194 ops/training.py:65 2019-01-16 18:09:25.937086: step 5064, loss = 0.70191 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:09:26.921434 ops/training.py:65 2019-01-16 18:09:26.921329: step 5065, loss = 0.70807 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:09:27.905281 ops/training.py:65 2019-01-16 18:09:27.905220: step 5066, loss = 0.70633 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:09:28.887291 ops/training.py:65 2019-01-16 18:09:28.887221: step 5067, loss = 0.68531 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:09:29.871108 ops/training.py:65 2019-01-16 18:09:29.871032: step 5068, loss = 0.71061 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:09:30.856402 ops/training.py:65 2019-01-16 18:09:30.856295: step 5069, loss = 0.69789 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:09:31.841192 ops/training.py:65 2019-01-16 18:09:31.841088: step 5070, loss = 0.68160 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:09:32.823630 ops/training.py:65 2019-01-16 18:09:32.823521: step 5071, loss = 0.70505 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:09:33.808294 ops/training.py:65 2019-01-16 18:09:33.808194: step 5072, loss = 0.70328 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:09:34.791135 ops/training.py:65 2019-01-16 18:09:34.791029: step 5073, loss = 0.69666 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:09:35.775596 ops/training.py:65 2019-01-16 18:09:35.775505: step 5074, loss = 0.68213 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:09:36.758897 ops/training.py:65 2019-01-16 18:09:36.758790: step 5075, loss = 0.68610 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:09:37.742705 ops/training.py:65 2019-01-16 18:09:37.742597: step 5076, loss = 0.70716 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:09:38.726170 ops/training.py:65 2019-01-16 18:09:38.726077: step 5077, loss = 0.69404 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:09:39.711413 ops/training.py:65 2019-01-16 18:09:39.711321: step 5078, loss = 0.69382 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:09:40.693648 ops/training.py:65 2019-01-16 18:09:40.693543: step 5079, loss = 0.71397 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:09:41.675838 ops/training.py:65 2019-01-16 18:09:41.675738: step 5080, loss = 0.69029 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:09:42.657385 ops/training.py:65 2019-01-16 18:09:42.657287: step 5081, loss = 0.70487 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:09:43.639615 ops/training.py:65 2019-01-16 18:09:43.639501: step 5082, loss = 0.69159 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:09:44.621157 ops/training.py:65 2019-01-16 18:09:44.621056: step 5083, loss = 0.69984 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:09:45.602522 ops/training.py:65 2019-01-16 18:09:45.602421: step 5084, loss = 0.70671 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 18:09:46.584805 ops/training.py:65 2019-01-16 18:09:46.584703: step 5085, loss = 0.68663 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:09:47.569222 ops/training.py:65 2019-01-16 18:09:47.569121: step 5086, loss = 0.69373 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:09:48.551870 ops/training.py:65 2019-01-16 18:09:48.551771: step 5087, loss = 0.69202 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:09:49.534280 ops/training.py:65 2019-01-16 18:09:49.534189: step 5088, loss = 0.69058 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:09:50.516066 ops/training.py:65 2019-01-16 18:09:50.515964: step 5089, loss = 0.69943 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:09:51.499114 ops/training.py:65 2019-01-16 18:09:51.499006: step 5090, loss = 0.70593 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:09:52.483412 ops/training.py:65 2019-01-16 18:09:52.483310: step 5091, loss = 0.68444 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:09:53.466128 ops/training.py:65 2019-01-16 18:09:53.466036: step 5092, loss = 0.71630 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:09:54.447788 ops/training.py:65 2019-01-16 18:09:54.447685: step 5093, loss = 0.68272 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:09:55.431023 ops/training.py:65 2019-01-16 18:09:55.430924: step 5094, loss = 0.70228 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:09:56.413428 ops/training.py:65 2019-01-16 18:09:56.413328: step 5095, loss = 0.70341 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:09:57.398265 ops/training.py:65 2019-01-16 18:09:57.398161: step 5096, loss = 0.68724 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:09:58.382608 ops/training.py:65 2019-01-16 18:09:58.382459: step 5097, loss = 0.72013 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.21875
I8192 2019-01-16 18:09:59.369031 ops/training.py:65 2019-01-16 18:09:59.368927: step 5098, loss = 0.69406 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:10:00.352942 ops/training.py:65 2019-01-16 18:10:00.352811: step 5099, loss = 0.70229 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:10:01.336103 ops/training.py:65 2019-01-16 18:10:01.335981: step 5100, loss = 0.69464 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:10:02.320146 ops/training.py:65 2019-01-16 18:10:02.320002: step 5101, loss = 0.70753 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:10:03.304486 ops/training.py:65 2019-01-16 18:10:03.304378: step 5102, loss = 0.69488 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:10:04.288760 ops/training.py:65 2019-01-16 18:10:04.288675: step 5103, loss = 0.67846 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:10:05.272160 ops/training.py:65 2019-01-16 18:10:05.272058: step 5104, loss = 0.69773 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:10:06.255660 ops/training.py:65 2019-01-16 18:10:06.255562: step 5105, loss = 0.69304 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:10:07.238645 ops/training.py:65 2019-01-16 18:10:07.238536: step 5106, loss = 0.71086 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:10:08.220554 ops/training.py:65 2019-01-16 18:10:08.220456: step 5107, loss = 0.70476 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:10:09.204843 ops/training.py:65 2019-01-16 18:10:09.204737: step 5108, loss = 0.67552 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:10:10.188583 ops/training.py:65 2019-01-16 18:10:10.188476: step 5109, loss = 0.69759 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:10:11.170084 ops/training.py:65 2019-01-16 18:10:11.170002: step 5110, loss = 0.69877 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:10:12.154321 ops/training.py:65 2019-01-16 18:10:12.154241: step 5111, loss = 0.69228 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:10:13.140223 ops/training.py:65 2019-01-16 18:10:13.140126: step 5112, loss = 0.69237 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:10:14.123426 ops/training.py:65 2019-01-16 18:10:14.123294: step 5113, loss = 0.70284 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:10:15.106244 ops/training.py:65 2019-01-16 18:10:15.106132: step 5114, loss = 0.70904 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:10:16.088231 ops/training.py:65 2019-01-16 18:10:16.088127: step 5115, loss = 0.73087 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:10:17.069804 ops/training.py:65 2019-01-16 18:10:17.069704: step 5116, loss = 0.68124 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:10:18.051617 ops/training.py:65 2019-01-16 18:10:18.051511: step 5117, loss = 0.69778 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:10:19.033165 ops/training.py:65 2019-01-16 18:10:19.033069: step 5118, loss = 0.70405 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:10:20.016125 ops/training.py:65 2019-01-16 18:10:20.016015: step 5119, loss = 0.70440 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:10:20.999343 ops/training.py:65 2019-01-16 18:10:20.999240: step 5120, loss = 0.69318 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:10:21.980987 ops/training.py:65 2019-01-16 18:10:21.980889: step 5121, loss = 0.69301 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:10:22.963305 ops/training.py:65 2019-01-16 18:10:22.963203: step 5122, loss = 0.70075 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:10:23.945908 ops/training.py:65 2019-01-16 18:10:23.945813: step 5123, loss = 0.68784 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:10:24.929316 ops/training.py:65 2019-01-16 18:10:24.929207: step 5124, loss = 0.68052 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:10:25.915825 ops/training.py:65 2019-01-16 18:10:25.915722: step 5125, loss = 0.70102 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:10:26.899764 ops/training.py:65 2019-01-16 18:10:26.899665: step 5126, loss = 0.67506 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:10:27.883437 ops/training.py:65 2019-01-16 18:10:27.883335: step 5127, loss = 0.69004 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:10:28.866195 ops/training.py:65 2019-01-16 18:10:28.866093: step 5128, loss = 0.68646 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:10:29.847900 ops/training.py:65 2019-01-16 18:10:29.847775: step 5129, loss = 0.68642 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:10:30.830738 ops/training.py:65 2019-01-16 18:10:30.830596: step 5130, loss = 0.70009 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:10:31.812478 ops/training.py:65 2019-01-16 18:10:31.812372: step 5131, loss = 0.70444 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:10:32.797008 ops/training.py:65 2019-01-16 18:10:32.796897: step 5132, loss = 0.68758 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:10:33.781279 ops/training.py:65 2019-01-16 18:10:33.781177: step 5133, loss = 0.71748 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:10:34.764518 ops/training.py:65 2019-01-16 18:10:34.764414: step 5134, loss = 0.70260 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:10:35.748178 ops/training.py:65 2019-01-16 18:10:35.748073: step 5135, loss = 0.68624 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:10:36.729613 ops/training.py:65 2019-01-16 18:10:36.729516: step 5136, loss = 0.68677 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:10:37.712520 ops/training.py:65 2019-01-16 18:10:37.712429: step 5137, loss = 0.66452 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:10:38.697335 ops/training.py:65 2019-01-16 18:10:38.697240: step 5138, loss = 0.69415 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:10:39.680655 ops/training.py:65 2019-01-16 18:10:39.680556: step 5139, loss = 0.70692 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:10:40.664098 ops/training.py:65 2019-01-16 18:10:40.663997: step 5140, loss = 0.70034 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:10:41.647641 ops/training.py:65 2019-01-16 18:10:41.647540: step 5141, loss = 0.69650 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:10:42.630760 ops/training.py:65 2019-01-16 18:10:42.630652: step 5142, loss = 0.68585 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:10:43.614168 ops/training.py:65 2019-01-16 18:10:43.614067: step 5143, loss = 0.67342 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:10:44.597923 ops/training.py:65 2019-01-16 18:10:44.597823: step 5144, loss = 0.69418 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:10:45.583676 ops/training.py:65 2019-01-16 18:10:45.583582: step 5145, loss = 0.69805 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:10:46.568912 ops/training.py:65 2019-01-16 18:10:46.568829: step 5146, loss = 0.68133 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:10:47.551851 ops/training.py:65 2019-01-16 18:10:47.551749: step 5147, loss = 0.69901 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:10:48.534073 ops/training.py:65 2019-01-16 18:10:48.533979: step 5148, loss = 0.71682 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:10:49.516062 ops/training.py:65 2019-01-16 18:10:49.515964: step 5149, loss = 0.68681 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:10:50.498006 ops/training.py:65 2019-01-16 18:10:50.497908: step 5150, loss = 0.71590 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:10:51.480196 ops/training.py:65 2019-01-16 18:10:51.480098: step 5151, loss = 0.69933 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:10:52.461319 ops/training.py:65 2019-01-16 18:10:52.461208: step 5152, loss = 0.67362 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:10:53.442378 ops/training.py:65 2019-01-16 18:10:53.442289: step 5153, loss = 0.69642 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:10:54.425470 ops/training.py:65 2019-01-16 18:10:54.425368: step 5154, loss = 0.72573 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:10:55.409575 ops/training.py:65 2019-01-16 18:10:55.409465: step 5155, loss = 0.70308 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:10:56.395349 ops/training.py:65 2019-01-16 18:10:56.395245: step 5156, loss = 0.69318 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:10:57.379283 ops/training.py:65 2019-01-16 18:10:57.379181: step 5157, loss = 0.70929 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:10:58.364024 ops/training.py:65 2019-01-16 18:10:58.363923: step 5158, loss = 0.67327 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:10:59.347489 ops/training.py:65 2019-01-16 18:10:59.347385: step 5159, loss = 0.68872 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:11:00.331743 ops/training.py:65 2019-01-16 18:11:00.331644: step 5160, loss = 0.71278 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:11:01.314289 ops/training.py:65 2019-01-16 18:11:01.314191: step 5161, loss = 0.69329 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:11:02.298580 ops/training.py:65 2019-01-16 18:11:02.298476: step 5162, loss = 0.70828 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:11:03.281673 ops/training.py:65 2019-01-16 18:11:03.281574: step 5163, loss = 0.70090 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:11:04.263863 ops/training.py:65 2019-01-16 18:11:04.263794: step 5164, loss = 0.67310 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:11:05.248051 ops/training.py:65 2019-01-16 18:11:05.247980: step 5165, loss = 0.70287 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:11:06.231006 ops/training.py:65 2019-01-16 18:11:06.230904: step 5166, loss = 0.70061 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:11:07.212795 ops/training.py:65 2019-01-16 18:11:07.212696: step 5167, loss = 0.70941 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:11:08.198460 ops/training.py:65 2019-01-16 18:11:08.198355: step 5168, loss = 0.68944 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:11:09.183416 ops/training.py:65 2019-01-16 18:11:09.183319: step 5169, loss = 0.71864 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:11:10.166742 ops/training.py:65 2019-01-16 18:11:10.166633: step 5170, loss = 0.69012 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:11:11.152038 ops/training.py:65 2019-01-16 18:11:11.151941: step 5171, loss = 0.68242 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:11:12.133784 ops/training.py:65 2019-01-16 18:11:12.133681: step 5172, loss = 0.71746 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:11:13.116212 ops/training.py:65 2019-01-16 18:11:13.116120: step 5173, loss = 0.69141 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:11:14.099049 ops/training.py:65 2019-01-16 18:11:14.098946: step 5174, loss = 0.67983 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:11:15.081623 ops/training.py:65 2019-01-16 18:11:15.081516: step 5175, loss = 0.69599 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:11:16.064996 ops/training.py:65 2019-01-16 18:11:16.064895: step 5176, loss = 0.69342 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:11:17.047902 ops/training.py:65 2019-01-16 18:11:17.047804: step 5177, loss = 0.70341 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:11:18.030739 ops/training.py:65 2019-01-16 18:11:18.030631: step 5178, loss = 0.70064 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:11:19.012114 ops/training.py:65 2019-01-16 18:11:19.012016: step 5179, loss = 0.68341 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:11:19.995715 ops/training.py:65 2019-01-16 18:11:19.995614: step 5180, loss = 0.70329 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:11:20.977866 ops/training.py:65 2019-01-16 18:11:20.977768: step 5181, loss = 0.69944 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:11:21.960342 ops/training.py:65 2019-01-16 18:11:21.960241: step 5182, loss = 0.69734 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:11:22.943029 ops/training.py:65 2019-01-16 18:11:22.942921: step 5183, loss = 0.69444 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:11:23.926768 ops/training.py:65 2019-01-16 18:11:23.926671: step 5184, loss = 0.69989 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:11:24.908890 ops/training.py:65 2019-01-16 18:11:24.908824: step 5185, loss = 0.68920 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:11:25.892597 ops/training.py:65 2019-01-16 18:11:25.892512: step 5186, loss = 0.66306 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:11:26.876719 ops/training.py:65 2019-01-16 18:11:26.876616: step 5187, loss = 0.68574 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:11:27.861536 ops/training.py:65 2019-01-16 18:11:27.861437: step 5188, loss = 0.69134 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:11:28.844652 ops/training.py:65 2019-01-16 18:11:28.844547: step 5189, loss = 0.71892 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:11:29.828422 ops/training.py:65 2019-01-16 18:11:29.828329: step 5190, loss = 0.68875 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:11:30.811558 ops/training.py:65 2019-01-16 18:11:30.811461: step 5191, loss = 0.67920 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:11:31.793839 ops/training.py:65 2019-01-16 18:11:31.793742: step 5192, loss = 0.70272 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:11:32.777520 ops/training.py:65 2019-01-16 18:11:32.777422: step 5193, loss = 0.70865 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:11:33.759391 ops/training.py:65 2019-01-16 18:11:33.759291: step 5194, loss = 0.72578 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:11:34.741878 ops/training.py:65 2019-01-16 18:11:34.741782: step 5195, loss = 0.68701 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:11:35.725127 ops/training.py:65 2019-01-16 18:11:35.725023: step 5196, loss = 0.70552 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:11:36.710499 ops/training.py:65 2019-01-16 18:11:36.710404: step 5197, loss = 0.69592 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:11:37.695508 ops/training.py:65 2019-01-16 18:11:37.695407: step 5198, loss = 0.73847 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:11:38.678681 ops/training.py:65 2019-01-16 18:11:38.678601: step 5199, loss = 0.70967 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:11:39.660042 ops/training.py:65 2019-01-16 18:11:39.659926: step 5200, loss = 0.68483 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:11:40.641706 ops/training.py:65 2019-01-16 18:11:40.641564: step 5201, loss = 0.70115 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:11:41.622911 ops/training.py:65 2019-01-16 18:11:41.622812: step 5202, loss = 0.68680 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:11:42.605125 ops/training.py:65 2019-01-16 18:11:42.605016: step 5203, loss = 0.71594 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:11:43.587583 ops/training.py:65 2019-01-16 18:11:43.587482: step 5204, loss = 0.68053 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:11:44.569789 ops/training.py:65 2019-01-16 18:11:44.569658: step 5205, loss = 0.69295 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:11:45.552062 ops/training.py:65 2019-01-16 18:11:45.551954: step 5206, loss = 0.69072 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:11:46.533677 ops/training.py:65 2019-01-16 18:11:46.533575: step 5207, loss = 0.72727 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:11:47.516762 ops/training.py:65 2019-01-16 18:11:47.516661: step 5208, loss = 0.73137 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:11:48.500433 ops/training.py:65 2019-01-16 18:11:48.500328: step 5209, loss = 0.70263 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:11:49.483272 ops/training.py:65 2019-01-16 18:11:49.483176: step 5210, loss = 0.67688 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:11:50.467455 ops/training.py:65 2019-01-16 18:11:50.467356: step 5211, loss = 0.70335 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:11:51.451093 ops/training.py:65 2019-01-16 18:11:51.450986: step 5212, loss = 0.69024 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:11:52.433557 ops/training.py:65 2019-01-16 18:11:52.433418: step 5213, loss = 0.71522 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:11:53.417584 ops/training.py:65 2019-01-16 18:11:53.417493: step 5214, loss = 0.69794 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:11:54.402962 ops/training.py:65 2019-01-16 18:11:54.402863: step 5215, loss = 0.69624 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:11:55.387505 ops/training.py:65 2019-01-16 18:11:55.387396: step 5216, loss = 0.70474 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:11:56.372566 ops/training.py:65 2019-01-16 18:11:56.372479: step 5217, loss = 0.68074 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:11:57.354966 ops/training.py:65 2019-01-16 18:11:57.354827: step 5218, loss = 0.69162 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:11:58.337745 ops/training.py:65 2019-01-16 18:11:58.337601: step 5219, loss = 0.68644 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:11:59.319478 ops/training.py:65 2019-01-16 18:11:59.319365: step 5220, loss = 0.69080 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:12:00.301610 ops/training.py:65 2019-01-16 18:12:00.301501: step 5221, loss = 0.68671 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:12:01.283563 ops/training.py:65 2019-01-16 18:12:01.283457: step 5222, loss = 0.70032 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:12:02.265840 ops/training.py:65 2019-01-16 18:12:02.265728: step 5223, loss = 0.70148 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:12:03.247703 ops/training.py:65 2019-01-16 18:12:03.247603: step 5224, loss = 0.72166 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:12:04.229501 ops/training.py:65 2019-01-16 18:12:04.229405: step 5225, loss = 0.70144 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:12:05.213841 ops/training.py:65 2019-01-16 18:12:05.213732: step 5226, loss = 0.67862 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:12:06.198629 ops/training.py:65 2019-01-16 18:12:06.198528: step 5227, loss = 0.70711 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:12:07.182561 ops/training.py:65 2019-01-16 18:12:07.182452: step 5228, loss = 0.71088 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:12:08.166788 ops/training.py:65 2019-01-16 18:12:08.166689: step 5229, loss = 0.69392 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:12:09.149406 ops/training.py:65 2019-01-16 18:12:09.149288: step 5230, loss = 0.69856 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:12:10.132423 ops/training.py:65 2019-01-16 18:12:10.132326: step 5231, loss = 0.70126 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:12:11.113941 ops/training.py:65 2019-01-16 18:12:11.113842: step 5232, loss = 0.69741 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:12:12.096075 ops/training.py:65 2019-01-16 18:12:12.095932: step 5233, loss = 0.66875 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:12:13.079396 ops/training.py:65 2019-01-16 18:12:13.079298: step 5234, loss = 0.71778 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 18:12:14.064931 ops/training.py:65 2019-01-16 18:12:14.064823: step 5235, loss = 0.69022 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:12:15.049672 ops/training.py:65 2019-01-16 18:12:15.049565: step 5236, loss = 0.69987 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:12:16.032735 ops/training.py:65 2019-01-16 18:12:16.032628: step 5237, loss = 0.67602 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:12:17.017723 ops/training.py:65 2019-01-16 18:12:17.017618: step 5238, loss = 0.70908 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:12:18.003168 ops/training.py:65 2019-01-16 18:12:18.003062: step 5239, loss = 0.67989 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:12:18.988541 ops/training.py:65 2019-01-16 18:12:18.988436: step 5240, loss = 0.70393 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:12:19.970372 ops/training.py:65 2019-01-16 18:12:19.970236: step 5241, loss = 0.69777 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:12:20.953657 ops/training.py:65 2019-01-16 18:12:20.953550: step 5242, loss = 0.68576 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:12:21.940211 ops/training.py:65 2019-01-16 18:12:21.940101: step 5243, loss = 0.72173 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:12:22.924840 ops/training.py:65 2019-01-16 18:12:22.924733: step 5244, loss = 0.68819 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:12:23.907463 ops/training.py:65 2019-01-16 18:12:23.907367: step 5245, loss = 0.70892 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:12:24.891682 ops/training.py:65 2019-01-16 18:12:24.891557: step 5246, loss = 0.67879 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:12:25.875913 ops/training.py:65 2019-01-16 18:12:25.875772: step 5247, loss = 0.69925 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:12:26.859267 ops/training.py:65 2019-01-16 18:12:26.859170: step 5248, loss = 0.70066 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:12:27.841324 ops/training.py:65 2019-01-16 18:12:27.841212: step 5249, loss = 0.68885 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:12:28.824631 ops/training.py:65 2019-01-16 18:12:28.824490: step 5250, loss = 0.67812 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:12:29.808992 ops/training.py:65 2019-01-16 18:12:29.808858: step 5251, loss = 0.69849 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:12:30.791681 ops/training.py:65 2019-01-16 18:12:30.791585: step 5252, loss = 0.70352 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:12:31.772796 ops/training.py:65 2019-01-16 18:12:31.772714: step 5253, loss = 0.70743 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:12:32.756911 ops/training.py:65 2019-01-16 18:12:32.756831: step 5254, loss = 0.71995 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:12:33.741024 ops/training.py:65 2019-01-16 18:12:33.740923: step 5255, loss = 0.68615 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:12:34.725225 ops/training.py:65 2019-01-16 18:12:34.725093: step 5256, loss = 0.69990 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:12:35.711175 ops/training.py:65 2019-01-16 18:12:35.711075: step 5257, loss = 0.70728 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:12:36.693578 ops/training.py:65 2019-01-16 18:12:36.693479: step 5258, loss = 0.66648 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:12:37.677930 ops/training.py:65 2019-01-16 18:12:37.677835: step 5259, loss = 0.69141 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:12:38.660189 ops/training.py:65 2019-01-16 18:12:38.660100: step 5260, loss = 0.64544 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:12:39.642756 ops/training.py:65 2019-01-16 18:12:39.642640: step 5261, loss = 0.71855 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:12:40.623756 ops/training.py:65 2019-01-16 18:12:40.623647: step 5262, loss = 0.70737 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:12:41.606077 ops/training.py:65 2019-01-16 18:12:41.605973: step 5263, loss = 0.68221 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:12:42.588039 ops/training.py:65 2019-01-16 18:12:42.587928: step 5264, loss = 0.74821 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 18:12:43.570889 ops/training.py:65 2019-01-16 18:12:43.570771: step 5265, loss = 0.69871 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:12:44.554108 ops/training.py:65 2019-01-16 18:12:44.553965: step 5266, loss = 0.69781 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:12:45.539761 ops/training.py:65 2019-01-16 18:12:45.539655: step 5267, loss = 0.70468 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:12:46.524755 ops/training.py:65 2019-01-16 18:12:46.524663: step 5268, loss = 0.69936 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:12:47.509897 ops/training.py:65 2019-01-16 18:12:47.509790: step 5269, loss = 0.67671 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:12:48.493183 ops/training.py:65 2019-01-16 18:12:48.493049: step 5270, loss = 0.69727 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:12:49.475854 ops/training.py:65 2019-01-16 18:12:49.475749: step 5271, loss = 0.65125 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.75
I8192 2019-01-16 18:12:50.459161 ops/training.py:65 2019-01-16 18:12:50.459066: step 5272, loss = 0.69000 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:12:51.442683 ops/training.py:65 2019-01-16 18:12:51.442581: step 5273, loss = 0.70347 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:12:52.425707 ops/training.py:65 2019-01-16 18:12:52.425635: step 5274, loss = 0.71925 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:12:53.408109 ops/training.py:65 2019-01-16 18:12:53.408044: step 5275, loss = 0.71104 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:12:54.388375 ops/training.py:65 2019-01-16 18:12:54.388311: step 5276, loss = 0.69880 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:12:55.368501 ops/training.py:65 2019-01-16 18:12:55.368435: step 5277, loss = 0.70048 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:12:56.351796 ops/training.py:65 2019-01-16 18:12:56.351716: step 5278, loss = 0.72873 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:12:57.335710 ops/training.py:65 2019-01-16 18:12:57.335609: step 5279, loss = 0.69657 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:12:58.317980 ops/training.py:65 2019-01-16 18:12:58.317877: step 5280, loss = 0.70943 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:12:59.300794 ops/training.py:65 2019-01-16 18:12:59.300689: step 5281, loss = 0.68644 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:13:00.282563 ops/training.py:65 2019-01-16 18:13:00.282469: step 5282, loss = 0.72557 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:13:01.266522 ops/training.py:65 2019-01-16 18:13:01.266421: step 5283, loss = 0.71055 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:13:02.249940 ops/training.py:65 2019-01-16 18:13:02.249844: step 5284, loss = 0.70822 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:13:03.232708 ops/training.py:65 2019-01-16 18:13:03.232608: step 5285, loss = 0.68769 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:13:04.215542 ops/training.py:65 2019-01-16 18:13:04.215440: step 5286, loss = 0.68320 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:13:05.197911 ops/training.py:65 2019-01-16 18:13:05.197811: step 5287, loss = 0.69649 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:13:06.182131 ops/training.py:65 2019-01-16 18:13:06.182031: step 5288, loss = 0.68174 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:13:07.165283 ops/training.py:65 2019-01-16 18:13:07.165182: step 5289, loss = 0.69856 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:13:08.147091 ops/training.py:65 2019-01-16 18:13:08.147004: step 5290, loss = 0.69183 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:13:09.129335 ops/training.py:65 2019-01-16 18:13:09.129252: step 5291, loss = 0.74438 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:13:10.113497 ops/training.py:65 2019-01-16 18:13:10.113394: step 5292, loss = 0.68386 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:13:11.097200 ops/training.py:65 2019-01-16 18:13:11.097102: step 5293, loss = 0.71070 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:13:12.079593 ops/training.py:65 2019-01-16 18:13:12.079536: step 5294, loss = 0.68374 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:13:13.063905 ops/training.py:65 2019-01-16 18:13:13.063836: step 5295, loss = 0.70828 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:13:14.048568 ops/training.py:65 2019-01-16 18:13:14.048467: step 5296, loss = 0.69019 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:13:15.032674 ops/training.py:65 2019-01-16 18:13:15.032574: step 5297, loss = 0.68225 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:13:16.014774 ops/training.py:65 2019-01-16 18:13:16.014639: step 5298, loss = 0.70017 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:13:16.997303 ops/training.py:65 2019-01-16 18:13:16.997202: step 5299, loss = 0.69407 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:13:17.980541 ops/training.py:65 2019-01-16 18:13:17.980434: step 5300, loss = 0.72080 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:13:18.963161 ops/training.py:65 2019-01-16 18:13:18.963063: step 5301, loss = 0.69461 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:13:19.947203 ops/training.py:65 2019-01-16 18:13:19.947056: step 5302, loss = 0.70311 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:13:20.930672 ops/training.py:65 2019-01-16 18:13:20.930603: step 5303, loss = 0.68297 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:13:21.915588 ops/training.py:65 2019-01-16 18:13:21.915497: step 5304, loss = 0.71345 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:13:22.898659 ops/training.py:65 2019-01-16 18:13:22.898561: step 5305, loss = 0.69824 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:13:23.882773 ops/training.py:65 2019-01-16 18:13:23.882685: step 5306, loss = 0.69009 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:13:24.868061 ops/training.py:65 2019-01-16 18:13:24.867964: step 5307, loss = 0.70724 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:13:25.852708 ops/training.py:65 2019-01-16 18:13:25.852612: step 5308, loss = 0.70628 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:13:26.836651 ops/training.py:65 2019-01-16 18:13:26.836555: step 5309, loss = 0.68294 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:13:27.820748 ops/training.py:65 2019-01-16 18:13:27.820642: step 5310, loss = 0.67265 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:13:28.803734 ops/training.py:65 2019-01-16 18:13:28.803664: step 5311, loss = 0.67985 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:13:29.786910 ops/training.py:65 2019-01-16 18:13:29.786830: step 5312, loss = 0.67302 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:13:30.770228 ops/training.py:65 2019-01-16 18:13:30.770127: step 5313, loss = 0.68730 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:13:31.754515 ops/training.py:65 2019-01-16 18:13:31.754406: step 5314, loss = 0.70185 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:13:32.739950 ops/training.py:65 2019-01-16 18:13:32.739840: step 5315, loss = 0.69397 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:13:33.725175 ops/training.py:65 2019-01-16 18:13:33.725074: step 5316, loss = 0.70642 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:13:34.710146 ops/training.py:65 2019-01-16 18:13:34.710045: step 5317, loss = 0.68819 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:13:35.693710 ops/training.py:65 2019-01-16 18:13:35.693639: step 5318, loss = 0.67565 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:13:36.676510 ops/training.py:65 2019-01-16 18:13:36.676445: step 5319, loss = 0.71470 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:13:37.658403 ops/training.py:65 2019-01-16 18:13:37.658337: step 5320, loss = 0.74946 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:13:38.639939 ops/training.py:65 2019-01-16 18:13:38.639873: step 5321, loss = 0.70292 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:13:39.623006 ops/training.py:65 2019-01-16 18:13:39.622937: step 5322, loss = 0.70528 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:13:40.605645 ops/training.py:65 2019-01-16 18:13:40.605581: step 5323, loss = 0.72013 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:13:41.589113 ops/training.py:65 2019-01-16 18:13:41.589004: step 5324, loss = 0.70853 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:13:42.571624 ops/training.py:65 2019-01-16 18:13:42.571520: step 5325, loss = 0.69040 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:13:43.553344 ops/training.py:65 2019-01-16 18:13:43.553245: step 5326, loss = 0.71962 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:13:44.536642 ops/training.py:65 2019-01-16 18:13:44.536536: step 5327, loss = 0.72204 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:13:45.519513 ops/training.py:65 2019-01-16 18:13:45.519372: step 5328, loss = 0.65997 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:13:46.504040 ops/training.py:65 2019-01-16 18:13:46.503932: step 5329, loss = 0.70881 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:13:47.489860 ops/training.py:65 2019-01-16 18:13:47.489762: step 5330, loss = 0.74119 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:13:48.474986 ops/training.py:65 2019-01-16 18:13:48.474885: step 5331, loss = 0.68050 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:13:49.458401 ops/training.py:65 2019-01-16 18:13:49.458304: step 5332, loss = 0.70867 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:13:50.440958 ops/training.py:65 2019-01-16 18:13:50.440858: step 5333, loss = 0.71938 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:13:51.422939 ops/training.py:65 2019-01-16 18:13:51.422839: step 5334, loss = 0.69216 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:13:52.405630 ops/training.py:65 2019-01-16 18:13:52.405522: step 5335, loss = 0.70407 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:13:53.389495 ops/training.py:65 2019-01-16 18:13:53.389374: step 5336, loss = 0.69340 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:13:54.372092 ops/training.py:65 2019-01-16 18:13:54.371996: step 5337, loss = 0.70758 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:13:55.354493 ops/training.py:65 2019-01-16 18:13:55.354389: step 5338, loss = 0.68811 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:13:56.339055 ops/training.py:65 2019-01-16 18:13:56.338957: step 5339, loss = 0.71323 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:13:57.323042 ops/training.py:65 2019-01-16 18:13:57.322949: step 5340, loss = 0.69236 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:13:58.306784 ops/training.py:65 2019-01-16 18:13:58.306688: step 5341, loss = 0.71781 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:13:59.290645 ops/training.py:65 2019-01-16 18:13:59.290535: step 5342, loss = 0.67711 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:14:00.272957 ops/training.py:65 2019-01-16 18:14:00.272869: step 5343, loss = 0.69229 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:14:01.255694 ops/training.py:65 2019-01-16 18:14:01.255606: step 5344, loss = 0.71035 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:14:02.238217 ops/training.py:65 2019-01-16 18:14:02.238126: step 5345, loss = 0.71431 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:14:03.220420 ops/training.py:65 2019-01-16 18:14:03.220319: step 5346, loss = 0.69876 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:14:04.201802 ops/training.py:65 2019-01-16 18:14:04.201712: step 5347, loss = 0.67116 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:14:05.184775 ops/training.py:65 2019-01-16 18:14:05.184638: step 5348, loss = 0.72575 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:14:06.169479 ops/training.py:65 2019-01-16 18:14:06.169345: step 5349, loss = 0.70155 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:14:07.153215 ops/training.py:65 2019-01-16 18:14:07.153112: step 5350, loss = 0.69087 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:14:08.137666 ops/training.py:65 2019-01-16 18:14:08.137532: step 5351, loss = 0.67346 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:14:09.120602 ops/training.py:65 2019-01-16 18:14:09.120498: step 5352, loss = 0.66592 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:14:10.105224 ops/training.py:65 2019-01-16 18:14:10.105087: step 5353, loss = 0.72413 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:14:11.090326 ops/training.py:65 2019-01-16 18:14:11.090217: step 5354, loss = 0.71736 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:14:12.072951 ops/training.py:65 2019-01-16 18:14:12.072850: step 5355, loss = 0.68919 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:14:13.057422 ops/training.py:65 2019-01-16 18:14:13.057327: step 5356, loss = 0.70304 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:14:14.042835 ops/training.py:65 2019-01-16 18:14:14.042741: step 5357, loss = 0.68156 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:14:15.028133 ops/training.py:65 2019-01-16 18:14:15.027986: step 5358, loss = 0.68216 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:14:16.013492 ops/training.py:65 2019-01-16 18:14:16.013387: step 5359, loss = 0.68773 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:14:16.995942 ops/training.py:65 2019-01-16 18:14:16.995862: step 5360, loss = 0.69570 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:14:17.979857 ops/training.py:65 2019-01-16 18:14:17.979778: step 5361, loss = 0.70799 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:14:18.963076 ops/training.py:65 2019-01-16 18:14:18.962969: step 5362, loss = 0.68813 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:14:19.944912 ops/training.py:65 2019-01-16 18:14:19.944811: step 5363, loss = 0.68766 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:14:20.926840 ops/training.py:65 2019-01-16 18:14:20.926744: step 5364, loss = 0.68443 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:14:21.909175 ops/training.py:65 2019-01-16 18:14:21.909075: step 5365, loss = 0.68660 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:14:22.891913 ops/training.py:65 2019-01-16 18:14:22.891815: step 5366, loss = 0.68325 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:14:23.873961 ops/training.py:65 2019-01-16 18:14:23.873869: step 5367, loss = 0.70294 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:14:24.858325 ops/training.py:65 2019-01-16 18:14:24.858224: step 5368, loss = 0.71770 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:14:25.841634 ops/training.py:65 2019-01-16 18:14:25.841530: step 5369, loss = 0.70549 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:14:26.825322 ops/training.py:65 2019-01-16 18:14:26.825241: step 5370, loss = 0.68037 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:14:27.809264 ops/training.py:65 2019-01-16 18:14:27.809160: step 5371, loss = 0.73665 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:14:28.793877 ops/training.py:65 2019-01-16 18:14:28.793776: step 5372, loss = 0.69978 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:14:29.775459 ops/training.py:65 2019-01-16 18:14:29.775362: step 5373, loss = 0.70953 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:14:30.757834 ops/training.py:65 2019-01-16 18:14:30.757738: step 5374, loss = 0.69992 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:14:31.740885 ops/training.py:65 2019-01-16 18:14:31.740777: step 5375, loss = 0.69715 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:14:32.723253 ops/training.py:65 2019-01-16 18:14:32.723149: step 5376, loss = 0.70588 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:14:33.705296 ops/training.py:65 2019-01-16 18:14:33.705190: step 5377, loss = 0.70649 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:14:34.687895 ops/training.py:65 2019-01-16 18:14:34.687790: step 5378, loss = 0.67448 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:14:35.669720 ops/training.py:65 2019-01-16 18:14:35.669615: step 5379, loss = 0.69463 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:14:36.651252 ops/training.py:65 2019-01-16 18:14:36.651167: step 5380, loss = 0.68994 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:14:37.633490 ops/training.py:65 2019-01-16 18:14:37.633381: step 5381, loss = 0.70026 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:14:38.615306 ops/training.py:65 2019-01-16 18:14:38.615218: step 5382, loss = 0.70330 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:14:39.597559 ops/training.py:65 2019-01-16 18:14:39.597457: step 5383, loss = 0.69462 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:14:40.581223 ops/training.py:65 2019-01-16 18:14:40.581121: step 5384, loss = 0.68633 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:14:41.565018 ops/training.py:65 2019-01-16 18:14:41.564920: step 5385, loss = 0.70339 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:14:42.547751 ops/training.py:65 2019-01-16 18:14:42.547666: step 5386, loss = 0.68368 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:14:43.534535 ops/training.py:65 2019-01-16 18:14:43.534438: step 5387, loss = 0.69566 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:14:44.518448 ops/training.py:65 2019-01-16 18:14:44.518347: step 5388, loss = 0.69189 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:14:45.502924 ops/training.py:65 2019-01-16 18:14:45.502830: step 5389, loss = 0.68584 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:14:46.486378 ops/training.py:65 2019-01-16 18:14:46.486283: step 5390, loss = 0.69011 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:14:47.471553 ops/training.py:65 2019-01-16 18:14:47.471488: step 5391, loss = 0.68647 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:14:48.454590 ops/training.py:65 2019-01-16 18:14:48.454483: step 5392, loss = 0.68000 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:14:49.437388 ops/training.py:65 2019-01-16 18:14:49.437283: step 5393, loss = 0.70256 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:14:50.419006 ops/training.py:65 2019-01-16 18:14:50.418901: step 5394, loss = 0.68274 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:14:51.402598 ops/training.py:65 2019-01-16 18:14:51.402487: step 5395, loss = 0.68746 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:14:52.386164 ops/training.py:65 2019-01-16 18:14:52.386061: step 5396, loss = 0.69284 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:14:53.369957 ops/training.py:65 2019-01-16 18:14:53.369876: step 5397, loss = 0.70029 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:14:54.351225 ops/training.py:65 2019-01-16 18:14:54.351125: step 5398, loss = 0.71535 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:14:55.334751 ops/training.py:65 2019-01-16 18:14:55.334622: step 5399, loss = 0.68498 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:14:56.316401 ops/training.py:65 2019-01-16 18:14:56.316295: step 5400, loss = 0.69778 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:14:57.298454 ops/training.py:65 2019-01-16 18:14:57.298349: step 5401, loss = 0.69195 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:14:58.280782 ops/training.py:65 2019-01-16 18:14:58.280678: step 5402, loss = 0.69761 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:14:59.263278 ops/training.py:65 2019-01-16 18:14:59.263173: step 5403, loss = 0.70417 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:15:00.246622 ops/training.py:65 2019-01-16 18:15:00.246535: step 5404, loss = 0.69747 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:15:01.232284 ops/training.py:65 2019-01-16 18:15:01.232181: step 5405, loss = 0.68347 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:15:02.215100 ops/training.py:65 2019-01-16 18:15:02.215002: step 5406, loss = 0.69032 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:15:03.198188 ops/training.py:65 2019-01-16 18:15:03.198086: step 5407, loss = 0.67328 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:15:04.180628 ops/training.py:65 2019-01-16 18:15:04.180523: step 5408, loss = 0.70650 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:15:05.164200 ops/training.py:65 2019-01-16 18:15:05.164091: step 5409, loss = 0.69871 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:15:06.145897 ops/training.py:65 2019-01-16 18:15:06.145808: step 5410, loss = 0.69069 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:15:07.128012 ops/training.py:65 2019-01-16 18:15:07.127909: step 5411, loss = 0.70640 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:15:08.110425 ops/training.py:65 2019-01-16 18:15:08.110321: step 5412, loss = 0.69032 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:15:09.095482 ops/training.py:65 2019-01-16 18:15:09.095373: step 5413, loss = 0.69058 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:15:10.079905 ops/training.py:65 2019-01-16 18:15:10.079804: step 5414, loss = 0.70169 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:15:11.064008 ops/training.py:65 2019-01-16 18:15:11.063905: step 5415, loss = 0.69796 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:15:12.049960 ops/training.py:65 2019-01-16 18:15:12.049870: step 5416, loss = 0.69675 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:15:13.033259 ops/training.py:65 2019-01-16 18:15:13.033159: step 5417, loss = 0.71476 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:15:14.016767 ops/training.py:65 2019-01-16 18:15:14.016666: step 5418, loss = 0.69357 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:15:14.997437 ops/training.py:65 2019-01-16 18:15:14.997329: step 5419, loss = 0.69011 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:15:15.979843 ops/training.py:65 2019-01-16 18:15:15.979750: step 5420, loss = 0.67590 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:15:16.962340 ops/training.py:65 2019-01-16 18:15:16.962239: step 5421, loss = 0.68895 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:15:17.948309 ops/training.py:65 2019-01-16 18:15:17.948201: step 5422, loss = 0.70635 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:15:18.933053 ops/training.py:65 2019-01-16 18:15:18.932967: step 5423, loss = 0.70682 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:15:19.917024 ops/training.py:65 2019-01-16 18:15:19.916934: step 5424, loss = 0.69743 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:15:20.901198 ops/training.py:65 2019-01-16 18:15:20.901108: step 5425, loss = 0.67389 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:15:21.884996 ops/training.py:65 2019-01-16 18:15:21.884903: step 5426, loss = 0.71755 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:15:22.867430 ops/training.py:65 2019-01-16 18:15:22.867324: step 5427, loss = 0.70710 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:15:23.850406 ops/training.py:65 2019-01-16 18:15:23.850316: step 5428, loss = 0.69435 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:15:24.834026 ops/training.py:65 2019-01-16 18:15:24.833916: step 5429, loss = 0.71393 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:15:25.819314 ops/training.py:65 2019-01-16 18:15:25.819216: step 5430, loss = 0.69184 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:15:26.803945 ops/training.py:65 2019-01-16 18:15:26.803840: step 5431, loss = 0.71154 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:15:27.788870 ops/training.py:65 2019-01-16 18:15:27.788762: step 5432, loss = 0.69195 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:15:28.772468 ops/training.py:65 2019-01-16 18:15:28.772360: step 5433, loss = 0.70225 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:15:29.757240 ops/training.py:65 2019-01-16 18:15:29.757143: step 5434, loss = 0.68816 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:15:30.741858 ops/training.py:65 2019-01-16 18:15:30.741755: step 5435, loss = 0.68147 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:15:31.728830 ops/training.py:65 2019-01-16 18:15:31.728728: step 5436, loss = 0.70255 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:15:32.712263 ops/training.py:65 2019-01-16 18:15:32.712159: step 5437, loss = 0.69748 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:15:33.694123 ops/training.py:65 2019-01-16 18:15:33.694027: step 5438, loss = 0.70346 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:15:34.675497 ops/training.py:65 2019-01-16 18:15:34.675418: step 5439, loss = 0.67980 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:15:35.658132 ops/training.py:65 2019-01-16 18:15:35.658023: step 5440, loss = 0.70399 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:15:36.642504 ops/training.py:65 2019-01-16 18:15:36.642400: step 5441, loss = 0.68865 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:15:37.627311 ops/training.py:65 2019-01-16 18:15:37.627200: step 5442, loss = 0.70293 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:15:38.612990 ops/training.py:65 2019-01-16 18:15:38.612898: step 5443, loss = 0.70226 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:15:39.596555 ops/training.py:65 2019-01-16 18:15:39.596453: step 5444, loss = 0.70553 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:15:40.578385 ops/training.py:65 2019-01-16 18:15:40.578279: step 5445, loss = 0.67772 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:15:41.560529 ops/training.py:65 2019-01-16 18:15:41.560424: step 5446, loss = 0.69399 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:15:42.542114 ops/training.py:65 2019-01-16 18:15:42.542013: step 5447, loss = 0.69055 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:15:43.524208 ops/training.py:65 2019-01-16 18:15:43.524106: step 5448, loss = 0.71559 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 18:15:44.506353 ops/training.py:65 2019-01-16 18:15:44.506268: step 5449, loss = 0.70379 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:15:45.492182 ops/training.py:65 2019-01-16 18:15:45.492084: step 5450, loss = 0.68403 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:15:46.476446 ops/training.py:65 2019-01-16 18:15:46.476348: step 5451, loss = 0.71035 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:15:47.458938 ops/training.py:65 2019-01-16 18:15:47.458864: step 5452, loss = 0.67673 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:15:48.440093 ops/training.py:65 2019-01-16 18:15:48.440023: step 5453, loss = 0.67980 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:15:49.423519 ops/training.py:65 2019-01-16 18:15:49.423395: step 5454, loss = 0.68454 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:15:50.406965 ops/training.py:65 2019-01-16 18:15:50.406858: step 5455, loss = 0.69561 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:15:51.389407 ops/training.py:65 2019-01-16 18:15:51.389299: step 5456, loss = 0.72059 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:15:52.372636 ops/training.py:65 2019-01-16 18:15:52.372529: step 5457, loss = 0.70487 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:15:53.358533 ops/training.py:65 2019-01-16 18:15:53.358429: step 5458, loss = 0.68054 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:15:54.343069 ops/training.py:65 2019-01-16 18:15:54.342973: step 5459, loss = 0.68012 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:15:55.326002 ops/training.py:65 2019-01-16 18:15:55.325894: step 5460, loss = 0.67521 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:15:56.310052 ops/training.py:65 2019-01-16 18:15:56.309928: step 5461, loss = 0.69087 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:15:57.296002 ops/training.py:65 2019-01-16 18:15:57.295898: step 5462, loss = 0.68766 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:15:58.281207 ops/training.py:65 2019-01-16 18:15:58.281105: step 5463, loss = 0.69292 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:15:59.265781 ops/training.py:65 2019-01-16 18:15:59.265680: step 5464, loss = 0.69414 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:16:00.248795 ops/training.py:65 2019-01-16 18:16:00.248661: step 5465, loss = 0.69996 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:16:01.231795 ops/training.py:65 2019-01-16 18:16:01.231691: step 5466, loss = 0.72344 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:16:02.213981 ops/training.py:65 2019-01-16 18:16:02.213878: step 5467, loss = 0.67477 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:16:03.196204 ops/training.py:65 2019-01-16 18:16:03.196107: step 5468, loss = 0.69845 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:16:04.178024 ops/training.py:65 2019-01-16 18:16:04.177918: step 5469, loss = 0.68886 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:16:05.162006 ops/training.py:65 2019-01-16 18:16:05.161902: step 5470, loss = 0.69917 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:16:06.147910 ops/training.py:65 2019-01-16 18:16:06.147807: step 5471, loss = 0.68645 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:16:07.131808 ops/training.py:65 2019-01-16 18:16:07.131697: step 5472, loss = 0.71123 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:16:08.114898 ops/training.py:65 2019-01-16 18:16:08.114792: step 5473, loss = 0.70308 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:16:09.097283 ops/training.py:65 2019-01-16 18:16:09.097190: step 5474, loss = 0.71447 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:16:10.078384 ops/training.py:65 2019-01-16 18:16:10.078277: step 5475, loss = 0.70745 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:16:11.060078 ops/training.py:65 2019-01-16 18:16:11.059982: step 5476, loss = 0.70119 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:16:12.041254 ops/training.py:65 2019-01-16 18:16:12.041153: step 5477, loss = 0.69660 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:16:13.023572 ops/training.py:65 2019-01-16 18:16:13.023470: step 5478, loss = 0.69303 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:16:14.008482 ops/training.py:65 2019-01-16 18:16:14.008375: step 5479, loss = 0.69881 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:16:14.992710 ops/training.py:65 2019-01-16 18:16:14.992606: step 5480, loss = 0.68448 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:16:15.976034 ops/training.py:65 2019-01-16 18:16:15.975930: step 5481, loss = 0.67790 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:16:16.959982 ops/training.py:65 2019-01-16 18:16:16.959880: step 5482, loss = 0.67122 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:16:17.943947 ops/training.py:65 2019-01-16 18:16:17.943842: step 5483, loss = 0.70728 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:16:18.927348 ops/training.py:65 2019-01-16 18:16:18.927249: step 5484, loss = 0.67262 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:16:19.908919 ops/training.py:65 2019-01-16 18:16:19.908813: step 5485, loss = 0.68594 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:16:20.890697 ops/training.py:65 2019-01-16 18:16:20.890592: step 5486, loss = 0.68802 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:16:21.872318 ops/training.py:65 2019-01-16 18:16:21.872219: step 5487, loss = 0.69883 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:16:22.854711 ops/training.py:65 2019-01-16 18:16:22.854605: step 5488, loss = 0.69654 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:16:23.837424 ops/training.py:65 2019-01-16 18:16:23.837335: step 5489, loss = 0.70991 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:16:24.822728 ops/training.py:65 2019-01-16 18:16:24.822624: step 5490, loss = 0.68850 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:16:25.807662 ops/training.py:65 2019-01-16 18:16:25.807560: step 5491, loss = 0.68716 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:16:26.791983 ops/training.py:65 2019-01-16 18:16:26.791870: step 5492, loss = 0.69774 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:16:27.774104 ops/training.py:65 2019-01-16 18:16:27.774001: step 5493, loss = 0.70683 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:16:28.756141 ops/training.py:65 2019-01-16 18:16:28.756003: step 5494, loss = 0.68857 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:16:29.738001 ops/training.py:65 2019-01-16 18:16:29.737869: step 5495, loss = 0.68722 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:16:30.721954 ops/training.py:65 2019-01-16 18:16:30.721814: step 5496, loss = 0.69263 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:16:31.704294 ops/training.py:65 2019-01-16 18:16:31.704226: step 5497, loss = 0.68501 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:16:32.685946 ops/training.py:65 2019-01-16 18:16:32.685880: step 5498, loss = 0.68322 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:16:33.668307 ops/training.py:65 2019-01-16 18:16:33.668239: step 5499, loss = 0.69431 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:16:34.649734 ops/training.py:65 2019-01-16 18:16:34.649696: step 5500, loss = 0.68135 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:16:35.631533 ops/training.py:65 2019-01-16 18:16:35.631495: step 5501, loss = 0.67824 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:16:36.612719 ops/training.py:65 2019-01-16 18:16:36.612669: step 5502, loss = 0.69528 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:16:37.594075 ops/training.py:65 2019-01-16 18:16:37.594033: step 5503, loss = 0.69820 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:16:38.575058 ops/training.py:65 2019-01-16 18:16:38.574971: step 5504, loss = 0.70711 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:16:39.555796 ops/training.py:65 2019-01-16 18:16:39.555706: step 5505, loss = 0.69026 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:16:40.539920 ops/training.py:65 2019-01-16 18:16:40.539878: step 5506, loss = 0.69764 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:16:41.523254 ops/training.py:65 2019-01-16 18:16:41.523216: step 5507, loss = 0.70095 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:16:42.505815 ops/training.py:65 2019-01-16 18:16:42.505778: step 5508, loss = 0.69714 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:16:43.487518 ops/training.py:65 2019-01-16 18:16:43.487478: step 5509, loss = 0.67808 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:16:44.469052 ops/training.py:65 2019-01-16 18:16:44.469007: step 5510, loss = 0.68991 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:16:45.451141 ops/training.py:65 2019-01-16 18:16:45.451100: step 5511, loss = 0.67949 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:16:46.432201 ops/training.py:65 2019-01-16 18:16:46.432147: step 5512, loss = 0.70923 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.21875
I8192 2019-01-16 18:16:47.415042 ops/training.py:65 2019-01-16 18:16:47.415011: step 5513, loss = 0.69625 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:16:48.397866 ops/training.py:65 2019-01-16 18:16:48.397830: step 5514, loss = 0.70424 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:16:49.380260 ops/training.py:65 2019-01-16 18:16:49.380219: step 5515, loss = 0.68792 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:16:50.362184 ops/training.py:65 2019-01-16 18:16:50.362125: step 5516, loss = 0.69742 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:16:51.344821 ops/training.py:65 2019-01-16 18:16:51.344780: step 5517, loss = 0.71249 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 18:16:52.327295 ops/training.py:65 2019-01-16 18:16:52.327258: step 5518, loss = 0.69819 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:16:53.309500 ops/training.py:65 2019-01-16 18:16:53.309465: step 5519, loss = 0.68644 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:16:54.291122 ops/training.py:65 2019-01-16 18:16:54.291082: step 5520, loss = 0.69851 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:16:55.273876 ops/training.py:65 2019-01-16 18:16:55.273838: step 5521, loss = 0.68312 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:16:56.256209 ops/training.py:65 2019-01-16 18:16:56.256165: step 5522, loss = 0.69481 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:16:57.238951 ops/training.py:65 2019-01-16 18:16:57.238920: step 5523, loss = 0.69709 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:16:58.221350 ops/training.py:65 2019-01-16 18:16:58.221317: step 5524, loss = 0.68701 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:16:59.202925 ops/training.py:65 2019-01-16 18:16:59.202889: step 5525, loss = 0.67749 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:17:00.186383 ops/training.py:65 2019-01-16 18:17:00.186324: step 5526, loss = 0.70134 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:17:01.168399 ops/training.py:65 2019-01-16 18:17:01.168366: step 5527, loss = 0.69005 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:17:02.150565 ops/training.py:65 2019-01-16 18:17:02.150466: step 5528, loss = 0.70245 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:17:03.133302 ops/training.py:65 2019-01-16 18:17:03.133204: step 5529, loss = 0.68683 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:17:04.117815 ops/training.py:65 2019-01-16 18:17:04.117777: step 5530, loss = 0.69685 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:17:05.099555 ops/training.py:65 2019-01-16 18:17:05.099483: step 5531, loss = 0.70028 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:17:06.082127 ops/training.py:65 2019-01-16 18:17:06.082080: step 5532, loss = 0.68550 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:17:07.064126 ops/training.py:65 2019-01-16 18:17:07.064057: step 5533, loss = 0.69893 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:17:08.047758 ops/training.py:65 2019-01-16 18:17:08.047717: step 5534, loss = 0.69690 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:17:09.031365 ops/training.py:65 2019-01-16 18:17:09.031331: step 5535, loss = 0.68664 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:17:10.013699 ops/training.py:65 2019-01-16 18:17:10.013659: step 5536, loss = 0.70135 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:17:10.995714 ops/training.py:65 2019-01-16 18:17:10.995671: step 5537, loss = 0.68821 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:17:11.978077 ops/training.py:65 2019-01-16 18:17:11.978039: step 5538, loss = 0.70194 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:17:12.960547 ops/training.py:65 2019-01-16 18:17:12.960445: step 5539, loss = 0.68369 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:17:13.946360 ops/training.py:65 2019-01-16 18:17:13.946329: step 5540, loss = 0.69409 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:17:14.931049 ops/training.py:65 2019-01-16 18:17:14.931017: step 5541, loss = 0.69244 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:17:15.913622 ops/training.py:65 2019-01-16 18:17:15.913591: step 5542, loss = 0.68651 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:17:16.895834 ops/training.py:65 2019-01-16 18:17:16.895804: step 5543, loss = 0.68971 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:17:17.878069 ops/training.py:65 2019-01-16 18:17:17.878026: step 5544, loss = 0.67162 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.75
I8192 2019-01-16 18:17:18.860886 ops/training.py:65 2019-01-16 18:17:18.860835: step 5545, loss = 0.69403 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:17:19.843577 ops/training.py:65 2019-01-16 18:17:19.843536: step 5546, loss = 0.68513 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:17:20.826398 ops/training.py:65 2019-01-16 18:17:20.826299: step 5547, loss = 0.70648 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:17:21.808249 ops/training.py:65 2019-01-16 18:17:21.808152: step 5548, loss = 0.69174 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:17:22.793055 ops/training.py:65 2019-01-16 18:17:22.793014: step 5549, loss = 0.68662 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:17:23.774935 ops/training.py:65 2019-01-16 18:17:23.774867: step 5550, loss = 0.68316 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:17:24.757630 ops/training.py:65 2019-01-16 18:17:24.757596: step 5551, loss = 0.69753 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:17:25.742218 ops/training.py:65 2019-01-16 18:17:25.742185: step 5552, loss = 0.71992 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 18:17:26.726000 ops/training.py:65 2019-01-16 18:17:26.725966: step 5553, loss = 0.69325 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:17:27.708075 ops/training.py:65 2019-01-16 18:17:27.708004: step 5554, loss = 0.69167 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:17:28.691134 ops/training.py:65 2019-01-16 18:17:28.691043: step 5555, loss = 0.70204 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:17:29.672899 ops/training.py:65 2019-01-16 18:17:29.672857: step 5556, loss = 0.68849 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:17:30.654298 ops/training.py:65 2019-01-16 18:17:30.654251: step 5557, loss = 0.69341 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:17:31.637247 ops/training.py:65 2019-01-16 18:17:31.637144: step 5558, loss = 0.70013 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:17:32.621326 ops/training.py:65 2019-01-16 18:17:32.621217: step 5559, loss = 0.69086 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:17:33.605303 ops/training.py:65 2019-01-16 18:17:33.605216: step 5560, loss = 0.67714 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:17:34.587633 ops/training.py:65 2019-01-16 18:17:34.587508: step 5561, loss = 0.68583 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:17:35.571009 ops/training.py:65 2019-01-16 18:17:35.570910: step 5562, loss = 0.68070 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.75
I8192 2019-01-16 18:17:36.553612 ops/training.py:65 2019-01-16 18:17:36.553509: step 5563, loss = 0.69439 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:17:37.535731 ops/training.py:65 2019-01-16 18:17:37.535619: step 5564, loss = 0.69689 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:17:38.518259 ops/training.py:65 2019-01-16 18:17:38.518163: step 5565, loss = 0.67859 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:17:39.501715 ops/training.py:65 2019-01-16 18:17:39.501618: step 5566, loss = 0.69788 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:17:40.486316 ops/training.py:65 2019-01-16 18:17:40.486218: step 5567, loss = 0.70293 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:17:41.469900 ops/training.py:65 2019-01-16 18:17:41.469762: step 5568, loss = 0.69266 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:17:42.453325 ops/training.py:65 2019-01-16 18:17:42.453183: step 5569, loss = 0.68779 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:17:43.436195 ops/training.py:65 2019-01-16 18:17:43.436098: step 5570, loss = 0.69450 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:17:44.418793 ops/training.py:65 2019-01-16 18:17:44.418698: step 5571, loss = 0.69836 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:17:45.400907 ops/training.py:65 2019-01-16 18:17:45.400776: step 5572, loss = 0.68326 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:17:46.383593 ops/training.py:65 2019-01-16 18:17:46.383460: step 5573, loss = 0.69134 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:17:47.367164 ops/training.py:65 2019-01-16 18:17:47.367057: step 5574, loss = 0.70164 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:17:48.350144 ops/training.py:65 2019-01-16 18:17:48.350040: step 5575, loss = 0.68539 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:17:49.334036 ops/training.py:65 2019-01-16 18:17:49.333934: step 5576, loss = 0.70103 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:17:50.319764 ops/training.py:65 2019-01-16 18:17:50.319667: step 5577, loss = 0.68926 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:17:51.304564 ops/training.py:65 2019-01-16 18:17:51.304458: step 5578, loss = 0.68633 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:17:52.288992 ops/training.py:65 2019-01-16 18:17:52.288886: step 5579, loss = 0.68740 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:17:53.271385 ops/training.py:65 2019-01-16 18:17:53.271282: step 5580, loss = 0.68195 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:17:54.253752 ops/training.py:65 2019-01-16 18:17:54.253661: step 5581, loss = 0.68602 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:17:55.236550 ops/training.py:65 2019-01-16 18:17:55.236449: step 5582, loss = 0.67490 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.78125
I8192 2019-01-16 18:17:56.217798 ops/training.py:65 2019-01-16 18:17:56.217700: step 5583, loss = 0.68443 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:17:57.198450 ops/training.py:65 2019-01-16 18:17:57.198345: step 5584, loss = 0.68189 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:17:58.180475 ops/training.py:65 2019-01-16 18:17:58.180341: step 5585, loss = 0.70829 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:17:59.162255 ops/training.py:65 2019-01-16 18:17:59.162146: step 5586, loss = 0.69128 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:18:00.144824 ops/training.py:65 2019-01-16 18:18:00.144724: step 5587, loss = 0.69368 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:18:01.130541 ops/training.py:65 2019-01-16 18:18:01.130395: step 5588, loss = 0.70048 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:18:02.113797 ops/training.py:65 2019-01-16 18:18:02.113692: step 5589, loss = 0.67881 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:18:03.098222 ops/training.py:65 2019-01-16 18:18:03.098121: step 5590, loss = 0.68649 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:18:04.081470 ops/training.py:65 2019-01-16 18:18:04.081325: step 5591, loss = 0.68082 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:18:05.065994 ops/training.py:65 2019-01-16 18:18:05.065893: step 5592, loss = 0.69892 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:18:06.050755 ops/training.py:65 2019-01-16 18:18:06.050611: step 5593, loss = 0.69816 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:18:07.034469 ops/training.py:65 2019-01-16 18:18:07.034364: step 5594, loss = 0.69657 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:18:08.019296 ops/training.py:65 2019-01-16 18:18:08.019190: step 5595, loss = 0.67086 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:18:09.003176 ops/training.py:65 2019-01-16 18:18:09.003084: step 5596, loss = 0.69883 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:18:09.986482 ops/training.py:65 2019-01-16 18:18:09.986338: step 5597, loss = 0.70662 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:18:10.970725 ops/training.py:65 2019-01-16 18:18:10.970622: step 5598, loss = 0.69835 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:18:11.953503 ops/training.py:65 2019-01-16 18:18:11.953427: step 5599, loss = 0.67664 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:18:12.934505 ops/training.py:65 2019-01-16 18:18:12.934406: step 5600, loss = 0.69946 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:18:13.918163 ops/training.py:65 2019-01-16 18:18:13.918073: step 5601, loss = 0.69101 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:18:14.902213 ops/training.py:65 2019-01-16 18:18:14.902113: step 5602, loss = 0.68970 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:18:15.885222 ops/training.py:65 2019-01-16 18:18:15.885130: step 5603, loss = 0.68894 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:18:16.866690 ops/training.py:65 2019-01-16 18:18:16.866584: step 5604, loss = 0.70362 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:18:17.848682 ops/training.py:65 2019-01-16 18:18:17.848579: step 5605, loss = 0.69746 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:18:18.833992 ops/training.py:65 2019-01-16 18:18:18.833890: step 5606, loss = 0.69189 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:18:19.818981 ops/training.py:65 2019-01-16 18:18:19.818876: step 5607, loss = 0.69068 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:18:20.803416 ops/training.py:65 2019-01-16 18:18:20.803315: step 5608, loss = 0.69990 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:18:21.786040 ops/training.py:65 2019-01-16 18:18:21.785910: step 5609, loss = 0.71190 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:18:22.768412 ops/training.py:65 2019-01-16 18:18:22.768278: step 5610, loss = 0.71609 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:18:23.754455 ops/training.py:65 2019-01-16 18:18:23.754363: step 5611, loss = 0.69349 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:18:24.739100 ops/training.py:65 2019-01-16 18:18:24.739000: step 5612, loss = 0.68153 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:18:25.722376 ops/training.py:65 2019-01-16 18:18:25.722228: step 5613, loss = 0.70818 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:18:26.706825 ops/training.py:65 2019-01-16 18:18:26.706684: step 5614, loss = 0.69605 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:18:27.691828 ops/training.py:65 2019-01-16 18:18:27.691724: step 5615, loss = 0.72017 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:18:28.674447 ops/training.py:65 2019-01-16 18:18:28.674350: step 5616, loss = 0.71018 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:18:29.659096 ops/training.py:65 2019-01-16 18:18:29.659003: step 5617, loss = 0.68958 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:18:30.643369 ops/training.py:65 2019-01-16 18:18:30.643268: step 5618, loss = 0.70870 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:18:31.627011 ops/training.py:65 2019-01-16 18:18:31.626906: step 5619, loss = 0.68800 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:18:32.609387 ops/training.py:65 2019-01-16 18:18:32.609276: step 5620, loss = 0.67799 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:18:33.591768 ops/training.py:65 2019-01-16 18:18:33.591678: step 5621, loss = 0.69583 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:18:34.573038 ops/training.py:65 2019-01-16 18:18:34.572941: step 5622, loss = 0.69647 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:18:35.554526 ops/training.py:65 2019-01-16 18:18:35.554424: step 5623, loss = 0.68953 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:18:36.536436 ops/training.py:65 2019-01-16 18:18:36.536333: step 5624, loss = 0.69952 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:18:37.518461 ops/training.py:65 2019-01-16 18:18:37.518382: step 5625, loss = 0.69248 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:18:38.500301 ops/training.py:65 2019-01-16 18:18:38.500211: step 5626, loss = 0.71003 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:18:39.482002 ops/training.py:65 2019-01-16 18:18:39.481906: step 5627, loss = 0.70107 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:18:40.464718 ops/training.py:65 2019-01-16 18:18:40.464619: step 5628, loss = 0.70831 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:18:41.446274 ops/training.py:65 2019-01-16 18:18:41.446186: step 5629, loss = 0.68816 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:18:42.428096 ops/training.py:65 2019-01-16 18:18:42.428010: step 5630, loss = 0.71011 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:18:43.410200 ops/training.py:65 2019-01-16 18:18:43.410107: step 5631, loss = 0.71211 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:18:44.392593 ops/training.py:65 2019-01-16 18:18:44.392504: step 5632, loss = 0.70126 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:18:45.375516 ops/training.py:65 2019-01-16 18:18:45.375410: step 5633, loss = 0.70684 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:18:46.358292 ops/training.py:65 2019-01-16 18:18:46.358197: step 5634, loss = 0.67578 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:18:47.341461 ops/training.py:65 2019-01-16 18:18:47.341357: step 5635, loss = 0.68503 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:18:48.325728 ops/training.py:65 2019-01-16 18:18:48.325619: step 5636, loss = 0.67539 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:18:49.312705 ops/training.py:65 2019-01-16 18:18:49.312599: step 5637, loss = 0.67690 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:18:50.296412 ops/training.py:65 2019-01-16 18:18:50.296306: step 5638, loss = 0.68761 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:18:51.279976 ops/training.py:65 2019-01-16 18:18:51.279868: step 5639, loss = 0.68246 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:18:52.263902 ops/training.py:65 2019-01-16 18:18:52.263807: step 5640, loss = 0.69580 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:18:53.249045 ops/training.py:65 2019-01-16 18:18:53.248946: step 5641, loss = 0.70497 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:18:54.235494 ops/training.py:65 2019-01-16 18:18:54.235399: step 5642, loss = 0.70102 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:18:55.219444 ops/training.py:65 2019-01-16 18:18:55.219336: step 5643, loss = 0.68134 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:18:56.204117 ops/training.py:65 2019-01-16 18:18:56.204006: step 5644, loss = 0.67810 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:18:57.187865 ops/training.py:65 2019-01-16 18:18:57.187759: step 5645, loss = 0.69901 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:18:58.173629 ops/training.py:65 2019-01-16 18:18:58.173520: step 5646, loss = 0.71675 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:18:59.158299 ops/training.py:65 2019-01-16 18:18:59.158191: step 5647, loss = 0.68506 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:19:00.142650 ops/training.py:65 2019-01-16 18:19:00.142512: step 5648, loss = 0.70077 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:19:01.125477 ops/training.py:65 2019-01-16 18:19:01.125373: step 5649, loss = 0.65784 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:19:02.109162 ops/training.py:65 2019-01-16 18:19:02.109081: step 5650, loss = 0.71533 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:19:03.091644 ops/training.py:65 2019-01-16 18:19:03.091549: step 5651, loss = 0.70550 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:19:04.076555 ops/training.py:65 2019-01-16 18:19:04.076455: step 5652, loss = 0.71328 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:19:05.059118 ops/training.py:65 2019-01-16 18:19:05.059013: step 5653, loss = 0.67811 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:19:06.041331 ops/training.py:65 2019-01-16 18:19:06.041224: step 5654, loss = 0.66494 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:19:07.024168 ops/training.py:65 2019-01-16 18:19:07.024058: step 5655, loss = 0.69977 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:19:08.009362 ops/training.py:65 2019-01-16 18:19:08.009256: step 5656, loss = 0.66710 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:19:08.993278 ops/training.py:65 2019-01-16 18:19:08.993187: step 5657, loss = 0.71280 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:19:09.978059 ops/training.py:65 2019-01-16 18:19:09.977953: step 5658, loss = 0.72452 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:19:10.962025 ops/training.py:65 2019-01-16 18:19:10.961884: step 5659, loss = 0.68159 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:19:11.945210 ops/training.py:65 2019-01-16 18:19:11.945100: step 5660, loss = 0.70208 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:19:12.928907 ops/training.py:65 2019-01-16 18:19:12.928795: step 5661, loss = 0.70518 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:19:13.914218 ops/training.py:65 2019-01-16 18:19:13.914117: step 5662, loss = 0.69639 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:19:14.898585 ops/training.py:65 2019-01-16 18:19:14.898474: step 5663, loss = 0.69550 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:19:15.883826 ops/training.py:65 2019-01-16 18:19:15.883718: step 5664, loss = 0.68818 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:19:16.867852 ops/training.py:65 2019-01-16 18:19:16.867749: step 5665, loss = 0.69474 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:19:17.852043 ops/training.py:65 2019-01-16 18:19:17.851935: step 5666, loss = 0.66203 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:19:18.837097 ops/training.py:65 2019-01-16 18:19:18.836995: step 5667, loss = 0.70742 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:19:19.821145 ops/training.py:65 2019-01-16 18:19:19.821030: step 5668, loss = 0.68700 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:19:20.807170 ops/training.py:65 2019-01-16 18:19:20.807066: step 5669, loss = 0.69873 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:19:21.791905 ops/training.py:65 2019-01-16 18:19:21.791807: step 5670, loss = 0.69068 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:19:22.776364 ops/training.py:65 2019-01-16 18:19:22.776256: step 5671, loss = 0.70472 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:19:23.761569 ops/training.py:65 2019-01-16 18:19:23.761460: step 5672, loss = 0.72004 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:19:24.746299 ops/training.py:65 2019-01-16 18:19:24.746204: step 5673, loss = 0.66303 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.75
I8192 2019-01-16 18:19:25.731684 ops/training.py:65 2019-01-16 18:19:25.731584: step 5674, loss = 0.69770 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:19:26.714749 ops/training.py:65 2019-01-16 18:19:26.714654: step 5675, loss = 0.68524 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:19:27.698318 ops/training.py:65 2019-01-16 18:19:27.698228: step 5676, loss = 0.67305 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:19:28.681653 ops/training.py:65 2019-01-16 18:19:28.681551: step 5677, loss = 0.67377 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:19:29.662783 ops/training.py:65 2019-01-16 18:19:29.662683: step 5678, loss = 0.70877 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:19:30.644436 ops/training.py:65 2019-01-16 18:19:30.644342: step 5679, loss = 0.70120 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:19:31.627631 ops/training.py:65 2019-01-16 18:19:31.627522: step 5680, loss = 0.70914 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:19:32.612734 ops/training.py:65 2019-01-16 18:19:32.612624: step 5681, loss = 0.70168 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:19:33.596870 ops/training.py:65 2019-01-16 18:19:33.596773: step 5682, loss = 0.69046 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:19:34.580855 ops/training.py:65 2019-01-16 18:19:34.580754: step 5683, loss = 0.68860 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:19:35.564132 ops/training.py:65 2019-01-16 18:19:35.563999: step 5684, loss = 0.66612 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:19:36.548576 ops/training.py:65 2019-01-16 18:19:36.548474: step 5685, loss = 0.71092 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:19:37.531483 ops/training.py:65 2019-01-16 18:19:37.531375: step 5686, loss = 0.71284 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:19:38.515627 ops/training.py:65 2019-01-16 18:19:38.515521: step 5687, loss = 0.70456 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:19:39.501031 ops/training.py:65 2019-01-16 18:19:39.500938: step 5688, loss = 0.70130 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:19:40.483475 ops/training.py:65 2019-01-16 18:19:40.483367: step 5689, loss = 0.69675 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:19:41.465122 ops/training.py:65 2019-01-16 18:19:41.465011: step 5690, loss = 0.71272 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:19:42.449308 ops/training.py:65 2019-01-16 18:19:42.449206: step 5691, loss = 0.70940 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:19:43.432033 ops/training.py:65 2019-01-16 18:19:43.431931: step 5692, loss = 0.69561 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:19:44.414711 ops/training.py:65 2019-01-16 18:19:44.414638: step 5693, loss = 0.71785 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:19:45.397768 ops/training.py:65 2019-01-16 18:19:45.397655: step 5694, loss = 0.69357 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:19:46.382415 ops/training.py:65 2019-01-16 18:19:46.382277: step 5695, loss = 0.70406 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:19:47.366464 ops/training.py:65 2019-01-16 18:19:47.366359: step 5696, loss = 0.69233 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:19:48.348494 ops/training.py:65 2019-01-16 18:19:48.348386: step 5697, loss = 0.69093 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:19:49.332817 ops/training.py:65 2019-01-16 18:19:49.332714: step 5698, loss = 0.70694 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:19:50.317189 ops/training.py:65 2019-01-16 18:19:50.317087: step 5699, loss = 0.71628 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:19:51.301310 ops/training.py:65 2019-01-16 18:19:51.301213: step 5700, loss = 0.70421 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:19:52.285106 ops/training.py:65 2019-01-16 18:19:52.285005: step 5701, loss = 0.71113 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:19:53.269266 ops/training.py:65 2019-01-16 18:19:53.269172: step 5702, loss = 0.69724 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:19:54.254238 ops/training.py:65 2019-01-16 18:19:54.254139: step 5703, loss = 0.69032 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:19:55.237323 ops/training.py:65 2019-01-16 18:19:55.237221: step 5704, loss = 0.70256 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:19:56.220617 ops/training.py:65 2019-01-16 18:19:56.220517: step 5705, loss = 0.68604 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:19:57.202682 ops/training.py:65 2019-01-16 18:19:57.202584: step 5706, loss = 0.69393 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:19:58.184453 ops/training.py:65 2019-01-16 18:19:58.184355: step 5707, loss = 0.68704 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:19:59.166026 ops/training.py:65 2019-01-16 18:19:59.165920: step 5708, loss = 0.69970 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:20:00.147496 ops/training.py:65 2019-01-16 18:20:00.147401: step 5709, loss = 0.69252 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:20:01.129307 ops/training.py:65 2019-01-16 18:20:01.129203: step 5710, loss = 0.68858 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:20:02.111271 ops/training.py:65 2019-01-16 18:20:02.111181: step 5711, loss = 0.69815 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:20:03.095617 ops/training.py:65 2019-01-16 18:20:03.095522: step 5712, loss = 0.71137 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:20:04.080689 ops/training.py:65 2019-01-16 18:20:04.080608: step 5713, loss = 0.67703 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:20:05.064402 ops/training.py:65 2019-01-16 18:20:05.064306: step 5714, loss = 0.69919 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:20:06.047293 ops/training.py:65 2019-01-16 18:20:06.047198: step 5715, loss = 0.68602 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:20:07.030189 ops/training.py:65 2019-01-16 18:20:07.030089: step 5716, loss = 0.69181 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:20:08.017501 ops/training.py:65 2019-01-16 18:20:08.017399: step 5717, loss = 0.69523 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:20:09.001469 ops/training.py:65 2019-01-16 18:20:09.001384: step 5718, loss = 0.66631 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:20:09.984750 ops/training.py:65 2019-01-16 18:20:09.984657: step 5719, loss = 0.69910 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:20:10.966695 ops/training.py:65 2019-01-16 18:20:10.966594: step 5720, loss = 0.71158 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:20:11.949287 ops/training.py:65 2019-01-16 18:20:11.949188: step 5721, loss = 0.69296 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:20:12.931118 ops/training.py:65 2019-01-16 18:20:12.931016: step 5722, loss = 0.70104 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:20:13.915495 ops/training.py:65 2019-01-16 18:20:13.915386: step 5723, loss = 0.68810 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:20:14.899212 ops/training.py:65 2019-01-16 18:20:14.899073: step 5724, loss = 0.69035 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:20:15.885323 ops/training.py:65 2019-01-16 18:20:15.885215: step 5725, loss = 0.68814 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:20:16.869214 ops/training.py:65 2019-01-16 18:20:16.869111: step 5726, loss = 0.69901 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:20:17.852055 ops/training.py:65 2019-01-16 18:20:17.851951: step 5727, loss = 0.69815 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:20:18.833082 ops/training.py:65 2019-01-16 18:20:18.832987: step 5728, loss = 0.70253 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:20:19.812990 ops/training.py:65 2019-01-16 18:20:19.812915: step 5729, loss = 0.71635 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:20:20.795909 ops/training.py:65 2019-01-16 18:20:20.795831: step 5730, loss = 0.70503 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:20:21.780637 ops/training.py:65 2019-01-16 18:20:21.780527: step 5731, loss = 0.71059 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:20:22.763897 ops/training.py:65 2019-01-16 18:20:22.763759: step 5732, loss = 0.66755 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:20:23.748896 ops/training.py:65 2019-01-16 18:20:23.748796: step 5733, loss = 0.70034 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:20:24.733118 ops/training.py:65 2019-01-16 18:20:24.733020: step 5734, loss = 0.68967 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:20:25.718062 ops/training.py:65 2019-01-16 18:20:25.717957: step 5735, loss = 0.69460 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:20:26.703401 ops/training.py:65 2019-01-16 18:20:26.703303: step 5736, loss = 0.69759 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:20:27.688696 ops/training.py:65 2019-01-16 18:20:27.688592: step 5737, loss = 0.69270 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:20:28.672104 ops/training.py:65 2019-01-16 18:20:28.672049: step 5738, loss = 0.69555 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:20:29.655099 ops/training.py:65 2019-01-16 18:20:29.655062: step 5739, loss = 0.70229 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:20:30.637633 ops/training.py:65 2019-01-16 18:20:30.637600: step 5740, loss = 0.68481 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:20:31.620434 ops/training.py:65 2019-01-16 18:20:31.620403: step 5741, loss = 0.69401 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:20:32.603730 ops/training.py:65 2019-01-16 18:20:32.603696: step 5742, loss = 0.68934 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:20:33.586275 ops/training.py:65 2019-01-16 18:20:33.586241: step 5743, loss = 0.68307 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:20:34.567955 ops/training.py:65 2019-01-16 18:20:34.567851: step 5744, loss = 0.70700 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:20:35.553604 ops/training.py:65 2019-01-16 18:20:35.553552: step 5745, loss = 0.70426 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:20:36.537661 ops/training.py:65 2019-01-16 18:20:36.537559: step 5746, loss = 0.69230 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:20:37.520543 ops/training.py:65 2019-01-16 18:20:37.520448: step 5747, loss = 0.69219 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:20:38.504233 ops/training.py:65 2019-01-16 18:20:38.504126: step 5748, loss = 0.69139 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:20:39.488448 ops/training.py:65 2019-01-16 18:20:39.488350: step 5749, loss = 0.68576 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:20:40.472820 ops/training.py:65 2019-01-16 18:20:40.472745: step 5750, loss = 0.69993 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:20:41.456347 ops/training.py:65 2019-01-16 18:20:41.456251: step 5751, loss = 0.68037 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:20:42.439105 ops/training.py:65 2019-01-16 18:20:42.438998: step 5752, loss = 0.69043 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:20:43.421176 ops/training.py:65 2019-01-16 18:20:43.421073: step 5753, loss = 0.69925 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:20:44.403096 ops/training.py:65 2019-01-16 18:20:44.402998: step 5754, loss = 0.69831 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:20:45.384777 ops/training.py:65 2019-01-16 18:20:45.384633: step 5755, loss = 0.68933 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:20:46.366733 ops/training.py:65 2019-01-16 18:20:46.366587: step 5756, loss = 0.69036 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:20:47.348731 ops/training.py:65 2019-01-16 18:20:47.348626: step 5757, loss = 0.69677 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:20:48.331004 ops/training.py:65 2019-01-16 18:20:48.330897: step 5758, loss = 0.70562 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:20:49.312541 ops/training.py:65 2019-01-16 18:20:49.312410: step 5759, loss = 0.68312 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:20:50.293713 ops/training.py:65 2019-01-16 18:20:50.293595: step 5760, loss = 0.70119 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:20:51.275944 ops/training.py:65 2019-01-16 18:20:51.275855: step 5761, loss = 0.69077 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:20:52.257355 ops/training.py:65 2019-01-16 18:20:52.257260: step 5762, loss = 0.69681 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:20:53.241855 ops/training.py:65 2019-01-16 18:20:53.241760: step 5763, loss = 0.69443 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:20:54.227233 ops/training.py:65 2019-01-16 18:20:54.227144: step 5764, loss = 0.68649 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:20:55.215570 ops/training.py:65 2019-01-16 18:20:55.215469: step 5765, loss = 0.68985 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:20:56.201079 ops/training.py:65 2019-01-16 18:20:56.200987: step 5766, loss = 0.69903 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:20:57.185315 ops/training.py:65 2019-01-16 18:20:57.185217: step 5767, loss = 0.69640 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:20:58.167152 ops/training.py:65 2019-01-16 18:20:58.167045: step 5768, loss = 0.69116 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:20:59.150866 ops/training.py:65 2019-01-16 18:20:59.150770: step 5769, loss = 0.69036 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:21:00.133545 ops/training.py:65 2019-01-16 18:21:00.133445: step 5770, loss = 0.68762 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:21:01.117250 ops/training.py:65 2019-01-16 18:21:01.117183: step 5771, loss = 0.68328 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:21:02.098515 ops/training.py:65 2019-01-16 18:21:02.098420: step 5772, loss = 0.69076 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:21:03.081377 ops/training.py:65 2019-01-16 18:21:03.081281: step 5773, loss = 0.68274 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:21:04.064366 ops/training.py:65 2019-01-16 18:21:04.064270: step 5774, loss = 0.69825 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:21:05.048640 ops/training.py:65 2019-01-16 18:21:05.048544: step 5775, loss = 0.67605 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:21:06.032439 ops/training.py:65 2019-01-16 18:21:06.032343: step 5776, loss = 0.70096 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:21:07.015801 ops/training.py:65 2019-01-16 18:21:07.015708: step 5777, loss = 0.69292 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:21:07.999606 ops/training.py:65 2019-01-16 18:21:07.999525: step 5778, loss = 0.70070 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:21:08.983637 ops/training.py:65 2019-01-16 18:21:08.983542: step 5779, loss = 0.71460 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 18:21:09.966340 ops/training.py:65 2019-01-16 18:21:09.966244: step 5780, loss = 0.69177 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:21:10.951520 ops/training.py:65 2019-01-16 18:21:10.951452: step 5781, loss = 0.68140 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:21:11.933634 ops/training.py:65 2019-01-16 18:21:11.933528: step 5782, loss = 0.70538 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:21:12.915308 ops/training.py:65 2019-01-16 18:21:12.915202: step 5783, loss = 0.70487 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:21:13.896433 ops/training.py:65 2019-01-16 18:21:13.896345: step 5784, loss = 0.69351 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:21:14.879997 ops/training.py:65 2019-01-16 18:21:14.879891: step 5785, loss = 0.70150 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:21:15.865470 ops/training.py:65 2019-01-16 18:21:15.865368: step 5786, loss = 0.69589 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:21:16.850735 ops/training.py:65 2019-01-16 18:21:16.850636: step 5787, loss = 0.69920 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 18:21:17.834775 ops/training.py:65 2019-01-16 18:21:17.834675: step 5788, loss = 0.68408 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:21:18.816827 ops/training.py:65 2019-01-16 18:21:18.816732: step 5789, loss = 0.70112 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:21:19.801595 ops/training.py:65 2019-01-16 18:21:19.801494: step 5790, loss = 0.69253 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:21:20.787978 ops/training.py:65 2019-01-16 18:21:20.787877: step 5791, loss = 0.71157 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:21:21.771530 ops/training.py:65 2019-01-16 18:21:21.771431: step 5792, loss = 0.70108 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:21:22.755445 ops/training.py:65 2019-01-16 18:21:22.755340: step 5793, loss = 0.70336 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:21:23.740013 ops/training.py:65 2019-01-16 18:21:23.739907: step 5794, loss = 0.68923 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:21:24.724129 ops/training.py:65 2019-01-16 18:21:24.724009: step 5795, loss = 0.69262 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:21:25.708914 ops/training.py:65 2019-01-16 18:21:25.708781: step 5796, loss = 0.70027 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:21:26.691842 ops/training.py:65 2019-01-16 18:21:26.691749: step 5797, loss = 0.69051 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:21:27.672655 ops/training.py:65 2019-01-16 18:21:27.672550: step 5798, loss = 0.70037 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:21:28.655382 ops/training.py:65 2019-01-16 18:21:28.655244: step 5799, loss = 0.70956 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.25
I8192 2019-01-16 18:21:29.640454 ops/training.py:65 2019-01-16 18:21:29.640368: step 5800, loss = 0.69529 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:21:30.625276 ops/training.py:65 2019-01-16 18:21:30.625136: step 5801, loss = 0.68744 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:21:31.608822 ops/training.py:65 2019-01-16 18:21:31.608725: step 5802, loss = 0.69116 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:21:32.591491 ops/training.py:65 2019-01-16 18:21:32.591390: step 5803, loss = 0.68641 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:21:33.574654 ops/training.py:65 2019-01-16 18:21:33.574560: step 5804, loss = 0.69364 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:21:34.558258 ops/training.py:65 2019-01-16 18:21:34.558162: step 5805, loss = 0.69320 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:21:35.543574 ops/training.py:65 2019-01-16 18:21:35.543476: step 5806, loss = 0.69694 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:21:36.526318 ops/training.py:65 2019-01-16 18:21:36.526224: step 5807, loss = 0.68211 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:21:37.508923 ops/training.py:65 2019-01-16 18:21:37.508824: step 5808, loss = 0.68384 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:21:38.490348 ops/training.py:65 2019-01-16 18:21:38.490253: step 5809, loss = 0.69121 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:21:39.474050 ops/training.py:65 2019-01-16 18:21:39.473960: step 5810, loss = 0.69270 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:21:40.458559 ops/training.py:65 2019-01-16 18:21:40.458466: step 5811, loss = 0.69350 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:21:41.442798 ops/training.py:65 2019-01-16 18:21:41.442702: step 5812, loss = 0.68150 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:21:42.427688 ops/training.py:65 2019-01-16 18:21:42.427586: step 5813, loss = 0.68875 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:21:43.410221 ops/training.py:65 2019-01-16 18:21:43.410117: step 5814, loss = 0.68812 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:21:44.395934 ops/training.py:65 2019-01-16 18:21:44.395868: step 5815, loss = 0.68974 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:21:45.379235 ops/training.py:65 2019-01-16 18:21:45.379195: step 5816, loss = 0.69831 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:21:46.361424 ops/training.py:65 2019-01-16 18:21:46.361376: step 5817, loss = 0.69485 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:21:47.343549 ops/training.py:65 2019-01-16 18:21:47.343494: step 5818, loss = 0.68153 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:21:48.326834 ops/training.py:65 2019-01-16 18:21:48.326778: step 5819, loss = 0.68653 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:21:49.309983 ops/training.py:65 2019-01-16 18:21:49.309917: step 5820, loss = 0.69480 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:21:50.292253 ops/training.py:65 2019-01-16 18:21:50.292181: step 5821, loss = 0.70090 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:21:51.275312 ops/training.py:65 2019-01-16 18:21:51.275274: step 5822, loss = 0.69593 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:21:52.257955 ops/training.py:65 2019-01-16 18:21:52.257909: step 5823, loss = 0.68759 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:21:53.239527 ops/training.py:65 2019-01-16 18:21:53.239491: step 5824, loss = 0.68581 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:21:54.222560 ops/training.py:65 2019-01-16 18:21:54.222527: step 5825, loss = 0.69473 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:21:55.206239 ops/training.py:65 2019-01-16 18:21:55.206205: step 5826, loss = 0.71875 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.21875
I8192 2019-01-16 18:21:56.189592 ops/training.py:65 2019-01-16 18:21:56.189559: step 5827, loss = 0.69522 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:21:57.171444 ops/training.py:65 2019-01-16 18:21:57.171378: step 5828, loss = 0.69656 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:21:58.154914 ops/training.py:65 2019-01-16 18:21:58.154866: step 5829, loss = 0.70519 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:21:59.138148 ops/training.py:65 2019-01-16 18:21:59.138113: step 5830, loss = 0.68141 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:22:00.120951 ops/training.py:65 2019-01-16 18:22:00.120909: step 5831, loss = 0.69149 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:22:01.102397 ops/training.py:65 2019-01-16 18:22:01.102358: step 5832, loss = 0.69106 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:22:02.084692 ops/training.py:65 2019-01-16 18:22:02.084646: step 5833, loss = 0.69761 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:22:03.066735 ops/training.py:65 2019-01-16 18:22:03.066698: step 5834, loss = 0.68876 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:22:04.048902 ops/training.py:65 2019-01-16 18:22:04.048865: step 5835, loss = 0.69811 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:22:05.035038 ops/training.py:65 2019-01-16 18:22:05.034994: step 5836, loss = 0.69329 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:22:06.017598 ops/training.py:65 2019-01-16 18:22:06.017491: step 5837, loss = 0.69152 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:22:07.000666 ops/training.py:65 2019-01-16 18:22:07.000567: step 5838, loss = 0.69940 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:22:07.986159 ops/training.py:65 2019-01-16 18:22:07.986112: step 5839, loss = 0.69091 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:22:08.967554 ops/training.py:65 2019-01-16 18:22:08.967484: step 5840, loss = 0.69679 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:22:09.950493 ops/training.py:65 2019-01-16 18:22:09.950456: step 5841, loss = 0.68747 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:22:10.934025 ops/training.py:65 2019-01-16 18:22:10.933981: step 5842, loss = 0.69618 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:22:11.916687 ops/training.py:65 2019-01-16 18:22:11.916633: step 5843, loss = 0.69210 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:22:12.903163 ops/training.py:65 2019-01-16 18:22:12.903121: step 5844, loss = 0.69129 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:22:13.885131 ops/training.py:65 2019-01-16 18:22:13.885088: step 5845, loss = 0.69400 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:22:14.867627 ops/training.py:65 2019-01-16 18:22:14.867591: step 5846, loss = 0.69434 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:22:15.851590 ops/training.py:65 2019-01-16 18:22:15.851554: step 5847, loss = 0.69466 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:22:16.834111 ops/training.py:65 2019-01-16 18:22:16.834077: step 5848, loss = 0.69440 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:22:17.816051 ops/training.py:65 2019-01-16 18:22:17.816015: step 5849, loss = 0.69437 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:22:18.797608 ops/training.py:65 2019-01-16 18:22:18.797571: step 5850, loss = 0.68989 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:22:19.778621 ops/training.py:65 2019-01-16 18:22:19.778587: step 5851, loss = 0.68760 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:22:20.765324 ops/training.py:65 2019-01-16 18:22:20.765228: step 5852, loss = 0.69226 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:22:21.748856 ops/training.py:65 2019-01-16 18:22:21.748742: step 5853, loss = 0.70157 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:22:22.733958 ops/training.py:65 2019-01-16 18:22:22.733912: step 5854, loss = 0.68815 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:22:23.717039 ops/training.py:65 2019-01-16 18:22:23.716998: step 5855, loss = 0.70935 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:22:24.699834 ops/training.py:65 2019-01-16 18:22:24.699785: step 5856, loss = 0.69521 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:22:25.684307 ops/training.py:65 2019-01-16 18:22:25.684262: step 5857, loss = 0.68361 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:22:26.668036 ops/training.py:65 2019-01-16 18:22:26.667997: step 5858, loss = 0.69376 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:22:27.653102 ops/training.py:65 2019-01-16 18:22:27.653063: step 5859, loss = 0.68574 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:22:28.638950 ops/training.py:65 2019-01-16 18:22:28.638878: step 5860, loss = 0.69746 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:22:29.623403 ops/training.py:65 2019-01-16 18:22:29.623357: step 5861, loss = 0.70169 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:22:30.606249 ops/training.py:65 2019-01-16 18:22:30.606204: step 5862, loss = 0.68936 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:22:31.588577 ops/training.py:65 2019-01-16 18:22:31.588535: step 5863, loss = 0.69444 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:22:32.570580 ops/training.py:65 2019-01-16 18:22:32.570539: step 5864, loss = 0.69898 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:22:33.551159 ops/training.py:65 2019-01-16 18:22:33.551122: step 5865, loss = 0.66907 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.75
I8192 2019-01-16 18:22:34.532458 ops/training.py:65 2019-01-16 18:22:34.532367: step 5866, loss = 0.68281 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:22:35.516621 ops/training.py:65 2019-01-16 18:22:35.516571: step 5867, loss = 0.69371 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:22:36.500135 ops/training.py:65 2019-01-16 18:22:36.500097: step 5868, loss = 0.69404 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:22:37.482723 ops/training.py:65 2019-01-16 18:22:37.482685: step 5869, loss = 0.69531 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:22:38.463441 ops/training.py:65 2019-01-16 18:22:38.463400: step 5870, loss = 0.69885 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:22:39.445380 ops/training.py:65 2019-01-16 18:22:39.445341: step 5871, loss = 0.68896 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:22:40.425902 ops/training.py:65 2019-01-16 18:22:40.425850: step 5872, loss = 0.68959 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:22:41.408539 ops/training.py:65 2019-01-16 18:22:41.408495: step 5873, loss = 0.69219 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:22:42.391028 ops/training.py:65 2019-01-16 18:22:42.390990: step 5874, loss = 0.69503 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:22:43.374125 ops/training.py:65 2019-01-16 18:22:43.374086: step 5875, loss = 0.69730 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:22:44.355161 ops/training.py:65 2019-01-16 18:22:44.355059: step 5876, loss = 0.69201 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:22:45.339022 ops/training.py:65 2019-01-16 18:22:45.338975: step 5877, loss = 0.70338 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:22:46.322610 ops/training.py:65 2019-01-16 18:22:46.322570: step 5878, loss = 0.68155 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:22:47.305259 ops/training.py:65 2019-01-16 18:22:47.305220: step 5879, loss = 0.68086 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:22:48.286571 ops/training.py:65 2019-01-16 18:22:48.286526: step 5880, loss = 0.69465 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:22:49.268253 ops/training.py:65 2019-01-16 18:22:49.268214: step 5881, loss = 0.70448 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:22:50.249091 ops/training.py:65 2019-01-16 18:22:50.249053: step 5882, loss = 0.69870 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:22:51.230949 ops/training.py:65 2019-01-16 18:22:51.230910: step 5883, loss = 0.69152 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:22:52.212359 ops/training.py:65 2019-01-16 18:22:52.212321: step 5884, loss = 0.69041 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:22:53.193012 ops/training.py:65 2019-01-16 18:22:53.192973: step 5885, loss = 0.68753 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:22:54.174347 ops/training.py:65 2019-01-16 18:22:54.174310: step 5886, loss = 0.69449 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:22:55.156159 ops/training.py:65 2019-01-16 18:22:55.156122: step 5887, loss = 0.69494 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:22:56.137820 ops/training.py:65 2019-01-16 18:22:56.137774: step 5888, loss = 0.69134 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:22:57.120745 ops/training.py:65 2019-01-16 18:22:57.120707: step 5889, loss = 0.69557 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:22:58.102016 ops/training.py:65 2019-01-16 18:22:58.101977: step 5890, loss = 0.69762 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:22:59.083390 ops/training.py:65 2019-01-16 18:22:59.083349: step 5891, loss = 0.68715 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:23:00.064585 ops/training.py:65 2019-01-16 18:23:00.064549: step 5892, loss = 0.69015 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:23:01.045780 ops/training.py:65 2019-01-16 18:23:01.045727: step 5893, loss = 0.69425 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:23:02.029075 ops/training.py:65 2019-01-16 18:23:02.029039: step 5894, loss = 0.69092 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:23:03.011025 ops/training.py:65 2019-01-16 18:23:03.010983: step 5895, loss = 0.69151 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:23:03.992959 ops/training.py:65 2019-01-16 18:23:03.992865: step 5896, loss = 0.69875 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:23:04.974502 ops/training.py:65 2019-01-16 18:23:04.974407: step 5897, loss = 0.69398 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:23:05.959228 ops/training.py:65 2019-01-16 18:23:05.959172: step 5898, loss = 0.69248 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:23:06.940884 ops/training.py:65 2019-01-16 18:23:06.940811: step 5899, loss = 0.68790 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:23:07.923898 ops/training.py:65 2019-01-16 18:23:07.923852: step 5900, loss = 0.69743 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:23:08.907281 ops/training.py:65 2019-01-16 18:23:08.907233: step 5901, loss = 0.68980 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:23:09.887781 ops/training.py:65 2019-01-16 18:23:09.887746: step 5902, loss = 0.68984 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:23:10.870169 ops/training.py:65 2019-01-16 18:23:10.870131: step 5903, loss = 0.70027 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:23:11.851613 ops/training.py:65 2019-01-16 18:23:11.851575: step 5904, loss = 0.69300 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:23:12.833154 ops/training.py:65 2019-01-16 18:23:12.833091: step 5905, loss = 0.69559 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:23:13.814010 ops/training.py:65 2019-01-16 18:23:13.813941: step 5906, loss = 0.68913 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:23:14.798084 ops/training.py:65 2019-01-16 18:23:14.798016: step 5907, loss = 0.69286 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:23:15.780311 ops/training.py:65 2019-01-16 18:23:15.780213: step 5908, loss = 0.68575 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:23:16.761738 ops/training.py:65 2019-01-16 18:23:16.761677: step 5909, loss = 0.68639 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:23:17.741033 ops/training.py:65 2019-01-16 18:23:17.740967: step 5910, loss = 0.69282 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:23:18.720845 ops/training.py:65 2019-01-16 18:23:18.720772: step 5911, loss = 0.69656 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:23:19.702009 ops/training.py:65 2019-01-16 18:23:19.701944: step 5912, loss = 0.68912 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:23:20.681644 ops/training.py:65 2019-01-16 18:23:20.681563: step 5913, loss = 0.69487 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:23:21.664596 ops/training.py:65 2019-01-16 18:23:21.664554: step 5914, loss = 0.69102 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:23:22.647515 ops/training.py:65 2019-01-16 18:23:22.647478: step 5915, loss = 0.69153 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:23:23.629199 ops/training.py:65 2019-01-16 18:23:23.629161: step 5916, loss = 0.69535 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:23:24.609900 ops/training.py:65 2019-01-16 18:23:24.609814: step 5917, loss = 0.69173 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:23:25.591542 ops/training.py:65 2019-01-16 18:23:25.591438: step 5918, loss = 0.70057 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:23:26.573296 ops/training.py:65 2019-01-16 18:23:26.573200: step 5919, loss = 0.68738 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:23:27.556600 ops/training.py:65 2019-01-16 18:23:27.556497: step 5920, loss = 0.70624 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:23:28.540383 ops/training.py:65 2019-01-16 18:23:28.540279: step 5921, loss = 0.70018 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:23:29.524372 ops/training.py:65 2019-01-16 18:23:29.524261: step 5922, loss = 0.69293 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:23:30.508521 ops/training.py:65 2019-01-16 18:23:30.508422: step 5923, loss = 0.69961 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:23:31.494225 ops/training.py:65 2019-01-16 18:23:31.494130: step 5924, loss = 0.68721 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:23:32.477801 ops/training.py:65 2019-01-16 18:23:32.477696: step 5925, loss = 0.70077 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:23:33.462332 ops/training.py:65 2019-01-16 18:23:33.462225: step 5926, loss = 0.70031 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:23:34.447151 ops/training.py:65 2019-01-16 18:23:34.447052: step 5927, loss = 0.69826 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:23:35.430558 ops/training.py:65 2019-01-16 18:23:35.430448: step 5928, loss = 0.67976 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:23:36.413170 ops/training.py:65 2019-01-16 18:23:36.413071: step 5929, loss = 0.68553 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:23:37.395583 ops/training.py:65 2019-01-16 18:23:37.395482: step 5930, loss = 0.69325 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:23:38.377138 ops/training.py:65 2019-01-16 18:23:38.377032: step 5931, loss = 0.68607 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:23:39.360967 ops/training.py:65 2019-01-16 18:23:39.360871: step 5932, loss = 0.69697 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:23:40.345241 ops/training.py:65 2019-01-16 18:23:40.345142: step 5933, loss = 0.70255 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:23:41.329659 ops/training.py:65 2019-01-16 18:23:41.329564: step 5934, loss = 0.68705 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:23:42.313717 ops/training.py:65 2019-01-16 18:23:42.313620: step 5935, loss = 0.69333 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:23:43.295785 ops/training.py:65 2019-01-16 18:23:43.295683: step 5936, loss = 0.69436 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:23:44.277324 ops/training.py:65 2019-01-16 18:23:44.277226: step 5937, loss = 0.70830 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:23:45.260830 ops/training.py:65 2019-01-16 18:23:45.260722: step 5938, loss = 0.70137 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:23:46.244865 ops/training.py:65 2019-01-16 18:23:46.244774: step 5939, loss = 0.69144 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:23:47.228616 ops/training.py:65 2019-01-16 18:23:47.228514: step 5940, loss = 0.68941 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:23:48.214165 ops/training.py:65 2019-01-16 18:23:48.214073: step 5941, loss = 0.67992 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:23:49.199217 ops/training.py:65 2019-01-16 18:23:49.199113: step 5942, loss = 0.69549 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:23:50.183623 ops/training.py:65 2019-01-16 18:23:50.183522: step 5943, loss = 0.68715 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:23:51.166581 ops/training.py:65 2019-01-16 18:23:51.166481: step 5944, loss = 0.69762 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:23:52.147843 ops/training.py:65 2019-01-16 18:23:52.147746: step 5945, loss = 0.68626 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:23:53.128974 ops/training.py:65 2019-01-16 18:23:53.128872: step 5946, loss = 0.70082 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:23:54.110218 ops/training.py:65 2019-01-16 18:23:54.110116: step 5947, loss = 0.70163 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:23:55.091203 ops/training.py:65 2019-01-16 18:23:55.091108: step 5948, loss = 0.70987 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 18:23:56.075705 ops/training.py:65 2019-01-16 18:23:56.075607: step 5949, loss = 0.69818 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:23:57.060903 ops/training.py:65 2019-01-16 18:23:57.060799: step 5950, loss = 0.68592 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:23:58.046032 ops/training.py:65 2019-01-16 18:23:58.045928: step 5951, loss = 0.68137 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:23:59.032638 ops/training.py:65 2019-01-16 18:23:59.032537: step 5952, loss = 0.69499 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:24:00.017157 ops/training.py:65 2019-01-16 18:24:00.017048: step 5953, loss = 0.69260 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:24:00.999251 ops/training.py:65 2019-01-16 18:24:00.999148: step 5954, loss = 0.68166 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:24:01.983653 ops/training.py:65 2019-01-16 18:24:01.983557: step 5955, loss = 0.69874 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:24:02.966909 ops/training.py:65 2019-01-16 18:24:02.966806: step 5956, loss = 0.70915 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:24:03.949400 ops/training.py:65 2019-01-16 18:24:03.949304: step 5957, loss = 0.69000 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:24:04.931313 ops/training.py:65 2019-01-16 18:24:04.931215: step 5958, loss = 0.69281 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:24:05.913656 ops/training.py:65 2019-01-16 18:24:05.913558: step 5959, loss = 0.69975 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:24:06.894975 ops/training.py:65 2019-01-16 18:24:06.894880: step 5960, loss = 0.69424 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:24:07.877253 ops/training.py:65 2019-01-16 18:24:07.877145: step 5961, loss = 0.68159 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:24:08.859322 ops/training.py:65 2019-01-16 18:24:08.859225: step 5962, loss = 0.69119 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:24:09.842329 ops/training.py:65 2019-01-16 18:24:09.842237: step 5963, loss = 0.68121 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:24:10.827462 ops/training.py:65 2019-01-16 18:24:10.827423: step 5964, loss = 0.68571 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:24:11.812107 ops/training.py:65 2019-01-16 18:24:11.812070: step 5965, loss = 0.69187 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:24:12.795744 ops/training.py:65 2019-01-16 18:24:12.795701: step 5966, loss = 0.69753 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:24:13.779558 ops/training.py:65 2019-01-16 18:24:13.779520: step 5967, loss = 0.69024 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:24:14.762191 ops/training.py:65 2019-01-16 18:24:14.762155: step 5968, loss = 0.69538 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:24:15.743704 ops/training.py:65 2019-01-16 18:24:15.743665: step 5969, loss = 0.68320 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:24:16.724725 ops/training.py:65 2019-01-16 18:24:16.724688: step 5970, loss = 0.70239 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:24:17.706242 ops/training.py:65 2019-01-16 18:24:17.706202: step 5971, loss = 0.69433 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:24:18.687455 ops/training.py:65 2019-01-16 18:24:18.687402: step 5972, loss = 0.69013 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:24:19.670738 ops/training.py:65 2019-01-16 18:24:19.670684: step 5973, loss = 0.69260 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:24:20.652094 ops/training.py:65 2019-01-16 18:24:20.652053: step 5974, loss = 0.68835 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:24:21.633912 ops/training.py:65 2019-01-16 18:24:21.633876: step 5975, loss = 0.69943 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:24:22.615318 ops/training.py:65 2019-01-16 18:24:22.615279: step 5976, loss = 0.67334 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:24:23.597049 ops/training.py:65 2019-01-16 18:24:23.597007: step 5977, loss = 0.69216 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:24:24.579103 ops/training.py:65 2019-01-16 18:24:24.579066: step 5978, loss = 0.69631 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:24:25.559998 ops/training.py:65 2019-01-16 18:24:25.559954: step 5979, loss = 0.69335 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:24:26.542144 ops/training.py:65 2019-01-16 18:24:26.542106: step 5980, loss = 0.68938 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:24:27.524323 ops/training.py:65 2019-01-16 18:24:27.524226: step 5981, loss = 0.69175 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:24:28.506597 ops/training.py:65 2019-01-16 18:24:28.506496: step 5982, loss = 0.68145 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:24:29.489367 ops/training.py:65 2019-01-16 18:24:29.489264: step 5983, loss = 0.68600 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:24:30.470920 ops/training.py:65 2019-01-16 18:24:30.470832: step 5984, loss = 0.69039 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:24:31.454849 ops/training.py:65 2019-01-16 18:24:31.454749: step 5985, loss = 0.69268 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:24:32.437079 ops/training.py:65 2019-01-16 18:24:32.436985: step 5986, loss = 0.69457 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:24:33.419587 ops/training.py:65 2019-01-16 18:24:33.419489: step 5987, loss = 0.68808 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:24:34.401280 ops/training.py:65 2019-01-16 18:24:34.401178: step 5988, loss = 0.70340 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:24:35.382843 ops/training.py:65 2019-01-16 18:24:35.382774: step 5989, loss = 0.69078 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:24:36.364300 ops/training.py:65 2019-01-16 18:24:36.364251: step 5990, loss = 0.69664 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:24:37.346005 ops/training.py:65 2019-01-16 18:24:37.345908: step 5991, loss = 0.70381 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:24:38.328790 ops/training.py:65 2019-01-16 18:24:38.328692: step 5992, loss = 0.68171 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:24:39.311902 ops/training.py:65 2019-01-16 18:24:39.311802: step 5993, loss = 0.69007 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:24:40.293448 ops/training.py:65 2019-01-16 18:24:40.293347: step 5994, loss = 0.70759 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:24:41.274663 ops/training.py:65 2019-01-16 18:24:41.274562: step 5995, loss = 0.70454 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:24:42.256953 ops/training.py:65 2019-01-16 18:24:42.256852: step 5996, loss = 0.70294 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:24:43.238988 ops/training.py:65 2019-01-16 18:24:43.238945: step 5997, loss = 0.69137 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:24:44.220620 ops/training.py:65 2019-01-16 18:24:44.220575: step 5998, loss = 0.70803 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:24:45.201873 ops/training.py:65 2019-01-16 18:24:45.201834: step 5999, loss = 0.68522 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:29:29.591454 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I8192 2019-01-16 18:29:29.592449 ops/training.py:41 2019-01-16 18:29:29.592362: step 6000, loss = 0.69 (0.1 examples/sec; 283.408 sec/batch) | Training accuracy = 0.65625 | Validation accuracy = 0.4899 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_16_30_45_270295
I8192 2019-01-16 18:29:30.585128 ops/training.py:65 2019-01-16 18:29:30.585024: step 6001, loss = 0.71329 (32.3 examples/sec; 0.991 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:29:31.567587 ops/training.py:65 2019-01-16 18:29:31.567487: step 6002, loss = 0.69433 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:29:32.551036 ops/training.py:65 2019-01-16 18:29:32.550966: step 6003, loss = 0.68786 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:29:33.532903 ops/training.py:65 2019-01-16 18:29:33.532839: step 6004, loss = 0.68609 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:29:34.519014 ops/training.py:65 2019-01-16 18:29:34.518915: step 6005, loss = 0.68564 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:29:35.502756 ops/training.py:65 2019-01-16 18:29:35.502653: step 6006, loss = 0.69954 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:29:36.487481 ops/training.py:65 2019-01-16 18:29:36.487380: step 6007, loss = 0.70684 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:29:37.473306 ops/training.py:65 2019-01-16 18:29:37.473201: step 6008, loss = 0.69904 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:29:38.455974 ops/training.py:65 2019-01-16 18:29:38.455877: step 6009, loss = 0.71044 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 18:29:39.438569 ops/training.py:65 2019-01-16 18:29:39.438462: step 6010, loss = 0.68787 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:29:40.423025 ops/training.py:65 2019-01-16 18:29:40.422932: step 6011, loss = 0.68848 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:29:41.407257 ops/training.py:65 2019-01-16 18:29:41.407161: step 6012, loss = 0.69019 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:29:42.392063 ops/training.py:65 2019-01-16 18:29:42.391959: step 6013, loss = 0.68514 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:29:43.378528 ops/training.py:65 2019-01-16 18:29:43.378434: step 6014, loss = 0.70931 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:29:44.364129 ops/training.py:65 2019-01-16 18:29:44.364025: step 6015, loss = 0.69211 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:29:45.348274 ops/training.py:65 2019-01-16 18:29:45.348179: step 6016, loss = 0.69717 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:29:46.331189 ops/training.py:65 2019-01-16 18:29:46.331090: step 6017, loss = 0.70117 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:29:47.314532 ops/training.py:65 2019-01-16 18:29:47.314426: step 6018, loss = 0.68615 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:29:48.298184 ops/training.py:65 2019-01-16 18:29:48.298085: step 6019, loss = 0.68395 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:29:49.282256 ops/training.py:65 2019-01-16 18:29:49.282157: step 6020, loss = 0.70079 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:29:50.266968 ops/training.py:65 2019-01-16 18:29:50.266868: step 6021, loss = 0.68067 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:29:51.252284 ops/training.py:65 2019-01-16 18:29:51.252179: step 6022, loss = 0.69100 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:29:52.237278 ops/training.py:65 2019-01-16 18:29:52.237177: step 6023, loss = 0.69247 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:29:53.223387 ops/training.py:65 2019-01-16 18:29:53.223303: step 6024, loss = 0.70094 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:29:54.207342 ops/training.py:65 2019-01-16 18:29:54.207245: step 6025, loss = 0.69805 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:29:55.191180 ops/training.py:65 2019-01-16 18:29:55.191090: step 6026, loss = 0.70280 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:29:56.177405 ops/training.py:65 2019-01-16 18:29:56.177305: step 6027, loss = 0.68684 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:29:57.163068 ops/training.py:65 2019-01-16 18:29:57.162967: step 6028, loss = 0.69331 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:29:58.145777 ops/training.py:65 2019-01-16 18:29:58.145678: step 6029, loss = 0.68160 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:29:59.134408 ops/training.py:65 2019-01-16 18:29:59.134307: step 6030, loss = 0.67719 (32.4 examples/sec; 0.987 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:30:00.118971 ops/training.py:65 2019-01-16 18:30:00.118871: step 6031, loss = 0.69005 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:30:01.104500 ops/training.py:65 2019-01-16 18:30:01.104399: step 6032, loss = 0.68358 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:30:02.087335 ops/training.py:65 2019-01-16 18:30:02.087249: step 6033, loss = 0.70962 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:30:03.071322 ops/training.py:65 2019-01-16 18:30:03.071221: step 6034, loss = 0.69573 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:30:04.054891 ops/training.py:65 2019-01-16 18:30:04.054790: step 6035, loss = 0.69385 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:30:05.037904 ops/training.py:65 2019-01-16 18:30:05.037810: step 6036, loss = 0.68357 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:30:06.021685 ops/training.py:65 2019-01-16 18:30:06.021588: step 6037, loss = 0.69418 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:30:07.004060 ops/training.py:65 2019-01-16 18:30:07.003970: step 6038, loss = 0.69693 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:30:07.989571 ops/training.py:65 2019-01-16 18:30:07.989468: step 6039, loss = 0.67916 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:30:08.973216 ops/training.py:65 2019-01-16 18:30:08.973113: step 6040, loss = 0.69765 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:30:09.957390 ops/training.py:65 2019-01-16 18:30:09.957300: step 6041, loss = 0.69527 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:30:10.940905 ops/training.py:65 2019-01-16 18:30:10.940808: step 6042, loss = 0.69460 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:30:11.927091 ops/training.py:65 2019-01-16 18:30:11.926993: step 6043, loss = 0.69039 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:30:12.910965 ops/training.py:65 2019-01-16 18:30:12.910860: step 6044, loss = 0.68985 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:30:13.893807 ops/training.py:65 2019-01-16 18:30:13.893705: step 6045, loss = 0.70764 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:30:14.875841 ops/training.py:65 2019-01-16 18:30:14.875735: step 6046, loss = 0.73022 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:30:15.862315 ops/training.py:65 2019-01-16 18:30:15.862219: step 6047, loss = 0.68498 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:30:16.848161 ops/training.py:65 2019-01-16 18:30:16.848062: step 6048, loss = 0.68890 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:30:17.832843 ops/training.py:65 2019-01-16 18:30:17.832738: step 6049, loss = 0.68983 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:30:18.817409 ops/training.py:65 2019-01-16 18:30:18.817299: step 6050, loss = 0.68634 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:30:19.804051 ops/training.py:65 2019-01-16 18:30:19.803943: step 6051, loss = 0.69011 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:30:20.788861 ops/training.py:65 2019-01-16 18:30:20.788754: step 6052, loss = 0.70763 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:30:21.772399 ops/training.py:65 2019-01-16 18:30:21.772299: step 6053, loss = 0.69539 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:30:22.755606 ops/training.py:65 2019-01-16 18:30:22.755499: step 6054, loss = 0.69382 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:30:23.738495 ops/training.py:65 2019-01-16 18:30:23.738392: step 6055, loss = 0.69304 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:30:24.721913 ops/training.py:65 2019-01-16 18:30:24.721830: step 6056, loss = 0.70282 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:30:25.704471 ops/training.py:65 2019-01-16 18:30:25.704367: step 6057, loss = 0.68916 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:30:26.686361 ops/training.py:65 2019-01-16 18:30:26.686258: step 6058, loss = 0.68313 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:30:27.669750 ops/training.py:65 2019-01-16 18:30:27.669639: step 6059, loss = 0.69684 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:30:28.651916 ops/training.py:65 2019-01-16 18:30:28.651818: step 6060, loss = 0.68813 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:30:29.635102 ops/training.py:65 2019-01-16 18:30:29.635003: step 6061, loss = 0.68992 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:30:30.617617 ops/training.py:65 2019-01-16 18:30:30.617521: step 6062, loss = 0.68847 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:30:31.601075 ops/training.py:65 2019-01-16 18:30:31.600970: step 6063, loss = 0.69752 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:30:32.585387 ops/training.py:65 2019-01-16 18:30:32.585281: step 6064, loss = 0.69682 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:30:33.569482 ops/training.py:65 2019-01-16 18:30:33.569384: step 6065, loss = 0.68485 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:30:34.552539 ops/training.py:65 2019-01-16 18:30:34.552435: step 6066, loss = 0.69616 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:30:35.535901 ops/training.py:65 2019-01-16 18:30:35.535807: step 6067, loss = 0.69451 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:30:36.519402 ops/training.py:65 2019-01-16 18:30:36.519306: step 6068, loss = 0.68040 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:30:37.503993 ops/training.py:65 2019-01-16 18:30:37.503891: step 6069, loss = 0.69621 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:30:38.489893 ops/training.py:65 2019-01-16 18:30:38.489795: step 6070, loss = 0.68998 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:30:39.474299 ops/training.py:65 2019-01-16 18:30:39.474184: step 6071, loss = 0.69457 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:30:40.457661 ops/training.py:65 2019-01-16 18:30:40.457573: step 6072, loss = 0.69060 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:30:41.441026 ops/training.py:65 2019-01-16 18:30:41.440932: step 6073, loss = 0.68647 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:30:42.426454 ops/training.py:65 2019-01-16 18:30:42.426349: step 6074, loss = 0.69556 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:30:43.409592 ops/training.py:65 2019-01-16 18:30:43.409498: step 6075, loss = 0.70269 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:30:44.392275 ops/training.py:65 2019-01-16 18:30:44.392167: step 6076, loss = 0.70205 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:30:45.374653 ops/training.py:65 2019-01-16 18:30:45.374576: step 6077, loss = 0.68131 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:30:46.357517 ops/training.py:65 2019-01-16 18:30:46.357448: step 6078, loss = 0.69209 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:30:47.341291 ops/training.py:65 2019-01-16 18:30:47.341184: step 6079, loss = 0.69221 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:30:48.325600 ops/training.py:65 2019-01-16 18:30:48.325492: step 6080, loss = 0.69400 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:30:49.310233 ops/training.py:65 2019-01-16 18:30:49.310132: step 6081, loss = 0.70487 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:30:50.293151 ops/training.py:65 2019-01-16 18:30:50.293051: step 6082, loss = 0.69848 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:30:51.275817 ops/training.py:65 2019-01-16 18:30:51.275757: step 6083, loss = 0.70999 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:30:52.257132 ops/training.py:65 2019-01-16 18:30:52.257058: step 6084, loss = 0.69868 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:30:53.239504 ops/training.py:65 2019-01-16 18:30:53.239419: step 6085, loss = 0.69543 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:30:54.223438 ops/training.py:65 2019-01-16 18:30:54.223377: step 6086, loss = 0.68889 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:30:55.209757 ops/training.py:65 2019-01-16 18:30:55.209659: step 6087, loss = 0.68495 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:30:56.194584 ops/training.py:65 2019-01-16 18:30:56.194483: step 6088, loss = 0.68288 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:30:57.177624 ops/training.py:65 2019-01-16 18:30:57.177559: step 6089, loss = 0.69482 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:30:58.157852 ops/training.py:65 2019-01-16 18:30:58.157788: step 6090, loss = 0.69990 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:30:59.143184 ops/training.py:65 2019-01-16 18:30:59.143103: step 6091, loss = 0.68347 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:31:00.128780 ops/training.py:65 2019-01-16 18:31:00.128673: step 6092, loss = 0.69741 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:31:01.115484 ops/training.py:65 2019-01-16 18:31:01.115381: step 6093, loss = 0.70291 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:31:02.098611 ops/training.py:65 2019-01-16 18:31:02.098515: step 6094, loss = 0.67960 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:31:03.081447 ops/training.py:65 2019-01-16 18:31:03.081347: step 6095, loss = 0.69008 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:31:04.066402 ops/training.py:65 2019-01-16 18:31:04.066301: step 6096, loss = 0.69839 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:31:05.049726 ops/training.py:65 2019-01-16 18:31:05.049620: step 6097, loss = 0.68980 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:31:06.032612 ops/training.py:65 2019-01-16 18:31:06.032509: step 6098, loss = 0.69803 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:31:07.015192 ops/training.py:65 2019-01-16 18:31:07.015095: step 6099, loss = 0.69553 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:31:07.997632 ops/training.py:65 2019-01-16 18:31:07.997527: step 6100, loss = 0.68610 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:31:08.985148 ops/training.py:65 2019-01-16 18:31:08.985042: step 6101, loss = 0.69737 (32.4 examples/sec; 0.986 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:31:09.970635 ops/training.py:65 2019-01-16 18:31:09.970538: step 6102, loss = 0.68477 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:31:10.955049 ops/training.py:65 2019-01-16 18:31:10.954943: step 6103, loss = 0.68902 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:31:11.938013 ops/training.py:65 2019-01-16 18:31:11.937946: step 6104, loss = 0.69552 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:31:12.920327 ops/training.py:65 2019-01-16 18:31:12.920257: step 6105, loss = 0.71288 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:31:13.903869 ops/training.py:65 2019-01-16 18:31:13.903782: step 6106, loss = 0.69306 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:31:14.888186 ops/training.py:65 2019-01-16 18:31:14.888082: step 6107, loss = 0.72715 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:31:15.871435 ops/training.py:65 2019-01-16 18:31:15.871331: step 6108, loss = 0.68042 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:31:16.854527 ops/training.py:65 2019-01-16 18:31:16.854425: step 6109, loss = 0.67695 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:31:17.837336 ops/training.py:65 2019-01-16 18:31:17.837230: step 6110, loss = 0.68716 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:31:18.818700 ops/training.py:65 2019-01-16 18:31:18.818609: step 6111, loss = 0.69663 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:31:19.801393 ops/training.py:65 2019-01-16 18:31:19.801298: step 6112, loss = 0.70900 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:31:20.783331 ops/training.py:65 2019-01-16 18:31:20.783232: step 6113, loss = 0.70188 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:31:21.764321 ops/training.py:65 2019-01-16 18:31:21.764222: step 6114, loss = 0.69095 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:31:22.747537 ops/training.py:65 2019-01-16 18:31:22.747430: step 6115, loss = 0.68830 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:31:23.729975 ops/training.py:65 2019-01-16 18:31:23.729865: step 6116, loss = 0.68530 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:31:24.712718 ops/training.py:65 2019-01-16 18:31:24.712630: step 6117, loss = 0.68511 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:31:25.694510 ops/training.py:65 2019-01-16 18:31:25.694406: step 6118, loss = 0.67398 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.75
I8192 2019-01-16 18:31:26.678250 ops/training.py:65 2019-01-16 18:31:26.678146: step 6119, loss = 0.70822 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:31:27.661232 ops/training.py:65 2019-01-16 18:31:27.661128: step 6120, loss = 0.70168 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:31:28.644827 ops/training.py:65 2019-01-16 18:31:28.644748: step 6121, loss = 0.69376 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:31:29.628012 ops/training.py:65 2019-01-16 18:31:29.627912: step 6122, loss = 0.67902 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:31:30.609843 ops/training.py:65 2019-01-16 18:31:30.609779: step 6123, loss = 0.68380 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:31:31.590362 ops/training.py:65 2019-01-16 18:31:31.590299: step 6124, loss = 0.70228 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:31:32.570886 ops/training.py:65 2019-01-16 18:31:32.570817: step 6125, loss = 0.68847 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:31:33.551587 ops/training.py:65 2019-01-16 18:31:33.551520: step 6126, loss = 0.67946 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:31:34.532929 ops/training.py:65 2019-01-16 18:31:34.532864: step 6127, loss = 0.70005 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:31:35.514135 ops/training.py:65 2019-01-16 18:31:35.514069: step 6128, loss = 0.70712 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:31:36.499641 ops/training.py:65 2019-01-16 18:31:36.499557: step 6129, loss = 0.69337 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:31:37.485325 ops/training.py:65 2019-01-16 18:31:37.485193: step 6130, loss = 0.70015 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:31:38.470211 ops/training.py:65 2019-01-16 18:31:38.470105: step 6131, loss = 0.70482 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:31:39.454300 ops/training.py:65 2019-01-16 18:31:39.454195: step 6132, loss = 0.70531 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:31:40.438726 ops/training.py:65 2019-01-16 18:31:40.438621: step 6133, loss = 0.68996 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:31:41.422792 ops/training.py:65 2019-01-16 18:31:41.422698: step 6134, loss = 0.68570 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:31:42.405590 ops/training.py:65 2019-01-16 18:31:42.405454: step 6135, loss = 0.69991 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:31:43.388056 ops/training.py:65 2019-01-16 18:31:43.387955: step 6136, loss = 0.69965 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:31:44.370806 ops/training.py:65 2019-01-16 18:31:44.370710: step 6137, loss = 0.68915 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:31:45.354065 ops/training.py:65 2019-01-16 18:31:45.353956: step 6138, loss = 0.69489 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:31:46.336579 ops/training.py:65 2019-01-16 18:31:46.336474: step 6139, loss = 0.69160 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:31:47.322680 ops/training.py:65 2019-01-16 18:31:47.322636: step 6140, loss = 0.69786 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:31:48.306062 ops/training.py:65 2019-01-16 18:31:48.305995: step 6141, loss = 0.69011 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:31:49.287903 ops/training.py:65 2019-01-16 18:31:49.287835: step 6142, loss = 0.69056 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:31:50.268222 ops/training.py:65 2019-01-16 18:31:50.268156: step 6143, loss = 0.69249 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:31:51.250136 ops/training.py:65 2019-01-16 18:31:51.250073: step 6144, loss = 0.66958 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:31:52.230541 ops/training.py:65 2019-01-16 18:31:52.230457: step 6145, loss = 0.69001 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:31:53.211700 ops/training.py:65 2019-01-16 18:31:53.211633: step 6146, loss = 0.68836 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:31:54.192057 ops/training.py:65 2019-01-16 18:31:54.191995: step 6147, loss = 0.69743 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:31:55.172387 ops/training.py:65 2019-01-16 18:31:55.172322: step 6148, loss = 0.70648 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:31:56.153787 ops/training.py:65 2019-01-16 18:31:56.153709: step 6149, loss = 0.71276 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:31:57.134205 ops/training.py:65 2019-01-16 18:31:57.134125: step 6150, loss = 0.69692 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:31:58.124357 ops/training.py:65 2019-01-16 18:31:58.124270: step 6151, loss = 0.67927 (32.4 examples/sec; 0.989 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:31:59.109859 ops/training.py:65 2019-01-16 18:31:59.109748: step 6152, loss = 0.70433 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:32:00.092690 ops/training.py:65 2019-01-16 18:32:00.092586: step 6153, loss = 0.68454 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:32:01.077112 ops/training.py:65 2019-01-16 18:32:01.077003: step 6154, loss = 0.69804 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:32:02.059698 ops/training.py:65 2019-01-16 18:32:02.059597: step 6155, loss = 0.67500 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:32:03.044649 ops/training.py:65 2019-01-16 18:32:03.044545: step 6156, loss = 0.70183 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:32:04.026705 ops/training.py:65 2019-01-16 18:32:04.026602: step 6157, loss = 0.71796 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:32:05.011288 ops/training.py:65 2019-01-16 18:32:05.011186: step 6158, loss = 0.69984 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:32:05.996973 ops/training.py:65 2019-01-16 18:32:05.996872: step 6159, loss = 0.69639 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:32:06.982208 ops/training.py:65 2019-01-16 18:32:06.982097: step 6160, loss = 0.71922 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:32:07.965326 ops/training.py:65 2019-01-16 18:32:07.965217: step 6161, loss = 0.67668 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:32:08.947781 ops/training.py:65 2019-01-16 18:32:08.947673: step 6162, loss = 0.70258 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:32:09.931605 ops/training.py:65 2019-01-16 18:32:09.931512: step 6163, loss = 0.71954 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:32:10.915933 ops/training.py:65 2019-01-16 18:32:10.915794: step 6164, loss = 0.69389 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:32:11.900144 ops/training.py:65 2019-01-16 18:32:11.900031: step 6165, loss = 0.68417 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:32:12.882840 ops/training.py:65 2019-01-16 18:32:12.882728: step 6166, loss = 0.69759 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:32:13.865165 ops/training.py:65 2019-01-16 18:32:13.865076: step 6167, loss = 0.71402 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:32:14.848927 ops/training.py:65 2019-01-16 18:32:14.848822: step 6168, loss = 0.70028 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:32:15.834501 ops/training.py:65 2019-01-16 18:32:15.834399: step 6169, loss = 0.69407 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:32:16.817546 ops/training.py:65 2019-01-16 18:32:16.817444: step 6170, loss = 0.69871 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:32:17.800825 ops/training.py:65 2019-01-16 18:32:17.800718: step 6171, loss = 0.70417 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:32:18.782707 ops/training.py:65 2019-01-16 18:32:18.782593: step 6172, loss = 0.71357 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:32:19.766315 ops/training.py:65 2019-01-16 18:32:19.766209: step 6173, loss = 0.68374 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:32:20.749550 ops/training.py:65 2019-01-16 18:32:20.749443: step 6174, loss = 0.68688 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:32:21.732398 ops/training.py:65 2019-01-16 18:32:21.732301: step 6175, loss = 0.68703 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:32:22.716529 ops/training.py:65 2019-01-16 18:32:22.716421: step 6176, loss = 0.68822 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:32:23.700066 ops/training.py:65 2019-01-16 18:32:23.699968: step 6177, loss = 0.66735 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:32:24.683503 ops/training.py:65 2019-01-16 18:32:24.683405: step 6178, loss = 0.73642 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.25
I8192 2019-01-16 18:32:25.665989 ops/training.py:65 2019-01-16 18:32:25.665892: step 6179, loss = 0.68868 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:32:26.648886 ops/training.py:65 2019-01-16 18:32:26.648785: step 6180, loss = 0.68085 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:32:27.632285 ops/training.py:65 2019-01-16 18:32:27.632178: step 6181, loss = 0.70246 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:32:28.614164 ops/training.py:65 2019-01-16 18:32:28.614068: step 6182, loss = 0.70224 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:32:29.598939 ops/training.py:65 2019-01-16 18:32:29.598866: step 6183, loss = 0.72039 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:32:30.583020 ops/training.py:65 2019-01-16 18:32:30.582919: step 6184, loss = 0.67315 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:32:31.568058 ops/training.py:65 2019-01-16 18:32:31.567952: step 6185, loss = 0.68120 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:32:32.551186 ops/training.py:65 2019-01-16 18:32:32.551079: step 6186, loss = 0.69453 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:32:33.535453 ops/training.py:65 2019-01-16 18:32:33.535392: step 6187, loss = 0.69946 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:32:34.518695 ops/training.py:65 2019-01-16 18:32:34.518598: step 6188, loss = 0.67949 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:32:35.502169 ops/training.py:65 2019-01-16 18:32:35.502070: step 6189, loss = 0.70824 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:32:36.484630 ops/training.py:65 2019-01-16 18:32:36.484489: step 6190, loss = 0.71867 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:32:37.470332 ops/training.py:65 2019-01-16 18:32:37.470186: step 6191, loss = 0.72154 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:32:38.455966 ops/training.py:65 2019-01-16 18:32:38.455866: step 6192, loss = 0.69237 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:32:39.440096 ops/training.py:65 2019-01-16 18:32:39.439993: step 6193, loss = 0.68695 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:32:40.424533 ops/training.py:65 2019-01-16 18:32:40.424446: step 6194, loss = 0.71312 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:32:41.407462 ops/training.py:65 2019-01-16 18:32:41.407325: step 6195, loss = 0.70716 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:32:42.390453 ops/training.py:65 2019-01-16 18:32:42.390379: step 6196, loss = 0.70678 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:32:43.372654 ops/training.py:65 2019-01-16 18:32:43.372585: step 6197, loss = 0.69152 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:32:44.356802 ops/training.py:65 2019-01-16 18:32:44.356730: step 6198, loss = 0.69656 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:32:45.340588 ops/training.py:65 2019-01-16 18:32:45.340483: step 6199, loss = 0.69585 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:32:46.323997 ops/training.py:65 2019-01-16 18:32:46.323891: step 6200, loss = 0.68668 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:32:47.306932 ops/training.py:65 2019-01-16 18:32:47.306826: step 6201, loss = 0.69693 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:32:48.292801 ops/training.py:65 2019-01-16 18:32:48.292693: step 6202, loss = 0.69746 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:32:49.277754 ops/training.py:65 2019-01-16 18:32:49.277612: step 6203, loss = 0.71076 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:32:50.261852 ops/training.py:65 2019-01-16 18:32:50.261748: step 6204, loss = 0.68217 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:32:51.245133 ops/training.py:65 2019-01-16 18:32:51.245043: step 6205, loss = 0.69652 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:32:52.227049 ops/training.py:65 2019-01-16 18:32:52.226943: step 6206, loss = 0.70174 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:32:53.210012 ops/training.py:65 2019-01-16 18:32:53.209913: step 6207, loss = 0.69222 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:32:54.192553 ops/training.py:65 2019-01-16 18:32:54.192449: step 6208, loss = 0.69566 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:32:55.175675 ops/training.py:65 2019-01-16 18:32:55.175582: step 6209, loss = 0.69865 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:32:56.158528 ops/training.py:65 2019-01-16 18:32:56.158428: step 6210, loss = 0.69755 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:32:57.143221 ops/training.py:65 2019-01-16 18:32:57.143157: step 6211, loss = 0.68628 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:32:58.126686 ops/training.py:65 2019-01-16 18:32:58.126579: step 6212, loss = 0.68515 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:32:59.114237 ops/training.py:65 2019-01-16 18:32:59.114130: step 6213, loss = 0.69456 (32.4 examples/sec; 0.986 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:33:00.098449 ops/training.py:65 2019-01-16 18:33:00.098341: step 6214, loss = 0.68418 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:33:01.082899 ops/training.py:65 2019-01-16 18:33:01.082800: step 6215, loss = 0.68239 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:33:02.064970 ops/training.py:65 2019-01-16 18:33:02.064901: step 6216, loss = 0.68470 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:33:03.047076 ops/training.py:65 2019-01-16 18:33:03.047012: step 6217, loss = 0.68509 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:33:04.030267 ops/training.py:65 2019-01-16 18:33:04.030193: step 6218, loss = 0.71492 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 18:33:05.014215 ops/training.py:65 2019-01-16 18:33:05.014108: step 6219, loss = 0.70483 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:33:06.006310 ops/training.py:65 2019-01-16 18:33:06.006202: step 6220, loss = 0.69096 (32.3 examples/sec; 0.991 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:33:06.990553 ops/training.py:65 2019-01-16 18:33:06.990456: step 6221, loss = 0.69356 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:33:07.974444 ops/training.py:65 2019-01-16 18:33:07.974335: step 6222, loss = 0.68537 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:33:08.959708 ops/training.py:65 2019-01-16 18:33:08.959627: step 6223, loss = 0.70228 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:33:09.945067 ops/training.py:65 2019-01-16 18:33:09.944976: step 6224, loss = 0.69253 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:33:10.930440 ops/training.py:65 2019-01-16 18:33:10.930332: step 6225, loss = 0.72172 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:33:11.936377 ops/training.py:65 2019-01-16 18:33:11.936272: step 6226, loss = 0.67673 (31.8 examples/sec; 1.005 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:33:12.920300 ops/training.py:65 2019-01-16 18:33:12.920194: step 6227, loss = 0.69081 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:33:13.905295 ops/training.py:65 2019-01-16 18:33:13.905224: step 6228, loss = 0.70434 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:33:14.889813 ops/training.py:65 2019-01-16 18:33:14.889712: step 6229, loss = 0.69239 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:33:15.872419 ops/training.py:65 2019-01-16 18:33:15.872313: step 6230, loss = 0.68485 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:33:16.855075 ops/training.py:65 2019-01-16 18:33:16.854977: step 6231, loss = 0.70881 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:33:17.837612 ops/training.py:65 2019-01-16 18:33:17.837505: step 6232, loss = 0.68380 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:33:18.820722 ops/training.py:65 2019-01-16 18:33:18.820617: step 6233, loss = 0.67912 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:33:19.803459 ops/training.py:65 2019-01-16 18:33:19.803363: step 6234, loss = 0.69527 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:33:20.786674 ops/training.py:65 2019-01-16 18:33:20.786573: step 6235, loss = 0.68882 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:33:21.770478 ops/training.py:65 2019-01-16 18:33:21.770375: step 6236, loss = 0.71297 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:33:22.753516 ops/training.py:65 2019-01-16 18:33:22.753406: step 6237, loss = 0.68750 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:33:23.736568 ops/training.py:65 2019-01-16 18:33:23.736468: step 6238, loss = 0.70709 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:33:24.721851 ops/training.py:65 2019-01-16 18:33:24.721750: step 6239, loss = 0.69892 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:33:25.704617 ops/training.py:65 2019-01-16 18:33:25.704527: step 6240, loss = 0.69771 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:33:26.690175 ops/training.py:65 2019-01-16 18:33:26.690071: step 6241, loss = 0.69519 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:33:27.675768 ops/training.py:65 2019-01-16 18:33:27.675663: step 6242, loss = 0.69278 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:33:28.660905 ops/training.py:65 2019-01-16 18:33:28.660807: step 6243, loss = 0.66776 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.75
I8192 2019-01-16 18:33:29.644997 ops/training.py:65 2019-01-16 18:33:29.644903: step 6244, loss = 0.69897 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:33:30.629770 ops/training.py:65 2019-01-16 18:33:30.629675: step 6245, loss = 0.69990 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:33:31.615084 ops/training.py:65 2019-01-16 18:33:31.614986: step 6246, loss = 0.70167 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:33:32.600081 ops/training.py:65 2019-01-16 18:33:32.599981: step 6247, loss = 0.68955 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:33:33.583375 ops/training.py:65 2019-01-16 18:33:33.583283: step 6248, loss = 0.68805 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:33:34.567062 ops/training.py:65 2019-01-16 18:33:34.566964: step 6249, loss = 0.68454 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:33:35.550097 ops/training.py:65 2019-01-16 18:33:35.549993: step 6250, loss = 0.67870 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:33:36.533166 ops/training.py:65 2019-01-16 18:33:36.533064: step 6251, loss = 0.69281 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:33:37.516008 ops/training.py:65 2019-01-16 18:33:37.515905: step 6252, loss = 0.70743 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:33:38.500385 ops/training.py:65 2019-01-16 18:33:38.500282: step 6253, loss = 0.68512 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:33:39.483207 ops/training.py:65 2019-01-16 18:33:39.483103: step 6254, loss = 0.71603 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:33:40.466550 ops/training.py:65 2019-01-16 18:33:40.466460: step 6255, loss = 0.69233 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:33:41.449750 ops/training.py:65 2019-01-16 18:33:41.449653: step 6256, loss = 0.70773 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:33:42.432421 ops/training.py:65 2019-01-16 18:33:42.432319: step 6257, loss = 0.71892 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:33:43.416457 ops/training.py:65 2019-01-16 18:33:43.416355: step 6258, loss = 0.68121 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:33:44.399191 ops/training.py:65 2019-01-16 18:33:44.399097: step 6259, loss = 0.68188 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:33:45.380985 ops/training.py:65 2019-01-16 18:33:45.380887: step 6260, loss = 0.69600 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:33:46.363140 ops/training.py:65 2019-01-16 18:33:46.363042: step 6261, loss = 0.70527 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:33:47.346584 ops/training.py:65 2019-01-16 18:33:47.346481: step 6262, loss = 0.69006 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:33:48.330685 ops/training.py:65 2019-01-16 18:33:48.330577: step 6263, loss = 0.69587 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:33:49.313681 ops/training.py:65 2019-01-16 18:33:49.313548: step 6264, loss = 0.68935 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:33:50.297249 ops/training.py:65 2019-01-16 18:33:50.297149: step 6265, loss = 0.70881 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:33:51.280797 ops/training.py:65 2019-01-16 18:33:51.280693: step 6266, loss = 0.68958 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:33:52.265104 ops/training.py:65 2019-01-16 18:33:52.265020: step 6267, loss = 0.66832 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:33:53.247749 ops/training.py:65 2019-01-16 18:33:53.247685: step 6268, loss = 0.70125 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:33:54.227867 ops/training.py:65 2019-01-16 18:33:54.227804: step 6269, loss = 0.68033 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:33:55.207170 ops/training.py:65 2019-01-16 18:33:55.207108: step 6270, loss = 0.68408 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:33:56.191852 ops/training.py:65 2019-01-16 18:33:56.191782: step 6271, loss = 0.68838 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:33:57.175358 ops/training.py:65 2019-01-16 18:33:57.175251: step 6272, loss = 0.70230 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:33:58.158278 ops/training.py:65 2019-01-16 18:33:58.158174: step 6273, loss = 0.68667 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:33:59.140051 ops/training.py:65 2019-01-16 18:33:59.139984: step 6274, loss = 0.73034 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:34:00.119189 ops/training.py:65 2019-01-16 18:34:00.119128: step 6275, loss = 0.69882 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:34:01.098657 ops/training.py:65 2019-01-16 18:34:01.098594: step 6276, loss = 0.72527 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:34:02.083963 ops/training.py:65 2019-01-16 18:34:02.083872: step 6277, loss = 0.74700 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:34:03.070062 ops/training.py:65 2019-01-16 18:34:03.069874: step 6278, loss = 0.66119 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:34:04.054357 ops/training.py:65 2019-01-16 18:34:04.054255: step 6279, loss = 0.69271 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:34:05.039685 ops/training.py:65 2019-01-16 18:34:05.039582: step 6280, loss = 0.70227 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:34:06.023292 ops/training.py:65 2019-01-16 18:34:06.023199: step 6281, loss = 0.67379 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:34:07.007673 ops/training.py:65 2019-01-16 18:34:07.007573: step 6282, loss = 0.66247 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:34:07.993540 ops/training.py:65 2019-01-16 18:34:07.993437: step 6283, loss = 0.68622 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:34:08.977244 ops/training.py:65 2019-01-16 18:34:08.977138: step 6284, loss = 0.70941 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:34:09.961356 ops/training.py:65 2019-01-16 18:34:09.961264: step 6285, loss = 0.68563 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:34:10.945807 ops/training.py:65 2019-01-16 18:34:10.945707: step 6286, loss = 0.67933 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:34:11.933643 ops/training.py:65 2019-01-16 18:34:11.933541: step 6287, loss = 0.68392 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:34:12.916569 ops/training.py:65 2019-01-16 18:34:12.916469: step 6288, loss = 0.69877 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:34:13.899754 ops/training.py:65 2019-01-16 18:34:13.899652: step 6289, loss = 0.69762 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:34:14.882532 ops/training.py:65 2019-01-16 18:34:14.882437: step 6290, loss = 0.70692 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:34:15.865279 ops/training.py:65 2019-01-16 18:34:15.865185: step 6291, loss = 0.67584 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:34:16.848509 ops/training.py:65 2019-01-16 18:34:16.848404: step 6292, loss = 0.69893 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:34:17.831800 ops/training.py:65 2019-01-16 18:34:17.831704: step 6293, loss = 0.68889 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:34:18.815898 ops/training.py:65 2019-01-16 18:34:18.815815: step 6294, loss = 0.69129 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:34:19.800254 ops/training.py:65 2019-01-16 18:34:19.800165: step 6295, loss = 0.68158 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:34:20.784984 ops/training.py:65 2019-01-16 18:34:20.784886: step 6296, loss = 0.70563 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:34:21.769818 ops/training.py:65 2019-01-16 18:34:21.769715: step 6297, loss = 0.69920 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:34:22.754881 ops/training.py:65 2019-01-16 18:34:22.754791: step 6298, loss = 0.68851 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:34:23.738597 ops/training.py:65 2019-01-16 18:34:23.738503: step 6299, loss = 0.66253 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:34:24.721660 ops/training.py:65 2019-01-16 18:34:24.721571: step 6300, loss = 0.67395 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:34:25.705287 ops/training.py:65 2019-01-16 18:34:25.705198: step 6301, loss = 0.70578 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:34:26.689439 ops/training.py:65 2019-01-16 18:34:26.689341: step 6302, loss = 0.67795 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:34:27.673113 ops/training.py:65 2019-01-16 18:34:27.673018: step 6303, loss = 0.69351 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:34:28.655571 ops/training.py:65 2019-01-16 18:34:28.655472: step 6304, loss = 0.70386 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:34:29.638488 ops/training.py:65 2019-01-16 18:34:29.638386: step 6305, loss = 0.70434 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:34:30.621322 ops/training.py:65 2019-01-16 18:34:30.621219: step 6306, loss = 0.68033 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:34:31.604006 ops/training.py:65 2019-01-16 18:34:31.603940: step 6307, loss = 0.68359 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:34:32.584315 ops/training.py:65 2019-01-16 18:34:32.584255: step 6308, loss = 0.68886 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:34:33.563691 ops/training.py:65 2019-01-16 18:34:33.563621: step 6309, loss = 0.70347 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:34:34.546965 ops/training.py:65 2019-01-16 18:34:34.546893: step 6310, loss = 0.67827 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:34:35.531611 ops/training.py:65 2019-01-16 18:34:35.531511: step 6311, loss = 0.71812 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:34:36.514856 ops/training.py:65 2019-01-16 18:34:36.514762: step 6312, loss = 0.70091 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:34:37.498091 ops/training.py:65 2019-01-16 18:34:37.498000: step 6313, loss = 0.70225 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:34:38.480139 ops/training.py:65 2019-01-16 18:34:38.479993: step 6314, loss = 0.72191 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:34:39.463883 ops/training.py:65 2019-01-16 18:34:39.463780: step 6315, loss = 0.69366 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:34:40.448348 ops/training.py:65 2019-01-16 18:34:40.448254: step 6316, loss = 0.69375 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:34:41.432275 ops/training.py:65 2019-01-16 18:34:41.432178: step 6317, loss = 0.70945 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:34:42.416108 ops/training.py:65 2019-01-16 18:34:42.416002: step 6318, loss = 0.67782 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:34:43.402293 ops/training.py:65 2019-01-16 18:34:43.402189: step 6319, loss = 0.68989 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:34:44.387553 ops/training.py:65 2019-01-16 18:34:44.387452: step 6320, loss = 0.69087 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:34:45.371191 ops/training.py:65 2019-01-16 18:34:45.371091: step 6321, loss = 0.69157 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:34:46.353431 ops/training.py:65 2019-01-16 18:34:46.353351: step 6322, loss = 0.70117 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:34:47.335127 ops/training.py:65 2019-01-16 18:34:47.335055: step 6323, loss = 0.68923 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:34:48.315452 ops/training.py:65 2019-01-16 18:34:48.315380: step 6324, loss = 0.70723 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:34:49.297380 ops/training.py:65 2019-01-16 18:34:49.297306: step 6325, loss = 0.68663 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:34:50.278193 ops/training.py:65 2019-01-16 18:34:50.278118: step 6326, loss = 0.68878 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:34:51.258671 ops/training.py:65 2019-01-16 18:34:51.258598: step 6327, loss = 0.71674 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:34:52.239336 ops/training.py:65 2019-01-16 18:34:52.239273: step 6328, loss = 0.71654 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:34:53.224554 ops/training.py:65 2019-01-16 18:34:53.224477: step 6329, loss = 0.70255 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:34:54.208451 ops/training.py:65 2019-01-16 18:34:54.208355: step 6330, loss = 0.69417 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:34:55.191995 ops/training.py:65 2019-01-16 18:34:55.191904: step 6331, loss = 0.70757 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:34:56.174711 ops/training.py:65 2019-01-16 18:34:56.174611: step 6332, loss = 0.69509 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:34:57.157895 ops/training.py:65 2019-01-16 18:34:57.157801: step 6333, loss = 0.70312 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:34:58.142070 ops/training.py:65 2019-01-16 18:34:58.141963: step 6334, loss = 0.68638 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:34:59.126577 ops/training.py:65 2019-01-16 18:34:59.126471: step 6335, loss = 0.69055 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:35:00.109140 ops/training.py:65 2019-01-16 18:35:00.109030: step 6336, loss = 0.70391 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:35:01.091067 ops/training.py:65 2019-01-16 18:35:01.091003: step 6337, loss = 0.70463 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:35:02.071492 ops/training.py:65 2019-01-16 18:35:02.071419: step 6338, loss = 0.71092 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:35:03.056530 ops/training.py:65 2019-01-16 18:35:03.056440: step 6339, loss = 0.68491 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:35:04.040065 ops/training.py:65 2019-01-16 18:35:04.039963: step 6340, loss = 0.68924 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:35:05.025654 ops/training.py:65 2019-01-16 18:35:05.025555: step 6341, loss = 0.68852 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:35:06.010352 ops/training.py:65 2019-01-16 18:35:06.010255: step 6342, loss = 0.69463 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:35:06.994338 ops/training.py:65 2019-01-16 18:35:06.994233: step 6343, loss = 0.69644 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:35:07.979901 ops/training.py:65 2019-01-16 18:35:07.979797: step 6344, loss = 0.69171 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:35:08.963314 ops/training.py:65 2019-01-16 18:35:08.963209: step 6345, loss = 0.69203 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:35:09.945792 ops/training.py:65 2019-01-16 18:35:09.945684: step 6346, loss = 0.68824 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:35:10.928505 ops/training.py:65 2019-01-16 18:35:10.928400: step 6347, loss = 0.70414 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:35:11.911055 ops/training.py:65 2019-01-16 18:35:11.910950: step 6348, loss = 0.68266 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:35:12.893314 ops/training.py:65 2019-01-16 18:35:12.893209: step 6349, loss = 0.71071 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:35:13.875671 ops/training.py:65 2019-01-16 18:35:13.875594: step 6350, loss = 0.68624 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:35:14.858919 ops/training.py:65 2019-01-16 18:35:14.858828: step 6351, loss = 0.70564 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:35:15.845160 ops/training.py:65 2019-01-16 18:35:15.845055: step 6352, loss = 0.71452 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:35:16.829659 ops/training.py:65 2019-01-16 18:35:16.829556: step 6353, loss = 0.67861 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:35:17.815227 ops/training.py:65 2019-01-16 18:35:17.815127: step 6354, loss = 0.68913 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:35:18.799471 ops/training.py:65 2019-01-16 18:35:18.799373: step 6355, loss = 0.71272 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:35:19.784394 ops/training.py:65 2019-01-16 18:35:19.784293: step 6356, loss = 0.68372 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:35:20.768556 ops/training.py:65 2019-01-16 18:35:20.768448: step 6357, loss = 0.69038 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:35:21.752034 ops/training.py:65 2019-01-16 18:35:21.751933: step 6358, loss = 0.69853 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:35:22.734523 ops/training.py:65 2019-01-16 18:35:22.734431: step 6359, loss = 0.71441 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:35:23.716789 ops/training.py:65 2019-01-16 18:35:23.716695: step 6360, loss = 0.68209 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:35:24.699694 ops/training.py:65 2019-01-16 18:35:24.699591: step 6361, loss = 0.68149 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:35:25.684218 ops/training.py:65 2019-01-16 18:35:25.684137: step 6362, loss = 0.69437 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:35:26.669991 ops/training.py:65 2019-01-16 18:35:26.669896: step 6363, loss = 0.68972 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:35:27.653979 ops/training.py:65 2019-01-16 18:35:27.653868: step 6364, loss = 0.69054 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:35:28.637583 ops/training.py:65 2019-01-16 18:35:28.637483: step 6365, loss = 0.70552 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:35:29.621648 ops/training.py:65 2019-01-16 18:35:29.621542: step 6366, loss = 0.69105 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:35:30.604296 ops/training.py:65 2019-01-16 18:35:30.604197: step 6367, loss = 0.69665 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:35:31.590646 ops/training.py:65 2019-01-16 18:35:31.590572: step 6368, loss = 0.67970 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:35:32.574753 ops/training.py:65 2019-01-16 18:35:32.574645: step 6369, loss = 0.69845 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:35:33.559078 ops/training.py:65 2019-01-16 18:35:33.558986: step 6370, loss = 0.69714 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:35:34.544525 ops/training.py:65 2019-01-16 18:35:34.544425: step 6371, loss = 0.68602 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:35:35.528452 ops/training.py:65 2019-01-16 18:35:35.528351: step 6372, loss = 0.70599 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:35:36.511334 ops/training.py:65 2019-01-16 18:35:36.511228: step 6373, loss = 0.68606 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:35:37.492718 ops/training.py:65 2019-01-16 18:35:37.492654: step 6374, loss = 0.69352 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:35:38.478249 ops/training.py:65 2019-01-16 18:35:38.478166: step 6375, loss = 0.69427 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:35:39.464021 ops/training.py:65 2019-01-16 18:35:39.463912: step 6376, loss = 0.69010 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:35:40.447848 ops/training.py:65 2019-01-16 18:35:40.447761: step 6377, loss = 0.71387 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:35:41.430625 ops/training.py:65 2019-01-16 18:35:41.430525: step 6378, loss = 0.69453 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:35:42.414085 ops/training.py:65 2019-01-16 18:35:42.413982: step 6379, loss = 0.69909 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:35:43.397391 ops/training.py:65 2019-01-16 18:35:43.397291: step 6380, loss = 0.69876 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:35:44.380574 ops/training.py:65 2019-01-16 18:35:44.380464: step 6381, loss = 0.69916 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:35:45.371015 ops/training.py:65 2019-01-16 18:35:45.370881: step 6382, loss = 0.68543 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:35:46.353755 ops/training.py:65 2019-01-16 18:35:46.353653: step 6383, loss = 0.69983 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:35:47.337737 ops/training.py:65 2019-01-16 18:35:47.337636: step 6384, loss = 0.71806 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:35:48.320502 ops/training.py:65 2019-01-16 18:35:48.320400: step 6385, loss = 0.68528 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:35:49.306769 ops/training.py:65 2019-01-16 18:35:49.306684: step 6386, loss = 0.70633 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:35:50.292019 ops/training.py:65 2019-01-16 18:35:50.291915: step 6387, loss = 0.68931 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:35:51.276313 ops/training.py:65 2019-01-16 18:35:51.276208: step 6388, loss = 0.71282 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 18:35:52.258324 ops/training.py:65 2019-01-16 18:35:52.258224: step 6389, loss = 0.69123 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:35:53.241211 ops/training.py:65 2019-01-16 18:35:53.241110: step 6390, loss = 0.70770 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:35:54.224181 ops/training.py:65 2019-01-16 18:35:54.224072: step 6391, loss = 0.71201 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:35:55.208726 ops/training.py:65 2019-01-16 18:35:55.208626: step 6392, loss = 0.67438 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:35:56.194561 ops/training.py:65 2019-01-16 18:35:56.194477: step 6393, loss = 0.70079 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:35:57.178276 ops/training.py:65 2019-01-16 18:35:57.178175: step 6394, loss = 0.70308 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:35:58.163204 ops/training.py:65 2019-01-16 18:35:58.163108: step 6395, loss = 0.69466 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:35:59.146096 ops/training.py:65 2019-01-16 18:35:59.145992: step 6396, loss = 0.69246 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:36:00.128508 ops/training.py:65 2019-01-16 18:36:00.128397: step 6397, loss = 0.70606 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:36:01.110727 ops/training.py:65 2019-01-16 18:36:01.110624: step 6398, loss = 0.70375 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:36:02.093762 ops/training.py:65 2019-01-16 18:36:02.093659: step 6399, loss = 0.68215 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:36:03.076041 ops/training.py:65 2019-01-16 18:36:03.075938: step 6400, loss = 0.69391 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:36:04.058785 ops/training.py:65 2019-01-16 18:36:04.058687: step 6401, loss = 0.69346 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:36:05.042960 ops/training.py:65 2019-01-16 18:36:05.042856: step 6402, loss = 0.70171 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:36:06.026722 ops/training.py:65 2019-01-16 18:36:06.026618: step 6403, loss = 0.68932 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:36:07.012714 ops/training.py:65 2019-01-16 18:36:07.012629: step 6404, loss = 0.71522 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:36:07.999006 ops/training.py:65 2019-01-16 18:36:07.998898: step 6405, loss = 0.69021 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:36:08.982591 ops/training.py:65 2019-01-16 18:36:08.982495: step 6406, loss = 0.67766 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:36:09.964798 ops/training.py:65 2019-01-16 18:36:09.964685: step 6407, loss = 0.70298 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:36:10.948015 ops/training.py:65 2019-01-16 18:36:10.947912: step 6408, loss = 0.68979 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:36:11.931276 ops/training.py:65 2019-01-16 18:36:11.931170: step 6409, loss = 0.70467 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:36:12.912937 ops/training.py:65 2019-01-16 18:36:12.912837: step 6410, loss = 0.71509 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:36:13.895156 ops/training.py:65 2019-01-16 18:36:13.895052: step 6411, loss = 0.69735 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:36:14.879590 ops/training.py:65 2019-01-16 18:36:14.879488: step 6412, loss = 0.69651 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:36:15.865456 ops/training.py:65 2019-01-16 18:36:15.865349: step 6413, loss = 0.70165 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:36:16.850080 ops/training.py:65 2019-01-16 18:36:16.849981: step 6414, loss = 0.68564 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:36:17.835167 ops/training.py:65 2019-01-16 18:36:17.835069: step 6415, loss = 0.69773 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:36:18.817641 ops/training.py:65 2019-01-16 18:36:18.817538: step 6416, loss = 0.68518 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:36:19.799844 ops/training.py:65 2019-01-16 18:36:19.799773: step 6417, loss = 0.69978 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:36:20.779693 ops/training.py:65 2019-01-16 18:36:20.779619: step 6418, loss = 0.70656 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:36:21.761105 ops/training.py:65 2019-01-16 18:36:21.761034: step 6419, loss = 0.68095 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:36:22.742269 ops/training.py:65 2019-01-16 18:36:22.742201: step 6420, loss = 0.69665 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:36:23.722641 ops/training.py:65 2019-01-16 18:36:23.722571: step 6421, loss = 0.69829 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:36:24.706504 ops/training.py:65 2019-01-16 18:36:24.706414: step 6422, loss = 0.69045 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:36:25.690778 ops/training.py:65 2019-01-16 18:36:25.690687: step 6423, loss = 0.70313 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:36:26.673111 ops/training.py:65 2019-01-16 18:36:26.673010: step 6424, loss = 0.68039 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:36:27.656041 ops/training.py:65 2019-01-16 18:36:27.655938: step 6425, loss = 0.69779 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:36:28.639217 ops/training.py:65 2019-01-16 18:36:28.639119: step 6426, loss = 0.68333 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:36:29.622961 ops/training.py:65 2019-01-16 18:36:29.622864: step 6427, loss = 0.70756 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:36:30.605167 ops/training.py:65 2019-01-16 18:36:30.605065: step 6428, loss = 0.67896 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:36:31.591239 ops/training.py:65 2019-01-16 18:36:31.591137: step 6429, loss = 0.70234 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:36:32.573325 ops/training.py:65 2019-01-16 18:36:32.573253: step 6430, loss = 0.71176 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:36:33.555955 ops/training.py:65 2019-01-16 18:36:33.555871: step 6431, loss = 0.70075 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:36:34.539729 ops/training.py:65 2019-01-16 18:36:34.539626: step 6432, loss = 0.68642 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:36:35.522139 ops/training.py:65 2019-01-16 18:36:35.522034: step 6433, loss = 0.69947 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:36:36.504907 ops/training.py:65 2019-01-16 18:36:36.504806: step 6434, loss = 0.69677 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:36:37.488333 ops/training.py:65 2019-01-16 18:36:37.488226: step 6435, loss = 0.69565 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:36:38.473313 ops/training.py:65 2019-01-16 18:36:38.473211: step 6436, loss = 0.69471 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:36:39.458831 ops/training.py:65 2019-01-16 18:36:39.458731: step 6437, loss = 0.69440 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:36:40.443596 ops/training.py:65 2019-01-16 18:36:40.443496: step 6438, loss = 0.69193 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:36:41.426897 ops/training.py:65 2019-01-16 18:36:41.426767: step 6439, loss = 0.69118 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:36:42.410649 ops/training.py:65 2019-01-16 18:36:42.410541: step 6440, loss = 0.68551 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:36:43.396067 ops/training.py:65 2019-01-16 18:36:43.395965: step 6441, loss = 0.69768 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:36:44.378732 ops/training.py:65 2019-01-16 18:36:44.378632: step 6442, loss = 0.69690 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:36:45.360827 ops/training.py:65 2019-01-16 18:36:45.360732: step 6443, loss = 0.71922 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 18:36:46.345475 ops/training.py:65 2019-01-16 18:36:46.345400: step 6444, loss = 0.68950 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:36:47.329514 ops/training.py:65 2019-01-16 18:36:47.329410: step 6445, loss = 0.69970 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:36:48.311904 ops/training.py:65 2019-01-16 18:36:48.311808: step 6446, loss = 0.71095 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:36:49.294274 ops/training.py:65 2019-01-16 18:36:49.294205: step 6447, loss = 0.68793 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:36:50.278402 ops/training.py:65 2019-01-16 18:36:50.278300: step 6448, loss = 0.70428 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:36:51.261752 ops/training.py:65 2019-01-16 18:36:51.261646: step 6449, loss = 0.69117 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:36:52.246374 ops/training.py:65 2019-01-16 18:36:52.246267: step 6450, loss = 0.70520 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:36:53.232361 ops/training.py:65 2019-01-16 18:36:53.232266: step 6451, loss = 0.69460 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:36:54.215308 ops/training.py:65 2019-01-16 18:36:54.215213: step 6452, loss = 0.70300 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:36:55.197286 ops/training.py:65 2019-01-16 18:36:55.197221: step 6453, loss = 0.70036 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:36:56.178060 ops/training.py:65 2019-01-16 18:36:56.177995: step 6454, loss = 0.70803 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.21875
I8192 2019-01-16 18:36:57.159087 ops/training.py:65 2019-01-16 18:36:57.159017: step 6455, loss = 0.68974 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:36:58.138789 ops/training.py:65 2019-01-16 18:36:58.138726: step 6456, loss = 0.69225 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:36:59.120679 ops/training.py:65 2019-01-16 18:36:59.120617: step 6457, loss = 0.70158 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:37:00.104882 ops/training.py:65 2019-01-16 18:37:00.104809: step 6458, loss = 0.69330 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:37:01.090062 ops/training.py:65 2019-01-16 18:37:01.089965: step 6459, loss = 0.68162 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:37:02.073081 ops/training.py:65 2019-01-16 18:37:02.072983: step 6460, loss = 0.69605 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:37:03.056019 ops/training.py:65 2019-01-16 18:37:03.055922: step 6461, loss = 0.68892 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:37:04.038633 ops/training.py:65 2019-01-16 18:37:04.038532: step 6462, loss = 0.70655 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:37:05.021130 ops/training.py:65 2019-01-16 18:37:05.021035: step 6463, loss = 0.69656 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:37:06.002774 ops/training.py:65 2019-01-16 18:37:06.002636: step 6464, loss = 0.70122 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:37:06.986074 ops/training.py:65 2019-01-16 18:37:06.985937: step 6465, loss = 0.70443 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:37:07.972228 ops/training.py:65 2019-01-16 18:37:07.972119: step 6466, loss = 0.69231 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:37:08.957389 ops/training.py:65 2019-01-16 18:37:08.957289: step 6467, loss = 0.68402 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:37:09.940658 ops/training.py:65 2019-01-16 18:37:09.940516: step 6468, loss = 0.69388 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:37:10.922929 ops/training.py:65 2019-01-16 18:37:10.922800: step 6469, loss = 0.68605 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:37:11.905845 ops/training.py:65 2019-01-16 18:37:11.905748: step 6470, loss = 0.69021 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:37:12.888291 ops/training.py:65 2019-01-16 18:37:12.888180: step 6471, loss = 0.70341 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:37:13.872007 ops/training.py:65 2019-01-16 18:37:13.871917: step 6472, loss = 0.69172 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:37:14.855855 ops/training.py:65 2019-01-16 18:37:14.855756: step 6473, loss = 0.68812 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:37:15.838565 ops/training.py:65 2019-01-16 18:37:15.838471: step 6474, loss = 0.70347 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:37:16.823549 ops/training.py:65 2019-01-16 18:37:16.823457: step 6475, loss = 0.69108 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:37:17.807216 ops/training.py:65 2019-01-16 18:37:17.807110: step 6476, loss = 0.68784 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:37:18.794100 ops/training.py:65 2019-01-16 18:37:18.794002: step 6477, loss = 0.69200 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:37:19.778544 ops/training.py:65 2019-01-16 18:37:19.778442: step 6478, loss = 0.69204 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:37:20.760004 ops/training.py:65 2019-01-16 18:37:20.759897: step 6479, loss = 0.69379 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:37:21.744495 ops/training.py:65 2019-01-16 18:37:21.744429: step 6480, loss = 0.69008 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:37:22.729131 ops/training.py:65 2019-01-16 18:37:22.729029: step 6481, loss = 0.68754 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:37:23.713523 ops/training.py:65 2019-01-16 18:37:23.713422: step 6482, loss = 0.69391 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:37:24.698089 ops/training.py:65 2019-01-16 18:37:24.698020: step 6483, loss = 0.69758 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:37:25.682118 ops/training.py:65 2019-01-16 18:37:25.682025: step 6484, loss = 0.69344 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:37:26.664765 ops/training.py:65 2019-01-16 18:37:26.664666: step 6485, loss = 0.69197 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:37:27.647602 ops/training.py:65 2019-01-16 18:37:27.647501: step 6486, loss = 0.70313 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:37:28.630653 ops/training.py:65 2019-01-16 18:37:28.630551: step 6487, loss = 0.68190 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:37:29.614841 ops/training.py:65 2019-01-16 18:37:29.614741: step 6488, loss = 0.70924 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:37:30.598813 ops/training.py:65 2019-01-16 18:37:30.598715: step 6489, loss = 0.69084 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:37:31.583280 ops/training.py:65 2019-01-16 18:37:31.583186: step 6490, loss = 0.69906 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:37:32.567720 ops/training.py:65 2019-01-16 18:37:32.567622: step 6491, loss = 0.69818 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:37:33.549879 ops/training.py:65 2019-01-16 18:37:33.549785: step 6492, loss = 0.69040 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:37:34.532658 ops/training.py:65 2019-01-16 18:37:34.532555: step 6493, loss = 0.69629 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:37:35.515449 ops/training.py:65 2019-01-16 18:37:35.515352: step 6494, loss = 0.67963 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:37:36.498190 ops/training.py:65 2019-01-16 18:37:36.498096: step 6495, loss = 0.68582 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:37:37.479925 ops/training.py:65 2019-01-16 18:37:37.479824: step 6496, loss = 0.68936 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:37:38.461484 ops/training.py:65 2019-01-16 18:37:38.461381: step 6497, loss = 0.69716 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:37:39.445177 ops/training.py:65 2019-01-16 18:37:39.445068: step 6498, loss = 0.70322 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:37:40.428692 ops/training.py:65 2019-01-16 18:37:40.428600: step 6499, loss = 0.70861 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:37:41.410013 ops/training.py:65 2019-01-16 18:37:41.409927: step 6500, loss = 0.68867 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:37:42.389598 ops/training.py:65 2019-01-16 18:37:42.389496: step 6501, loss = 0.69458 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:37:43.374698 ops/training.py:65 2019-01-16 18:37:43.374611: step 6502, loss = 0.69505 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:37:44.360992 ops/training.py:65 2019-01-16 18:37:44.360875: step 6503, loss = 0.69282 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:37:45.344734 ops/training.py:65 2019-01-16 18:37:45.344606: step 6504, loss = 0.68814 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:37:46.326998 ops/training.py:65 2019-01-16 18:37:46.326866: step 6505, loss = 0.69870 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:37:47.308762 ops/training.py:65 2019-01-16 18:37:47.308661: step 6506, loss = 0.70341 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:37:48.290798 ops/training.py:65 2019-01-16 18:37:48.290701: step 6507, loss = 0.68556 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:37:49.272894 ops/training.py:65 2019-01-16 18:37:49.272794: step 6508, loss = 0.69410 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:37:50.254650 ops/training.py:65 2019-01-16 18:37:50.254562: step 6509, loss = 0.69880 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:37:51.236406 ops/training.py:65 2019-01-16 18:37:51.236306: step 6510, loss = 0.69118 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:37:52.218555 ops/training.py:65 2019-01-16 18:37:52.218455: step 6511, loss = 0.70102 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:37:53.201238 ops/training.py:65 2019-01-16 18:37:53.201145: step 6512, loss = 0.69448 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:37:54.184150 ops/training.py:65 2019-01-16 18:37:54.184047: step 6513, loss = 0.69838 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:37:55.167124 ops/training.py:65 2019-01-16 18:37:55.167021: step 6514, loss = 0.69500 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:37:56.150280 ops/training.py:65 2019-01-16 18:37:56.150147: step 6515, loss = 0.69581 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:37:57.133489 ops/training.py:65 2019-01-16 18:37:57.133391: step 6516, loss = 0.69173 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:37:58.119692 ops/training.py:65 2019-01-16 18:37:58.119605: step 6517, loss = 0.68484 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:37:59.104949 ops/training.py:65 2019-01-16 18:37:59.104849: step 6518, loss = 0.69521 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:38:00.089342 ops/training.py:65 2019-01-16 18:38:00.089238: step 6519, loss = 0.69518 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:38:01.071796 ops/training.py:65 2019-01-16 18:38:01.071696: step 6520, loss = 0.69972 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:38:02.054890 ops/training.py:65 2019-01-16 18:38:02.054784: step 6521, loss = 0.70161 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:38:03.036551 ops/training.py:65 2019-01-16 18:38:03.036455: step 6522, loss = 0.68983 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:38:04.021834 ops/training.py:65 2019-01-16 18:38:04.021730: step 6523, loss = 0.69380 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:38:05.006565 ops/training.py:65 2019-01-16 18:38:05.006461: step 6524, loss = 0.69456 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:38:05.990733 ops/training.py:65 2019-01-16 18:38:05.990658: step 6525, loss = 0.69509 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:38:06.972469 ops/training.py:65 2019-01-16 18:38:06.972402: step 6526, loss = 0.70114 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:38:07.957468 ops/training.py:65 2019-01-16 18:38:07.957372: step 6527, loss = 0.69678 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:38:08.943673 ops/training.py:65 2019-01-16 18:38:08.943570: step 6528, loss = 0.69926 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:38:09.926949 ops/training.py:65 2019-01-16 18:38:09.926850: step 6529, loss = 0.69804 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:38:10.909213 ops/training.py:65 2019-01-16 18:38:10.909117: step 6530, loss = 0.71763 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:38:11.892182 ops/training.py:65 2019-01-16 18:38:11.892078: step 6531, loss = 0.69039 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:38:12.874253 ops/training.py:65 2019-01-16 18:38:12.874145: step 6532, loss = 0.66438 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:38:13.856809 ops/training.py:65 2019-01-16 18:38:13.856675: step 6533, loss = 0.68615 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:38:14.840378 ops/training.py:65 2019-01-16 18:38:14.840252: step 6534, loss = 0.71809 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:38:15.823247 ops/training.py:65 2019-01-16 18:38:15.823145: step 6535, loss = 0.69595 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:38:16.806016 ops/training.py:65 2019-01-16 18:38:16.805911: step 6536, loss = 0.72007 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:38:17.788808 ops/training.py:65 2019-01-16 18:38:17.788723: step 6537, loss = 0.71267 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:38:18.771636 ops/training.py:65 2019-01-16 18:38:18.771543: step 6538, loss = 0.71428 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:38:19.754989 ops/training.py:65 2019-01-16 18:38:19.754890: step 6539, loss = 0.68368 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:38:20.736812 ops/training.py:65 2019-01-16 18:38:20.736718: step 6540, loss = 0.69416 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:38:21.719183 ops/training.py:65 2019-01-16 18:38:21.719074: step 6541, loss = 0.70861 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:38:22.701039 ops/training.py:65 2019-01-16 18:38:22.700941: step 6542, loss = 0.70159 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:38:23.684243 ops/training.py:65 2019-01-16 18:38:23.684138: step 6543, loss = 0.70932 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:38:24.669697 ops/training.py:65 2019-01-16 18:38:24.669596: step 6544, loss = 0.71487 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:38:25.654346 ops/training.py:65 2019-01-16 18:38:25.654241: step 6545, loss = 0.67122 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:38:26.638208 ops/training.py:65 2019-01-16 18:38:26.638074: step 6546, loss = 0.71635 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:38:27.622142 ops/training.py:65 2019-01-16 18:38:27.622039: step 6547, loss = 0.69760 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:38:28.604797 ops/training.py:65 2019-01-16 18:38:28.604688: step 6548, loss = 0.68091 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:38:29.588756 ops/training.py:65 2019-01-16 18:38:29.588675: step 6549, loss = 0.70293 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:38:30.574135 ops/training.py:65 2019-01-16 18:38:30.574037: step 6550, loss = 0.68651 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:38:31.558468 ops/training.py:65 2019-01-16 18:38:31.558368: step 6551, loss = 0.69131 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:38:32.541611 ops/training.py:65 2019-01-16 18:38:32.541514: step 6552, loss = 0.69652 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:38:33.526443 ops/training.py:65 2019-01-16 18:38:33.526369: step 6553, loss = 0.68612 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:38:34.510288 ops/training.py:65 2019-01-16 18:38:34.510193: step 6554, loss = 0.69618 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:38:35.493093 ops/training.py:65 2019-01-16 18:38:35.492994: step 6555, loss = 0.68918 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:38:36.474823 ops/training.py:65 2019-01-16 18:38:36.474726: step 6556, loss = 0.68998 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:38:37.457603 ops/training.py:65 2019-01-16 18:38:37.457460: step 6557, loss = 0.69742 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:38:38.439934 ops/training.py:65 2019-01-16 18:38:38.439836: step 6558, loss = 0.71057 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:38:39.425775 ops/training.py:65 2019-01-16 18:38:39.425690: step 6559, loss = 0.69516 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:38:40.410440 ops/training.py:65 2019-01-16 18:38:40.410347: step 6560, loss = 0.70112 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:38:41.394083 ops/training.py:65 2019-01-16 18:38:41.393987: step 6561, loss = 0.70490 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:38:42.376362 ops/training.py:65 2019-01-16 18:38:42.376266: step 6562, loss = 0.69753 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:38:43.359570 ops/training.py:65 2019-01-16 18:38:43.359480: step 6563, loss = 0.69785 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:38:44.341557 ops/training.py:65 2019-01-16 18:38:44.341432: step 6564, loss = 0.69342 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:38:45.324005 ops/training.py:65 2019-01-16 18:38:45.323906: step 6565, loss = 0.70064 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:38:46.305591 ops/training.py:65 2019-01-16 18:38:46.305490: step 6566, loss = 0.69653 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:38:47.287673 ops/training.py:65 2019-01-16 18:38:47.287570: step 6567, loss = 0.69182 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:38:48.268592 ops/training.py:65 2019-01-16 18:38:48.268525: step 6568, loss = 0.69706 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:38:49.249304 ops/training.py:65 2019-01-16 18:38:49.249239: step 6569, loss = 0.69173 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:38:50.228603 ops/training.py:65 2019-01-16 18:38:50.228536: step 6570, loss = 0.69395 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:38:51.209237 ops/training.py:65 2019-01-16 18:38:51.209168: step 6571, loss = 0.69270 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:38:52.193897 ops/training.py:65 2019-01-16 18:38:52.193812: step 6572, loss = 0.69385 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:38:53.177004 ops/training.py:65 2019-01-16 18:38:53.176905: step 6573, loss = 0.69554 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:38:54.162577 ops/training.py:65 2019-01-16 18:38:54.162477: step 6574, loss = 0.69936 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:38:55.145827 ops/training.py:65 2019-01-16 18:38:55.145729: step 6575, loss = 0.69210 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:38:56.129051 ops/training.py:65 2019-01-16 18:38:56.128956: step 6576, loss = 0.69385 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:38:57.111573 ops/training.py:65 2019-01-16 18:38:57.111467: step 6577, loss = 0.70504 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:38:58.094060 ops/training.py:65 2019-01-16 18:38:58.093956: step 6578, loss = 0.69363 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:38:59.076512 ops/training.py:65 2019-01-16 18:38:59.076418: step 6579, loss = 0.69607 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:39:00.059403 ops/training.py:65 2019-01-16 18:39:00.059310: step 6580, loss = 0.68686 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:39:01.041635 ops/training.py:65 2019-01-16 18:39:01.041545: step 6581, loss = 0.69304 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:39:02.023646 ops/training.py:65 2019-01-16 18:39:02.023560: step 6582, loss = 0.69804 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:39:03.005430 ops/training.py:65 2019-01-16 18:39:03.005352: step 6583, loss = 0.69105 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:39:03.987728 ops/training.py:65 2019-01-16 18:39:03.987642: step 6584, loss = 0.69694 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:39:04.969601 ops/training.py:65 2019-01-16 18:39:04.969504: step 6585, loss = 0.69141 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:39:05.951369 ops/training.py:65 2019-01-16 18:39:05.951280: step 6586, loss = 0.69234 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:39:06.933242 ops/training.py:65 2019-01-16 18:39:06.933145: step 6587, loss = 0.69261 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:39:07.916490 ops/training.py:65 2019-01-16 18:39:07.916382: step 6588, loss = 0.70678 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:39:08.898989 ops/training.py:65 2019-01-16 18:39:08.898887: step 6589, loss = 0.69726 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:39:09.881938 ops/training.py:65 2019-01-16 18:39:09.881858: step 6590, loss = 0.69314 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:39:10.864564 ops/training.py:65 2019-01-16 18:39:10.864478: step 6591, loss = 0.69620 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:39:11.847272 ops/training.py:65 2019-01-16 18:39:11.847183: step 6592, loss = 0.69296 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:39:12.829059 ops/training.py:65 2019-01-16 18:39:12.828967: step 6593, loss = 0.69394 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:39:13.810849 ops/training.py:65 2019-01-16 18:39:13.810757: step 6594, loss = 0.69090 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:39:14.795233 ops/training.py:65 2019-01-16 18:39:14.795137: step 6595, loss = 0.69623 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:39:15.780835 ops/training.py:65 2019-01-16 18:39:15.780735: step 6596, loss = 0.70416 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:39:16.766573 ops/training.py:65 2019-01-16 18:39:16.766483: step 6597, loss = 0.71113 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:39:17.750875 ops/training.py:65 2019-01-16 18:39:17.750778: step 6598, loss = 0.68980 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:39:18.734190 ops/training.py:65 2019-01-16 18:39:18.734099: step 6599, loss = 0.68181 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:39:19.717441 ops/training.py:65 2019-01-16 18:39:19.717338: step 6600, loss = 0.69590 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:39:20.699838 ops/training.py:65 2019-01-16 18:39:20.699752: step 6601, loss = 0.69527 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:39:21.716162 ops/training.py:65 2019-01-16 18:39:21.716068: step 6602, loss = 0.69801 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:39:22.699542 ops/training.py:65 2019-01-16 18:39:22.699446: step 6603, loss = 0.69138 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:39:23.682740 ops/training.py:65 2019-01-16 18:39:23.682641: step 6604, loss = 0.69972 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:39:24.664753 ops/training.py:65 2019-01-16 18:39:24.664675: step 6605, loss = 0.70862 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:39:25.646464 ops/training.py:65 2019-01-16 18:39:25.646379: step 6606, loss = 0.67326 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:39:26.628638 ops/training.py:65 2019-01-16 18:39:26.628547: step 6607, loss = 0.71690 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:39:27.611276 ops/training.py:65 2019-01-16 18:39:27.611180: step 6608, loss = 0.66031 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:39:28.593359 ops/training.py:65 2019-01-16 18:39:28.593260: step 6609, loss = 0.71726 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:39:29.576279 ops/training.py:65 2019-01-16 18:39:29.576189: step 6610, loss = 0.69935 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:39:30.558486 ops/training.py:65 2019-01-16 18:39:30.558389: step 6611, loss = 0.67601 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:39:31.540183 ops/training.py:65 2019-01-16 18:39:31.540093: step 6612, loss = 0.69019 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:39:32.522589 ops/training.py:65 2019-01-16 18:39:32.522456: step 6613, loss = 0.68247 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:39:33.507452 ops/training.py:65 2019-01-16 18:39:33.507352: step 6614, loss = 0.67860 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:39:34.490651 ops/training.py:65 2019-01-16 18:39:34.490516: step 6615, loss = 0.67014 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:39:35.474551 ops/training.py:65 2019-01-16 18:39:35.474449: step 6616, loss = 0.70181 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:39:36.456593 ops/training.py:65 2019-01-16 18:39:36.456498: step 6617, loss = 0.67645 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:39:37.438810 ops/training.py:65 2019-01-16 18:39:37.438710: step 6618, loss = 0.71687 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:39:38.420501 ops/training.py:65 2019-01-16 18:39:38.420397: step 6619, loss = 0.70338 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:39:39.405727 ops/training.py:65 2019-01-16 18:39:39.405630: step 6620, loss = 0.69395 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:39:40.389999 ops/training.py:65 2019-01-16 18:39:40.389903: step 6621, loss = 0.69985 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:39:41.372717 ops/training.py:65 2019-01-16 18:39:41.372624: step 6622, loss = 0.67984 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:39:42.354695 ops/training.py:65 2019-01-16 18:39:42.354590: step 6623, loss = 0.70484 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:39:43.335944 ops/training.py:65 2019-01-16 18:39:43.335852: step 6624, loss = 0.69418 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:39:44.316118 ops/training.py:65 2019-01-16 18:39:44.316057: step 6625, loss = 0.69295 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:39:45.296429 ops/training.py:65 2019-01-16 18:39:45.296367: step 6626, loss = 0.69476 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:39:46.275557 ops/training.py:65 2019-01-16 18:39:46.275495: step 6627, loss = 0.70085 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:39:47.254831 ops/training.py:65 2019-01-16 18:39:47.254769: step 6628, loss = 0.69542 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:39:48.239225 ops/training.py:65 2019-01-16 18:39:48.239143: step 6629, loss = 0.69472 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:39:49.223667 ops/training.py:65 2019-01-16 18:39:49.223522: step 6630, loss = 0.69330 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:39:50.207071 ops/training.py:65 2019-01-16 18:39:50.206926: step 6631, loss = 0.69179 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:39:51.189444 ops/training.py:65 2019-01-16 18:39:51.189380: step 6632, loss = 0.69425 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:39:52.170403 ops/training.py:65 2019-01-16 18:39:52.170331: step 6633, loss = 0.67344 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:39:53.150023 ops/training.py:65 2019-01-16 18:39:53.149948: step 6634, loss = 0.69809 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:39:54.129876 ops/training.py:65 2019-01-16 18:39:54.129805: step 6635, loss = 0.70559 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:39:55.114049 ops/training.py:65 2019-01-16 18:39:55.113960: step 6636, loss = 0.69728 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:39:56.099574 ops/training.py:65 2019-01-16 18:39:56.099474: step 6637, loss = 0.69992 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:39:57.083799 ops/training.py:65 2019-01-16 18:39:57.083697: step 6638, loss = 0.71149 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.25
I8192 2019-01-16 18:39:58.068922 ops/training.py:65 2019-01-16 18:39:58.068827: step 6639, loss = 0.68985 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:39:59.051663 ops/training.py:65 2019-01-16 18:39:59.051561: step 6640, loss = 0.70394 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:40:00.036612 ops/training.py:65 2019-01-16 18:40:00.036513: step 6641, loss = 0.69583 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:40:01.019082 ops/training.py:65 2019-01-16 18:40:01.018982: step 6642, loss = 0.69272 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:40:02.004726 ops/training.py:65 2019-01-16 18:40:02.004650: step 6643, loss = 0.69134 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:40:02.987826 ops/training.py:65 2019-01-16 18:40:02.987724: step 6644, loss = 0.70276 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:40:03.972063 ops/training.py:65 2019-01-16 18:40:03.971956: step 6645, loss = 0.69094 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:40:04.953492 ops/training.py:65 2019-01-16 18:40:04.953391: step 6646, loss = 0.69219 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:40:05.937448 ops/training.py:65 2019-01-16 18:40:05.937355: step 6647, loss = 0.69556 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:40:06.920636 ops/training.py:65 2019-01-16 18:40:06.920506: step 6648, loss = 0.69190 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:40:07.902886 ops/training.py:65 2019-01-16 18:40:07.902779: step 6649, loss = 0.69109 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:40:08.884569 ops/training.py:65 2019-01-16 18:40:08.884468: step 6650, loss = 0.68922 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:40:09.869021 ops/training.py:65 2019-01-16 18:40:09.868917: step 6651, loss = 0.68750 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:40:10.855265 ops/training.py:65 2019-01-16 18:40:10.855185: step 6652, loss = 0.69743 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:40:11.840205 ops/training.py:65 2019-01-16 18:40:11.840106: step 6653, loss = 0.68808 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:40:12.824102 ops/training.py:65 2019-01-16 18:40:12.824003: step 6654, loss = 0.68592 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:40:13.808147 ops/training.py:65 2019-01-16 18:40:13.808046: step 6655, loss = 0.68371 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:40:14.791374 ops/training.py:65 2019-01-16 18:40:14.791271: step 6656, loss = 0.69739 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:40:15.776434 ops/training.py:65 2019-01-16 18:40:15.776349: step 6657, loss = 0.70574 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:40:16.761355 ops/training.py:65 2019-01-16 18:40:16.761255: step 6658, loss = 0.68841 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:40:17.744819 ops/training.py:65 2019-01-16 18:40:17.744719: step 6659, loss = 0.68626 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:40:18.728638 ops/training.py:65 2019-01-16 18:40:18.728540: step 6660, loss = 0.70164 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:40:19.713355 ops/training.py:65 2019-01-16 18:40:19.713253: step 6661, loss = 0.70238 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:40:20.696126 ops/training.py:65 2019-01-16 18:40:20.696027: step 6662, loss = 0.67911 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:40:21.678565 ops/training.py:65 2019-01-16 18:40:21.678471: step 6663, loss = 0.68351 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:40:22.661528 ops/training.py:65 2019-01-16 18:40:22.661424: step 6664, loss = 0.70184 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:40:23.644020 ops/training.py:65 2019-01-16 18:40:23.643931: step 6665, loss = 0.69535 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:40:24.625779 ops/training.py:65 2019-01-16 18:40:24.625694: step 6666, loss = 0.70134 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:40:25.609100 ops/training.py:65 2019-01-16 18:40:25.609011: step 6667, loss = 0.70605 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:40:26.592014 ops/training.py:65 2019-01-16 18:40:26.591917: step 6668, loss = 0.69958 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:40:27.575349 ops/training.py:65 2019-01-16 18:40:27.575240: step 6669, loss = 0.67940 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:40:28.558349 ops/training.py:65 2019-01-16 18:40:28.558258: step 6670, loss = 0.68991 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:40:29.541552 ops/training.py:65 2019-01-16 18:40:29.541459: step 6671, loss = 0.67841 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:40:30.524838 ops/training.py:65 2019-01-16 18:40:30.524739: step 6672, loss = 0.70775 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:40:31.511588 ops/training.py:65 2019-01-16 18:40:31.511491: step 6673, loss = 0.67946 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:40:32.495847 ops/training.py:65 2019-01-16 18:40:32.495711: step 6674, loss = 0.70945 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:40:33.479340 ops/training.py:65 2019-01-16 18:40:33.479246: step 6675, loss = 0.69199 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:40:34.462594 ops/training.py:65 2019-01-16 18:40:34.462497: step 6676, loss = 0.70593 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:40:35.446650 ops/training.py:65 2019-01-16 18:40:35.446541: step 6677, loss = 0.69007 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:40:36.429148 ops/training.py:65 2019-01-16 18:40:36.429046: step 6678, loss = 0.68783 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:40:37.412177 ops/training.py:65 2019-01-16 18:40:37.412083: step 6679, loss = 0.70243 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:40:38.395152 ops/training.py:65 2019-01-16 18:40:38.395048: step 6680, loss = 0.69644 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:40:39.377072 ops/training.py:65 2019-01-16 18:40:39.377003: step 6681, loss = 0.69971 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:40:40.358416 ops/training.py:65 2019-01-16 18:40:40.358349: step 6682, loss = 0.70389 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:40:41.343075 ops/training.py:65 2019-01-16 18:40:41.342996: step 6683, loss = 0.68667 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:40:42.327669 ops/training.py:65 2019-01-16 18:40:42.327573: step 6684, loss = 0.69709 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:40:43.311849 ops/training.py:65 2019-01-16 18:40:43.311753: step 6685, loss = 0.69057 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:40:44.293908 ops/training.py:65 2019-01-16 18:40:44.293809: step 6686, loss = 0.68022 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:40:45.277516 ops/training.py:65 2019-01-16 18:40:45.277409: step 6687, loss = 0.68539 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:40:46.260467 ops/training.py:65 2019-01-16 18:40:46.260353: step 6688, loss = 0.71806 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:40:47.242807 ops/training.py:65 2019-01-16 18:40:47.242698: step 6689, loss = 0.69530 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:40:48.224618 ops/training.py:65 2019-01-16 18:40:48.224510: step 6690, loss = 0.69182 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:40:49.206821 ops/training.py:65 2019-01-16 18:40:49.206713: step 6691, loss = 0.69888 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:40:50.189095 ops/training.py:65 2019-01-16 18:40:50.188985: step 6692, loss = 0.69227 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:40:51.171839 ops/training.py:65 2019-01-16 18:40:51.171730: step 6693, loss = 0.68927 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:40:52.154229 ops/training.py:65 2019-01-16 18:40:52.154117: step 6694, loss = 0.70919 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:40:53.137462 ops/training.py:65 2019-01-16 18:40:53.137362: step 6695, loss = 0.69039 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:40:54.121221 ops/training.py:65 2019-01-16 18:40:54.121114: step 6696, loss = 0.69224 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:40:55.104165 ops/training.py:65 2019-01-16 18:40:55.104064: step 6697, loss = 0.70014 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:40:56.086480 ops/training.py:65 2019-01-16 18:40:56.086405: step 6698, loss = 0.70004 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:40:57.067761 ops/training.py:65 2019-01-16 18:40:57.067686: step 6699, loss = 0.70068 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:40:58.051802 ops/training.py:65 2019-01-16 18:40:58.051717: step 6700, loss = 0.68505 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:40:59.038466 ops/training.py:65 2019-01-16 18:40:59.038372: step 6701, loss = 0.69076 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:41:00.022829 ops/training.py:65 2019-01-16 18:41:00.022721: step 6702, loss = 0.70602 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:41:01.005026 ops/training.py:65 2019-01-16 18:41:01.004924: step 6703, loss = 0.69311 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:41:01.986923 ops/training.py:65 2019-01-16 18:41:01.986827: step 6704, loss = 0.69520 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:41:02.970106 ops/training.py:65 2019-01-16 18:41:02.969998: step 6705, loss = 0.69873 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:41:03.954289 ops/training.py:65 2019-01-16 18:41:03.954196: step 6706, loss = 0.69851 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:41:04.936563 ops/training.py:65 2019-01-16 18:41:04.936460: step 6707, loss = 0.69891 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:41:05.918750 ops/training.py:65 2019-01-16 18:41:05.918652: step 6708, loss = 0.68773 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:41:06.900860 ops/training.py:65 2019-01-16 18:41:06.900754: step 6709, loss = 0.69934 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:41:07.884366 ops/training.py:65 2019-01-16 18:41:07.884265: step 6710, loss = 0.68344 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:41:08.867980 ops/training.py:65 2019-01-16 18:41:08.867876: step 6711, loss = 0.70562 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:41:09.851315 ops/training.py:65 2019-01-16 18:41:09.851176: step 6712, loss = 0.69565 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:41:10.834788 ops/training.py:65 2019-01-16 18:41:10.834668: step 6713, loss = 0.69246 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:41:11.818229 ops/training.py:65 2019-01-16 18:41:11.818129: step 6714, loss = 0.70258 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:41:12.803363 ops/training.py:65 2019-01-16 18:41:12.803258: step 6715, loss = 0.69730 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:41:13.785221 ops/training.py:65 2019-01-16 18:41:13.785114: step 6716, loss = 0.70495 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:41:14.767537 ops/training.py:65 2019-01-16 18:41:14.767430: step 6717, loss = 0.68988 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:41:15.750319 ops/training.py:65 2019-01-16 18:41:15.750213: step 6718, loss = 0.69171 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:41:16.732004 ops/training.py:65 2019-01-16 18:41:16.731932: step 6719, loss = 0.67833 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:41:17.712842 ops/training.py:65 2019-01-16 18:41:17.712775: step 6720, loss = 0.69305 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:41:18.703290 ops/training.py:65 2019-01-16 18:41:18.703199: step 6721, loss = 0.69305 (32.3 examples/sec; 0.989 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:41:19.686506 ops/training.py:65 2019-01-16 18:41:19.686399: step 6722, loss = 0.68862 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:41:20.668947 ops/training.py:65 2019-01-16 18:41:20.668869: step 6723, loss = 0.68081 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:41:21.649904 ops/training.py:65 2019-01-16 18:41:21.649835: step 6724, loss = 0.71055 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:41:22.630486 ops/training.py:65 2019-01-16 18:41:22.630408: step 6725, loss = 0.67480 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:41:23.613393 ops/training.py:65 2019-01-16 18:41:23.613327: step 6726, loss = 0.71419 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:41:24.607564 ops/training.py:65 2019-01-16 18:41:24.607456: step 6727, loss = 0.69400 (32.2 examples/sec; 0.993 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:41:25.589949 ops/training.py:65 2019-01-16 18:41:25.589852: step 6728, loss = 0.72156 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:41:26.571614 ops/training.py:65 2019-01-16 18:41:26.571540: step 6729, loss = 0.69552 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:41:27.552756 ops/training.py:65 2019-01-16 18:41:27.552691: step 6730, loss = 0.69601 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:41:28.533728 ops/training.py:65 2019-01-16 18:41:28.533666: step 6731, loss = 0.67767 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:41:29.515044 ops/training.py:65 2019-01-16 18:41:29.514963: step 6732, loss = 0.70924 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:41:30.495636 ops/training.py:65 2019-01-16 18:41:30.495565: step 6733, loss = 0.64760 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:41:31.477504 ops/training.py:65 2019-01-16 18:41:31.477435: step 6734, loss = 0.71023 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:41:32.462210 ops/training.py:65 2019-01-16 18:41:32.462129: step 6735, loss = 0.69012 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:41:33.446936 ops/training.py:65 2019-01-16 18:41:33.446837: step 6736, loss = 0.68851 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:41:34.431417 ops/training.py:65 2019-01-16 18:41:34.431313: step 6737, loss = 0.69828 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:41:35.414094 ops/training.py:65 2019-01-16 18:41:35.413997: step 6738, loss = 0.70634 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:41:36.397305 ops/training.py:65 2019-01-16 18:41:36.397203: step 6739, loss = 0.69068 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:41:37.381002 ops/training.py:65 2019-01-16 18:41:37.380898: step 6740, loss = 0.69334 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:41:38.364566 ops/training.py:65 2019-01-16 18:41:38.364462: step 6741, loss = 0.68399 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:41:39.347482 ops/training.py:65 2019-01-16 18:41:39.347379: step 6742, loss = 0.71551 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:41:40.330505 ops/training.py:65 2019-01-16 18:41:40.330400: step 6743, loss = 0.69787 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:41:41.313858 ops/training.py:65 2019-01-16 18:41:41.313772: step 6744, loss = 0.68924 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:41:42.296902 ops/training.py:65 2019-01-16 18:41:42.296797: step 6745, loss = 0.68963 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:41:43.280358 ops/training.py:65 2019-01-16 18:41:43.280251: step 6746, loss = 0.71991 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:41:44.263856 ops/training.py:65 2019-01-16 18:41:44.263752: step 6747, loss = 0.68847 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:41:45.245147 ops/training.py:65 2019-01-16 18:41:45.245083: step 6748, loss = 0.70235 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:41:46.229785 ops/training.py:65 2019-01-16 18:41:46.229710: step 6749, loss = 0.68698 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:41:47.214533 ops/training.py:65 2019-01-16 18:41:47.214432: step 6750, loss = 0.70293 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:41:48.199828 ops/training.py:65 2019-01-16 18:41:48.199724: step 6751, loss = 0.70591 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:41:49.182059 ops/training.py:65 2019-01-16 18:41:49.181927: step 6752, loss = 0.69655 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:41:50.165487 ops/training.py:65 2019-01-16 18:41:50.165382: step 6753, loss = 0.68403 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:41:51.148284 ops/training.py:65 2019-01-16 18:41:51.148176: step 6754, loss = 0.69191 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:41:52.130031 ops/training.py:65 2019-01-16 18:41:52.129919: step 6755, loss = 0.69795 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:41:53.111815 ops/training.py:65 2019-01-16 18:41:53.111718: step 6756, loss = 0.69650 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:41:54.092544 ops/training.py:65 2019-01-16 18:41:54.092477: step 6757, loss = 0.70897 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:41:55.073078 ops/training.py:65 2019-01-16 18:41:55.073010: step 6758, loss = 0.68469 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:41:56.053412 ops/training.py:65 2019-01-16 18:41:56.053338: step 6759, loss = 0.69073 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:41:57.035416 ops/training.py:65 2019-01-16 18:41:57.035349: step 6760, loss = 0.69369 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:41:58.016139 ops/training.py:65 2019-01-16 18:41:58.016074: step 6761, loss = 0.69368 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:41:58.997433 ops/training.py:65 2019-01-16 18:41:58.997371: step 6762, loss = 0.68052 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:41:59.981725 ops/training.py:65 2019-01-16 18:41:59.981662: step 6763, loss = 0.68953 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:42:00.964179 ops/training.py:65 2019-01-16 18:42:00.964111: step 6764, loss = 0.70564 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:42:01.945899 ops/training.py:65 2019-01-16 18:42:01.945829: step 6765, loss = 0.70237 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:42:02.926799 ops/training.py:65 2019-01-16 18:42:02.926737: step 6766, loss = 0.68333 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:42:03.909636 ops/training.py:65 2019-01-16 18:42:03.909573: step 6767, loss = 0.69370 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:42:04.891347 ops/training.py:65 2019-01-16 18:42:04.891288: step 6768, loss = 0.71219 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:42:05.872041 ops/training.py:65 2019-01-16 18:42:05.871978: step 6769, loss = 0.70734 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:42:06.856003 ops/training.py:65 2019-01-16 18:42:06.855917: step 6770, loss = 0.69527 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:42:07.842298 ops/training.py:65 2019-01-16 18:42:07.842193: step 6771, loss = 0.69909 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:42:08.826426 ops/training.py:65 2019-01-16 18:42:08.826317: step 6772, loss = 0.69436 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:42:09.810340 ops/training.py:65 2019-01-16 18:42:09.810197: step 6773, loss = 0.69429 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:42:10.794603 ops/training.py:65 2019-01-16 18:42:10.794504: step 6774, loss = 0.71242 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:42:11.777510 ops/training.py:65 2019-01-16 18:42:11.777401: step 6775, loss = 0.68765 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:42:12.759180 ops/training.py:65 2019-01-16 18:42:12.759115: step 6776, loss = 0.69651 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:42:13.739621 ops/training.py:65 2019-01-16 18:42:13.739548: step 6777, loss = 0.70300 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:42:14.724394 ops/training.py:65 2019-01-16 18:42:14.724299: step 6778, loss = 0.69493 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:42:15.708683 ops/training.py:65 2019-01-16 18:42:15.708577: step 6779, loss = 0.70888 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:42:16.694026 ops/training.py:65 2019-01-16 18:42:16.693916: step 6780, loss = 0.69597 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:42:17.676684 ops/training.py:65 2019-01-16 18:42:17.676577: step 6781, loss = 0.67718 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:42:18.659299 ops/training.py:65 2019-01-16 18:42:18.659200: step 6782, loss = 0.69152 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:42:19.643230 ops/training.py:65 2019-01-16 18:42:19.643125: step 6783, loss = 0.69089 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:42:20.625828 ops/training.py:65 2019-01-16 18:42:20.625734: step 6784, loss = 0.69250 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:42:21.609158 ops/training.py:65 2019-01-16 18:42:21.609055: step 6785, loss = 0.69117 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:42:22.591140 ops/training.py:65 2019-01-16 18:42:22.591032: step 6786, loss = 0.68912 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:42:23.573251 ops/training.py:65 2019-01-16 18:42:23.573148: step 6787, loss = 0.69683 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:42:24.553223 ops/training.py:65 2019-01-16 18:42:24.553138: step 6788, loss = 0.69312 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:42:25.534750 ops/training.py:65 2019-01-16 18:42:25.534689: step 6789, loss = 0.68438 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:42:26.518536 ops/training.py:65 2019-01-16 18:42:26.518455: step 6790, loss = 0.70841 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:42:27.503652 ops/training.py:65 2019-01-16 18:42:27.503552: step 6791, loss = 0.69750 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:42:28.488195 ops/training.py:65 2019-01-16 18:42:28.488092: step 6792, loss = 0.69666 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:42:29.471776 ops/training.py:65 2019-01-16 18:42:29.471672: step 6793, loss = 0.69289 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:42:30.455353 ops/training.py:65 2019-01-16 18:42:30.455256: step 6794, loss = 0.69410 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:42:31.437421 ops/training.py:65 2019-01-16 18:42:31.437323: step 6795, loss = 0.70131 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:42:32.421902 ops/training.py:65 2019-01-16 18:42:32.421805: step 6796, loss = 0.68333 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:42:33.406537 ops/training.py:65 2019-01-16 18:42:33.406436: step 6797, loss = 0.70216 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:42:34.389485 ops/training.py:65 2019-01-16 18:42:34.389376: step 6798, loss = 0.69983 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:42:35.373358 ops/training.py:65 2019-01-16 18:42:35.373249: step 6799, loss = 0.69492 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:42:36.358270 ops/training.py:65 2019-01-16 18:42:36.358164: step 6800, loss = 0.68054 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:42:37.341663 ops/training.py:65 2019-01-16 18:42:37.341558: step 6801, loss = 0.70062 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:42:38.323669 ops/training.py:65 2019-01-16 18:42:38.323590: step 6802, loss = 0.69255 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:42:39.308626 ops/training.py:65 2019-01-16 18:42:39.308566: step 6803, loss = 0.68905 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:42:40.293597 ops/training.py:65 2019-01-16 18:42:40.293500: step 6804, loss = 0.70097 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:42:41.278194 ops/training.py:65 2019-01-16 18:42:41.278102: step 6805, loss = 0.68167 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:42:42.261738 ops/training.py:65 2019-01-16 18:42:42.261604: step 6806, loss = 0.68194 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:42:43.246233 ops/training.py:65 2019-01-16 18:42:43.246128: step 6807, loss = 0.69531 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:42:44.230123 ops/training.py:65 2019-01-16 18:42:44.230014: step 6808, loss = 0.69630 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:42:45.213137 ops/training.py:65 2019-01-16 18:42:45.213035: step 6809, loss = 0.70026 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:42:46.196189 ops/training.py:65 2019-01-16 18:42:46.196080: step 6810, loss = 0.68890 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:42:47.178311 ops/training.py:65 2019-01-16 18:42:47.178205: step 6811, loss = 0.69325 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:42:48.164443 ops/training.py:65 2019-01-16 18:42:48.164358: step 6812, loss = 0.69337 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:42:49.149327 ops/training.py:65 2019-01-16 18:42:49.149224: step 6813, loss = 0.67657 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:42:50.132893 ops/training.py:65 2019-01-16 18:42:50.132793: step 6814, loss = 0.70121 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:42:51.115628 ops/training.py:65 2019-01-16 18:42:51.115525: step 6815, loss = 0.68685 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:42:52.097356 ops/training.py:65 2019-01-16 18:42:52.097251: step 6816, loss = 0.68337 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:42:53.079557 ops/training.py:65 2019-01-16 18:42:53.079458: step 6817, loss = 0.70702 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:42:54.061592 ops/training.py:65 2019-01-16 18:42:54.061487: step 6818, loss = 0.69402 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:42:55.043859 ops/training.py:65 2019-01-16 18:42:55.043753: step 6819, loss = 0.68835 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:42:56.026597 ops/training.py:65 2019-01-16 18:42:56.026504: step 6820, loss = 0.69203 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:42:57.008489 ops/training.py:65 2019-01-16 18:42:57.008391: step 6821, loss = 0.70065 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:42:57.992775 ops/training.py:65 2019-01-16 18:42:57.992669: step 6822, loss = 0.69121 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:42:58.975869 ops/training.py:65 2019-01-16 18:42:58.975770: step 6823, loss = 0.69545 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:42:59.957721 ops/training.py:65 2019-01-16 18:42:59.957648: step 6824, loss = 0.69203 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:43:00.937853 ops/training.py:65 2019-01-16 18:43:00.937789: step 6825, loss = 0.70377 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:43:01.917532 ops/training.py:65 2019-01-16 18:43:01.917461: step 6826, loss = 0.69474 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:43:02.897383 ops/training.py:65 2019-01-16 18:43:02.897316: step 6827, loss = 0.68191 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:43:03.876669 ops/training.py:65 2019-01-16 18:43:03.876602: step 6828, loss = 0.70437 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:43:04.858472 ops/training.py:65 2019-01-16 18:43:04.858399: step 6829, loss = 0.70005 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:43:05.838253 ops/training.py:65 2019-01-16 18:43:05.838188: step 6830, loss = 0.68125 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:43:06.818500 ops/training.py:65 2019-01-16 18:43:06.818435: step 6831, loss = 0.70942 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:43:07.799085 ops/training.py:65 2019-01-16 18:43:07.799017: step 6832, loss = 0.70043 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:43:08.779812 ops/training.py:65 2019-01-16 18:43:08.779742: step 6833, loss = 0.68321 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:43:09.765296 ops/training.py:65 2019-01-16 18:43:09.765212: step 6834, loss = 0.70793 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:43:10.749625 ops/training.py:65 2019-01-16 18:43:10.749533: step 6835, loss = 0.68774 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:43:11.733208 ops/training.py:65 2019-01-16 18:43:11.733096: step 6836, loss = 0.70386 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:43:12.717921 ops/training.py:65 2019-01-16 18:43:12.717815: step 6837, loss = 0.70243 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:43:13.701101 ops/training.py:65 2019-01-16 18:43:13.701033: step 6838, loss = 0.68718 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:43:14.680477 ops/training.py:65 2019-01-16 18:43:14.680413: step 6839, loss = 0.68835 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:43:15.660152 ops/training.py:65 2019-01-16 18:43:15.660092: step 6840, loss = 0.70180 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:43:16.639073 ops/training.py:65 2019-01-16 18:43:16.639010: step 6841, loss = 0.68356 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:43:17.619283 ops/training.py:65 2019-01-16 18:43:17.619220: step 6842, loss = 0.69708 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:43:18.598972 ops/training.py:65 2019-01-16 18:43:18.598899: step 6843, loss = 0.69619 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:43:19.582067 ops/training.py:65 2019-01-16 18:43:19.582011: step 6844, loss = 0.70985 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:43:20.566472 ops/training.py:65 2019-01-16 18:43:20.566330: step 6845, loss = 0.69605 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:43:21.550443 ops/training.py:65 2019-01-16 18:43:21.550335: step 6846, loss = 0.70594 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:43:22.532055 ops/training.py:65 2019-01-16 18:43:22.531947: step 6847, loss = 0.68153 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:43:23.517725 ops/training.py:65 2019-01-16 18:43:23.517643: step 6848, loss = 0.69422 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:43:24.503148 ops/training.py:65 2019-01-16 18:43:24.503047: step 6849, loss = 0.68822 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:43:25.486128 ops/training.py:65 2019-01-16 18:43:25.486021: step 6850, loss = 0.68713 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:43:26.467390 ops/training.py:65 2019-01-16 18:43:26.467297: step 6851, loss = 0.69522 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:43:27.450246 ops/training.py:65 2019-01-16 18:43:27.450136: step 6852, loss = 0.69036 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:43:28.433645 ops/training.py:65 2019-01-16 18:43:28.433543: step 6853, loss = 0.70197 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:43:29.416670 ops/training.py:65 2019-01-16 18:43:29.416567: step 6854, loss = 0.69859 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:43:30.399363 ops/training.py:65 2019-01-16 18:43:30.399256: step 6855, loss = 0.70176 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:43:31.381738 ops/training.py:65 2019-01-16 18:43:31.381632: step 6856, loss = 0.69679 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:43:32.366111 ops/training.py:65 2019-01-16 18:43:32.366010: step 6857, loss = 0.69565 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:43:33.350805 ops/training.py:65 2019-01-16 18:43:33.350702: step 6858, loss = 0.69072 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:43:34.334679 ops/training.py:65 2019-01-16 18:43:34.334576: step 6859, loss = 0.69438 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:43:35.317156 ops/training.py:65 2019-01-16 18:43:35.317046: step 6860, loss = 0.70283 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:43:36.300515 ops/training.py:65 2019-01-16 18:43:36.300414: step 6861, loss = 0.69341 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:43:37.282773 ops/training.py:65 2019-01-16 18:43:37.282672: step 6862, loss = 0.70480 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:43:38.266381 ops/training.py:65 2019-01-16 18:43:38.266270: step 6863, loss = 0.68947 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:43:39.249887 ops/training.py:65 2019-01-16 18:43:39.249783: step 6864, loss = 0.69734 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:43:40.232732 ops/training.py:65 2019-01-16 18:43:40.232639: step 6865, loss = 0.69332 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:43:41.215394 ops/training.py:65 2019-01-16 18:43:41.215307: step 6866, loss = 0.69027 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:43:42.198130 ops/training.py:65 2019-01-16 18:43:42.197999: step 6867, loss = 0.69036 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:43:43.181649 ops/training.py:65 2019-01-16 18:43:43.181545: step 6868, loss = 0.69808 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:43:44.165397 ops/training.py:65 2019-01-16 18:43:44.165295: step 6869, loss = 0.69083 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:43:45.147754 ops/training.py:65 2019-01-16 18:43:45.147653: step 6870, loss = 0.69528 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:43:46.131076 ops/training.py:65 2019-01-16 18:43:46.130967: step 6871, loss = 0.69973 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:43:47.114819 ops/training.py:65 2019-01-16 18:43:47.114709: step 6872, loss = 0.69208 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:43:48.100756 ops/training.py:65 2019-01-16 18:43:48.100648: step 6873, loss = 0.69437 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:43:49.085319 ops/training.py:65 2019-01-16 18:43:49.085212: step 6874, loss = 0.70209 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:43:50.068343 ops/training.py:65 2019-01-16 18:43:50.068236: step 6875, loss = 0.68982 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:43:51.050045 ops/training.py:65 2019-01-16 18:43:51.049933: step 6876, loss = 0.68720 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:43:52.029845 ops/training.py:65 2019-01-16 18:43:52.029777: step 6877, loss = 0.69397 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:43:53.011123 ops/training.py:65 2019-01-16 18:43:53.011061: step 6878, loss = 0.68680 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:43:53.996025 ops/training.py:65 2019-01-16 18:43:53.995946: step 6879, loss = 0.69893 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:43:54.980962 ops/training.py:65 2019-01-16 18:43:54.980863: step 6880, loss = 0.68923 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:43:55.964337 ops/training.py:65 2019-01-16 18:43:55.964239: step 6881, loss = 0.70199 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 18:43:56.946938 ops/training.py:65 2019-01-16 18:43:56.946826: step 6882, loss = 0.68678 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:43:57.929660 ops/training.py:65 2019-01-16 18:43:57.929555: step 6883, loss = 0.68745 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:43:58.911669 ops/training.py:65 2019-01-16 18:43:58.911557: step 6884, loss = 0.69190 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:43:59.897665 ops/training.py:65 2019-01-16 18:43:59.897561: step 6885, loss = 0.68986 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:44:00.882749 ops/training.py:65 2019-01-16 18:44:00.882649: step 6886, loss = 0.68332 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:44:01.867684 ops/training.py:65 2019-01-16 18:44:01.867574: step 6887, loss = 0.68453 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:44:02.850818 ops/training.py:65 2019-01-16 18:44:02.850712: step 6888, loss = 0.68081 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:44:03.834291 ops/training.py:65 2019-01-16 18:44:03.834193: step 6889, loss = 0.70479 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:44:04.816737 ops/training.py:65 2019-01-16 18:44:04.816625: step 6890, loss = 0.68148 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:44:05.798533 ops/training.py:65 2019-01-16 18:44:05.798430: step 6891, loss = 0.70630 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:44:06.780757 ops/training.py:65 2019-01-16 18:44:06.780652: step 6892, loss = 0.68773 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:44:07.761200 ops/training.py:65 2019-01-16 18:44:07.761133: step 6893, loss = 0.69360 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:44:08.741700 ops/training.py:65 2019-01-16 18:44:08.741632: step 6894, loss = 0.69632 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:44:09.722508 ops/training.py:65 2019-01-16 18:44:09.722444: step 6895, loss = 0.69812 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:44:10.704072 ops/training.py:65 2019-01-16 18:44:10.704003: step 6896, loss = 0.68552 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:44:11.686236 ops/training.py:65 2019-01-16 18:44:11.686169: step 6897, loss = 0.68803 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:44:12.667313 ops/training.py:65 2019-01-16 18:44:12.667247: step 6898, loss = 0.70129 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:44:13.648349 ops/training.py:65 2019-01-16 18:44:13.648284: step 6899, loss = 0.69936 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:44:14.633448 ops/training.py:65 2019-01-16 18:44:14.633359: step 6900, loss = 0.69063 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:44:15.619349 ops/training.py:65 2019-01-16 18:44:15.619248: step 6901, loss = 0.69409 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:44:16.602961 ops/training.py:65 2019-01-16 18:44:16.602855: step 6902, loss = 0.68666 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:44:17.584880 ops/training.py:65 2019-01-16 18:44:17.584779: step 6903, loss = 0.70052 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:44:18.567159 ops/training.py:65 2019-01-16 18:44:18.567054: step 6904, loss = 0.69842 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:44:19.551227 ops/training.py:65 2019-01-16 18:44:19.551114: step 6905, loss = 0.68260 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:44:20.537258 ops/training.py:65 2019-01-16 18:44:20.537150: step 6906, loss = 0.69290 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:44:21.521433 ops/training.py:65 2019-01-16 18:44:21.521361: step 6907, loss = 0.70222 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:44:22.505538 ops/training.py:65 2019-01-16 18:44:22.505433: step 6908, loss = 0.69283 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:44:23.491934 ops/training.py:65 2019-01-16 18:44:23.491829: step 6909, loss = 0.69122 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:44:24.475781 ops/training.py:65 2019-01-16 18:44:24.475672: step 6910, loss = 0.69724 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:44:25.459514 ops/training.py:65 2019-01-16 18:44:25.459413: step 6911, loss = 0.68132 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:44:26.442163 ops/training.py:65 2019-01-16 18:44:26.442069: step 6912, loss = 0.69833 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:44:27.424542 ops/training.py:65 2019-01-16 18:44:27.424433: step 6913, loss = 0.69067 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:44:28.406556 ops/training.py:65 2019-01-16 18:44:28.406485: step 6914, loss = 0.69050 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:44:29.387094 ops/training.py:65 2019-01-16 18:44:29.387023: step 6915, loss = 0.70033 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:44:30.371111 ops/training.py:65 2019-01-16 18:44:30.371027: step 6916, loss = 0.68983 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:44:31.356446 ops/training.py:65 2019-01-16 18:44:31.356342: step 6917, loss = 0.70717 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:44:32.340412 ops/training.py:65 2019-01-16 18:44:32.340315: step 6918, loss = 0.70493 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:44:33.324035 ops/training.py:65 2019-01-16 18:44:33.323940: step 6919, loss = 0.68517 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:44:34.306901 ops/training.py:65 2019-01-16 18:44:34.306802: step 6920, loss = 0.69417 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:44:35.290045 ops/training.py:65 2019-01-16 18:44:35.289937: step 6921, loss = 0.68491 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:44:36.273158 ops/training.py:65 2019-01-16 18:44:36.273058: step 6922, loss = 0.70499 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:44:37.256490 ops/training.py:65 2019-01-16 18:44:37.256391: step 6923, loss = 0.69772 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:44:38.239477 ops/training.py:65 2019-01-16 18:44:38.239377: step 6924, loss = 0.69589 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:44:39.222466 ops/training.py:65 2019-01-16 18:44:39.222364: step 6925, loss = 0.68590 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:44:40.206016 ops/training.py:65 2019-01-16 18:44:40.205913: step 6926, loss = 0.69385 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:44:41.189182 ops/training.py:65 2019-01-16 18:44:41.189089: step 6927, loss = 0.69574 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:44:42.172735 ops/training.py:65 2019-01-16 18:44:42.172636: step 6928, loss = 0.68666 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:44:43.154905 ops/training.py:65 2019-01-16 18:44:43.154805: step 6929, loss = 0.68331 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:44:44.140850 ops/training.py:65 2019-01-16 18:44:44.140764: step 6930, loss = 0.69200 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:44:45.127204 ops/training.py:65 2019-01-16 18:44:45.127111: step 6931, loss = 0.68450 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:44:46.112181 ops/training.py:65 2019-01-16 18:44:46.112078: step 6932, loss = 0.70338 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:44:47.094606 ops/training.py:65 2019-01-16 18:44:47.094500: step 6933, loss = 0.70521 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:44:48.076436 ops/training.py:65 2019-01-16 18:44:48.076331: step 6934, loss = 0.69036 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:44:49.058371 ops/training.py:65 2019-01-16 18:44:49.058288: step 6935, loss = 0.69305 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:44:50.039225 ops/training.py:65 2019-01-16 18:44:50.039139: step 6936, loss = 0.69400 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:44:51.018476 ops/training.py:65 2019-01-16 18:44:51.018393: step 6937, loss = 0.69736 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:44:52.004102 ops/training.py:65 2019-01-16 18:44:52.004008: step 6938, loss = 0.69104 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:44:52.989117 ops/training.py:65 2019-01-16 18:44:52.989018: step 6939, loss = 0.68494 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:44:53.973084 ops/training.py:65 2019-01-16 18:44:53.972987: step 6940, loss = 0.71595 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:44:54.955052 ops/training.py:65 2019-01-16 18:44:54.954938: step 6941, loss = 0.69681 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:44:55.938001 ops/training.py:65 2019-01-16 18:44:55.937885: step 6942, loss = 0.69384 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:44:56.920827 ops/training.py:65 2019-01-16 18:44:56.920695: step 6943, loss = 0.69826 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:44:57.903722 ops/training.py:65 2019-01-16 18:44:57.903616: step 6944, loss = 0.69634 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:44:58.886540 ops/training.py:65 2019-01-16 18:44:58.886438: step 6945, loss = 0.68978 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:44:59.869418 ops/training.py:65 2019-01-16 18:44:59.869317: step 6946, loss = 0.69784 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:45:00.852884 ops/training.py:65 2019-01-16 18:45:00.852780: step 6947, loss = 0.70983 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:45:01.834578 ops/training.py:65 2019-01-16 18:45:01.834471: step 6948, loss = 0.70944 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:45:02.820271 ops/training.py:65 2019-01-16 18:45:02.820163: step 6949, loss = 0.69299 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:45:03.805067 ops/training.py:65 2019-01-16 18:45:03.804931: step 6950, loss = 0.67791 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:45:04.788639 ops/training.py:65 2019-01-16 18:45:04.788533: step 6951, loss = 0.69986 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:45:05.768999 ops/training.py:65 2019-01-16 18:45:05.768896: step 6952, loss = 0.69424 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:45:06.751569 ops/training.py:65 2019-01-16 18:45:06.751499: step 6953, loss = 0.68355 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:45:07.731961 ops/training.py:65 2019-01-16 18:45:07.731888: step 6954, loss = 0.69706 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:45:08.711416 ops/training.py:65 2019-01-16 18:45:08.711343: step 6955, loss = 0.68936 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:45:09.690784 ops/training.py:65 2019-01-16 18:45:09.690719: step 6956, loss = 0.68863 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:45:10.670257 ops/training.py:65 2019-01-16 18:45:10.670183: step 6957, loss = 0.68541 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:45:11.651047 ops/training.py:65 2019-01-16 18:45:11.650980: step 6958, loss = 0.69138 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:45:12.631804 ops/training.py:65 2019-01-16 18:45:12.631736: step 6959, loss = 0.70590 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:45:13.611817 ops/training.py:65 2019-01-16 18:45:13.611745: step 6960, loss = 0.69078 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:45:14.593225 ops/training.py:65 2019-01-16 18:45:14.593153: step 6961, loss = 0.68785 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:45:15.574274 ops/training.py:65 2019-01-16 18:45:15.574201: step 6962, loss = 0.68646 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:45:16.554513 ops/training.py:65 2019-01-16 18:45:16.554430: step 6963, loss = 0.68661 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:45:17.533293 ops/training.py:65 2019-01-16 18:45:17.533227: step 6964, loss = 0.69538 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:45:18.512844 ops/training.py:65 2019-01-16 18:45:18.512773: step 6965, loss = 0.69299 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:45:19.492134 ops/training.py:65 2019-01-16 18:45:19.492061: step 6966, loss = 0.68971 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:45:20.472577 ops/training.py:65 2019-01-16 18:45:20.472508: step 6967, loss = 0.69297 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:45:21.456429 ops/training.py:65 2019-01-16 18:45:21.456350: step 6968, loss = 0.69355 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:45:22.439996 ops/training.py:65 2019-01-16 18:45:22.439884: step 6969, loss = 0.69715 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:45:23.422688 ops/training.py:65 2019-01-16 18:45:23.422580: step 6970, loss = 0.70900 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.21875
I8192 2019-01-16 18:45:24.405566 ops/training.py:65 2019-01-16 18:45:24.405470: step 6971, loss = 0.69478 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:45:25.388377 ops/training.py:65 2019-01-16 18:45:25.388283: step 6972, loss = 0.69319 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:45:26.370722 ops/training.py:65 2019-01-16 18:45:26.370628: step 6973, loss = 0.69569 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:45:27.353251 ops/training.py:65 2019-01-16 18:45:27.353150: step 6974, loss = 0.69468 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:45:28.336031 ops/training.py:65 2019-01-16 18:45:28.335916: step 6975, loss = 0.69335 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:45:29.321172 ops/training.py:65 2019-01-16 18:45:29.321066: step 6976, loss = 0.69406 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:45:30.304455 ops/training.py:65 2019-01-16 18:45:30.304362: step 6977, loss = 0.69111 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:45:31.284914 ops/training.py:65 2019-01-16 18:45:31.284835: step 6978, loss = 0.68765 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:45:32.270016 ops/training.py:65 2019-01-16 18:45:32.269939: step 6979, loss = 0.69528 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:45:33.254640 ops/training.py:65 2019-01-16 18:45:33.254538: step 6980, loss = 0.69211 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:45:34.239190 ops/training.py:65 2019-01-16 18:45:34.239090: step 6981, loss = 0.68156 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:45:35.223651 ops/training.py:65 2019-01-16 18:45:35.223547: step 6982, loss = 0.68888 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:45:36.206297 ops/training.py:65 2019-01-16 18:45:36.206195: step 6983, loss = 0.69312 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:45:37.188608 ops/training.py:65 2019-01-16 18:45:37.188510: step 6984, loss = 0.68848 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:45:38.172047 ops/training.py:65 2019-01-16 18:45:38.171974: step 6985, loss = 0.68447 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:45:39.157074 ops/training.py:65 2019-01-16 18:45:39.156970: step 6986, loss = 0.69011 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:45:40.141811 ops/training.py:65 2019-01-16 18:45:40.141715: step 6987, loss = 0.68720 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:45:41.125535 ops/training.py:65 2019-01-16 18:45:41.125445: step 6988, loss = 0.69613 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:45:42.107869 ops/training.py:65 2019-01-16 18:45:42.107798: step 6989, loss = 0.69576 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:45:43.088292 ops/training.py:65 2019-01-16 18:45:43.088221: step 6990, loss = 0.69833 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:45:44.067453 ops/training.py:65 2019-01-16 18:45:44.067375: step 6991, loss = 0.68548 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:45:45.048595 ops/training.py:65 2019-01-16 18:45:45.048516: step 6992, loss = 0.68564 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:45:46.031570 ops/training.py:65 2019-01-16 18:45:46.031505: step 6993, loss = 0.70121 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:45:47.016019 ops/training.py:65 2019-01-16 18:45:47.015892: step 6994, loss = 0.69190 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:45:47.999164 ops/training.py:65 2019-01-16 18:45:47.999017: step 6995, loss = 0.68187 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:45:48.982939 ops/training.py:65 2019-01-16 18:45:48.982831: step 6996, loss = 0.69603 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:45:49.966421 ops/training.py:65 2019-01-16 18:45:49.966313: step 6997, loss = 0.68923 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:45:50.947882 ops/training.py:65 2019-01-16 18:45:50.947770: step 6998, loss = 0.69267 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:45:51.929758 ops/training.py:65 2019-01-16 18:45:51.929649: step 6999, loss = 0.70273 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:45:52.911683 ops/training.py:65 2019-01-16 18:45:52.911572: step 7000, loss = 0.69339 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:45:53.896118 ops/training.py:65 2019-01-16 18:45:53.896014: step 7001, loss = 0.70902 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:45:54.878609 ops/training.py:65 2019-01-16 18:45:54.878471: step 7002, loss = 0.69456 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:45:55.860956 ops/training.py:65 2019-01-16 18:45:55.860860: step 7003, loss = 0.69079 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:45:56.843509 ops/training.py:65 2019-01-16 18:45:56.843404: step 7004, loss = 0.71465 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 18:45:57.826923 ops/training.py:65 2019-01-16 18:45:57.826811: step 7005, loss = 0.67967 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:45:58.811932 ops/training.py:65 2019-01-16 18:45:58.811827: step 7006, loss = 0.70501 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:45:59.796267 ops/training.py:65 2019-01-16 18:45:59.796165: step 7007, loss = 0.68476 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:46:00.779797 ops/training.py:65 2019-01-16 18:46:00.779688: step 7008, loss = 0.68668 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:46:01.761943 ops/training.py:65 2019-01-16 18:46:01.761840: step 7009, loss = 0.69022 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:46:02.744892 ops/training.py:65 2019-01-16 18:46:02.744791: step 7010, loss = 0.68909 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:46:03.728566 ops/training.py:65 2019-01-16 18:46:03.728459: step 7011, loss = 0.69932 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:46:04.711162 ops/training.py:65 2019-01-16 18:46:04.711056: step 7012, loss = 0.69239 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:46:05.693635 ops/training.py:65 2019-01-16 18:46:05.693528: step 7013, loss = 0.68457 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:46:06.676162 ops/training.py:65 2019-01-16 18:46:06.676059: step 7014, loss = 0.70058 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:46:07.658990 ops/training.py:65 2019-01-16 18:46:07.658885: step 7015, loss = 0.70425 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:46:08.640405 ops/training.py:65 2019-01-16 18:46:08.640299: step 7016, loss = 0.69698 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:46:09.621824 ops/training.py:65 2019-01-16 18:46:09.621719: step 7017, loss = 0.69435 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:46:10.602972 ops/training.py:65 2019-01-16 18:46:10.602872: step 7018, loss = 0.70157 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:46:11.585233 ops/training.py:65 2019-01-16 18:46:11.585147: step 7019, loss = 0.69960 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:46:12.567462 ops/training.py:65 2019-01-16 18:46:12.567357: step 7020, loss = 0.69888 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:46:13.550791 ops/training.py:65 2019-01-16 18:46:13.550690: step 7021, loss = 0.70280 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:46:14.532584 ops/training.py:65 2019-01-16 18:46:14.532446: step 7022, loss = 0.69567 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:46:15.516427 ops/training.py:65 2019-01-16 18:46:15.516321: step 7023, loss = 0.68200 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:46:16.500430 ops/training.py:65 2019-01-16 18:46:16.500299: step 7024, loss = 0.68939 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:46:17.484465 ops/training.py:65 2019-01-16 18:46:17.484365: step 7025, loss = 0.70267 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:46:18.467404 ops/training.py:65 2019-01-16 18:46:18.467294: step 7026, loss = 0.70277 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:46:19.451298 ops/training.py:65 2019-01-16 18:46:19.451187: step 7027, loss = 0.70455 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:46:20.434235 ops/training.py:65 2019-01-16 18:46:20.434131: step 7028, loss = 0.67949 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:46:21.415693 ops/training.py:65 2019-01-16 18:46:21.415591: step 7029, loss = 0.71063 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:46:22.397244 ops/training.py:65 2019-01-16 18:46:22.397150: step 7030, loss = 0.66831 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:46:23.380869 ops/training.py:65 2019-01-16 18:46:23.380760: step 7031, loss = 0.71075 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:46:24.366364 ops/training.py:65 2019-01-16 18:46:24.366265: step 7032, loss = 0.70363 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:46:25.349608 ops/training.py:65 2019-01-16 18:46:25.349509: step 7033, loss = 0.71144 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:46:26.333066 ops/training.py:65 2019-01-16 18:46:26.332974: step 7034, loss = 0.67952 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:46:27.317670 ops/training.py:65 2019-01-16 18:46:27.317574: step 7035, loss = 0.69501 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:46:28.301633 ops/training.py:65 2019-01-16 18:46:28.301530: step 7036, loss = 0.69147 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:46:29.285356 ops/training.py:65 2019-01-16 18:46:29.285258: step 7037, loss = 0.68837 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:46:30.268656 ops/training.py:65 2019-01-16 18:46:30.268550: step 7038, loss = 0.69777 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:46:31.252055 ops/training.py:65 2019-01-16 18:46:31.251949: step 7039, loss = 0.68720 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:46:32.234485 ops/training.py:65 2019-01-16 18:46:32.234386: step 7040, loss = 0.70335 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:46:33.218009 ops/training.py:65 2019-01-16 18:46:33.217906: step 7041, loss = 0.68088 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:46:34.200959 ops/training.py:65 2019-01-16 18:46:34.200855: step 7042, loss = 0.69859 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:46:35.183646 ops/training.py:65 2019-01-16 18:46:35.183551: step 7043, loss = 0.67994 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:46:36.165988 ops/training.py:65 2019-01-16 18:46:36.165893: step 7044, loss = 0.68753 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:46:37.148032 ops/training.py:65 2019-01-16 18:46:37.147933: step 7045, loss = 0.71584 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:46:38.130919 ops/training.py:65 2019-01-16 18:46:38.130815: step 7046, loss = 0.68481 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:46:39.113126 ops/training.py:65 2019-01-16 18:46:39.113022: step 7047, loss = 0.67953 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:46:40.095452 ops/training.py:65 2019-01-16 18:46:40.095351: step 7048, loss = 0.68645 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:46:41.080328 ops/training.py:65 2019-01-16 18:46:41.080234: step 7049, loss = 0.68731 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:46:42.061769 ops/training.py:65 2019-01-16 18:46:42.061688: step 7050, loss = 0.69453 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:46:43.043676 ops/training.py:65 2019-01-16 18:46:43.043592: step 7051, loss = 0.72441 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:46:44.023763 ops/training.py:65 2019-01-16 18:46:44.023679: step 7052, loss = 0.68732 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:46:45.007075 ops/training.py:65 2019-01-16 18:46:45.007002: step 7053, loss = 0.70140 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:46:45.990816 ops/training.py:65 2019-01-16 18:46:45.990718: step 7054, loss = 0.69057 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:46:46.972571 ops/training.py:65 2019-01-16 18:46:46.972466: step 7055, loss = 0.71789 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:46:47.956841 ops/training.py:65 2019-01-16 18:46:47.956750: step 7056, loss = 0.71155 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:46:48.940205 ops/training.py:65 2019-01-16 18:46:48.940106: step 7057, loss = 0.68892 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:46:49.922894 ops/training.py:65 2019-01-16 18:46:49.922795: step 7058, loss = 0.68493 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:46:50.905677 ops/training.py:65 2019-01-16 18:46:50.905570: step 7059, loss = 0.68391 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:46:51.890022 ops/training.py:65 2019-01-16 18:46:51.889910: step 7060, loss = 0.71433 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:46:52.875472 ops/training.py:65 2019-01-16 18:46:52.875365: step 7061, loss = 0.70458 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:46:53.858604 ops/training.py:65 2019-01-16 18:46:53.858513: step 7062, loss = 0.69345 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:46:54.840994 ops/training.py:65 2019-01-16 18:46:54.840905: step 7063, loss = 0.70626 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:46:55.824424 ops/training.py:65 2019-01-16 18:46:55.824333: step 7064, loss = 0.69737 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:46:56.808946 ops/training.py:65 2019-01-16 18:46:56.808851: step 7065, loss = 0.70734 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:46:57.792193 ops/training.py:65 2019-01-16 18:46:57.792086: step 7066, loss = 0.69061 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:46:58.776292 ops/training.py:65 2019-01-16 18:46:58.776194: step 7067, loss = 0.70770 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:46:59.760212 ops/training.py:65 2019-01-16 18:46:59.760110: step 7068, loss = 0.69096 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:47:00.744545 ops/training.py:65 2019-01-16 18:47:00.744447: step 7069, loss = 0.69314 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:47:01.727026 ops/training.py:65 2019-01-16 18:47:01.726928: step 7070, loss = 0.70569 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:47:02.710067 ops/training.py:65 2019-01-16 18:47:02.709953: step 7071, loss = 0.70239 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:47:03.690910 ops/training.py:65 2019-01-16 18:47:03.690815: step 7072, loss = 0.69755 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:47:04.672090 ops/training.py:65 2019-01-16 18:47:04.672015: step 7073, loss = 0.71240 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:47:05.654977 ops/training.py:65 2019-01-16 18:47:05.654897: step 7074, loss = 0.68234 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:47:06.638610 ops/training.py:65 2019-01-16 18:47:06.638477: step 7075, loss = 0.70911 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:47:07.622614 ops/training.py:65 2019-01-16 18:47:07.622511: step 7076, loss = 0.69023 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:47:08.606384 ops/training.py:65 2019-01-16 18:47:08.606301: step 7077, loss = 0.68980 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:47:09.589140 ops/training.py:65 2019-01-16 18:47:09.589038: step 7078, loss = 0.68655 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:47:10.572415 ops/training.py:65 2019-01-16 18:47:10.572316: step 7079, loss = 0.70928 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:47:11.557750 ops/training.py:65 2019-01-16 18:47:11.557657: step 7080, loss = 0.69165 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:47:12.541212 ops/training.py:65 2019-01-16 18:47:12.541109: step 7081, loss = 0.69161 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:47:13.524412 ops/training.py:65 2019-01-16 18:47:13.524311: step 7082, loss = 0.67273 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:47:14.506980 ops/training.py:65 2019-01-16 18:47:14.506877: step 7083, loss = 0.71598 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:47:15.490164 ops/training.py:65 2019-01-16 18:47:15.490060: step 7084, loss = 0.71783 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:47:16.472875 ops/training.py:65 2019-01-16 18:47:16.472768: step 7085, loss = 0.71332 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:47:17.454806 ops/training.py:65 2019-01-16 18:47:17.454695: step 7086, loss = 0.70699 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:47:18.438165 ops/training.py:65 2019-01-16 18:47:18.438054: step 7087, loss = 0.70226 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:47:19.420455 ops/training.py:65 2019-01-16 18:47:19.420352: step 7088, loss = 0.71389 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:47:20.401226 ops/training.py:65 2019-01-16 18:47:20.401124: step 7089, loss = 0.69446 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:47:21.381202 ops/training.py:65 2019-01-16 18:47:21.381135: step 7090, loss = 0.69019 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:47:22.363876 ops/training.py:65 2019-01-16 18:47:22.363802: step 7091, loss = 0.73573 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:47:23.347766 ops/training.py:65 2019-01-16 18:47:23.347667: step 7092, loss = 0.68670 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:47:24.331671 ops/training.py:65 2019-01-16 18:47:24.331574: step 7093, loss = 0.66704 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:47:25.313516 ops/training.py:65 2019-01-16 18:47:25.313405: step 7094, loss = 0.70685 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:47:26.298156 ops/training.py:65 2019-01-16 18:47:26.298057: step 7095, loss = 0.68532 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:47:27.285171 ops/training.py:65 2019-01-16 18:47:27.285062: step 7096, loss = 0.66805 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:47:28.268707 ops/training.py:65 2019-01-16 18:47:28.268638: step 7097, loss = 0.69663 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:47:29.254363 ops/training.py:65 2019-01-16 18:47:29.254251: step 7098, loss = 0.68727 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:47:30.237178 ops/training.py:65 2019-01-16 18:47:30.237049: step 7099, loss = 0.69564 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:47:31.220959 ops/training.py:65 2019-01-16 18:47:31.220869: step 7100, loss = 0.69023 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:47:32.203546 ops/training.py:65 2019-01-16 18:47:32.203447: step 7101, loss = 0.74043 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:47:33.186426 ops/training.py:65 2019-01-16 18:47:33.186320: step 7102, loss = 0.68064 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:47:34.169367 ops/training.py:65 2019-01-16 18:47:34.169269: step 7103, loss = 0.70056 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:47:35.153895 ops/training.py:65 2019-01-16 18:47:35.153791: step 7104, loss = 0.65911 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:47:36.138270 ops/training.py:65 2019-01-16 18:47:36.138166: step 7105, loss = 0.70567 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:47:37.123178 ops/training.py:65 2019-01-16 18:47:37.123075: step 7106, loss = 0.68785 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:47:38.107617 ops/training.py:65 2019-01-16 18:47:38.107505: step 7107, loss = 0.69668 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:47:39.091996 ops/training.py:65 2019-01-16 18:47:39.091888: step 7108, loss = 0.68747 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:47:40.075015 ops/training.py:65 2019-01-16 18:47:40.074909: step 7109, loss = 0.73346 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:47:41.057049 ops/training.py:65 2019-01-16 18:47:41.056951: step 7110, loss = 0.69765 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:47:42.038918 ops/training.py:65 2019-01-16 18:47:42.038810: step 7111, loss = 0.67825 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:47:43.020083 ops/training.py:65 2019-01-16 18:47:43.019976: step 7112, loss = 0.69437 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:47:44.001503 ops/training.py:65 2019-01-16 18:47:44.001402: step 7113, loss = 0.74054 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 18:47:44.983940 ops/training.py:65 2019-01-16 18:47:44.983838: step 7114, loss = 0.69167 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:47:45.966586 ops/training.py:65 2019-01-16 18:47:45.966472: step 7115, loss = 0.69756 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:47:46.949965 ops/training.py:65 2019-01-16 18:47:46.949850: step 7116, loss = 0.70259 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:47:47.934147 ops/training.py:65 2019-01-16 18:47:47.934036: step 7117, loss = 0.66120 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:47:48.916556 ops/training.py:65 2019-01-16 18:47:48.916455: step 7118, loss = 0.69434 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:47:49.901538 ops/training.py:65 2019-01-16 18:47:49.901432: step 7119, loss = 0.70239 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:47:50.886072 ops/training.py:65 2019-01-16 18:47:50.885974: step 7120, loss = 0.68049 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:47:51.871238 ops/training.py:65 2019-01-16 18:47:51.871128: step 7121, loss = 0.69848 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:47:52.856292 ops/training.py:65 2019-01-16 18:47:52.856180: step 7122, loss = 0.69434 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:47:53.840132 ops/training.py:65 2019-01-16 18:47:53.840027: step 7123, loss = 0.69747 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:47:54.822430 ops/training.py:65 2019-01-16 18:47:54.822325: step 7124, loss = 0.69056 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:47:55.804374 ops/training.py:65 2019-01-16 18:47:55.804284: step 7125, loss = 0.68677 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:47:56.785950 ops/training.py:65 2019-01-16 18:47:56.785851: step 7126, loss = 0.70930 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:47:57.767563 ops/training.py:65 2019-01-16 18:47:57.767458: step 7127, loss = 0.68946 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:47:58.749647 ops/training.py:65 2019-01-16 18:47:58.749535: step 7128, loss = 0.69428 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:47:59.733282 ops/training.py:65 2019-01-16 18:47:59.733178: step 7129, loss = 0.65300 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:48:00.716640 ops/training.py:65 2019-01-16 18:48:00.716553: step 7130, loss = 0.69754 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:48:01.698087 ops/training.py:65 2019-01-16 18:48:01.698016: step 7131, loss = 0.71359 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:48:02.681017 ops/training.py:65 2019-01-16 18:48:02.680948: step 7132, loss = 0.68826 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:48:03.664925 ops/training.py:65 2019-01-16 18:48:03.664823: step 7133, loss = 0.67655 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:48:04.649559 ops/training.py:65 2019-01-16 18:48:04.649457: step 7134, loss = 0.70686 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:48:05.634332 ops/training.py:65 2019-01-16 18:48:05.634227: step 7135, loss = 0.68341 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:48:06.617312 ops/training.py:65 2019-01-16 18:48:06.617207: step 7136, loss = 0.69455 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:48:07.602135 ops/training.py:65 2019-01-16 18:48:07.602029: step 7137, loss = 0.68260 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:48:08.586184 ops/training.py:65 2019-01-16 18:48:08.586076: step 7138, loss = 0.69235 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:48:09.572660 ops/training.py:65 2019-01-16 18:48:09.572548: step 7139, loss = 0.70488 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:48:10.557304 ops/training.py:65 2019-01-16 18:48:10.557199: step 7140, loss = 0.68644 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:48:11.543029 ops/training.py:65 2019-01-16 18:48:11.542939: step 7141, loss = 0.70106 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:48:12.527130 ops/training.py:65 2019-01-16 18:48:12.527029: step 7142, loss = 0.68531 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:48:13.513007 ops/training.py:65 2019-01-16 18:48:13.512897: step 7143, loss = 0.68607 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:48:14.498925 ops/training.py:65 2019-01-16 18:48:14.498820: step 7144, loss = 0.69865 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:48:15.482436 ops/training.py:65 2019-01-16 18:48:15.482352: step 7145, loss = 0.69677 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:48:16.462517 ops/training.py:65 2019-01-16 18:48:16.462439: step 7146, loss = 0.69956 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:48:17.442285 ops/training.py:65 2019-01-16 18:48:17.442214: step 7147, loss = 0.70554 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:48:18.422663 ops/training.py:65 2019-01-16 18:48:18.422587: step 7148, loss = 0.67295 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:48:19.403807 ops/training.py:65 2019-01-16 18:48:19.403723: step 7149, loss = 0.69998 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:48:20.386307 ops/training.py:65 2019-01-16 18:48:20.386203: step 7150, loss = 0.70114 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:48:21.366193 ops/training.py:65 2019-01-16 18:48:21.366120: step 7151, loss = 0.70082 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:48:22.345886 ops/training.py:65 2019-01-16 18:48:22.345814: step 7152, loss = 0.71851 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 18:48:23.330637 ops/training.py:65 2019-01-16 18:48:23.330548: step 7153, loss = 0.66898 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:48:24.316579 ops/training.py:65 2019-01-16 18:48:24.316462: step 7154, loss = 0.70227 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:48:25.300206 ops/training.py:65 2019-01-16 18:48:25.300101: step 7155, loss = 0.68219 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:48:26.285327 ops/training.py:65 2019-01-16 18:48:26.285234: step 7156, loss = 0.70206 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:48:27.269391 ops/training.py:65 2019-01-16 18:48:27.269290: step 7157, loss = 0.68797 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:48:28.253034 ops/training.py:65 2019-01-16 18:48:28.252930: step 7158, loss = 0.71021 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:48:29.234152 ops/training.py:65 2019-01-16 18:48:29.234053: step 7159, loss = 0.67367 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:48:30.215025 ops/training.py:65 2019-01-16 18:48:30.214949: step 7160, loss = 0.69909 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:48:31.195035 ops/training.py:65 2019-01-16 18:48:31.194961: step 7161, loss = 0.71098 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:48:32.174992 ops/training.py:65 2019-01-16 18:48:32.174894: step 7162, loss = 0.69844 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:48:33.156373 ops/training.py:65 2019-01-16 18:48:33.156297: step 7163, loss = 0.70459 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:48:34.137633 ops/training.py:65 2019-01-16 18:48:34.137564: step 7164, loss = 0.69809 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:48:35.121650 ops/training.py:65 2019-01-16 18:48:35.121539: step 7165, loss = 0.70585 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:48:36.106696 ops/training.py:65 2019-01-16 18:48:36.106588: step 7166, loss = 0.69414 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:48:37.090695 ops/training.py:65 2019-01-16 18:48:37.090593: step 7167, loss = 0.68542 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:48:38.074150 ops/training.py:65 2019-01-16 18:48:38.074074: step 7168, loss = 0.70045 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:48:39.054271 ops/training.py:65 2019-01-16 18:48:39.054191: step 7169, loss = 0.69439 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:48:40.037531 ops/training.py:65 2019-01-16 18:48:40.037463: step 7170, loss = 0.68151 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:48:41.020939 ops/training.py:65 2019-01-16 18:48:41.020843: step 7171, loss = 0.69348 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:48:42.004505 ops/training.py:65 2019-01-16 18:48:42.004398: step 7172, loss = 0.69634 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:48:42.987028 ops/training.py:65 2019-01-16 18:48:42.986913: step 7173, loss = 0.70621 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:48:43.971795 ops/training.py:65 2019-01-16 18:48:43.971685: step 7174, loss = 0.69065 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:48:44.957063 ops/training.py:65 2019-01-16 18:48:44.956933: step 7175, loss = 0.69691 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:48:45.941992 ops/training.py:65 2019-01-16 18:48:45.941883: step 7176, loss = 0.69256 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:48:46.925790 ops/training.py:65 2019-01-16 18:48:46.925685: step 7177, loss = 0.67699 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:48:47.909311 ops/training.py:65 2019-01-16 18:48:47.909206: step 7178, loss = 0.71301 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:48:48.893333 ops/training.py:65 2019-01-16 18:48:48.893230: step 7179, loss = 0.70488 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:48:49.874881 ops/training.py:65 2019-01-16 18:48:49.874772: step 7180, loss = 0.69893 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:48:50.858846 ops/training.py:65 2019-01-16 18:48:50.858739: step 7181, loss = 0.68244 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:48:51.843744 ops/training.py:65 2019-01-16 18:48:51.843639: step 7182, loss = 0.69681 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:48:52.827265 ops/training.py:65 2019-01-16 18:48:52.827157: step 7183, loss = 0.70384 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:48:53.808777 ops/training.py:65 2019-01-16 18:48:53.808676: step 7184, loss = 0.69415 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:48:54.793041 ops/training.py:65 2019-01-16 18:48:54.792957: step 7185, loss = 0.69886 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:48:55.776410 ops/training.py:65 2019-01-16 18:48:55.776298: step 7186, loss = 0.70573 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:48:56.762026 ops/training.py:65 2019-01-16 18:48:56.761892: step 7187, loss = 0.67167 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:48:57.747632 ops/training.py:65 2019-01-16 18:48:57.747525: step 7188, loss = 0.70875 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:48:58.730769 ops/training.py:65 2019-01-16 18:48:58.730656: step 7189, loss = 0.68659 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:48:59.713065 ops/training.py:65 2019-01-16 18:48:59.712980: step 7190, loss = 0.69761 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:49:00.697326 ops/training.py:65 2019-01-16 18:49:00.697214: step 7191, loss = 0.72789 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 18:49:01.682281 ops/training.py:65 2019-01-16 18:49:01.682181: step 7192, loss = 0.69289 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:49:02.665969 ops/training.py:65 2019-01-16 18:49:02.665861: step 7193, loss = 0.69476 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:49:03.649716 ops/training.py:65 2019-01-16 18:49:03.649613: step 7194, loss = 0.69538 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:49:04.633076 ops/training.py:65 2019-01-16 18:49:04.632983: step 7195, loss = 0.68501 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:49:05.615846 ops/training.py:65 2019-01-16 18:49:05.615742: step 7196, loss = 0.70488 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:49:06.599220 ops/training.py:65 2019-01-16 18:49:06.599112: step 7197, loss = 0.70073 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:49:07.584333 ops/training.py:65 2019-01-16 18:49:07.584233: step 7198, loss = 0.68888 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:49:08.578033 ops/training.py:65 2019-01-16 18:49:08.577930: step 7199, loss = 0.69358 (32.2 examples/sec; 0.992 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:49:09.562975 ops/training.py:65 2019-01-16 18:49:09.562846: step 7200, loss = 0.67220 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:49:10.546759 ops/training.py:65 2019-01-16 18:49:10.546659: step 7201, loss = 0.68829 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:49:11.529896 ops/training.py:65 2019-01-16 18:49:11.529792: step 7202, loss = 0.71668 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:49:12.512157 ops/training.py:65 2019-01-16 18:49:12.512048: step 7203, loss = 0.68737 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:49:13.494339 ops/training.py:65 2019-01-16 18:49:13.494235: step 7204, loss = 0.69353 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:49:14.477219 ops/training.py:65 2019-01-16 18:49:14.477108: step 7205, loss = 0.68995 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:49:15.461799 ops/training.py:65 2019-01-16 18:49:15.461693: step 7206, loss = 0.68502 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:49:16.446736 ops/training.py:65 2019-01-16 18:49:16.446631: step 7207, loss = 0.68205 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:49:17.430673 ops/training.py:65 2019-01-16 18:49:17.430571: step 7208, loss = 0.70745 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:49:18.415553 ops/training.py:65 2019-01-16 18:49:18.415454: step 7209, loss = 0.72044 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 18:49:19.400555 ops/training.py:65 2019-01-16 18:49:19.400442: step 7210, loss = 0.70083 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:49:20.385024 ops/training.py:65 2019-01-16 18:49:20.384916: step 7211, loss = 0.68572 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:49:21.369007 ops/training.py:65 2019-01-16 18:49:21.368909: step 7212, loss = 0.69971 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:49:22.350413 ops/training.py:65 2019-01-16 18:49:22.350331: step 7213, loss = 0.69921 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:49:23.332221 ops/training.py:65 2019-01-16 18:49:23.332155: step 7214, loss = 0.70143 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:49:24.315528 ops/training.py:65 2019-01-16 18:49:24.315460: step 7215, loss = 0.68253 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:49:25.299047 ops/training.py:65 2019-01-16 18:49:25.298939: step 7216, loss = 0.68511 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:49:26.282314 ops/training.py:65 2019-01-16 18:49:26.282221: step 7217, loss = 0.70247 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:49:27.263935 ops/training.py:65 2019-01-16 18:49:27.263826: step 7218, loss = 0.69194 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:49:28.248340 ops/training.py:65 2019-01-16 18:49:28.248235: step 7219, loss = 0.69795 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:49:29.231108 ops/training.py:65 2019-01-16 18:49:29.230996: step 7220, loss = 0.70272 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:49:30.216159 ops/training.py:65 2019-01-16 18:49:30.216054: step 7221, loss = 0.68390 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:49:31.199549 ops/training.py:65 2019-01-16 18:49:31.199444: step 7222, loss = 0.69538 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:49:32.181881 ops/training.py:65 2019-01-16 18:49:32.181773: step 7223, loss = 0.69392 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:49:33.165826 ops/training.py:65 2019-01-16 18:49:33.165726: step 7224, loss = 0.68064 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:49:34.151501 ops/training.py:65 2019-01-16 18:49:34.151398: step 7225, loss = 0.67967 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:49:35.133954 ops/training.py:65 2019-01-16 18:49:35.133846: step 7226, loss = 0.69764 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:49:36.117598 ops/training.py:65 2019-01-16 18:49:36.117507: step 7227, loss = 0.69729 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:49:37.102112 ops/training.py:65 2019-01-16 18:49:37.102002: step 7228, loss = 0.69282 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:49:38.086217 ops/training.py:65 2019-01-16 18:49:38.086112: step 7229, loss = 0.69872 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:49:39.068882 ops/training.py:65 2019-01-16 18:49:39.068779: step 7230, loss = 0.69083 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:49:40.051341 ops/training.py:65 2019-01-16 18:49:40.051240: step 7231, loss = 0.70687 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:49:41.034234 ops/training.py:65 2019-01-16 18:49:41.034143: step 7232, loss = 0.69037 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:49:42.016581 ops/training.py:65 2019-01-16 18:49:42.016484: step 7233, loss = 0.69571 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:49:42.999520 ops/training.py:65 2019-01-16 18:49:42.999435: step 7234, loss = 0.69432 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:49:43.982062 ops/training.py:65 2019-01-16 18:49:43.981952: step 7235, loss = 0.69325 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:49:44.965989 ops/training.py:65 2019-01-16 18:49:44.965912: step 7236, loss = 0.67637 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:49:45.948667 ops/training.py:65 2019-01-16 18:49:45.948562: step 7237, loss = 0.69741 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:49:46.930031 ops/training.py:65 2019-01-16 18:49:46.929924: step 7238, loss = 0.70704 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 18:49:47.917626 ops/training.py:65 2019-01-16 18:49:47.917521: step 7239, loss = 0.69598 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:49:48.901346 ops/training.py:65 2019-01-16 18:49:48.901244: step 7240, loss = 0.69915 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:49:49.885831 ops/training.py:65 2019-01-16 18:49:49.885729: step 7241, loss = 0.70564 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:49:50.868574 ops/training.py:65 2019-01-16 18:49:50.868477: step 7242, loss = 0.68443 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:49:51.853795 ops/training.py:65 2019-01-16 18:49:51.853699: step 7243, loss = 0.69842 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:49:52.837600 ops/training.py:65 2019-01-16 18:49:52.837498: step 7244, loss = 0.70236 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:49:53.822944 ops/training.py:65 2019-01-16 18:49:53.822851: step 7245, loss = 0.70921 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:49:54.807354 ops/training.py:65 2019-01-16 18:49:54.807262: step 7246, loss = 0.69720 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:49:55.792916 ops/training.py:65 2019-01-16 18:49:55.792815: step 7247, loss = 0.71456 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:49:56.776388 ops/training.py:65 2019-01-16 18:49:56.776292: step 7248, loss = 0.70244 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:49:57.759703 ops/training.py:65 2019-01-16 18:49:57.759597: step 7249, loss = 0.68504 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:49:58.742239 ops/training.py:65 2019-01-16 18:49:58.742140: step 7250, loss = 0.69560 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:49:59.731623 ops/training.py:65 2019-01-16 18:49:59.731521: step 7251, loss = 0.70465 (32.4 examples/sec; 0.988 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:50:00.716281 ops/training.py:65 2019-01-16 18:50:00.716184: step 7252, loss = 0.69171 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:50:01.700444 ops/training.py:65 2019-01-16 18:50:01.700359: step 7253, loss = 0.69249 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:50:02.685084 ops/training.py:65 2019-01-16 18:50:02.684985: step 7254, loss = 0.68806 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:50:03.668787 ops/training.py:65 2019-01-16 18:50:03.668694: step 7255, loss = 0.67754 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:50:04.651905 ops/training.py:65 2019-01-16 18:50:04.651801: step 7256, loss = 0.69786 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:50:05.634296 ops/training.py:65 2019-01-16 18:50:05.634194: step 7257, loss = 0.68922 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:50:06.616773 ops/training.py:65 2019-01-16 18:50:06.616668: step 7258, loss = 0.68874 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:50:07.598935 ops/training.py:65 2019-01-16 18:50:07.598830: step 7259, loss = 0.72170 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:50:08.583582 ops/training.py:65 2019-01-16 18:50:08.583484: step 7260, loss = 0.68035 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:50:09.566749 ops/training.py:65 2019-01-16 18:50:09.566643: step 7261, loss = 0.68695 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:50:10.551392 ops/training.py:65 2019-01-16 18:50:10.551286: step 7262, loss = 0.69798 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:50:11.532991 ops/training.py:65 2019-01-16 18:50:11.532906: step 7263, loss = 0.71013 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:50:12.517630 ops/training.py:65 2019-01-16 18:50:12.517547: step 7264, loss = 0.71371 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:50:13.501168 ops/training.py:65 2019-01-16 18:50:13.501066: step 7265, loss = 0.69899 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:50:14.484404 ops/training.py:65 2019-01-16 18:50:14.484296: step 7266, loss = 0.71710 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:50:15.466536 ops/training.py:65 2019-01-16 18:50:15.466429: step 7267, loss = 0.69242 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:50:16.448099 ops/training.py:65 2019-01-16 18:50:16.447997: step 7268, loss = 0.70068 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:50:17.430564 ops/training.py:65 2019-01-16 18:50:17.430423: step 7269, loss = 0.70907 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:50:18.414530 ops/training.py:65 2019-01-16 18:50:18.414423: step 7270, loss = 0.67327 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:50:19.399805 ops/training.py:65 2019-01-16 18:50:19.399700: step 7271, loss = 0.70815 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:50:20.385943 ops/training.py:65 2019-01-16 18:50:20.385842: step 7272, loss = 0.69760 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:50:21.370623 ops/training.py:65 2019-01-16 18:50:21.370521: step 7273, loss = 0.68476 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:50:22.353897 ops/training.py:65 2019-01-16 18:50:22.353798: step 7274, loss = 0.69805 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:50:23.337907 ops/training.py:65 2019-01-16 18:50:23.337805: step 7275, loss = 0.72035 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:50:24.319123 ops/training.py:65 2019-01-16 18:50:24.319016: step 7276, loss = 0.69599 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:50:25.300003 ops/training.py:65 2019-01-16 18:50:25.299894: step 7277, loss = 0.69120 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:50:26.280887 ops/training.py:65 2019-01-16 18:50:26.280793: step 7278, loss = 0.69801 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:50:27.262855 ops/training.py:65 2019-01-16 18:50:27.262748: step 7279, loss = 0.69371 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:50:28.245053 ops/training.py:65 2019-01-16 18:50:28.244937: step 7280, loss = 0.67685 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:50:29.226303 ops/training.py:65 2019-01-16 18:50:29.226199: step 7281, loss = 0.70962 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:50:30.208656 ops/training.py:65 2019-01-16 18:50:30.208572: step 7282, loss = 0.69015 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:50:31.194295 ops/training.py:65 2019-01-16 18:50:31.194192: step 7283, loss = 0.69937 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:50:32.178117 ops/training.py:65 2019-01-16 18:50:32.177993: step 7284, loss = 0.68746 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:50:33.162900 ops/training.py:65 2019-01-16 18:50:33.162798: step 7285, loss = 0.68710 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:50:34.146386 ops/training.py:65 2019-01-16 18:50:34.146286: step 7286, loss = 0.69294 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:50:35.130306 ops/training.py:65 2019-01-16 18:50:35.130208: step 7287, loss = 0.68700 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:50:36.112532 ops/training.py:65 2019-01-16 18:50:36.112428: step 7288, loss = 0.68563 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:50:37.097950 ops/training.py:65 2019-01-16 18:50:37.097848: step 7289, loss = 0.68963 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:50:38.080718 ops/training.py:65 2019-01-16 18:50:38.080608: step 7290, loss = 0.69369 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:50:39.065596 ops/training.py:65 2019-01-16 18:50:39.065513: step 7291, loss = 0.70217 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:50:40.049254 ops/training.py:65 2019-01-16 18:50:40.049144: step 7292, loss = 0.70014 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:50:41.035220 ops/training.py:65 2019-01-16 18:50:41.035112: step 7293, loss = 0.70436 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:50:42.018148 ops/training.py:65 2019-01-16 18:50:42.018047: step 7294, loss = 0.69164 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:50:43.002009 ops/training.py:65 2019-01-16 18:50:43.001822: step 7295, loss = 0.70060 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:50:43.986231 ops/training.py:65 2019-01-16 18:50:43.986125: step 7296, loss = 0.68502 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:50:44.968985 ops/training.py:65 2019-01-16 18:50:44.968882: step 7297, loss = 0.70111 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:50:45.949674 ops/training.py:65 2019-01-16 18:50:45.949533: step 7298, loss = 0.69735 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:50:46.929800 ops/training.py:65 2019-01-16 18:50:46.929730: step 7299, loss = 0.69524 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:50:47.914488 ops/training.py:65 2019-01-16 18:50:47.914399: step 7300, loss = 0.69807 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:50:48.898548 ops/training.py:65 2019-01-16 18:50:48.898447: step 7301, loss = 0.69749 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:50:49.882629 ops/training.py:65 2019-01-16 18:50:49.882529: step 7302, loss = 0.69552 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:50:50.866777 ops/training.py:65 2019-01-16 18:50:50.866670: step 7303, loss = 0.70387 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:50:51.851294 ops/training.py:65 2019-01-16 18:50:51.851215: step 7304, loss = 0.69089 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:50:52.835139 ops/training.py:65 2019-01-16 18:50:52.835038: step 7305, loss = 0.68853 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:50:53.819236 ops/training.py:65 2019-01-16 18:50:53.819149: step 7306, loss = 0.69756 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:50:54.801338 ops/training.py:65 2019-01-16 18:50:54.801206: step 7307, loss = 0.68260 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:50:55.786164 ops/training.py:65 2019-01-16 18:50:55.786064: step 7308, loss = 0.68749 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:50:56.769126 ops/training.py:65 2019-01-16 18:50:56.769039: step 7309, loss = 0.70069 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:50:57.752539 ops/training.py:65 2019-01-16 18:50:57.752467: step 7310, loss = 0.69480 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:50:58.736415 ops/training.py:65 2019-01-16 18:50:58.736310: step 7311, loss = 0.69965 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:50:59.720079 ops/training.py:65 2019-01-16 18:50:59.719935: step 7312, loss = 0.70525 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:51:00.702855 ops/training.py:65 2019-01-16 18:51:00.702747: step 7313, loss = 0.70151 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:51:01.684347 ops/training.py:65 2019-01-16 18:51:01.684247: step 7314, loss = 0.69936 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:51:02.666339 ops/training.py:65 2019-01-16 18:51:02.666232: step 7315, loss = 0.67915 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:51:03.650463 ops/training.py:65 2019-01-16 18:51:03.650363: step 7316, loss = 0.70024 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:51:04.634263 ops/training.py:65 2019-01-16 18:51:04.634163: step 7317, loss = 0.69652 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:51:05.616536 ops/training.py:65 2019-01-16 18:51:05.616433: step 7318, loss = 0.71217 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:51:06.597881 ops/training.py:65 2019-01-16 18:51:06.597781: step 7319, loss = 0.68550 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:51:07.581613 ops/training.py:65 2019-01-16 18:51:07.581510: step 7320, loss = 0.70188 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:51:08.564684 ops/training.py:65 2019-01-16 18:51:08.564587: step 7321, loss = 0.71335 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:51:09.546616 ops/training.py:65 2019-01-16 18:51:09.546482: step 7322, loss = 0.69419 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:51:10.528835 ops/training.py:65 2019-01-16 18:51:10.528728: step 7323, loss = 0.69082 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:51:11.509626 ops/training.py:65 2019-01-16 18:51:11.509555: step 7324, loss = 0.68732 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:51:12.492910 ops/training.py:65 2019-01-16 18:51:12.492837: step 7325, loss = 0.70649 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:51:13.475762 ops/training.py:65 2019-01-16 18:51:13.475666: step 7326, loss = 0.69854 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:51:14.459120 ops/training.py:65 2019-01-16 18:51:14.459013: step 7327, loss = 0.70522 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:51:15.441897 ops/training.py:65 2019-01-16 18:51:15.441786: step 7328, loss = 0.69085 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:51:16.424354 ops/training.py:65 2019-01-16 18:51:16.424255: step 7329, loss = 0.68140 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:51:17.406322 ops/training.py:65 2019-01-16 18:51:17.406214: step 7330, loss = 0.70104 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:51:18.388158 ops/training.py:65 2019-01-16 18:51:18.388063: step 7331, loss = 0.68922 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:51:19.370693 ops/training.py:65 2019-01-16 18:51:19.370581: step 7332, loss = 0.70629 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:51:20.352848 ops/training.py:65 2019-01-16 18:51:20.352742: step 7333, loss = 0.68759 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:51:21.336068 ops/training.py:65 2019-01-16 18:51:21.335956: step 7334, loss = 0.69760 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:51:22.320061 ops/training.py:65 2019-01-16 18:51:22.319950: step 7335, loss = 0.69218 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:51:23.302418 ops/training.py:65 2019-01-16 18:51:23.302318: step 7336, loss = 0.69573 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:51:24.286326 ops/training.py:65 2019-01-16 18:51:24.286217: step 7337, loss = 0.70089 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:51:25.269403 ops/training.py:65 2019-01-16 18:51:25.269295: step 7338, loss = 0.68850 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:51:26.251167 ops/training.py:65 2019-01-16 18:51:26.251090: step 7339, loss = 0.69794 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:51:27.235399 ops/training.py:65 2019-01-16 18:51:27.235327: step 7340, loss = 0.69736 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:51:28.219986 ops/training.py:65 2019-01-16 18:51:28.219868: step 7341, loss = 0.68831 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:51:29.204335 ops/training.py:65 2019-01-16 18:51:29.204232: step 7342, loss = 0.68396 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:51:30.187285 ops/training.py:65 2019-01-16 18:51:30.187177: step 7343, loss = 0.68627 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:51:31.169450 ops/training.py:65 2019-01-16 18:51:31.169334: step 7344, loss = 0.70025 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:51:32.151585 ops/training.py:65 2019-01-16 18:51:32.151479: step 7345, loss = 0.68669 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:51:33.134714 ops/training.py:65 2019-01-16 18:51:33.134616: step 7346, loss = 0.70149 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:51:34.118467 ops/training.py:65 2019-01-16 18:51:34.118356: step 7347, loss = 0.70284 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:51:35.102253 ops/training.py:65 2019-01-16 18:51:35.102155: step 7348, loss = 0.70103 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:51:36.086084 ops/training.py:65 2019-01-16 18:51:36.085976: step 7349, loss = 0.69937 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:51:37.070669 ops/training.py:65 2019-01-16 18:51:37.070569: step 7350, loss = 0.69572 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:51:38.055234 ops/training.py:65 2019-01-16 18:51:38.055126: step 7351, loss = 0.69095 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:51:39.038638 ops/training.py:65 2019-01-16 18:51:39.038532: step 7352, loss = 0.69166 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:51:40.020720 ops/training.py:65 2019-01-16 18:51:40.020612: step 7353, loss = 0.68887 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:51:41.003066 ops/training.py:65 2019-01-16 18:51:41.002960: step 7354, loss = 0.69442 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:51:41.985236 ops/training.py:65 2019-01-16 18:51:41.985100: step 7355, loss = 0.68445 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:51:42.967629 ops/training.py:65 2019-01-16 18:51:42.967519: step 7356, loss = 0.69763 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:51:43.950231 ops/training.py:65 2019-01-16 18:51:43.950114: step 7357, loss = 0.68664 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:51:44.932016 ops/training.py:65 2019-01-16 18:51:44.931901: step 7358, loss = 0.68057 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:51:45.913399 ops/training.py:65 2019-01-16 18:51:45.913286: step 7359, loss = 0.69717 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:51:46.896358 ops/training.py:65 2019-01-16 18:51:46.896248: step 7360, loss = 0.70170 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:51:47.878539 ops/training.py:65 2019-01-16 18:51:47.878428: step 7361, loss = 0.69258 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:51:48.860934 ops/training.py:65 2019-01-16 18:51:48.860826: step 7362, loss = 0.68241 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:51:49.842934 ops/training.py:65 2019-01-16 18:51:49.842822: step 7363, loss = 0.69388 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:51:50.824093 ops/training.py:65 2019-01-16 18:51:50.823992: step 7364, loss = 0.69900 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:51:51.805766 ops/training.py:65 2019-01-16 18:51:51.805656: step 7365, loss = 0.69969 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:51:52.790463 ops/training.py:65 2019-01-16 18:51:52.790349: step 7366, loss = 0.70125 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:51:53.774887 ops/training.py:65 2019-01-16 18:51:53.774775: step 7367, loss = 0.68297 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:51:54.759182 ops/training.py:65 2019-01-16 18:51:54.759089: step 7368, loss = 0.69132 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:51:55.743142 ops/training.py:65 2019-01-16 18:51:55.743034: step 7369, loss = 0.70751 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 18:51:56.726422 ops/training.py:65 2019-01-16 18:51:56.726331: step 7370, loss = 0.69852 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:51:57.710415 ops/training.py:65 2019-01-16 18:51:57.710309: step 7371, loss = 0.68620 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:51:58.692458 ops/training.py:65 2019-01-16 18:51:58.692348: step 7372, loss = 0.68798 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:51:59.675263 ops/training.py:65 2019-01-16 18:51:59.675158: step 7373, loss = 0.70498 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:52:00.657669 ops/training.py:65 2019-01-16 18:52:00.657558: step 7374, loss = 0.70134 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:52:01.640254 ops/training.py:65 2019-01-16 18:52:01.640149: step 7375, loss = 0.69175 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:52:02.623042 ops/training.py:65 2019-01-16 18:52:02.622937: step 7376, loss = 0.69452 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:52:03.606273 ops/training.py:65 2019-01-16 18:52:03.606164: step 7377, loss = 0.68711 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:52:04.590632 ops/training.py:65 2019-01-16 18:52:04.590526: step 7378, loss = 0.70258 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 18:52:05.573613 ops/training.py:65 2019-01-16 18:52:05.573511: step 7379, loss = 0.69069 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:52:06.556262 ops/training.py:65 2019-01-16 18:52:06.556161: step 7380, loss = 0.69136 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:52:07.540525 ops/training.py:65 2019-01-16 18:52:07.540420: step 7381, loss = 0.68259 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:52:08.522141 ops/training.py:65 2019-01-16 18:52:08.522057: step 7382, loss = 0.69403 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:52:09.501506 ops/training.py:65 2019-01-16 18:52:09.501429: step 7383, loss = 0.69814 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:52:10.480936 ops/training.py:65 2019-01-16 18:52:10.480862: step 7384, loss = 0.69657 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:52:11.464113 ops/training.py:65 2019-01-16 18:52:11.464034: step 7385, loss = 0.69423 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:52:12.447061 ops/training.py:65 2019-01-16 18:52:12.446959: step 7386, loss = 0.68725 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:52:13.429567 ops/training.py:65 2019-01-16 18:52:13.429469: step 7387, loss = 0.70012 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:52:14.410535 ops/training.py:65 2019-01-16 18:52:14.410430: step 7388, loss = 0.69430 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:52:15.392713 ops/training.py:65 2019-01-16 18:52:15.392604: step 7389, loss = 0.69144 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:52:16.374735 ops/training.py:65 2019-01-16 18:52:16.374628: step 7390, loss = 0.69582 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:52:17.357117 ops/training.py:65 2019-01-16 18:52:17.357017: step 7391, loss = 0.69793 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:52:18.341262 ops/training.py:65 2019-01-16 18:52:18.341156: step 7392, loss = 0.70093 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:52:19.325370 ops/training.py:65 2019-01-16 18:52:19.325265: step 7393, loss = 0.69924 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:52:20.307777 ops/training.py:65 2019-01-16 18:52:20.307679: step 7394, loss = 0.69613 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:52:21.290293 ops/training.py:65 2019-01-16 18:52:21.290197: step 7395, loss = 0.68996 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:52:22.272887 ops/training.py:65 2019-01-16 18:52:22.272794: step 7396, loss = 0.69290 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:52:23.254440 ops/training.py:65 2019-01-16 18:52:23.254342: step 7397, loss = 0.69192 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:52:24.235986 ops/training.py:65 2019-01-16 18:52:24.235884: step 7398, loss = 0.68541 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:52:25.217704 ops/training.py:65 2019-01-16 18:52:25.217600: step 7399, loss = 0.69230 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:52:26.199622 ops/training.py:65 2019-01-16 18:52:26.199479: step 7400, loss = 0.68752 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:52:27.182930 ops/training.py:65 2019-01-16 18:52:27.182836: step 7401, loss = 0.69652 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:52:28.163285 ops/training.py:65 2019-01-16 18:52:28.163194: step 7402, loss = 0.70013 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:52:29.143746 ops/training.py:65 2019-01-16 18:52:29.143643: step 7403, loss = 0.69579 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:52:30.123614 ops/training.py:65 2019-01-16 18:52:30.123534: step 7404, loss = 0.69299 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:52:31.106882 ops/training.py:65 2019-01-16 18:52:31.106810: step 7405, loss = 0.69732 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:52:32.091550 ops/training.py:65 2019-01-16 18:52:32.091458: step 7406, loss = 0.69760 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:52:33.077016 ops/training.py:65 2019-01-16 18:52:33.076917: step 7407, loss = 0.68252 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:52:34.061739 ops/training.py:65 2019-01-16 18:52:34.061634: step 7408, loss = 0.68934 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:52:35.046104 ops/training.py:65 2019-01-16 18:52:35.046001: step 7409, loss = 0.68371 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:52:36.028805 ops/training.py:65 2019-01-16 18:52:36.028700: step 7410, loss = 0.69320 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:52:37.010654 ops/training.py:65 2019-01-16 18:52:37.010555: step 7411, loss = 0.69693 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:52:37.991133 ops/training.py:65 2019-01-16 18:52:37.991033: step 7412, loss = 0.69601 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:52:38.974943 ops/training.py:65 2019-01-16 18:52:38.974844: step 7413, loss = 0.70081 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:52:39.958216 ops/training.py:65 2019-01-16 18:52:39.958114: step 7414, loss = 0.69355 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:52:40.940892 ops/training.py:65 2019-01-16 18:52:40.940796: step 7415, loss = 0.68751 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:52:41.924519 ops/training.py:65 2019-01-16 18:52:41.924426: step 7416, loss = 0.69342 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:52:42.909504 ops/training.py:65 2019-01-16 18:52:42.909400: step 7417, loss = 0.69662 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:52:43.892965 ops/training.py:65 2019-01-16 18:52:43.892869: step 7418, loss = 0.68961 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:52:44.873327 ops/training.py:65 2019-01-16 18:52:44.873228: step 7419, loss = 0.69699 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:52:45.858472 ops/training.py:65 2019-01-16 18:52:45.858380: step 7420, loss = 0.69760 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:52:46.842479 ops/training.py:65 2019-01-16 18:52:46.842383: step 7421, loss = 0.70534 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:52:47.826941 ops/training.py:65 2019-01-16 18:52:47.826839: step 7422, loss = 0.68929 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:52:48.811585 ops/training.py:65 2019-01-16 18:52:48.811484: step 7423, loss = 0.69012 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:52:49.792164 ops/training.py:65 2019-01-16 18:52:49.792081: step 7424, loss = 0.68815 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:52:50.772740 ops/training.py:65 2019-01-16 18:52:50.772681: step 7425, loss = 0.69514 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:52:51.756435 ops/training.py:65 2019-01-16 18:52:51.756343: step 7426, loss = 0.68531 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:52:52.740155 ops/training.py:65 2019-01-16 18:52:52.740050: step 7427, loss = 0.68584 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:52:53.723035 ops/training.py:65 2019-01-16 18:52:53.722943: step 7428, loss = 0.69366 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:52:54.705692 ops/training.py:65 2019-01-16 18:52:54.705622: step 7429, loss = 0.69998 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:52:55.687125 ops/training.py:65 2019-01-16 18:52:55.687060: step 7430, loss = 0.69371 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:52:56.670211 ops/training.py:65 2019-01-16 18:52:56.670133: step 7431, loss = 0.68748 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:52:57.653983 ops/training.py:65 2019-01-16 18:52:57.653875: step 7432, loss = 0.69857 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:52:58.637903 ops/training.py:65 2019-01-16 18:52:58.637804: step 7433, loss = 0.68922 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:52:59.619907 ops/training.py:65 2019-01-16 18:52:59.619803: step 7434, loss = 0.69423 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:53:00.602753 ops/training.py:65 2019-01-16 18:53:00.602617: step 7435, loss = 0.68638 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:53:01.585239 ops/training.py:65 2019-01-16 18:53:01.585111: step 7436, loss = 0.69754 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:53:02.568637 ops/training.py:65 2019-01-16 18:53:02.568535: step 7437, loss = 0.70441 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:53:03.551956 ops/training.py:65 2019-01-16 18:53:03.551858: step 7438, loss = 0.69165 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:53:04.535410 ops/training.py:65 2019-01-16 18:53:04.535322: step 7439, loss = 0.70624 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 18:53:05.519454 ops/training.py:65 2019-01-16 18:53:05.519355: step 7440, loss = 0.68318 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:53:06.503476 ops/training.py:65 2019-01-16 18:53:06.503367: step 7441, loss = 0.68694 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:53:07.487068 ops/training.py:65 2019-01-16 18:53:07.486972: step 7442, loss = 0.69042 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:53:08.470622 ops/training.py:65 2019-01-16 18:53:08.470530: step 7443, loss = 0.69867 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:53:09.454204 ops/training.py:65 2019-01-16 18:53:09.454104: step 7444, loss = 0.70658 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:53:10.438277 ops/training.py:65 2019-01-16 18:53:10.438179: step 7445, loss = 0.69919 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:53:11.422886 ops/training.py:65 2019-01-16 18:53:11.422792: step 7446, loss = 0.70105 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:53:12.407542 ops/training.py:65 2019-01-16 18:53:12.407452: step 7447, loss = 0.69998 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:53:13.389725 ops/training.py:65 2019-01-16 18:53:13.389638: step 7448, loss = 0.68687 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:53:14.372208 ops/training.py:65 2019-01-16 18:53:14.372112: step 7449, loss = 0.69031 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:53:15.353338 ops/training.py:65 2019-01-16 18:53:15.353239: step 7450, loss = 0.69157 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:53:16.332748 ops/training.py:65 2019-01-16 18:53:16.332683: step 7451, loss = 0.70037 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:53:17.312119 ops/training.py:65 2019-01-16 18:53:17.312054: step 7452, loss = 0.68981 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:53:18.296403 ops/training.py:65 2019-01-16 18:53:18.296332: step 7453, loss = 0.68959 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:53:19.280597 ops/training.py:65 2019-01-16 18:53:19.280489: step 7454, loss = 0.68841 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:53:20.264908 ops/training.py:65 2019-01-16 18:53:20.264808: step 7455, loss = 0.69100 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:53:21.248274 ops/training.py:65 2019-01-16 18:53:21.248172: step 7456, loss = 0.70469 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:53:22.231048 ops/training.py:65 2019-01-16 18:53:22.230948: step 7457, loss = 0.69464 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:53:23.213592 ops/training.py:65 2019-01-16 18:53:23.213497: step 7458, loss = 0.69923 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:53:24.196020 ops/training.py:65 2019-01-16 18:53:24.195926: step 7459, loss = 0.68734 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:53:25.178293 ops/training.py:65 2019-01-16 18:53:25.178197: step 7460, loss = 0.68798 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:53:26.161914 ops/training.py:65 2019-01-16 18:53:26.161815: step 7461, loss = 0.70105 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:53:27.142934 ops/training.py:65 2019-01-16 18:53:27.142865: step 7462, loss = 0.69826 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:53:28.126036 ops/training.py:65 2019-01-16 18:53:28.125966: step 7463, loss = 0.69459 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:53:29.109584 ops/training.py:65 2019-01-16 18:53:29.109448: step 7464, loss = 0.69673 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:53:30.093003 ops/training.py:65 2019-01-16 18:53:30.092909: step 7465, loss = 0.68787 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:53:31.075896 ops/training.py:65 2019-01-16 18:53:31.075789: step 7466, loss = 0.69151 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:53:32.057739 ops/training.py:65 2019-01-16 18:53:32.057651: step 7467, loss = 0.68888 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:53:33.040891 ops/training.py:65 2019-01-16 18:53:33.040789: step 7468, loss = 0.69182 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:53:34.024156 ops/training.py:65 2019-01-16 18:53:34.024017: step 7469, loss = 0.69457 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:53:35.008251 ops/training.py:65 2019-01-16 18:53:35.008156: step 7470, loss = 0.69066 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:53:35.990599 ops/training.py:65 2019-01-16 18:53:35.990500: step 7471, loss = 0.69363 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:53:36.975947 ops/training.py:65 2019-01-16 18:53:36.975848: step 7472, loss = 0.69116 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:53:37.960980 ops/training.py:65 2019-01-16 18:53:37.960873: step 7473, loss = 0.69045 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:53:38.941326 ops/training.py:65 2019-01-16 18:53:38.941241: step 7474, loss = 0.68834 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:53:39.924662 ops/training.py:65 2019-01-16 18:53:39.924603: step 7475, loss = 0.69153 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:53:40.908049 ops/training.py:65 2019-01-16 18:53:40.907950: step 7476, loss = 0.69685 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:53:41.892287 ops/training.py:65 2019-01-16 18:53:41.892191: step 7477, loss = 0.69176 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:53:42.875473 ops/training.py:65 2019-01-16 18:53:42.875368: step 7478, loss = 0.69822 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:53:43.856493 ops/training.py:65 2019-01-16 18:53:43.856392: step 7479, loss = 0.69368 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:53:44.835404 ops/training.py:65 2019-01-16 18:53:44.835334: step 7480, loss = 0.69282 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:53:45.814983 ops/training.py:65 2019-01-16 18:53:45.814918: step 7481, loss = 0.69050 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:53:46.793695 ops/training.py:65 2019-01-16 18:53:46.793630: step 7482, loss = 0.68821 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:53:47.773852 ops/training.py:65 2019-01-16 18:53:47.773788: step 7483, loss = 0.68618 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:53:48.753802 ops/training.py:65 2019-01-16 18:53:48.753740: step 7484, loss = 0.69993 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:53:49.737642 ops/training.py:65 2019-01-16 18:53:49.737573: step 7485, loss = 0.69025 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:53:50.721003 ops/training.py:65 2019-01-16 18:53:50.720902: step 7486, loss = 0.69845 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:53:51.704739 ops/training.py:65 2019-01-16 18:53:51.704634: step 7487, loss = 0.70515 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:53:52.687309 ops/training.py:65 2019-01-16 18:53:52.687194: step 7488, loss = 0.69951 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:53:53.669916 ops/training.py:65 2019-01-16 18:53:53.669818: step 7489, loss = 0.69965 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:53:54.652148 ops/training.py:65 2019-01-16 18:53:54.652044: step 7490, loss = 0.70240 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:53:55.637610 ops/training.py:65 2019-01-16 18:53:55.637512: step 7491, loss = 0.68308 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:53:56.623473 ops/training.py:65 2019-01-16 18:53:56.623378: step 7492, loss = 0.68992 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:53:57.607942 ops/training.py:65 2019-01-16 18:53:57.607830: step 7493, loss = 0.67725 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:53:58.591739 ops/training.py:65 2019-01-16 18:53:58.591634: step 7494, loss = 0.69546 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:53:59.574124 ops/training.py:65 2019-01-16 18:53:59.574014: step 7495, loss = 0.68246 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:54:00.557356 ops/training.py:65 2019-01-16 18:54:00.557252: step 7496, loss = 0.69807 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:54:01.539542 ops/training.py:65 2019-01-16 18:54:01.539446: step 7497, loss = 0.67352 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:54:02.520805 ops/training.py:65 2019-01-16 18:54:02.520707: step 7498, loss = 0.70743 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:54:03.506009 ops/training.py:65 2019-01-16 18:54:03.505915: step 7499, loss = 0.70951 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:54:04.489651 ops/training.py:65 2019-01-16 18:54:04.489552: step 7500, loss = 0.70724 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:54:05.470682 ops/training.py:65 2019-01-16 18:54:05.470582: step 7501, loss = 0.68073 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:54:06.453467 ops/training.py:65 2019-01-16 18:54:06.453395: step 7502, loss = 0.72195 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:54:07.436740 ops/training.py:65 2019-01-16 18:54:07.436641: step 7503, loss = 0.69309 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:54:08.420245 ops/training.py:65 2019-01-16 18:54:08.420151: step 7504, loss = 0.70865 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:54:09.401590 ops/training.py:65 2019-01-16 18:54:09.401497: step 7505, loss = 0.67706 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:54:10.383319 ops/training.py:65 2019-01-16 18:54:10.383223: step 7506, loss = 0.68489 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:54:11.365594 ops/training.py:65 2019-01-16 18:54:11.365493: step 7507, loss = 0.73303 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:54:12.346745 ops/training.py:65 2019-01-16 18:54:12.346651: step 7508, loss = 0.67359 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:54:13.328765 ops/training.py:65 2019-01-16 18:54:13.328673: step 7509, loss = 0.71945 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:54:14.312037 ops/training.py:65 2019-01-16 18:54:14.311932: step 7510, loss = 0.69573 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:54:15.294424 ops/training.py:65 2019-01-16 18:54:15.294314: step 7511, loss = 0.70289 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:54:16.276838 ops/training.py:65 2019-01-16 18:54:16.276733: step 7512, loss = 0.68411 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:54:17.258552 ops/training.py:65 2019-01-16 18:54:17.258408: step 7513, loss = 0.75282 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.25
I8192 2019-01-16 18:54:18.240263 ops/training.py:65 2019-01-16 18:54:18.240165: step 7514, loss = 0.68611 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:54:19.222705 ops/training.py:65 2019-01-16 18:54:19.222599: step 7515, loss = 0.71741 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:54:20.204755 ops/training.py:65 2019-01-16 18:54:20.204654: step 7516, loss = 0.71548 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:54:21.188303 ops/training.py:65 2019-01-16 18:54:21.188204: step 7517, loss = 0.68579 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:54:22.170923 ops/training.py:65 2019-01-16 18:54:22.170826: step 7518, loss = 0.71627 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:54:23.157760 ops/training.py:65 2019-01-16 18:54:23.157665: step 7519, loss = 0.71479 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:54:24.142140 ops/training.py:65 2019-01-16 18:54:24.142040: step 7520, loss = 0.66330 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:54:25.126989 ops/training.py:65 2019-01-16 18:54:25.126890: step 7521, loss = 0.70181 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:54:26.109320 ops/training.py:65 2019-01-16 18:54:26.109216: step 7522, loss = 0.71686 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:54:27.090894 ops/training.py:65 2019-01-16 18:54:27.090809: step 7523, loss = 0.69827 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:54:28.074305 ops/training.py:65 2019-01-16 18:54:28.074230: step 7524, loss = 0.70437 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:54:29.059179 ops/training.py:65 2019-01-16 18:54:29.059087: step 7525, loss = 0.72172 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:54:30.041665 ops/training.py:65 2019-01-16 18:54:30.041566: step 7526, loss = 0.68086 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:54:31.023263 ops/training.py:65 2019-01-16 18:54:31.023162: step 7527, loss = 0.70236 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:54:32.005057 ops/training.py:65 2019-01-16 18:54:32.004950: step 7528, loss = 0.69380 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:54:32.989497 ops/training.py:65 2019-01-16 18:54:32.989392: step 7529, loss = 0.69324 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:54:33.970307 ops/training.py:65 2019-01-16 18:54:33.970210: step 7530, loss = 0.69362 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:54:34.952059 ops/training.py:65 2019-01-16 18:54:34.951958: step 7531, loss = 0.68252 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:54:35.935341 ops/training.py:65 2019-01-16 18:54:35.935266: step 7532, loss = 0.69535 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:54:36.920210 ops/training.py:65 2019-01-16 18:54:36.920120: step 7533, loss = 0.68653 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:54:37.903193 ops/training.py:65 2019-01-16 18:54:37.903097: step 7534, loss = 0.70108 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:54:38.885891 ops/training.py:65 2019-01-16 18:54:38.885796: step 7535, loss = 0.68780 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:54:39.868121 ops/training.py:65 2019-01-16 18:54:39.868025: step 7536, loss = 0.68009 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:54:40.850242 ops/training.py:65 2019-01-16 18:54:40.850139: step 7537, loss = 0.70752 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:54:41.832261 ops/training.py:65 2019-01-16 18:54:41.832177: step 7538, loss = 0.69358 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:54:42.814944 ops/training.py:65 2019-01-16 18:54:42.814843: step 7539, loss = 0.68312 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:54:43.798322 ops/training.py:65 2019-01-16 18:54:43.798224: step 7540, loss = 0.68209 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:54:44.781082 ops/training.py:65 2019-01-16 18:54:44.780982: step 7541, loss = 0.68609 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:54:45.761242 ops/training.py:65 2019-01-16 18:54:45.761141: step 7542, loss = 0.71529 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:54:46.745765 ops/training.py:65 2019-01-16 18:54:46.745678: step 7543, loss = 0.68902 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:54:47.729803 ops/training.py:65 2019-01-16 18:54:47.729690: step 7544, loss = 0.68732 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:54:48.712991 ops/training.py:65 2019-01-16 18:54:48.712894: step 7545, loss = 0.68591 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:54:49.695390 ops/training.py:65 2019-01-16 18:54:49.695281: step 7546, loss = 0.69854 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:54:50.677726 ops/training.py:65 2019-01-16 18:54:50.677624: step 7547, loss = 0.68409 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:54:51.661730 ops/training.py:65 2019-01-16 18:54:51.661626: step 7548, loss = 0.69996 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:54:52.644059 ops/training.py:65 2019-01-16 18:54:52.643957: step 7549, loss = 0.69701 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:54:53.628899 ops/training.py:65 2019-01-16 18:54:53.628801: step 7550, loss = 0.67987 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:54:54.613129 ops/training.py:65 2019-01-16 18:54:54.613025: step 7551, loss = 0.69915 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:54:55.595942 ops/training.py:65 2019-01-16 18:54:55.595825: step 7552, loss = 0.68482 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:54:56.578687 ops/training.py:65 2019-01-16 18:54:56.578587: step 7553, loss = 0.69946 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:54:57.560588 ops/training.py:65 2019-01-16 18:54:57.560505: step 7554, loss = 0.69438 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:54:58.542554 ops/training.py:65 2019-01-16 18:54:58.542495: step 7555, loss = 0.69918 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:54:59.524034 ops/training.py:65 2019-01-16 18:54:59.523936: step 7556, loss = 0.68645 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:55:00.504336 ops/training.py:65 2019-01-16 18:55:00.504250: step 7557, loss = 0.68573 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:55:01.487421 ops/training.py:65 2019-01-16 18:55:01.487381: step 7558, loss = 0.69628 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:55:02.470000 ops/training.py:65 2019-01-16 18:55:02.469919: step 7559, loss = 0.69226 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:55:03.454295 ops/training.py:65 2019-01-16 18:55:03.454245: step 7560, loss = 0.68255 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:55:04.437328 ops/training.py:65 2019-01-16 18:55:04.437271: step 7561, loss = 0.70323 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:55:05.419718 ops/training.py:65 2019-01-16 18:55:05.419663: step 7562, loss = 0.71064 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:55:06.401808 ops/training.py:65 2019-01-16 18:55:06.401758: step 7563, loss = 0.69186 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:55:07.385242 ops/training.py:65 2019-01-16 18:55:07.385139: step 7564, loss = 0.70026 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:55:08.369294 ops/training.py:65 2019-01-16 18:55:08.369233: step 7565, loss = 0.68366 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:55:09.352352 ops/training.py:65 2019-01-16 18:55:09.352268: step 7566, loss = 0.69660 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:55:10.336026 ops/training.py:65 2019-01-16 18:55:10.335985: step 7567, loss = 0.70841 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:55:11.318857 ops/training.py:65 2019-01-16 18:55:11.318827: step 7568, loss = 0.69327 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:55:12.300819 ops/training.py:65 2019-01-16 18:55:12.300786: step 7569, loss = 0.68442 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:55:13.281797 ops/training.py:65 2019-01-16 18:55:13.281704: step 7570, loss = 0.69132 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:55:14.263078 ops/training.py:65 2019-01-16 18:55:14.262974: step 7571, loss = 0.69136 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:55:15.243650 ops/training.py:65 2019-01-16 18:55:15.243569: step 7572, loss = 0.69490 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:55:16.229143 ops/training.py:65 2019-01-16 18:55:16.229101: step 7573, loss = 0.70382 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:55:17.213058 ops/training.py:65 2019-01-16 18:55:17.212988: step 7574, loss = 0.68596 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:55:18.195411 ops/training.py:65 2019-01-16 18:55:18.195349: step 7575, loss = 0.69154 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:55:19.177244 ops/training.py:65 2019-01-16 18:55:19.177207: step 7576, loss = 0.70597 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:55:20.158707 ops/training.py:65 2019-01-16 18:55:20.158657: step 7577, loss = 0.68981 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:55:21.139990 ops/training.py:65 2019-01-16 18:55:21.139948: step 7578, loss = 0.68989 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:55:22.121394 ops/training.py:65 2019-01-16 18:55:22.121346: step 7579, loss = 0.69025 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:55:23.102200 ops/training.py:65 2019-01-16 18:55:23.102142: step 7580, loss = 0.69100 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:55:24.083578 ops/training.py:65 2019-01-16 18:55:24.083531: step 7581, loss = 0.68516 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:55:25.066312 ops/training.py:65 2019-01-16 18:55:25.066211: step 7582, loss = 0.68927 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:55:26.049246 ops/training.py:65 2019-01-16 18:55:26.049140: step 7583, loss = 0.68035 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:55:27.034089 ops/training.py:65 2019-01-16 18:55:27.033979: step 7584, loss = 0.69944 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:55:28.018638 ops/training.py:65 2019-01-16 18:55:28.018527: step 7585, loss = 0.68669 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:55:29.002101 ops/training.py:65 2019-01-16 18:55:29.001993: step 7586, loss = 0.69471 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:55:29.987269 ops/training.py:65 2019-01-16 18:55:29.987123: step 7587, loss = 0.69534 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:55:30.972906 ops/training.py:65 2019-01-16 18:55:30.972801: step 7588, loss = 0.69510 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:55:31.957626 ops/training.py:65 2019-01-16 18:55:31.957522: step 7589, loss = 0.69458 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:55:32.941492 ops/training.py:65 2019-01-16 18:55:32.941383: step 7590, loss = 0.69236 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:55:33.925680 ops/training.py:65 2019-01-16 18:55:33.925580: step 7591, loss = 0.69073 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:55:34.909909 ops/training.py:65 2019-01-16 18:55:34.909795: step 7592, loss = 0.69300 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:55:35.891724 ops/training.py:65 2019-01-16 18:55:35.891614: step 7593, loss = 0.68096 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:55:36.873604 ops/training.py:65 2019-01-16 18:55:36.873502: step 7594, loss = 0.69365 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:55:37.856465 ops/training.py:65 2019-01-16 18:55:37.856354: step 7595, loss = 0.69321 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:55:38.838187 ops/training.py:65 2019-01-16 18:55:38.838087: step 7596, loss = 0.68625 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:55:39.821799 ops/training.py:65 2019-01-16 18:55:39.821706: step 7597, loss = 0.69064 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:55:40.803430 ops/training.py:65 2019-01-16 18:55:40.803329: step 7598, loss = 0.69412 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:55:41.786759 ops/training.py:65 2019-01-16 18:55:41.786667: step 7599, loss = 0.68663 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:55:42.770705 ops/training.py:65 2019-01-16 18:55:42.770590: step 7600, loss = 0.68623 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:55:43.754647 ops/training.py:65 2019-01-16 18:55:43.754541: step 7601, loss = 0.68758 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:55:44.738146 ops/training.py:65 2019-01-16 18:55:44.738049: step 7602, loss = 0.69091 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:55:45.721799 ops/training.py:65 2019-01-16 18:55:45.721688: step 7603, loss = 0.68428 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:55:46.704262 ops/training.py:65 2019-01-16 18:55:46.704158: step 7604, loss = 0.68250 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:55:47.688161 ops/training.py:65 2019-01-16 18:55:47.688053: step 7605, loss = 0.69681 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:55:48.670442 ops/training.py:65 2019-01-16 18:55:48.670347: step 7606, loss = 0.68669 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:55:49.653400 ops/training.py:65 2019-01-16 18:55:49.653298: step 7607, loss = 0.69113 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:55:50.636332 ops/training.py:65 2019-01-16 18:55:50.636229: step 7608, loss = 0.70650 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:55:51.620057 ops/training.py:65 2019-01-16 18:55:51.619944: step 7609, loss = 0.69195 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:55:52.602636 ops/training.py:65 2019-01-16 18:55:52.602527: step 7610, loss = 0.69368 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:55:53.585100 ops/training.py:65 2019-01-16 18:55:53.584999: step 7611, loss = 0.70968 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:55:54.567884 ops/training.py:65 2019-01-16 18:55:54.567785: step 7612, loss = 0.70767 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:55:55.550211 ops/training.py:65 2019-01-16 18:55:55.550105: step 7613, loss = 0.68052 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:55:56.532321 ops/training.py:65 2019-01-16 18:55:56.532232: step 7614, loss = 0.67675 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:55:57.515009 ops/training.py:65 2019-01-16 18:55:57.514902: step 7615, loss = 0.70846 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:55:58.498375 ops/training.py:65 2019-01-16 18:55:58.498271: step 7616, loss = 0.71508 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:55:59.481137 ops/training.py:65 2019-01-16 18:55:59.481034: step 7617, loss = 0.71287 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:56:00.466594 ops/training.py:65 2019-01-16 18:56:00.466494: step 7618, loss = 0.71003 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:56:01.451024 ops/training.py:65 2019-01-16 18:56:01.450931: step 7619, loss = 0.69067 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:56:02.436584 ops/training.py:65 2019-01-16 18:56:02.436482: step 7620, loss = 0.69423 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:56:03.420453 ops/training.py:65 2019-01-16 18:56:03.420356: step 7621, loss = 0.69572 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:56:04.403934 ops/training.py:65 2019-01-16 18:56:04.403834: step 7622, loss = 0.71038 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:56:05.386970 ops/training.py:65 2019-01-16 18:56:05.386864: step 7623, loss = 0.71635 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:56:06.369227 ops/training.py:65 2019-01-16 18:56:06.369126: step 7624, loss = 0.70215 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:56:07.351411 ops/training.py:65 2019-01-16 18:56:07.351308: step 7625, loss = 0.71637 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:56:08.334876 ops/training.py:65 2019-01-16 18:56:08.334770: step 7626, loss = 0.71901 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:56:09.317453 ops/training.py:65 2019-01-16 18:56:09.317350: step 7627, loss = 0.71420 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:56:10.301604 ops/training.py:65 2019-01-16 18:56:10.301498: step 7628, loss = 0.67361 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:56:11.286427 ops/training.py:65 2019-01-16 18:56:11.286329: step 7629, loss = 0.68344 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:56:12.270874 ops/training.py:65 2019-01-16 18:56:12.270785: step 7630, loss = 0.70415 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:56:13.255130 ops/training.py:65 2019-01-16 18:56:13.255029: step 7631, loss = 0.72555 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:56:14.237348 ops/training.py:65 2019-01-16 18:56:14.237246: step 7632, loss = 0.69595 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:56:15.220104 ops/training.py:65 2019-01-16 18:56:15.220020: step 7633, loss = 0.72714 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:56:16.203086 ops/training.py:65 2019-01-16 18:56:16.202996: step 7634, loss = 0.66686 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:56:17.186105 ops/training.py:65 2019-01-16 18:56:17.186005: step 7635, loss = 0.68147 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:56:18.168305 ops/training.py:65 2019-01-16 18:56:18.168203: step 7636, loss = 0.70687 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:56:19.151179 ops/training.py:65 2019-01-16 18:56:19.151073: step 7637, loss = 0.70902 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:56:20.133828 ops/training.py:65 2019-01-16 18:56:20.133719: step 7638, loss = 0.68479 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:56:21.117032 ops/training.py:65 2019-01-16 18:56:21.116925: step 7639, loss = 0.69226 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:56:22.101325 ops/training.py:65 2019-01-16 18:56:22.101220: step 7640, loss = 0.69541 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:56:23.085432 ops/training.py:65 2019-01-16 18:56:23.085334: step 7641, loss = 0.69204 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:56:24.068478 ops/training.py:65 2019-01-16 18:56:24.068369: step 7642, loss = 0.68677 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:56:25.050728 ops/training.py:65 2019-01-16 18:56:25.050627: step 7643, loss = 0.68885 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:56:26.033168 ops/training.py:65 2019-01-16 18:56:26.033068: step 7644, loss = 0.68587 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:56:27.015881 ops/training.py:65 2019-01-16 18:56:27.015797: step 7645, loss = 0.68920 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:56:27.998907 ops/training.py:65 2019-01-16 18:56:27.998803: step 7646, loss = 0.69459 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:56:28.981920 ops/training.py:65 2019-01-16 18:56:28.981809: step 7647, loss = 0.70861 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:56:29.964489 ops/training.py:65 2019-01-16 18:56:29.964400: step 7648, loss = 0.68803 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:56:30.946739 ops/training.py:65 2019-01-16 18:56:30.946655: step 7649, loss = 0.69217 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:56:31.930660 ops/training.py:65 2019-01-16 18:56:31.930561: step 7650, loss = 0.69058 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:56:32.914797 ops/training.py:65 2019-01-16 18:56:32.914693: step 7651, loss = 0.68943 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:56:33.898184 ops/training.py:65 2019-01-16 18:56:33.898085: step 7652, loss = 0.69360 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:56:34.881764 ops/training.py:65 2019-01-16 18:56:34.881668: step 7653, loss = 0.69766 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:56:35.864949 ops/training.py:65 2019-01-16 18:56:35.864863: step 7654, loss = 0.68905 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:56:36.847118 ops/training.py:65 2019-01-16 18:56:36.846986: step 7655, loss = 0.69757 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:56:37.830485 ops/training.py:65 2019-01-16 18:56:37.830372: step 7656, loss = 0.70692 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:56:38.812948 ops/training.py:65 2019-01-16 18:56:38.812844: step 7657, loss = 0.68543 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:56:39.797965 ops/training.py:65 2019-01-16 18:56:39.797858: step 7658, loss = 0.68485 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:56:40.780882 ops/training.py:65 2019-01-16 18:56:40.780793: step 7659, loss = 0.69466 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:56:41.764896 ops/training.py:65 2019-01-16 18:56:41.764812: step 7660, loss = 0.70320 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:56:42.748536 ops/training.py:65 2019-01-16 18:56:42.748432: step 7661, loss = 0.68718 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:56:43.731265 ops/training.py:65 2019-01-16 18:56:43.731167: step 7662, loss = 0.70585 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:56:44.714219 ops/training.py:65 2019-01-16 18:56:44.714131: step 7663, loss = 0.68630 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:56:45.698776 ops/training.py:65 2019-01-16 18:56:45.698676: step 7664, loss = 0.69061 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:56:46.683746 ops/training.py:65 2019-01-16 18:56:46.683648: step 7665, loss = 0.69093 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:56:47.664702 ops/training.py:65 2019-01-16 18:56:47.664626: step 7666, loss = 0.68955 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:56:48.644645 ops/training.py:65 2019-01-16 18:56:48.644572: step 7667, loss = 0.68134 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:56:49.629867 ops/training.py:65 2019-01-16 18:56:49.629791: step 7668, loss = 0.69872 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:56:50.614377 ops/training.py:65 2019-01-16 18:56:50.614269: step 7669, loss = 0.70201 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:56:51.599314 ops/training.py:65 2019-01-16 18:56:51.599209: step 7670, loss = 0.69147 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:56:52.584172 ops/training.py:65 2019-01-16 18:56:52.584071: step 7671, loss = 0.71556 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:56:53.568203 ops/training.py:65 2019-01-16 18:56:53.568099: step 7672, loss = 0.68725 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:56:54.550990 ops/training.py:65 2019-01-16 18:56:54.550876: step 7673, loss = 0.69488 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:56:55.533194 ops/training.py:65 2019-01-16 18:56:55.533088: step 7674, loss = 0.67802 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:56:56.515225 ops/training.py:65 2019-01-16 18:56:56.515121: step 7675, loss = 0.69432 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:56:57.496888 ops/training.py:65 2019-01-16 18:56:57.496793: step 7676, loss = 0.71655 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:56:58.478499 ops/training.py:65 2019-01-16 18:56:58.478398: step 7677, loss = 0.67349 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:56:59.461762 ops/training.py:65 2019-01-16 18:56:59.461664: step 7678, loss = 0.71460 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:57:00.444261 ops/training.py:65 2019-01-16 18:57:00.444165: step 7679, loss = 0.68523 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:57:01.425727 ops/training.py:65 2019-01-16 18:57:01.425661: step 7680, loss = 0.67689 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:57:02.409309 ops/training.py:65 2019-01-16 18:57:02.409233: step 7681, loss = 0.71343 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:57:03.395255 ops/training.py:65 2019-01-16 18:57:03.395155: step 7682, loss = 0.70146 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:57:04.378815 ops/training.py:65 2019-01-16 18:57:04.378710: step 7683, loss = 0.69559 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:57:05.360338 ops/training.py:65 2019-01-16 18:57:05.360210: step 7684, loss = 0.69712 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:57:06.341930 ops/training.py:65 2019-01-16 18:57:06.341833: step 7685, loss = 0.69660 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:57:07.323521 ops/training.py:65 2019-01-16 18:57:07.323416: step 7686, loss = 0.70681 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:57:08.306136 ops/training.py:65 2019-01-16 18:57:08.306030: step 7687, loss = 0.68880 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:57:09.289122 ops/training.py:65 2019-01-16 18:57:09.288985: step 7688, loss = 0.67605 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:57:10.271262 ops/training.py:65 2019-01-16 18:57:10.271161: step 7689, loss = 0.69820 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:57:11.253206 ops/training.py:65 2019-01-16 18:57:11.253111: step 7690, loss = 0.66992 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 18:57:12.236178 ops/training.py:65 2019-01-16 18:57:12.236090: step 7691, loss = 0.69789 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:57:13.218899 ops/training.py:65 2019-01-16 18:57:13.218796: step 7692, loss = 0.69214 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:57:14.201220 ops/training.py:65 2019-01-16 18:57:14.201121: step 7693, loss = 0.68618 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:57:15.183836 ops/training.py:65 2019-01-16 18:57:15.183729: step 7694, loss = 0.69821 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:57:16.165676 ops/training.py:65 2019-01-16 18:57:16.165572: step 7695, loss = 0.70682 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:57:17.147762 ops/training.py:65 2019-01-16 18:57:17.147662: step 7696, loss = 0.68952 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:57:18.131467 ops/training.py:65 2019-01-16 18:57:18.131367: step 7697, loss = 0.68917 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:57:19.113565 ops/training.py:65 2019-01-16 18:57:19.113458: step 7698, loss = 0.69667 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:57:20.095134 ops/training.py:65 2019-01-16 18:57:20.095025: step 7699, loss = 0.70464 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:57:21.077318 ops/training.py:65 2019-01-16 18:57:21.077182: step 7700, loss = 0.69659 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:57:22.059032 ops/training.py:65 2019-01-16 18:57:22.058935: step 7701, loss = 0.68381 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:57:23.042071 ops/training.py:65 2019-01-16 18:57:23.041970: step 7702, loss = 0.69872 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:57:24.025061 ops/training.py:65 2019-01-16 18:57:24.024956: step 7703, loss = 0.69777 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:57:25.006729 ops/training.py:65 2019-01-16 18:57:25.006631: step 7704, loss = 0.69710 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:57:25.988796 ops/training.py:65 2019-01-16 18:57:25.988694: step 7705, loss = 0.68777 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:57:26.971303 ops/training.py:65 2019-01-16 18:57:26.971202: step 7706, loss = 0.68831 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:57:27.954300 ops/training.py:65 2019-01-16 18:57:27.954212: step 7707, loss = 0.70241 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:57:28.937249 ops/training.py:65 2019-01-16 18:57:28.937148: step 7708, loss = 0.70147 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:57:29.919352 ops/training.py:65 2019-01-16 18:57:29.919253: step 7709, loss = 0.69471 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:57:30.901234 ops/training.py:65 2019-01-16 18:57:30.901137: step 7710, loss = 0.68988 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:57:31.884529 ops/training.py:65 2019-01-16 18:57:31.884427: step 7711, loss = 0.69136 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:57:32.869273 ops/training.py:65 2019-01-16 18:57:32.869176: step 7712, loss = 0.68559 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:57:33.852961 ops/training.py:65 2019-01-16 18:57:33.852838: step 7713, loss = 0.70503 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:57:34.835352 ops/training.py:65 2019-01-16 18:57:34.835245: step 7714, loss = 0.68705 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:57:35.819030 ops/training.py:65 2019-01-16 18:57:35.818924: step 7715, loss = 0.69066 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:57:36.804359 ops/training.py:65 2019-01-16 18:57:36.804219: step 7716, loss = 0.68566 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:57:37.788276 ops/training.py:65 2019-01-16 18:57:37.788166: step 7717, loss = 0.69543 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:57:38.771030 ops/training.py:65 2019-01-16 18:57:38.770932: step 7718, loss = 0.69430 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:57:39.753321 ops/training.py:65 2019-01-16 18:57:39.753223: step 7719, loss = 0.68861 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:57:40.736131 ops/training.py:65 2019-01-16 18:57:40.736041: step 7720, loss = 0.69664 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:57:41.719618 ops/training.py:65 2019-01-16 18:57:41.719520: step 7721, loss = 0.70051 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:57:42.703348 ops/training.py:65 2019-01-16 18:57:42.703250: step 7722, loss = 0.69302 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:57:43.686899 ops/training.py:65 2019-01-16 18:57:43.686807: step 7723, loss = 0.68168 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:57:44.670132 ops/training.py:65 2019-01-16 18:57:44.670034: step 7724, loss = 0.67599 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 18:57:45.652719 ops/training.py:65 2019-01-16 18:57:45.652626: step 7725, loss = 0.69938 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:57:46.634710 ops/training.py:65 2019-01-16 18:57:46.634616: step 7726, loss = 0.68584 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:57:47.617063 ops/training.py:65 2019-01-16 18:57:47.616965: step 7727, loss = 0.69974 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:57:48.600117 ops/training.py:65 2019-01-16 18:57:48.600018: step 7728, loss = 0.68259 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:57:49.583025 ops/training.py:65 2019-01-16 18:57:49.582928: step 7729, loss = 0.69917 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:57:50.565651 ops/training.py:65 2019-01-16 18:57:50.565556: step 7730, loss = 0.69622 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:57:51.547963 ops/training.py:65 2019-01-16 18:57:51.547868: step 7731, loss = 0.69135 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:57:52.530368 ops/training.py:65 2019-01-16 18:57:52.530262: step 7732, loss = 0.69268 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:57:53.513529 ops/training.py:65 2019-01-16 18:57:53.513448: step 7733, loss = 0.69529 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:57:54.496027 ops/training.py:65 2019-01-16 18:57:54.495927: step 7734, loss = 0.69515 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:57:55.477432 ops/training.py:65 2019-01-16 18:57:55.477361: step 7735, loss = 0.68961 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:57:56.457934 ops/training.py:65 2019-01-16 18:57:56.457864: step 7736, loss = 0.69898 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:57:57.439265 ops/training.py:65 2019-01-16 18:57:57.439186: step 7737, loss = 0.69848 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:57:58.423148 ops/training.py:65 2019-01-16 18:57:58.423080: step 7738, loss = 0.68588 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:57:59.407843 ops/training.py:65 2019-01-16 18:57:59.407748: step 7739, loss = 0.69215 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:58:00.393228 ops/training.py:65 2019-01-16 18:58:00.393126: step 7740, loss = 0.69545 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:58:01.377346 ops/training.py:65 2019-01-16 18:58:01.377282: step 7741, loss = 0.69874 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:58:02.361591 ops/training.py:65 2019-01-16 18:58:02.361488: step 7742, loss = 0.69394 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:58:03.346959 ops/training.py:65 2019-01-16 18:58:03.346862: step 7743, loss = 0.67864 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.75
I8192 2019-01-16 18:58:04.330089 ops/training.py:65 2019-01-16 18:58:04.329987: step 7744, loss = 0.69849 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:58:05.313940 ops/training.py:65 2019-01-16 18:58:05.313836: step 7745, loss = 0.69610 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:58:06.295838 ops/training.py:65 2019-01-16 18:58:06.295734: step 7746, loss = 0.69718 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:58:07.278384 ops/training.py:65 2019-01-16 18:58:07.278275: step 7747, loss = 0.71004 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 18:58:08.260868 ops/training.py:65 2019-01-16 18:58:08.260769: step 7748, loss = 0.68389 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:58:09.244481 ops/training.py:65 2019-01-16 18:58:09.244344: step 7749, loss = 0.68273 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:58:10.228596 ops/training.py:65 2019-01-16 18:58:10.228455: step 7750, loss = 0.68405 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:58:11.213448 ops/training.py:65 2019-01-16 18:58:11.213337: step 7751, loss = 0.68321 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:58:12.195298 ops/training.py:65 2019-01-16 18:58:12.195205: step 7752, loss = 0.70275 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:58:13.181167 ops/training.py:65 2019-01-16 18:58:13.181062: step 7753, loss = 0.68522 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:58:14.166106 ops/training.py:65 2019-01-16 18:58:14.166008: step 7754, loss = 0.69711 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:58:15.149655 ops/training.py:65 2019-01-16 18:58:15.149553: step 7755, loss = 0.69225 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:58:16.132891 ops/training.py:65 2019-01-16 18:58:16.132797: step 7756, loss = 0.69061 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:58:17.114921 ops/training.py:65 2019-01-16 18:58:17.114815: step 7757, loss = 0.68913 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:58:18.098099 ops/training.py:65 2019-01-16 18:58:18.098016: step 7758, loss = 0.69154 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:58:19.083241 ops/training.py:65 2019-01-16 18:58:19.083136: step 7759, loss = 0.70123 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:58:20.067031 ops/training.py:65 2019-01-16 18:58:20.066933: step 7760, loss = 0.70123 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:58:21.050919 ops/training.py:65 2019-01-16 18:58:21.050813: step 7761, loss = 0.69406 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:58:22.032944 ops/training.py:65 2019-01-16 18:58:22.032850: step 7762, loss = 0.69804 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:58:23.023360 ops/training.py:65 2019-01-16 18:58:23.023257: step 7763, loss = 0.69134 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:58:24.006464 ops/training.py:65 2019-01-16 18:58:24.006368: step 7764, loss = 0.69153 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:58:24.990161 ops/training.py:65 2019-01-16 18:58:24.990065: step 7765, loss = 0.69344 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:58:25.973108 ops/training.py:65 2019-01-16 18:58:25.973017: step 7766, loss = 0.69979 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:58:26.956796 ops/training.py:65 2019-01-16 18:58:26.956705: step 7767, loss = 0.69234 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:58:27.939551 ops/training.py:65 2019-01-16 18:58:27.939448: step 7768, loss = 0.69145 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:58:28.922171 ops/training.py:65 2019-01-16 18:58:28.922073: step 7769, loss = 0.68890 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:58:29.904794 ops/training.py:65 2019-01-16 18:58:29.904702: step 7770, loss = 0.68860 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:58:30.886911 ops/training.py:65 2019-01-16 18:58:30.886814: step 7771, loss = 0.69437 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:58:31.870448 ops/training.py:65 2019-01-16 18:58:31.870350: step 7772, loss = 0.69385 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:58:32.854407 ops/training.py:65 2019-01-16 18:58:32.854305: step 7773, loss = 0.69143 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:58:33.838039 ops/training.py:65 2019-01-16 18:58:33.837915: step 7774, loss = 0.69283 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:58:34.819272 ops/training.py:65 2019-01-16 18:58:34.819197: step 7775, loss = 0.71087 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.15625
I8192 2019-01-16 18:58:35.799686 ops/training.py:65 2019-01-16 18:58:35.799607: step 7776, loss = 0.68979 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:58:36.779008 ops/training.py:65 2019-01-16 18:58:36.778936: step 7777, loss = 0.69794 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:58:37.758704 ops/training.py:65 2019-01-16 18:58:37.758632: step 7778, loss = 0.69275 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:58:38.740069 ops/training.py:65 2019-01-16 18:58:38.740000: step 7779, loss = 0.69021 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.75
I8192 2019-01-16 18:58:39.720858 ops/training.py:65 2019-01-16 18:58:39.720779: step 7780, loss = 0.69208 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:58:40.700012 ops/training.py:65 2019-01-16 18:58:40.699937: step 7781, loss = 0.69297 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:58:41.678926 ops/training.py:65 2019-01-16 18:58:41.678860: step 7782, loss = 0.69745 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:58:42.658289 ops/training.py:65 2019-01-16 18:58:42.658213: step 7783, loss = 0.68874 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:58:43.643057 ops/training.py:65 2019-01-16 18:58:43.642979: step 7784, loss = 0.69210 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:58:44.628211 ops/training.py:65 2019-01-16 18:58:44.628115: step 7785, loss = 0.69847 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:58:45.611602 ops/training.py:65 2019-01-16 18:58:45.611494: step 7786, loss = 0.69184 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:58:46.594815 ops/training.py:65 2019-01-16 18:58:46.594715: step 7787, loss = 0.69551 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:58:47.577479 ops/training.py:65 2019-01-16 18:58:47.577385: step 7788, loss = 0.68971 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:58:48.561361 ops/training.py:65 2019-01-16 18:58:48.561258: step 7789, loss = 0.70081 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:58:49.544252 ops/training.py:65 2019-01-16 18:58:49.544155: step 7790, loss = 0.69281 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:58:50.526738 ops/training.py:65 2019-01-16 18:58:50.526597: step 7791, loss = 0.69970 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:58:51.512096 ops/training.py:65 2019-01-16 18:58:51.511998: step 7792, loss = 0.69503 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:58:52.497116 ops/training.py:65 2019-01-16 18:58:52.497017: step 7793, loss = 0.69318 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:58:53.480455 ops/training.py:65 2019-01-16 18:58:53.480360: step 7794, loss = 0.69956 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 18:58:54.462950 ops/training.py:65 2019-01-16 18:58:54.462858: step 7795, loss = 0.68250 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:58:55.445555 ops/training.py:65 2019-01-16 18:58:55.445454: step 7796, loss = 0.69119 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:58:56.429424 ops/training.py:65 2019-01-16 18:58:56.429319: step 7797, loss = 0.69942 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:58:57.411683 ops/training.py:65 2019-01-16 18:58:57.411584: step 7798, loss = 0.69465 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:58:58.394712 ops/training.py:65 2019-01-16 18:58:58.394610: step 7799, loss = 0.69356 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:58:59.377095 ops/training.py:65 2019-01-16 18:58:59.376987: step 7800, loss = 0.69309 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:59:00.359615 ops/training.py:65 2019-01-16 18:59:00.359511: step 7801, loss = 0.70151 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:59:01.341233 ops/training.py:65 2019-01-16 18:59:01.341136: step 7802, loss = 0.70321 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:59:02.322277 ops/training.py:65 2019-01-16 18:59:02.322181: step 7803, loss = 0.70776 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:59:03.306183 ops/training.py:65 2019-01-16 18:59:03.306079: step 7804, loss = 0.70009 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:59:04.288879 ops/training.py:65 2019-01-16 18:59:04.288774: step 7805, loss = 0.71390 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 18:59:05.274296 ops/training.py:65 2019-01-16 18:59:05.274195: step 7806, loss = 0.70109 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:59:06.258758 ops/training.py:65 2019-01-16 18:59:06.258658: step 7807, loss = 0.66864 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.75
I8192 2019-01-16 18:59:07.243708 ops/training.py:65 2019-01-16 18:59:07.243606: step 7808, loss = 0.69561 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:59:08.227510 ops/training.py:65 2019-01-16 18:59:08.227407: step 7809, loss = 0.68945 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:59:09.210356 ops/training.py:65 2019-01-16 18:59:09.210253: step 7810, loss = 0.68973 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:59:10.193775 ops/training.py:65 2019-01-16 18:59:10.193674: step 7811, loss = 0.68334 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:59:11.176531 ops/training.py:65 2019-01-16 18:59:11.176438: step 7812, loss = 0.68984 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:59:12.159630 ops/training.py:65 2019-01-16 18:59:12.159537: step 7813, loss = 0.69315 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:59:13.144125 ops/training.py:65 2019-01-16 18:59:13.144030: step 7814, loss = 0.67757 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:59:14.126908 ops/training.py:65 2019-01-16 18:59:14.126810: step 7815, loss = 0.68966 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:59:15.109808 ops/training.py:65 2019-01-16 18:59:15.109715: step 7816, loss = 0.68603 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:59:16.092656 ops/training.py:65 2019-01-16 18:59:16.092573: step 7817, loss = 0.69010 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:59:17.074824 ops/training.py:65 2019-01-16 18:59:17.074728: step 7818, loss = 0.71832 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 18:59:18.058494 ops/training.py:65 2019-01-16 18:59:18.058391: step 7819, loss = 0.69747 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:59:19.040518 ops/training.py:65 2019-01-16 18:59:19.040425: step 7820, loss = 0.68281 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:59:20.023672 ops/training.py:65 2019-01-16 18:59:20.023576: step 7821, loss = 0.68586 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:59:21.006045 ops/training.py:65 2019-01-16 18:59:21.005939: step 7822, loss = 0.69225 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:59:21.988302 ops/training.py:65 2019-01-16 18:59:21.988200: step 7823, loss = 0.68811 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:59:22.972325 ops/training.py:65 2019-01-16 18:59:22.972226: step 7824, loss = 0.69593 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:59:23.954001 ops/training.py:65 2019-01-16 18:59:23.953899: step 7825, loss = 0.70885 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:59:24.936704 ops/training.py:65 2019-01-16 18:59:24.936599: step 7826, loss = 0.68949 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:59:25.918934 ops/training.py:65 2019-01-16 18:59:25.918834: step 7827, loss = 0.72276 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.25
I8192 2019-01-16 18:59:26.901329 ops/training.py:65 2019-01-16 18:59:26.901212: step 7828, loss = 0.69671 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:59:27.883533 ops/training.py:65 2019-01-16 18:59:27.883439: step 7829, loss = 0.70777 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:59:28.867199 ops/training.py:65 2019-01-16 18:59:28.867107: step 7830, loss = 0.69467 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:59:29.849892 ops/training.py:65 2019-01-16 18:59:29.849798: step 7831, loss = 0.69600 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:59:30.832960 ops/training.py:65 2019-01-16 18:59:30.832861: step 7832, loss = 0.70045 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:59:31.815528 ops/training.py:65 2019-01-16 18:59:31.815431: step 7833, loss = 0.69995 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:59:32.798326 ops/training.py:65 2019-01-16 18:59:32.798224: step 7834, loss = 0.70358 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:59:33.782303 ops/training.py:65 2019-01-16 18:59:33.782178: step 7835, loss = 0.69159 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:59:34.764919 ops/training.py:65 2019-01-16 18:59:34.764817: step 7836, loss = 0.70192 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:59:35.750864 ops/training.py:65 2019-01-16 18:59:35.750765: step 7837, loss = 0.68723 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:59:36.734479 ops/training.py:65 2019-01-16 18:59:36.734380: step 7838, loss = 0.70931 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.28125
I8192 2019-01-16 18:59:37.718410 ops/training.py:65 2019-01-16 18:59:37.718312: step 7839, loss = 0.70431 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:59:38.700045 ops/training.py:65 2019-01-16 18:59:38.699906: step 7840, loss = 0.69713 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:59:39.682411 ops/training.py:65 2019-01-16 18:59:39.682310: step 7841, loss = 0.69319 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:59:40.663808 ops/training.py:65 2019-01-16 18:59:40.663703: step 7842, loss = 0.69073 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:59:41.644419 ops/training.py:65 2019-01-16 18:59:41.644335: step 7843, loss = 0.69444 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:59:42.624795 ops/training.py:65 2019-01-16 18:59:42.624721: step 7844, loss = 0.68284 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:59:43.605396 ops/training.py:65 2019-01-16 18:59:43.605297: step 7845, loss = 0.67102 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 18:59:44.585565 ops/training.py:65 2019-01-16 18:59:44.585486: step 7846, loss = 0.69528 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:59:45.568474 ops/training.py:65 2019-01-16 18:59:45.568394: step 7847, loss = 0.69518 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:59:46.552750 ops/training.py:65 2019-01-16 18:59:46.552661: step 7848, loss = 0.69148 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:59:47.537774 ops/training.py:65 2019-01-16 18:59:47.537670: step 7849, loss = 0.69786 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:59:48.520366 ops/training.py:65 2019-01-16 18:59:48.520263: step 7850, loss = 0.68964 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:59:49.503162 ops/training.py:65 2019-01-16 18:59:49.503067: step 7851, loss = 0.69668 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 18:59:50.485455 ops/training.py:65 2019-01-16 18:59:50.485357: step 7852, loss = 0.68788 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 18:59:51.468079 ops/training.py:65 2019-01-16 18:59:51.467973: step 7853, loss = 0.69693 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 18:59:52.450809 ops/training.py:65 2019-01-16 18:59:52.450711: step 7854, loss = 0.70515 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 18:59:53.434637 ops/training.py:65 2019-01-16 18:59:53.434536: step 7855, loss = 0.70294 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:59:54.416774 ops/training.py:65 2019-01-16 18:59:54.416677: step 7856, loss = 0.68948 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 18:59:55.400822 ops/training.py:65 2019-01-16 18:59:55.400724: step 7857, loss = 0.69267 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 18:59:56.383498 ops/training.py:65 2019-01-16 18:59:56.383408: step 7858, loss = 0.68318 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:59:57.366477 ops/training.py:65 2019-01-16 18:59:57.366357: step 7859, loss = 0.69686 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 18:59:58.348939 ops/training.py:65 2019-01-16 18:59:58.348844: step 7860, loss = 0.68891 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 18:59:59.332622 ops/training.py:65 2019-01-16 18:59:59.332535: step 7861, loss = 0.69785 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:00:00.315661 ops/training.py:65 2019-01-16 19:00:00.315561: step 7862, loss = 0.68989 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:00:01.298048 ops/training.py:65 2019-01-16 19:00:01.297952: step 7863, loss = 0.70274 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:00:02.279797 ops/training.py:65 2019-01-16 19:00:02.279679: step 7864, loss = 0.70752 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 19:00:03.264659 ops/training.py:65 2019-01-16 19:00:03.264559: step 7865, loss = 0.69775 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:00:04.249005 ops/training.py:65 2019-01-16 19:00:04.248909: step 7866, loss = 0.69349 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:00:05.232668 ops/training.py:65 2019-01-16 19:00:05.232578: step 7867, loss = 0.69449 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:00:06.215655 ops/training.py:65 2019-01-16 19:00:06.215548: step 7868, loss = 0.69086 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:00:07.198901 ops/training.py:65 2019-01-16 19:00:07.198798: step 7869, loss = 0.68457 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:00:08.182839 ops/training.py:65 2019-01-16 19:00:08.182737: step 7870, loss = 0.68687 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:00:09.165568 ops/training.py:65 2019-01-16 19:00:09.165466: step 7871, loss = 0.69703 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:00:10.150199 ops/training.py:65 2019-01-16 19:00:10.150096: step 7872, loss = 0.69711 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:00:11.134314 ops/training.py:65 2019-01-16 19:00:11.134210: step 7873, loss = 0.68705 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:00:12.117601 ops/training.py:65 2019-01-16 19:00:12.117509: step 7874, loss = 0.72177 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 19:00:13.101500 ops/training.py:65 2019-01-16 19:00:13.101404: step 7875, loss = 0.68658 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 19:00:14.083924 ops/training.py:65 2019-01-16 19:00:14.083825: step 7876, loss = 0.67983 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:00:15.064807 ops/training.py:65 2019-01-16 19:00:15.064732: step 7877, loss = 0.70644 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 19:00:16.044985 ops/training.py:65 2019-01-16 19:00:16.044910: step 7878, loss = 0.68838 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:00:17.024696 ops/training.py:65 2019-01-16 19:00:17.024630: step 7879, loss = 0.70417 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:00:18.008996 ops/training.py:65 2019-01-16 19:00:18.008910: step 7880, loss = 0.70867 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:00:18.993886 ops/training.py:65 2019-01-16 19:00:18.993790: step 7881, loss = 0.68095 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:00:19.977793 ops/training.py:65 2019-01-16 19:00:19.977691: step 7882, loss = 0.70544 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:00:20.961548 ops/training.py:65 2019-01-16 19:00:20.961466: step 7883, loss = 0.68730 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:00:21.943484 ops/training.py:65 2019-01-16 19:00:21.943373: step 7884, loss = 0.68591 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:00:22.925616 ops/training.py:65 2019-01-16 19:00:22.925512: step 7885, loss = 0.70341 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:00:23.907564 ops/training.py:65 2019-01-16 19:00:23.907463: step 7886, loss = 0.68037 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:00:24.890257 ops/training.py:65 2019-01-16 19:00:24.890154: step 7887, loss = 0.69423 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:00:25.872175 ops/training.py:65 2019-01-16 19:00:25.872068: step 7888, loss = 0.68838 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:00:26.852251 ops/training.py:65 2019-01-16 19:00:26.852173: step 7889, loss = 0.67861 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 19:00:27.832727 ops/training.py:65 2019-01-16 19:00:27.832635: step 7890, loss = 0.68851 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:00:28.814337 ops/training.py:65 2019-01-16 19:00:28.814258: step 7891, loss = 0.70879 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:00:29.799316 ops/training.py:65 2019-01-16 19:00:29.799233: step 7892, loss = 0.68582 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:00:30.786317 ops/training.py:65 2019-01-16 19:00:30.786215: step 7893, loss = 0.69208 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:00:31.770800 ops/training.py:65 2019-01-16 19:00:31.770695: step 7894, loss = 0.70771 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:00:32.754350 ops/training.py:65 2019-01-16 19:00:32.754250: step 7895, loss = 0.68704 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:00:33.739302 ops/training.py:65 2019-01-16 19:00:33.739206: step 7896, loss = 0.69570 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:00:34.724161 ops/training.py:65 2019-01-16 19:00:34.724060: step 7897, loss = 0.68603 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:00:35.709038 ops/training.py:65 2019-01-16 19:00:35.708940: step 7898, loss = 0.68104 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:00:36.693234 ops/training.py:65 2019-01-16 19:00:36.693129: step 7899, loss = 0.69300 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:00:37.676869 ops/training.py:65 2019-01-16 19:00:37.676766: step 7900, loss = 0.69950 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:00:38.660630 ops/training.py:65 2019-01-16 19:00:38.660527: step 7901, loss = 0.67811 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:00:39.644119 ops/training.py:65 2019-01-16 19:00:39.644020: step 7902, loss = 0.67812 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 19:00:40.627809 ops/training.py:65 2019-01-16 19:00:40.627707: step 7903, loss = 0.68056 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:00:41.610574 ops/training.py:65 2019-01-16 19:00:41.610480: step 7904, loss = 0.68834 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:00:42.594086 ops/training.py:65 2019-01-16 19:00:42.593987: step 7905, loss = 0.67659 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:00:43.577895 ops/training.py:65 2019-01-16 19:00:43.577800: step 7906, loss = 0.72191 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:00:44.562606 ops/training.py:65 2019-01-16 19:00:44.562499: step 7907, loss = 0.71250 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:00:45.546089 ops/training.py:65 2019-01-16 19:00:45.545984: step 7908, loss = 0.70955 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:00:46.530107 ops/training.py:65 2019-01-16 19:00:46.530007: step 7909, loss = 0.67603 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 19:00:47.512177 ops/training.py:65 2019-01-16 19:00:47.512073: step 7910, loss = 0.69290 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:00:48.495873 ops/training.py:65 2019-01-16 19:00:48.495764: step 7911, loss = 0.67414 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 19:00:49.478771 ops/training.py:65 2019-01-16 19:00:49.478681: step 7912, loss = 0.69488 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:00:50.462517 ops/training.py:65 2019-01-16 19:00:50.462418: step 7913, loss = 0.69756 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:00:51.445268 ops/training.py:65 2019-01-16 19:00:51.445171: step 7914, loss = 0.68293 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:00:52.425411 ops/training.py:65 2019-01-16 19:00:52.425337: step 7915, loss = 0.69198 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:00:53.407327 ops/training.py:65 2019-01-16 19:00:53.407247: step 7916, loss = 0.70790 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:00:54.392319 ops/training.py:65 2019-01-16 19:00:54.392229: step 7917, loss = 0.70017 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:00:55.376191 ops/training.py:65 2019-01-16 19:00:55.376097: step 7918, loss = 0.68857 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:00:56.360781 ops/training.py:65 2019-01-16 19:00:56.360693: step 7919, loss = 0.68484 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:00:57.343603 ops/training.py:65 2019-01-16 19:00:57.343509: step 7920, loss = 0.69170 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:00:58.326672 ops/training.py:65 2019-01-16 19:00:58.326573: step 7921, loss = 0.69370 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:00:59.309952 ops/training.py:65 2019-01-16 19:00:59.309851: step 7922, loss = 0.69448 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:01:00.292348 ops/training.py:65 2019-01-16 19:01:00.292242: step 7923, loss = 0.70035 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:01:01.274348 ops/training.py:65 2019-01-16 19:01:01.274246: step 7924, loss = 0.68978 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:01:02.257437 ops/training.py:65 2019-01-16 19:01:02.257348: step 7925, loss = 0.69702 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:01:03.241498 ops/training.py:65 2019-01-16 19:01:03.241396: step 7926, loss = 0.69947 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:01:04.226464 ops/training.py:65 2019-01-16 19:01:04.226367: step 7927, loss = 0.69417 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:01:05.210451 ops/training.py:65 2019-01-16 19:01:05.210357: step 7928, loss = 0.67590 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 19:01:06.193347 ops/training.py:65 2019-01-16 19:01:06.193250: step 7929, loss = 0.69136 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:01:07.175642 ops/training.py:65 2019-01-16 19:01:07.175542: step 7930, loss = 0.70146 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:01:08.159259 ops/training.py:65 2019-01-16 19:01:08.159153: step 7931, loss = 0.68672 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:01:09.142143 ops/training.py:65 2019-01-16 19:01:09.142039: step 7932, loss = 0.68939 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:01:10.125220 ops/training.py:65 2019-01-16 19:01:10.125123: step 7933, loss = 0.69059 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:01:11.107291 ops/training.py:65 2019-01-16 19:01:11.107188: step 7934, loss = 0.68917 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:01:12.089189 ops/training.py:65 2019-01-16 19:01:12.089093: step 7935, loss = 0.69375 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:01:13.072519 ops/training.py:65 2019-01-16 19:01:13.072419: step 7936, loss = 0.69150 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:01:14.055652 ops/training.py:65 2019-01-16 19:01:14.055542: step 7937, loss = 0.67929 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 19:01:15.037620 ops/training.py:65 2019-01-16 19:01:15.037514: step 7938, loss = 0.69456 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:01:16.023355 ops/training.py:65 2019-01-16 19:01:16.023261: step 7939, loss = 0.70165 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:01:17.008096 ops/training.py:65 2019-01-16 19:01:17.007993: step 7940, loss = 0.69982 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:01:17.994006 ops/training.py:65 2019-01-16 19:01:17.993896: step 7941, loss = 0.69510 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:01:18.977051 ops/training.py:65 2019-01-16 19:01:18.976957: step 7942, loss = 0.68548 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:01:19.960078 ops/training.py:65 2019-01-16 19:01:19.959967: step 7943, loss = 0.69544 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:01:20.943677 ops/training.py:65 2019-01-16 19:01:20.943575: step 7944, loss = 0.70414 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:01:21.927443 ops/training.py:65 2019-01-16 19:01:21.927349: step 7945, loss = 0.69725 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:01:22.910570 ops/training.py:65 2019-01-16 19:01:22.910469: step 7946, loss = 0.68837 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:01:23.893446 ops/training.py:65 2019-01-16 19:01:23.893345: step 7947, loss = 0.68634 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:01:24.873807 ops/training.py:65 2019-01-16 19:01:24.873710: step 7948, loss = 0.69196 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:01:25.854243 ops/training.py:65 2019-01-16 19:01:25.854152: step 7949, loss = 0.70039 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:01:26.838356 ops/training.py:65 2019-01-16 19:01:26.838278: step 7950, loss = 0.69659 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:01:27.823172 ops/training.py:65 2019-01-16 19:01:27.823090: step 7951, loss = 0.69528 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:01:28.807760 ops/training.py:65 2019-01-16 19:01:28.807668: step 7952, loss = 0.69556 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:01:29.790384 ops/training.py:65 2019-01-16 19:01:29.790293: step 7953, loss = 0.69254 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:01:30.773053 ops/training.py:65 2019-01-16 19:01:30.772958: step 7954, loss = 0.69358 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:01:31.755029 ops/training.py:65 2019-01-16 19:01:31.754917: step 7955, loss = 0.69520 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:01:32.739167 ops/training.py:65 2019-01-16 19:01:32.739079: step 7956, loss = 0.69166 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:01:33.722774 ops/training.py:65 2019-01-16 19:01:33.722681: step 7957, loss = 0.69288 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:01:34.706877 ops/training.py:65 2019-01-16 19:01:34.706793: step 7958, loss = 0.69404 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:01:35.692111 ops/training.py:65 2019-01-16 19:01:35.692017: step 7959, loss = 0.69094 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:01:36.674083 ops/training.py:65 2019-01-16 19:01:36.673981: step 7960, loss = 0.70079 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:01:37.656444 ops/training.py:65 2019-01-16 19:01:37.656339: step 7961, loss = 0.70568 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 19:01:38.639284 ops/training.py:65 2019-01-16 19:01:38.639176: step 7962, loss = 0.69091 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:01:39.623027 ops/training.py:65 2019-01-16 19:01:39.622922: step 7963, loss = 0.67883 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 19:01:40.605965 ops/training.py:65 2019-01-16 19:01:40.605866: step 7964, loss = 0.70143 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 19:01:41.589120 ops/training.py:65 2019-01-16 19:01:41.589022: step 7965, loss = 0.69344 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:01:42.572077 ops/training.py:65 2019-01-16 19:01:42.571979: step 7966, loss = 0.69723 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:01:43.554613 ops/training.py:65 2019-01-16 19:01:43.554507: step 7967, loss = 0.69428 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:01:44.537016 ops/training.py:65 2019-01-16 19:01:44.536913: step 7968, loss = 0.69524 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:01:45.519406 ops/training.py:65 2019-01-16 19:01:45.519309: step 7969, loss = 0.69545 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 19:01:46.501759 ops/training.py:65 2019-01-16 19:01:46.501655: step 7970, loss = 0.69192 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:01:47.483403 ops/training.py:65 2019-01-16 19:01:47.483315: step 7971, loss = 0.69484 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:01:48.467367 ops/training.py:65 2019-01-16 19:01:48.467261: step 7972, loss = 0.70359 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 19:01:49.449318 ops/training.py:65 2019-01-16 19:01:49.449214: step 7973, loss = 0.69718 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:01:50.431814 ops/training.py:65 2019-01-16 19:01:50.431713: step 7974, loss = 0.69632 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:01:51.418282 ops/training.py:65 2019-01-16 19:01:51.418175: step 7975, loss = 0.69149 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:01:52.404101 ops/training.py:65 2019-01-16 19:01:52.403970: step 7976, loss = 0.69097 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:01:53.388027 ops/training.py:65 2019-01-16 19:01:53.387929: step 7977, loss = 0.69916 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 19:01:54.370419 ops/training.py:65 2019-01-16 19:01:54.370320: step 7978, loss = 0.68972 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:01:55.352882 ops/training.py:65 2019-01-16 19:01:55.352778: step 7979, loss = 0.69429 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:01:56.335945 ops/training.py:65 2019-01-16 19:01:56.335856: step 7980, loss = 0.69525 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:01:57.318040 ops/training.py:65 2019-01-16 19:01:57.317941: step 7981, loss = 0.69122 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:01:58.299926 ops/training.py:65 2019-01-16 19:01:58.299828: step 7982, loss = 0.70277 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:01:59.281652 ops/training.py:65 2019-01-16 19:01:59.281553: step 7983, loss = 0.69294 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:02:00.264282 ops/training.py:65 2019-01-16 19:02:00.264182: step 7984, loss = 0.68638 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:02:01.247333 ops/training.py:65 2019-01-16 19:02:01.247231: step 7985, loss = 0.69458 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:02:02.229760 ops/training.py:65 2019-01-16 19:02:02.229661: step 7986, loss = 0.68767 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 19:02:03.211724 ops/training.py:65 2019-01-16 19:02:03.211623: step 7987, loss = 0.68959 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:02:04.195282 ops/training.py:65 2019-01-16 19:02:04.195182: step 7988, loss = 0.69330 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:02:05.178475 ops/training.py:65 2019-01-16 19:02:05.178390: step 7989, loss = 0.69379 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:02:06.161503 ops/training.py:65 2019-01-16 19:02:06.161397: step 7990, loss = 0.68851 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:02:07.143819 ops/training.py:65 2019-01-16 19:02:07.143723: step 7991, loss = 0.69036 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:02:08.126104 ops/training.py:65 2019-01-16 19:02:08.126005: step 7992, loss = 0.69196 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:02:09.109383 ops/training.py:65 2019-01-16 19:02:09.109284: step 7993, loss = 0.68579 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:02:10.091054 ops/training.py:65 2019-01-16 19:02:10.090960: step 7994, loss = 0.69255 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:02:11.073076 ops/training.py:65 2019-01-16 19:02:11.072972: step 7995, loss = 0.68656 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:02:12.057380 ops/training.py:65 2019-01-16 19:02:12.057292: step 7996, loss = 0.69560 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:02:13.042845 ops/training.py:65 2019-01-16 19:02:13.042750: step 7997, loss = 0.69014 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:02:14.026363 ops/training.py:65 2019-01-16 19:02:14.026267: step 7998, loss = 0.69880 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:02:15.008443 ops/training.py:65 2019-01-16 19:02:15.008341: step 7999, loss = 0.69167 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:06:59.511751 ops/training.py:396 Failed to save checkpoint: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()
I8192 2019-01-16 19:06:59.512975 ops/training.py:41 2019-01-16 19:06:59.512918: step 8000, loss = 0.70 (0.1 examples/sec; 283.521 sec/batch) | Training accuracy = 0.53125 | Validation accuracy = 0.49005 | logdir = /users/dlinsley/cluttered_nist_experiments/summaries/nist_3_ix2v2_50k_2019_01_16_16_30_45_270295
I8192 2019-01-16 19:07:00.538758 ops/training.py:65 2019-01-16 19:07:00.538661: step 8001, loss = 0.69120 (31.2 examples/sec; 1.025 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:07:01.522545 ops/training.py:65 2019-01-16 19:07:01.522444: step 8002, loss = 0.70214 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:07:02.506875 ops/training.py:65 2019-01-16 19:07:02.506776: step 8003, loss = 0.69286 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:07:03.492447 ops/training.py:65 2019-01-16 19:07:03.492352: step 8004, loss = 0.69202 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:07:04.476419 ops/training.py:65 2019-01-16 19:07:04.476315: step 8005, loss = 0.70060 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:07:05.460493 ops/training.py:65 2019-01-16 19:07:05.460392: step 8006, loss = 0.69142 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:07:06.445770 ops/training.py:65 2019-01-16 19:07:06.445679: step 8007, loss = 0.68957 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:07:07.430631 ops/training.py:65 2019-01-16 19:07:07.430531: step 8008, loss = 0.70162 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 19:07:08.415890 ops/training.py:65 2019-01-16 19:07:08.415792: step 8009, loss = 0.68744 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:07:09.400520 ops/training.py:65 2019-01-16 19:07:09.400420: step 8010, loss = 0.69351 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:07:10.383881 ops/training.py:65 2019-01-16 19:07:10.383781: step 8011, loss = 0.69685 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:07:11.369613 ops/training.py:65 2019-01-16 19:07:11.369504: step 8012, loss = 0.69489 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:07:12.352003 ops/training.py:65 2019-01-16 19:07:12.351911: step 8013, loss = 0.69408 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:07:13.333665 ops/training.py:65 2019-01-16 19:07:13.333566: step 8014, loss = 0.69454 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:07:14.314160 ops/training.py:65 2019-01-16 19:07:14.314094: step 8015, loss = 0.69115 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:07:15.294385 ops/training.py:65 2019-01-16 19:07:15.294320: step 8016, loss = 0.69261 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:07:16.274121 ops/training.py:65 2019-01-16 19:07:16.274053: step 8017, loss = 0.68764 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:07:17.253263 ops/training.py:65 2019-01-16 19:07:17.253200: step 8018, loss = 0.68639 (32.7 examples/sec; 0.978 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:07:18.237889 ops/training.py:65 2019-01-16 19:07:18.237819: step 8019, loss = 0.69104 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:07:19.220942 ops/training.py:65 2019-01-16 19:07:19.220832: step 8020, loss = 0.69315 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:07:20.207485 ops/training.py:65 2019-01-16 19:07:20.207399: step 8021, loss = 0.69767 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:07:21.190858 ops/training.py:65 2019-01-16 19:07:21.190765: step 8022, loss = 0.68490 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.75
I8192 2019-01-16 19:07:22.174336 ops/training.py:65 2019-01-16 19:07:22.174232: step 8023, loss = 0.69661 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:07:23.157468 ops/training.py:65 2019-01-16 19:07:23.157368: step 8024, loss = 0.69897 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 19:07:24.143041 ops/training.py:65 2019-01-16 19:07:24.142943: step 8025, loss = 0.68794 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:07:25.128508 ops/training.py:65 2019-01-16 19:07:25.128407: step 8026, loss = 0.69079 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:07:26.115123 ops/training.py:65 2019-01-16 19:07:26.115019: step 8027, loss = 0.70592 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 19:07:27.099904 ops/training.py:65 2019-01-16 19:07:27.099804: step 8028, loss = 0.69583 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:07:28.086660 ops/training.py:65 2019-01-16 19:07:28.086538: step 8029, loss = 0.69327 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:07:29.070920 ops/training.py:65 2019-01-16 19:07:29.070781: step 8030, loss = 0.70114 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:07:30.055079 ops/training.py:65 2019-01-16 19:07:30.054979: step 8031, loss = 0.69178 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:07:31.038359 ops/training.py:65 2019-01-16 19:07:31.038224: step 8032, loss = 0.69848 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:07:32.021949 ops/training.py:65 2019-01-16 19:07:32.021865: step 8033, loss = 0.69809 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 19:07:33.005609 ops/training.py:65 2019-01-16 19:07:33.005484: step 8034, loss = 0.69296 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:07:33.990842 ops/training.py:65 2019-01-16 19:07:33.990710: step 8035, loss = 0.68837 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:07:34.974186 ops/training.py:65 2019-01-16 19:07:34.974050: step 8036, loss = 0.69974 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:07:35.956071 ops/training.py:65 2019-01-16 19:07:35.956014: step 8037, loss = 0.69506 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:07:36.942975 ops/training.py:65 2019-01-16 19:07:36.942905: step 8038, loss = 0.67459 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 19:07:37.927031 ops/training.py:65 2019-01-16 19:07:37.926927: step 8039, loss = 0.69055 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:07:38.910730 ops/training.py:65 2019-01-16 19:07:38.910631: step 8040, loss = 0.69997 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:07:39.895581 ops/training.py:65 2019-01-16 19:07:39.895481: step 8041, loss = 0.68580 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 19:07:40.878820 ops/training.py:65 2019-01-16 19:07:40.878720: step 8042, loss = 0.70299 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:07:41.861447 ops/training.py:65 2019-01-16 19:07:41.861300: step 8043, loss = 0.70386 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 19:07:42.846859 ops/training.py:65 2019-01-16 19:07:42.846758: step 8044, loss = 0.69632 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:07:43.829655 ops/training.py:65 2019-01-16 19:07:43.829556: step 8045, loss = 0.69707 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:07:44.812600 ops/training.py:65 2019-01-16 19:07:44.812501: step 8046, loss = 0.69082 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:07:45.796286 ops/training.py:65 2019-01-16 19:07:45.796180: step 8047, loss = 0.69234 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:07:46.778735 ops/training.py:65 2019-01-16 19:07:46.778599: step 8048, loss = 0.71236 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:07:47.762048 ops/training.py:65 2019-01-16 19:07:47.761941: step 8049, loss = 0.70635 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 19:07:48.745946 ops/training.py:65 2019-01-16 19:07:48.745842: step 8050, loss = 0.69479 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 19:07:49.729402 ops/training.py:65 2019-01-16 19:07:49.729300: step 8051, loss = 0.70763 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 19:07:50.713060 ops/training.py:65 2019-01-16 19:07:50.712957: step 8052, loss = 0.66712 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.8125
I8192 2019-01-16 19:07:51.697103 ops/training.py:65 2019-01-16 19:07:51.696996: step 8053, loss = 0.68674 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:07:52.682618 ops/training.py:65 2019-01-16 19:07:52.682519: step 8054, loss = 0.69582 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:07:53.668339 ops/training.py:65 2019-01-16 19:07:53.668244: step 8055, loss = 0.69816 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:07:54.651478 ops/training.py:65 2019-01-16 19:07:54.651372: step 8056, loss = 0.69029 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:07:55.633952 ops/training.py:65 2019-01-16 19:07:55.633849: step 8057, loss = 0.68165 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:07:56.614250 ops/training.py:65 2019-01-16 19:07:56.614181: step 8058, loss = 0.69503 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:07:57.595577 ops/training.py:65 2019-01-16 19:07:57.595503: step 8059, loss = 0.70351 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:07:58.580423 ops/training.py:65 2019-01-16 19:07:58.580336: step 8060, loss = 0.69272 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:07:59.565938 ops/training.py:65 2019-01-16 19:07:59.565839: step 8061, loss = 0.69658 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:08:00.549983 ops/training.py:65 2019-01-16 19:08:00.549871: step 8062, loss = 0.69284 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:08:01.533006 ops/training.py:65 2019-01-16 19:08:01.532911: step 8063, loss = 0.68404 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:08:02.516249 ops/training.py:65 2019-01-16 19:08:02.516152: step 8064, loss = 0.69196 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:08:03.500098 ops/training.py:65 2019-01-16 19:08:03.499997: step 8065, loss = 0.69355 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:08:04.483758 ops/training.py:65 2019-01-16 19:08:04.483657: step 8066, loss = 0.70139 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:08:05.467528 ops/training.py:65 2019-01-16 19:08:05.467387: step 8067, loss = 0.69995 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 19:08:06.450513 ops/training.py:65 2019-01-16 19:08:06.450391: step 8068, loss = 0.69376 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:08:07.431957 ops/training.py:65 2019-01-16 19:08:07.431873: step 8069, loss = 0.69833 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:08:08.412581 ops/training.py:65 2019-01-16 19:08:08.412480: step 8070, loss = 0.69732 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:08:09.398376 ops/training.py:65 2019-01-16 19:08:09.398295: step 8071, loss = 0.68301 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:08:10.384461 ops/training.py:65 2019-01-16 19:08:10.384365: step 8072, loss = 0.70261 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 19:08:11.369138 ops/training.py:65 2019-01-16 19:08:11.369041: step 8073, loss = 0.69357 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:08:12.353467 ops/training.py:65 2019-01-16 19:08:12.353338: step 8074, loss = 0.68788 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:08:13.337658 ops/training.py:65 2019-01-16 19:08:13.337560: step 8075, loss = 0.69587 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:08:14.320690 ops/training.py:65 2019-01-16 19:08:14.320563: step 8076, loss = 0.68564 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:08:15.303846 ops/training.py:65 2019-01-16 19:08:15.303742: step 8077, loss = 0.69805 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:08:16.286759 ops/training.py:65 2019-01-16 19:08:16.286653: step 8078, loss = 0.69081 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:08:17.270570 ops/training.py:65 2019-01-16 19:08:17.270471: step 8079, loss = 0.68641 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:08:18.256828 ops/training.py:65 2019-01-16 19:08:18.256721: step 8080, loss = 0.69725 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:08:19.243398 ops/training.py:65 2019-01-16 19:08:19.243318: step 8081, loss = 0.69399 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 19:08:20.228069 ops/training.py:65 2019-01-16 19:08:20.227931: step 8082, loss = 0.69452 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:08:21.212204 ops/training.py:65 2019-01-16 19:08:21.212112: step 8083, loss = 0.70804 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 19:08:22.196363 ops/training.py:65 2019-01-16 19:08:22.196273: step 8084, loss = 0.68639 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 19:08:23.180764 ops/training.py:65 2019-01-16 19:08:23.180680: step 8085, loss = 0.68806 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:08:24.163849 ops/training.py:65 2019-01-16 19:08:24.163744: step 8086, loss = 0.70090 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:08:25.147357 ops/training.py:65 2019-01-16 19:08:25.147259: step 8087, loss = 0.69802 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:08:26.130938 ops/training.py:65 2019-01-16 19:08:26.130833: step 8088, loss = 0.70337 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:08:27.114580 ops/training.py:65 2019-01-16 19:08:27.114474: step 8089, loss = 0.68129 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:08:28.098704 ops/training.py:65 2019-01-16 19:08:28.098602: step 8090, loss = 0.68067 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:08:29.082485 ops/training.py:65 2019-01-16 19:08:29.082373: step 8091, loss = 0.68365 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:08:30.064122 ops/training.py:65 2019-01-16 19:08:30.063980: step 8092, loss = 0.68792 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:08:31.044605 ops/training.py:65 2019-01-16 19:08:31.044536: step 8093, loss = 0.68810 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:08:32.024567 ops/training.py:65 2019-01-16 19:08:32.024501: step 8094, loss = 0.67795 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 19:08:33.006460 ops/training.py:65 2019-01-16 19:08:33.006395: step 8095, loss = 0.69378 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:08:33.991322 ops/training.py:65 2019-01-16 19:08:33.991240: step 8096, loss = 0.67726 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:08:34.977411 ops/training.py:65 2019-01-16 19:08:34.977309: step 8097, loss = 0.71368 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:08:35.960993 ops/training.py:65 2019-01-16 19:08:35.960890: step 8098, loss = 0.68427 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 19:08:36.944738 ops/training.py:65 2019-01-16 19:08:36.944629: step 8099, loss = 0.69224 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:08:37.928270 ops/training.py:65 2019-01-16 19:08:37.928166: step 8100, loss = 0.69329 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:08:38.912074 ops/training.py:65 2019-01-16 19:08:38.911966: step 8101, loss = 0.70318 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:08:39.894371 ops/training.py:65 2019-01-16 19:08:39.894272: step 8102, loss = 0.69540 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:08:40.882039 ops/training.py:65 2019-01-16 19:08:40.881943: step 8103, loss = 0.69033 (32.4 examples/sec; 0.986 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:08:41.867024 ops/training.py:65 2019-01-16 19:08:41.866923: step 8104, loss = 0.68248 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:08:42.849741 ops/training.py:65 2019-01-16 19:08:42.849646: step 8105, loss = 0.67941 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 19:08:43.831918 ops/training.py:65 2019-01-16 19:08:43.831817: step 8106, loss = 0.69469 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:08:44.813904 ops/training.py:65 2019-01-16 19:08:44.813799: step 8107, loss = 0.69520 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:08:45.794718 ops/training.py:65 2019-01-16 19:08:45.794643: step 8108, loss = 0.69170 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:08:46.779983 ops/training.py:65 2019-01-16 19:08:46.779887: step 8109, loss = 0.68130 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:08:47.764959 ops/training.py:65 2019-01-16 19:08:47.764852: step 8110, loss = 0.70242 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:08:48.748847 ops/training.py:65 2019-01-16 19:08:48.748743: step 8111, loss = 0.69038 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:08:49.732502 ops/training.py:65 2019-01-16 19:08:49.732397: step 8112, loss = 0.68972 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:08:50.716349 ops/training.py:65 2019-01-16 19:08:50.716249: step 8113, loss = 0.70094 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:08:51.700422 ops/training.py:65 2019-01-16 19:08:51.700314: step 8114, loss = 0.69684 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:08:52.684872 ops/training.py:65 2019-01-16 19:08:52.684766: step 8115, loss = 0.67939 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.71875
I8192 2019-01-16 19:08:53.668669 ops/training.py:65 2019-01-16 19:08:53.668543: step 8116, loss = 0.69799 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:08:54.652166 ops/training.py:65 2019-01-16 19:08:54.652060: step 8117, loss = 0.69020 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:08:55.636575 ops/training.py:65 2019-01-16 19:08:55.636470: step 8118, loss = 0.68907 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:08:56.620338 ops/training.py:65 2019-01-16 19:08:56.620232: step 8119, loss = 0.69063 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:08:57.604165 ops/training.py:65 2019-01-16 19:08:57.604068: step 8120, loss = 0.70679 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:08:58.588072 ops/training.py:65 2019-01-16 19:08:58.587982: step 8121, loss = 0.67357 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 19:08:59.573408 ops/training.py:65 2019-01-16 19:08:59.573297: step 8122, loss = 0.69684 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:09:00.557373 ops/training.py:65 2019-01-16 19:09:00.557259: step 8123, loss = 0.70090 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:09:01.541342 ops/training.py:65 2019-01-16 19:09:01.541243: step 8124, loss = 0.67448 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:09:02.526285 ops/training.py:65 2019-01-16 19:09:02.526192: step 8125, loss = 0.69768 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:09:03.511653 ops/training.py:65 2019-01-16 19:09:03.511557: step 8126, loss = 0.68889 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:09:04.497643 ops/training.py:65 2019-01-16 19:09:04.497537: step 8127, loss = 0.70151 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:09:05.482661 ops/training.py:65 2019-01-16 19:09:05.482564: step 8128, loss = 0.69497 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:09:06.467191 ops/training.py:65 2019-01-16 19:09:06.467081: step 8129, loss = 0.69333 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:09:07.451294 ops/training.py:65 2019-01-16 19:09:07.451193: step 8130, loss = 0.68150 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:09:08.434337 ops/training.py:65 2019-01-16 19:09:08.434225: step 8131, loss = 0.69721 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:09:09.417566 ops/training.py:65 2019-01-16 19:09:09.417468: step 8132, loss = 0.69025 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:09:10.401000 ops/training.py:65 2019-01-16 19:09:10.400895: step 8133, loss = 0.69860 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:09:11.385599 ops/training.py:65 2019-01-16 19:09:11.385491: step 8134, loss = 0.70427 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:09:12.369239 ops/training.py:65 2019-01-16 19:09:12.369132: step 8135, loss = 0.71223 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:09:13.352891 ops/training.py:65 2019-01-16 19:09:13.352803: step 8136, loss = 0.70182 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:09:14.335596 ops/training.py:65 2019-01-16 19:09:14.335457: step 8137, loss = 0.68992 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:09:15.319197 ops/training.py:65 2019-01-16 19:09:15.319092: step 8138, loss = 0.69517 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:09:16.302494 ops/training.py:65 2019-01-16 19:09:16.302392: step 8139, loss = 0.67835 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:09:17.285658 ops/training.py:65 2019-01-16 19:09:17.285558: step 8140, loss = 0.69915 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:09:18.268582 ops/training.py:65 2019-01-16 19:09:18.268477: step 8141, loss = 0.69158 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:09:19.251896 ops/training.py:65 2019-01-16 19:09:19.251801: step 8142, loss = 0.67294 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:09:20.236074 ops/training.py:65 2019-01-16 19:09:20.235982: step 8143, loss = 0.70567 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:09:21.219281 ops/training.py:65 2019-01-16 19:09:21.219184: step 8144, loss = 0.70193 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:09:22.202055 ops/training.py:65 2019-01-16 19:09:22.201957: step 8145, loss = 0.69814 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:09:23.185617 ops/training.py:65 2019-01-16 19:09:23.185515: step 8146, loss = 0.68567 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:09:24.169940 ops/training.py:65 2019-01-16 19:09:24.169834: step 8147, loss = 0.69780 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:09:25.154378 ops/training.py:65 2019-01-16 19:09:25.154278: step 8148, loss = 0.68617 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:09:26.139620 ops/training.py:65 2019-01-16 19:09:26.139517: step 8149, loss = 0.69016 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:09:27.124714 ops/training.py:65 2019-01-16 19:09:27.124610: step 8150, loss = 0.68936 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:09:28.110579 ops/training.py:65 2019-01-16 19:09:28.110479: step 8151, loss = 0.70320 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:09:29.094535 ops/training.py:65 2019-01-16 19:09:29.094436: step 8152, loss = 0.69439 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:09:30.078690 ops/training.py:65 2019-01-16 19:09:30.078593: step 8153, loss = 0.68303 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:09:31.061911 ops/training.py:65 2019-01-16 19:09:31.061810: step 8154, loss = 0.68969 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:09:32.045036 ops/training.py:65 2019-01-16 19:09:32.044935: step 8155, loss = 0.66888 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:09:33.028559 ops/training.py:65 2019-01-16 19:09:33.028470: step 8156, loss = 0.68863 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:09:34.011949 ops/training.py:65 2019-01-16 19:09:34.011844: step 8157, loss = 0.68058 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:09:34.995337 ops/training.py:65 2019-01-16 19:09:34.995225: step 8158, loss = 0.67043 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 19:09:35.978325 ops/training.py:65 2019-01-16 19:09:35.978224: step 8159, loss = 0.71326 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:09:36.959467 ops/training.py:65 2019-01-16 19:09:36.959358: step 8160, loss = 0.69899 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:09:37.941036 ops/training.py:65 2019-01-16 19:09:37.940934: step 8161, loss = 0.68851 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:09:38.927379 ops/training.py:65 2019-01-16 19:09:38.927283: step 8162, loss = 0.69573 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:09:39.912075 ops/training.py:65 2019-01-16 19:09:39.911980: step 8163, loss = 0.68874 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:09:40.895751 ops/training.py:65 2019-01-16 19:09:40.895656: step 8164, loss = 0.68260 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:09:41.879312 ops/training.py:65 2019-01-16 19:09:41.879232: step 8165, loss = 0.69012 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:09:42.862293 ops/training.py:65 2019-01-16 19:09:42.862194: step 8166, loss = 0.69176 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:09:43.845300 ops/training.py:65 2019-01-16 19:09:43.845211: step 8167, loss = 0.74245 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 19:09:44.828081 ops/training.py:65 2019-01-16 19:09:44.827985: step 8168, loss = 0.69416 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:09:45.811193 ops/training.py:65 2019-01-16 19:09:45.811097: step 8169, loss = 0.68978 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:09:46.794689 ops/training.py:65 2019-01-16 19:09:46.794593: step 8170, loss = 0.69940 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:09:47.777717 ops/training.py:65 2019-01-16 19:09:47.777614: step 8171, loss = 0.70941 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:09:48.761652 ops/training.py:65 2019-01-16 19:09:48.761547: step 8172, loss = 0.69808 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:09:49.743886 ops/training.py:65 2019-01-16 19:09:49.743797: step 8173, loss = 0.70634 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:09:50.723825 ops/training.py:65 2019-01-16 19:09:50.723746: step 8174, loss = 0.69058 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:09:51.704371 ops/training.py:65 2019-01-16 19:09:51.704290: step 8175, loss = 0.68558 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:09:52.690593 ops/training.py:65 2019-01-16 19:09:52.690510: step 8176, loss = 0.69347 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:09:53.676385 ops/training.py:65 2019-01-16 19:09:53.676289: step 8177, loss = 0.69009 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:09:54.660280 ops/training.py:65 2019-01-16 19:09:54.660178: step 8178, loss = 0.70114 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:09:55.646048 ops/training.py:65 2019-01-16 19:09:55.645945: step 8179, loss = 0.70073 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:09:56.629428 ops/training.py:65 2019-01-16 19:09:56.629331: step 8180, loss = 0.69020 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:09:57.612705 ops/training.py:65 2019-01-16 19:09:57.612607: step 8181, loss = 0.69388 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:09:58.596154 ops/training.py:65 2019-01-16 19:09:58.596050: step 8182, loss = 0.69136 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:09:59.579863 ops/training.py:65 2019-01-16 19:09:59.579756: step 8183, loss = 0.70012 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:10:00.562689 ops/training.py:65 2019-01-16 19:10:00.562589: step 8184, loss = 0.69420 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:10:01.545506 ops/training.py:65 2019-01-16 19:10:01.545421: step 8185, loss = 0.69474 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:10:02.528610 ops/training.py:65 2019-01-16 19:10:02.528518: step 8186, loss = 0.68973 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:10:03.513078 ops/training.py:65 2019-01-16 19:10:03.513002: step 8187, loss = 0.68777 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:10:04.497422 ops/training.py:65 2019-01-16 19:10:04.497329: step 8188, loss = 0.70141 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:10:05.480350 ops/training.py:65 2019-01-16 19:10:05.480252: step 8189, loss = 0.68585 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:10:06.467149 ops/training.py:65 2019-01-16 19:10:06.467049: step 8190, loss = 0.69334 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:10:07.449929 ops/training.py:65 2019-01-16 19:10:07.449824: step 8191, loss = 0.68630 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 19:10:08.431972 ops/training.py:65 2019-01-16 19:10:08.431871: step 8192, loss = 0.69361 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:10:09.416058 ops/training.py:65 2019-01-16 19:10:09.415959: step 8193, loss = 0.71110 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 19:10:10.399132 ops/training.py:65 2019-01-16 19:10:10.399032: step 8194, loss = 0.68778 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:10:11.383514 ops/training.py:65 2019-01-16 19:10:11.383404: step 8195, loss = 0.70575 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:10:12.368530 ops/training.py:65 2019-01-16 19:10:12.368405: step 8196, loss = 0.68190 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 19:10:13.351814 ops/training.py:65 2019-01-16 19:10:13.351726: step 8197, loss = 0.70035 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:10:14.335361 ops/training.py:65 2019-01-16 19:10:14.335256: step 8198, loss = 0.69512 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:10:15.319497 ops/training.py:65 2019-01-16 19:10:15.319386: step 8199, loss = 0.70216 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:10:16.300607 ops/training.py:65 2019-01-16 19:10:16.300526: step 8200, loss = 0.68758 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:10:17.280345 ops/training.py:65 2019-01-16 19:10:17.280265: step 8201, loss = 0.68592 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:10:18.264991 ops/training.py:65 2019-01-16 19:10:18.264904: step 8202, loss = 0.70463 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 19:10:19.251502 ops/training.py:65 2019-01-16 19:10:19.251406: step 8203, loss = 0.70041 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:10:20.236233 ops/training.py:65 2019-01-16 19:10:20.236129: step 8204, loss = 0.68981 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:10:21.219284 ops/training.py:65 2019-01-16 19:10:21.219147: step 8205, loss = 0.68719 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:10:22.201374 ops/training.py:65 2019-01-16 19:10:22.201268: step 8206, loss = 0.70372 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:10:23.183775 ops/training.py:65 2019-01-16 19:10:23.183679: step 8207, loss = 0.69190 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:10:24.165600 ops/training.py:65 2019-01-16 19:10:24.165495: step 8208, loss = 0.68926 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:10:25.149483 ops/training.py:65 2019-01-16 19:10:25.149384: step 8209, loss = 0.69988 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:10:26.131204 ops/training.py:65 2019-01-16 19:10:26.131106: step 8210, loss = 0.69144 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:10:27.118175 ops/training.py:65 2019-01-16 19:10:27.118072: step 8211, loss = 0.68071 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:10:28.103381 ops/training.py:65 2019-01-16 19:10:28.103300: step 8212, loss = 0.68409 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:10:29.088309 ops/training.py:65 2019-01-16 19:10:29.088217: step 8213, loss = 0.68344 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:10:30.071915 ops/training.py:65 2019-01-16 19:10:30.071819: step 8214, loss = 0.69879 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:10:31.055861 ops/training.py:65 2019-01-16 19:10:31.055763: step 8215, loss = 0.68098 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 19:10:32.038068 ops/training.py:65 2019-01-16 19:10:32.037965: step 8216, loss = 0.67924 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 19:10:33.019706 ops/training.py:65 2019-01-16 19:10:33.019609: step 8217, loss = 0.68853 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:10:34.001864 ops/training.py:65 2019-01-16 19:10:34.001761: step 8218, loss = 0.69330 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:10:34.986489 ops/training.py:65 2019-01-16 19:10:34.986408: step 8219, loss = 0.68966 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:10:35.969736 ops/training.py:65 2019-01-16 19:10:35.969644: step 8220, loss = 0.68841 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:10:36.952622 ops/training.py:65 2019-01-16 19:10:36.952528: step 8221, loss = 0.69512 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:10:37.936478 ops/training.py:65 2019-01-16 19:10:37.936376: step 8222, loss = 0.69654 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 19:10:38.920394 ops/training.py:65 2019-01-16 19:10:38.920302: step 8223, loss = 0.68591 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:10:39.905538 ops/training.py:65 2019-01-16 19:10:39.905448: step 8224, loss = 0.70559 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:10:40.889897 ops/training.py:65 2019-01-16 19:10:40.889796: step 8225, loss = 0.71347 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:10:41.872660 ops/training.py:65 2019-01-16 19:10:41.872519: step 8226, loss = 0.68381 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:10:42.856313 ops/training.py:65 2019-01-16 19:10:42.856220: step 8227, loss = 0.68914 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:10:43.842812 ops/training.py:65 2019-01-16 19:10:43.842708: step 8228, loss = 0.72350 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 19:10:44.829407 ops/training.py:65 2019-01-16 19:10:44.829298: step 8229, loss = 0.69678 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:10:45.814305 ops/training.py:65 2019-01-16 19:10:45.814203: step 8230, loss = 0.70249 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:10:46.796452 ops/training.py:65 2019-01-16 19:10:46.796316: step 8231, loss = 0.66365 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:10:47.779328 ops/training.py:65 2019-01-16 19:10:47.779222: step 8232, loss = 0.69702 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:10:48.762514 ops/training.py:65 2019-01-16 19:10:48.762405: step 8233, loss = 0.66542 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:10:49.747736 ops/training.py:65 2019-01-16 19:10:49.747654: step 8234, loss = 0.72711 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 19:10:50.731720 ops/training.py:65 2019-01-16 19:10:50.731620: step 8235, loss = 0.74010 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 19:10:51.716130 ops/training.py:65 2019-01-16 19:10:51.716028: step 8236, loss = 0.71934 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:10:52.700899 ops/training.py:65 2019-01-16 19:10:52.700804: step 8237, loss = 0.68115 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:10:53.686281 ops/training.py:65 2019-01-16 19:10:53.686186: step 8238, loss = 0.66421 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 19:10:54.669961 ops/training.py:65 2019-01-16 19:10:54.669855: step 8239, loss = 0.65868 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 19:10:55.653693 ops/training.py:65 2019-01-16 19:10:55.653595: step 8240, loss = 0.66976 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:10:56.636734 ops/training.py:65 2019-01-16 19:10:56.636628: step 8241, loss = 0.67684 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:10:57.620435 ops/training.py:65 2019-01-16 19:10:57.620337: step 8242, loss = 0.69136 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:10:58.604521 ops/training.py:65 2019-01-16 19:10:58.604418: step 8243, loss = 0.69506 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:10:59.588911 ops/training.py:65 2019-01-16 19:10:59.588805: step 8244, loss = 0.71621 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:11:00.574999 ops/training.py:65 2019-01-16 19:11:00.574898: step 8245, loss = 0.69238 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:11:01.558088 ops/training.py:65 2019-01-16 19:11:01.557985: step 8246, loss = 0.67020 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 19:11:02.540816 ops/training.py:65 2019-01-16 19:11:02.540710: step 8247, loss = 0.68402 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:11:03.524935 ops/training.py:65 2019-01-16 19:11:03.524863: step 8248, loss = 0.71476 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:11:04.509056 ops/training.py:65 2019-01-16 19:11:04.508948: step 8249, loss = 0.72373 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:11:05.492544 ops/training.py:65 2019-01-16 19:11:05.492443: step 8250, loss = 0.71875 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 19:11:06.476711 ops/training.py:65 2019-01-16 19:11:06.476611: step 8251, loss = 0.69972 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:11:07.460306 ops/training.py:65 2019-01-16 19:11:07.460202: step 8252, loss = 0.67987 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:11:08.444845 ops/training.py:65 2019-01-16 19:11:08.444746: step 8253, loss = 0.70473 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:11:09.427932 ops/training.py:65 2019-01-16 19:11:09.427829: step 8254, loss = 0.70283 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:11:10.410956 ops/training.py:65 2019-01-16 19:11:10.410849: step 8255, loss = 0.69519 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:11:11.393841 ops/training.py:65 2019-01-16 19:11:11.393733: step 8256, loss = 0.69670 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:11:12.376544 ops/training.py:65 2019-01-16 19:11:12.376443: step 8257, loss = 0.69253 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:11:13.359937 ops/training.py:65 2019-01-16 19:11:13.359845: step 8258, loss = 0.70230 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:11:14.343408 ops/training.py:65 2019-01-16 19:11:14.343307: step 8259, loss = 0.67254 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:11:15.325590 ops/training.py:65 2019-01-16 19:11:15.325490: step 8260, loss = 0.68332 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:11:16.308609 ops/training.py:65 2019-01-16 19:11:16.308508: step 8261, loss = 0.70708 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 19:11:17.290850 ops/training.py:65 2019-01-16 19:11:17.290748: step 8262, loss = 0.67907 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:11:18.273580 ops/training.py:65 2019-01-16 19:11:18.273479: step 8263, loss = 0.71090 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:11:19.257262 ops/training.py:65 2019-01-16 19:11:19.257161: step 8264, loss = 0.66794 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:11:20.241194 ops/training.py:65 2019-01-16 19:11:20.241099: step 8265, loss = 0.70135 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:11:21.225287 ops/training.py:65 2019-01-16 19:11:21.225185: step 8266, loss = 0.69103 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:11:22.210815 ops/training.py:65 2019-01-16 19:11:22.210715: step 8267, loss = 0.69693 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 19:11:23.196166 ops/training.py:65 2019-01-16 19:11:23.196073: step 8268, loss = 0.68692 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:11:24.180704 ops/training.py:65 2019-01-16 19:11:24.180607: step 8269, loss = 0.72774 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:11:25.165107 ops/training.py:65 2019-01-16 19:11:25.165015: step 8270, loss = 0.70641 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:11:26.148485 ops/training.py:65 2019-01-16 19:11:26.148385: step 8271, loss = 0.69334 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:11:27.132514 ops/training.py:65 2019-01-16 19:11:27.132411: step 8272, loss = 0.68587 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:11:28.115041 ops/training.py:65 2019-01-16 19:11:28.114949: step 8273, loss = 0.70074 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:11:29.097834 ops/training.py:65 2019-01-16 19:11:29.097728: step 8274, loss = 0.68884 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:11:30.082272 ops/training.py:65 2019-01-16 19:11:30.082173: step 8275, loss = 0.72103 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:11:31.068195 ops/training.py:65 2019-01-16 19:11:31.068087: step 8276, loss = 0.68978 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:11:32.052643 ops/training.py:65 2019-01-16 19:11:32.052536: step 8277, loss = 0.70564 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:11:33.038006 ops/training.py:65 2019-01-16 19:11:33.037881: step 8278, loss = 0.69451 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:11:34.023104 ops/training.py:65 2019-01-16 19:11:34.022999: step 8279, loss = 0.67895 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:11:35.007154 ops/training.py:65 2019-01-16 19:11:35.007052: step 8280, loss = 0.70245 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 19:11:35.989674 ops/training.py:65 2019-01-16 19:11:35.989567: step 8281, loss = 0.72568 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 19:11:36.973923 ops/training.py:65 2019-01-16 19:11:36.973830: step 8282, loss = 0.69159 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:11:37.957414 ops/training.py:65 2019-01-16 19:11:37.957306: step 8283, loss = 0.69736 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:11:38.941189 ops/training.py:65 2019-01-16 19:11:38.941117: step 8284, loss = 0.68085 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:11:39.925805 ops/training.py:65 2019-01-16 19:11:39.925732: step 8285, loss = 0.69222 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:11:40.909867 ops/training.py:65 2019-01-16 19:11:40.909765: step 8286, loss = 0.68590 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:11:41.892979 ops/training.py:65 2019-01-16 19:11:41.892874: step 8287, loss = 0.70414 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 19:11:42.874963 ops/training.py:65 2019-01-16 19:11:42.874876: step 8288, loss = 0.69697 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:11:43.857177 ops/training.py:65 2019-01-16 19:11:43.857080: step 8289, loss = 0.69399 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:11:44.839496 ops/training.py:65 2019-01-16 19:11:44.839390: step 8290, loss = 0.70397 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 19:11:45.822500 ops/training.py:65 2019-01-16 19:11:45.822399: step 8291, loss = 0.70776 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:11:46.806562 ops/training.py:65 2019-01-16 19:11:46.806463: step 8292, loss = 0.68972 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:11:47.790093 ops/training.py:65 2019-01-16 19:11:47.789985: step 8293, loss = 0.68594 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:11:48.772503 ops/training.py:65 2019-01-16 19:11:48.772398: step 8294, loss = 0.69420 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:11:49.754798 ops/training.py:65 2019-01-16 19:11:49.754693: step 8295, loss = 0.68412 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:11:50.736612 ops/training.py:65 2019-01-16 19:11:50.736503: step 8296, loss = 0.68590 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:11:51.719142 ops/training.py:65 2019-01-16 19:11:51.719003: step 8297, loss = 0.68203 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 19:11:52.701432 ops/training.py:65 2019-01-16 19:11:52.701361: step 8298, loss = 0.68284 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:11:53.681500 ops/training.py:65 2019-01-16 19:11:53.681421: step 8299, loss = 0.70341 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:11:54.667058 ops/training.py:65 2019-01-16 19:11:54.666963: step 8300, loss = 0.69701 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:11:55.653838 ops/training.py:65 2019-01-16 19:11:55.653730: step 8301, loss = 0.69966 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:11:56.638078 ops/training.py:65 2019-01-16 19:11:56.637973: step 8302, loss = 0.70624 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 19:11:57.621049 ops/training.py:65 2019-01-16 19:11:57.620924: step 8303, loss = 0.70839 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 19:11:58.603835 ops/training.py:65 2019-01-16 19:11:58.603700: step 8304, loss = 0.70320 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:11:59.586277 ops/training.py:65 2019-01-16 19:11:59.586173: step 8305, loss = 0.68996 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:12:00.570815 ops/training.py:65 2019-01-16 19:12:00.570715: step 8306, loss = 0.69121 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:12:01.554378 ops/training.py:65 2019-01-16 19:12:01.554278: step 8307, loss = 0.69628 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:12:02.537333 ops/training.py:65 2019-01-16 19:12:02.537230: step 8308, loss = 0.71412 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 19:12:03.519355 ops/training.py:65 2019-01-16 19:12:03.519278: step 8309, loss = 0.68044 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:12:04.505013 ops/training.py:65 2019-01-16 19:12:04.504930: step 8310, loss = 0.69217 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:12:05.490846 ops/training.py:65 2019-01-16 19:12:05.490743: step 8311, loss = 0.68841 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:12:06.474918 ops/training.py:65 2019-01-16 19:12:06.474817: step 8312, loss = 0.69883 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:12:07.459185 ops/training.py:65 2019-01-16 19:12:07.459085: step 8313, loss = 0.68775 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:12:08.442717 ops/training.py:65 2019-01-16 19:12:08.442622: step 8314, loss = 0.68213 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:12:09.425988 ops/training.py:65 2019-01-16 19:12:09.425889: step 8315, loss = 0.68555 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:12:10.408328 ops/training.py:65 2019-01-16 19:12:10.408228: step 8316, loss = 0.70863 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:12:11.392887 ops/training.py:65 2019-01-16 19:12:11.392780: step 8317, loss = 0.69259 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:12:12.379537 ops/training.py:65 2019-01-16 19:12:12.379441: step 8318, loss = 0.68707 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:12:13.363700 ops/training.py:65 2019-01-16 19:12:13.363607: step 8319, loss = 0.68172 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:12:14.347450 ops/training.py:65 2019-01-16 19:12:14.347352: step 8320, loss = 0.69604 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:12:15.331794 ops/training.py:65 2019-01-16 19:12:15.331694: step 8321, loss = 0.69744 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:12:16.315669 ops/training.py:65 2019-01-16 19:12:16.315567: step 8322, loss = 0.70525 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:12:17.298649 ops/training.py:65 2019-01-16 19:12:17.298547: step 8323, loss = 0.71727 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.3125
I8192 2019-01-16 19:12:18.284585 ops/training.py:65 2019-01-16 19:12:18.284488: step 8324, loss = 0.68458 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:12:19.270351 ops/training.py:65 2019-01-16 19:12:19.270249: step 8325, loss = 0.69379 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:12:20.255115 ops/training.py:65 2019-01-16 19:12:20.255022: step 8326, loss = 0.69685 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:12:21.239516 ops/training.py:65 2019-01-16 19:12:21.239417: step 8327, loss = 0.69960 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:12:22.224580 ops/training.py:65 2019-01-16 19:12:22.224480: step 8328, loss = 0.69285 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:12:23.208251 ops/training.py:65 2019-01-16 19:12:23.208154: step 8329, loss = 0.70662 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 19:12:24.191974 ops/training.py:65 2019-01-16 19:12:24.191880: step 8330, loss = 0.69028 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:12:25.175944 ops/training.py:65 2019-01-16 19:12:25.175844: step 8331, loss = 0.69624 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:12:26.157935 ops/training.py:65 2019-01-16 19:12:26.157841: step 8332, loss = 0.70667 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 19:12:27.140927 ops/training.py:65 2019-01-16 19:12:27.140861: step 8333, loss = 0.68773 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:12:28.120831 ops/training.py:65 2019-01-16 19:12:28.120764: step 8334, loss = 0.68601 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:12:29.101901 ops/training.py:65 2019-01-16 19:12:29.101832: step 8335, loss = 0.67021 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.75
I8192 2019-01-16 19:12:30.081991 ops/training.py:65 2019-01-16 19:12:30.081923: step 8336, loss = 0.70169 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:12:31.066414 ops/training.py:65 2019-01-16 19:12:31.066332: step 8337, loss = 0.69469 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:12:32.051100 ops/training.py:65 2019-01-16 19:12:32.051000: step 8338, loss = 0.70075 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:12:33.035412 ops/training.py:65 2019-01-16 19:12:33.035308: step 8339, loss = 0.69252 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:12:34.018220 ops/training.py:65 2019-01-16 19:12:34.018116: step 8340, loss = 0.70100 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:12:35.002310 ops/training.py:65 2019-01-16 19:12:35.002210: step 8341, loss = 0.69554 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:12:35.984956 ops/training.py:65 2019-01-16 19:12:35.984856: step 8342, loss = 0.68937 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:12:36.968249 ops/training.py:65 2019-01-16 19:12:36.968143: step 8343, loss = 0.69269 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:12:37.950921 ops/training.py:65 2019-01-16 19:12:37.950819: step 8344, loss = 0.69487 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:12:38.934741 ops/training.py:65 2019-01-16 19:12:38.934638: step 8345, loss = 0.69658 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:12:39.917991 ops/training.py:65 2019-01-16 19:12:39.917887: step 8346, loss = 0.68119 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:12:40.901657 ops/training.py:65 2019-01-16 19:12:40.901564: step 8347, loss = 0.70340 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:12:41.884682 ops/training.py:65 2019-01-16 19:12:41.884540: step 8348, loss = 0.70041 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 19:12:42.868207 ops/training.py:65 2019-01-16 19:12:42.868112: step 8349, loss = 0.69809 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:12:43.851282 ops/training.py:65 2019-01-16 19:12:43.851181: step 8350, loss = 0.70142 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:12:44.834728 ops/training.py:65 2019-01-16 19:12:44.834628: step 8351, loss = 0.70059 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:12:45.817482 ops/training.py:65 2019-01-16 19:12:45.817335: step 8352, loss = 0.69298 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:12:46.800368 ops/training.py:65 2019-01-16 19:12:46.800266: step 8353, loss = 0.69897 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:12:47.783385 ops/training.py:65 2019-01-16 19:12:47.783296: step 8354, loss = 0.69051 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:12:48.767084 ops/training.py:65 2019-01-16 19:12:48.766981: step 8355, loss = 0.69612 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:12:49.750246 ops/training.py:65 2019-01-16 19:12:49.750113: step 8356, loss = 0.68984 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:12:50.734026 ops/training.py:65 2019-01-16 19:12:50.733882: step 8357, loss = 0.69181 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:12:51.716829 ops/training.py:65 2019-01-16 19:12:51.716721: step 8358, loss = 0.69681 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:12:52.700137 ops/training.py:65 2019-01-16 19:12:52.700030: step 8359, loss = 0.69227 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:12:53.683061 ops/training.py:65 2019-01-16 19:12:53.682967: step 8360, loss = 0.68659 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:12:54.666770 ops/training.py:65 2019-01-16 19:12:54.666670: step 8361, loss = 0.68290 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:12:55.651974 ops/training.py:65 2019-01-16 19:12:55.651866: step 8362, loss = 0.69839 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:12:56.637961 ops/training.py:65 2019-01-16 19:12:56.637864: step 8363, loss = 0.68965 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:12:57.623018 ops/training.py:65 2019-01-16 19:12:57.622916: step 8364, loss = 0.68821 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:12:58.607434 ops/training.py:65 2019-01-16 19:12:58.607339: step 8365, loss = 0.68634 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:12:59.590260 ops/training.py:65 2019-01-16 19:12:59.590171: step 8366, loss = 0.70438 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:13:00.571073 ops/training.py:65 2019-01-16 19:13:00.571013: step 8367, loss = 0.69270 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:13:01.555343 ops/training.py:65 2019-01-16 19:13:01.555262: step 8368, loss = 0.70509 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:13:02.538502 ops/training.py:65 2019-01-16 19:13:02.538392: step 8369, loss = 0.69326 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:13:03.521030 ops/training.py:65 2019-01-16 19:13:03.520928: step 8370, loss = 0.68857 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:13:04.506827 ops/training.py:65 2019-01-16 19:13:04.506741: step 8371, loss = 0.69285 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:13:05.490049 ops/training.py:65 2019-01-16 19:13:05.489945: step 8372, loss = 0.69841 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:13:06.473381 ops/training.py:65 2019-01-16 19:13:06.473234: step 8373, loss = 0.70011 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:13:07.459263 ops/training.py:65 2019-01-16 19:13:07.459151: step 8374, loss = 0.68812 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:13:08.442740 ops/training.py:65 2019-01-16 19:13:08.442634: step 8375, loss = 0.70176 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:13:09.425582 ops/training.py:65 2019-01-16 19:13:09.425457: step 8376, loss = 0.70143 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 19:13:10.408166 ops/training.py:65 2019-01-16 19:13:10.408096: step 8377, loss = 0.70496 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:13:11.387887 ops/training.py:65 2019-01-16 19:13:11.387818: step 8378, loss = 0.69271 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:13:12.368448 ops/training.py:65 2019-01-16 19:13:12.368379: step 8379, loss = 0.69323 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:13:13.349800 ops/training.py:65 2019-01-16 19:13:13.349731: step 8380, loss = 0.68222 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 19:13:14.336158 ops/training.py:65 2019-01-16 19:13:14.336063: step 8381, loss = 0.69100 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:13:15.320231 ops/training.py:65 2019-01-16 19:13:15.320122: step 8382, loss = 0.69291 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:13:16.302905 ops/training.py:65 2019-01-16 19:13:16.302819: step 8383, loss = 0.71116 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:13:17.285038 ops/training.py:65 2019-01-16 19:13:17.284938: step 8384, loss = 0.69610 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:13:18.267750 ops/training.py:65 2019-01-16 19:13:18.267652: step 8385, loss = 0.66855 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:13:19.251128 ops/training.py:65 2019-01-16 19:13:19.251021: step 8386, loss = 0.69682 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:13:20.234451 ops/training.py:65 2019-01-16 19:13:20.234325: step 8387, loss = 0.68418 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:13:21.220550 ops/training.py:65 2019-01-16 19:13:21.220457: step 8388, loss = 0.69596 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:13:22.206267 ops/training.py:65 2019-01-16 19:13:22.206144: step 8389, loss = 0.69648 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:13:23.191606 ops/training.py:65 2019-01-16 19:13:23.191509: step 8390, loss = 0.70005 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:13:24.177010 ops/training.py:65 2019-01-16 19:13:24.176912: step 8391, loss = 0.68717 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:13:25.160024 ops/training.py:65 2019-01-16 19:13:25.159877: step 8392, loss = 0.70061 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:13:26.141907 ops/training.py:65 2019-01-16 19:13:26.141799: step 8393, loss = 0.67155 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:13:27.127644 ops/training.py:65 2019-01-16 19:13:27.127532: step 8394, loss = 0.69457 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:13:28.113503 ops/training.py:65 2019-01-16 19:13:28.113402: step 8395, loss = 0.70519 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:13:29.098312 ops/training.py:65 2019-01-16 19:13:29.098183: step 8396, loss = 0.69909 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:13:30.081893 ops/training.py:65 2019-01-16 19:13:30.081762: step 8397, loss = 0.70157 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:13:31.065271 ops/training.py:65 2019-01-16 19:13:31.065167: step 8398, loss = 0.71083 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:13:32.047558 ops/training.py:65 2019-01-16 19:13:32.047462: step 8399, loss = 0.68990 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:13:33.030445 ops/training.py:65 2019-01-16 19:13:33.030338: step 8400, loss = 0.68041 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:13:34.013422 ops/training.py:65 2019-01-16 19:13:34.013320: step 8401, loss = 0.67123 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 19:13:34.995162 ops/training.py:65 2019-01-16 19:13:34.995019: step 8402, loss = 0.71210 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:13:35.976655 ops/training.py:65 2019-01-16 19:13:35.976585: step 8403, loss = 0.69523 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:13:36.958402 ops/training.py:65 2019-01-16 19:13:36.958337: step 8404, loss = 0.69993 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:13:37.943414 ops/training.py:65 2019-01-16 19:13:37.943336: step 8405, loss = 0.69591 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:13:38.928016 ops/training.py:65 2019-01-16 19:13:38.927921: step 8406, loss = 0.69052 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:13:39.912107 ops/training.py:65 2019-01-16 19:13:39.912004: step 8407, loss = 0.69970 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:13:40.894617 ops/training.py:65 2019-01-16 19:13:40.894508: step 8408, loss = 0.68250 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:13:41.877317 ops/training.py:65 2019-01-16 19:13:41.877218: step 8409, loss = 0.70643 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:13:42.860027 ops/training.py:65 2019-01-16 19:13:42.859932: step 8410, loss = 0.69234 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:13:43.844006 ops/training.py:65 2019-01-16 19:13:43.843909: step 8411, loss = 0.69169 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:13:44.828385 ops/training.py:65 2019-01-16 19:13:44.828285: step 8412, loss = 0.70266 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:13:45.811883 ops/training.py:65 2019-01-16 19:13:45.811781: step 8413, loss = 0.67946 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 19:13:46.794776 ops/training.py:65 2019-01-16 19:13:46.794674: step 8414, loss = 0.69701 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:13:47.778441 ops/training.py:65 2019-01-16 19:13:47.778333: step 8415, loss = 0.69860 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:13:48.761916 ops/training.py:65 2019-01-16 19:13:48.761807: step 8416, loss = 0.68726 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:13:49.745987 ops/training.py:65 2019-01-16 19:13:49.745884: step 8417, loss = 0.69570 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:13:50.729883 ops/training.py:65 2019-01-16 19:13:50.729772: step 8418, loss = 0.69945 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:13:51.714943 ops/training.py:65 2019-01-16 19:13:51.714837: step 8419, loss = 0.69151 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:13:52.698548 ops/training.py:65 2019-01-16 19:13:52.698479: step 8420, loss = 0.70278 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:13:53.683598 ops/training.py:65 2019-01-16 19:13:53.683516: step 8421, loss = 0.69542 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:13:54.668610 ops/training.py:65 2019-01-16 19:13:54.668505: step 8422, loss = 0.69585 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:13:55.653245 ops/training.py:65 2019-01-16 19:13:55.653138: step 8423, loss = 0.69245 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:13:56.638554 ops/training.py:65 2019-01-16 19:13:56.638449: step 8424, loss = 0.69630 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:13:57.623144 ops/training.py:65 2019-01-16 19:13:57.623038: step 8425, loss = 0.68716 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:13:58.606171 ops/training.py:65 2019-01-16 19:13:58.606072: step 8426, loss = 0.70263 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:13:59.591760 ops/training.py:65 2019-01-16 19:13:59.591676: step 8427, loss = 0.68783 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:14:00.576831 ops/training.py:65 2019-01-16 19:14:00.576722: step 8428, loss = 0.67808 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 19:14:01.563050 ops/training.py:65 2019-01-16 19:14:01.562950: step 8429, loss = 0.69191 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:14:02.544736 ops/training.py:65 2019-01-16 19:14:02.544635: step 8430, loss = 0.68943 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 19:14:03.526740 ops/training.py:65 2019-01-16 19:14:03.526664: step 8431, loss = 0.70455 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:14:04.507298 ops/training.py:65 2019-01-16 19:14:04.507228: step 8432, loss = 0.68747 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:14:05.490633 ops/training.py:65 2019-01-16 19:14:05.490565: step 8433, loss = 0.69282 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:14:06.475695 ops/training.py:65 2019-01-16 19:14:06.475597: step 8434, loss = 0.68933 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:14:07.460520 ops/training.py:65 2019-01-16 19:14:07.460422: step 8435, loss = 0.68977 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:14:08.445005 ops/training.py:65 2019-01-16 19:14:08.444897: step 8436, loss = 0.68660 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:14:09.428393 ops/training.py:65 2019-01-16 19:14:09.428292: step 8437, loss = 0.70328 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 19:14:10.411700 ops/training.py:65 2019-01-16 19:14:10.411564: step 8438, loss = 0.68995 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:14:11.396411 ops/training.py:65 2019-01-16 19:14:11.396310: step 8439, loss = 0.69948 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 19:14:12.380205 ops/training.py:65 2019-01-16 19:14:12.380103: step 8440, loss = 0.69350 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:14:13.363358 ops/training.py:65 2019-01-16 19:14:13.363266: step 8441, loss = 0.69197 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:14:14.346576 ops/training.py:65 2019-01-16 19:14:14.346467: step 8442, loss = 0.69292 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:14:15.329897 ops/training.py:65 2019-01-16 19:14:15.329789: step 8443, loss = 0.70172 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:14:16.315934 ops/training.py:65 2019-01-16 19:14:16.315831: step 8444, loss = 0.68576 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:14:17.301221 ops/training.py:65 2019-01-16 19:14:17.301116: step 8445, loss = 0.69348 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:14:18.285816 ops/training.py:65 2019-01-16 19:14:18.285709: step 8446, loss = 0.69446 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:14:19.269638 ops/training.py:65 2019-01-16 19:14:19.269529: step 8447, loss = 0.69739 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:14:20.250726 ops/training.py:65 2019-01-16 19:14:20.250649: step 8448, loss = 0.67943 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 19:14:21.231774 ops/training.py:65 2019-01-16 19:14:21.231715: step 8449, loss = 0.70081 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:14:22.212336 ops/training.py:65 2019-01-16 19:14:22.212271: step 8450, loss = 0.69686 (32.7 examples/sec; 0.980 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:14:23.196736 ops/training.py:65 2019-01-16 19:14:23.196654: step 8451, loss = 0.68875 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:14:24.181544 ops/training.py:65 2019-01-16 19:14:24.181442: step 8452, loss = 0.68977 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:14:25.165714 ops/training.py:65 2019-01-16 19:14:25.165606: step 8453, loss = 0.69712 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:14:26.149166 ops/training.py:65 2019-01-16 19:14:26.149059: step 8454, loss = 0.69042 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:14:27.133820 ops/training.py:65 2019-01-16 19:14:27.133716: step 8455, loss = 0.69503 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:14:28.119522 ops/training.py:65 2019-01-16 19:14:28.119426: step 8456, loss = 0.69672 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:14:29.103231 ops/training.py:65 2019-01-16 19:14:29.103129: step 8457, loss = 0.68188 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 19:14:30.088910 ops/training.py:65 2019-01-16 19:14:30.088804: step 8458, loss = 0.69286 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:14:31.073907 ops/training.py:65 2019-01-16 19:14:31.073800: step 8459, loss = 0.70717 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:14:32.056993 ops/training.py:65 2019-01-16 19:14:32.056888: step 8460, loss = 0.69760 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:14:33.040440 ops/training.py:65 2019-01-16 19:14:33.040342: step 8461, loss = 0.70017 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:14:34.023998 ops/training.py:65 2019-01-16 19:14:34.023893: step 8462, loss = 0.71292 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:14:35.006899 ops/training.py:65 2019-01-16 19:14:35.006800: step 8463, loss = 0.67311 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 19:14:35.989788 ops/training.py:65 2019-01-16 19:14:35.989713: step 8464, loss = 0.69823 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:14:36.971369 ops/training.py:65 2019-01-16 19:14:36.971307: step 8465, loss = 0.68894 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:14:37.953069 ops/training.py:65 2019-01-16 19:14:37.953005: step 8466, loss = 0.68965 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 19:14:38.934352 ops/training.py:65 2019-01-16 19:14:38.934284: step 8467, loss = 0.69356 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:14:39.917556 ops/training.py:65 2019-01-16 19:14:39.917485: step 8468, loss = 0.71105 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:14:40.902755 ops/training.py:65 2019-01-16 19:14:40.902659: step 8469, loss = 0.70587 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 19:14:41.886362 ops/training.py:65 2019-01-16 19:14:41.886256: step 8470, loss = 0.73444 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.1875
I8192 2019-01-16 19:14:42.869945 ops/training.py:65 2019-01-16 19:14:42.869846: step 8471, loss = 0.68509 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:14:43.852738 ops/training.py:65 2019-01-16 19:14:43.852641: step 8472, loss = 0.68844 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:14:44.837341 ops/training.py:65 2019-01-16 19:14:44.837237: step 8473, loss = 0.71794 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:14:45.820729 ops/training.py:65 2019-01-16 19:14:45.820623: step 8474, loss = 0.68108 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.6875
I8192 2019-01-16 19:14:46.803021 ops/training.py:65 2019-01-16 19:14:46.802920: step 8475, loss = 0.67987 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:14:47.787940 ops/training.py:65 2019-01-16 19:14:47.787836: step 8476, loss = 0.67861 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:14:48.772367 ops/training.py:65 2019-01-16 19:14:48.772264: step 8477, loss = 0.70049 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 19:14:49.757766 ops/training.py:65 2019-01-16 19:14:49.757673: step 8478, loss = 0.69891 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:14:50.742744 ops/training.py:65 2019-01-16 19:14:50.742643: step 8479, loss = 0.67703 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:14:51.726812 ops/training.py:65 2019-01-16 19:14:51.726707: step 8480, loss = 0.73753 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.21875
I8192 2019-01-16 19:14:52.711327 ops/training.py:65 2019-01-16 19:14:52.711222: step 8481, loss = 0.68885 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:14:53.694867 ops/training.py:65 2019-01-16 19:14:53.694760: step 8482, loss = 0.68777 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:14:54.678155 ops/training.py:65 2019-01-16 19:14:54.678049: step 8483, loss = 0.70517 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:14:55.661010 ops/training.py:65 2019-01-16 19:14:55.660893: step 8484, loss = 0.70039 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:14:56.644427 ops/training.py:65 2019-01-16 19:14:56.644323: step 8485, loss = 0.68231 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:14:57.625867 ops/training.py:65 2019-01-16 19:14:57.625752: step 8486, loss = 0.69644 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:14:58.611298 ops/training.py:65 2019-01-16 19:14:58.611210: step 8487, loss = 0.70056 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:14:59.596453 ops/training.py:65 2019-01-16 19:14:59.596345: step 8488, loss = 0.68961 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:15:00.583430 ops/training.py:65 2019-01-16 19:15:00.583322: step 8489, loss = 0.70400 (32.5 examples/sec; 0.986 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:15:01.568234 ops/training.py:65 2019-01-16 19:15:01.568133: step 8490, loss = 0.70969 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:15:02.550819 ops/training.py:65 2019-01-16 19:15:02.550721: step 8491, loss = 0.69255 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:15:03.536139 ops/training.py:65 2019-01-16 19:15:03.536039: step 8492, loss = 0.71247 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:15:04.520298 ops/training.py:65 2019-01-16 19:15:04.520206: step 8493, loss = 0.69300 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:15:05.503797 ops/training.py:65 2019-01-16 19:15:05.503700: step 8494, loss = 0.69364 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:15:06.487392 ops/training.py:65 2019-01-16 19:15:06.487287: step 8495, loss = 0.68639 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:15:07.470343 ops/training.py:65 2019-01-16 19:15:07.470241: step 8496, loss = 0.68273 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 19:15:08.453594 ops/training.py:65 2019-01-16 19:15:08.453489: step 8497, loss = 0.71283 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:15:09.436134 ops/training.py:65 2019-01-16 19:15:09.436029: step 8498, loss = 0.69907 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:15:10.418797 ops/training.py:65 2019-01-16 19:15:10.418699: step 8499, loss = 0.69087 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:15:11.402291 ops/training.py:65 2019-01-16 19:15:11.402190: step 8500, loss = 0.70340 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:15:12.385208 ops/training.py:65 2019-01-16 19:15:12.385103: step 8501, loss = 0.71723 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 19:15:13.370378 ops/training.py:65 2019-01-16 19:15:13.370282: step 8502, loss = 0.70299 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:15:14.355402 ops/training.py:65 2019-01-16 19:15:14.355297: step 8503, loss = 0.67670 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.65625
I8192 2019-01-16 19:15:15.339996 ops/training.py:65 2019-01-16 19:15:15.339881: step 8504, loss = 0.69181 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:15:16.323798 ops/training.py:65 2019-01-16 19:15:16.323692: step 8505, loss = 0.71943 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 19:15:17.308872 ops/training.py:65 2019-01-16 19:15:17.308775: step 8506, loss = 0.69244 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:15:18.292593 ops/training.py:65 2019-01-16 19:15:18.292519: step 8507, loss = 0.69570 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:15:19.274156 ops/training.py:65 2019-01-16 19:15:19.274078: step 8508, loss = 0.67087 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:15:20.259734 ops/training.py:65 2019-01-16 19:15:20.259651: step 8509, loss = 0.70051 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 19:15:21.244552 ops/training.py:65 2019-01-16 19:15:21.244452: step 8510, loss = 0.68889 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:15:22.228125 ops/training.py:65 2019-01-16 19:15:22.228023: step 8511, loss = 0.68997 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:15:23.211737 ops/training.py:65 2019-01-16 19:15:23.211638: step 8512, loss = 0.69852 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:15:24.197743 ops/training.py:65 2019-01-16 19:15:24.197645: step 8513, loss = 0.68173 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:15:25.182856 ops/training.py:65 2019-01-16 19:15:25.182758: step 8514, loss = 0.70866 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 19:15:26.167935 ops/training.py:65 2019-01-16 19:15:26.167837: step 8515, loss = 0.69144 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:15:27.150185 ops/training.py:65 2019-01-16 19:15:27.150085: step 8516, loss = 0.70253 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:15:28.131890 ops/training.py:65 2019-01-16 19:15:28.131795: step 8517, loss = 0.70112 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:15:29.114952 ops/training.py:65 2019-01-16 19:15:29.114847: step 8518, loss = 0.70952 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:15:30.098102 ops/training.py:65 2019-01-16 19:15:30.097995: step 8519, loss = 0.68827 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:15:31.083641 ops/training.py:65 2019-01-16 19:15:31.083534: step 8520, loss = 0.70727 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:15:32.070279 ops/training.py:65 2019-01-16 19:15:32.070168: step 8521, loss = 0.69236 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:15:33.055387 ops/training.py:65 2019-01-16 19:15:33.055286: step 8522, loss = 0.70865 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:15:34.040088 ops/training.py:65 2019-01-16 19:15:34.039986: step 8523, loss = 0.70029 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:15:35.029806 ops/training.py:65 2019-01-16 19:15:35.029698: step 8524, loss = 0.69639 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5625
I8192 2019-01-16 19:15:36.013468 ops/training.py:65 2019-01-16 19:15:36.013361: step 8525, loss = 0.68086 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:15:36.997755 ops/training.py:65 2019-01-16 19:15:36.997623: step 8526, loss = 0.68066 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:15:37.981462 ops/training.py:65 2019-01-16 19:15:37.981350: step 8527, loss = 0.69917 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 19:15:38.964894 ops/training.py:65 2019-01-16 19:15:38.964762: step 8528, loss = 0.67780 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:15:39.949214 ops/training.py:65 2019-01-16 19:15:39.949097: step 8529, loss = 0.69040 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:15:40.931836 ops/training.py:65 2019-01-16 19:15:40.931732: step 8530, loss = 0.70593 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.375
I8192 2019-01-16 19:15:41.914290 ops/training.py:65 2019-01-16 19:15:41.914183: step 8531, loss = 0.69291 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:15:42.899608 ops/training.py:65 2019-01-16 19:15:42.899512: step 8532, loss = 0.67568 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.59375
I8192 2019-01-16 19:15:43.883557 ops/training.py:65 2019-01-16 19:15:43.883452: step 8533, loss = 0.70971 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:15:44.866747 ops/training.py:65 2019-01-16 19:15:44.866641: step 8534, loss = 0.69996 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:15:45.851594 ops/training.py:65 2019-01-16 19:15:45.851490: step 8535, loss = 0.69066 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:15:46.836457 ops/training.py:65 2019-01-16 19:15:46.836354: step 8536, loss = 0.70320 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:15:47.822198 ops/training.py:65 2019-01-16 19:15:47.822094: step 8537, loss = 0.69926 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:15:48.807110 ops/training.py:65 2019-01-16 19:15:48.807003: step 8538, loss = 0.73095 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.25
I8192 2019-01-16 19:15:49.790728 ops/training.py:65 2019-01-16 19:15:49.790622: step 8539, loss = 0.69932 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:15:50.772442 ops/training.py:65 2019-01-16 19:15:50.772320: step 8540, loss = 0.69104 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:15:51.758240 ops/training.py:65 2019-01-16 19:15:51.758132: step 8541, loss = 0.70233 (32.5 examples/sec; 0.985 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:15:52.743243 ops/training.py:65 2019-01-16 19:15:52.743137: step 8542, loss = 0.69328 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:15:53.727862 ops/training.py:65 2019-01-16 19:15:53.727763: step 8543, loss = 0.69723 (32.5 examples/sec; 0.983 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:15:54.711876 ops/training.py:65 2019-01-16 19:15:54.711737: step 8544, loss = 0.71162 (32.6 examples/sec; 0.983 sec/batch) | Training accuracy = 0.46875
I8192 2019-01-16 19:15:55.695217 ops/training.py:65 2019-01-16 19:15:55.695109: step 8545, loss = 0.69823 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.53125
I8192 2019-01-16 19:15:56.678213 ops/training.py:65 2019-01-16 19:15:56.678104: step 8546, loss = 0.71614 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.34375
I8192 2019-01-16 19:15:57.661244 ops/training.py:65 2019-01-16 19:15:57.661141: step 8547, loss = 0.69700 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.40625
I8192 2019-01-16 19:15:58.644540 ops/training.py:65 2019-01-16 19:15:58.644445: step 8548, loss = 0.70284 (32.6 examples/sec; 0.981 sec/batch) | Training accuracy = 0.4375
I8192 2019-01-16 19:15:59.629794 ops/training.py:65 2019-01-16 19:15:59.629688: step 8549, loss = 0.69475 (32.5 examples/sec; 0.984 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:16:00.613023 ops/training.py:65 2019-01-16 19:16:00.612918: step 8550, loss = 0.67465 (32.6 examples/sec; 0.982 sec/batch) | Training accuracy = 0.625
I8192 2019-01-16 19:16:01.594453 ops/training.py:65 2019-01-16 19:16:01.594350: step 8551, loss = 0.70854 (32.6 examples/sec; 0.980 sec/batch) | Training accuracy = 0.5
I8192 2019-01-16 19:16:02.575152 ops/training.py:65 2019-01-16 19:16:02.575084: step 8552, loss = 0.67508 (32.7 examples/sec; 0.979 sec/batch) | Training accuracy = 0.625
